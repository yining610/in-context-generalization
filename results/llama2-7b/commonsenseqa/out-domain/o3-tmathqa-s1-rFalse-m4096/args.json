{"model_name": "llama2-7b", "model_type": "llama", "model_path": "/scratch4/danielk/ylu130/model-hf", "model_hf_name": "meta-llama/Llama-2-7b-hf", "is_opensource": true, "is_slurm": true, "data_name": "commonsenseqa", "data_dir": "/scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o3-tmathqa-s1-rFalse", "processed_data_dir": null, "num_eval": 1000, "num_in_domain": 0, "num_out_domain": 3, "out_domain_data_name": "mathqa", "out_domain_data_dir": null, "num_workers": 0, "max_prompt_length": 4096, "max_length": 512, "save": "/home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o3-tmathqa-s1-rFalse-m4096", "rationales": false, "top_k": 50, "top_p": 1.0, "do_sample": true, "num_beams": 1, "temperature": 1.0, "no_repeat_ngram_size": 6, "repetition_penalty": null, "batch_size": 10, "seed": 1, "deepspeed": true, "deepspeed_config": "/home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json", "deepscale": false, "deepscale_config": null, "deepspeed_mpi": false, "local_rank": 0, "rank": 0, "gpus_per_node": 1, "world_size": 1}