PYTHONPATH=/home/ylu130/workspace/in-context-generalization
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-out-domain 0 --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 4 --data-dir /scratch/ylu130/processed_data/commonsenseqa/in-domain/i0-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-in-domain 0
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-27 13:26:13,301] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-27 13:26:13,336] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-27 13:26:13,337] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-27 13:26:13,413] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/in-domain/i0-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 0
  out_domain_data_name ......... None
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i0-s1-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                                       | 0/9741 [00:00<?, ?it/s]Loading data: 100%|███████████████████████████████████████| 9741/9741 [00:00<00:00, 1339915.89it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:06<00:06,  6.98s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.03s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.08s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.21s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.63s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.22s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.64s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.22s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.65s/it]
[2023-08-27 13:26:23,969] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
 > number of parameters: 6738415616
[2023-08-27 13:26:24,025] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-27 13:26:24,046] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:10<00:10, 10.02s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:11<00:00,  5.27s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:11<00:00,  5.99s/it]
[2023-08-27 13:26:26,702] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-27 13:26:27,523] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-27 13:26:27,525] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-27 13:26:27,525] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-27 13:26:27,526] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-27 13:26:27,526] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-27 13:26:27,526] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-27 13:26:27,526] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-27 13:26:27,526] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-27 13:26:27,526] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-27 13:26:27,526] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-27 13:26:27,526] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-27 13:26:27,526] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fe27eb93520>
[2023-08-27 13:26:27,526] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-27 13:26:27,526] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-27 13:26:27,526] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-27 13:26:27,526] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-27 13:26:27,526] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-27 13:26:27,526] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-27 13:26:27,526] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-27 13:26:27,526] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-27 13:26:27,526] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-27 13:26:27,526] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-27 13:26:27,527] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-27 13:26:27,528] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-27 13:26:27,528] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-27 13:26:27,528] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-27 13:26:27,528] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-27 13:26:27,528] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-27 13:26:27,528] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-27 13:26:27,528] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-27 13:26:27,528] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-27 13:26:27,528] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-27 13:26:27,528] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-27 13:26:27,528] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-27 13:26:27,528] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-27 13:26:27,528] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-27 13:26:27,528] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-27 13:26:27,528] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-27 13:26:27,528] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-27 13:26:27,528] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                                            | 0/63 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.



Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i0-s1-rTrue-m4096
Evaluating commonsenseqa :   2%|▌                                | 1/63 [01:58<2:02:40, 118.72s/it]Evaluating commonsenseqa :   3%|█                                | 2/63 [03:38<1:49:32, 107.74s/it]Evaluating commonsenseqa :   5%|█▌                                | 3/63 [04:40<1:26:42, 86.71s/it]Evaluating commonsenseqa :   6%|██▎                                 | 4/63 [04:53<56:43, 57.69s/it]Evaluating commonsenseqa :   8%|██▊                                 | 5/63 [05:46<54:01, 55.88s/it]Evaluating commonsenseqa :  10%|███▏                              | 6/63 [07:44<1:13:17, 77.14s/it]Evaluating commonsenseqa :  11%|███▊                              | 7/63 [08:22<1:00:01, 64.32s/it]Evaluating commonsenseqa :  13%|████▌                               | 8/63 [09:15<55:29, 60.53s/it]Evaluating commonsenseqa :  14%|█████▏                              | 9/63 [10:11<53:21, 59.29s/it]Evaluating commonsenseqa :  16%|█████▏                           | 10/63 [12:08<1:08:04, 77.07s/it]Evaluating commonsenseqa :  17%|█████▊                           | 11/63 [13:08<1:02:14, 71.82s/it]Evaluating commonsenseqa :  19%|██████▎                          | 12/63 [14:49<1:08:29, 80.57s/it]Evaluating commonsenseqa :  21%|██████▊                          | 13/63 [16:46<1:16:25, 91.72s/it]Evaluating commonsenseqa :  22%|███████▎                         | 14/63 [18:45<1:21:32, 99.84s/it]Evaluating commonsenseqa :  24%|███████▊                         | 15/63 [19:58<1:13:24, 91.75s/it]Evaluating commonsenseqa :  25%|████████▍                        | 16/63 [20:46<1:01:42, 78.78s/it]Evaluating commonsenseqa :  27%|████████▉                        | 17/63 [22:23<1:04:40, 84.35s/it]Evaluating commonsenseqa :  29%|█████████▍                       | 18/63 [23:50<1:03:39, 84.88s/it]Evaluating commonsenseqa :  30%|██████████▌                        | 19/63 [24:28<51:55, 70.81s/it]Evaluating commonsenseqa :  32%|██████████▍                      | 20/63 [26:22<1:00:02, 83.79s/it]Evaluating commonsenseqa :  33%|███████████                      | 21/63 [28:19<1:05:43, 93.88s/it]Evaluating commonsenseqa :  35%|███████████▌                     | 22/63 [29:50<1:03:32, 93.00s/it]Evaluating commonsenseqa :  37%|████████████▊                      | 23/63 [30:45<54:27, 81.68s/it]Evaluating commonsenseqa :  38%|████████████▌                    | 24/63 [32:42<1:00:00, 92.33s/it]Evaluating commonsenseqa :  40%|█████████████                    | 25/63 [34:40<1:03:12, 99.80s/it]Evaluating commonsenseqa :  41%|██████████████▍                    | 26/63 [35:45<55:11, 89.51s/it]Evaluating commonsenseqa :  43%|███████████████                    | 27/63 [36:32<45:59, 76.66s/it]Evaluating commonsenseqa :  44%|███████████████▌                   | 28/63 [37:56<46:02, 78.92s/it]Evaluating commonsenseqa :  46%|████████████████                   | 29/63 [39:52<50:59, 89.98s/it]Evaluating commonsenseqa :  48%|████████████████▋                  | 30/63 [40:38<42:16, 76.88s/it]Evaluating commonsenseqa :  49%|█████████████████▏                 | 31/63 [41:34<37:42, 70.69s/it]Evaluating commonsenseqa :  51%|█████████████████▊                 | 32/63 [43:32<43:49, 84.83s/it]Evaluating commonsenseqa :  52%|██████████████████▎                | 33/63 [45:27<46:53, 93.77s/it]Evaluating commonsenseqa :  54%|██████████████████▎               | 34/63 [47:27<49:05, 101.57s/it]Evaluating commonsenseqa :  56%|██████████████████▉               | 35/63 [49:22<49:20, 105.72s/it]Evaluating commonsenseqa :  57%|███████████████████▍              | 36/63 [51:22<49:28, 109.94s/it]Evaluating commonsenseqa :  59%|███████████████████▉              | 37/63 [53:20<48:45, 112.53s/it]Evaluating commonsenseqa :  60%|████████████████████▌             | 38/63 [55:18<47:33, 114.13s/it]Evaluating commonsenseqa :  62%|█████████████████████▋             | 39/63 [55:55<36:18, 90.78s/it]Evaluating commonsenseqa :  63%|██████████████████████▏            | 40/63 [56:49<30:36, 79.87s/it]Evaluating commonsenseqa :  65%|██████████████████████▊            | 41/63 [58:05<28:53, 78.81s/it]Evaluating commonsenseqa :  67%|███████████████████████▎           | 42/63 [58:59<24:55, 71.20s/it]Evaluating commonsenseqa :  68%|██████████████████████▌          | 43/63 [1:00:14<24:10, 72.50s/it]Evaluating commonsenseqa :  70%|███████████████████████          | 44/63 [1:01:27<22:57, 72.48s/it]Evaluating commonsenseqa :  71%|███████████████████████▌         | 45/63 [1:03:23<25:40, 85.58s/it]Evaluating commonsenseqa :  73%|████████████████████████         | 46/63 [1:05:20<26:57, 95.13s/it]Evaluating commonsenseqa :  75%|███████████████████████▊        | 47/63 [1:07:14<26:52, 100.81s/it]Evaluating commonsenseqa :  76%|████████████████████████▍       | 48/63 [1:09:10<26:19, 105.28s/it]Evaluating commonsenseqa :  78%|████████████████████████▉       | 49/63 [1:10:41<23:33, 100.94s/it]Evaluating commonsenseqa :  79%|█████████████████████████▍      | 50/63 [1:12:38<22:56, 105.89s/it]Evaluating commonsenseqa :  81%|█████████████████████████▉      | 51/63 [1:14:05<20:00, 100.03s/it]Evaluating commonsenseqa :  83%|███████████████████████████▏     | 52/63 [1:15:22<17:06, 93.34s/it]Evaluating commonsenseqa :  84%|███████████████████████████▊     | 53/63 [1:17:04<15:59, 95.90s/it]Evaluating commonsenseqa :  86%|████████████████████████████▎    | 54/63 [1:17:31<11:15, 75.02s/it]Evaluating commonsenseqa :  87%|████████████████████████████▊    | 55/63 [1:19:28<11:41, 87.73s/it]Evaluating commonsenseqa :  89%|█████████████████████████████▎   | 56/63 [1:21:26<11:18, 96.91s/it]Evaluating commonsenseqa :  90%|█████████████████████████████▊   | 57/63 [1:21:56<07:40, 76.73s/it]Evaluating commonsenseqa :  92%|██████████████████████████████▍  | 58/63 [1:23:04<06:10, 74.01s/it]Evaluating commonsenseqa :  94%|██████████████████████████████▉  | 59/63 [1:25:01<05:48, 87.04s/it]Evaluating commonsenseqa :  95%|███████████████████████████████▍ | 60/63 [1:27:00<04:49, 96.52s/it]Evaluating commonsenseqa :  97%|██████████████████████████████▉ | 61/63 [1:28:56<03:25, 102.52s/it]Evaluating commonsenseqa :  98%|███████████████████████████████▍| 62/63 [1:30:35<01:41, 101.47s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████| 63/63 [1:31:40<00:00, 90.53s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████| 63/63 [1:31:40<00:00, 87.31s/it]
name: commonsenseqa | avg. gen lenth: 187.368 | time: 5500.952555179596s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-out-domain 0 --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 4 --data-dir /scratch/ylu130/processed_data/commonsenseqa/in-domain/i1-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-in-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-27 15:04:31,791] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-27 15:04:31,820] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-27 15:04:31,832] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-27 15:04:31,845] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/in-domain/i1-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 1
  num_out_domain ............... 0
  out_domain_data_name ......... None
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i1-s1-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                                       | 0/9740 [00:00<?, ?it/s]Loading data: 100%|████████████████████████████████████████| 9740/9740 [00:00<00:00, 809521.87it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:06<00:06,  6.53s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.05s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.11s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:08<00:00,  3.90s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:08<00:00,  4.30s/it]
[2023-08-27 15:04:41,651] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.23s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.65s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.26s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.69s/it]
Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:09<00:09,  9.40s/it] > number of parameters: 6738415616
[2023-08-27 15:04:42,424] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-27 15:04:42,458] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:11<00:00,  5.06s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:11<00:00,  5.71s/it]
[2023-08-27 15:04:44,533] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-27 15:04:45,226] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-27 15:04:45,230] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-27 15:04:45,232] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-27 15:04:45,232] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-27 15:04:45,233] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-27 15:04:45,233] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-27 15:04:45,234] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-27 15:04:45,234] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-27 15:04:45,234] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-27 15:04:45,234] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-27 15:04:45,234] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-27 15:04:45,234] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f0ccff57640>
[2023-08-27 15:04:45,234] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-27 15:04:45,234] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-27 15:04:45,234] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-27 15:04:45,235] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-27 15:04:45,235] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-27 15:04:45,235] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-27 15:04:45,235] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-27 15:04:45,235] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-27 15:04:45,235] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-27 15:04:45,235] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-27 15:04:45,235] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-27 15:04:45,235] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-27 15:04:45,235] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-27 15:04:45,235] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-27 15:04:45,235] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-27 15:04:45,235] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-27 15:04:45,235] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-27 15:04:45,235] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-27 15:04:45,236] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-27 15:04:45,236] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-27 15:04:45,236] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-27 15:04:45,236] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-27 15:04:45,236] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-27 15:04:45,236] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-27 15:04:45,236] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-27 15:04:45,236] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-27 15:04:45,236] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-27 15:04:45,236] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-27 15:04:45,236] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-27 15:04:45,237] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-27 15:04:45,237] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-27 15:04:45,237] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-27 15:04:45,237] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-27 15:04:45,237] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-27 15:04:45,237] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-27 15:04:45,237] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-27 15:04:45,237] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-27 15:04:45,237] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-27 15:04:45,237] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-27 15:04:45,237] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-27 15:04:45,237] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-27 15:04:45,238] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-27 15:04:45,238] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-27 15:04:45,238] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-27 15:04:45,238] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-27 15:04:45,238] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-27 15:04:45,238] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-27 15:04:45,238] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-27 15:04:45,238] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-27 15:04:45,238] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-27 15:04:45,238] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-27 15:04:45,238] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-27 15:04:45,238] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-27 15:04:45,238] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-27 15:04:45,238] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-27 15:04:45,238] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-27 15:04:45,239] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-27 15:04:45,239] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-27 15:04:45,239] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-27 15:04:45,239] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                                            | 0/63 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Output: 1. The question is asking where you could find some plumbing that would not be of use to you if you are thirsty.
2. We then consider each of the given options.
3. Option A: oil refineries. Even though there may be water available in oil refineries, it is not safe to drink as it may be contaminated with oil.
4. Option B: wall. In most cases, there may be water pipes inside walls of buildings that supplies water. Therefore, if you are thirsty, these pipes in the wall may be of use to you as they may contain drinkable water.
5. Option C: show. It doesn't specify what kind of "show" it is, but if it's a TV show, there could be no actual plumbing. If it's a trade show, you could find usable plumbing in display booths or restroom areas. Therefore, the possibility of getting drinkable water from a "show" depends largely on context and cannot be completely ruled out.
6. Option D: own home. This should not be the correct answer because in your own home, the plumbing serves you with fresh water, which you can drink when you're thirsty.
7. Option E: water fountain. Plumbing for a water fountain usually includes potable water that is treated and safe to drink.
8. After considering all the options, it is clear that option A, oil refineries, is the only one where you would not access potable water through the plumbing.
So the final answer is A: oil refineries

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i1-s1-rTrue-m4096
Evaluating commonsenseqa :   2%|▌                                | 1/63 [01:43<1:47:04, 103.61s/it]Evaluating commonsenseqa :   3%|█                                | 2/63 [03:24<1:43:45, 102.05s/it]Evaluating commonsenseqa :   5%|█▌                               | 3/63 [05:07<1:42:39, 102.66s/it]Evaluating commonsenseqa :   6%|██                               | 4/63 [06:50<1:40:45, 102.47s/it]Evaluating commonsenseqa :   8%|██▌                              | 5/63 [08:31<1:38:45, 102.17s/it]Evaluating commonsenseqa :  10%|███▏                             | 6/63 [10:13<1:36:57, 102.06s/it]Evaluating commonsenseqa :  11%|███▋                             | 7/63 [11:54<1:34:49, 101.59s/it]Evaluating commonsenseqa :  13%|████▏                            | 8/63 [13:38<1:33:45, 102.29s/it]Evaluating commonsenseqa :  14%|████▊                             | 9/63 [15:08<1:28:52, 98.74s/it]Evaluating commonsenseqa :  16%|█████                           | 10/63 [16:52<1:28:28, 100.16s/it]Evaluating commonsenseqa :  17%|█████▌                          | 11/63 [18:33<1:27:04, 100.47s/it]Evaluating commonsenseqa :  19%|██████                          | 12/63 [20:14<1:25:27, 100.54s/it]Evaluating commonsenseqa :  21%|██████▌                         | 13/63 [21:58<1:24:37, 101.55s/it]Evaluating commonsenseqa :  22%|███████                         | 14/63 [23:41<1:23:16, 101.98s/it]Evaluating commonsenseqa :  24%|███████▊                         | 15/63 [24:37<1:10:31, 88.15s/it]Evaluating commonsenseqa :  25%|████████▍                        | 16/63 [26:18<1:12:07, 92.08s/it]Evaluating commonsenseqa :  27%|████████▉                        | 17/63 [28:00<1:12:58, 95.17s/it]Evaluating commonsenseqa :  29%|█████████▍                       | 18/63 [29:32<1:10:30, 94.02s/it]Evaluating commonsenseqa :  30%|█████████▉                       | 19/63 [31:16<1:11:10, 97.06s/it]Evaluating commonsenseqa :  32%|██████████▍                      | 20/63 [32:22<1:02:54, 87.77s/it]Evaluating commonsenseqa :  33%|███████████                      | 21/63 [34:04<1:04:25, 92.03s/it]Evaluating commonsenseqa :  35%|████████████▏                      | 22/63 [34:54<54:24, 79.63s/it]Evaluating commonsenseqa :  37%|████████████▊                      | 23/63 [36:36<57:22, 86.07s/it]Evaluating commonsenseqa :  38%|█████████████▎                     | 24/63 [38:18<59:04, 90.89s/it]Evaluating commonsenseqa :  40%|█████████████▉                     | 25/63 [40:00<59:46, 94.37s/it]Evaluating commonsenseqa :  41%|██████████████▍                    | 26/63 [41:41<59:17, 96.15s/it]Evaluating commonsenseqa :  43%|███████████████                    | 27/63 [43:21<58:29, 97.48s/it]Evaluating commonsenseqa :  44%|███████████████▌                   | 28/63 [45:02<57:32, 98.64s/it]Evaluating commonsenseqa :  46%|████████████████                   | 29/63 [46:45<56:30, 99.72s/it]Evaluating commonsenseqa :  48%|████████████████▏                 | 30/63 [48:27<55:17, 100.52s/it]Evaluating commonsenseqa :  49%|████████████████▋                 | 31/63 [50:11<54:11, 101.60s/it]Evaluating commonsenseqa :  51%|█████████████████▊                 | 32/63 [51:28<48:37, 94.12s/it]Evaluating commonsenseqa :  52%|██████████████████▎                | 33/63 [53:09<48:07, 96.25s/it]Evaluating commonsenseqa :  54%|██████████████████▉                | 34/63 [54:06<40:45, 84.31s/it]Evaluating commonsenseqa :  56%|███████████████████▍               | 35/63 [55:46<41:39, 89.26s/it]Evaluating commonsenseqa :  57%|████████████████████               | 36/63 [57:27<41:41, 92.66s/it]Evaluating commonsenseqa :  59%|████████████████████▌              | 37/63 [59:10<41:28, 95.73s/it]Evaluating commonsenseqa :  60%|███████████████████▉             | 38/63 [1:00:52<40:42, 97.71s/it]Evaluating commonsenseqa :  62%|████████████████████▍            | 39/63 [1:01:54<34:47, 86.99s/it]Evaluating commonsenseqa :  63%|████████████████████▉            | 40/63 [1:03:37<35:09, 91.71s/it]Evaluating commonsenseqa :  65%|█████████████████████▍           | 41/63 [1:05:20<34:52, 95.13s/it]Evaluating commonsenseqa :  67%|██████████████████████           | 42/63 [1:07:03<34:07, 97.49s/it]Evaluating commonsenseqa :  68%|██████████████████████▌          | 43/63 [1:08:45<32:59, 98.97s/it]Evaluating commonsenseqa :  70%|███████████████████████          | 44/63 [1:10:27<31:33, 99.67s/it]Evaluating commonsenseqa :  71%|██████████████████████▊         | 45/63 [1:12:08<30:03, 100.18s/it]Evaluating commonsenseqa :  73%|███████████████████████▎        | 46/63 [1:13:49<28:24, 100.26s/it]Evaluating commonsenseqa :  75%|███████████████████████▊        | 47/63 [1:15:30<26:50, 100.66s/it]Evaluating commonsenseqa :  76%|████████████████████████▍       | 48/63 [1:17:10<25:08, 100.56s/it]Evaluating commonsenseqa :  78%|█████████████████████████▋       | 49/63 [1:18:38<22:33, 96.69s/it]Evaluating commonsenseqa :  79%|██████████████████████████▏      | 50/63 [1:20:22<21:24, 98.79s/it]Evaluating commonsenseqa :  81%|██████████████████████████▋      | 51/63 [1:22:03<19:52, 99.41s/it]Evaluating commonsenseqa :  83%|██████████████████████████▍     | 52/63 [1:23:46<18:25, 100.51s/it]Evaluating commonsenseqa :  84%|██████████████████████████▉     | 53/63 [1:25:27<16:46, 100.60s/it]Evaluating commonsenseqa :  86%|████████████████████████████▎    | 54/63 [1:26:22<13:04, 87.20s/it]Evaluating commonsenseqa :  87%|████████████████████████████▊    | 55/63 [1:28:04<12:13, 91.63s/it]Evaluating commonsenseqa :  89%|█████████████████████████████▎   | 56/63 [1:29:46<11:02, 94.61s/it]Evaluating commonsenseqa :  90%|█████████████████████████████▊   | 57/63 [1:31:07<09:02, 90.44s/it]Evaluating commonsenseqa :  92%|██████████████████████████████▍  | 58/63 [1:32:48<07:48, 93.73s/it]Evaluating commonsenseqa :  94%|██████████████████████████████▉  | 59/63 [1:34:30<06:24, 96.19s/it]Evaluating commonsenseqa :  95%|███████████████████████████████▍ | 60/63 [1:36:12<04:53, 97.94s/it]Evaluating commonsenseqa :  97%|███████████████████████████████▉ | 61/63 [1:37:54<03:18, 99.22s/it]Evaluating commonsenseqa :  98%|███████████████████████████████▍| 62/63 [1:39:37<01:40, 100.31s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████| 63/63 [1:40:12<00:00, 80.82s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████| 63/63 [1:40:12<00:00, 95.44s/it]
name: commonsenseqa | avg. gen lenth: 344.448 | time: 6013.321685791016s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-out-domain 0 --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 4 --data-dir /scratch/ylu130/processed_data/commonsenseqa/in-domain/i2-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-in-domain 2
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-27 16:49:39,807] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-27 16:49:40,344] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-27 16:49:40,355] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-27 16:49:40,362] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/in-domain/i2-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 2
  num_out_domain ............... 0
  out_domain_data_name ......... None
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i2-s1-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                                       | 0/9739 [00:00<?, ?it/s]Loading data: 100%|████████████████████████████████████████| 9739/9739 [00:00<00:00, 856107.78it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.14s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.15s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.77s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.93s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.16s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.61s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.19s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.63s/it]
 > number of parameters: 6738415616
[2023-08-27 16:49:50,912] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-27 16:49:50,996] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:10<00:00,  4.58s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:10<00:00,  5.06s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:10<00:00,  4.52s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:10<00:00,  5.03s/it]
[2023-08-27 16:49:51,740] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-27 16:49:51,833] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-27 16:49:52,433] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-27 16:49:52,434] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-27 16:49:52,434] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-27 16:49:52,434] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-27 16:49:52,434] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-27 16:49:52,434] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7faab5273520>
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-27 16:49:52,435] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-27 16:49:52,436] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-27 16:49:52,436] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-27 16:49:52,436] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-27 16:49:52,436] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-27 16:49:52,436] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-27 16:49:52,436] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-27 16:49:52,436] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-27 16:49:52,436] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-27 16:49:52,436] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-27 16:49:52,436] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-27 16:49:52,436] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-27 16:49:52,436] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-27 16:49:52,436] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-27 16:49:52,436] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-27 16:49:52,436] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-27 16:49:52,436] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                                            | 0/63 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Output: 1. The question is asking for a place where plumbing exists but is not useful for someone who is thirsty. 
2. This means we are looking for a place where the plumbing doesn't carry potable water that one could drink to quench their thirst.
3. We can first eliminate choices that are obviously incorrect. The plumbing in your own home (D) and a water fountain (E) would undoubtedly be able to provide drinkable water. So these cannot be the correct options.
4. Considering option B, the wall, it could contain plumbing if, for example, it's a wall in a home with pipes for bathrooms or the kitchen running through it. Therefore, you could potentially get water from here if you're thirsty. We can rule this option out as well.
5. Looking at option C, the show, it's a bit unclear whether this is referring to a television show, a theatre show, or something else entirely. If we take it to mean a television or theatre show, then there certainly is no plumbing there that you could drink from. However, such shows typically don't have any plumbing to begin with, so this option is not a 'perfect' fit as per the exact wording of the question.
6. This leaves us with choice A, oil refineries. Oil refineries do have extensive plumbing for the transportation and processing of petroleum products. However, this plumbing system does not carry potable water, and definitely isn't something you could drink from if you're thirsty. 
7. Therefore the correct answer is A: oil refineries.
So the final answer is A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Output: 1. The question is about identifying what a person is not doing yet when they are beginning work.
2. Let's consider each answer choice:
    - A: working – This isn't the answer because when a person is beginning work, they are indeed working.
    - B: resting – This isn't applicable because not all people rest before they begin to work, and the process of beginning work is contradictory to resting. 
    - C: tiredness – This is not an action and therefore, it can't be the answer. 
    - D: accomplishing – In the context of this question, when a person is just beginning work, they haven't yet completed or accomplished any of the tasks they're setting out to do. Therefore, it's accurately describing what they aren't doing yet.
    - E: momentum – This isn't the correct answer either because one can have momentum as soon as they begin work.
3. With these considerations, the answer is D: accomplishing.
So the final answer is D: accomplishing

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i2-s1-rTrue-m4096
Evaluating commonsenseqa :   2%|▌                                 | 1/63 [01:33<1:37:06, 93.97s/it]Evaluating commonsenseqa :   3%|█                                 | 2/63 [03:07<1:35:10, 93.61s/it]Evaluating commonsenseqa :   5%|█▌                                | 3/63 [04:40<1:33:15, 93.26s/it]Evaluating commonsenseqa :   6%|██▏                               | 4/63 [06:12<1:31:23, 92.95s/it]Evaluating commonsenseqa :   8%|██▋                               | 5/63 [07:44<1:29:36, 92.71s/it]Evaluating commonsenseqa :  10%|███▏                              | 6/63 [09:17<1:28:09, 92.79s/it]Evaluating commonsenseqa :  11%|███▊                              | 7/63 [10:49<1:26:12, 92.37s/it]Evaluating commonsenseqa :  13%|████▎                             | 8/63 [12:21<1:24:42, 92.41s/it]Evaluating commonsenseqa :  14%|████▊                             | 9/63 [13:53<1:22:55, 92.15s/it]Evaluating commonsenseqa :  16%|█████▏                           | 10/63 [15:25<1:21:19, 92.06s/it]Evaluating commonsenseqa :  17%|█████▊                           | 11/63 [16:57<1:19:51, 92.15s/it]Evaluating commonsenseqa :  19%|██████▎                          | 12/63 [18:30<1:18:23, 92.23s/it]Evaluating commonsenseqa :  21%|██████▊                          | 13/63 [20:02<1:17:00, 92.40s/it]Evaluating commonsenseqa :  22%|███████▎                         | 14/63 [21:37<1:15:55, 92.97s/it]Evaluating commonsenseqa :  24%|███████▊                         | 15/63 [23:10<1:14:23, 92.99s/it]Evaluating commonsenseqa :  25%|████████▍                        | 16/63 [24:05<1:03:54, 81.59s/it]Evaluating commonsenseqa :  27%|████████▉                        | 17/63 [25:37<1:04:58, 84.74s/it]Evaluating commonsenseqa :  29%|█████████▍                       | 18/63 [27:09<1:05:17, 87.06s/it]Evaluating commonsenseqa :  30%|█████████▉                       | 19/63 [28:43<1:05:13, 88.94s/it]Evaluating commonsenseqa :  32%|██████████▍                      | 20/63 [30:16<1:04:38, 90.20s/it]Evaluating commonsenseqa :  33%|███████████                      | 21/63 [31:48<1:03:31, 90.76s/it]Evaluating commonsenseqa :  35%|███████████▌                     | 22/63 [33:13<1:00:47, 88.97s/it]Evaluating commonsenseqa :  37%|████████████                     | 23/63 [34:47<1:00:20, 90.52s/it]Evaluating commonsenseqa :  38%|█████████████▎                     | 24/63 [36:20<59:17, 91.21s/it]Evaluating commonsenseqa :  40%|█████████████▉                     | 25/63 [37:52<58:00, 91.59s/it]Evaluating commonsenseqa :  41%|██████████████▍                    | 26/63 [39:26<56:49, 92.14s/it]Evaluating commonsenseqa :  43%|███████████████                    | 27/63 [40:58<55:17, 92.15s/it]Evaluating commonsenseqa :  44%|███████████████▌                   | 28/63 [42:30<53:51, 92.33s/it]Evaluating commonsenseqa :  46%|████████████████                   | 29/63 [44:03<52:18, 92.32s/it]Evaluating commonsenseqa :  48%|████████████████▋                  | 30/63 [45:36<50:56, 92.61s/it]Evaluating commonsenseqa :  49%|█████████████████▏                 | 31/63 [47:08<49:18, 92.46s/it]Evaluating commonsenseqa :  51%|█████████████████▊                 | 32/63 [48:42<47:54, 92.74s/it]Evaluating commonsenseqa :  52%|██████████████████▎                | 33/63 [50:14<46:23, 92.79s/it]Evaluating commonsenseqa :  54%|██████████████████▉                | 34/63 [51:47<44:47, 92.66s/it]Evaluating commonsenseqa :  56%|███████████████████▍               | 35/63 [53:22<43:32, 93.29s/it]Evaluating commonsenseqa :  57%|████████████████████               | 36/63 [54:54<41:51, 93.00s/it]Evaluating commonsenseqa :  59%|████████████████████▌              | 37/63 [56:26<40:12, 92.79s/it]Evaluating commonsenseqa :  60%|█████████████████████              | 38/63 [57:59<38:37, 92.70s/it]Evaluating commonsenseqa :  62%|█████████████████████▋             | 39/63 [59:30<36:58, 92.43s/it]Evaluating commonsenseqa :  63%|████████████████████▉            | 40/63 [1:01:02<35:21, 92.26s/it]Evaluating commonsenseqa :  65%|█████████████████████▍           | 41/63 [1:02:36<33:59, 92.72s/it]Evaluating commonsenseqa :  67%|██████████████████████           | 42/63 [1:04:08<32:22, 92.50s/it]Evaluating commonsenseqa :  68%|██████████████████████▌          | 43/63 [1:05:40<30:43, 92.19s/it]Evaluating commonsenseqa :  70%|███████████████████████          | 44/63 [1:07:12<29:14, 92.36s/it]Evaluating commonsenseqa :  71%|███████████████████████▌         | 45/63 [1:08:45<27:42, 92.35s/it]Evaluating commonsenseqa :  73%|████████████████████████         | 46/63 [1:10:17<26:10, 92.41s/it]Evaluating commonsenseqa :  75%|████████████████████████▌        | 47/63 [1:11:51<24:43, 92.72s/it]Evaluating commonsenseqa :  76%|█████████████████████████▏       | 48/63 [1:13:23<23:10, 92.70s/it]Evaluating commonsenseqa :  78%|█████████████████████████▋       | 49/63 [1:14:55<21:35, 92.51s/it]Evaluating commonsenseqa :  79%|██████████████████████████▏      | 50/63 [1:16:27<20:00, 92.32s/it]Evaluating commonsenseqa :  81%|██████████████████████████▋      | 51/63 [1:18:00<18:30, 92.56s/it]Evaluating commonsenseqa :  83%|███████████████████████████▏     | 52/63 [1:19:32<16:55, 92.28s/it]Evaluating commonsenseqa :  84%|███████████████████████████▊     | 53/63 [1:21:04<15:22, 92.24s/it]Evaluating commonsenseqa :  86%|████████████████████████████▎    | 54/63 [1:22:37<13:52, 92.50s/it]Evaluating commonsenseqa :  87%|████████████████████████████▊    | 55/63 [1:24:11<12:21, 92.72s/it]Evaluating commonsenseqa :  89%|█████████████████████████████▎   | 56/63 [1:25:42<10:46, 92.30s/it]Evaluating commonsenseqa :  90%|█████████████████████████████▊   | 57/63 [1:27:16<09:17, 92.83s/it]Evaluating commonsenseqa :  92%|██████████████████████████████▍  | 58/63 [1:28:49<07:44, 92.87s/it]Evaluating commonsenseqa :  94%|██████████████████████████████▉  | 59/63 [1:30:21<06:10, 92.55s/it]Evaluating commonsenseqa :  95%|███████████████████████████████▍ | 60/63 [1:31:54<04:37, 92.65s/it]Evaluating commonsenseqa :  97%|███████████████████████████████▉ | 61/63 [1:33:27<03:05, 92.75s/it]Evaluating commonsenseqa :  98%|████████████████████████████████▍| 62/63 [1:35:01<01:33, 93.19s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████| 63/63 [1:35:53<00:00, 80.80s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████| 63/63 [1:35:53<00:00, 91.32s/it]
name: commonsenseqa | avg. gen lenth: 401.336 | time: 5753.569405555725s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-out-domain 0 --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 4 --data-dir /scratch/ylu130/processed_data/commonsenseqa/in-domain/i3-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-in-domain 3
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-27 18:26:13,624] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-27 18:26:13,627] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-27 18:26:13,628] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-27 18:26:13,639] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/in-domain/i3-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 3
  num_out_domain ............... 0
  out_domain_data_name ......... None
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i3-s1-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                                       | 0/9738 [00:00<?, ?it/s]Loading data: 100%|████████████████████████████████████████| 9738/9738 [00:00<00:00, 798095.48it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.10s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.13s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.24s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.52s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.21s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.64s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.17s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.62s/it]
 > number of parameters: 6738415616
[2023-08-27 18:26:24,331] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-27 18:26:24,367] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.35s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.79s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.32s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.80s/it]
[2023-08-27 18:26:24,711] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-27 18:26:24,752] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-27 18:26:25,330] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-27 18:26:25,331] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-27 18:26:25,331] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-27 18:26:25,331] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-27 18:26:25,331] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-27 18:26:25,331] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f2b6ba43520>
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-27 18:26:25,332] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-27 18:26:25,333] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-27 18:26:25,333] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-27 18:26:25,333] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-27 18:26:25,333] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-27 18:26:25,333] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-27 18:26:25,333] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-27 18:26:25,333] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-27 18:26:25,333] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-27 18:26:25,333] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-27 18:26:25,333] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-27 18:26:25,333] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-27 18:26:25,333] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-27 18:26:25,333] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-27 18:26:25,333] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-27 18:26:25,333] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-27 18:26:25,333] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-27 18:26:25,333] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-27 18:26:25,333] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-27 18:26:25,333] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-27 18:26:25,333] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-27 18:26:25,333] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-27 18:26:25,333] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                                            | 0/63 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Output: 1. The question is asking about a location where there would be plumbing, but it wouldn't be of use to you if you were thirsty.
2. When we are thirsty, we need to drink water for hydration.
3. To understand the possibilities, let's investigate the options individually.
4. Option A: Oil refineries have plumbing to transport oil and various by-products. These pipelines do not contain drinking water.
5. Option B: Walls may have plumbing inside for residential water distribution, which contains water.
6. Option C: Shows represent an event place and they could also have some plumbing for firefighting or sanitary purposes, which again, contains water.
7. Option D: Own home obviously contains plenty of plumbing for water usage.
8. Option E: Water fountains have plumbing that contains water which is drinkable.
9. Comparing all the choices, the only one that doesn't have drinking water in its plumbing is the oil refinery.
10. Thus, the answer is A: Oil refineries.
So the final answer is A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Output: 1. Let's examine each answer choice closely. 
2. Choice A: working. This cannot be the answer because when a person is beginning work, they are working.
3. Choice B: resting. This also cannot be the answer because when a person is beginning work, they are inherently not resting.
4. Choice C: tiredness. Similarly, this cannot be the answer because this is a state that can occur both during and after work, but not necessarily when a person is beginning work. 
5. Choice E: momentum. This is not the answer because momentum refers to the drive or push for doing something, which would likely be present at the beginning of work.
6. Lastly, we look at Choice D: accomplishing. This is the correct answer because when a person is beginning work, they are in the process of attempting to accomplish something. Therefore, they aren't accomplishing something yet, as the task is merely just starting and there hasn't been enough time to complete anything meaningful.
So the final answer is D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Output: 1. Begin by understanding what the question is asking. "Where might I find pens with a company logo?" The key here is "company logo". This implies a professional setting where a company will give out pens with their logo.
2. Let's eliminate the options that are not directly related to professional environments. "On a pencil" (B) is a place you wouldn't find a logoed pen because pens and pencils are different objects. "Write sentences on paper" (C) is not a place but an activity. 
3. Options "School" (D) and "Backpack" (E) could potentially have pens, but they are not the most direct answers. While a school or backpack might contain a logoed pen, they aren't places associated directly with companies. 
4. That leaves us with "Office" (A), which is a professional environment and the most likely place to find pens with a company logo. Companies often have pens with their logos in offices for employees to use or give to clients.
5. Therefore, the answer is A: Office.
So the final answer is A: office

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i3-s1-rTrue-m4096
Evaluating commonsenseqa :   2%|▌                                 | 1/63 [01:30<1:33:25, 90.42s/it]Evaluating commonsenseqa :   3%|█                                 | 2/63 [02:59<1:30:54, 89.42s/it]Evaluating commonsenseqa :   5%|█▌                                | 3/63 [04:27<1:28:55, 88.92s/it]Evaluating commonsenseqa :   6%|██▏                               | 4/63 [05:55<1:26:58, 88.44s/it]Evaluating commonsenseqa :   8%|██▋                               | 5/63 [07:23<1:25:22, 88.32s/it]Evaluating commonsenseqa :  10%|███▏                              | 6/63 [08:52<1:24:07, 88.55s/it]Evaluating commonsenseqa :  11%|███▊                              | 7/63 [10:21<1:22:51, 88.77s/it]Evaluating commonsenseqa :  13%|████▎                             | 8/63 [11:51<1:21:35, 89.01s/it]Evaluating commonsenseqa :  14%|████▊                             | 9/63 [13:19<1:20:05, 89.00s/it]Evaluating commonsenseqa :  16%|█████▏                           | 10/63 [14:47<1:18:09, 88.49s/it]Evaluating commonsenseqa :  17%|█████▊                           | 11/63 [16:14<1:16:27, 88.23s/it]Evaluating commonsenseqa :  19%|██████▎                          | 12/63 [17:42<1:14:48, 88.00s/it]Evaluating commonsenseqa :  21%|██████▊                          | 13/63 [19:11<1:13:37, 88.35s/it]Evaluating commonsenseqa :  22%|███████▎                         | 14/63 [20:38<1:11:53, 88.04s/it]Evaluating commonsenseqa :  24%|███████▊                         | 15/63 [22:06<1:10:16, 87.84s/it]Evaluating commonsenseqa :  25%|████████▍                        | 16/63 [23:35<1:09:08, 88.27s/it]Evaluating commonsenseqa :  27%|████████▉                        | 17/63 [25:03<1:07:33, 88.12s/it]Evaluating commonsenseqa :  29%|█████████▍                       | 18/63 [26:32<1:06:14, 88.33s/it]Evaluating commonsenseqa :  30%|█████████▉                       | 19/63 [27:59<1:04:35, 88.07s/it]Evaluating commonsenseqa :  32%|██████████▍                      | 20/63 [29:26<1:02:49, 87.67s/it]Evaluating commonsenseqa :  33%|███████████                      | 21/63 [30:53<1:01:15, 87.51s/it]Evaluating commonsenseqa :  35%|████████████▏                      | 22/63 [32:21<59:58, 87.76s/it]Evaluating commonsenseqa :  37%|████████████▊                      | 23/63 [33:49<58:25, 87.65s/it]Evaluating commonsenseqa :  38%|█████████████▎                     | 24/63 [35:16<56:51, 87.48s/it]Evaluating commonsenseqa :  40%|█████████████▉                     | 25/63 [36:44<55:29, 87.63s/it]Evaluating commonsenseqa :  41%|██████████████▍                    | 26/63 [38:10<53:51, 87.35s/it]Evaluating commonsenseqa :  43%|███████████████                    | 27/63 [39:38<52:31, 87.54s/it]Evaluating commonsenseqa :  44%|███████████████▌                   | 28/63 [41:06<51:05, 87.58s/it]Evaluating commonsenseqa :  46%|████████████████                   | 29/63 [42:34<49:42, 87.71s/it]Evaluating commonsenseqa :  48%|████████████████▋                  | 30/63 [44:02<48:19, 87.87s/it]Evaluating commonsenseqa :  49%|█████████████████▏                 | 31/63 [45:32<47:03, 88.24s/it]Evaluating commonsenseqa :  51%|█████████████████▊                 | 32/63 [46:59<45:27, 87.97s/it]Evaluating commonsenseqa :  52%|██████████████████▎                | 33/63 [48:27<43:56, 87.88s/it]Evaluating commonsenseqa :  54%|██████████████████▉                | 34/63 [49:54<42:28, 87.86s/it]Evaluating commonsenseqa :  56%|███████████████████▍               | 35/63 [51:22<40:56, 87.72s/it]Evaluating commonsenseqa :  57%|████████████████████               | 36/63 [52:50<39:30, 87.78s/it]Evaluating commonsenseqa :  59%|████████████████████▌              | 37/63 [54:18<38:04, 87.85s/it]Evaluating commonsenseqa :  60%|█████████████████████              | 38/63 [55:44<36:27, 87.52s/it]Evaluating commonsenseqa :  62%|█████████████████████▋             | 39/63 [57:12<35:00, 87.52s/it]Evaluating commonsenseqa :  63%|██████████████████████▏            | 40/63 [58:40<33:34, 87.59s/it]Evaluating commonsenseqa :  65%|█████████████████████▍           | 41/63 [1:00:08<32:14, 87.92s/it]Evaluating commonsenseqa :  67%|██████████████████████           | 42/63 [1:01:38<30:57, 88.45s/it]Evaluating commonsenseqa :  68%|██████████████████████▌          | 43/63 [1:03:05<29:21, 88.07s/it]Evaluating commonsenseqa :  70%|███████████████████████          | 44/63 [1:04:33<27:53, 88.06s/it]Evaluating commonsenseqa :  71%|███████████████████████▌         | 45/63 [1:06:01<26:21, 87.88s/it]Evaluating commonsenseqa :  73%|████████████████████████         | 46/63 [1:07:29<24:53, 87.84s/it]Evaluating commonsenseqa :  75%|████████████████████████▌        | 47/63 [1:08:57<23:27, 88.00s/it]Evaluating commonsenseqa :  76%|█████████████████████████▏       | 48/63 [1:10:25<22:02, 88.14s/it]Evaluating commonsenseqa :  78%|█████████████████████████▋       | 49/63 [1:11:54<20:35, 88.26s/it]Evaluating commonsenseqa :  79%|██████████████████████████▏      | 50/63 [1:13:09<18:14, 84.17s/it]Evaluating commonsenseqa :  81%|██████████████████████████▋      | 51/63 [1:14:37<17:05, 85.43s/it]Evaluating commonsenseqa :  83%|███████████████████████████▏     | 52/63 [1:16:05<15:49, 86.32s/it]Evaluating commonsenseqa :  84%|███████████████████████████▊     | 53/63 [1:17:18<13:43, 82.31s/it]Evaluating commonsenseqa :  86%|████████████████████████████▎    | 54/63 [1:18:46<12:34, 83.89s/it]Evaluating commonsenseqa :  87%|████████████████████████████▊    | 55/63 [1:20:14<11:21, 85.13s/it]Evaluating commonsenseqa :  89%|█████████████████████████████▎   | 56/63 [1:21:41<09:59, 85.70s/it]Evaluating commonsenseqa :  90%|█████████████████████████████▊   | 57/63 [1:23:09<08:39, 86.50s/it]Evaluating commonsenseqa :  92%|██████████████████████████████▍  | 58/63 [1:24:36<07:13, 86.69s/it]Evaluating commonsenseqa :  94%|██████████████████████████████▉  | 59/63 [1:26:04<05:48, 87.08s/it]Evaluating commonsenseqa :  95%|███████████████████████████████▍ | 60/63 [1:27:32<04:21, 87.30s/it]Evaluating commonsenseqa :  97%|███████████████████████████████▉ | 61/63 [1:28:59<02:54, 87.28s/it]Evaluating commonsenseqa :  98%|████████████████████████████████▍| 62/63 [1:30:26<01:27, 87.16s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████| 63/63 [1:31:16<00:00, 76.01s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████| 63/63 [1:31:16<00:00, 86.93s/it]
name: commonsenseqa | avg. gen lenth: 412.516 | time: 5477.207474708557s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-out-domain 0 --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 4 --data-dir /scratch/ylu130/processed_data/commonsenseqa/in-domain/i4-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-in-domain 4
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-27 19:58:36,580] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-27 19:58:36,633] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-27 19:58:36,684] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-27 19:58:36,697] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/in-domain/i4-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 4
  num_out_domain ............... 0
  out_domain_data_name ......... None
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i4-s1-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                                       | 0/9737 [00:00<?, ?it/s]Loading data: 100%|████████████████████████████████████████| 9737/9737 [00:00<00:00, 445996.92it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.02s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.31s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.39s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.44s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.24s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.65s/it]
[2023-08-27 19:58:47,560] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.30s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.77s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.32s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.79s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.36s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.81s/it]
[2023-08-27 19:58:47,773] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
 > number of parameters: 6738415616
[2023-08-27 19:58:47,789] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-27 19:58:47,800] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-27 19:58:48,372] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-27 19:58:48,373] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-27 19:58:48,373] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-27 19:58:48,373] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-27 19:58:48,373] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-27 19:58:48,373] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-27 19:58:48,373] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-27 19:58:48,373] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-27 19:58:48,373] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-27 19:58:48,373] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-27 19:58:48,373] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-27 19:58:48,373] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f610e553640>
[2023-08-27 19:58:48,373] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-27 19:58:48,373] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-27 19:58:48,374] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-27 19:58:48,375] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-27 19:58:48,375] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-27 19:58:48,375] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-27 19:58:48,375] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-27 19:58:48,375] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                                            | 0/63 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Output: 1. The question asks where you would find plumbing that is not useful to you when you are thirsty.
2. This means we're looking for a place with plumbing that does not contain potable, or drinkable, water.
3. The choices are: oil refineries, a wall, a show, your own home, and a water fountain.
4. You can eliminate "a wall" because generally, walls do not have plumbing.
5. You can also eliminate "a show" because it refers to a type of event rather than a place which could contain plumbing.
6. In your own home and at water fountains, you would generally expect the plumbing to supply clean, drinkable water. Therefore, these can also be eliminated.
7. That leaves "oil refineries." Oil refineries use complex systems of plumbing to transport and process oil.
8. You wouldn't want to or be able to drink the liquids (like oil or other chemicals) passing through an oil refinery's plumbing system. 
9. Therefore, the answer is A: oil refineries.
So the final answer is A: oil refineries.

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Output: 1. The question is asking for what a person isn't doing yet when they are beginning to work. 

2. Let's analyze each answer choice: 

   A: working - this suggests that the person is actually in action. But since they are just starting, they may not yet be fully engaged. However, they are still technically working. So, this isn't the right choice.
  
   B: resting - this implies that the person is not involved in any activities. If they are beginning to work, then they are definitely not resting. This answer can be eliminated as well.
   
   C: tiredness - this relates to a physical or mental state of exhaustion. It is possible that a person might feel tired at the beginning of work. However, it isn't necessarily true that they are not experiencing tiredness. So, this isn't the best choice.
   
   D: accomplishing - this refers to the act of achieving or completing something. If the person is just beginning to work, they have not completed or achieved their task yet. Thus, this could be a possible correct answer.
   
   E: momentum - this implies movement or progress. Since the person is just beginning work, they haven't started gaining momentum yet. It could be a close contender, but not as precise as choice D.

3. Therefore, the best answer is D: accomplishing, because when a person is just starting to work, they are not yet achieving or completing anything.
So the final answer is D: accomplishing.

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Output: Step 1: Understand the question, which is asking for a location where pens with a company logo might be found.
Step 2: Review each of the choices individually and analyze their relevance to the question.
Step 3: Look at choice A: "Office". This is a common setting where pens are used and many companies distribute logoed pens as promotional items to their employees or during meetings.
Step 4: Look at choice B: "On a pencil". This doesn't provide a location, rather a different object. This is not a logical answer to the question. 
Step 5: Look at choice C: "Write sentences on paper". This again is not a location so it cannot be the correct answer. 
Step 6: Look at choice D: "School". While this is a location and pens are used here, it's less usual to find pens with a company logo at a school as compared to an office.
Step 7: Look at choice E: "Backpack". Bags might hold pens, but it's not directly related to company logo pens, as these could be anywhere rather than specifically in a backpack.
Step 8: After reviewing all the choices, choice A "office" appears to be the most likely and logical location to find pens with a company logo.
So the final answer is A: office.

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Output: 1. The question is about what Billy is expecting after he calls out to John.
2. To understand what Billy is expecting, we have to understand the usual sequence of events in a conversation.
3. When one person calls out to another, typically they are doing so to elicit some sort of reaction.
4. This reaction can take on various forms but in the context of a conversation, this reaction is usually a response.
5. Among the answer choices provided, "response" is the one that suits best in this context.
6. Therefore, the answer is B: response.
So the final answer is B: response.

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i4-s1-rTrue-m4096
Evaluating commonsenseqa :   2%|▌                                 | 1/63 [01:21<1:24:02, 81.33s/it]Evaluating commonsenseqa :   3%|█                                 | 2/63 [02:41<1:21:55, 80.58s/it]Evaluating commonsenseqa :   5%|█▌                                | 3/63 [04:01<1:20:28, 80.48s/it]Evaluating commonsenseqa :   6%|██▏                               | 4/63 [04:52<1:07:24, 68.55s/it]Evaluating commonsenseqa :   8%|██▋                               | 5/63 [06:12<1:10:21, 72.79s/it]Evaluating commonsenseqa :  10%|███▏                              | 6/63 [07:34<1:12:18, 76.11s/it]Evaluating commonsenseqa :  11%|███▊                              | 7/63 [08:54<1:12:03, 77.20s/it]Evaluating commonsenseqa :  13%|████▎                             | 8/63 [10:14<1:11:38, 78.16s/it]Evaluating commonsenseqa :  14%|████▊                             | 9/63 [11:34<1:10:58, 78.85s/it]Evaluating commonsenseqa :  16%|█████▏                           | 10/63 [12:55<1:10:07, 79.38s/it]Evaluating commonsenseqa :  17%|█████▊                           | 11/63 [14:16<1:09:11, 79.85s/it]Evaluating commonsenseqa :  19%|██████▎                          | 12/63 [15:36<1:08:02, 80.04s/it]Evaluating commonsenseqa :  21%|██████▊                          | 13/63 [16:58<1:07:04, 80.48s/it]Evaluating commonsenseqa :  22%|███████▎                         | 14/63 [18:18<1:05:33, 80.27s/it]Evaluating commonsenseqa :  24%|███████▊                         | 15/63 [19:38<1:04:12, 80.25s/it]Evaluating commonsenseqa :  25%|████████▍                        | 16/63 [20:58<1:02:52, 80.28s/it]Evaluating commonsenseqa :  27%|████████▉                        | 17/63 [22:18<1:01:20, 80.02s/it]Evaluating commonsenseqa :  29%|█████████▍                       | 18/63 [23:38<1:00:07, 80.16s/it]Evaluating commonsenseqa :  30%|██████████▌                        | 19/63 [24:58<58:46, 80.14s/it]Evaluating commonsenseqa :  32%|███████████                        | 20/63 [26:20<57:49, 80.68s/it]Evaluating commonsenseqa :  33%|███████████▋                       | 21/63 [27:41<56:25, 80.61s/it]Evaluating commonsenseqa :  35%|████████████▏                      | 22/63 [29:01<54:58, 80.46s/it]Evaluating commonsenseqa :  37%|████████████▊                      | 23/63 [30:21<53:35, 80.40s/it]Evaluating commonsenseqa :  38%|█████████████▎                     | 24/63 [31:41<52:15, 80.39s/it]Evaluating commonsenseqa :  40%|█████████████▉                     | 25/63 [33:01<50:50, 80.28s/it]Evaluating commonsenseqa :  41%|██████████████▍                    | 26/63 [34:21<49:27, 80.21s/it]Evaluating commonsenseqa :  43%|███████████████                    | 27/63 [35:42<48:11, 80.32s/it]Evaluating commonsenseqa :  44%|███████████████▌                   | 28/63 [37:03<46:57, 80.49s/it]Evaluating commonsenseqa :  46%|████████████████                   | 29/63 [38:22<45:26, 80.20s/it]Evaluating commonsenseqa :  48%|████████████████▋                  | 30/63 [39:42<44:04, 80.13s/it]Evaluating commonsenseqa :  49%|█████████████████▏                 | 31/63 [41:03<42:50, 80.32s/it]Evaluating commonsenseqa :  51%|█████████████████▊                 | 32/63 [42:25<41:43, 80.76s/it]Evaluating commonsenseqa :  52%|██████████████████▎                | 33/63 [43:45<40:14, 80.49s/it]Evaluating commonsenseqa :  54%|██████████████████▉                | 34/63 [45:06<39:02, 80.76s/it]Evaluating commonsenseqa :  56%|███████████████████▍               | 35/63 [46:26<37:33, 80.49s/it]Evaluating commonsenseqa :  57%|████████████████████               | 36/63 [47:45<36:03, 80.12s/it]Evaluating commonsenseqa :  59%|████████████████████▌              | 37/63 [49:06<34:47, 80.30s/it]Evaluating commonsenseqa :  60%|█████████████████████              | 38/63 [50:27<33:30, 80.44s/it]Evaluating commonsenseqa :  62%|█████████████████████▋             | 39/63 [51:47<32:07, 80.32s/it]Evaluating commonsenseqa :  63%|██████████████████████▏            | 40/63 [53:07<30:48, 80.36s/it]Evaluating commonsenseqa :  65%|██████████████████████▊            | 41/63 [54:26<29:20, 80.02s/it]Evaluating commonsenseqa :  67%|███████████████████████▎           | 42/63 [55:46<27:57, 79.88s/it]Evaluating commonsenseqa :  68%|███████████████████████▉           | 43/63 [57:07<26:44, 80.23s/it]Evaluating commonsenseqa :  70%|████████████████████████▍          | 44/63 [58:27<25:20, 80.03s/it]Evaluating commonsenseqa :  71%|█████████████████████████          | 45/63 [59:47<24:00, 80.03s/it]Evaluating commonsenseqa :  73%|████████████████████████         | 46/63 [1:00:28<19:23, 68.42s/it]Evaluating commonsenseqa :  75%|████████████████████████▌        | 47/63 [1:01:48<19:11, 71.96s/it]Evaluating commonsenseqa :  76%|█████████████████████████▏       | 48/63 [1:03:07<18:32, 74.16s/it]Evaluating commonsenseqa :  78%|█████████████████████████▋       | 49/63 [1:04:29<17:47, 76.24s/it]Evaluating commonsenseqa :  79%|██████████████████████████▏      | 50/63 [1:05:49<16:46, 77.41s/it]Evaluating commonsenseqa :  81%|██████████████████████████▋      | 51/63 [1:07:08<15:36, 78.06s/it]Evaluating commonsenseqa :  83%|███████████████████████████▏     | 52/63 [1:08:28<14:25, 78.64s/it]Evaluating commonsenseqa :  84%|███████████████████████████▊     | 53/63 [1:09:18<11:40, 70.01s/it]Evaluating commonsenseqa :  86%|████████████████████████████▎    | 54/63 [1:10:38<10:57, 73.09s/it]Evaluating commonsenseqa :  87%|████████████████████████████▊    | 55/63 [1:11:58<09:59, 74.98s/it]Evaluating commonsenseqa :  89%|█████████████████████████████▎   | 56/63 [1:12:54<08:06, 69.48s/it]Evaluating commonsenseqa :  90%|█████████████████████████████▊   | 57/63 [1:14:15<07:17, 72.85s/it]Evaluating commonsenseqa :  92%|██████████████████████████████▍  | 58/63 [1:15:36<06:16, 75.30s/it]Evaluating commonsenseqa :  94%|██████████████████████████████▉  | 59/63 [1:16:56<05:06, 76.50s/it]Evaluating commonsenseqa :  95%|███████████████████████████████▍ | 60/63 [1:18:15<03:52, 77.55s/it]Evaluating commonsenseqa :  97%|███████████████████████████████▉ | 61/63 [1:19:37<02:37, 78.66s/it]Evaluating commonsenseqa :  98%|████████████████████████████████▍| 62/63 [1:20:57<01:19, 79.13s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████| 63/63 [1:21:24<00:00, 63.39s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████| 63/63 [1:21:24<00:00, 77.53s/it]
name: commonsenseqa | avg. gen lenth: 391.304 | time: 4884.6136906147s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-out-domain 0 --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 4 --data-dir /scratch/ylu130/processed_data/commonsenseqa/in-domain/i5-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-in-domain 5
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-27 21:23:14,180] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-27 21:23:14,203] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-27 21:23:14,205] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-27 21:23:14,224] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/in-domain/i5-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 5
  num_out_domain ............... 0
  out_domain_data_name ......... None
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i5-s1-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                                       | 0/9736 [00:00<?, ?it/s]Loading data: 100%|████████████████████████████████████████| 9736/9736 [00:00<00:00, 388608.36it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:06<00:06,  6.92s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.30s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.44s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.22s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.63s/it]
[2023-08-27 21:23:25,034] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.29s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.74s/it]
[2023-08-27 21:23:25,334] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.40s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.85s/it]
[2023-08-27 21:23:25,579] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:10<00:10, 10.46s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:12<00:00,  5.63s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:12<00:00,  6.35s/it]
 > number of parameters: 6738415616
[2023-08-27 21:23:28,484] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-27 21:23:29,052] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-27 21:23:29,054] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-27 21:23:29,054] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-27 21:23:29,054] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-27 21:23:29,054] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-27 21:23:29,054] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-27 21:23:29,054] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-27 21:23:29,054] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-27 21:23:29,054] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-27 21:23:29,054] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-27 21:23:29,054] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-27 21:23:29,054] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f967d25b610>
[2023-08-27 21:23:29,054] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-27 21:23:29,054] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-27 21:23:29,054] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-27 21:23:29,054] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-27 21:23:29,054] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-27 21:23:29,054] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-27 21:23:29,054] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-27 21:23:29,054] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-27 21:23:29,054] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-27 21:23:29,054] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-27 21:23:29,054] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-27 21:23:29,054] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-27 21:23:29,054] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-27 21:23:29,055] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-27 21:23:29,055] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                                            | 0/63 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Output: 1. To be "of use when thirsty," the plumbing in question would need to convey water.
2. Starting from the answer choices given:
    A: Oil refineries: The primary function of an oil refinery is to process and refine crude oil. Any plumbing found in an oil refinery would therefore be used to transport oil, not water.
    B: Wall: While walls can contain plumbing, this plumbing could provide water, especially if it serves sinks, showers or other water-based utilities within a building.
    C: Show: This choice is vague, but if it refers to a show or performance, any plumbing might be for special effects or backstage utilities - which could still potentially provide water.
    D: Own home: The plumbing in your own home would certainly be useful if you were thirsty, as it provides taps, showers, and other water sources.
    E: Water fountain: A water fountain might be the most obvious source of drinakble water and would certainly be useful if you were thirsty.
3. Therefore, by process of elimination, you would only find plumbing that would not be "of use to you if you are thirsty" in an oil refinery, making `A: oil refineries` the correct answer.
So the final answer is A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Output: 1. The question is asking for the activity that a person is not immediately doing when they are beginning to work. 
2. To determine the correct response, we need to compare each option, while considering the immediate meaning of "beginning work".
3. In terms of immediate actions, "beginning to work" could also imply "working" (Option A), so it cannot be the correct answer.
4. Similarly, "momentum" (Option E) is a phenomenon that can start as soon as one begins to work, so it is also not the answer.
5. "Resting" (Option B) is an action contrary to working so it doesn't fit the context. They are not resting but working.
6. Option C: "Tiredness", associated with extensive effort or work, doesn't fit either. It's unlikely for a person to feel tired at the beginning.
7. The remaining option is "Accomplishing" (Option D). When a person is just beginning to work, they haven't had time to accomplish their tasks or goals yet. Hence, this must be the correct answer. 
8. So, the right answer is D: accomplishing.
So the final answer is D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Output: 1. The question is asking for a place (location) where one may find pens containing a company logo. 
2. Look at each of the choices and consider whether it is a viable location for finding such pens.
3. Choice B: on a pencil - This is unlikely as pencils and pens are different types of writing instruments. They would not usually be found together as part of the same item.
4. Choice C: write sentences on paper - This is not a place or location, rather it's an activity involving using a pen or pencil.
5. Choice D: school - Though it is a location, it's less common to find pens with company logos in a school setting. Usually, pens in schools are for students who likely wouldn't have pens with company logos.
6. Choice E: backpack - It is a viable place to find pens but doesn't specify the type of pen like those with a company logo.
7. Choice A: office - This is the most likely place as promotional pens are often dispersed in such professional environments. Company logo pens are commonly used in offices as part of a company's stationery.
8. Hence, the answer is A: office, as it's the most probable location to find pens that have a company's logo.
So the final answer is A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Output: 1. The question is about what Billy expected after he called out to John. 
2. When someone calls out to another person, it generally means they want to get their attention or want to communicate something to them. 
3. After calling out, the normal expectation is that the other person will acknowledge or respond in some way. 
4. The option 'A: silence' does not fit because it is the opposite of what should normally happen if Billy is calling out to John.
5. The option 'C: communication' might seem plausible but in the provided options, there is a more appropriate answer.
6. 'D: hanging up' and 'E: whisper' are not a probable outcome from calling out, unless mentioned beforehand.
7. Therefore, the most logical choice, considering the normally expected outcome of calling out to someone, is 'B: response'.
So the final answer is B: response

Input: The lizard frightened the hiker, it's movements made what rustle? Choices:  A: garden B: trees C: books D: rocks E: bushes
Output: 1. The question tells us that the "lizard frightened the hiker".
2. Following this, it specifies that the lizard caused a rustle movement.
3. We need to find out where this rustling movement happened - a place associated with both lizard's habitat and a hiker’s path.
4. Looking at the choices, we can eliminate 'garden' and 'books' as a lizard would not frequently be found rustling around in a garden or within books, especially in a context involving a hiker.
5. We can also eliminate 'rocks' as rocks can't rustle.
6. Out of 'trees' and 'bushes', a lizard is more likely to cause rustling in bushes than in trees as lizards are more commonly found on or near the ground.
7. Thus, the correct answer is E: bushes.
So the final answer is E: bushes

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i5-s1-rTrue-m4096
Evaluating commonsenseqa :   2%|▌                                 | 1/63 [01:16<1:18:35, 76.05s/it]Evaluating commonsenseqa :   3%|█                                 | 2/63 [02:30<1:16:32, 75.28s/it]Evaluating commonsenseqa :   5%|█▌                                | 3/63 [03:44<1:14:42, 74.71s/it]Evaluating commonsenseqa :   6%|██▏                               | 4/63 [04:59<1:13:20, 74.59s/it]Evaluating commonsenseqa :   8%|██▋                               | 5/63 [06:13<1:12:06, 74.59s/it]Evaluating commonsenseqa :  10%|███▏                              | 6/63 [07:28<1:10:57, 74.70s/it]Evaluating commonsenseqa :  11%|███▊                              | 7/63 [08:43<1:09:48, 74.79s/it]Evaluating commonsenseqa :  13%|████▎                             | 8/63 [09:58<1:08:27, 74.68s/it]Evaluating commonsenseqa :  14%|████▊                             | 9/63 [11:11<1:06:48, 74.24s/it]Evaluating commonsenseqa :  16%|█████▏                           | 10/63 [12:26<1:05:43, 74.41s/it]Evaluating commonsenseqa :  17%|█████▊                           | 11/63 [13:40<1:04:21, 74.25s/it]Evaluating commonsenseqa :  19%|██████▎                          | 12/63 [14:53<1:02:55, 74.03s/it]Evaluating commonsenseqa :  21%|███████▏                           | 13/63 [15:45<56:11, 67.43s/it]Evaluating commonsenseqa :  22%|███████▊                           | 14/63 [16:59<56:39, 69.37s/it]Evaluating commonsenseqa :  24%|████████▎                          | 15/63 [18:14<56:44, 70.92s/it]Evaluating commonsenseqa :  25%|████████▉                          | 16/63 [19:27<56:11, 71.74s/it]Evaluating commonsenseqa :  27%|█████████▍                         | 17/63 [20:41<55:28, 72.37s/it]Evaluating commonsenseqa :  29%|██████████                         | 18/63 [21:55<54:38, 72.85s/it]Evaluating commonsenseqa :  30%|██████████▌                        | 19/63 [23:09<53:38, 73.15s/it]Evaluating commonsenseqa :  32%|███████████                        | 20/63 [24:23<52:37, 73.42s/it]Evaluating commonsenseqa :  33%|███████████▋                       | 21/63 [25:37<51:34, 73.68s/it]Evaluating commonsenseqa :  35%|████████████▏                      | 22/63 [26:51<50:21, 73.70s/it]Evaluating commonsenseqa :  37%|████████████▊                      | 23/63 [28:05<49:07, 73.68s/it]Evaluating commonsenseqa :  38%|█████████████▎                     | 24/63 [29:18<47:52, 73.66s/it]Evaluating commonsenseqa :  40%|█████████████▉                     | 25/63 [30:32<46:41, 73.73s/it]Evaluating commonsenseqa :  41%|██████████████▍                    | 26/63 [31:46<45:31, 73.82s/it]Evaluating commonsenseqa :  43%|███████████████                    | 27/63 [33:01<44:27, 74.10s/it]Evaluating commonsenseqa :  44%|███████████████▌                   | 28/63 [34:15<43:09, 73.99s/it]Evaluating commonsenseqa :  46%|████████████████                   | 29/63 [35:29<42:02, 74.18s/it]Evaluating commonsenseqa :  48%|████████████████▋                  | 30/63 [36:44<40:49, 74.22s/it]Evaluating commonsenseqa :  49%|█████████████████▏                 | 31/63 [37:58<39:35, 74.25s/it]Evaluating commonsenseqa :  51%|█████████████████▊                 | 32/63 [39:12<38:15, 74.05s/it]Evaluating commonsenseqa :  52%|██████████████████▎                | 33/63 [40:25<36:56, 73.90s/it]Evaluating commonsenseqa :  54%|██████████████████▉                | 34/63 [41:39<35:42, 73.88s/it]Evaluating commonsenseqa :  56%|███████████████████▍               | 35/63 [42:53<34:28, 73.88s/it]Evaluating commonsenseqa :  57%|████████████████████               | 36/63 [44:07<33:17, 73.97s/it]Evaluating commonsenseqa :  59%|████████████████████▌              | 37/63 [45:21<32:03, 73.99s/it]Evaluating commonsenseqa :  60%|█████████████████████              | 38/63 [46:35<30:48, 73.93s/it]Evaluating commonsenseqa :  62%|█████████████████████▋             | 39/63 [47:50<29:41, 74.23s/it]Evaluating commonsenseqa :  63%|██████████████████████▏            | 40/63 [49:03<28:23, 74.06s/it]Evaluating commonsenseqa :  65%|██████████████████████▊            | 41/63 [50:18<27:14, 74.32s/it]Evaluating commonsenseqa :  67%|███████████████████████▎           | 42/63 [51:33<26:05, 74.53s/it]Evaluating commonsenseqa :  68%|███████████████████████▉           | 43/63 [52:49<24:53, 74.70s/it]Evaluating commonsenseqa :  70%|████████████████████████▍          | 44/63 [54:03<23:37, 74.63s/it]Evaluating commonsenseqa :  71%|█████████████████████████          | 45/63 [55:16<22:17, 74.29s/it]Evaluating commonsenseqa :  73%|█████████████████████████▌         | 46/63 [56:31<21:04, 74.39s/it]Evaluating commonsenseqa :  75%|██████████████████████████         | 47/63 [57:45<19:47, 74.20s/it]Evaluating commonsenseqa :  76%|██████████████████████████▋        | 48/63 [58:59<18:31, 74.10s/it]Evaluating commonsenseqa :  78%|█████████████████████████▋       | 49/63 [1:00:13<17:16, 74.01s/it]Evaluating commonsenseqa :  79%|██████████████████████████▏      | 50/63 [1:01:26<16:00, 73.88s/it]Evaluating commonsenseqa :  81%|██████████████████████████▋      | 51/63 [1:02:40<14:48, 74.03s/it]Evaluating commonsenseqa :  83%|███████████████████████████▏     | 52/63 [1:03:54<13:33, 73.95s/it]Evaluating commonsenseqa :  84%|███████████████████████████▊     | 53/63 [1:05:08<12:19, 73.91s/it]Evaluating commonsenseqa :  86%|████████████████████████████▎    | 54/63 [1:06:23<11:08, 74.31s/it]Evaluating commonsenseqa :  87%|████████████████████████████▊    | 55/63 [1:07:37<09:52, 74.12s/it]Evaluating commonsenseqa :  89%|█████████████████████████████▎   | 56/63 [1:08:52<08:40, 74.39s/it]Evaluating commonsenseqa :  90%|█████████████████████████████▊   | 57/63 [1:10:06<07:25, 74.28s/it]Evaluating commonsenseqa :  92%|██████████████████████████████▍  | 58/63 [1:11:20<06:10, 74.07s/it]Evaluating commonsenseqa :  94%|██████████████████████████████▉  | 59/63 [1:12:34<04:56, 74.15s/it]Evaluating commonsenseqa :  95%|███████████████████████████████▍ | 60/63 [1:13:48<03:42, 74.14s/it]Evaluating commonsenseqa :  97%|███████████████████████████████▉ | 61/63 [1:15:02<02:27, 73.96s/it]Evaluating commonsenseqa :  98%|████████████████████████████████▍| 62/63 [1:16:16<01:14, 74.02s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████| 63/63 [1:16:59<00:00, 64.68s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████| 63/63 [1:16:59<00:00, 73.32s/it]
name: commonsenseqa | avg. gen lenth: 427.548 | time: 4619.680743932724s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-out-domain 0 --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 4 --data-dir /scratch/ylu130/processed_data/commonsenseqa/in-domain/i6-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-in-domain 6
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-27 22:41:16,237] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-27 22:41:16,276] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-27 22:41:16,293] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-27 22:41:16,303] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/in-domain/i6-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 6
  num_out_domain ............... 0
  out_domain_data_name ......... None
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i6-s1-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                                       | 0/9735 [00:00<?, ?it/s]Loading data: 100%|████████████████████████████████████████| 9735/9735 [00:00<00:00, 371034.00it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:06<00:06,  6.76s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.06s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.23s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.12s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.51s/it]
[2023-08-27 22:41:26,632] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.16s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.60s/it]
 > number of parameters: 6738415616
[2023-08-27 22:41:26,913] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.27s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.71s/it]
[2023-08-27 22:41:27,131] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:09<00:09,  9.91s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:11<00:00,  5.28s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:11<00:00,  5.97s/it]
[2023-08-27 22:41:29,692] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-27 22:41:30,275] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-27 22:41:30,276] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-27 22:41:30,276] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-27 22:41:30,276] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-27 22:41:30,276] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-27 22:41:30,276] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-27 22:41:30,276] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-27 22:41:30,276] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-27 22:41:30,276] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fba6c57b520>
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-27 22:41:30,277] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-27 22:41:30,278] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-27 22:41:30,278] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-27 22:41:30,278] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-27 22:41:30,278] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-27 22:41:30,278] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-27 22:41:30,278] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-27 22:41:30,278] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-27 22:41:30,278] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-27 22:41:30,278] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-27 22:41:30,278] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-27 22:41:30,278] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                                            | 0/63 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Output: 1. First, let's understand the question which is asking where you can find some plumbing that would not be beneficial if you are thirsty. 
2. The plumbing system of interest here should be one that does not carry drinkable water.
3. We start to eliminate the options. Looking at choice E: water fountain, this obviously carries drinkable water so it can't be it.
4. Option D: own home, also carries drinkable water from faucets, so we eliminate this option too.
5. Option C: show and option B: wall do not seem to make sense in this context as they do not typically refer to places with a plumbing system.
6. This leaves us with option A: oil refineries. Oil refineries typically have pipelines for transporting oil, not water. So, the plumbing in oil refineries would not be of use if you are thirsty.
7. Therefore, the answer is A: oil refineries.
So the final answer is A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Output: 1. The question asks us to identify what a person is not doing when they are beginning work.
2. Let's look at each option individually: 
3. Option A: Working. This option is probable because when someone is beginning work, they are indeed working.
4. Option B: Resting. This is unlikely as someone can't be starting to work and resting at the same time.
5. Option C: Tiredness. This could be ruled out because it is a state of feeling, not an action. Although one might argue that someone could be tired from the onset of work, it doesn't make sense within the context of the question.
6. Option D: Accomplishing. This seems to be the most likely answer. When someone is beginning their work, they will most likely not have accomplished anything yet as they have just started.
7. Option E: Momentum. This could be ruled out because similar to tiredness, it is not an action one performs. Rather, it can be a result or a product of work over time.
8. Hence, the correct answer is D: Accomplishing.
So the final answer is D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Output: Reasoning:
1. Pens with a company logo are often passed out or used in an office setting.
2. They could be given to employees to use, or to visitors as part of a promotional activity.
3. A pencil is a different stationery item, so it is not likely to find pens inscribed with logos on them.
4. Also, while pens are commonly used to write sentences on paper, the paper doesn't have anything to do with where you might discover logo-embossed pens.
5. Although students use pens at school, it is unusual for schools to distribute pens with company logos, so it is less likely you will find such pens there.
6. A backpack could hold a pen with a logo, but this choice is more about where someone might store such an item, it doesn't necessarily provide a good answer to where you might encounter one.
7. Therefore, considering all the options, 'office' makes the most sense as an answer.
So the final answer is A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Output: 1. The question pertains to the reason why Billy called out to John.
2. Usually, when a person calls out to someone else, it's to attract their attention and generate some form of verbal or non-verbal acknowledgment or reply.
3. 'Silence' and 'hanging up' would not be what Billy would be waiting for after calling out to John.
4. 'Whisper' could be a type of response, but it is not the most direct answer. 'Communication' is more general and less direct than'response'.
5. Hence, the most appropriate choice is B:'response'. This indicates that Billy is waiting for John to reply or acknowledge him in some way.
So the final answer is B: response

Input: The lizard frightened the hiker, it's movements made what rustle? Choices:  A: garden B: trees C: books D: rocks E: bushes
Output: 1. This question calls for reasoning based on understanding of common contextual usage and behavior of lizards and hikers.
2. We start by eliminating irrelevant options: Lizards aren't usually found in gardens, nor do they frighten hikers there typically. Books are definitely out of question since lizards don't rustle books.
3. Between trees, rocks, and bushes, lizards can't make trees rustle because they are too small and light, and rocks don't rustle at all.
4. Therefore, by process of elimination, the answer has to be E: bushes. Lizards often inhabit areas with bushes and their movement through them can cause rustling sounds, which could frighten a hiker.
So the final answer is E: bushes

Input: The man spent big money and time maintaining his lawn, it was part of keeping up with the Joneses where? Choices:  A: front yard B: suburbia C: neighborhood D: back yard E: golf course
Output: 1. The phrase "keeping up with the Joneses" refers to the comparison to one's neighbors as a benchmark for social class or the accumulation of material goods. 
2. This means the context is most likely a residential area where there are neighbors to compare with.
3. Among the options, A: front yard, B: suburbia, C: neighborhood, D: back yard, E: golf course, the phrase could technically apply to the front yard, the suburbia, the neighborhood, or the back yard, but not the golf course. The golf course option can be eliminated as it's not a residential area. 
4. However, the phrase "keeping up with the Joneses" is often applied in a broader sense, on a community level.
5. Therefore, the front yard and the back yard can be eliminated. The phrase does not usually refer to individual properties but rather to an entire residential community.
6. This then narrows down the choice to either suburbia or neighborhood. 
7. The "man spent big money", which suggests the community is relatively affluent, characteristic of suburbia.
8. Therefore, the answer is B: suburbia.
So the final answer is B: suburbia

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i6-s1-rTrue-m4096
Evaluating commonsenseqa :   2%|▌                                 | 1/63 [01:12<1:15:24, 72.97s/it]Evaluating commonsenseqa :   3%|█                                 | 2/63 [02:24<1:13:29, 72.29s/it]Evaluating commonsenseqa :   5%|█▌                                | 3/63 [03:36<1:12:14, 72.24s/it]Evaluating commonsenseqa :   6%|██▏                               | 4/63 [04:48<1:10:53, 72.10s/it]Evaluating commonsenseqa :   8%|██▋                               | 5/63 [06:00<1:09:37, 72.03s/it]Evaluating commonsenseqa :  10%|███▏                              | 6/63 [07:12<1:08:15, 71.85s/it]Evaluating commonsenseqa :  11%|███▊                              | 7/63 [08:24<1:07:10, 71.97s/it]Evaluating commonsenseqa :  13%|████▎                             | 8/63 [09:36<1:05:56, 71.94s/it]Evaluating commonsenseqa :  14%|████▊                             | 9/63 [10:48<1:04:46, 71.97s/it]Evaluating commonsenseqa :  16%|█████▏                           | 10/63 [12:00<1:03:40, 72.09s/it]Evaluating commonsenseqa :  17%|█████▊                           | 11/63 [13:12<1:02:29, 72.11s/it]Evaluating commonsenseqa :  19%|██████▎                          | 12/63 [14:25<1:01:26, 72.28s/it]Evaluating commonsenseqa :  21%|██████▊                          | 13/63 [15:37<1:00:10, 72.20s/it]Evaluating commonsenseqa :  22%|███████▊                           | 14/63 [16:49<58:50, 72.04s/it]Evaluating commonsenseqa :  24%|████████▎                          | 15/63 [18:01<57:48, 72.25s/it]Evaluating commonsenseqa :  25%|████████▉                          | 16/63 [19:13<56:30, 72.14s/it]Evaluating commonsenseqa :  27%|█████████▍                         | 17/63 [20:26<55:19, 72.16s/it]Evaluating commonsenseqa :  29%|██████████                         | 18/63 [21:37<53:56, 71.93s/it]Evaluating commonsenseqa :  30%|██████████▌                        | 19/63 [22:49<52:51, 72.08s/it]Evaluating commonsenseqa :  32%|███████████                        | 20/63 [24:01<51:32, 71.92s/it]Evaluating commonsenseqa :  33%|███████████▋                       | 21/63 [25:13<50:16, 71.81s/it]Evaluating commonsenseqa :  35%|████████████▏                      | 22/63 [26:24<49:00, 71.72s/it]Evaluating commonsenseqa :  37%|████████████▊                      | 23/63 [27:36<47:47, 71.68s/it]Evaluating commonsenseqa :  38%|█████████████▎                     | 24/63 [28:48<46:42, 71.86s/it]Evaluating commonsenseqa :  40%|█████████████▉                     | 25/63 [30:00<45:38, 72.07s/it]Evaluating commonsenseqa :  41%|██████████████▍                    | 26/63 [31:12<44:17, 71.82s/it]Evaluating commonsenseqa :  43%|███████████████                    | 27/63 [32:24<43:06, 71.83s/it]Evaluating commonsenseqa :  44%|███████████████▌                   | 28/63 [33:35<41:51, 71.77s/it]Evaluating commonsenseqa :  46%|████████████████                   | 29/63 [34:48<40:52, 72.14s/it]Evaluating commonsenseqa :  48%|████████████████▋                  | 30/63 [35:59<39:30, 71.82s/it]Evaluating commonsenseqa :  49%|█████████████████▏                 | 31/63 [37:11<38:20, 71.91s/it]Evaluating commonsenseqa :  51%|█████████████████▊                 | 32/63 [38:23<37:10, 71.95s/it]Evaluating commonsenseqa :  52%|██████████████████▎                | 33/63 [39:35<35:53, 71.79s/it]Evaluating commonsenseqa :  54%|██████████████████▉                | 34/63 [40:48<34:49, 72.06s/it]Evaluating commonsenseqa :  56%|███████████████████▍               | 35/63 [42:00<33:37, 72.07s/it]Evaluating commonsenseqa :  57%|████████████████████               | 36/63 [43:11<32:21, 71.89s/it]Evaluating commonsenseqa :  59%|████████████████████▌              | 37/63 [44:23<31:08, 71.85s/it]Evaluating commonsenseqa :  60%|█████████████████████              | 38/63 [45:35<30:01, 72.05s/it]Evaluating commonsenseqa :  62%|█████████████████████▋             | 39/63 [46:48<28:50, 72.09s/it]Evaluating commonsenseqa :  63%|██████████████████████▏            | 40/63 [47:59<27:34, 71.95s/it]Evaluating commonsenseqa :  65%|██████████████████████▊            | 41/63 [48:48<23:49, 64.97s/it]Evaluating commonsenseqa :  67%|███████████████████████▎           | 42/63 [50:01<23:37, 67.51s/it]Evaluating commonsenseqa :  68%|███████████████████████▉           | 43/63 [51:14<22:59, 68.97s/it]Evaluating commonsenseqa :  70%|████████████████████████▍          | 44/63 [52:25<22:06, 69.83s/it]Evaluating commonsenseqa :  71%|█████████████████████████          | 45/63 [53:38<21:09, 70.53s/it]Evaluating commonsenseqa :  73%|█████████████████████████▌         | 46/63 [54:50<20:09, 71.16s/it]Evaluating commonsenseqa :  75%|██████████████████████████         | 47/63 [56:02<19:00, 71.28s/it]Evaluating commonsenseqa :  76%|██████████████████████████▋        | 48/63 [57:15<17:57, 71.84s/it]Evaluating commonsenseqa :  78%|███████████████████████████▏       | 49/63 [58:27<16:47, 71.98s/it]Evaluating commonsenseqa :  79%|███████████████████████████▊       | 50/63 [59:39<15:34, 71.90s/it]Evaluating commonsenseqa :  81%|██████████████████████████▋      | 51/63 [1:00:50<14:20, 71.72s/it]Evaluating commonsenseqa :  83%|███████████████████████████▏     | 52/63 [1:02:03<13:10, 71.89s/it]Evaluating commonsenseqa :  84%|███████████████████████████▊     | 53/63 [1:03:15<12:01, 72.18s/it]Evaluating commonsenseqa :  86%|████████████████████████████▎    | 54/63 [1:04:27<10:48, 72.10s/it]Evaluating commonsenseqa :  87%|████████████████████████████▊    | 55/63 [1:05:40<09:37, 72.13s/it]Evaluating commonsenseqa :  89%|█████████████████████████████▎   | 56/63 [1:06:51<08:24, 72.01s/it]Evaluating commonsenseqa :  90%|█████████████████████████████▊   | 57/63 [1:08:03<07:11, 71.92s/it]Evaluating commonsenseqa :  92%|██████████████████████████████▍  | 58/63 [1:09:15<05:59, 71.92s/it]Evaluating commonsenseqa :  94%|██████████████████████████████▉  | 59/63 [1:10:26<04:47, 71.78s/it]Evaluating commonsenseqa :  95%|███████████████████████████████▍ | 60/63 [1:11:38<03:35, 71.81s/it]Evaluating commonsenseqa :  97%|███████████████████████████████▉ | 61/63 [1:12:50<02:23, 71.90s/it]Evaluating commonsenseqa :  98%|████████████████████████████████▍| 62/63 [1:14:03<01:12, 72.14s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████| 63/63 [1:14:19<00:00, 55.15s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████| 63/63 [1:14:19<00:00, 70.78s/it]
name: commonsenseqa | avg. gen lenth: 421.64 | time: 4459.572130441666s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-out-domain 0 --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 4 --data-dir /scratch/ylu130/processed_data/commonsenseqa/in-domain/i7-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-in-domain 7
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-27 23:56:52,822] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-27 23:56:53,239] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-27 23:56:53,334] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-27 23:56:53,376] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/in-domain/i7-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 7
  num_out_domain ............... 0
  out_domain_data_name ......... None
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i7-s1-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                                       | 0/9734 [00:00<?, ?it/s]Loading data: 100%|████████████████████████████████████████| 9734/9734 [00:00<00:00, 399610.01it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:06<00:06,  6.82s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:06<00:06,  6.91s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.16s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.06s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.11s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.52s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.11s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.53s/it]
 > number of parameters: 6738415616
[2023-08-27 23:57:03,777] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.14s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.59s/it]
[2023-08-27 23:57:03,928] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-27 23:57:04,006] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.20s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.63s/it]
[2023-08-27 23:57:04,201] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-27 23:57:04,753] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-27 23:57:04,755] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-27 23:57:04,755] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-27 23:57:04,755] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-27 23:57:04,755] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-27 23:57:04,755] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-27 23:57:04,755] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-27 23:57:04,755] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-27 23:57:04,755] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-27 23:57:04,755] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-27 23:57:04,755] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-27 23:57:04,755] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fb78b78f640>
[2023-08-27 23:57:04,755] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-27 23:57:04,755] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-27 23:57:04,755] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-27 23:57:04,755] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-27 23:57:04,755] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-27 23:57:04,755] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-27 23:57:04,755] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-27 23:57:04,755] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-27 23:57:04,755] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-27 23:57:04,755] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-27 23:57:04,755] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-27 23:57:04,755] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-27 23:57:04,755] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-27 23:57:04,755] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-27 23:57:04,755] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-27 23:57:04,755] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-27 23:57:04,755] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-27 23:57:04,756] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-27 23:57:04,756] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                                            | 0/63 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Output: 1. The question asks where you could find plumbing that would not be useful to you if you were thirsty.
2. This means we need to identify an option among A: oil refineries, B: wall, C: show, D: own home, E: water fountain where the plumbing would not be capable of supplying drinkable water.
3. We know that plumbing in our own home (D) and at a water fountain (E) would provide water for thirst, so we eliminate these options.
4. The plumbing within a wall (B) could potentially supply water if it's connected to a suitable source, so we can also remove this option.
5. A show (C) is a vague answer and may or may not have plumbing. However, if it has a plumbing system, it would more likely be connected to drinkable water supply eliminating this option too.
6. This leaves us with A: oil refineries. Oil refineries, while having an extensive network of pipes and plumbing, these are designed to transport oil, not drinkable water.
7. Therefore, the answer is A: oil refineries as it's the only place where the plumbing would not be of use if you were thirsty.
So the final answer is A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Output: 1. The question is asking what a person is not doing when they are just starting to work. 
2. The first option "working" is not correct since the person is obviously just beginning to work or is in the process of working.
3. Similarly, the fifth option "momentum" cannot fit as it implies being under motion or making progress, which the person may well be doing while starting to work.
4. While it's possible for some to consider "tiredness," as a right option assuming that the person wouldn't be tired just starting to work, the keyword here is "doing." "Tiredness" isn't an action; instead, it's a state. So, "tiredness" can't be the right answer.
5. The third option "resting" is also incorrect because if a person is beginning to work it implies they're not at rest. 
6. Thus, the only remaining option is "accomplishing," which makes sense since when a person is just beginning work, they have not accomplished anything just yet. 
7. Therefore, the answer is D: accomplishing.
So the final answer is D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Output: 1. Start with the given question which is asking where you can find pens with a company logo. 
2. Company logo pens are usually used in places of business or organizations, where they may be given out to employees, clients or customers. 
3. These places want to have their branding on items such as pens, which are seen and used by many people. 
4. With this in mind, let's evaluate each of the given options.
5. Option B: Pens aren't usually found on pencils, and pencils are not likely to carry a company logo.
6. Option C: Writing sentences on paper doesn't relate to the location where you can find pens with a company logo.
7. Option D: Schools are more likely to have pens with school logos, not company logos.
8. Option E: A backpack could theoretically hold a pen with a company logo, but it's not a place where you primarily find them.
9. However, option A: Office, is strongly associated with companies and businesses, and it’s mostly in the office space that a person would come across pens with a company logo.
10. Therefore, the answer is A: office.
So the final answer is A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Output: Step 1: Understand the context of the question. It is about communication between two people, where one person (Billy) initiates the contact.
 
Step 2: Evaluate the options. It mentions that Billy 'called out' implying he is seeking attention or an answer. When you communicate or 'call out' to someone else, you typically await their reply.

Step 3: Options A and E, silence and whisper, don't fit the context as Billy would be expecting clear communication after he called out. Option D, hanging up, is not suitable because it refers to ending a call on a phone, not initiating a conversation.

Step 4: Option C, communication, is close but too broad. Communication can refer to any exchange or transfer of information between people, not specifically a return message from John.

Step 5: Option B, response, is the best answer. It correctly defines what Billy would be waiting for after he called out to John - a reply or return communication from John. 

In conclusion, the answer is B: response.
So the final answer is B: response

Input: The lizard frightened the hiker, it's movements made what rustle? Choices:  A: garden B: trees C: books D: rocks E: bushes
Output: 1. The primary information provided in the question is that the lizard frightened the hiker through its movements that made some rustle.
2. To find the right answer, we need to pinpoint what the lizard's movements could have rustled. We need something that can rustle or make a rustling sound.
3. Let's go through the options one by one. 
4. Option A is garden. However, a garden itself cannot rustle, various elements within it might, but it's not specific enough. This does not seem to fit the given situation.
5. Next is Option B, trees. Trees do make rustle-like noises when the wind blows through their leaves, but usually, they are not low enough to the ground for a lizard to rustle.
6. Then we have Option C, books. It is very unlikely for a lizard to rustle books as they are typically indoors and lizards are mostly found outside. So option C is out.
7. Option D, rocks, cannot rustle as they are solid and non-flexible objects.
8. Finally, Option E is bushes. Bushes contain leaves that could easily rustle with the slightest touch or when wind passes through them. And more importantly, a lizard, being a creature that usually stays on the ground, could easily create a rustle by moving through them.
9. Therefore, putting together all the information and reasoning, we find that the answer is E: bushes.
So the final answer is E: bushes

Input: The man spent big money and time maintaining his lawn, it was part of keeping up with the Joneses where? Choices:  A: front yard B: suburbia C: neighborhood D: back yard E: golf course
Output: 1. The phrase "keeping up with the Joneses" refers to the comparison to one's neighbor as a benchmark for social class or the accumulation of material goods.
2. This phrase is often used in the context of appearances and the social status related to where one lives.
3. Therefore, the answer should be a place where neighbors could see and compare such material displays.
4. Although options A, C, D, and E are all plausible locations for a lawn to be maintained, option B, the suburbia encompasses the whole neighborhood where 'keeping up with the Joneses' is an essential part.
5. This means that'suburbia' is the most appropriate answer, as it covers a greater area where this social comparison can occur.
6. Hence, the answer is B: suburbia.
So the final answer is B: suburbia

Input: What would a human do if they want to get to a store that he or she can see? Choices:  A: cross road B: see around C: drink coffee D: dream dreams E: think critically
Output: The question gives a scenario where a person can see the store they want to reach.

This implies a physical distance between the person and the store that needs to be covered.

Among the options provided, option B: seeing around, may be a part of the process, but it wouldn't necessarily help the person get closer to the store.

Option C: Drinking coffee, Option D: Dreaming dreams, and Option E: Thinking critically, do not involve any physical movement towards the store.

Hence, the most logical choice would be option A: crossing the road, as it involves moving closer to the store.
So the final answer is A: cross road

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i7-s1-rTrue-m4096
Evaluating commonsenseqa :   2%|▌                                 | 1/63 [01:05<1:07:56, 65.75s/it]Evaluating commonsenseqa :   3%|█                                 | 2/63 [02:10<1:06:16, 65.19s/it]Evaluating commonsenseqa :   5%|█▌                                | 3/63 [03:14<1:04:50, 64.83s/it]Evaluating commonsenseqa :   6%|██▏                               | 4/63 [04:18<1:03:23, 64.47s/it]Evaluating commonsenseqa :   8%|██▋                               | 5/63 [05:22<1:02:07, 64.27s/it]Evaluating commonsenseqa :  10%|███▏                              | 6/63 [06:27<1:01:12, 64.43s/it]Evaluating commonsenseqa :  11%|████                                | 7/63 [07:31<59:59, 64.27s/it]Evaluating commonsenseqa :  13%|████▌                               | 8/63 [08:36<59:10, 64.55s/it]Evaluating commonsenseqa :  14%|█████▏                              | 9/63 [09:40<57:56, 64.37s/it]Evaluating commonsenseqa :  16%|█████▌                             | 10/63 [10:45<56:59, 64.52s/it]Evaluating commonsenseqa :  17%|██████                             | 11/63 [11:50<55:58, 64.59s/it]Evaluating commonsenseqa :  19%|██████▋                            | 12/63 [12:54<54:53, 64.57s/it]Evaluating commonsenseqa :  21%|███████▏                           | 13/63 [13:59<53:49, 64.58s/it]Evaluating commonsenseqa :  22%|███████▊                           | 14/63 [15:03<52:45, 64.61s/it]Evaluating commonsenseqa :  24%|████████▎                          | 15/63 [16:08<51:41, 64.61s/it]Evaluating commonsenseqa :  25%|████████▉                          | 16/63 [17:13<50:36, 64.61s/it]Evaluating commonsenseqa :  27%|█████████▍                         | 17/63 [18:17<49:25, 64.46s/it]Evaluating commonsenseqa :  29%|██████████                         | 18/63 [19:21<48:19, 64.43s/it]Evaluating commonsenseqa :  30%|██████████▌                        | 19/63 [20:26<47:16, 64.46s/it]Evaluating commonsenseqa :  32%|███████████                        | 20/63 [21:30<46:05, 64.32s/it]Evaluating commonsenseqa :  33%|███████████▋                       | 21/63 [22:34<45:05, 64.42s/it]Evaluating commonsenseqa :  35%|████████████▏                      | 22/63 [23:38<43:54, 64.25s/it]Evaluating commonsenseqa :  37%|████████████▊                      | 23/63 [24:43<42:50, 64.26s/it]Evaluating commonsenseqa :  38%|█████████████▎                     | 24/63 [25:47<41:45, 64.23s/it]Evaluating commonsenseqa :  40%|█████████████▉                     | 25/63 [26:51<40:38, 64.17s/it]Evaluating commonsenseqa :  41%|██████████████▍                    | 26/63 [27:55<39:31, 64.10s/it]Evaluating commonsenseqa :  43%|███████████████                    | 27/63 [28:59<38:34, 64.30s/it]Evaluating commonsenseqa :  44%|███████████████▌                   | 28/63 [30:04<37:35, 64.44s/it]Evaluating commonsenseqa :  46%|████████████████                   | 29/63 [31:08<36:25, 64.29s/it]Evaluating commonsenseqa :  48%|████████████████▋                  | 30/63 [32:13<35:27, 64.47s/it]Evaluating commonsenseqa :  49%|█████████████████▏                 | 31/63 [33:17<34:16, 64.27s/it]Evaluating commonsenseqa :  51%|█████████████████▊                 | 32/63 [34:22<33:20, 64.52s/it]Evaluating commonsenseqa :  52%|██████████████████▎                | 33/63 [35:26<32:16, 64.53s/it]Evaluating commonsenseqa :  54%|██████████████████▉                | 34/63 [36:31<31:11, 64.53s/it]Evaluating commonsenseqa :  56%|███████████████████▍               | 35/63 [37:35<30:00, 64.31s/it]Evaluating commonsenseqa :  57%|████████████████████               | 36/63 [38:40<29:01, 64.50s/it]Evaluating commonsenseqa :  59%|████████████████████▌              | 37/63 [39:44<27:55, 64.45s/it]Evaluating commonsenseqa :  60%|█████████████████████              | 38/63 [40:48<26:48, 64.33s/it]Evaluating commonsenseqa :  62%|█████████████████████▋             | 39/63 [41:53<25:45, 64.40s/it]Evaluating commonsenseqa :  63%|██████████████████████▏            | 40/63 [42:57<24:37, 64.24s/it]Evaluating commonsenseqa :  65%|██████████████████████▊            | 41/63 [44:01<23:35, 64.32s/it]Evaluating commonsenseqa :  67%|███████████████████████▎           | 42/63 [45:05<22:28, 64.21s/it]Evaluating commonsenseqa :  68%|███████████████████████▉           | 43/63 [46:09<21:22, 64.15s/it]Evaluating commonsenseqa :  70%|████████████████████████▍          | 44/63 [47:13<20:20, 64.22s/it]Evaluating commonsenseqa :  71%|█████████████████████████          | 45/63 [48:18<19:16, 64.23s/it]Evaluating commonsenseqa :  73%|█████████████████████████▌         | 46/63 [49:22<18:11, 64.19s/it]Evaluating commonsenseqa :  75%|██████████████████████████         | 47/63 [50:26<17:06, 64.16s/it]Evaluating commonsenseqa :  76%|██████████████████████████▋        | 48/63 [51:30<16:01, 64.09s/it]Evaluating commonsenseqa :  78%|███████████████████████████▏       | 49/63 [52:35<15:02, 64.46s/it]Evaluating commonsenseqa :  79%|███████████████████████████▊       | 50/63 [53:39<13:55, 64.30s/it]Evaluating commonsenseqa :  81%|████████████████████████████▎      | 51/63 [54:43<12:51, 64.29s/it]Evaluating commonsenseqa :  83%|████████████████████████████▉      | 52/63 [55:47<11:46, 64.19s/it]Evaluating commonsenseqa :  84%|█████████████████████████████▍     | 53/63 [56:51<10:41, 64.13s/it]Evaluating commonsenseqa :  86%|██████████████████████████████     | 54/63 [57:56<09:38, 64.23s/it]Evaluating commonsenseqa :  87%|██████████████████████████████▌    | 55/63 [59:01<08:35, 64.42s/it]Evaluating commonsenseqa :  89%|█████████████████████████████▎   | 56/63 [1:00:04<07:29, 64.24s/it]Evaluating commonsenseqa :  90%|█████████████████████████████▊   | 57/63 [1:01:08<06:25, 64.19s/it]Evaluating commonsenseqa :  92%|██████████████████████████████▍  | 58/63 [1:02:13<05:21, 64.34s/it]Evaluating commonsenseqa :  94%|██████████████████████████████▉  | 59/63 [1:03:18<04:17, 64.36s/it]Evaluating commonsenseqa :  95%|███████████████████████████████▍ | 60/63 [1:04:22<03:13, 64.44s/it]Evaluating commonsenseqa :  97%|███████████████████████████████▉ | 61/63 [1:05:26<02:08, 64.38s/it]Evaluating commonsenseqa :  98%|████████████████████████████████▍| 62/63 [1:06:30<01:04, 64.06s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████| 63/63 [1:07:08<00:00, 56.18s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████| 63/63 [1:07:08<00:00, 63.94s/it]
name: commonsenseqa | avg. gen lenth: 440.564 | time: 4028.67707490921s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-out-domain 0 --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 4 --data-dir /scratch/ylu130/processed_data/commonsenseqa/in-domain/i8-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-in-domain 8
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 01:04:19,146] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 01:04:19,686] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 01:04:19,687] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 01:04:19,687] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/in-domain/i8-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 8
  num_out_domain ............... 0
  out_domain_data_name ......... None
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i8-s1-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                                       | 0/9733 [00:00<?, ?it/s]Loading data: 100%|████████████████████████████████████████| 9733/9733 [00:00<00:00, 294263.40it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:06<00:06,  6.70s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:06<00:06,  6.98s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.02s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:08<00:08,  8.56s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:08<00:00,  4.03s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:08<00:00,  4.43s/it]
[2023-08-28 01:04:30,177] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.08s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.52s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.09s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.53s/it]
[2023-08-28 01:04:30,379] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
 > number of parameters: 6738415616
[2023-08-28 01:04:30,414] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:10<00:00,  4.70s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:10<00:00,  5.28s/it]
[2023-08-28 01:04:31,858] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-28 01:04:32,392] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-28 01:04:32,393] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-28 01:04:32,393] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-28 01:04:32,393] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-28 01:04:32,393] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-28 01:04:32,393] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f5601267640>
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-28 01:04:32,394] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-28 01:04:32,395] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-28 01:04:32,395] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-28 01:04:32,395] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-28 01:04:32,395] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-28 01:04:32,395] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-28 01:04:32,395] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-28 01:04:32,395] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-28 01:04:32,395] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-28 01:04:32,395] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-28 01:04:32,395] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-28 01:04:32,395] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-28 01:04:32,395] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-28 01:04:32,395] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-28 01:04:32,395] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-28 01:04:32,395] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-28 01:04:32,395] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-28 01:04:32,395] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-28 01:04:32,395] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-28 01:04:32,395] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-28 01:04:32,395] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-28 01:04:32,395] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-28 01:04:32,395] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-28 01:04:32,395] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-28 01:04:32,395] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                                            | 0/63 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Output: 1. The question is asking where you would find plumbing that would not be helpful if you were thirsty, meaning the plumbing would not provide drinkable water. 
2. Choice B - a wall wouldn't typically have any plumbing, so that choice doesn't make sense. 
3. Choice C - is not specific enough, as it doesn't even refer to a place, thus it can be eliminated.
4. Choice D - own home would likely have drinkable water, so that option doesn't make sense either.
5. Choice E - a water fountain is specifically designed to provide drinkable water, so this can't be the correct answer.
6. That leaves us with choice A - an oil refinery. This is a place where plumbing is used, but the pipelines carry oil, not water.
7. So, the correct response is A: oil refineries. This is a place where you could find plumbing (in the form of oil pipelines) but drinking the oil from these pipes when you're thirsty isn't possible or safe.
So the final answer is A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Output: 1. The question asks "What aren't they doing yet when a person is beginning work?"
2. Let's analyze each of the choices:

   - A: Working - incorrect, since the person is beginning work, so they are doing this.
 
   - B: Resting - incorrect, it's not related to starting work. One can rest before or after work.
   
   - C: Tiredness - incorrect, tiredness is a state and not an action. Plus it could happen during or after work.
   
   - D: Accomplishing - correct, as this is something which hasn't happened yet when a person is beginning to work. It's the result of completed work.
   
   - E: Momentum - incorrect, momentum implies motion or progress which can be a part of work process but not an outcome.

3. Therefore, the answer is D: Accomplishing.
So the final answer is D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Output: 1. The question is asking where one might find pens with a company logo.
2. A company logo is typically seen on company property or items that represent a certain company. 
3. Option B: On a pencil is incorrect because pencils and pens are two different types of stationery and they are not a place to find anything.
4. Option C: Write sentences on paper is not a place, rather it's a process you could do with a pen.
5. Option D: School is plausible; however, pens with company logos are less likely to be found in Schools as schools typically use generic or school-branded pens.
6. Option E: Backpack can be a possible place but it doesn't directly imply the presence of company logo pens.
7. Option A: Is an office, typically, companies will have pens with their logo in their office for employees, visitors, or clients to use. This makes it the most probable place to find pens with a company logo.
8. Therefore, the answer is A: office.
So the final answer is A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Output: 1. The question provides a scenario in which Billy is calling out to John.
2. The key here is to understand what Billy is expecting after he calls out.
3. When we call out to someone, it's generally implied that we are expecting an answer or a'response' from them. This is an interpretation based on common social conventions.
4. Checking the given options for what goes with this scenario, "response" seems to fit the context most appropriately as it signifies something in return to Billy's call out.
5. Option A, silence, would mean that Billy is expecting no return. This doesn't typically fit the context when someone calls out.
6. Option C, communication, although not entirely incorrect, it's important to note that the communication has already begun when Billy called out. He's now waiting for John's part.
7. Option D, hanging up, and option E, whisper, don't apply to the situation described, as they are more suited to phone call scenarios or situations requiring secrecy respectively.
8. Based on these reasonings, the most appropriate answer would be B: response.
So the final answer is B: response

Input: The lizard frightened the hiker, it's movements made what rustle? Choices:  A: garden B: trees C: books D: rocks E: bushes
Output: 1. The question is asking us to identify what a lizard, in its movement, would make rustle that could frighten a hiker.
2. We can eliminate choice A: garden, as it's too broad; a lizard can't make an entire garden rustle.
3. We also eliminate option C: books because typically, lizards and hikers would not be interacting in a place where books are present.
4. Consider choice D: rocks. Rocks do not rustle, hence it can't be the correct answer.
5. Looking at choice B: trees, this could be a plausible answer. However, lizards contain mostly ground-dwelling species and are likely too small and light to create a rustling sound in a tree.
6. We're left with choice E: bushes. Bushes could reasonably rustle with the movement of a lizard, especially if it was moving quickly.
7. Therefore, the most fitting answer is E: bushes.
So the final answer is E: bushes

Input: The man spent big money and time maintaining his lawn, it was part of keeping up with the Joneses where? Choices:  A: front yard B: suburbia C: neighborhood D: back yard E: golf course
Output: 1. The phrase "keeping up with the Joneses" is a figure of speech that originates from the suburbs. 
2. It is used to describe the phenomenon of using your neighbors as a standard for comparison and always trying to outdo or compete with them, especially in terms of material possessions. 
3. The context clues that help us in solving this question are "man spent big money and time maintaining his lawn" and "keeping up with the Joneses"; both are quite relevant to the suburban lifestyle and competition. 
4. Although options C 'neighborhood' and A 'front yard' might seem plausible, they could apply to urban or rural environments as well, not exclusively to suburban ones, therefore making them too broad. 
5. Option D 'back yard' doesn't accurately reflect the competition aspect of the expression as backyards are typically private venture, and E 'golf course' is not relevant to the scenario described. 
6. Therefore, the answer that best fits the question is B:'suburbia'.
So the final answer is B: suburbia

Input: What would a human do if they want to get to a store that he or she can see? Choices:  A: cross road B: see around C: drink coffee D: dream dreams E: think critically
Output: 1. The objective is for the person to reach a store he or she can already see.
2. Getting to the store involves some form of movement or action on the person's part.
3. Looking at the given choices, options B: see around, C: drink coffee, D: dream dreams, and E: think critically do not involve immediate physical movement towards the store.
4. The only choice that involves the person physically moving towards the store is A: cross road.
5. Therefore, the answer is A: cross road.
So the final answer is A: cross road

Input: Where would you grab an object contained by a doorway? Choices:  A: television B: control panel C: opening doors D: doorknob E: doorway
Output: 1. The question asks where you would grab an object contained by a doorway. 
2. This word 'contained by' implies that the object must be within the structure of the doorway instead of being an independent object that could be located elsewhere.
3. While a television (A), control panel (B), opening doors (C), and doorknob (D) are possible objects potentially connected to a doorway, they are not contained by the doorway itself.
4. A television is typically placed within rooms, not within doorways. A control panel can be attached near a doorway, but it can exist separately too. Opening doors is a verb and a process, not a physical entity. Doorknobs, although directly connected to doorways, are independent entities that exist separate from the doorway.
5. The logically reasonable answer, therefore, is E: doorway. It is the only option that is contained by the doorway - it is the doorway.
So the final answer is E: doorway

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i8-s1-rTrue-m4096
Evaluating commonsenseqa :   2%|▌                                 | 1/63 [01:04<1:06:23, 64.25s/it]Evaluating commonsenseqa :   3%|█                                 | 2/63 [02:08<1:05:16, 64.20s/it]Evaluating commonsenseqa :   5%|█▌                                | 3/63 [03:11<1:03:38, 63.65s/it]Evaluating commonsenseqa :   6%|██▏                               | 4/63 [04:14<1:02:21, 63.42s/it]Evaluating commonsenseqa :   8%|██▋                               | 5/63 [05:17<1:01:15, 63.36s/it]Evaluating commonsenseqa :  10%|███▏                              | 6/63 [06:20<1:00:01, 63.18s/it]Evaluating commonsenseqa :  11%|████                                | 7/63 [07:23<58:55, 63.14s/it]Evaluating commonsenseqa :  13%|████▌                               | 8/63 [08:26<57:49, 63.08s/it]Evaluating commonsenseqa :  14%|█████▏                              | 9/63 [09:29<56:35, 62.88s/it]Evaluating commonsenseqa :  16%|█████▌                             | 10/63 [10:31<55:26, 62.76s/it]Evaluating commonsenseqa :  17%|██████                             | 11/63 [11:34<54:28, 62.86s/it]Evaluating commonsenseqa :  19%|██████▋                            | 12/63 [12:36<53:18, 62.71s/it]Evaluating commonsenseqa :  21%|███████▏                           | 13/63 [13:40<52:23, 62.88s/it]Evaluating commonsenseqa :  22%|███████▊                           | 14/63 [14:43<51:22, 62.90s/it]Evaluating commonsenseqa :  24%|████████▎                          | 15/63 [15:45<50:16, 62.84s/it]Evaluating commonsenseqa :  25%|████████▉                          | 16/63 [16:48<49:09, 62.75s/it]Evaluating commonsenseqa :  27%|█████████▍                         | 17/63 [17:51<48:08, 62.80s/it]Evaluating commonsenseqa :  29%|██████████                         | 18/63 [18:54<47:08, 62.85s/it]Evaluating commonsenseqa :  30%|██████████▌                        | 19/63 [19:56<46:02, 62.77s/it]Evaluating commonsenseqa :  32%|███████████                        | 20/63 [20:59<44:57, 62.72s/it]Evaluating commonsenseqa :  33%|███████████▋                       | 21/63 [22:01<43:48, 62.59s/it]Evaluating commonsenseqa :  35%|████████████▏                      | 22/63 [23:04<42:53, 62.77s/it]Evaluating commonsenseqa :  37%|████████████▊                      | 23/63 [24:07<41:48, 62.71s/it]Evaluating commonsenseqa :  38%|█████████████▎                     | 24/63 [25:11<40:54, 62.94s/it]Evaluating commonsenseqa :  40%|█████████████▉                     | 25/63 [26:13<39:51, 62.94s/it]Evaluating commonsenseqa :  41%|██████████████▍                    | 26/63 [27:17<38:51, 63.01s/it]Evaluating commonsenseqa :  43%|███████████████                    | 27/63 [28:19<37:45, 62.92s/it]Evaluating commonsenseqa :  44%|███████████████▌                   | 28/63 [29:22<36:38, 62.82s/it]Evaluating commonsenseqa :  46%|████████████████                   | 29/63 [30:25<35:36, 62.82s/it]Evaluating commonsenseqa :  48%|████████████████▋                  | 30/63 [31:27<34:30, 62.76s/it]Evaluating commonsenseqa :  49%|█████████████████▏                 | 31/63 [32:30<33:29, 62.81s/it]Evaluating commonsenseqa :  51%|█████████████████▊                 | 32/63 [33:33<32:28, 62.86s/it]Evaluating commonsenseqa :  52%|██████████████████▎                | 33/63 [34:36<31:25, 62.86s/it]Evaluating commonsenseqa :  54%|██████████████████▉                | 34/63 [35:39<30:22, 62.83s/it]Evaluating commonsenseqa :  56%|███████████████████▍               | 35/63 [36:42<29:17, 62.77s/it]Evaluating commonsenseqa :  57%|████████████████████               | 36/63 [37:44<28:16, 62.82s/it]Evaluating commonsenseqa :  59%|████████████████████▌              | 37/63 [38:47<27:12, 62.80s/it]Evaluating commonsenseqa :  60%|█████████████████████              | 38/63 [39:51<26:17, 63.11s/it]Evaluating commonsenseqa :  62%|█████████████████████▋             | 39/63 [40:54<25:12, 63.01s/it]Evaluating commonsenseqa :  63%|██████████████████████▏            | 40/63 [41:57<24:08, 62.96s/it]Evaluating commonsenseqa :  65%|██████████████████████▊            | 41/63 [43:00<23:08, 63.12s/it]Evaluating commonsenseqa :  67%|███████████████████████▎           | 42/63 [44:03<22:06, 63.15s/it]Evaluating commonsenseqa :  68%|███████████████████████▉           | 43/63 [45:07<21:03, 63.18s/it]Evaluating commonsenseqa :  70%|████████████████████████▍          | 44/63 [46:10<19:59, 63.13s/it]Evaluating commonsenseqa :  71%|█████████████████████████          | 45/63 [47:12<18:52, 62.94s/it]Evaluating commonsenseqa :  73%|█████████████████████████▌         | 46/63 [48:15<17:50, 62.94s/it]Evaluating commonsenseqa :  75%|██████████████████████████         | 47/63 [49:18<16:47, 62.95s/it]Evaluating commonsenseqa :  76%|██████████████████████████▋        | 48/63 [50:21<15:45, 63.05s/it]Evaluating commonsenseqa :  78%|███████████████████████████▏       | 49/63 [51:25<14:44, 63.16s/it]Evaluating commonsenseqa :  79%|███████████████████████████▊       | 50/63 [52:28<13:42, 63.25s/it]Evaluating commonsenseqa :  81%|████████████████████████████▎      | 51/63 [53:31<12:38, 63.22s/it]Evaluating commonsenseqa :  83%|████████████████████████████▉      | 52/63 [54:35<11:35, 63.27s/it]Evaluating commonsenseqa :  84%|█████████████████████████████▍     | 53/63 [55:38<10:31, 63.18s/it]Evaluating commonsenseqa :  86%|██████████████████████████████     | 54/63 [56:41<09:29, 63.32s/it]Evaluating commonsenseqa :  87%|██████████████████████████████▌    | 55/63 [57:44<08:24, 63.12s/it]Evaluating commonsenseqa :  89%|███████████████████████████████    | 56/63 [58:48<07:22, 63.27s/it]Evaluating commonsenseqa :  90%|███████████████████████████████▋   | 57/63 [59:51<06:19, 63.18s/it]Evaluating commonsenseqa :  92%|██████████████████████████████▍  | 58/63 [1:00:54<05:16, 63.36s/it]Evaluating commonsenseqa :  94%|██████████████████████████████▉  | 59/63 [1:01:57<04:12, 63.20s/it]Evaluating commonsenseqa :  95%|███████████████████████████████▍ | 60/63 [1:03:00<03:09, 63.13s/it]Evaluating commonsenseqa :  97%|███████████████████████████████▉ | 61/63 [1:04:03<02:05, 62.99s/it]Evaluating commonsenseqa :  98%|████████████████████████████████▍| 62/63 [1:05:05<01:02, 62.84s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████| 63/63 [1:05:43<00:00, 55.20s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████| 63/63 [1:05:43<00:00, 62.59s/it]
name: commonsenseqa | avg. gen lenth: 434.648 | time: 3943.777048110962s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-out-domain 0 --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 4 --data-dir /scratch/ylu130/processed_data/commonsenseqa/in-domain/i9-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-in-domain 9
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 02:10:26,095] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 02:10:26,107] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 02:10:26,113] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 02:10:26,132] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/in-domain/i9-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 9
  num_out_domain ............... 0
  out_domain_data_name ......... None
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i9-s1-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                                       | 0/9732 [00:00<?, ?it/s]Loading data: 100%|████████████████████████████████████████| 9732/9732 [00:00<00:00, 261534.30it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:06<00:06,  6.81s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.14s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.14s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:08<00:00,  4.05s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:08<00:00,  4.47s/it]
[2023-08-28 02:10:36,789] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.16s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.61s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.19s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.63s/it]
 > number of parameters: 6738415616
[2023-08-28 02:10:36,932] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-28 02:10:37,003] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:09<00:09,  9.47s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:11<00:00,  5.11s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:11<00:00,  5.77s/it]
[2023-08-28 02:10:39,349] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-28 02:10:39,976] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-28 02:10:39,978] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-28 02:10:39,978] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-28 02:10:39,978] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-28 02:10:39,978] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-28 02:10:39,978] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f32e008f640>
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-28 02:10:39,979] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-28 02:10:39,980] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-28 02:10:39,980] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                                            | 0/63 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Output: 1. The question asks where you can find plumbing that wouldn't help if you were thirsty.
2. This implies that you need to find a place with plumbing that does not transport drinkable water.
3. Option B, C, D, and E all have plumbing that can potentially access drinkable water.
4. Option B: the wall could refer to pipes running inside the wall, carrying clean water.
5. Option C: a show could imply a venue that has facilities, including water.
6. Option D: your own home definitely has usable plumbing for drinking water.
7. Option E: a water fountain also provides drinkable water.
8. Option A, oil refineries, are facilities for refining crude oil into usable materials such as gasoline and are not suitable for human water consumption.
9. Thus, the answer is A: oil refineries.
So the final answer is A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Output: 1. The question is asking what a person is not doing yet when they are in the beginning stages of work.
2. Option A: Working - This is not a correct answer because the person is in fact working. The question itself states that they are "beginning work."
3. Option B: Resting - This is not a correct option either. When somebody is beginning to work, they are not resting. Though it might be accurate to say they are not resting, the question is asking for what they are specifically not doing related to the work.
4. Option C: Tiredness - This option is irrelevant. Tiredness is a state of being, not an action. Therefore this can't be the correct answer. 
5. Option E: Momentum - This is also not the correct answer. Momentum refers to the process of working and keeping up a pace. It can be argued that at the beginning of work, momentum is being established.
6. Option D: Accomplishing - This is the correct answer. When a person is just beginning to work, they haven't accomplished anything yet. Accomplishment comes later, once the work is completed. So, at the beginning of the work, they are not yet accomplishing anything.
So the final answer is D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Output: 1. Pens with a company logo would most likely be used for professional purposes rather than personal use.
2. Offices often use pens with the company logo on them for branding or marketing.
3. This means that they are probably not found on a pencil, which is a separate type of writing instrument and not likely to carry a company's logo.
4. While you indeed use pens to write sentences on paper, the statement does not suggest a specific location where you could find these pens.
5. Schools generally supply standard pens or pencils for their students or staff and would not typically have pens with a company logo.
6. You might carry a pen in a backpack, but it does not suggest where the pen, especially one with a company logo, would originate.
7. Therefore, the most logical place to find pens with a company logo is in an office.
So the final answer is A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Output: 1. The question is about an interaction between Billy and John in which Billy calls out to John.
2. Calling out to someone traditionally assumes that a response is expected. 
3. The primary aim of Billy's action (calling out) in the context of the question would be to get a reaction or result, which in human interaction terms would be a'response'. 
4. Therefore, the correct answer is B: response.
So the final answer is B: response

Input: The lizard frightened the hiker, it's movements made what rustle? Choices:  A: garden B: trees C: books D: rocks E: bushes
Output: 1. The question is asking about the source of a sound, specifically, a rustling sound.
2. Rustling is typically associated with things that can move or be displaced in a subtle manner.
3. We look at the provided choices to pinpoint the source of the rustling. 
4. The choice 'garden' may be too broad, as a garden could encompass different elements, many of which may not make a rustling sound.
5. 'Trees' could rustle, but it would require a powerful force such as strong wind, unlikely to be caused by a lizard.
6. 'Books' can make a rustling noise, but it wouldn't make sense in this context as a lizard is an outdoors creature.
7. The choice 'rocks' is not suitable because rocks do not rustle.
8. The last choice is 'bushes', which can certainly rustle if something is moving around inside them, such as a lizard.
9. Given these considerations, the answer is E: 'bushes'.
So the final answer is E: bushes

Input: The man spent big money and time maintaining his lawn, it was part of keeping up with the Joneses where? Choices:  A: front yard B: suburbia C: neighborhood D: back yard E: golf course
Output: 1. The phrase "keeping up with the Joneses" is an idiom referring to the comparison to one's neighbor as a benchmark for social class or the accumulation of material goods.
2. The context of the question suggests the place should be related to where the man lives and where his efforts of maintaining his lawn would potentially be reciprocated.
3. The options "front yard" and "back yard" are specific parts of a property so they could not represent the surroundings where people are competing for appearances. 
4. The "golf course" also cannot be a correct answer as it is a place for sport, and not a residential area.
5. So, the correct answer among the given choices is "suburbia" as it refers to residential areas where people live and maintain their properties. Hence, this term most closely aligns with the concept of "keeping up with the Joneses".
So the final answer is B: suburbia

Input: What would a human do if they want to get to a store that he or she can see? Choices:  A: cross road B: see around C: drink coffee D: dream dreams E: think critically
Output: 1. The problem presents a situation where a human can see a store and presumably wants to get to that store.
2. We need to identify the best course of action from the given choices that will help the person reach the store.
3. Looking at choice A: crossing the road, it's a physical act of moving from one location to another which could possibly lead someone closer to their target location.
4. Examining choice B: see around, it's less direct and might only serve as a preparatory step for moving but not the actual movement.
5. Looking at choice C: drink coffee, is not relevant to the issue at hand because it doesn't involve any action that would bring someone closer to the store.
6. Choice D: dream dreams, involves a state of mind not connected to physical movement or orientation.
7. Looking at choice E: think critically, while useful in problem-solving scenarios, it's less direct in achieving the goal of getting to the store than choice A.
8. Therefore, from the given options, A: cross road appears to be the most likely action a person would take to get to a store they can see.
So the final answer is A: cross road

Input: Where would you grab an object contained by a doorway? Choices:  A: television B: control panel C: opening doors D: doorknob E: doorway
Output: 1. The question is asking for the place to grab an object that is contained by a doorway. 
2. To grab an object contained by a doorway means that you want to manipulate something that is part of the structure or system of the door itself. 
3. Your options are the television, control panel, opening doors, doorknob, and the doorway. 
4. The television and control panel are not part of the door's structure, so those options can be eliminated.
5. Open doors seem like a probable choice, yet it refers to the moving part of the doorway only, when the object may be located anywhere within the structure of a doorway.
6. The doorknob, like opening doors, refers to a specific part of a door and not the entire structure. 
7. This leaves doorway, which is the only choice encompassing the full structure of a door. You would grab the object at the doorway because it envelops the entire space and structure where the object described could be located. 
8. Therefore, the answer is E: doorway.
So the final answer is E: doorway

Input: Sarah knew she was committing perjury, so there was a lot of what feeling between her and the prosecutor? Choices:  A: arrest B: tension C: shame D: attraction E: embarrassment
Output: 1. The question requires understanding of the implied emotional context between Sarah and the prosecutor.
2. The context implies an antagonistic situation rather than a friendly or neutral one, since perjury is a serious offence and Sarah would be in opposition to the prosecutor.
3. Arrest, the first possible option, is not fitting because it describes an action rather than a feeling.
4. Shame and embarrassment could be feelings that Sarah might be experiencing, but these are personal feelings - they don't necessarily describe the dynamic between Sarah and the prosecutor.
5. While attraction is technically a feeling that could exist between two people, it's unlikely in this context as it usually describes a positive or pleasant dynamic. The context here is one of dishonesty and confrontation.
6. Tension, however, is a term often used to describe a strained, difficult or stressed relationship or situation. Since perjury is a crime and Sarah knows this, there would likely be a tense feeling between her and the prosecutor.
7. Hence, the answer is B: tension.
So the final answer is B: tension

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i9-s1-rTrue-m4096
Evaluating commonsenseqa :   2%|▌                                 | 1/63 [01:00<1:02:44, 60.71s/it]Evaluating commonsenseqa :   3%|█                                 | 2/63 [02:00<1:01:01, 60.03s/it]Evaluating commonsenseqa :   5%|█▋                                  | 3/63 [02:59<59:37, 59.63s/it]Evaluating commonsenseqa :   6%|██▎                                 | 4/63 [03:58<58:30, 59.50s/it]Evaluating commonsenseqa :   8%|██▊                                 | 5/63 [04:58<57:39, 59.64s/it]Evaluating commonsenseqa :  10%|███▍                                | 6/63 [05:57<56:33, 59.54s/it]Evaluating commonsenseqa :  11%|████                                | 7/63 [06:56<55:22, 59.33s/it]Evaluating commonsenseqa :  13%|████▌                               | 8/63 [07:55<54:15, 59.19s/it]Evaluating commonsenseqa :  14%|█████▏                              | 9/63 [08:55<53:22, 59.31s/it]Evaluating commonsenseqa :  16%|█████▌                             | 10/63 [09:54<52:17, 59.19s/it]Evaluating commonsenseqa :  17%|██████                             | 11/63 [10:53<51:15, 59.15s/it]Evaluating commonsenseqa :  19%|██████▋                            | 12/63 [11:52<50:15, 59.12s/it]Evaluating commonsenseqa :  21%|███████▏                           | 13/63 [12:51<49:15, 59.11s/it]Evaluating commonsenseqa :  22%|███████▊                           | 14/63 [13:50<48:12, 59.02s/it]Evaluating commonsenseqa :  24%|████████▎                          | 15/63 [14:49<47:16, 59.10s/it]Evaluating commonsenseqa :  25%|████████▉                          | 16/63 [15:48<46:15, 59.05s/it]Evaluating commonsenseqa :  27%|█████████▍                         | 17/63 [16:47<45:21, 59.16s/it]Evaluating commonsenseqa :  29%|██████████                         | 18/63 [17:46<44:15, 59.01s/it]Evaluating commonsenseqa :  30%|██████████▌                        | 19/63 [18:45<43:14, 58.96s/it]Evaluating commonsenseqa :  32%|███████████                        | 20/63 [19:44<42:11, 58.88s/it]Evaluating commonsenseqa :  33%|███████████▋                       | 21/63 [20:43<41:14, 58.91s/it]Evaluating commonsenseqa :  35%|████████████▏                      | 22/63 [21:41<40:13, 58.87s/it]Evaluating commonsenseqa :  37%|████████████▊                      | 23/63 [22:41<39:24, 59.10s/it]Evaluating commonsenseqa :  38%|█████████████▎                     | 24/63 [23:40<38:29, 59.21s/it]Evaluating commonsenseqa :  40%|█████████████▉                     | 25/63 [24:39<37:23, 59.03s/it]Evaluating commonsenseqa :  41%|██████████████▍                    | 26/63 [25:38<36:20, 58.94s/it]Evaluating commonsenseqa :  43%|███████████████                    | 27/63 [26:37<35:28, 59.13s/it]Evaluating commonsenseqa :  44%|███████████████▌                   | 28/63 [27:36<34:27, 59.07s/it]Evaluating commonsenseqa :  46%|████████████████                   | 29/63 [28:35<33:25, 58.99s/it]Evaluating commonsenseqa :  48%|████████████████▋                  | 30/63 [29:34<32:25, 58.96s/it]Evaluating commonsenseqa :  49%|█████████████████▏                 | 31/63 [30:33<31:28, 59.03s/it]Evaluating commonsenseqa :  51%|█████████████████▊                 | 32/63 [31:32<30:31, 59.08s/it]Evaluating commonsenseqa :  52%|██████████████████▎                | 33/63 [32:31<29:30, 59.02s/it]Evaluating commonsenseqa :  54%|██████████████████▉                | 34/63 [33:30<28:31, 59.03s/it]Evaluating commonsenseqa :  56%|███████████████████▍               | 35/63 [34:29<27:32, 59.03s/it]Evaluating commonsenseqa :  57%|████████████████████               | 36/63 [35:29<26:37, 59.18s/it]Evaluating commonsenseqa :  59%|████████████████████▌              | 37/63 [36:28<25:37, 59.12s/it]Evaluating commonsenseqa :  60%|█████████████████████              | 38/63 [37:27<24:39, 59.19s/it]Evaluating commonsenseqa :  62%|█████████████████████▋             | 39/63 [38:26<23:39, 59.13s/it]Evaluating commonsenseqa :  63%|██████████████████████▏            | 40/63 [39:25<22:38, 59.06s/it]Evaluating commonsenseqa :  65%|██████████████████████▊            | 41/63 [40:24<21:41, 59.16s/it]Evaluating commonsenseqa :  67%|███████████████████████▎           | 42/63 [41:24<20:43, 59.19s/it]Evaluating commonsenseqa :  68%|███████████████████████▉           | 43/63 [42:23<19:42, 59.12s/it]Evaluating commonsenseqa :  70%|████████████████████████▍          | 44/63 [43:22<18:43, 59.14s/it]Evaluating commonsenseqa :  71%|█████████████████████████          | 45/63 [44:21<17:42, 59.02s/it]Evaluating commonsenseqa :  73%|█████████████████████████▌         | 46/63 [45:20<16:42, 58.98s/it]Evaluating commonsenseqa :  75%|██████████████████████████         | 47/63 [46:18<15:42, 58.93s/it]Evaluating commonsenseqa :  76%|██████████████████████████▋        | 48/63 [47:17<14:43, 58.92s/it]Evaluating commonsenseqa :  78%|███████████████████████████▏       | 49/63 [48:16<13:44, 58.92s/it]Evaluating commonsenseqa :  79%|███████████████████████████▊       | 50/63 [49:15<12:46, 58.95s/it]Evaluating commonsenseqa :  81%|████████████████████████████▎      | 51/63 [50:14<11:47, 58.93s/it]Evaluating commonsenseqa :  83%|████████████████████████████▉      | 52/63 [51:13<10:48, 58.98s/it]Evaluating commonsenseqa :  84%|█████████████████████████████▍     | 53/63 [52:12<09:49, 58.95s/it]Evaluating commonsenseqa :  86%|██████████████████████████████     | 54/63 [53:11<08:50, 58.97s/it]Evaluating commonsenseqa :  87%|██████████████████████████████▌    | 55/63 [54:10<07:52, 59.00s/it]Evaluating commonsenseqa :  89%|███████████████████████████████    | 56/63 [55:09<06:52, 58.94s/it]Evaluating commonsenseqa :  90%|███████████████████████████████▋   | 57/63 [56:08<05:54, 59.11s/it]Evaluating commonsenseqa :  92%|████████████████████████████████▏  | 58/63 [57:07<04:55, 59.04s/it]Evaluating commonsenseqa :  94%|████████████████████████████████▊  | 59/63 [58:06<03:55, 58.97s/it]Evaluating commonsenseqa :  95%|█████████████████████████████████▎ | 60/63 [59:06<02:57, 59.10s/it]Evaluating commonsenseqa :  97%|███████████████████████████████▉ | 61/63 [1:00:05<01:58, 59.11s/it]Evaluating commonsenseqa :  98%|████████████████████████████████▍| 62/63 [1:01:03<00:59, 59.03s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████| 63/63 [1:01:39<00:00, 51.96s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████| 63/63 [1:01:39<00:00, 58.72s/it]
name: commonsenseqa | avg. gen lenth: 458.416 | time: 3700.09597325325s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-out-domain 0 --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 4 --data-dir /scratch/ylu130/processed_data/commonsenseqa/in-domain/i1-s1-rFalse --seed 1 --max-prompt-length 4096 --num-in-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 03:12:52,202] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 03:12:52,202] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 03:12:52,212] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 03:12:52,212] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/in-domain/i1-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 1
  num_out_domain ............... 0
  out_domain_data_name ......... None
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i1-s1-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                                       | 0/9740 [00:00<?, ?it/s]Loading data: 100%|███████████████████████████████████████| 9740/9740 [00:00<00:00, 1249007.00it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:06<00:06,  6.82s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.46s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.42s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.50s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.21s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.60s/it]
[2023-08-28 03:13:02,563] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.29s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.76s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.33s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.80s/it]
[2023-08-28 03:13:03,092] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-28 03:13:03,104] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.37s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.84s/it]
 > number of parameters: 6738415616
[2023-08-28 03:13:03,297] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-28 03:13:03,832] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-28 03:13:03,833] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f2629fff1f0>
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-28 03:13:03,834] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-28 03:13:03,835] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-28 03:13:03,835] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                                            | 0/63 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Output: A: oil refineries

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i1-s1-rFalse-m4096
Evaluating commonsenseqa :   2%|▌                                | 1/63 [01:41<1:44:49, 101.45s/it]Evaluating commonsenseqa :   3%|█                                | 2/63 [03:24<1:44:01, 102.32s/it]Evaluating commonsenseqa :   5%|█▌                               | 3/63 [05:21<1:49:10, 109.18s/it]Evaluating commonsenseqa :   6%|██                               | 4/63 [07:21<1:51:21, 113.24s/it]Evaluating commonsenseqa :   8%|██▌                              | 5/63 [09:15<1:49:57, 113.76s/it]Evaluating commonsenseqa :  10%|███▏                             | 6/63 [10:40<1:38:42, 103.90s/it]Evaluating commonsenseqa :  11%|███▋                             | 7/63 [12:33<1:39:47, 106.91s/it]Evaluating commonsenseqa :  13%|████▏                            | 8/63 [14:29<1:40:27, 109.59s/it]Evaluating commonsenseqa :  14%|████▊                             | 9/63 [15:41<1:28:08, 97.94s/it]Evaluating commonsenseqa :  16%|█████                           | 10/63 [17:36<1:31:12, 103.26s/it]Evaluating commonsenseqa :  17%|█████▊                           | 11/63 [19:07<1:26:09, 99.40s/it]Evaluating commonsenseqa :  19%|██████                          | 12/63 [21:01<1:28:20, 103.94s/it]Evaluating commonsenseqa :  21%|██████▌                         | 13/63 [22:38<1:24:57, 101.95s/it]Evaluating commonsenseqa :  22%|███████▎                         | 14/63 [23:58<1:17:48, 95.27s/it]Evaluating commonsenseqa :  24%|███████▌                        | 15/63 [25:52<1:20:47, 100.98s/it]Evaluating commonsenseqa :  25%|████████▏                       | 16/63 [27:47<1:22:23, 105.18s/it]Evaluating commonsenseqa :  27%|████████▋                       | 17/63 [29:44<1:23:18, 108.66s/it]Evaluating commonsenseqa :  29%|█████████▏                      | 18/63 [31:39<1:22:50, 110.45s/it]Evaluating commonsenseqa :  30%|█████████▉                       | 19/63 [32:32<1:08:25, 93.30s/it]Evaluating commonsenseqa :  32%|██████████▍                      | 20/63 [34:24<1:10:54, 98.93s/it]Evaluating commonsenseqa :  33%|██████████▋                     | 21/63 [36:20<1:12:47, 104.00s/it]Evaluating commonsenseqa :  35%|███████████▏                    | 22/63 [38:15<1:13:15, 107.20s/it]Evaluating commonsenseqa :  37%|███████████▋                    | 23/63 [40:09<1:12:55, 109.38s/it]Evaluating commonsenseqa :  38%|████████████▏                   | 24/63 [41:57<1:10:43, 108.80s/it]Evaluating commonsenseqa :  40%|████████████▋                   | 25/63 [43:50<1:09:51, 110.31s/it]Evaluating commonsenseqa :  41%|█████████████▏                  | 26/63 [45:47<1:09:09, 112.15s/it]Evaluating commonsenseqa :  43%|█████████████▋                  | 27/63 [47:41<1:07:35, 112.64s/it]Evaluating commonsenseqa :  44%|██████████████▏                 | 28/63 [49:34<1:05:54, 112.99s/it]Evaluating commonsenseqa :  46%|██████████████▋                 | 29/63 [51:30<1:04:27, 113.74s/it]Evaluating commonsenseqa :  48%|███████████████▏                | 30/63 [53:12<1:00:36, 110.21s/it]Evaluating commonsenseqa :  49%|████████████████▋                 | 31/63 [55:07<59:38, 111.81s/it]Evaluating commonsenseqa :  51%|█████████████████▎                | 32/63 [57:02<58:14, 112.74s/it]Evaluating commonsenseqa :  52%|█████████████████▊                | 33/63 [58:27<52:06, 104.21s/it]Evaluating commonsenseqa :  54%|█████████████████▎              | 34/63 [1:00:24<52:17, 108.18s/it]Evaluating commonsenseqa :  56%|█████████████████▊              | 35/63 [1:02:22<51:51, 111.13s/it]Evaluating commonsenseqa :  57%|██████████████████▊              | 36/63 [1:03:33<44:32, 99.00s/it]Evaluating commonsenseqa :  59%|███████████████████▍             | 37/63 [1:04:15<35:34, 82.10s/it]Evaluating commonsenseqa :  60%|███████████████████▉             | 38/63 [1:06:10<38:14, 91.77s/it]Evaluating commonsenseqa :  62%|████████████████████▍            | 39/63 [1:07:32<35:34, 88.95s/it]Evaluating commonsenseqa :  63%|████████████████████▉            | 40/63 [1:09:12<35:23, 92.32s/it]Evaluating commonsenseqa :  65%|█████████████████████▍           | 41/63 [1:11:07<36:16, 98.95s/it]Evaluating commonsenseqa :  67%|██████████████████████           | 42/63 [1:12:41<34:10, 97.64s/it]Evaluating commonsenseqa :  68%|█████████████████████▊          | 43/63 [1:14:37<34:21, 103.09s/it]Evaluating commonsenseqa :  70%|██████████████████████▎         | 44/63 [1:16:33<33:50, 106.85s/it]Evaluating commonsenseqa :  71%|██████████████████████▊         | 45/63 [1:18:27<32:43, 109.09s/it]Evaluating commonsenseqa :  73%|███████████████████████▎        | 46/63 [1:19:56<29:13, 103.14s/it]Evaluating commonsenseqa :  75%|███████████████████████▊        | 47/63 [1:21:40<27:31, 103.24s/it]Evaluating commonsenseqa :  76%|█████████████████████████▏       | 48/63 [1:22:12<20:28, 81.87s/it]Evaluating commonsenseqa :  78%|█████████████████████████▋       | 49/63 [1:24:10<21:37, 92.66s/it]Evaluating commonsenseqa :  79%|██████████████████████████▏      | 50/63 [1:26:05<21:32, 99.39s/it]Evaluating commonsenseqa :  81%|█████████████████████████▉      | 51/63 [1:28:00<20:48, 104.02s/it]Evaluating commonsenseqa :  83%|██████████████████████████▍     | 52/63 [1:29:54<19:38, 107.12s/it]Evaluating commonsenseqa :  84%|██████████████████████████▉     | 53/63 [1:31:52<18:24, 110.44s/it]Evaluating commonsenseqa :  86%|███████████████████████████▍    | 54/63 [1:33:44<16:37, 110.82s/it]Evaluating commonsenseqa :  87%|███████████████████████████▉    | 55/63 [1:35:36<14:48, 111.09s/it]Evaluating commonsenseqa :  89%|█████████████████████████████▎   | 56/63 [1:36:19<10:36, 90.87s/it]Evaluating commonsenseqa :  90%|█████████████████████████████▊   | 57/63 [1:38:17<09:53, 98.93s/it]Evaluating commonsenseqa :  92%|██████████████████████████████▍  | 58/63 [1:38:57<06:46, 81.37s/it]Evaluating commonsenseqa :  94%|██████████████████████████████▉  | 59/63 [1:40:53<06:06, 91.64s/it]Evaluating commonsenseqa :  95%|███████████████████████████████▍ | 60/63 [1:42:51<04:58, 99.51s/it]Evaluating commonsenseqa :  97%|███████████████████████████████▉ | 61/63 [1:43:51<02:55, 87.82s/it]Evaluating commonsenseqa :  98%|████████████████████████████████▍| 62/63 [1:45:45<01:35, 95.52s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████| 63/63 [1:46:49<00:00, 86.03s/it]Evaluating commonsenseqa : 100%|████████████████████████████████| 63/63 [1:46:49<00:00, 101.74s/it]
name: commonsenseqa | avg. gen lenth: 260.78 | time: 6409.573023080826s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-out-domain 0 --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 4 --data-dir /scratch/ylu130/processed_data/commonsenseqa/in-domain/i2-s1-rFalse --seed 1 --max-prompt-length 4096 --num-in-domain 2
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 05:02:36,092] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 05:02:36,204] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 05:02:36,257] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 05:02:36,298] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/in-domain/i2-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 2
  num_out_domain ............... 0
  out_domain_data_name ......... None
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i2-s1-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                                       | 0/9739 [00:00<?, ?it/s]Loading data: 100%|███████████████████████████████████████| 9739/9739 [00:00<00:00, 1160826.58it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:06<00:06,  6.73s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.21s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.24s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.27s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:08<00:00,  3.92s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:08<00:00,  4.34s/it]
[2023-08-28 05:02:46,197] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.18s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.64s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.25s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.70s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.26s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.71s/it]
[2023-08-28 05:02:46,862] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
 > number of parameters: 6738415616
[2023-08-28 05:02:46,949] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-28 05:02:46,999] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-28 05:02:47,598] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-28 05:02:47,599] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f370985b610>
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-28 05:02:47,600] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-28 05:02:47,601] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-28 05:02:47,601] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                                            | 0/63 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Output: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Output: D: accomplishing

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i2-s1-rFalse-m4096
Evaluating commonsenseqa :   2%|▌                                | 1/63 [01:55<1:59:40, 115.82s/it]Evaluating commonsenseqa :   3%|█                                | 2/63 [03:38<1:50:01, 108.23s/it]Evaluating commonsenseqa :   5%|█▌                               | 3/63 [05:32<1:50:46, 110.77s/it]Evaluating commonsenseqa :   6%|██                               | 4/63 [07:25<1:49:38, 111.50s/it]Evaluating commonsenseqa :   8%|██▌                              | 5/63 [09:14<1:47:01, 110.71s/it]Evaluating commonsenseqa :  10%|███▏                             | 6/63 [11:07<1:45:47, 111.35s/it]Evaluating commonsenseqa :  11%|███▋                             | 7/63 [12:28<1:34:51, 101.64s/it]Evaluating commonsenseqa :  13%|████▎                             | 8/63 [14:01<1:30:33, 98.79s/it]Evaluating commonsenseqa :  14%|████▊                             | 9/63 [15:18<1:22:45, 91.96s/it]Evaluating commonsenseqa :  16%|█████▏                           | 10/63 [17:11<1:26:58, 98.47s/it]Evaluating commonsenseqa :  17%|█████▊                           | 11/63 [18:45<1:24:09, 97.11s/it]Evaluating commonsenseqa :  19%|██████                          | 12/63 [20:40<1:27:07, 102.50s/it]Evaluating commonsenseqa :  21%|██████▊                          | 13/63 [21:51<1:17:30, 93.01s/it]Evaluating commonsenseqa :  22%|███████▎                         | 14/63 [23:44<1:20:58, 99.15s/it]Evaluating commonsenseqa :  24%|███████▌                        | 15/63 [25:37<1:22:34, 103.23s/it]Evaluating commonsenseqa :  25%|████████▏                       | 16/63 [27:32<1:23:37, 106.76s/it]Evaluating commonsenseqa :  27%|████████▋                       | 17/63 [29:25<1:23:22, 108.76s/it]Evaluating commonsenseqa :  29%|█████████▏                      | 18/63 [31:06<1:19:48, 106.41s/it]Evaluating commonsenseqa :  30%|█████████▋                      | 19/63 [32:59<1:19:27, 108.36s/it]Evaluating commonsenseqa :  32%|██████████▏                     | 20/63 [34:52<1:18:41, 109.80s/it]Evaluating commonsenseqa :  33%|██████████▋                     | 21/63 [36:17<1:11:36, 102.30s/it]Evaluating commonsenseqa :  35%|███████████▏                    | 22/63 [38:09<1:11:50, 105.14s/it]Evaluating commonsenseqa :  37%|███████████▋                    | 23/63 [39:59<1:11:06, 106.67s/it]Evaluating commonsenseqa :  38%|████████████▏                   | 24/63 [41:44<1:08:58, 106.11s/it]Evaluating commonsenseqa :  40%|████████████▋                   | 25/63 [43:36<1:08:19, 107.88s/it]Evaluating commonsenseqa :  41%|██████████████▍                    | 26/63 [44:31<56:48, 92.13s/it]Evaluating commonsenseqa :  43%|███████████████                    | 27/63 [46:25<59:05, 98.49s/it]Evaluating commonsenseqa :  44%|██████████████▏                 | 28/63 [48:20<1:00:21, 103.47s/it]Evaluating commonsenseqa :  46%|██████████████▋                 | 29/63 [50:14<1:00:23, 106.58s/it]Evaluating commonsenseqa :  48%|████████████████▏                 | 30/63 [52:05<59:25, 108.06s/it]Evaluating commonsenseqa :  49%|████████████████▋                 | 31/63 [53:48<56:45, 106.43s/it]Evaluating commonsenseqa :  51%|█████████████████▎                | 32/63 [55:40<55:51, 108.11s/it]Evaluating commonsenseqa :  52%|██████████████████▎                | 33/63 [56:35<46:03, 92.11s/it]Evaluating commonsenseqa :  54%|██████████████████▉                | 34/63 [58:28<47:36, 98.49s/it]Evaluating commonsenseqa :  56%|█████████████████▊              | 35/63 [1:00:20<47:55, 102.71s/it]Evaluating commonsenseqa :  57%|██████████████████▎             | 36/63 [1:02:11<47:16, 105.05s/it]Evaluating commonsenseqa :  59%|██████████████████▊             | 37/63 [1:04:04<46:31, 107.37s/it]Evaluating commonsenseqa :  60%|███████████████████▎            | 38/63 [1:05:54<45:06, 108.26s/it]Evaluating commonsenseqa :  62%|███████████████████▊            | 39/63 [1:07:47<43:52, 109.71s/it]Evaluating commonsenseqa :  63%|████████████████████▎           | 40/63 [1:09:41<42:32, 110.99s/it]Evaluating commonsenseqa :  65%|████████████████████▊           | 41/63 [1:11:12<38:28, 104.95s/it]Evaluating commonsenseqa :  67%|█████████████████████▎          | 42/63 [1:13:05<37:33, 107.31s/it]Evaluating commonsenseqa :  68%|██████████████████████▌          | 43/63 [1:14:15<32:05, 96.27s/it]Evaluating commonsenseqa :  70%|██████████████████████▎         | 44/63 [1:16:07<31:54, 100.77s/it]Evaluating commonsenseqa :  71%|██████████████████████▊         | 45/63 [1:18:00<31:19, 104.41s/it]Evaluating commonsenseqa :  73%|████████████████████████         | 46/63 [1:19:27<28:06, 99.23s/it]Evaluating commonsenseqa :  75%|████████████████████████▌        | 47/63 [1:20:58<25:47, 96.74s/it]Evaluating commonsenseqa :  76%|█████████████████████████▏       | 48/63 [1:22:09<22:15, 89.03s/it]Evaluating commonsenseqa :  78%|█████████████████████████▋       | 49/63 [1:23:56<22:02, 94.44s/it]Evaluating commonsenseqa :  79%|█████████████████████████▍      | 50/63 [1:25:49<21:41, 100.14s/it]Evaluating commonsenseqa :  81%|█████████████████████████▉      | 51/63 [1:27:40<20:41, 103.45s/it]Evaluating commonsenseqa :  83%|██████████████████████████▍     | 52/63 [1:29:32<19:25, 105.99s/it]Evaluating commonsenseqa :  84%|██████████████████████████▉     | 53/63 [1:31:03<16:54, 101.49s/it]Evaluating commonsenseqa :  86%|███████████████████████████▍    | 54/63 [1:32:56<15:43, 104.85s/it]Evaluating commonsenseqa :  87%|████████████████████████████▊    | 55/63 [1:33:47<11:49, 88.73s/it]Evaluating commonsenseqa :  89%|█████████████████████████████▎   | 56/63 [1:35:20<10:29, 89.95s/it]Evaluating commonsenseqa :  90%|█████████████████████████████▊   | 57/63 [1:37:12<09:39, 96.58s/it]Evaluating commonsenseqa :  92%|██████████████████████████████▍  | 58/63 [1:38:46<07:59, 95.89s/it]Evaluating commonsenseqa :  94%|█████████████████████████████▉  | 59/63 [1:40:39<06:44, 101.04s/it]Evaluating commonsenseqa :  95%|██████████████████████████████▍ | 60/63 [1:42:33<05:14, 104.91s/it]Evaluating commonsenseqa :  97%|██████████████████████████████▉ | 61/63 [1:44:26<03:34, 107.35s/it]Evaluating commonsenseqa :  98%|███████████████████████████████▍| 62/63 [1:46:17<01:48, 108.54s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████| 63/63 [1:47:19<00:00, 94.54s/it]Evaluating commonsenseqa : 100%|████████████████████████████████| 63/63 [1:47:19<00:00, 102.22s/it]
name: commonsenseqa | avg. gen lenth: 269.12 | time: 6440.118919610977s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-out-domain 0 --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 4 --data-dir /scratch/ylu130/processed_data/commonsenseqa/in-domain/i3-s1-rFalse --seed 1 --max-prompt-length 4096 --num-in-domain 3
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 06:52:10,356] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 06:52:10,386] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 06:52:10,404] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 06:52:10,405] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/in-domain/i3-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 3
  num_out_domain ............... 0
  out_domain_data_name ......... None
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i3-s1-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                                       | 0/9738 [00:00<?, ?it/s]Loading data: 100%|███████████████████████████████████████| 9738/9738 [00:00<00:00, 1108900.51it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:06<00:06,  6.39s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:06<00:06,  6.82s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.00s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:08<00:00,  3.94s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:08<00:00,  4.31s/it]
Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:08<00:08,  8.64s/it][2023-08-28 06:52:20,246] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:08<00:00,  4.07s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:08<00:00,  4.48s/it]
[2023-08-28 06:52:20,680] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.18s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.60s/it]
[2023-08-28 06:52:20,932] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:10<00:00,  4.67s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:10<00:00,  5.26s/it]
 > number of parameters: 6738415616
[2023-08-28 06:52:22,198] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-28 06:52:22,768] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-28 06:52:22,769] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-28 06:52:22,769] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f58cbfcf4c0>
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-28 06:52:22,770] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-28 06:52:22,771] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-28 06:52:22,771] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-28 06:52:22,771] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-28 06:52:22,771] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-28 06:52:22,771] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-28 06:52:22,771] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-28 06:52:22,771] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-28 06:52:22,771] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-28 06:52:22,771] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-28 06:52:22,771] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-28 06:52:22,771] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-28 06:52:22,771] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-28 06:52:22,771] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-28 06:52:22,771] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-28 06:52:22,771] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-28 06:52:22,771] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-28 06:52:22,771] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-28 06:52:22,771] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-28 06:52:22,771] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-28 06:52:22,771] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-28 06:52:22,771] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-28 06:52:22,771] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-28 06:52:22,771] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-28 06:52:22,771] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-28 06:52:22,771] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-28 06:52:22,771] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-28 06:52:22,771] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-28 06:52:22,771] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-28 06:52:22,771] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-28 06:52:22,771] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                                            | 0/63 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Output: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Output: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Output: A: office

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i3-s1-rFalse-m4096
Evaluating commonsenseqa :   2%|▌                                | 1/63 [01:44<1:47:48, 104.33s/it]Evaluating commonsenseqa :   3%|█                                | 2/63 [03:35<1:50:25, 108.61s/it]Evaluating commonsenseqa :   5%|█▌                               | 3/63 [05:23<1:48:13, 108.23s/it]Evaluating commonsenseqa :   6%|██▏                               | 4/63 [06:20<1:26:38, 88.11s/it]Evaluating commonsenseqa :   8%|██▋                               | 5/63 [08:04<1:30:40, 93.81s/it]Evaluating commonsenseqa :  10%|███▏                              | 6/63 [09:56<1:34:44, 99.72s/it]Evaluating commonsenseqa :  11%|███▊                              | 7/63 [11:08<1:24:37, 90.67s/it]Evaluating commonsenseqa :  13%|████▎                             | 8/63 [12:24<1:18:52, 86.05s/it]Evaluating commonsenseqa :  14%|████▊                             | 9/63 [13:17<1:08:19, 75.91s/it]Evaluating commonsenseqa :  16%|█████▏                           | 10/63 [15:10<1:16:58, 87.15s/it]Evaluating commonsenseqa :  17%|█████▊                           | 11/63 [17:03<1:22:24, 95.08s/it]Evaluating commonsenseqa :  19%|██████▎                          | 12/63 [18:30<1:18:41, 92.57s/it]Evaluating commonsenseqa :  21%|██████▊                          | 13/63 [19:57<1:15:47, 90.95s/it]Evaluating commonsenseqa :  22%|███████▎                         | 14/63 [21:36<1:16:22, 93.52s/it]Evaluating commonsenseqa :  24%|████████▎                          | 15/63 [22:05<59:06, 73.88s/it]Evaluating commonsenseqa :  25%|████████▉                          | 16/63 [22:36<47:53, 61.14s/it]Evaluating commonsenseqa :  27%|█████████▍                         | 17/63 [24:27<58:19, 76.07s/it]Evaluating commonsenseqa :  29%|█████████▍                       | 18/63 [26:16<1:04:29, 86.00s/it]Evaluating commonsenseqa :  30%|█████████▉                       | 19/63 [28:07<1:08:38, 93.61s/it]Evaluating commonsenseqa :  32%|██████████▍                      | 20/63 [29:40<1:06:58, 93.44s/it]Evaluating commonsenseqa :  33%|███████████                      | 21/63 [31:20<1:06:35, 95.14s/it]Evaluating commonsenseqa :  35%|███████████▏                    | 22/63 [33:12<1:08:32, 100.30s/it]Evaluating commonsenseqa :  37%|███████████▋                    | 23/63 [35:05<1:09:21, 104.03s/it]Evaluating commonsenseqa :  38%|████████████▏                   | 24/63 [36:58<1:09:26, 106.85s/it]Evaluating commonsenseqa :  40%|████████████▋                   | 25/63 [38:50<1:08:35, 108.31s/it]Evaluating commonsenseqa :  41%|█████████████▏                  | 26/63 [40:39<1:07:01, 108.68s/it]Evaluating commonsenseqa :  43%|█████████████▋                  | 27/63 [42:28<1:05:13, 108.72s/it]Evaluating commonsenseqa :  44%|██████████████▏                 | 28/63 [44:19<1:03:46, 109.32s/it]Evaluating commonsenseqa :  46%|██████████████▋                 | 29/63 [46:09<1:02:09, 109.68s/it]Evaluating commonsenseqa :  48%|███████████████▏                | 30/63 [48:01<1:00:43, 110.41s/it]Evaluating commonsenseqa :  49%|████████████████▋                 | 31/63 [49:52<58:52, 110.39s/it]Evaluating commonsenseqa :  51%|█████████████████▎                | 32/63 [51:10<52:02, 100.72s/it]Evaluating commonsenseqa :  52%|█████████████████▊                | 33/63 [53:00<51:44, 103.47s/it]Evaluating commonsenseqa :  54%|██████████████████▎               | 34/63 [54:50<50:56, 105.41s/it]Evaluating commonsenseqa :  56%|███████████████████▍               | 35/63 [56:04<44:50, 96.07s/it]Evaluating commonsenseqa :  57%|███████████████████▍              | 36/63 [57:55<45:13, 100.50s/it]Evaluating commonsenseqa :  59%|███████████████████▉              | 37/63 [59:47<45:05, 104.06s/it]Evaluating commonsenseqa :  60%|███████████████████▎            | 38/63 [1:01:39<44:16, 106.26s/it]Evaluating commonsenseqa :  62%|███████████████████▊            | 39/63 [1:03:31<43:10, 107.94s/it]Evaluating commonsenseqa :  63%|████████████████████▎           | 40/63 [1:05:22<41:43, 108.87s/it]Evaluating commonsenseqa :  65%|█████████████████████▍           | 41/63 [1:06:08<33:06, 90.28s/it]Evaluating commonsenseqa :  67%|██████████████████████           | 42/63 [1:06:50<26:31, 75.79s/it]Evaluating commonsenseqa :  68%|██████████████████████▌          | 43/63 [1:08:40<28:35, 85.78s/it]Evaluating commonsenseqa :  70%|███████████████████████          | 44/63 [1:10:32<29:39, 93.68s/it]Evaluating commonsenseqa :  71%|███████████████████████▌         | 45/63 [1:11:58<27:28, 91.60s/it]Evaluating commonsenseqa :  73%|████████████████████████         | 46/63 [1:12:27<20:37, 72.81s/it]Evaluating commonsenseqa :  75%|████████████████████████▌        | 47/63 [1:14:09<21:44, 81.56s/it]Evaluating commonsenseqa :  76%|█████████████████████████▏       | 48/63 [1:15:41<21:09, 84.60s/it]Evaluating commonsenseqa :  78%|█████████████████████████▋       | 49/63 [1:17:31<21:30, 92.17s/it]Evaluating commonsenseqa :  79%|██████████████████████████▏      | 50/63 [1:19:25<21:25, 98.87s/it]Evaluating commonsenseqa :  81%|█████████████████████████▉      | 51/63 [1:21:18<20:37, 103.12s/it]Evaluating commonsenseqa :  83%|██████████████████████████▍     | 52/63 [1:23:11<19:27, 106.10s/it]Evaluating commonsenseqa :  84%|██████████████████████████▉     | 53/63 [1:25:04<17:58, 107.90s/it]Evaluating commonsenseqa :  86%|███████████████████████████▍    | 54/63 [1:26:56<16:22, 109.14s/it]Evaluating commonsenseqa :  87%|████████████████████████████▊    | 55/63 [1:27:29<11:31, 86.42s/it]Evaluating commonsenseqa :  89%|█████████████████████████████▎   | 56/63 [1:29:20<10:56, 93.80s/it]Evaluating commonsenseqa :  90%|█████████████████████████████▊   | 57/63 [1:31:09<09:50, 98.49s/it]Evaluating commonsenseqa :  92%|█████████████████████████████▍  | 58/63 [1:33:00<08:30, 102.09s/it]Evaluating commonsenseqa :  94%|█████████████████████████████▉  | 59/63 [1:34:50<06:58, 104.53s/it]Evaluating commonsenseqa :  95%|██████████████████████████████▍ | 60/63 [1:36:43<05:21, 107.03s/it]Evaluating commonsenseqa :  97%|██████████████████████████████▉ | 61/63 [1:38:34<03:36, 108.33s/it]Evaluating commonsenseqa :  98%|████████████████████████████████▍| 62/63 [1:39:44<01:36, 96.73s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████| 63/63 [1:40:46<00:00, 86.33s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████| 63/63 [1:40:46<00:00, 95.98s/it]
name: commonsenseqa | avg. gen lenth: 245.864 | time: 6046.872441530228s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-out-domain 0 --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 4 --data-dir /scratch/ylu130/processed_data/commonsenseqa/in-domain/i4-s1-rFalse --seed 1 --max-prompt-length 4096 --num-in-domain 4
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 08:35:59,108] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 08:35:59,155] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 08:35:59,157] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 08:35:59,179] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/in-domain/i4-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 4
  num_out_domain ............... 0
  out_domain_data_name ......... None
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i4-s1-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                                       | 0/9737 [00:00<?, ?it/s]Loading data: 100%|███████████████████████████████████████| 9737/9737 [00:00<00:00, 1037731.88it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:06<00:06,  6.63s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:06<00:06,  6.66s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.06s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.12s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:08<00:00,  3.99s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:08<00:00,  4.38s/it]
[2023-08-28 08:36:09,118] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:08<00:00,  3.99s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:08<00:00,  4.39s/it]
 > number of parameters: 6738415616
[2023-08-28 08:36:09,221] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.17s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.61s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.18s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.62s/it]
[2023-08-28 08:36:09,684] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-28 08:36:09,718] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-28 08:36:10,370] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-28 08:36:10,373] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-28 08:36:10,374] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-28 08:36:10,374] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-28 08:36:10,374] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-28 08:36:10,374] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-28 08:36:10,375] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-28 08:36:10,375] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-28 08:36:10,375] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-28 08:36:10,375] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-28 08:36:10,375] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-28 08:36:10,375] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f96a665f520>
[2023-08-28 08:36:10,375] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-28 08:36:10,376] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-28 08:36:10,376] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-28 08:36:10,376] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-28 08:36:10,376] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-28 08:36:10,376] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-28 08:36:10,376] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-28 08:36:10,376] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-28 08:36:10,376] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-28 08:36:10,376] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-28 08:36:10,376] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-28 08:36:10,376] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-28 08:36:10,376] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-28 08:36:10,376] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-28 08:36:10,376] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-28 08:36:10,376] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-28 08:36:10,376] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-28 08:36:10,376] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-28 08:36:10,376] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-28 08:36:10,376] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-28 08:36:10,376] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-28 08:36:10,376] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-28 08:36:10,376] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-28 08:36:10,376] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-28 08:36:10,376] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-28 08:36:10,376] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-28 08:36:10,376] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-28 08:36:10,376] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-28 08:36:10,376] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-28 08:36:10,376] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-28 08:36:10,377] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-28 08:36:10,377] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-28 08:36:10,377] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-28 08:36:10,377] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-28 08:36:10,377] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-28 08:36:10,377] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-28 08:36:10,377] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-28 08:36:10,377] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-28 08:36:10,377] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-28 08:36:10,377] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-28 08:36:10,377] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-28 08:36:10,377] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-28 08:36:10,377] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-28 08:36:10,377] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-28 08:36:10,377] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-28 08:36:10,377] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-28 08:36:10,377] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-28 08:36:10,377] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-28 08:36:10,377] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-28 08:36:10,377] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-28 08:36:10,377] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-28 08:36:10,377] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-28 08:36:10,377] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-28 08:36:10,377] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-28 08:36:10,377] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-28 08:36:10,377] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-28 08:36:10,377] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-28 08:36:10,377] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-28 08:36:10,377] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-28 08:36:10,378] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                                            | 0/63 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Output: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Output: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Output: A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Output: B: response

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i4-s1-rFalse-m4096
Evaluating commonsenseqa :   2%|▌                                | 1/63 [01:53<1:56:53, 113.12s/it]Evaluating commonsenseqa :   3%|█                                | 2/63 [03:41<1:52:20, 110.50s/it]Evaluating commonsenseqa :   5%|█▌                               | 3/63 [05:32<1:50:25, 110.43s/it]Evaluating commonsenseqa :   6%|██                               | 4/63 [07:20<1:47:48, 109.64s/it]Evaluating commonsenseqa :   8%|██▌                              | 5/63 [09:10<1:46:10, 109.83s/it]Evaluating commonsenseqa :  10%|███▏                             | 6/63 [11:00<1:44:28, 109.97s/it]Evaluating commonsenseqa :  11%|███▋                             | 7/63 [12:51<1:42:54, 110.26s/it]Evaluating commonsenseqa :  13%|████▏                            | 8/63 [14:45<1:41:55, 111.19s/it]Evaluating commonsenseqa :  14%|████▊                             | 9/63 [15:35<1:23:07, 92.36s/it]Evaluating commonsenseqa :  16%|█████▏                           | 10/63 [17:25<1:26:20, 97.75s/it]Evaluating commonsenseqa :  17%|█████▊                           | 11/63 [19:04<1:24:50, 97.90s/it]Evaluating commonsenseqa :  19%|██████                          | 12/63 [20:54<1:26:22, 101.62s/it]Evaluating commonsenseqa :  21%|██████▊                          | 13/63 [21:46<1:12:17, 86.76s/it]Evaluating commonsenseqa :  22%|███████▎                         | 14/63 [23:35<1:16:12, 93.32s/it]Evaluating commonsenseqa :  24%|███████▊                         | 15/63 [25:24<1:18:27, 98.08s/it]Evaluating commonsenseqa :  25%|████████▏                       | 16/63 [27:12<1:19:08, 101.03s/it]Evaluating commonsenseqa :  27%|████████▋                       | 17/63 [29:02<1:19:31, 103.73s/it]Evaluating commonsenseqa :  29%|█████████▏                      | 18/63 [30:53<1:19:31, 106.02s/it]Evaluating commonsenseqa :  30%|█████████▋                      | 19/63 [32:35<1:16:46, 104.68s/it]Evaluating commonsenseqa :  32%|██████████▍                      | 20/63 [33:47<1:08:06, 95.04s/it]Evaluating commonsenseqa :  33%|███████████                      | 21/63 [35:37<1:09:41, 99.57s/it]Evaluating commonsenseqa :  35%|███████████▏                    | 22/63 [37:29<1:10:27, 103.12s/it]Evaluating commonsenseqa :  37%|███████████▋                    | 23/63 [39:18<1:10:02, 105.06s/it]Evaluating commonsenseqa :  38%|████████████▏                   | 24/63 [41:08<1:09:10, 106.43s/it]Evaluating commonsenseqa :  40%|████████████▋                   | 25/63 [43:00<1:08:31, 108.21s/it]Evaluating commonsenseqa :  41%|█████████████▏                  | 26/63 [44:50<1:06:56, 108.55s/it]Evaluating commonsenseqa :  43%|█████████████▋                  | 27/63 [46:15<1:00:52, 101.45s/it]Evaluating commonsenseqa :  44%|██████████████▏                 | 28/63 [48:03<1:00:24, 103.56s/it]Evaluating commonsenseqa :  46%|███████████████▋                  | 29/63 [49:54<59:55, 105.74s/it]Evaluating commonsenseqa :  48%|████████████████▏                 | 30/63 [51:42<58:29, 106.35s/it]Evaluating commonsenseqa :  49%|████████████████▋                 | 31/63 [53:31<57:12, 107.26s/it]Evaluating commonsenseqa :  51%|█████████████████▎                | 32/63 [55:08<53:47, 104.12s/it]Evaluating commonsenseqa :  52%|█████████████████▊                | 33/63 [56:58<52:57, 105.91s/it]Evaluating commonsenseqa :  54%|██████████████████▉                | 34/63 [57:57<44:27, 91.97s/it]Evaluating commonsenseqa :  56%|███████████████████▍               | 35/63 [59:49<45:44, 98.00s/it]Evaluating commonsenseqa :  57%|██████████████████▎             | 36/63 [1:01:38<45:33, 101.23s/it]Evaluating commonsenseqa :  59%|██████████████████▊             | 37/63 [1:03:29<45:09, 104.20s/it]Evaluating commonsenseqa :  60%|███████████████████▎            | 38/63 [1:05:18<43:59, 105.57s/it]Evaluating commonsenseqa :  62%|███████████████████▊            | 39/63 [1:07:06<42:32, 106.36s/it]Evaluating commonsenseqa :  63%|████████████████████▎           | 40/63 [1:08:55<41:02, 107.06s/it]Evaluating commonsenseqa :  65%|████████████████████▊           | 41/63 [1:10:40<39:04, 106.55s/it]Evaluating commonsenseqa :  67%|██████████████████████           | 42/63 [1:11:42<32:32, 93.00s/it]Evaluating commonsenseqa :  68%|██████████████████████▌          | 43/63 [1:13:33<32:48, 98.45s/it]Evaluating commonsenseqa :  70%|███████████████████████          | 44/63 [1:15:03<30:25, 96.09s/it]Evaluating commonsenseqa :  71%|██████████████████████▊         | 45/63 [1:16:54<30:08, 100.47s/it]Evaluating commonsenseqa :  73%|███████████████████████▎        | 46/63 [1:18:44<29:16, 103.34s/it]Evaluating commonsenseqa :  75%|███████████████████████▊        | 47/63 [1:20:32<27:53, 104.57s/it]Evaluating commonsenseqa :  76%|████████████████████████▍       | 48/63 [1:22:23<26:40, 106.73s/it]Evaluating commonsenseqa :  78%|████████████████████████▉       | 49/63 [1:24:13<25:04, 107.45s/it]Evaluating commonsenseqa :  79%|██████████████████████████▏      | 50/63 [1:25:29<21:15, 98.10s/it]Evaluating commonsenseqa :  81%|██████████████████████████▋      | 51/63 [1:26:14<16:27, 82.29s/it]Evaluating commonsenseqa :  83%|███████████████████████████▏     | 52/63 [1:28:04<16:37, 90.68s/it]Evaluating commonsenseqa :  84%|███████████████████████████▊     | 53/63 [1:29:31<14:53, 89.32s/it]Evaluating commonsenseqa :  86%|████████████████████████████▎    | 54/63 [1:30:48<12:51, 85.67s/it]Evaluating commonsenseqa :  87%|████████████████████████████▊    | 55/63 [1:31:18<09:12, 69.03s/it]Evaluating commonsenseqa :  89%|█████████████████████████████▎   | 56/63 [1:32:29<08:07, 69.58s/it]Evaluating commonsenseqa :  90%|█████████████████████████████▊   | 57/63 [1:34:19<08:10, 81.76s/it]Evaluating commonsenseqa :  92%|██████████████████████████████▍  | 58/63 [1:36:08<07:30, 90.03s/it]Evaluating commonsenseqa :  94%|██████████████████████████████▉  | 59/63 [1:37:59<06:24, 96.13s/it]Evaluating commonsenseqa :  95%|███████████████████████████████▍ | 60/63 [1:39:34<04:47, 95.93s/it]Evaluating commonsenseqa :  97%|███████████████████████████████▉ | 61/63 [1:40:08<02:34, 77.34s/it]Evaluating commonsenseqa :  98%|████████████████████████████████▍| 62/63 [1:41:58<01:27, 87.22s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████| 63/63 [1:42:58<00:00, 78.93s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████| 63/63 [1:42:58<00:00, 98.07s/it]
name: commonsenseqa | avg. gen lenth: 257.712 | time: 6178.7612454891205s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-out-domain 0 --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 4 --data-dir /scratch/ylu130/processed_data/commonsenseqa/in-domain/i5-s1-rFalse --seed 1 --max-prompt-length 4096 --num-in-domain 5
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 10:24:37,603] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 10:24:38,127] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 10:24:38,148] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 10:24:38,210] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/in-domain/i5-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 5
  num_out_domain ............... 0
  out_domain_data_name ......... None
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i5-s1-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                                       | 0/9736 [00:00<?, ?it/s]Loading data: 100%|███████████████████████████████████████| 9736/9736 [00:00<00:00, 1470763.33it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:06<00:06,  6.80s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.12s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.12s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.36s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.11s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.52s/it]
[2023-08-28 10:24:48,386] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.21s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.65s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.28s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.70s/it]
[2023-08-28 10:24:48,783] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
 > number of parameters: 6738415616
[2023-08-28 10:24:48,803] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.30s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.76s/it]
[2023-08-28 10:24:49,043] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-28 10:24:49,659] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-28 10:24:49,660] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-28 10:24:49,660] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-28 10:24:49,660] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-28 10:24:49,660] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-28 10:24:49,660] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fe89a867640>
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-28 10:24:49,661] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-28 10:24:49,662] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-28 10:24:49,662] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-28 10:24:49,662] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-28 10:24:49,662] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-28 10:24:49,662] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-28 10:24:49,662] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-28 10:24:49,662] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-28 10:24:49,662] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-28 10:24:49,662] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-28 10:24:49,662] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-28 10:24:49,662] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-28 10:24:49,662] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-28 10:24:49,662] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-28 10:24:49,662] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-28 10:24:49,662] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-28 10:24:49,662] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-28 10:24:49,662] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-28 10:24:49,662] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                                            | 0/63 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Output: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Output: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Output: A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Output: B: response

Input: The lizard frightened the hiker, it's movements made what rustle? Choices:  A: garden B: trees C: books D: rocks E: bushes
Output: E: bushes

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i5-s1-rFalse-m4096
Evaluating commonsenseqa :   2%|▌                                 | 1/63 [01:28<1:31:41, 88.74s/it]Evaluating commonsenseqa :   3%|█                                 | 2/63 [03:16<1:41:18, 99.65s/it]Evaluating commonsenseqa :   5%|█▌                               | 3/63 [05:02<1:42:47, 102.78s/it]Evaluating commonsenseqa :   6%|██                               | 4/63 [06:52<1:43:50, 105.61s/it]Evaluating commonsenseqa :   8%|██▌                              | 5/63 [08:42<1:43:43, 107.31s/it]Evaluating commonsenseqa :  10%|███▏                             | 6/63 [10:11<1:35:53, 100.94s/it]Evaluating commonsenseqa :  11%|███▊                              | 7/63 [11:39<1:30:13, 96.68s/it]Evaluating commonsenseqa :  13%|████▎                             | 8/63 [12:43<1:19:14, 86.44s/it]Evaluating commonsenseqa :  14%|████▊                             | 9/63 [14:31<1:23:44, 93.05s/it]Evaluating commonsenseqa :  16%|█████▏                           | 10/63 [16:19<1:26:13, 97.61s/it]Evaluating commonsenseqa :  17%|█████▌                          | 11/63 [18:06<1:27:11, 100.60s/it]Evaluating commonsenseqa :  19%|██████                          | 12/63 [19:53<1:27:04, 102.44s/it]Evaluating commonsenseqa :  21%|██████▊                          | 13/63 [20:24<1:07:20, 80.81s/it]Evaluating commonsenseqa :  22%|███████▎                         | 14/63 [22:12<1:12:48, 89.15s/it]Evaluating commonsenseqa :  24%|███████▊                         | 15/63 [24:00<1:15:48, 94.76s/it]Evaluating commonsenseqa :  25%|████████▍                        | 16/63 [24:59<1:05:42, 83.89s/it]Evaluating commonsenseqa :  27%|████████▉                        | 17/63 [26:34<1:07:02, 87.45s/it]Evaluating commonsenseqa :  29%|█████████▍                       | 18/63 [28:25<1:10:44, 94.33s/it]Evaluating commonsenseqa :  30%|██████████▌                        | 19/63 [29:17<59:59, 81.81s/it]Evaluating commonsenseqa :  32%|██████████▍                      | 20/63 [31:04<1:04:04, 89.41s/it]Evaluating commonsenseqa :  33%|███████████                      | 21/63 [32:51<1:06:14, 94.64s/it]Evaluating commonsenseqa :  35%|███████████▌                     | 22/63 [34:40<1:07:33, 98.86s/it]Evaluating commonsenseqa :  37%|███████████▋                    | 23/63 [36:27<1:07:37, 101.43s/it]Evaluating commonsenseqa :  38%|████████████▏                   | 24/63 [38:14<1:06:58, 103.03s/it]Evaluating commonsenseqa :  40%|████████████▋                   | 25/63 [40:02<1:06:12, 104.53s/it]Evaluating commonsenseqa :  41%|█████████████▏                  | 26/63 [41:49<1:04:57, 105.32s/it]Evaluating commonsenseqa :  43%|███████████████                    | 27/63 [42:35<52:27, 87.44s/it]Evaluating commonsenseqa :  44%|███████████████▌                   | 28/63 [44:02<50:59, 87.42s/it]Evaluating commonsenseqa :  46%|████████████████                   | 29/63 [45:51<53:07, 93.75s/it]Evaluating commonsenseqa :  48%|████████████████▋                  | 30/63 [47:39<53:51, 97.93s/it]Evaluating commonsenseqa :  49%|████████████████▋                 | 31/63 [49:29<54:09, 101.55s/it]Evaluating commonsenseqa :  51%|█████████████████▎                | 32/63 [51:17<53:27, 103.46s/it]Evaluating commonsenseqa :  52%|█████████████████▊                | 33/63 [53:05<52:29, 104.98s/it]Evaluating commonsenseqa :  54%|██████████████████▉                | 34/63 [54:14<45:33, 94.27s/it]Evaluating commonsenseqa :  56%|███████████████████▍               | 35/63 [56:02<45:52, 98.32s/it]Evaluating commonsenseqa :  57%|███████████████████▍              | 36/63 [57:49<45:27, 101.02s/it]Evaluating commonsenseqa :  59%|███████████████████▉              | 37/63 [59:38<44:41, 103.14s/it]Evaluating commonsenseqa :  60%|███████████████████▎            | 38/63 [1:01:27<43:48, 105.14s/it]Evaluating commonsenseqa :  62%|███████████████████▊            | 39/63 [1:03:14<42:15, 105.64s/it]Evaluating commonsenseqa :  63%|████████████████████▉            | 40/63 [1:04:09<34:37, 90.33s/it]Evaluating commonsenseqa :  65%|█████████████████████▍           | 41/63 [1:05:16<30:32, 83.29s/it]Evaluating commonsenseqa :  67%|██████████████████████           | 42/63 [1:07:05<31:50, 90.98s/it]Evaluating commonsenseqa :  68%|██████████████████████▌          | 43/63 [1:08:08<27:37, 82.85s/it]Evaluating commonsenseqa :  70%|███████████████████████          | 44/63 [1:09:56<28:35, 90.29s/it]Evaluating commonsenseqa :  71%|███████████████████████▌         | 45/63 [1:11:43<28:36, 95.36s/it]Evaluating commonsenseqa :  73%|████████████████████████         | 46/63 [1:13:30<27:58, 98.73s/it]Evaluating commonsenseqa :  75%|███████████████████████▊        | 47/63 [1:15:17<26:58, 101.17s/it]Evaluating commonsenseqa :  76%|████████████████████████▍       | 48/63 [1:17:07<25:56, 103.80s/it]Evaluating commonsenseqa :  78%|████████████████████████▉       | 49/63 [1:18:54<24:29, 104.99s/it]Evaluating commonsenseqa :  79%|█████████████████████████▍      | 50/63 [1:20:43<22:59, 106.08s/it]Evaluating commonsenseqa :  81%|█████████████████████████▉      | 51/63 [1:22:29<21:13, 106.10s/it]Evaluating commonsenseqa :  83%|██████████████████████████▍     | 52/63 [1:24:18<19:35, 106.89s/it]Evaluating commonsenseqa :  84%|███████████████████████████▊     | 53/63 [1:25:10<15:04, 90.42s/it]Evaluating commonsenseqa :  86%|████████████████████████████▎    | 54/63 [1:26:56<14:15, 95.06s/it]Evaluating commonsenseqa :  87%|████████████████████████████▊    | 55/63 [1:28:41<13:05, 98.13s/it]Evaluating commonsenseqa :  89%|████████████████████████████▍   | 56/63 [1:30:29<11:46, 100.99s/it]Evaluating commonsenseqa :  90%|████████████████████████████▉   | 57/63 [1:32:15<10:15, 102.61s/it]Evaluating commonsenseqa :  92%|█████████████████████████████▍  | 58/63 [1:34:04<08:41, 104.34s/it]Evaluating commonsenseqa :  94%|█████████████████████████████▉  | 59/63 [1:35:51<07:01, 105.25s/it]Evaluating commonsenseqa :  95%|███████████████████████████████▍ | 60/63 [1:37:07<04:49, 96.49s/it]Evaluating commonsenseqa :  97%|██████████████████████████████▉ | 61/63 [1:38:55<03:20, 100.10s/it]Evaluating commonsenseqa :  98%|███████████████████████████████▍| 62/63 [1:40:42<01:41, 101.91s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████| 63/63 [1:41:41<00:00, 89.02s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████| 63/63 [1:41:41<00:00, 96.84s/it]
name: commonsenseqa | avg. gen lenth: 296.544 | time: 6101.368772029877s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-out-domain 0 --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 4 --data-dir /scratch/ylu130/processed_data/commonsenseqa/in-domain/i6-s1-rFalse --seed 1 --max-prompt-length 4096 --num-in-domain 6
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 12:09:31,541] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-28 12:09:31,972] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 12:09:32,060] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 12:09:32,080] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/in-domain/i6-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 6
  num_out_domain ............... 0
  out_domain_data_name ......... None
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i6-s1-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                                       | 0/9735 [00:00<?, ?it/s]Loading data: 100%|████████████████████████████████████████| 9735/9735 [00:00<00:00, 935752.25it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                             | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:06<00:06,  6.75s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:06<00:06,  6.87s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.13s/it]Loading checkpoint shards:  50%|██████████████████▌                  | 1/2 [00:07<00:07,  7.18s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:08<00:00,  4.04s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:08<00:00,  4.45s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:08<00:00,  4.02s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:08<00:00,  4.45s/it]
[2023-08-28 12:09:42,189] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
 > number of parameters: 6738415616
[2023-08-28 12:09:42,251] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.18s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.63s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.19s/it]Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [00:09<00:00,  4.64s/it]
[2023-08-28 12:09:42,541] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-28 12:09:42,622] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-28 12:09:43,210] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-28 12:09:43,212] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-28 12:09:43,212] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-28 12:09:43,212] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-28 12:09:43,212] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-28 12:09:43,212] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-28 12:09:43,212] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-28 12:09:43,212] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-28 12:09:43,212] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-28 12:09:43,212] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-28 12:09:43,212] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-28 12:09:43,212] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f44c7b83520>
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-28 12:09:43,213] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-28 12:09:43,214] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-28 12:09:43,214] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-28 12:09:43,214] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-28 12:09:43,214] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-28 12:09:43,214] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-28 12:09:43,214] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-28 12:09:43,214] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-28 12:09:43,214] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-28 12:09:43,214] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-28 12:09:43,214] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                                            | 0/63 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Output: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Output: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Output: A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Output: B: response

Input: The lizard frightened the hiker, it's movements made what rustle? Choices:  A: garden B: trees C: books D: rocks E: bushes
Output: E: bushes

Input: The man spent big money and time maintaining his lawn, it was part of keeping up with the Joneses where? Choices:  A: front yard B: suburbia C: neighborhood D: back yard E: golf course
Output: B: suburbia

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i6-s1-rFalse-m4096
Evaluating commonsenseqa :   2%|▌                                   | 1/63 [00:44<45:47, 44.32s/it]Evaluating commonsenseqa :   3%|█▏                                  | 2/63 [01:45<55:22, 54.46s/it]Evaluating commonsenseqa :   5%|█▌                                | 3/63 [03:32<1:18:18, 78.30s/it]Evaluating commonsenseqa :   6%|██▏                               | 4/63 [05:20<1:28:28, 89.97s/it]Evaluating commonsenseqa :   8%|██▋                               | 5/63 [07:06<1:32:28, 95.67s/it]Evaluating commonsenseqa :  10%|███▏                             | 6/63 [08:55<1:35:23, 100.41s/it]Evaluating commonsenseqa :  11%|███▋                             | 7/63 [10:35<1:33:29, 100.16s/it]Evaluating commonsenseqa :  13%|████▏                            | 8/63 [12:22<1:33:50, 102.37s/it]Evaluating commonsenseqa :  14%|████▋                            | 9/63 [14:10<1:33:39, 104.06s/it]Evaluating commonsenseqa :  16%|█████                           | 10/63 [15:58<1:32:58, 105.26s/it]Evaluating commonsenseqa :  17%|█████▊                           | 11/63 [16:31<1:12:12, 83.32s/it]Evaluating commonsenseqa :  19%|██████▎                          | 12/63 [18:18<1:16:52, 90.44s/it]Evaluating commonsenseqa :  21%|██████▊                          | 13/63 [20:04<1:19:23, 95.27s/it]Evaluating commonsenseqa :  22%|███████▎                         | 14/63 [21:49<1:20:11, 98.20s/it]Evaluating commonsenseqa :  24%|███████▌                        | 15/63 [23:36<1:20:29, 100.62s/it]Evaluating commonsenseqa :  25%|████████▏                       | 16/63 [25:23<1:20:22, 102.60s/it]Evaluating commonsenseqa :  27%|████████▉                        | 17/63 [26:40<1:12:41, 94.82s/it]Evaluating commonsenseqa :  29%|█████████▍                       | 18/63 [28:08<1:09:45, 93.01s/it]Evaluating commonsenseqa :  30%|█████████▉                       | 19/63 [29:55<1:11:17, 97.21s/it]Evaluating commonsenseqa :  32%|██████████▍                      | 20/63 [31:42<1:11:35, 99.90s/it]Evaluating commonsenseqa :  33%|██████████▋                     | 21/63 [33:29<1:11:25, 102.03s/it]Evaluating commonsenseqa :  35%|███████████▏                    | 22/63 [35:17<1:10:59, 103.89s/it]Evaluating commonsenseqa :  37%|███████████▋                    | 23/63 [37:04<1:09:51, 104.79s/it]Evaluating commonsenseqa :  38%|█████████████▎                     | 24/63 [37:51<56:55, 87.59s/it]Evaluating commonsenseqa :  40%|█████████████▉                     | 25/63 [39:36<58:50, 92.90s/it]Evaluating commonsenseqa :  41%|██████████████▍                    | 26/63 [41:22<59:36, 96.67s/it]Evaluating commonsenseqa :  43%|███████████████                    | 27/63 [43:05<59:14, 98.74s/it]Evaluating commonsenseqa :  44%|███████████████                   | 28/63 [44:49<58:28, 100.25s/it]Evaluating commonsenseqa :  46%|███████████████▋                  | 29/63 [46:37<58:05, 102.51s/it]Evaluating commonsenseqa :  48%|████████████████▏                 | 30/63 [48:25<57:20, 104.25s/it]Evaluating commonsenseqa :  49%|████████████████▋                 | 31/63 [50:13<56:12, 105.39s/it]Evaluating commonsenseqa :  51%|█████████████████▎                | 32/63 [52:00<54:40, 105.82s/it]Evaluating commonsenseqa :  52%|█████████████████▊                | 33/63 [53:48<53:08, 106.28s/it]Evaluating commonsenseqa :  54%|██████████████████▎               | 34/63 [55:35<51:28, 106.50s/it]Evaluating commonsenseqa :  56%|██████████████████▉               | 35/63 [57:19<49:22, 105.79s/it]Evaluating commonsenseqa :  57%|███████████████████▍              | 36/63 [59:06<47:46, 106.16s/it]Evaluating commonsenseqa :  59%|██████████████████▊             | 37/63 [1:00:53<46:10, 106.55s/it]Evaluating commonsenseqa :  60%|███████████████████▉             | 38/63 [1:01:54<38:37, 92.71s/it]Evaluating commonsenseqa :  62%|████████████████████▍            | 39/63 [1:03:39<38:35, 96.47s/it]Evaluating commonsenseqa :  63%|████████████████████▎           | 40/63 [1:05:29<38:33, 100.57s/it]Evaluating commonsenseqa :  65%|████████████████████▊           | 41/63 [1:07:21<38:05, 103.90s/it]Evaluating commonsenseqa :  67%|██████████████████████           | 42/63 [1:07:58<29:24, 84.02s/it]Evaluating commonsenseqa :  68%|██████████████████████▌          | 43/63 [1:09:17<27:25, 82.29s/it]Evaluating commonsenseqa :  70%|███████████████████████          | 44/63 [1:11:06<28:37, 90.39s/it]Evaluating commonsenseqa :  71%|███████████████████████▌         | 45/63 [1:12:51<28:28, 94.94s/it]