torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 22:15:06,703] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:15:07,068] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:15:07,088] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:15:07,147] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 2
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 22:15:13,607] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:15:13,607] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-28 22:15:14,048] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:15:14,098] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o3-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 3
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 22:15:20,551] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:15:20,753] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:15:21,031] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:15:21,082] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o4-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 4
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 22:15:27,751] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:15:28,227] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:15:28,229] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:15:28,257] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o5-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 5
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 22:15:34,633] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:15:34,634] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:15:34,685] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-28 22:15:35,168] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 6
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 22:15:41,570] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:15:41,571] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-28 22:15:41,990] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:15:42,072] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o7-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 7
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 22:15:48,552] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:15:48,553] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:15:48,594] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:15:49,058] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 8
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 22:15:55,495] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:15:55,495] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:15:55,495] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:15:55,521] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o9-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 9
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 22:16:02,446] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:16:02,459] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:16:02,506] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-28 22:16:03,026] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o10-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 10
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 22:16:09,745] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:16:09,745] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:16:09,745] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-28 22:16:10,236] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Answers already exist, exiting...
Answers already exist, exiting...Answers already exist, exiting...

Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o11-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 11
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 22:16:17,134] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:16:17,647] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:16:17,647] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:16:17,657] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o12-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 12
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 22:16:24,497] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:16:24,527] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:16:25,035] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:16:25,053] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o13-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 13
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 22:16:31,709] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:16:31,834] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:16:31,834] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:16:31,834] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o14-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 14
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 22:16:38,793] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:16:38,798] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:16:38,877] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-28 22:16:39,372] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o15-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 15
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 22:16:45,687] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:16:45,717] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:16:45,775] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-28 22:16:46,244] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o16-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 16
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 22:16:52,592] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:16:52,686] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:16:52,754] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-28 22:16:53,243] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o17-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 17
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 22:16:59,751] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:16:59,751] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:16:59,855] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:17:00,263] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o18-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 18
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 22:17:06,632] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:17:06,632] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:17:06,645] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-28 22:17:07,144] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o19-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 19
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 22:17:13,613] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:17:13,615] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:17:13,660] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-28 22:17:14,121] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o20-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 20
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 22:17:20,536] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:17:20,545] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:17:20,548] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:17:20,550] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o21-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 21
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 22:17:27,435] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:17:27,436] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:17:27,436] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 22:17:27,438] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o21-tgsm8k-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 21
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o21-tgsm8k-s1-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                                        | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████████████████████████| 9741/9741 [00:00<00:00, 358829.76it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.36s/it]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.41s/it]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:08<00:08,  8.60s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.22s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.69s/it]
[2023-08-28 22:17:38,341] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.32s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.78s/it]
[2023-08-28 22:17:38,569] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:10<00:10, 10.81s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:10<00:00,  4.89s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:10<00:00,  5.45s/it]
 > number of parameters: 6738415616
[2023-08-28 22:17:39,902] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:13<00:00,  5.81s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:13<00:00,  6.56s/it]
[2023-08-28 22:17:42,142] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-28 22:17:42,727] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-28 22:17:42,728] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-28 22:17:42,728] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f18382710f0>
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-28 22:17:42,729] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-28 22:17:42,730] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-28 22:17:42,730] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                                             | 0/63 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: 6

Input: Mark has kangaroos and goats.  Kangaroos have two legs and goats have four legs.  If he has 23 kangaroos and three times as many goats as kangaroos what is the total number of legs of all his animals?
Output: 322

Input: Josh’s mom gives him $20 to go shopping at the mall. He buys a hat for $10 and a pencil for $2. Then he buys four cookies. If each cookie costs $1.25, how much money does Josh have left?
Output: 3

Input: George's bowling team is one round away from breaking the league record for most points scored in a season. The old record is an average score per player of 287 per round. Each team has 4 players and there are 10 rounds in the season. Through the first 9 rounds, his team has scored a total of 10,440. How many points less than the current league record per game average is the minimum average they need to score, per player, in the final round to tie the league record?
Output: 27

Input: Max was doing homework in three different subjects. It took him 20 minutes to finish tasks from biology and two times more time to finish history. Geography took him the most time, three times more than history. How much time did Max spend on doing his homework?
Output: 180

Input: Sophia ate 1/6 of her pie and she put the rest on the fridge. If the pie left in the fridge weighs 1200 grams, how many grams did Sophia eat?
Output: 240

Input: Sarah, Mary, and Tuan decided to go to the restaurant for a meal. They decided to split the cost of the meal evenly. If the total price of the meal comes to $67 and they have a coupon for $4, how much does each person need to contribute to the bill?
Output: 21

Input: Tom's brother is 4 times as old as Tom's dog. If in 6 years, Tom's brother will be 30 years, how old is Tom's dog going to be in six years?
Output: 12

Input: There are 50 children at the party. Three-fifths of them are boys. How many of the children are girls?
Output: 20

Input: Gail has some bills in her wallet which amount to $100. She has four $5 bills and three $20 bills, and the rest are $10 bills. How many $10 bills are in her wallet?
Output: 2

Input: A 220-liter barrel has a small leak. It lost 10% of its contents before anyone noticed. How many liters are left in the barrel?
Output: 198

Input: Markese earned 5 fewer dollars than Evan. Together they earned $37. How many dollars did Markese earn? Use E to represent how many dollars Evan earned.
Output: 16

Input: Lou Senior took 3 cookies out of the cookie jar and ate them.  Since he didn't get caught by his wife, he went back the next day and took another 3 cookies out of the jar.  But after eating just one of the cookies, he felt guilty about it and put the other two cookies back.  His son, Louie Junior saw that his Dad was eating cookies.  So, Louie Junior took seven cookies out of the jar and hid them in his bedroom for later.  The next morning, Debra, Lou's wife looked into the cookie jar and reacted by accusing her husband of eating half of the cookies out of the cookie jar.  How many cookies remained in the jar?
Output: 11

Input: John had $200. He gave 3/8 of his money to his mother and 3/10 to his father. How much money did John have left?
Output: 65

Input: Tonya has $150.00 on her credit card.  If she leaves any balance on her card at the end of the month, she is charged 20% interest.  If she makes a $50.00 payment on her card, what will be the new balance?
Output: 120

Input: In her first term, Governor Sandoval gave twice as many commencement addresses as Governor Hawkins. Governor Sloan gave ten more commencement addresses than Governor Sandoval in the same amount of time. If Governor Sandoval gave 12 commencement addresses, how many commencement addresses did the three of them give altogether?
Output: 40

Input: If Buzz bought a pizza with 78 slices at a restaurant and then decided to share it with the waiter in the ratio of 5:8, with Buzz's ratio being 5, what's twenty less the number of slices of pizza that the waiter ate?
Output: 28

Input: Jolene and Phil have four children, each with the same birthday.  They gave birth to their first child exactly 15 years ago.  They gave birth to their second child exactly one year after the birth of their first child.  They gave birth to their third child on the fourth birthday of their second child. Two years after the birth of their third child, they gave birth to their fourth child.  How old, in years, is their fourth child?
Output: 8

Input: Each purple book has 230 pages. Each orange book contains 510 pages. Mirella read 5 purple books and 4 orange books. How many more orange pages did she read than purple pages?
Output: 890

Input: Isabella has $45 more than Sam but only $15 more than Giselle. If Giselle has $120, calculate the total amount of money each shopper will receive if Isabella, Sam, and Giselle donate the money to three shoppers at their local town's supermarket who then decides to share it equally.
Output: 115

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o21-tgsm8k-s1-rFalse-m4096
Evaluating commonsenseqa :   2%|▌                                  | 1/63 [01:14<1:16:35, 74.12s/it]Evaluating commonsenseqa :   3%|█                                  | 2/63 [02:26<1:14:19, 73.11s/it]Evaluating commonsenseqa :   5%|█▋                                 | 3/63 [03:39<1:12:52, 72.88s/it]Evaluating commonsenseqa :   6%|██▏                                | 4/63 [04:53<1:12:12, 73.43s/it]Evaluating commonsenseqa :   8%|██▊                                | 5/63 [06:05<1:10:36, 73.05s/it]Evaluating commonsenseqa :  10%|███▎                               | 6/63 [07:18<1:09:24, 73.05s/it]Evaluating commonsenseqa :  11%|███▉                               | 7/63 [08:31<1:08:02, 72.91s/it]Evaluating commonsenseqa :  13%|████▍                              | 8/63 [09:46<1:07:20, 73.46s/it]Evaluating commonsenseqa :  14%|█████                              | 9/63 [10:59<1:06:09, 73.51s/it]Evaluating commonsenseqa :  16%|█████▍                            | 10/63 [12:13<1:05:07, 73.73s/it]Evaluating commonsenseqa :  17%|█████▉                            | 11/63 [13:27<1:03:59, 73.83s/it]Evaluating commonsenseqa :  19%|██████▍                           | 12/63 [14:40<1:02:18, 73.31s/it]Evaluating commonsenseqa :  21%|███████                           | 13/63 [15:54<1:01:21, 73.63s/it]Evaluating commonsenseqa :  22%|████████                            | 14/63 [17:06<59:45, 73.18s/it]Evaluating commonsenseqa :  24%|████████▌                           | 15/63 [18:18<58:16, 72.85s/it]Evaluating commonsenseqa :  25%|█████████▏                          | 16/63 [19:16<53:34, 68.40s/it]Evaluating commonsenseqa :  27%|█████████▋                          | 17/63 [20:06<48:11, 62.87s/it]Evaluating commonsenseqa :  29%|██████████▎                         | 18/63 [21:19<49:27, 65.95s/it]Evaluating commonsenseqa :  30%|██████████▊                         | 19/63 [22:33<50:04, 68.28s/it]Evaluating commonsenseqa :  32%|███████████▍                        | 20/63 [23:46<49:58, 69.72s/it]Evaluating commonsenseqa :  33%|████████████                        | 21/63 [25:00<49:41, 70.99s/it]Evaluating commonsenseqa :  35%|████████████▌                       | 22/63 [26:12<48:41, 71.25s/it]Evaluating commonsenseqa :  37%|█████████████▏                      | 23/63 [27:25<47:47, 71.69s/it]Evaluating commonsenseqa :  38%|█████████████▋                      | 24/63 [28:38<46:54, 72.16s/it]Evaluating commonsenseqa :  40%|██████████████▎                     | 25/63 [29:50<45:44, 72.22s/it]Evaluating commonsenseqa :  41%|██████████████▊                     | 26/63 [30:48<41:52, 67.91s/it]Evaluating commonsenseqa :  43%|███████████████▍                    | 27/63 [32:02<41:46, 69.62s/it]Evaluating commonsenseqa :  44%|████████████████                    | 28/63 [33:15<41:16, 70.77s/it]Evaluating commonsenseqa :  46%|████████████████▌                   | 29/63 [34:29<40:41, 71.80s/it]Evaluating commonsenseqa :  48%|█████████████████▏                  | 30/63 [35:41<39:30, 71.85s/it]Evaluating commonsenseqa :  49%|█████████████████▋                  | 31/63 [36:30<34:40, 65.00s/it]Evaluating commonsenseqa :  51%|██████████████████▎                 | 32/63 [37:44<34:55, 67.61s/it]Evaluating commonsenseqa :  52%|██████████████████▊                 | 33/63 [39:00<35:04, 70.15s/it]Evaluating commonsenseqa :  54%|███████████████████▍                | 34/63 [40:15<34:32, 71.45s/it]Evaluating commonsenseqa :  56%|████████████████████                | 35/63 [41:28<33:36, 72.03s/it]Evaluating commonsenseqa :  57%|████████████████████▌               | 36/63 [42:41<32:35, 72.43s/it]Evaluating commonsenseqa :  59%|█████████████████████▏              | 37/63 [43:04<24:53, 57.42s/it]Evaluating commonsenseqa :  60%|█████████████████████▋              | 38/63 [44:18<25:58, 62.34s/it]Evaluating commonsenseqa :  62%|██████████████████████▎             | 39/63 [45:31<26:15, 65.65s/it]Evaluating commonsenseqa :  63%|██████████████████████▊             | 40/63 [46:36<25:04, 65.41s/it]Evaluating commonsenseqa :  65%|███████████████████████▍            | 41/63 [47:49<24:50, 67.75s/it]Evaluating commonsenseqa :  67%|████████████████████████            | 42/63 [49:03<24:21, 69.60s/it]Evaluating commonsenseqa :  68%|████████████████████████▌           | 43/63 [50:17<23:38, 70.92s/it]Evaluating commonsenseqa :  70%|█████████████████████████▏          | 44/63 [51:30<22:40, 71.59s/it]Evaluating commonsenseqa :  71%|█████████████████████████▋          | 45/63 [52:43<21:37, 72.06s/it]Evaluating commonsenseqa :  73%|██████████████████████████▎         | 46/63 [53:57<20:31, 72.45s/it]Evaluating commonsenseqa :  75%|██████████████████████████▊         | 47/63 [55:12<19:30, 73.18s/it]Evaluating commonsenseqa :  76%|███████████████████████████▍        | 48/63 [55:38<14:47, 59.14s/it]Evaluating commonsenseqa :  78%|████████████████████████████        | 49/63 [56:52<14:49, 63.54s/it]Evaluating commonsenseqa :  79%|████████████████████████████▌       | 50/63 [58:03<14:15, 65.82s/it]Evaluating commonsenseqa :  81%|█████████████████████████████▏      | 51/63 [59:15<13:32, 67.70s/it]Evaluating commonsenseqa :  83%|████████████████████████████      | 52/63 [1:00:27<12:39, 69.02s/it]Evaluating commonsenseqa :  84%|████████████████████████████▌     | 53/63 [1:01:39<11:39, 69.92s/it]Evaluating commonsenseqa :  86%|█████████████████████████████▏    | 54/63 [1:02:53<10:39, 71.07s/it]Evaluating commonsenseqa :  87%|█████████████████████████████▋    | 55/63 [1:04:05<09:30, 71.29s/it]Evaluating commonsenseqa :  89%|██████████████████████████████▏   | 56/63 [1:04:25<06:32, 56.14s/it]Evaluating commonsenseqa :  90%|██████████████████████████████▊   | 57/63 [1:05:40<06:09, 61.53s/it]Evaluating commonsenseqa :  92%|███████████████████████████████▎  | 58/63 [1:06:55<05:28, 65.66s/it]Evaluating commonsenseqa :  94%|███████████████████████████████▊  | 59/63 [1:08:07<04:30, 67.53s/it]Evaluating commonsenseqa :  95%|████████████████████████████████▍ | 60/63 [1:09:20<03:27, 69.33s/it]Evaluating commonsenseqa :  97%|████████████████████████████████▉ | 61/63 [1:10:35<02:21, 70.89s/it]Evaluating commonsenseqa :  98%|█████████████████████████████████▍| 62/63 [1:11:48<01:11, 71.69s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████| 63/63 [1:12:31<00:00, 63.04s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████| 63/63 [1:12:31<00:00, 69.08s/it]
name: commonsenseqa | avg. gen lenth: 324.424 | time: 4352.172687768936s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o22-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 22
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 23:32:44,739] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 23:32:44,773] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 23:32:44,806] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 23:32:44,830] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o22-tgsm8k-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 22
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o22-tgsm8k-s1-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                                        | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████████████████████████| 9741/9741 [00:00<00:00, 389861.59it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:06<00:06,  6.51s/it]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.22s/it]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.27s/it]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.27s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:08<00:00,  3.94s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:08<00:00,  4.33s/it]
 > number of parameters: 6738415616
[2023-08-28 23:32:54,938] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.20s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.66s/it]
Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.21s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.66s/it]
Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.20s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.66s/it]
[2023-08-28 23:32:55,533] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-28 23:32:55,536] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-28 23:32:55,617] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-28 23:32:56,278] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-28 23:32:56,280] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-28 23:32:56,280] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-28 23:32:56,280] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-28 23:32:56,280] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-28 23:32:56,280] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-28 23:32:56,281] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-28 23:32:56,281] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-28 23:32:56,281] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-28 23:32:56,281] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-28 23:32:56,281] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-28 23:32:56,281] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fd537a4f610>
[2023-08-28 23:32:56,281] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-28 23:32:56,281] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-28 23:32:56,281] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-28 23:32:56,281] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-28 23:32:56,281] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-28 23:32:56,281] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-28 23:32:56,281] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-28 23:32:56,281] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-28 23:32:56,281] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-28 23:32:56,281] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-28 23:32:56,281] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-28 23:32:56,281] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-28 23:32:56,281] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-28 23:32:56,281] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-28 23:32:56,281] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-28 23:32:56,281] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-28 23:32:56,281] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-28 23:32:56,281] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-28 23:32:56,281] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-28 23:32:56,281] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-28 23:32:56,281] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-28 23:32:56,281] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-28 23:32:56,281] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-28 23:32:56,282] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-28 23:32:56,283] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-28 23:32:56,283] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                                             | 0/63 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: 6

Input: Mark has kangaroos and goats.  Kangaroos have two legs and goats have four legs.  If he has 23 kangaroos and three times as many goats as kangaroos what is the total number of legs of all his animals?
Output: 322

Input: Josh’s mom gives him $20 to go shopping at the mall. He buys a hat for $10 and a pencil for $2. Then he buys four cookies. If each cookie costs $1.25, how much money does Josh have left?
Output: 3

Input: George's bowling team is one round away from breaking the league record for most points scored in a season. The old record is an average score per player of 287 per round. Each team has 4 players and there are 10 rounds in the season. Through the first 9 rounds, his team has scored a total of 10,440. How many points less than the current league record per game average is the minimum average they need to score, per player, in the final round to tie the league record?
Output: 27

Input: Max was doing homework in three different subjects. It took him 20 minutes to finish tasks from biology and two times more time to finish history. Geography took him the most time, three times more than history. How much time did Max spend on doing his homework?
Output: 180

Input: Sophia ate 1/6 of her pie and she put the rest on the fridge. If the pie left in the fridge weighs 1200 grams, how many grams did Sophia eat?
Output: 240

Input: Sarah, Mary, and Tuan decided to go to the restaurant for a meal. They decided to split the cost of the meal evenly. If the total price of the meal comes to $67 and they have a coupon for $4, how much does each person need to contribute to the bill?
Output: 21

Input: Tom's brother is 4 times as old as Tom's dog. If in 6 years, Tom's brother will be 30 years, how old is Tom's dog going to be in six years?
Output: 12

Input: There are 50 children at the party. Three-fifths of them are boys. How many of the children are girls?
Output: 20

Input: Gail has some bills in her wallet which amount to $100. She has four $5 bills and three $20 bills, and the rest are $10 bills. How many $10 bills are in her wallet?
Output: 2

Input: A 220-liter barrel has a small leak. It lost 10% of its contents before anyone noticed. How many liters are left in the barrel?
Output: 198

Input: Markese earned 5 fewer dollars than Evan. Together they earned $37. How many dollars did Markese earn? Use E to represent how many dollars Evan earned.
Output: 16

Input: Lou Senior took 3 cookies out of the cookie jar and ate them.  Since he didn't get caught by his wife, he went back the next day and took another 3 cookies out of the jar.  But after eating just one of the cookies, he felt guilty about it and put the other two cookies back.  His son, Louie Junior saw that his Dad was eating cookies.  So, Louie Junior took seven cookies out of the jar and hid them in his bedroom for later.  The next morning, Debra, Lou's wife looked into the cookie jar and reacted by accusing her husband of eating half of the cookies out of the cookie jar.  How many cookies remained in the jar?
Output: 11

Input: John had $200. He gave 3/8 of his money to his mother and 3/10 to his father. How much money did John have left?
Output: 65

Input: Tonya has $150.00 on her credit card.  If she leaves any balance on her card at the end of the month, she is charged 20% interest.  If she makes a $50.00 payment on her card, what will be the new balance?
Output: 120

Input: In her first term, Governor Sandoval gave twice as many commencement addresses as Governor Hawkins. Governor Sloan gave ten more commencement addresses than Governor Sandoval in the same amount of time. If Governor Sandoval gave 12 commencement addresses, how many commencement addresses did the three of them give altogether?
Output: 40

Input: If Buzz bought a pizza with 78 slices at a restaurant and then decided to share it with the waiter in the ratio of 5:8, with Buzz's ratio being 5, what's twenty less the number of slices of pizza that the waiter ate?
Output: 28

Input: Jolene and Phil have four children, each with the same birthday.  They gave birth to their first child exactly 15 years ago.  They gave birth to their second child exactly one year after the birth of their first child.  They gave birth to their third child on the fourth birthday of their second child. Two years after the birth of their third child, they gave birth to their fourth child.  How old, in years, is their fourth child?
Output: 8

Input: Each purple book has 230 pages. Each orange book contains 510 pages. Mirella read 5 purple books and 4 orange books. How many more orange pages did she read than purple pages?
Output: 890

Input: Isabella has $45 more than Sam but only $15 more than Giselle. If Giselle has $120, calculate the total amount of money each shopper will receive if Isabella, Sam, and Giselle donate the money to three shoppers at their local town's supermarket who then decides to share it equally.
Output: 115

Input: It takes 40 minutes to freeze ice cubes and 3 minutes per smoothie to turn them into smoothies once they're frozen. How long does it take to make 5 smoothies?
Output: 55

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o22-tgsm8k-s1-rFalse-m4096
Evaluating commonsenseqa :   2%|▌                                  | 1/63 [01:13<1:16:03, 73.61s/it]Evaluating commonsenseqa :   3%|█                                  | 2/63 [02:26<1:14:09, 72.93s/it]Evaluating commonsenseqa :   5%|█▋                                 | 3/63 [03:29<1:08:43, 68.72s/it]Evaluating commonsenseqa :   6%|██▏                                | 4/63 [04:44<1:09:44, 70.92s/it]Evaluating commonsenseqa :   8%|██▊                                | 5/63 [05:55<1:08:44, 71.12s/it]Evaluating commonsenseqa :  10%|███▎                               | 6/63 [07:07<1:07:58, 71.56s/it]Evaluating commonsenseqa :  11%|███▉                               | 7/63 [08:20<1:07:07, 71.91s/it]Evaluating commonsenseqa :  13%|████▍                              | 8/63 [09:26<1:04:03, 69.88s/it]Evaluating commonsenseqa :  14%|█████                              | 9/63 [10:37<1:03:11, 70.21s/it]Evaluating commonsenseqa :  16%|█████▍                            | 10/63 [11:48<1:02:19, 70.56s/it]Evaluating commonsenseqa :  17%|█████▉                            | 11/63 [12:59<1:01:25, 70.87s/it]Evaluating commonsenseqa :  19%|██████▍                           | 12/63 [14:11<1:00:19, 70.97s/it]Evaluating commonsenseqa :  21%|███████▍                            | 13/63 [14:58<53:16, 63.93s/it]Evaluating commonsenseqa :  22%|████████                            | 14/63 [16:10<54:12, 66.37s/it]Evaluating commonsenseqa :  24%|████████▌                           | 15/63 [17:23<54:35, 68.25s/it]Evaluating commonsenseqa :  25%|█████████▏                          | 16/63 [18:35<54:20, 69.37s/it]Evaluating commonsenseqa :  27%|█████████▋                          | 17/63 [19:48<53:54, 70.31s/it]Evaluating commonsenseqa :  29%|██████████▎                         | 18/63 [20:59<53:04, 70.76s/it]Evaluating commonsenseqa :  30%|██████████▊                         | 19/63 [21:35<44:08, 60.20s/it]Evaluating commonsenseqa :  32%|███████████▍                        | 20/63 [22:46<45:25, 63.38s/it]Evaluating commonsenseqa :  33%|████████████                        | 21/63 [23:56<45:48, 65.45s/it]Evaluating commonsenseqa :  35%|████████████▌                       | 22/63 [25:08<46:00, 67.34s/it]Evaluating commonsenseqa :  37%|█████████████▏                      | 23/63 [26:19<45:44, 68.61s/it]Evaluating commonsenseqa :  38%|█████████████▋                      | 24/63 [27:31<45:06, 69.40s/it]Evaluating commonsenseqa :  40%|██████████████▎                     | 25/63 [28:44<44:40, 70.55s/it]Evaluating commonsenseqa :  41%|██████████████▊                     | 26/63 [29:56<43:44, 70.94s/it]Evaluating commonsenseqa :  43%|███████████████▍                    | 27/63 [31:08<42:47, 71.31s/it]Evaluating commonsenseqa :  44%|████████████████                    | 28/63 [32:19<41:33, 71.25s/it]Evaluating commonsenseqa :  46%|████████████████▌                   | 29/63 [33:31<40:32, 71.54s/it]Evaluating commonsenseqa :  48%|█████████████████▏                  | 30/63 [34:42<39:12, 71.30s/it]Evaluating commonsenseqa :  49%|█████████████████▋                  | 31/63 [35:54<38:10, 71.58s/it]Evaluating commonsenseqa :  51%|██████████████████▎                 | 32/63 [37:06<37:02, 71.68s/it]Evaluating commonsenseqa :  52%|██████████████████▊                 | 33/63 [38:18<35:52, 71.74s/it]Evaluating commonsenseqa :  54%|███████████████████▍                | 34/63 [39:29<34:38, 71.67s/it]Evaluating commonsenseqa :  56%|████████████████████                | 35/63 [40:42<33:38, 72.07s/it]Evaluating commonsenseqa :  57%|████████████████████▌               | 36/63 [41:54<32:21, 71.92s/it]Evaluating commonsenseqa :  59%|█████████████████████▏              | 37/63 [42:49<28:55, 66.76s/it]Evaluating commonsenseqa :  60%|█████████████████████▋              | 38/63 [44:01<28:28, 68.35s/it]Evaluating commonsenseqa :  62%|██████████████████████▎             | 39/63 [45:15<28:00, 70.03s/it]Evaluating commonsenseqa :  63%|██████████████████████▊             | 40/63 [46:28<27:15, 71.11s/it]Evaluating commonsenseqa :  65%|███████████████████████▍            | 41/63 [47:40<26:09, 71.35s/it]Evaluating commonsenseqa :  67%|████████████████████████            | 42/63 [48:53<25:07, 71.79s/it]Evaluating commonsenseqa :  68%|████████████████████████▌           | 43/63 [50:04<23:50, 71.52s/it]Evaluating commonsenseqa :  70%|█████████████████████████▏          | 44/63 [51:17<22:45, 71.86s/it]Evaluating commonsenseqa :  71%|█████████████████████████▋          | 45/63 [52:05<19:25, 64.75s/it]Evaluating commonsenseqa :  73%|██████████████████████████▎         | 46/63 [52:54<17:02, 60.18s/it]Evaluating commonsenseqa :  75%|██████████████████████████▊         | 47/63 [54:08<17:06, 64.19s/it]Evaluating commonsenseqa :  76%|███████████████████████████▍        | 48/63 [55:19<16:32, 66.16s/it]Evaluating commonsenseqa :  78%|████████████████████████████        | 49/63 [56:31<15:52, 68.00s/it]Evaluating commonsenseqa :  79%|████████████████████████████▌       | 50/63 [57:44<15:02, 69.45s/it]Evaluating commonsenseqa :  81%|█████████████████████████████▏      | 51/63 [58:56<14:03, 70.31s/it]Evaluating commonsenseqa :  83%|████████████████████████████      | 52/63 [1:00:07<12:57, 70.64s/it]Evaluating commonsenseqa :  84%|████████████████████████████▌     | 53/63 [1:01:19<11:48, 70.88s/it]Evaluating commonsenseqa :  86%|█████████████████████████████▏    | 54/63 [1:02:32<10:43, 71.50s/it]Evaluating commonsenseqa :  87%|█████████████████████████████▋    | 55/63 [1:03:45<09:35, 71.98s/it]Evaluating commonsenseqa :  89%|██████████████████████████████▏   | 56/63 [1:04:56<08:22, 71.85s/it]Evaluating commonsenseqa :  90%|██████████████████████████████▊   | 57/63 [1:06:08<07:10, 71.83s/it]Evaluating commonsenseqa :  92%|███████████████████████████████▎  | 58/63 [1:07:21<05:59, 71.99s/it]Evaluating commonsenseqa :  94%|███████████████████████████████▊  | 59/63 [1:08:33<04:48, 72.01s/it]Evaluating commonsenseqa :  95%|████████████████████████████████▍ | 60/63 [1:09:45<03:36, 72.16s/it]Evaluating commonsenseqa :  97%|████████████████████████████████▉ | 61/63 [1:10:57<02:24, 72.21s/it]Evaluating commonsenseqa :  98%|█████████████████████████████████▍| 62/63 [1:12:09<01:11, 71.90s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████| 63/63 [1:12:46<00:00, 61.50s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████| 63/63 [1:12:46<00:00, 69.31s/it]
name: commonsenseqa | avg. gen lenth: 341.952 | time: 4366.8374490737915s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o23-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 23
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-29 00:46:36,749] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-29 00:46:36,763] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-29 00:46:36,765] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-29 00:46:36,790] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o23-tgsm8k-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 23
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o23-tgsm8k-s1-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                                        | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████████████████████████| 9741/9741 [00:00<00:00, 383443.91it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.28s/it]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.29s/it]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.28s/it]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.30s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.21s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.67s/it]
Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.24s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.70s/it]
Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.26s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.71s/it]
Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.26s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.72s/it]
 > number of parameters: 6738415616
[2023-08-29 00:46:47,595] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-29 00:46:47,660] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-29 00:46:47,715] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-29 00:46:47,725] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-29 00:46:48,293] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-29 00:46:48,294] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-29 00:46:48,294] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-29 00:46:48,294] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-29 00:46:48,294] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-29 00:46:48,294] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f6e7b87f520>
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-29 00:46:48,295] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-29 00:46:48,296] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-29 00:46:48,296] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-29 00:46:48,296] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-29 00:46:48,296] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-29 00:46:48,296] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-29 00:46:48,296] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-29 00:46:48,296] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-29 00:46:48,296] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-29 00:46:48,296] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-29 00:46:48,296] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-29 00:46:48,296] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-29 00:46:48,296] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-29 00:46:48,296] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-29 00:46:48,296] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-29 00:46:48,296] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-29 00:46:48,296] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-29 00:46:48,296] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-29 00:46:48,296] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-29 00:46:48,296] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-29 00:46:48,296] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-29 00:46:48,296] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                                             | 0/63 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: 6

Input: Mark has kangaroos and goats.  Kangaroos have two legs and goats have four legs.  If he has 23 kangaroos and three times as many goats as kangaroos what is the total number of legs of all his animals?
Output: 322

Input: Josh’s mom gives him $20 to go shopping at the mall. He buys a hat for $10 and a pencil for $2. Then he buys four cookies. If each cookie costs $1.25, how much money does Josh have left?
Output: 3

Input: George's bowling team is one round away from breaking the league record for most points scored in a season. The old record is an average score per player of 287 per round. Each team has 4 players and there are 10 rounds in the season. Through the first 9 rounds, his team has scored a total of 10,440. How many points less than the current league record per game average is the minimum average they need to score, per player, in the final round to tie the league record?
Output: 27

Input: Max was doing homework in three different subjects. It took him 20 minutes to finish tasks from biology and two times more time to finish history. Geography took him the most time, three times more than history. How much time did Max spend on doing his homework?
Output: 180

Input: Sophia ate 1/6 of her pie and she put the rest on the fridge. If the pie left in the fridge weighs 1200 grams, how many grams did Sophia eat?
Output: 240

Input: Sarah, Mary, and Tuan decided to go to the restaurant for a meal. They decided to split the cost of the meal evenly. If the total price of the meal comes to $67 and they have a coupon for $4, how much does each person need to contribute to the bill?
Output: 21

Input: Tom's brother is 4 times as old as Tom's dog. If in 6 years, Tom's brother will be 30 years, how old is Tom's dog going to be in six years?
Output: 12

Input: There are 50 children at the party. Three-fifths of them are boys. How many of the children are girls?
Output: 20

Input: Gail has some bills in her wallet which amount to $100. She has four $5 bills and three $20 bills, and the rest are $10 bills. How many $10 bills are in her wallet?
Output: 2

Input: A 220-liter barrel has a small leak. It lost 10% of its contents before anyone noticed. How many liters are left in the barrel?
Output: 198

Input: Markese earned 5 fewer dollars than Evan. Together they earned $37. How many dollars did Markese earn? Use E to represent how many dollars Evan earned.
Output: 16

Input: Lou Senior took 3 cookies out of the cookie jar and ate them.  Since he didn't get caught by his wife, he went back the next day and took another 3 cookies out of the jar.  But after eating just one of the cookies, he felt guilty about it and put the other two cookies back.  His son, Louie Junior saw that his Dad was eating cookies.  So, Louie Junior took seven cookies out of the jar and hid them in his bedroom for later.  The next morning, Debra, Lou's wife looked into the cookie jar and reacted by accusing her husband of eating half of the cookies out of the cookie jar.  How many cookies remained in the jar?
Output: 11

Input: John had $200. He gave 3/8 of his money to his mother and 3/10 to his father. How much money did John have left?
Output: 65

Input: Tonya has $150.00 on her credit card.  If she leaves any balance on her card at the end of the month, she is charged 20% interest.  If she makes a $50.00 payment on her card, what will be the new balance?
Output: 120

Input: In her first term, Governor Sandoval gave twice as many commencement addresses as Governor Hawkins. Governor Sloan gave ten more commencement addresses than Governor Sandoval in the same amount of time. If Governor Sandoval gave 12 commencement addresses, how many commencement addresses did the three of them give altogether?
Output: 40

Input: If Buzz bought a pizza with 78 slices at a restaurant and then decided to share it with the waiter in the ratio of 5:8, with Buzz's ratio being 5, what's twenty less the number of slices of pizza that the waiter ate?
Output: 28

Input: Jolene and Phil have four children, each with the same birthday.  They gave birth to their first child exactly 15 years ago.  They gave birth to their second child exactly one year after the birth of their first child.  They gave birth to their third child on the fourth birthday of their second child. Two years after the birth of their third child, they gave birth to their fourth child.  How old, in years, is their fourth child?
Output: 8

Input: Each purple book has 230 pages. Each orange book contains 510 pages. Mirella read 5 purple books and 4 orange books. How many more orange pages did she read than purple pages?
Output: 890

Input: Isabella has $45 more than Sam but only $15 more than Giselle. If Giselle has $120, calculate the total amount of money each shopper will receive if Isabella, Sam, and Giselle donate the money to three shoppers at their local town's supermarket who then decides to share it equally.
Output: 115

Input: It takes 40 minutes to freeze ice cubes and 3 minutes per smoothie to turn them into smoothies once they're frozen. How long does it take to make 5 smoothies?
Output: 55

Input: Belle eats 4 dog biscuits and 2 rawhide bones every evening. If each rawhide bone is $1, and each dog biscuit is $0.25, then how much does it cost, in dollars, to feed Belle these treats for a week?
Output: 21

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o23-tgsm8k-s1-rFalse-m4096
Evaluating commonsenseqa :   2%|▌                                  | 1/63 [01:12<1:15:18, 72.88s/it]Evaluating commonsenseqa :   3%|█▏                                   | 2/63 [01:55<56:14, 55.31s/it]Evaluating commonsenseqa :   5%|█▋                                 | 3/63 [03:07<1:02:39, 62.65s/it]Evaluating commonsenseqa :   6%|██▏                                | 4/63 [04:17<1:04:44, 65.83s/it]Evaluating commonsenseqa :   8%|██▊                                | 5/63 [05:25<1:04:22, 66.59s/it]Evaluating commonsenseqa :  10%|███▎                               | 6/63 [06:35<1:04:21, 67.74s/it]Evaluating commonsenseqa :  11%|███▉                               | 7/63 [07:33<1:00:14, 64.55s/it]Evaluating commonsenseqa :  13%|████▍                              | 8/63 [08:45<1:01:19, 66.90s/it]Evaluating commonsenseqa :  14%|█████▎                               | 9/63 [09:39<56:35, 62.87s/it]Evaluating commonsenseqa :  16%|█████▋                              | 10/63 [10:49<57:26, 65.03s/it]Evaluating commonsenseqa :  17%|██████▎                             | 11/63 [11:59<57:35, 66.46s/it]Evaluating commonsenseqa :  19%|██████▊                             | 12/63 [13:09<57:31, 67.68s/it]Evaluating commonsenseqa :  21%|███████▍                            | 13/63 [14:20<57:03, 68.46s/it]Evaluating commonsenseqa :  22%|████████                            | 14/63 [15:30<56:17, 68.92s/it]Evaluating commonsenseqa :  24%|████████▌                           | 15/63 [16:41<55:37, 69.54s/it]Evaluating commonsenseqa :  25%|█████████▏                          | 16/63 [17:51<54:45, 69.90s/it]Evaluating commonsenseqa :  27%|█████████▋                          | 17/63 [19:01<53:37, 69.94s/it]Evaluating commonsenseqa :  29%|██████████▎                         | 18/63 [20:11<52:24, 69.89s/it]Evaluating commonsenseqa :  30%|██████████▊                         | 19/63 [21:22<51:28, 70.20s/it]Evaluating commonsenseqa :  32%|███████████▍                        | 20/63 [22:05<44:31, 62.12s/it]Evaluating commonsenseqa :  33%|████████████                        | 21/63 [23:16<45:20, 64.77s/it]Evaluating commonsenseqa :  35%|████████████▌                       | 22/63 [24:27<45:28, 66.54s/it]Evaluating commonsenseqa :  37%|█████████████▏                      | 23/63 [25:37<45:04, 67.62s/it]Evaluating commonsenseqa :  38%|█████████████▋                      | 24/63 [26:48<44:38, 68.67s/it]Evaluating commonsenseqa :  40%|██████████████▎                     | 25/63 [27:58<43:41, 68.99s/it]Evaluating commonsenseqa :  41%|██████████████▊                     | 26/63 [29:08<42:41, 69.22s/it]Evaluating commonsenseqa :  43%|███████████████▍                    | 27/63 [30:18<41:44, 69.57s/it]Evaluating commonsenseqa :  44%|████████████████                    | 28/63 [31:30<40:57, 70.22s/it]Evaluating commonsenseqa :  46%|████████████████▌                   | 29/63 [32:40<39:43, 70.11s/it]Evaluating commonsenseqa :  48%|█████████████████▏                  | 30/63 [33:50<38:38, 70.25s/it]Evaluating commonsenseqa :  49%|█████████████████▋                  | 31/63 [35:00<37:23, 70.10s/it]Evaluating commonsenseqa :  51%|██████████████████▎                 | 32/63 [36:10<36:16, 70.21s/it]Evaluating commonsenseqa :  52%|██████████████████▊                 | 33/63 [37:22<35:22, 70.74s/it]Evaluating commonsenseqa :  54%|███████████████████▍                | 34/63 [38:33<34:12, 70.77s/it]Evaluating commonsenseqa :  56%|████████████████████                | 35/63 [39:45<33:11, 71.14s/it]Evaluating commonsenseqa :  57%|████████████████████▌               | 36/63 [40:57<32:06, 71.36s/it]Evaluating commonsenseqa :  59%|█████████████████████▏              | 37/63 [42:07<30:41, 70.82s/it]Evaluating commonsenseqa :  60%|█████████████████████▋              | 38/63 [43:18<29:35, 71.01s/it]Evaluating commonsenseqa :  62%|██████████████████████▎             | 39/63 [44:29<28:24, 71.01s/it]Evaluating commonsenseqa :  63%|██████████████████████▊             | 40/63 [45:39<27:04, 70.63s/it]Evaluating commonsenseqa :  65%|███████████████████████▍            | 41/63 [46:50<25:59, 70.87s/it]Evaluating commonsenseqa :  67%|████████████████████████            | 42/63 [48:01<24:49, 70.93s/it]Evaluating commonsenseqa :  68%|████████████████████████▌           | 43/63 [48:53<21:44, 65.24s/it]Evaluating commonsenseqa :  70%|█████████████████████████▏          | 44/63 [50:05<21:14, 67.06s/it]Evaluating commonsenseqa :  71%|█████████████████████████▋          | 45/63 [51:10<19:57, 66.51s/it]Evaluating commonsenseqa :  73%|██████████████████████████▎         | 46/63 [52:21<19:13, 67.86s/it]Evaluating commonsenseqa :  75%|██████████████████████████▊         | 47/63 [53:31<18:15, 68.45s/it]Evaluating commonsenseqa :  76%|███████████████████████████▍        | 48/63 [54:33<16:40, 66.73s/it]Evaluating commonsenseqa :  78%|████████████████████████████        | 49/63 [55:44<15:50, 67.92s/it]Evaluating commonsenseqa :  79%|████████████████████████████▌       | 50/63 [56:58<15:04, 69.61s/it]Evaluating commonsenseqa :  81%|█████████████████████████████▏      | 51/63 [58:08<13:57, 69.82s/it]Evaluating commonsenseqa :  83%|█████████████████████████████▋      | 52/63 [59:19<12:52, 70.27s/it]Evaluating commonsenseqa :  84%|████████████████████████████▌     | 53/63 [1:00:31<11:48, 70.81s/it]Evaluating commonsenseqa :  86%|█████████████████████████████▏    | 54/63 [1:01:42<10:37, 70.78s/it]Evaluating commonsenseqa :  87%|█████████████████████████████▋    | 55/63 [1:02:47<09:11, 68.88s/it]Evaluating commonsenseqa :  89%|██████████████████████████████▏   | 56/63 [1:03:57<08:05, 69.36s/it]Evaluating commonsenseqa :  90%|██████████████████████████████▊   | 57/63 [1:05:09<07:01, 70.26s/it]Evaluating commonsenseqa :  92%|███████████████████████████████▎  | 58/63 [1:06:20<05:52, 70.49s/it]Evaluating commonsenseqa :  94%|███████████████████████████████▊  | 59/63 [1:07:30<04:40, 70.19s/it]Evaluating commonsenseqa :  95%|████████████████████████████████▍ | 60/63 [1:08:15<03:07, 62.53s/it]Evaluating commonsenseqa :  97%|████████████████████████████████▉ | 61/63 [1:09:24<02:09, 64.66s/it]Evaluating commonsenseqa :  98%|█████████████████████████████████▍| 62/63 [1:10:35<01:06, 66.43s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████| 63/63 [1:11:15<00:00, 58.64s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████| 63/63 [1:11:15<00:00, 67.87s/it]
name: commonsenseqa | avg. gen lenth: 342.128 | time: 4276.233566761017s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o24-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 24
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-29 01:58:58,517] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-29 01:58:58,534] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-29 01:58:58,568] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-29 01:58:58,602] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o24-tgsm8k-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 24
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o24-tgsm8k-s1-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                                        | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████████████████████████| 9741/9741 [00:00<00:00, 371431.44it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.28s/it]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.35s/it]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.41s/it]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.86s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.32s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.78s/it]
Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.34s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.79s/it]
 > number of parameters: 6738415616
[2023-08-29 01:59:09,586] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.41s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.84s/it]
[2023-08-29 01:59:09,710] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-29 01:59:09,799] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:10<00:00,  4.52s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:10<00:00,  5.02s/it]
[2023-08-29 01:59:10,028] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-29 01:59:10,608] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-29 01:59:10,610] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-29 01:59:10,611] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-29 01:59:10,611] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-29 01:59:10,611] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-29 01:59:10,611] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-29 01:59:10,611] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-29 01:59:10,611] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-29 01:59:10,611] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-29 01:59:10,611] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-29 01:59:10,611] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-29 01:59:10,611] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fa34b343610>
[2023-08-29 01:59:10,611] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-29 01:59:10,611] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-29 01:59:10,611] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-29 01:59:10,611] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-29 01:59:10,612] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-29 01:59:10,613] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-29 01:59:10,613] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-29 01:59:10,613] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-29 01:59:10,613] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-29 01:59:10,613] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-29 01:59:10,613] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-29 01:59:10,613] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-29 01:59:10,613] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-29 01:59:10,613] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-29 01:59:10,613] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-29 01:59:10,613] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-29 01:59:10,613] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-29 01:59:10,613] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-29 01:59:10,613] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-29 01:59:10,613] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-29 01:59:10,613] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-29 01:59:10,613] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-29 01:59:10,613] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-29 01:59:10,613] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-29 01:59:10,613] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-29 01:59:10,613] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-29 01:59:10,613] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-29 01:59:10,613] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                                             | 0/63 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: 6

Input: Mark has kangaroos and goats.  Kangaroos have two legs and goats have four legs.  If he has 23 kangaroos and three times as many goats as kangaroos what is the total number of legs of all his animals?
Output: 322

Input: Josh’s mom gives him $20 to go shopping at the mall. He buys a hat for $10 and a pencil for $2. Then he buys four cookies. If each cookie costs $1.25, how much money does Josh have left?
Output: 3

Input: George's bowling team is one round away from breaking the league record for most points scored in a season. The old record is an average score per player of 287 per round. Each team has 4 players and there are 10 rounds in the season. Through the first 9 rounds, his team has scored a total of 10,440. How many points less than the current league record per game average is the minimum average they need to score, per player, in the final round to tie the league record?
Output: 27

Input: Max was doing homework in three different subjects. It took him 20 minutes to finish tasks from biology and two times more time to finish history. Geography took him the most time, three times more than history. How much time did Max spend on doing his homework?
Output: 180

Input: Sophia ate 1/6 of her pie and she put the rest on the fridge. If the pie left in the fridge weighs 1200 grams, how many grams did Sophia eat?
Output: 240

Input: Sarah, Mary, and Tuan decided to go to the restaurant for a meal. They decided to split the cost of the meal evenly. If the total price of the meal comes to $67 and they have a coupon for $4, how much does each person need to contribute to the bill?
Output: 21

Input: Tom's brother is 4 times as old as Tom's dog. If in 6 years, Tom's brother will be 30 years, how old is Tom's dog going to be in six years?
Output: 12

Input: There are 50 children at the party. Three-fifths of them are boys. How many of the children are girls?
Output: 20

Input: Gail has some bills in her wallet which amount to $100. She has four $5 bills and three $20 bills, and the rest are $10 bills. How many $10 bills are in her wallet?
Output: 2

Input: A 220-liter barrel has a small leak. It lost 10% of its contents before anyone noticed. How many liters are left in the barrel?
Output: 198

Input: Markese earned 5 fewer dollars than Evan. Together they earned $37. How many dollars did Markese earn? Use E to represent how many dollars Evan earned.
Output: 16

Input: Lou Senior took 3 cookies out of the cookie jar and ate them.  Since he didn't get caught by his wife, he went back the next day and took another 3 cookies out of the jar.  But after eating just one of the cookies, he felt guilty about it and put the other two cookies back.  His son, Louie Junior saw that his Dad was eating cookies.  So, Louie Junior took seven cookies out of the jar and hid them in his bedroom for later.  The next morning, Debra, Lou's wife looked into the cookie jar and reacted by accusing her husband of eating half of the cookies out of the cookie jar.  How many cookies remained in the jar?
Output: 11

Input: John had $200. He gave 3/8 of his money to his mother and 3/10 to his father. How much money did John have left?
Output: 65

Input: Tonya has $150.00 on her credit card.  If she leaves any balance on her card at the end of the month, she is charged 20% interest.  If she makes a $50.00 payment on her card, what will be the new balance?
Output: 120

Input: In her first term, Governor Sandoval gave twice as many commencement addresses as Governor Hawkins. Governor Sloan gave ten more commencement addresses than Governor Sandoval in the same amount of time. If Governor Sandoval gave 12 commencement addresses, how many commencement addresses did the three of them give altogether?
Output: 40

Input: If Buzz bought a pizza with 78 slices at a restaurant and then decided to share it with the waiter in the ratio of 5:8, with Buzz's ratio being 5, what's twenty less the number of slices of pizza that the waiter ate?
Output: 28

Input: Jolene and Phil have four children, each with the same birthday.  They gave birth to their first child exactly 15 years ago.  They gave birth to their second child exactly one year after the birth of their first child.  They gave birth to their third child on the fourth birthday of their second child. Two years after the birth of their third child, they gave birth to their fourth child.  How old, in years, is their fourth child?
Output: 8

Input: Each purple book has 230 pages. Each orange book contains 510 pages. Mirella read 5 purple books and 4 orange books. How many more orange pages did she read than purple pages?
Output: 890

Input: Isabella has $45 more than Sam but only $15 more than Giselle. If Giselle has $120, calculate the total amount of money each shopper will receive if Isabella, Sam, and Giselle donate the money to three shoppers at their local town's supermarket who then decides to share it equally.
Output: 115

Input: It takes 40 minutes to freeze ice cubes and 3 minutes per smoothie to turn them into smoothies once they're frozen. How long does it take to make 5 smoothies?
Output: 55

Input: Belle eats 4 dog biscuits and 2 rawhide bones every evening. If each rawhide bone is $1, and each dog biscuit is $0.25, then how much does it cost, in dollars, to feed Belle these treats for a week?
Output: 21

Input: There are 10 6-ounces of glasses that are only 4/5 full of water. How many ounces of water are needed to fill to the brim all those 10 glasses?
Output: 12

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o24-tgsm8k-s1-rFalse-m4096
Evaluating commonsenseqa :   2%|▌                                  | 1/63 [01:12<1:14:35, 72.18s/it]Evaluating commonsenseqa :   3%|█                                  | 2/63 [02:22<1:12:03, 70.87s/it]Evaluating commonsenseqa :   5%|█▋                                 | 3/63 [03:31<1:10:06, 70.11s/it]Evaluating commonsenseqa :   6%|██▏                                | 4/63 [04:42<1:09:10, 70.34s/it]Evaluating commonsenseqa :   8%|██▊                                | 5/63 [05:51<1:07:50, 70.19s/it]Evaluating commonsenseqa :  10%|███▎                               | 6/63 [07:02<1:06:47, 70.32s/it]Evaluating commonsenseqa :  11%|███▉                               | 7/63 [08:11<1:05:20, 70.02s/it]Evaluating commonsenseqa :  13%|████▍                              | 8/63 [09:23<1:04:43, 70.60s/it]Evaluating commonsenseqa :  14%|█████                              | 9/63 [10:27<1:01:33, 68.40s/it]Evaluating commonsenseqa :  16%|█████▍                            | 10/63 [11:38<1:01:17, 69.39s/it]Evaluating commonsenseqa :  17%|█████▉                            | 11/63 [12:50<1:00:44, 70.08s/it]Evaluating commonsenseqa :  19%|██████▊                             | 12/63 [13:59<59:20, 69.81s/it]Evaluating commonsenseqa :  21%|███████▍                            | 13/63 [15:09<58:07, 69.75s/it]Evaluating commonsenseqa :  22%|████████                            | 14/63 [16:20<57:25, 70.31s/it]Evaluating commonsenseqa :  24%|████████▌                           | 15/63 [17:31<56:17, 70.36s/it]Evaluating commonsenseqa :  25%|█████████▏                          | 16/63 [18:40<54:55, 70.11s/it]Evaluating commonsenseqa :  27%|█████████▋                          | 17/63 [19:50<53:41, 70.04s/it]Evaluating commonsenseqa :  29%|██████████▎                         | 18/63 [21:01<52:39, 70.20s/it]Evaluating commonsenseqa :  30%|██████████▊                         | 19/63 [22:10<51:11, 69.81s/it]Evaluating commonsenseqa :  32%|███████████▍                        | 20/63 [23:20<50:01, 69.80s/it]Evaluating commonsenseqa :  33%|████████████                        | 21/63 [24:29<48:46, 69.67s/it]Evaluating commonsenseqa :  35%|████████████▌                       | 22/63 [25:39<47:43, 69.85s/it]Evaluating commonsenseqa :  37%|█████████████▏                      | 23/63 [26:48<46:25, 69.65s/it]Evaluating commonsenseqa :  38%|█████████████▋                      | 24/63 [27:59<45:28, 69.96s/it]Evaluating commonsenseqa :  40%|██████████████▎                     | 25/63 [29:10<44:34, 70.37s/it]Evaluating commonsenseqa :  41%|██████████████▊                     | 26/63 [30:21<43:23, 70.37s/it]Evaluating commonsenseqa :  43%|███████████████▍                    | 27/63 [31:25<41:09, 68.59s/it]Evaluating commonsenseqa :  44%|████████████████                    | 28/63 [32:35<40:14, 68.99s/it]Evaluating commonsenseqa :  46%|████████████████▌                   | 29/63 [33:46<39:27, 69.64s/it]Evaluating commonsenseqa :  48%|█████████████████▏                  | 30/63 [34:47<36:45, 66.84s/it]Evaluating commonsenseqa :  49%|█████████████████▋                  | 31/63 [35:56<36:06, 67.71s/it]Evaluating commonsenseqa :  51%|██████████████████▎                 | 32/63 [37:07<35:28, 68.66s/it]Evaluating commonsenseqa :  52%|██████████████████▊                 | 33/63 [37:44<29:36, 59.23s/it]Evaluating commonsenseqa :  54%|███████████████████▍                | 34/63 [38:56<30:25, 62.95s/it]Evaluating commonsenseqa :  56%|████████████████████                | 35/63 [40:05<30:13, 64.78s/it]Evaluating commonsenseqa :  57%|████████████████████▌               | 36/63 [41:15<29:48, 66.24s/it]Evaluating commonsenseqa :  59%|█████████████████████▏              | 37/63 [42:24<29:03, 67.04s/it]Evaluating commonsenseqa :  60%|█████████████████████▋              | 38/63 [43:37<28:41, 68.84s/it]Evaluating commonsenseqa :  62%|██████████████████████▎             | 39/63 [44:48<27:48, 69.51s/it]Evaluating commonsenseqa :  63%|██████████████████████▊             | 40/63 [45:58<26:45, 69.81s/it]Evaluating commonsenseqa :  65%|███████████████████████▍            | 41/63 [47:09<25:42, 70.14s/it]Evaluating commonsenseqa :  67%|████████████████████████            | 42/63 [48:10<23:35, 67.40s/it]Evaluating commonsenseqa :  68%|████████████████████████▌           | 43/63 [49:22<22:54, 68.71s/it]Evaluating commonsenseqa :  70%|█████████████████████████▏          | 44/63 [50:33<21:57, 69.36s/it]Evaluating commonsenseqa :  71%|█████████████████████████▋          | 45/63 [51:44<20:56, 69.81s/it]Evaluating commonsenseqa :  73%|██████████████████████████▎         | 46/63 [52:53<19:44, 69.68s/it]Evaluating commonsenseqa :  75%|██████████████████████████▊         | 47/63 [54:05<18:45, 70.34s/it]Evaluating commonsenseqa :  76%|███████████████████████████▍        | 48/63 [55:16<17:36, 70.44s/it]Evaluating commonsenseqa :  78%|████████████████████████████        | 49/63 [56:27<16:29, 70.68s/it]Evaluating commonsenseqa :  79%|████████████████████████████▌       | 50/63 [57:36<15:13, 70.31s/it]Evaluating commonsenseqa :  81%|█████████████████████████████▏      | 51/63 [58:18<12:21, 61.81s/it]Evaluating commonsenseqa :  83%|█████████████████████████████▋      | 52/63 [59:29<11:49, 64.52s/it]Evaluating commonsenseqa :  84%|████████████████████████████▌     | 53/63 [1:00:40<11:03, 66.39s/it]Evaluating commonsenseqa :  86%|█████████████████████████████▏    | 54/63 [1:01:51<10:09, 67.67s/it]Evaluating commonsenseqa :  87%|█████████████████████████████▋    | 55/63 [1:03:02<09:09, 68.66s/it]Evaluating commonsenseqa :  89%|██████████████████████████████▏   | 56/63 [1:03:45<07:07, 61.06s/it]Evaluating commonsenseqa :  90%|██████████████████████████████▊   | 57/63 [1:04:10<05:02, 50.39s/it]Evaluating commonsenseqa :  92%|███████████████████████████████▎  | 58/63 [1:04:47<03:51, 46.32s/it]Evaluating commonsenseqa :  94%|███████████████████████████████▊  | 59/63 [1:05:58<03:34, 53.50s/it]Evaluating commonsenseqa :  95%|████████████████████████████████▍ | 60/63 [1:07:08<02:55, 58.64s/it]Evaluating commonsenseqa :  97%|████████████████████████████████▉ | 61/63 [1:08:19<02:04, 62.24s/it]Evaluating commonsenseqa :  98%|█████████████████████████████████▍| 62/63 [1:09:12<00:59, 59.40s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████| 63/63 [1:09:52<00:00, 53.63s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████| 63/63 [1:09:52<00:00, 66.54s/it]
name: commonsenseqa | avg. gen lenth: 319.436 | time: 4192.661918640137s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o25-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 25
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-29 03:10:25,217] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-29 03:10:25,300] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-29 03:10:25,308] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-29 03:10:25,309] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o25-tgsm8k-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 25
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o25-tgsm8k-s1-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                                        | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████████████████████████| 9741/9741 [00:00<00:00, 357849.19it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.44s/it]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.48s/it]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.52s/it]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.58s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.40s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.86s/it]
 > number of parameters: 6738415616
[2023-08-29 03:10:36,458] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.54s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.98s/it]
Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.53s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.98s/it]
[2023-08-29 03:10:36,759] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.45s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.92s/it]
[2023-08-29 03:10:36,782] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-29 03:10:36,877] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-29 03:10:37,465] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-29 03:10:37,467] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-29 03:10:37,467] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-29 03:10:37,467] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-29 03:10:37,467] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-29 03:10:37,467] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-29 03:10:37,467] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-29 03:10:37,467] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-29 03:10:37,467] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fc0c7477640>
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-29 03:10:37,468] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-29 03:10:37,469] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-29 03:10:37,469] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-29 03:10:37,469] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-29 03:10:37,469] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-29 03:10:37,469] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-29 03:10:37,469] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-29 03:10:37,469] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-29 03:10:37,469] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-29 03:10:37,469] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-29 03:10:37,469] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-29 03:10:37,469] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-29 03:10:37,469] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-29 03:10:37,469] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-29 03:10:37,469] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-29 03:10:37,469] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-29 03:10:37,469] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                                             | 0/63 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: 6

Input: Mark has kangaroos and goats.  Kangaroos have two legs and goats have four legs.  If he has 23 kangaroos and three times as many goats as kangaroos what is the total number of legs of all his animals?
Output: 322

Input: Josh’s mom gives him $20 to go shopping at the mall. He buys a hat for $10 and a pencil for $2. Then he buys four cookies. If each cookie costs $1.25, how much money does Josh have left?
Output: 3

Input: George's bowling team is one round away from breaking the league record for most points scored in a season. The old record is an average score per player of 287 per round. Each team has 4 players and there are 10 rounds in the season. Through the first 9 rounds, his team has scored a total of 10,440. How many points less than the current league record per game average is the minimum average they need to score, per player, in the final round to tie the league record?
Output: 27

Input: Max was doing homework in three different subjects. It took him 20 minutes to finish tasks from biology and two times more time to finish history. Geography took him the most time, three times more than history. How much time did Max spend on doing his homework?
Output: 180

Input: Sophia ate 1/6 of her pie and she put the rest on the fridge. If the pie left in the fridge weighs 1200 grams, how many grams did Sophia eat?
Output: 240

Input: Sarah, Mary, and Tuan decided to go to the restaurant for a meal. They decided to split the cost of the meal evenly. If the total price of the meal comes to $67 and they have a coupon for $4, how much does each person need to contribute to the bill?
Output: 21

Input: Tom's brother is 4 times as old as Tom's dog. If in 6 years, Tom's brother will be 30 years, how old is Tom's dog going to be in six years?
Output: 12

Input: There are 50 children at the party. Three-fifths of them are boys. How many of the children are girls?
Output: 20

Input: Gail has some bills in her wallet which amount to $100. She has four $5 bills and three $20 bills, and the rest are $10 bills. How many $10 bills are in her wallet?
Output: 2

Input: A 220-liter barrel has a small leak. It lost 10% of its contents before anyone noticed. How many liters are left in the barrel?
Output: 198

Input: Markese earned 5 fewer dollars than Evan. Together they earned $37. How many dollars did Markese earn? Use E to represent how many dollars Evan earned.
Output: 16

Input: Lou Senior took 3 cookies out of the cookie jar and ate them.  Since he didn't get caught by his wife, he went back the next day and took another 3 cookies out of the jar.  But after eating just one of the cookies, he felt guilty about it and put the other two cookies back.  His son, Louie Junior saw that his Dad was eating cookies.  So, Louie Junior took seven cookies out of the jar and hid them in his bedroom for later.  The next morning, Debra, Lou's wife looked into the cookie jar and reacted by accusing her husband of eating half of the cookies out of the cookie jar.  How many cookies remained in the jar?
Output: 11

Input: John had $200. He gave 3/8 of his money to his mother and 3/10 to his father. How much money did John have left?
Output: 65

Input: Tonya has $150.00 on her credit card.  If she leaves any balance on her card at the end of the month, she is charged 20% interest.  If she makes a $50.00 payment on her card, what will be the new balance?
Output: 120

Input: In her first term, Governor Sandoval gave twice as many commencement addresses as Governor Hawkins. Governor Sloan gave ten more commencement addresses than Governor Sandoval in the same amount of time. If Governor Sandoval gave 12 commencement addresses, how many commencement addresses did the three of them give altogether?
Output: 40

Input: If Buzz bought a pizza with 78 slices at a restaurant and then decided to share it with the waiter in the ratio of 5:8, with Buzz's ratio being 5, what's twenty less the number of slices of pizza that the waiter ate?
Output: 28

Input: Jolene and Phil have four children, each with the same birthday.  They gave birth to their first child exactly 15 years ago.  They gave birth to their second child exactly one year after the birth of their first child.  They gave birth to their third child on the fourth birthday of their second child. Two years after the birth of their third child, they gave birth to their fourth child.  How old, in years, is their fourth child?
Output: 8

Input: Each purple book has 230 pages. Each orange book contains 510 pages. Mirella read 5 purple books and 4 orange books. How many more orange pages did she read than purple pages?
Output: 890

Input: Isabella has $45 more than Sam but only $15 more than Giselle. If Giselle has $120, calculate the total amount of money each shopper will receive if Isabella, Sam, and Giselle donate the money to three shoppers at their local town's supermarket who then decides to share it equally.
Output: 115

Input: It takes 40 minutes to freeze ice cubes and 3 minutes per smoothie to turn them into smoothies once they're frozen. How long does it take to make 5 smoothies?
Output: 55

Input: Belle eats 4 dog biscuits and 2 rawhide bones every evening. If each rawhide bone is $1, and each dog biscuit is $0.25, then how much does it cost, in dollars, to feed Belle these treats for a week?
Output: 21

Input: There are 10 6-ounces of glasses that are only 4/5 full of water. How many ounces of water are needed to fill to the brim all those 10 glasses?
Output: 12

Input: Tony decided to rent a small cottage.  The master bedroom and bath totaled 500 sq ft.  The 2 guest bedrooms were 200 sq ft each.  And the kitchen, guest bath and living area totaled 600 sq ft.  If Tony spends $3,000 a month on rent, how much money is he spending per sq ft of house?
Output: 2

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o25-tgsm8k-s1-rFalse-m4096
Evaluating commonsenseqa :   2%|▌                                  | 1/63 [01:13<1:16:03, 73.60s/it]Evaluating commonsenseqa :   3%|█                                  | 2/63 [02:03<1:00:52, 59.88s/it]Evaluating commonsenseqa :   5%|█▋                                 | 3/63 [03:10<1:03:08, 63.15s/it]Evaluating commonsenseqa :   6%|██▏                                | 4/63 [04:20<1:04:24, 65.51s/it]Evaluating commonsenseqa :   8%|██▊                                | 5/63 [05:28<1:04:17, 66.51s/it]Evaluating commonsenseqa :  10%|███▎                               | 6/63 [06:36<1:03:39, 67.01s/it]Evaluating commonsenseqa :  11%|███▉                               | 7/63 [07:44<1:02:54, 67.40s/it]Evaluating commonsenseqa :  13%|████▋                                | 8/63 [08:05<48:20, 52.73s/it]Evaluating commonsenseqa :  14%|█████▎                               | 9/63 [09:10<50:47, 56.44s/it]Evaluating commonsenseqa :  16%|█████▋                              | 10/63 [10:18<53:05, 60.10s/it]Evaluating commonsenseqa :  17%|██████▎                             | 11/63 [11:28<54:32, 62.94s/it]Evaluating commonsenseqa :  19%|██████▊                             | 12/63 [12:35<54:44, 64.40s/it]Evaluating commonsenseqa :  21%|███████▍                            | 13/63 [13:43<54:28, 65.36s/it]Evaluating commonsenseqa :  22%|████████                            | 14/63 [14:51<54:07, 66.27s/it]Evaluating commonsenseqa :  24%|████████▌                           | 15/63 [15:59<53:20, 66.67s/it]Evaluating commonsenseqa :  25%|█████████▏                          | 16/63 [17:08<52:46, 67.38s/it]Evaluating commonsenseqa :  27%|█████████▋                          | 17/63 [18:15<51:38, 67.37s/it]Evaluating commonsenseqa :  29%|██████████▎                         | 18/63 [19:22<50:28, 67.29s/it]Evaluating commonsenseqa :  30%|██████████▊                         | 19/63 [20:31<49:38, 67.70s/it]Evaluating commonsenseqa :  32%|███████████▍                        | 20/63 [21:39<48:32, 67.74s/it]Evaluating commonsenseqa :  33%|████████████                        | 21/63 [22:47<47:34, 67.97s/it]Evaluating commonsenseqa :  35%|████████████▌                       | 22/63 [23:55<46:26, 67.95s/it]Evaluating commonsenseqa :  37%|█████████████▏                      | 23/63 [25:02<45:05, 67.63s/it]Evaluating commonsenseqa :  38%|█████████████▋                      | 24/63 [26:10<43:59, 67.68s/it]Evaluating commonsenseqa :  40%|██████████████▎                     | 25/63 [27:18<42:59, 67.87s/it]Evaluating commonsenseqa :  41%|██████████████▊                     | 26/63 [28:26<41:52, 67.90s/it]Evaluating commonsenseqa :  43%|███████████████▍                    | 27/63 [29:34<40:44, 67.91s/it]Evaluating commonsenseqa :  44%|████████████████                    | 28/63 [30:44<39:52, 68.34s/it]Evaluating commonsenseqa :  46%|████████████████▌                   | 29/63 [31:29<34:52, 61.54s/it]Evaluating commonsenseqa :  48%|█████████████████▏                  | 30/63 [32:38<35:00, 63.66s/it]Evaluating commonsenseqa :  49%|█████████████████▋                  | 31/63 [33:45<34:26, 64.59s/it]Evaluating commonsenseqa :  51%|██████████████████▎                 | 32/63 [34:53<33:59, 65.78s/it]Evaluating commonsenseqa :  52%|██████████████████▊                 | 33/63 [35:55<32:17, 64.57s/it]Evaluating commonsenseqa :  54%|███████████████████▍                | 34/63 [36:40<28:23, 58.74s/it]Evaluating commonsenseqa :  56%|████████████████████                | 35/63 [37:43<28:04, 60.15s/it]Evaluating commonsenseqa :  57%|████████████████████▌               | 36/63 [38:51<28:03, 62.37s/it]Evaluating commonsenseqa :  59%|█████████████████████▏              | 37/63 [39:59<27:44, 64.01s/it]Evaluating commonsenseqa :  60%|█████████████████████▋              | 38/63 [41:06<27:01, 64.87s/it]Evaluating commonsenseqa :  62%|██████████████████████▎             | 39/63 [42:15<26:25, 66.06s/it]Evaluating commonsenseqa :  63%|██████████████████████▊             | 40/63 [43:23<25:34, 66.71s/it]Evaluating commonsenseqa :  65%|███████████████████████▍            | 41/63 [44:30<24:34, 67.01s/it]Evaluating commonsenseqa :  67%|████████████████████████            | 42/63 [45:38<23:31, 67.21s/it]Evaluating commonsenseqa :  68%|████████████████████████▌           | 43/63 [46:45<22:24, 67.21s/it]Evaluating commonsenseqa :  70%|█████████████████████████▏          | 44/63 [47:52<21:14, 67.08s/it]Evaluating commonsenseqa :  71%|█████████████████████████▋          | 45/63 [48:59<20:06, 67.03s/it]Evaluating commonsenseqa :  73%|██████████████████████████▎         | 46/63 [50:07<19:04, 67.34s/it]Evaluating commonsenseqa :  75%|██████████████████████████▊         | 47/63 [51:15<17:59, 67.47s/it]Evaluating commonsenseqa :  76%|███████████████████████████▍        | 48/63 [52:23<16:55, 67.67s/it]Evaluating commonsenseqa :  78%|████████████████████████████        | 49/63 [53:31<15:48, 67.78s/it]Evaluating commonsenseqa :  79%|████████████████████████████▌       | 50/63 [54:39<14:40, 67.70s/it]Evaluating commonsenseqa :  81%|█████████████████████████████▏      | 51/63 [55:46<13:31, 67.62s/it]Evaluating commonsenseqa :  83%|█████████████████████████████▋      | 52/63 [56:53<12:22, 67.52s/it]Evaluating commonsenseqa :  84%|██████████████████████████████▎     | 53/63 [58:01<11:16, 67.61s/it]Evaluating commonsenseqa :  86%|██████████████████████████████▊     | 54/63 [59:09<10:10, 67.83s/it]Evaluating commonsenseqa :  87%|█████████████████████████████▋    | 55/63 [1:00:13<08:51, 66.45s/it]Evaluating commonsenseqa :  89%|██████████████████████████████▏   | 56/63 [1:01:21<07:50, 67.16s/it]Evaluating commonsenseqa :  90%|██████████████████████████████▊   | 57/63 [1:02:29<06:44, 67.36s/it]Evaluating commonsenseqa :  92%|███████████████████████████████▎  | 58/63 [1:03:36<05:35, 67.16s/it]Evaluating commonsenseqa :  94%|███████████████████████████████▊  | 59/63 [1:04:43<04:27, 66.99s/it]Evaluating commonsenseqa :  95%|████████████████████████████████▍ | 60/63 [1:05:52<03:23, 67.74s/it]Evaluating commonsenseqa :  97%|████████████████████████████████▉ | 61/63 [1:06:59<02:15, 67.63s/it]Evaluating commonsenseqa :  98%|█████████████████████████████████▍| 62/63 [1:08:07<01:07, 67.57s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████| 63/63 [1:08:46<00:00, 59.07s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████| 63/63 [1:08:46<00:00, 65.50s/it]
name: commonsenseqa | avg. gen lenth: 322.912 | time: 4127.086293458939s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-29 04:20:21,959] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-29 04:20:21,992] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-29 04:20:21,992] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-29 04:20:21,992] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 1
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o1-tgsm8k-s10-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                                        | 0/9741 [00:00<?, ?it/s]Loading data: 100%|████████████████████████████████████████| 9741/9741 [00:00<00:00, 1238908.22it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.36s/it]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.41s/it]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.42s/it]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.66s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.19s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.67s/it]
Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.29s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.76s/it]
[2023-08-29 04:20:32,683] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-29 04:20:32,851] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.44s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.89s/it]
[2023-08-29 04:20:33,093] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:10<00:00,  4.59s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:10<00:00,  5.05s/it]
 > number of parameters: 6738415616
[2023-08-29 04:20:33,413] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-29 04:20:34,026] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-29 04:20:34,028] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-29 04:20:34,028] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-29 04:20:34,028] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-29 04:20:34,028] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-29 04:20:34,028] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-29 04:20:34,028] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f613923b520>
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-29 04:20:34,029] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-29 04:20:34,030] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-29 04:20:34,030] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                                             | 0/63 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: 56

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o1-tgsm8k-s10-rFalse-m4096
Evaluating commonsenseqa :   2%|▌                                 | 1/63 [01:56<2:00:49, 116.93s/it]Evaluating commonsenseqa :   3%|█                                  | 2/63 [03:23<1:40:56, 99.29s/it]Evaluating commonsenseqa :   5%|█▌                                | 3/63 [05:19<1:46:53, 106.90s/it]Evaluating commonsenseqa :   6%|██▏                               | 4/63 [07:16<1:49:04, 110.93s/it]Evaluating commonsenseqa :   8%|██▋                               | 5/63 [09:11<1:48:34, 112.31s/it]Evaluating commonsenseqa :  10%|███▏                              | 6/63 [10:28<1:35:06, 100.11s/it]Evaluating commonsenseqa :  11%|███▊                              | 7/63 [12:25<1:38:45, 105.81s/it]Evaluating commonsenseqa :  13%|████▎                             | 8/63 [14:23<1:40:38, 109.78s/it]Evaluating commonsenseqa :  14%|████▊                             | 9/63 [16:19<1:40:30, 111.68s/it]Evaluating commonsenseqa :  16%|█████▍                            | 10/63 [17:32<1:28:05, 99.72s/it]Evaluating commonsenseqa :  17%|█████▊                           | 11/63 [19:26<1:30:13, 104.11s/it]Evaluating commonsenseqa :  19%|██████▍                           | 12/63 [20:35<1:19:21, 93.37s/it]Evaluating commonsenseqa :  21%|███████                           | 13/63 [22:28<1:22:46, 99.33s/it]Evaluating commonsenseqa :  22%|███████▎                         | 14/63 [24:22<1:24:37, 103.62s/it]Evaluating commonsenseqa :  24%|███████▊                         | 15/63 [26:17<1:25:39, 107.07s/it]Evaluating commonsenseqa :  25%|████████▋                         | 16/63 [27:27<1:15:16, 96.10s/it]Evaluating commonsenseqa :  27%|█████████▏                        | 17/63 [28:21<1:03:58, 83.44s/it]Evaluating commonsenseqa :  29%|█████████▋                        | 18/63 [30:17<1:09:55, 93.22s/it]Evaluating commonsenseqa :  30%|██████████▊                         | 19/63 [30:54<55:54, 76.24s/it]Evaluating commonsenseqa :  32%|██████████▊                       | 20/63 [32:49<1:02:59, 87.89s/it]Evaluating commonsenseqa :  33%|███████████▎                      | 21/63 [34:45<1:07:23, 96.28s/it]Evaluating commonsenseqa :  35%|███████████▌                     | 22/63 [36:38<1:09:08, 101.19s/it]Evaluating commonsenseqa :  37%|████████████▍                     | 23/63 [38:06<1:05:00, 97.50s/it]Evaluating commonsenseqa :  38%|█████████████▋                      | 24/63 [38:43<51:23, 79.07s/it]Evaluating commonsenseqa :  40%|██████████████▎                     | 25/63 [40:39<57:11, 90.30s/it]Evaluating commonsenseqa :  41%|██████████████▊                     | 26/63 [42:21<57:52, 93.86s/it]Evaluating commonsenseqa :  43%|██████████████▏                  | 27/63 [44:18<1:00:30, 100.85s/it]Evaluating commonsenseqa :  44%|██████████████▋                  | 28/63 [46:15<1:01:33, 105.54s/it]Evaluating commonsenseqa :  46%|███████████████▏                 | 29/63 [48:11<1:01:41, 108.86s/it]Evaluating commonsenseqa :  48%|███████████████▋                 | 30/63 [50:09<1:01:15, 111.37s/it]Evaluating commonsenseqa :  49%|█████████████████▋                  | 31/63 [51:17<52:26, 98.31s/it]Evaluating commonsenseqa :  51%|█████████████████▊                 | 32/63 [53:13<53:35, 103.72s/it]Evaluating commonsenseqa :  52%|██████████████████▎                | 33/63 [55:08<53:37, 107.26s/it]Evaluating commonsenseqa :  54%|██████████████████▉                | 34/63 [57:05<53:15, 110.18s/it]Evaluating commonsenseqa :  56%|███████████████████▍               | 35/63 [59:02<52:22, 112.22s/it]Evaluating commonsenseqa :  57%|██████████████████▊              | 36/63 [1:01:00<51:17, 113.97s/it]Evaluating commonsenseqa :  59%|███████████████████▍             | 37/63 [1:02:55<49:26, 114.10s/it]Evaluating commonsenseqa :  60%|███████████████████▉             | 38/63 [1:04:48<47:23, 113.75s/it]Evaluating commonsenseqa :  62%|█████████████████████             | 39/63 [1:05:54<39:50, 99.61s/it]Evaluating commonsenseqa :  63%|████████████████████▉            | 40/63 [1:07:51<40:05, 104.58s/it]Evaluating commonsenseqa :  65%|█████████████████████▍           | 41/63 [1:09:47<39:38, 108.10s/it]Evaluating commonsenseqa :  67%|██████████████████████           | 42/63 [1:11:46<38:58, 111.36s/it]Evaluating commonsenseqa :  68%|██████████████████████▌          | 43/63 [1:13:43<37:40, 113.00s/it]Evaluating commonsenseqa :  70%|███████████████████████▋          | 44/63 [1:14:09<27:31, 86.93s/it]Evaluating commonsenseqa :  71%|████████████████████████▎         | 45/63 [1:16:03<28:31, 95.10s/it]Evaluating commonsenseqa :  73%|████████████████████████         | 46/63 [1:17:58<28:39, 101.13s/it]Evaluating commonsenseqa :  75%|████████████████████████▌        | 47/63 [1:19:55<28:13, 105.85s/it]Evaluating commonsenseqa :  76%|█████████████████████████▏       | 48/63 [1:21:52<27:17, 109.15s/it]Evaluating commonsenseqa :  78%|█████████████████████████▋       | 49/63 [1:23:48<25:59, 111.38s/it]Evaluating commonsenseqa :  79%|██████████████████████████▏      | 50/63 [1:25:42<24:18, 112.17s/it]Evaluating commonsenseqa :  81%|██████████████████████████▋      | 51/63 [1:27:30<22:09, 110.78s/it]Evaluating commonsenseqa :  83%|████████████████████████████      | 52/63 [1:28:08<16:18, 88.91s/it]Evaluating commonsenseqa :  84%|████████████████████████████▌     | 53/63 [1:29:46<15:16, 91.62s/it]Evaluating commonsenseqa :  86%|█████████████████████████████▏    | 54/63 [1:31:39<14:42, 98.10s/it]Evaluating commonsenseqa :  87%|████████████████████████████▊    | 55/63 [1:33:34<13:46, 103.29s/it]Evaluating commonsenseqa :  89%|█████████████████████████████▎   | 56/63 [1:35:29<12:26, 106.69s/it]Evaluating commonsenseqa :  90%|██████████████████████████████▊   | 57/63 [1:36:07<08:36, 86.08s/it]Evaluating commonsenseqa :  92%|███████████████████████████████▎  | 58/63 [1:38:05<07:58, 95.70s/it]Evaluating commonsenseqa :  94%|██████████████████████████████▉  | 59/63 [1:39:59<06:44, 101.17s/it]Evaluating commonsenseqa :  95%|███████████████████████████████▍ | 60/63 [1:41:46<05:08, 102.96s/it]Evaluating commonsenseqa :  97%|███████████████████████████████▉ | 61/63 [1:43:40<03:32, 106.07s/it]Evaluating commonsenseqa :  98%|████████████████████████████████▍| 62/63 [1:45:27<01:46, 106.38s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████| 63/63 [1:46:15<00:00, 88.91s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████| 63/63 [1:46:15<00:00, 101.20s/it]
name: commonsenseqa | avg. gen lenth: 233.332 | time: 6375.584306716919s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 2
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-29 06:06:55,946] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-29 06:06:55,987] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-29 06:06:55,990] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-29 06:06:56,010] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 2
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o2-tgsm8k-s10-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                                        | 0/9741 [00:00<?, ?it/s]Loading data: 100%|████████████████████████████████████████| 9741/9741 [00:00<00:00, 1121574.48it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.10s/it]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.40s/it]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.51s/it]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:08<00:08,  8.82s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.20s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.64s/it]
[2023-08-29 06:07:06,554] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.26s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.73s/it]
Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.29s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.77s/it]
[2023-08-29 06:07:06,794] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
 > number of parameters: 6738415616
[2023-08-29 06:07:06,857] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:10<00:00,  4.83s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:10<00:00,  5.43s/it]
[2023-08-29 06:07:08,192] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-29 06:07:08,798] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-29 06:07:08,799] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fa657363520>
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-29 06:07:08,800] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-29 06:07:08,801] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-29 06:07:08,801] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                                             | 0/63 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: 4

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o2-tgsm8k-s10-rFalse-m4096
Evaluating commonsenseqa :   2%|▌                                 | 1/63 [01:51<1:54:55, 111.22s/it]Evaluating commonsenseqa :   3%|█                                 | 2/63 [03:45<1:54:50, 112.97s/it]Evaluating commonsenseqa :   5%|█▌                                | 3/63 [05:36<1:52:13, 112.22s/it]Evaluating commonsenseqa :   6%|██▏                               | 4/63 [07:10<1:43:01, 104.76s/it]Evaluating commonsenseqa :   8%|██▊                                | 5/63 [07:48<1:18:16, 80.97s/it]Evaluating commonsenseqa :  10%|███▎                               | 6/63 [09:40<1:26:59, 91.56s/it]Evaluating commonsenseqa :  11%|███▉                               | 7/63 [11:32<1:31:34, 98.12s/it]Evaluating commonsenseqa :  13%|████▎                             | 8/63 [13:24<1:33:59, 102.53s/it]Evaluating commonsenseqa :  14%|████▊                             | 9/63 [15:14<1:34:17, 104.77s/it]Evaluating commonsenseqa :  16%|█████▏                           | 10/63 [17:07<1:34:47, 107.32s/it]Evaluating commonsenseqa :  17%|█████▊                           | 11/63 [18:45<1:30:32, 104.48s/it]Evaluating commonsenseqa :  19%|██████▎                          | 12/63 [20:38<1:31:03, 107.13s/it]Evaluating commonsenseqa :  21%|██████▊                          | 13/63 [22:33<1:31:08, 109.36s/it]Evaluating commonsenseqa :  22%|███████▎                         | 14/63 [24:24<1:29:54, 110.09s/it]Evaluating commonsenseqa :  24%|███████▊                         | 15/63 [26:16<1:28:27, 110.56s/it]Evaluating commonsenseqa :  25%|████████▍                        | 16/63 [28:08<1:27:03, 111.13s/it]Evaluating commonsenseqa :  27%|████████▉                        | 17/63 [30:03<1:25:54, 112.06s/it]Evaluating commonsenseqa :  29%|█████████▍                       | 18/63 [31:54<1:23:58, 111.96s/it]Evaluating commonsenseqa :  30%|█████████▉                       | 19/63 [33:46<1:21:57, 111.75s/it]Evaluating commonsenseqa :  32%|██████████▍                      | 20/63 [35:39<1:20:27, 112.27s/it]Evaluating commonsenseqa :  33%|███████████▎                      | 21/63 [36:17<1:02:52, 89.83s/it]Evaluating commonsenseqa :  35%|███████████▊                      | 22/63 [37:45<1:01:03, 89.35s/it]Evaluating commonsenseqa :  37%|████████████▍                     | 23/63 [39:40<1:04:40, 97.02s/it]Evaluating commonsenseqa :  38%|████████████▌                    | 24/63 [41:33<1:06:15, 101.94s/it]Evaluating commonsenseqa :  40%|█████████████                    | 25/63 [43:26<1:06:33, 105.11s/it]Evaluating commonsenseqa :  41%|█████████████▌                   | 26/63 [45:21<1:06:38, 108.05s/it]Evaluating commonsenseqa :  43%|███████████████▍                    | 27/63 [46:32<58:09, 96.94s/it]Evaluating commonsenseqa :  44%|████████████████                    | 28/63 [47:06<45:39, 78.26s/it]Evaluating commonsenseqa :  46%|████████████████▌                   | 29/63 [49:02<50:44, 89.53s/it]Evaluating commonsenseqa :  48%|█████████████████▏                  | 30/63 [50:56<53:15, 96.84s/it]Evaluating commonsenseqa :  49%|█████████████████▏                 | 31/63 [52:50<54:20, 101.88s/it]Evaluating commonsenseqa :  51%|██████████████████▎                 | 32/63 [54:21<50:59, 98.68s/it]Evaluating commonsenseqa :  52%|██████████████████▎                | 33/63 [56:14<51:34, 103.14s/it]Evaluating commonsenseqa :  54%|███████████████████▍                | 34/63 [57:32<46:05, 95.37s/it]Evaluating commonsenseqa :  56%|███████████████████▍               | 35/63 [59:23<46:46, 100.23s/it]Evaluating commonsenseqa :  57%|██████████████████▊              | 36/63 [1:01:14<46:34, 103.49s/it]Evaluating commonsenseqa :  59%|███████████████████▍             | 37/63 [1:03:07<46:00, 106.18s/it]Evaluating commonsenseqa :  60%|███████████████████▉             | 38/63 [1:04:59<45:03, 108.14s/it]Evaluating commonsenseqa :  62%|████████████████████▍            | 39/63 [1:06:51<43:41, 109.25s/it]Evaluating commonsenseqa :  63%|█████████████████████▌            | 40/63 [1:07:57<36:50, 96.10s/it]Evaluating commonsenseqa :  65%|█████████████████████▍           | 41/63 [1:09:50<37:06, 101.18s/it]Evaluating commonsenseqa :  67%|██████████████████████           | 42/63 [1:11:42<36:31, 104.36s/it]Evaluating commonsenseqa :  68%|███████████████████████▏          | 43/63 [1:12:41<30:15, 90.79s/it]Evaluating commonsenseqa :  70%|███████████████████████▋          | 44/63 [1:14:35<31:01, 97.97s/it]Evaluating commonsenseqa :  71%|███████████████████████▌         | 45/63 [1:16:27<30:37, 102.11s/it]Evaluating commonsenseqa :  73%|████████████████████████         | 46/63 [1:18:19<29:43, 104.91s/it]Evaluating commonsenseqa :  75%|█████████████████████████▎        | 47/63 [1:19:30<25:20, 95.00s/it]Evaluating commonsenseqa :  76%|█████████████████████████▉        | 48/63 [1:21:19<24:47, 99.15s/it]Evaluating commonsenseqa :  78%|██████████████████████████▍       | 49/63 [1:22:21<20:30, 87.89s/it]Evaluating commonsenseqa :  79%|██████████████████████████▉       | 50/63 [1:24:12<20:31, 94.75s/it]Evaluating commonsenseqa :  81%|███████████████████████████▌      | 51/63 [1:25:08<16:38, 83.18s/it]Evaluating commonsenseqa :  83%|████████████████████████████      | 52/63 [1:25:39<12:23, 67.56s/it]Evaluating commonsenseqa :  84%|████████████████████████████▌     | 53/63 [1:27:29<13:22, 80.27s/it]Evaluating commonsenseqa :  86%|█████████████████████████████▏    | 54/63 [1:29:21<13:27, 89.76s/it]Evaluating commonsenseqa :  87%|█████████████████████████████▋    | 55/63 [1:31:13<12:52, 96.58s/it]Evaluating commonsenseqa :  89%|█████████████████████████████▎   | 56/63 [1:33:04<11:46, 100.91s/it]Evaluating commonsenseqa :  90%|█████████████████████████████▊   | 57/63 [1:35:00<10:31, 105.22s/it]Evaluating commonsenseqa :  92%|██████████████████████████████▍  | 58/63 [1:36:27<08:20, 100.01s/it]Evaluating commonsenseqa :  94%|██████████████████████████████▉  | 59/63 [1:38:13<06:46, 101.67s/it]Evaluating commonsenseqa :  95%|███████████████████████████████▍ | 60/63 [1:40:05<05:14, 104.77s/it]Evaluating commonsenseqa :  97%|███████████████████████████████▉ | 61/63 [1:41:58<03:34, 107.14s/it]Evaluating commonsenseqa :  98%|████████████████████████████████▍| 62/63 [1:43:52<01:49, 109.20s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████| 63/63 [1:44:28<00:00, 87.41s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████| 63/63 [1:44:28<00:00, 99.50s/it]
name: commonsenseqa | avg. gen lenth: 260.08 | time: 6268.995167255402s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o3-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 3
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-29 07:51:44,873] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-29 07:51:44,875] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-29 07:51:44,889] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-29 07:51:44,892] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o3-tgsm8k-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 3
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o3-tgsm8k-s10-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                                        | 0/9741 [00:00<?, ?it/s]Loading data: 100%|████████████████████████████████████████| 9741/9741 [00:00<00:00, 1043514.30it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.22s/it]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.62s/it]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.70s/it]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.41s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.13s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.59s/it]
 > number of parameters: 6738415616
[2023-08-29 07:51:55,490] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.43s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.92s/it]
[2023-08-29 07:51:56,070] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.39s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.85s/it]
Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:10<00:00,  4.54s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:10<00:00,  5.00s/it]
[2023-08-29 07:51:56,283] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-29 07:51:56,380] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-29 07:51:56,989] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-29 07:51:56,990] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-29 07:51:56,990] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-29 07:51:56,990] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-29 07:51:56,990] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-29 07:51:56,990] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7ff7a7177640>
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-29 07:51:56,991] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-29 07:51:56,992] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-29 07:51:56,992] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-29 07:51:56,992] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-29 07:51:56,992] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-29 07:51:56,992] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-29 07:51:56,992] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-29 07:51:56,992] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-29 07:51:56,992] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-29 07:51:56,992] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-29 07:51:56,992] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-29 07:51:56,992] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-29 07:51:56,992] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-29 07:51:56,992] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-29 07:51:56,992] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-29 07:51:56,992] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-29 07:51:56,992] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-29 07:51:56,992] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-29 07:51:56,992] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-29 07:51:56,992] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-29 07:51:56,992] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-29 07:51:56,992] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-29 07:51:56,992] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-29 07:51:56,992] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-29 07:51:56,992] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                                             | 0/63 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: 480

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o3-tgsm8k-s10-rFalse-m4096
Evaluating commonsenseqa :   2%|▌                                 | 1/63 [01:51<1:55:39, 111.94s/it]Evaluating commonsenseqa :   3%|█                                  | 2/63 [03:11<1:34:19, 92.77s/it]Evaluating commonsenseqa :   5%|█▌                                | 3/63 [05:00<1:40:14, 100.24s/it]Evaluating commonsenseqa :   6%|██▏                               | 4/63 [06:49<1:41:51, 103.58s/it]Evaluating commonsenseqa :   8%|██▋                               | 5/63 [08:40<1:42:43, 106.27s/it]Evaluating commonsenseqa :  10%|███▏                              | 6/63 [10:30<1:42:24, 107.79s/it]Evaluating commonsenseqa :  11%|███▊                              | 7/63 [12:23<1:42:09, 109.46s/it]Evaluating commonsenseqa :  13%|████▎                             | 8/63 [14:12<1:40:02, 109.14s/it]Evaluating commonsenseqa :  14%|████▊                             | 9/63 [16:00<1:38:02, 108.93s/it]Evaluating commonsenseqa :  16%|█████▏                           | 10/63 [17:50<1:36:19, 109.04s/it]Evaluating commonsenseqa :  17%|█████▊                           | 11/63 [19:38<1:34:25, 108.95s/it]Evaluating commonsenseqa :  19%|██████▎                          | 12/63 [21:26<1:32:21, 108.65s/it]Evaluating commonsenseqa :  21%|██████▊                          | 13/63 [23:18<1:31:23, 109.68s/it]Evaluating commonsenseqa :  22%|███████▎                         | 14/63 [25:05<1:28:50, 108.79s/it]Evaluating commonsenseqa :  24%|███████▊                         | 15/63 [26:56<1:27:32, 109.43s/it]Evaluating commonsenseqa :  25%|████████▋                         | 16/63 [27:22<1:06:09, 84.47s/it]Evaluating commonsenseqa :  27%|█████████▏                        | 17/63 [28:43<1:03:56, 83.40s/it]Evaluating commonsenseqa :  29%|█████████▋                        | 18/63 [30:32<1:08:08, 90.86s/it]Evaluating commonsenseqa :  30%|██████████▎                       | 19/63 [32:22<1:10:56, 96.75s/it]Evaluating commonsenseqa :  32%|██████████▊                       | 20/63 [33:39<1:05:09, 90.92s/it]Evaluating commonsenseqa :  33%|███████████▎                      | 21/63 [35:29<1:07:35, 96.57s/it]Evaluating commonsenseqa :  35%|███████████▌                     | 22/63 [37:20<1:08:52, 100.80s/it]Evaluating commonsenseqa :  37%|████████████                     | 23/63 [39:10<1:09:02, 103.57s/it]Evaluating commonsenseqa :  38%|████████████▉                     | 24/63 [40:33<1:03:22, 97.49s/it]Evaluating commonsenseqa :  40%|██████████████▎                     | 25/63 [41:50<57:50, 91.33s/it]Evaluating commonsenseqa :  41%|██████████████▊                     | 26/63 [42:57<51:47, 84.00s/it]Evaluating commonsenseqa :  43%|███████████████▍                    | 27/63 [44:48<55:12, 92.02s/it]Evaluating commonsenseqa :  44%|████████████████                    | 28/63 [46:38<56:47, 97.37s/it]Evaluating commonsenseqa :  46%|████████████████                   | 29/63 [48:27<57:14, 101.03s/it]Evaluating commonsenseqa :  48%|████████████████▋                  | 30/63 [50:16<56:54, 103.48s/it]Evaluating commonsenseqa :  49%|█████████████████▋                  | 31/63 [51:47<53:04, 99.50s/it]Evaluating commonsenseqa :  51%|█████████████████▊                 | 32/63 [53:37<53:09, 102.90s/it]Evaluating commonsenseqa :  52%|██████████████████▎                | 33/63 [55:28<52:34, 105.14s/it]Evaluating commonsenseqa :  54%|██████████████████▉                | 34/63 [57:17<51:26, 106.42s/it]Evaluating commonsenseqa :  56%|███████████████████▍               | 35/63 [59:05<49:52, 106.86s/it]Evaluating commonsenseqa :  57%|██████████████████▊              | 36/63 [1:00:54<48:24, 107.56s/it]Evaluating commonsenseqa :  59%|███████████████████▍             | 37/63 [1:02:46<47:07, 108.75s/it]Evaluating commonsenseqa :  60%|███████████████████▉             | 38/63 [1:04:36<45:33, 109.32s/it]Evaluating commonsenseqa :  62%|█████████████████████             | 39/63 [1:05:34<37:30, 93.75s/it]Evaluating commonsenseqa :  63%|█████████████████████▌            | 40/63 [1:07:23<37:43, 98.41s/it]Evaluating commonsenseqa :  65%|█████████████████████▍           | 41/63 [1:09:13<37:20, 101.82s/it]Evaluating commonsenseqa :  67%|██████████████████████           | 42/63 [1:11:02<36:26, 104.13s/it]Evaluating commonsenseqa :  68%|██████████████████████▌          | 43/63 [1:12:53<35:18, 105.94s/it]Evaluating commonsenseqa :  70%|███████████████████████          | 44/63 [1:14:42<33:53, 107.03s/it]Evaluating commonsenseqa :  71%|███████████████████████▌         | 45/63 [1:16:30<32:10, 107.23s/it]Evaluating commonsenseqa :  73%|████████████████████████         | 46/63 [1:18:18<30:28, 107.56s/it]Evaluating commonsenseqa :  75%|████████████████████████▌        | 47/63 [1:20:07<28:46, 107.93s/it]Evaluating commonsenseqa :  76%|█████████████████████████▏       | 48/63 [1:21:58<27:12, 108.84s/it]Evaluating commonsenseqa :  78%|█████████████████████████▋       | 49/63 [1:23:50<25:35, 109.69s/it]Evaluating commonsenseqa :  79%|██████████████████████████▉       | 50/63 [1:24:10<17:56, 82.82s/it]Evaluating commonsenseqa :  81%|███████████████████████████▌      | 51/63 [1:26:01<18:15, 91.33s/it]Evaluating commonsenseqa :  83%|████████████████████████████      | 52/63 [1:27:52<17:50, 97.32s/it]Evaluating commonsenseqa :  84%|████████████████████████████▌     | 53/63 [1:28:59<14:42, 88.24s/it]Evaluating commonsenseqa :  86%|█████████████████████████████▏    | 54/63 [1:30:50<14:16, 95.12s/it]Evaluating commonsenseqa :  87%|█████████████████████████████▋    | 55/63 [1:32:38<13:11, 98.98s/it]Evaluating commonsenseqa :  89%|██████████████████████████████▏   | 56/63 [1:33:59<10:53, 93.35s/it]Evaluating commonsenseqa :  90%|██████████████████████████████▊   | 57/63 [1:35:51<09:53, 98.92s/it]Evaluating commonsenseqa :  92%|███████████████████████████████▎  | 58/63 [1:36:24<06:36, 79.24s/it]Evaluating commonsenseqa :  94%|███████████████████████████████▊  | 59/63 [1:37:24<04:54, 73.59s/it]Evaluating commonsenseqa :  95%|████████████████████████████████▍ | 60/63 [1:39:15<04:14, 84.70s/it]Evaluating commonsenseqa :  97%|████████████████████████████████▉ | 61/63 [1:41:04<03:03, 91.97s/it]Evaluating commonsenseqa :  98%|█████████████████████████████████▍| 62/63 [1:42:24<01:28, 88.36s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████| 63/63 [1:43:25<00:00, 80.10s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████| 63/63 [1:43:25<00:00, 98.49s/it]
name: commonsenseqa | avg. gen lenth: 272.608 | time: 6205.34765124321s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o4-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 4
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-29 09:35:38,618] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-29 09:35:38,670] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-29 09:35:38,692] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-29 09:35:38,703] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o4-tgsm8k-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 4
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o4-tgsm8k-s10-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                                        | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████████████████████████| 9741/9741 [00:00<00:00, 945713.51it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.30s/it]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.38s/it]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.46s/it]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.52s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.20s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.66s/it]
Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.28s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.74s/it]
[2023-08-29 09:35:49,345] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.33s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.81s/it]
[2023-08-29 09:35:49,475] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.35s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.82s/it]
[2023-08-29 09:35:49,556] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
 > number of parameters: 6738415616
[2023-08-29 09:35:49,647] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-29 09:35:50,275] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-29 09:35:50,277] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-29 09:35:50,277] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-29 09:35:50,277] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-29 09:35:50,277] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-29 09:35:50,277] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-29 09:35:50,277] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-29 09:35:50,277] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-29 09:35:50,277] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-29 09:35:50,277] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-29 09:35:50,277] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-29 09:35:50,277] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fd20d27f520>
[2023-08-29 09:35:50,277] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-29 09:35:50,277] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-29 09:35:50,277] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-29 09:35:50,277] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-29 09:35:50,277] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-29 09:35:50,277] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-29 09:35:50,277] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-29 09:35:50,277] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-29 09:35:50,277] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-29 09:35:50,277] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-29 09:35:50,277] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-29 09:35:50,277] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-29 09:35:50,277] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-29 09:35:50,277] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-29 09:35:50,277] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-29 09:35:50,277] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-29 09:35:50,278] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-29 09:35:50,278] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                                             | 0/63 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: 30

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o4-tgsm8k-s10-rFalse-m4096
Evaluating commonsenseqa :   2%|▌                                 | 1/63 [01:47<1:51:25, 107.84s/it]Evaluating commonsenseqa :   3%|█                                 | 2/63 [03:35<1:49:27, 107.66s/it]Evaluating commonsenseqa :   5%|█▌                                | 3/63 [05:22<1:47:37, 107.63s/it]Evaluating commonsenseqa :   6%|██▏                               | 4/63 [06:57<1:40:46, 102.49s/it]Evaluating commonsenseqa :   8%|██▋                               | 5/63 [08:45<1:41:00, 104.50s/it]Evaluating commonsenseqa :  10%|███▏                              | 6/63 [10:32<1:40:05, 105.37s/it]Evaluating commonsenseqa :  11%|███▉                               | 7/63 [11:51<1:30:15, 96.71s/it]Evaluating commonsenseqa :  13%|████▎                             | 8/63 [13:39<1:32:00, 100.38s/it]Evaluating commonsenseqa :  14%|████▊                             | 9/63 [15:28<1:32:46, 103.08s/it]Evaluating commonsenseqa :  16%|█████▏                           | 10/63 [17:16<1:32:19, 104.51s/it]Evaluating commonsenseqa :  17%|█████▊                           | 11/63 [19:04<1:31:34, 105.67s/it]Evaluating commonsenseqa :  19%|██████▎                          | 12/63 [20:51<1:30:10, 106.09s/it]Evaluating commonsenseqa :  21%|███████                           | 13/63 [21:44<1:14:48, 89.77s/it]Evaluating commonsenseqa :  22%|███████▌                          | 14/63 [23:32<1:17:47, 95.26s/it]Evaluating commonsenseqa :  24%|████████                          | 15/63 [24:55<1:13:14, 91.55s/it]Evaluating commonsenseqa :  25%|████████▋                         | 16/63 [26:21<1:10:27, 89.96s/it]Evaluating commonsenseqa :  27%|█████████▏                        | 17/63 [27:22<1:02:25, 81.42s/it]Evaluating commonsenseqa :  29%|█████████▋                        | 18/63 [29:11<1:07:05, 89.46s/it]Evaluating commonsenseqa :  30%|██████████▎                       | 19/63 [30:58<1:09:35, 94.90s/it]Evaluating commonsenseqa :  32%|███████████▍                        | 20/63 [31:49<58:35, 81.76s/it]Evaluating commonsenseqa :  33%|████████████                        | 21/63 [32:10<44:27, 63.50s/it]Evaluating commonsenseqa :  35%|████████████▌                       | 22/63 [33:55<51:46, 75.77s/it]Evaluating commonsenseqa :  37%|█████████████▏                      | 23/63 [35:40<56:28, 84.71s/it]Evaluating commonsenseqa :  38%|█████████████▋                      | 24/63 [37:27<59:18, 91.24s/it]Evaluating commonsenseqa :  40%|█████████████▍                    | 25/63 [39:14<1:00:56, 96.22s/it]Evaluating commonsenseqa :  41%|██████████████                    | 26/63 [41:02<1:01:23, 99.55s/it]Evaluating commonsenseqa :  43%|██████████████▏                  | 27/63 [42:49<1:01:05, 101.81s/it]Evaluating commonsenseqa :  44%|██████████████▋                  | 28/63 [44:36<1:00:23, 103.51s/it]Evaluating commonsenseqa :  46%|████████████████▌                   | 29/63 [45:34<50:55, 89.87s/it]Evaluating commonsenseqa :  48%|█████████████████▏                  | 30/63 [46:37<45:00, 81.84s/it]Evaluating commonsenseqa :  49%|█████████████████▋                  | 31/63 [48:26<47:51, 89.74s/it]Evaluating commonsenseqa :  51%|██████████████████▎                 | 32/63 [50:14<49:19, 95.46s/it]Evaluating commonsenseqa :  52%|██████████████████▊                 | 33/63 [52:02<49:30, 99.01s/it]Evaluating commonsenseqa :  54%|██████████████████▉                | 34/63 [53:48<48:53, 101.15s/it]Evaluating commonsenseqa :  56%|███████████████████▍               | 35/63 [55:33<47:43, 102.28s/it]Evaluating commonsenseqa :  57%|████████████████████               | 36/63 [57:20<46:37, 103.63s/it]Evaluating commonsenseqa :  59%|████████████████████▌              | 37/63 [59:05<45:06, 104.11s/it]Evaluating commonsenseqa :  60%|███████████████████▉             | 38/63 [1:00:54<43:59, 105.59s/it]Evaluating commonsenseqa :  62%|█████████████████████             | 39/63 [1:02:19<39:48, 99.53s/it]Evaluating commonsenseqa :  63%|████████████████████▉            | 40/63 [1:04:07<39:05, 101.99s/it]Evaluating commonsenseqa :  65%|██████████████████████▏           | 41/63 [1:05:16<33:43, 91.97s/it]Evaluating commonsenseqa :  67%|██████████████████████▋           | 42/63 [1:07:04<33:57, 97.02s/it]Evaluating commonsenseqa :  68%|██████████████████████▌          | 43/63 [1:08:53<33:28, 100.43s/it]Evaluating commonsenseqa :  70%|███████████████████████▋          | 44/63 [1:09:51<27:48, 87.83s/it]Evaluating commonsenseqa :  71%|████████████████████████▎         | 45/63 [1:11:40<28:15, 94.17s/it]Evaluating commonsenseqa :  73%|████████████████████████▊         | 46/63 [1:12:42<23:56, 84.47s/it]Evaluating commonsenseqa :  75%|█████████████████████████▎        | 47/63 [1:14:08<22:38, 84.88s/it]Evaluating commonsenseqa :  76%|█████████████████████████▉        | 48/63 [1:15:53<22:42, 90.85s/it]Evaluating commonsenseqa :  78%|██████████████████████████▍       | 49/63 [1:17:41<22:23, 95.98s/it]Evaluating commonsenseqa :  79%|██████████████████████████▉       | 50/63 [1:19:28<21:31, 99.34s/it]Evaluating commonsenseqa :  81%|██████████████████████████▋      | 51/63 [1:21:17<20:26, 102.19s/it]Evaluating commonsenseqa :  83%|████████████████████████████      | 52/63 [1:22:02<15:37, 85.25s/it]Evaluating commonsenseqa :  84%|████████████████████████████▌     | 53/63 [1:23:51<15:23, 92.30s/it]Evaluating commonsenseqa :  86%|█████████████████████████████▏    | 54/63 [1:25:38<14:29, 96.56s/it]Evaluating commonsenseqa :  87%|█████████████████████████████▋    | 55/63 [1:27:25<13:19, 99.96s/it]Evaluating commonsenseqa :  89%|█████████████████████████████▎   | 56/63 [1:29:12<11:52, 101.82s/it]Evaluating commonsenseqa :  90%|█████████████████████████████▊   | 57/63 [1:30:56<10:16, 102.67s/it]Evaluating commonsenseqa :  92%|███████████████████████████████▎  | 58/63 [1:31:16<06:28, 77.69s/it]Evaluating commonsenseqa :  94%|███████████████████████████████▊  | 59/63 [1:33:06<05:49, 87.38s/it]Evaluating commonsenseqa :  95%|████████████████████████████████▍ | 60/63 [1:34:55<04:41, 93.87s/it]Evaluating commonsenseqa :  97%|████████████████████████████████▉ | 61/63 [1:36:43<03:16, 98.23s/it]Evaluating commonsenseqa :  98%|█████████████████████████████████▍| 62/63 [1:37:59<01:31, 91.70s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████| 63/63 [1:39:00<00:00, 82.38s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████| 63/63 [1:39:00<00:00, 94.30s/it]
name: commonsenseqa | avg. gen lenth: 255.516 | time: 5940.875900506973s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o5-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 5
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-29 11:17:12,135] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-29 11:17:12,155] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-29 11:17:12,157] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-29 11:17:12,171] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o5-tgsm8k-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 5
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o5-tgsm8k-s10-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                                        | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████████████████████████| 9741/9741 [00:00<00:00, 902033.72it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                              | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.24s/it]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.61s/it]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.59s/it]Loading checkpoint shards:  50%|███████████████████                   | 1/2 [00:07<00:07,  7.41s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.13s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.60s/it]
[2023-08-29 11:17:22,710] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.36s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.85s/it]
Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.31s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.78s/it]
Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.44s/it]Loading checkpoint shards: 100%|██████████████████████████████████████| 2/2 [00:09<00:00,  4.92s/it]
[2023-08-29 11:17:23,327] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-29 11:17:23,343] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
 > number of parameters: 6738415616
[2023-08-29 11:17:23,372] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-29 11:17:23,893] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-29 11:17:23,895] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-29 11:17:23,895] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-29 11:17:23,895] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-29 11:17:23,895] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-29 11:17:23,895] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f637683b520>
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-29 11:17:23,896] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-29 11:17:23,897] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-29 11:17:23,897] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-29 11:17:23,897] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-29 11:17:23,897] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-29 11:17:23,897] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-29 11:17:23,897] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-29 11:17:23,897] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-29 11:17:23,897] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-29 11:17:23,897] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-29 11:17:23,897] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-29 11:17:23,897] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-29 11:17:23,897] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-29 11:17:23,897] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-29 11:17:23,897] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-29 11:17:23,897] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-29 11:17:23,897] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-29 11:17:23,897] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-29 11:17:23,897] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-29 11:17:23,897] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-29 11:17:23,897] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-29 11:17:23,897] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-29 11:17:23,897] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-29 11:17:23,897] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-29 11:17:23,897] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                                             | 0/63 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: 868

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o5-tgsm8k-s10-rFalse-m4096
Evaluating commonsenseqa :   2%|▌                                 | 1/63 [01:47<1:50:59, 107.41s/it]Evaluating commonsenseqa :   3%|█                                 | 2/63 [03:31<1:47:19, 105.56s/it]Evaluating commonsenseqa :   5%|█▌                                | 3/63 [05:16<1:45:07, 105.13s/it]Evaluating commonsenseqa :   6%|██▏                               | 4/63 [07:01<1:43:15, 105.01s/it]Evaluating commonsenseqa :   8%|██▊                                | 5/63 [07:41<1:19:06, 81.84s/it]Evaluating commonsenseqa :  10%|███▎                               | 6/63 [09:26<1:25:09, 89.64s/it]Evaluating commonsenseqa :  11%|███▉                               | 7/63 [10:52<1:22:28, 88.37s/it]Evaluating commonsenseqa :  13%|████▍                              | 8/63 [12:38<1:26:06, 93.93s/it]Evaluating commonsenseqa :  14%|█████                              | 9/63 [14:24<1:27:55, 97.69s/it]Evaluating commonsenseqa :  16%|█████▏                           | 10/63 [16:09<1:28:27, 100.13s/it]Evaluating commonsenseqa :  17%|█████▊                           | 11/63 [17:52<1:27:34, 101.04s/it]Evaluating commonsenseqa :  19%|██████▎                          | 12/63 [19:37<1:26:49, 102.14s/it]Evaluating commonsenseqa :  21%|███████                           | 13/63 [20:50<1:17:43, 93.28s/it]Evaluating commonsenseqa :  22%|███████▌                          | 14/63 [22:35<1:19:03, 96.80s/it]Evaluating commonsenseqa :  24%|████████                          | 15/63 [23:47<1:11:30, 89.38s/it]Evaluating commonsenseqa :  25%|████████▋                         | 16/63 [24:58<1:05:42, 83.88s/it]Evaluating commonsenseqa :  27%|█████████▏                        | 17/63 [26:30<1:06:11, 86.35s/it]Evaluating commonsenseqa :  29%|█████████▋                        | 18/63 [28:14<1:08:46, 91.70s/it]Evaluating commonsenseqa :  30%|██████████▎                       | 19/63 [29:59<1:09:59, 95.44s/it]Evaluating commonsenseqa :  32%|██████████▊                       | 20/63 [31:44<1:10:26, 98.30s/it]Evaluating commonsenseqa :  33%|███████████                      | 21/63 [33:30<1:10:27, 100.65s/it]Evaluating commonsenseqa :  35%|███████████▊                      | 22/63 [35:01<1:06:52, 97.86s/it]Evaluating commonsenseqa :  37%|█████████████▏                      | 23/63 [36:01<57:42, 86.56s/it]Evaluating commonsenseqa :  38%|█████████████▋                      | 24/63 [37:45<59:40, 91.80s/it]Evaluating commonsenseqa :  40%|█████████████▍                    | 25/63 [39:29<1:00:20, 95.28s/it]Evaluating commonsenseqa :  41%|██████████████                    | 26/63 [41:14<1:00:41, 98.41s/it]Evaluating commonsenseqa :  43%|██████████████▏                  | 27/63 [43:00<1:00:23, 100.66s/it]Evaluating commonsenseqa :  44%|████████████████                    | 28/63 [44:26<56:06, 96.18s/it]Evaluating commonsenseqa :  46%|████████████████▌                   | 29/63 [46:11<55:56, 98.71s/it]