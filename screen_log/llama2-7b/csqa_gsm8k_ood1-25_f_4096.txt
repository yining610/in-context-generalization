torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:13:53,419] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:13:53,425] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:13:53,471] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:13:53,473] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 2
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:13:59,863] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:13:59,864] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:13:59,864] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:13:59,864] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o3-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 3
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:14:06,938] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:14:07,496] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:14:07,503] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:14:07,618] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o4-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 4
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:14:14,034] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:14:14,052] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:14:14,548] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:14:14,675] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o5-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 5
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:14:21,087] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:14:21,152] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-30 00:14:21,620] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:14:21,700] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 6
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:14:28,112] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-30 00:14:28,651] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:14:28,667] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:14:28,672] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...Answers already exist, exiting...

torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o7-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 7
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:14:35,198] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:14:35,713] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:14:35,725] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:14:35,725] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 8
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:14:43,384] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:14:43,396] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:14:43,467] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:14:43,491] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o9-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 9
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:14:49,813] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:14:49,813] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:14:50,110] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:14:50,363] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o10-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 10
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:14:56,777] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:14:57,275] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:14:57,302] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:14:57,332] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
Answers already exist, exiting...
Answers already exist, exiting...Answers already exist, exiting...

Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o11-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 11
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:15:03,843] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:15:03,913] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-30 00:15:04,374] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:15:04,412] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o12-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 12
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:15:10,865] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:15:10,916] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:15:11,402] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:15:11,418] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o13-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 13
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:15:17,710] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:15:17,831] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-30 00:15:18,269] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:15:18,291] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o14-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 14
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:15:24,941] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:15:24,954] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:15:25,463] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:15:25,473] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o15-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 15
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:15:31,942] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:15:31,942] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-30 00:15:32,475] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:15:32,507] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o16-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 16
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:15:38,978] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-30 00:15:39,448] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:15:39,491] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:15:39,535] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o17-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 17
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:15:45,876] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:15:45,876] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:15:46,393] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:15:46,475] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o18-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 18
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:15:52,909] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:15:52,910] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-30 00:15:53,446] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:15:53,467] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...Answers already exist, exiting...

torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o19-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 19
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:15:59,968] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:15:59,984] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-30 00:16:00,452] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:16:00,499] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o20-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 20
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:16:07,045] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:16:07,051] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:16:07,052] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-30 00:16:07,640] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...Answers already exist, exiting...

torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o21-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 21
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:16:14,040] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:16:14,047] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:16:14,047] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-30 00:16:14,567] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o22-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 22
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:16:20,990] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:16:20,991] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:16:20,991] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-30 00:16:21,523] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o23-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 23
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:16:28,092] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:16:28,555] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:16:28,617] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:16:28,637] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o24-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 24
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:16:35,168] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:16:35,212] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:16:35,699] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:16:35,711] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o25-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 25
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:16:42,125] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:16:42,126] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:16:42,630] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:16:42,642] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:16:49,095] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:16:49,223] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-30 00:16:49,749] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:16:49,749] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 2
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:16:56,284] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:16:56,299] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:16:56,763] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:16:56,814] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o3-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 3
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:17:03,258] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:17:03,258] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:17:03,264] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-30 00:17:03,787] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o4-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 4
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:17:10,246] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:17:10,248] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:17:10,774] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:17:10,794] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o5-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 5
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:17:17,349] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:17:17,360] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-30 00:17:17,878] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:17:17,878] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 6
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:17:24,386] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:17:24,386] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-30 00:17:24,907] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:17:24,912] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o7-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 7
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:17:31,451] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:17:31,451] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:17:31,465] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:17:31,983] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 8
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:17:38,478] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:17:38,960] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:17:39,024] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:17:39,057] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o9-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 9
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:17:45,413] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:17:45,518] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:17:45,523] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-30 00:17:46,022] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o10-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 10
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:17:52,300] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:17:52,522] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-30 00:17:52,955] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:17:52,989] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o11-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 11
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:17:59,492] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:18:00,024] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:18:00,024] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:18:00,057] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o12-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 12
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:18:06,569] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:18:06,569] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:18:06,580] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-30 00:18:07,097] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
Answers already exist, exiting...
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o13-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 13
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:18:13,619] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:18:13,619] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:18:13,666] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-30 00:18:14,187] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o13-tgsm8k-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 13
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o13-tgsm8k-s10-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████| 9741/9741 [00:00<00:00, 560571.80it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.68s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.75s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.85s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.98s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.42s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.91s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.48s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.97s/it]
[2023-08-30 00:18:25,343] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 00:18:25,431] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  4.56s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.06s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  4.60s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.11s/it]
 > number of parameters: 6738415616
[2023-08-30 00:18:25,709] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 00:18:25,753] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 00:18:26,344] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-30 00:18:26,345] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-30 00:18:26,346] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-30 00:18:26,346] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-30 00:18:26,346] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-30 00:18:26,346] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-30 00:18:26,346] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-30 00:18:26,346] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-30 00:18:26,346] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-30 00:18:26,346] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-30 00:18:26,346] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-30 00:18:26,346] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f0f371c52d0>
[2023-08-30 00:18:26,346] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-30 00:18:26,346] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-30 00:18:26,346] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-30 00:18:26,346] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-30 00:18:26,346] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-30 00:18:26,346] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-30 00:18:26,346] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-30 00:18:26,346] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-30 00:18:26,346] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-30 00:18:26,346] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-30 00:18:26,346] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-30 00:18:26,346] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-30 00:18:26,346] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-30 00:18:26,346] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-30 00:18:26,346] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-30 00:18:26,346] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-30 00:18:26,346] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-30 00:18:26,346] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-30 00:18:26,346] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-30 00:18:26,347] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-30 00:18:26,347] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: 868

Input: Stella and Twinkle are filling up a truck with a capacity of 6000 stone blocks at the rate of 250 blocks per hour per person. They work for four hours and are then joined by 6 other people who also work at the same rate. How many hours did filling the truck take?
Output: 6

Input: Elijah drank 8.5 pints of coffee yesterday. Emilio drank 9.5 pints of water yesterday. How many cups of liquid did the two boys drink yesterday?
Output: 36

Input: Doris works at the Widget Factory in the packing department. She puts 3 widgets in each carton, which are 4 inches wide, 4 inches long, and 5 inches tall. She then packs those cartons into a shipping box before sending it to the loading bay. The shipping boxes are 20 inches wide, 20 inches long, and 20 inches high. How many widgets get shipped in each shipping box?
Output: 300

Input: Queenie earns $150 a day as a part-time clerk. She earns an additional $5 per hour as overtime pay. How much will Queenie receive for working 5 days with 4 hours overtime?
Output: 770

Input: Jodi starts off walking 1 mile a day for 6 days a week.  On the second week, she walks 2 miles a day, 6 days a week.  On the third week, she walks 3 miles a day, 6 days a week. Finally on the fourth week, she walks 4 miles a day, 6 days a week.  How many miles has she walked in 4 weeks?
Output: 60

Input: A club is going to get additional members so that they will have 5 more than twice their current number of their members. If the club has 10 members now, how many additional members do they need?
Output: 15

Input: Andrea buys herself a pony for her 30th birthday. She pays $500/month to rent a pasture for it, $10 a day for food, and $60/lesson for two lessons a week. How much does she spend on her pony in a year?
Output: 15890

Input: A pet shop has 2 puppies and some kittens. A puppy costs $20, and a kitten costs $15. If the stock is worth $100, how many kittens does the pet shop have?
Output: 4

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o13-tgsm8k-s10-rFalse-m4096
Evaluating commonsenseqa :   2%|▎             | 1/50 [01:50<1:30:34, 110.91s/it]Evaluating commonsenseqa :   4%|▌             | 2/50 [03:38<1:27:16, 109.09s/it]Evaluating commonsenseqa :   6%|▊             | 3/50 [05:27<1:25:23, 109.00s/it]Evaluating commonsenseqa :   8%|█             | 4/50 [07:17<1:23:45, 109.24s/it]Evaluating commonsenseqa :  10%|█▍            | 5/50 [09:06<1:21:50, 109.13s/it]Evaluating commonsenseqa :  12%|█▋            | 6/50 [10:54<1:19:54, 108.97s/it]Evaluating commonsenseqa :  14%|█▉            | 7/50 [12:43<1:18:01, 108.87s/it]Evaluating commonsenseqa :  16%|██▏           | 8/50 [14:32<1:16:20, 109.07s/it]Evaluating commonsenseqa :  18%|██▌           | 9/50 [16:12<1:12:29, 106.08s/it]Evaluating commonsenseqa :  20%|██▌          | 10/50 [17:59<1:10:52, 106.31s/it]Evaluating commonsenseqa :  22%|██▊          | 11/50 [19:47<1:09:30, 106.93s/it]Evaluating commonsenseqa :  24%|███          | 12/50 [21:35<1:07:52, 107.16s/it]Evaluating commonsenseqa :  26%|███▍         | 13/50 [23:23<1:06:13, 107.38s/it]Evaluating commonsenseqa :  28%|███▋         | 14/50 [25:12<1:04:43, 107.87s/it]Evaluating commonsenseqa :  30%|███▉         | 15/50 [27:01<1:03:10, 108.29s/it]Evaluating commonsenseqa :  32%|████▏        | 16/50 [28:42<1:00:03, 105.99s/it]Evaluating commonsenseqa :  34%|█████          | 17/50 [30:32<59:04, 107.40s/it]Evaluating commonsenseqa :  36%|█████▍         | 18/50 [32:22<57:41, 108.18s/it]Evaluating commonsenseqa :  38%|█████▋         | 19/50 [34:13<56:14, 108.84s/it]Evaluating commonsenseqa :  40%|██████         | 20/50 [36:00<54:15, 108.52s/it]Evaluating commonsenseqa :  42%|██████▎        | 21/50 [37:49<52:25, 108.48s/it]Evaluating commonsenseqa :  44%|██████▌        | 22/50 [39:36<50:29, 108.18s/it]Evaluating commonsenseqa :  46%|██████▉        | 23/50 [41:24<48:33, 107.91s/it]Evaluating commonsenseqa :  48%|███████▏       | 24/50 [43:12<46:47, 107.98s/it]Evaluating commonsenseqa :  50%|████████        | 25/50 [44:07<38:22, 92.09s/it]Evaluating commonsenseqa :  52%|████████▎       | 26/50 [45:56<38:53, 97.21s/it]Evaluating commonsenseqa :  54%|████████       | 27/50 [47:44<38:30, 100.47s/it]Evaluating commonsenseqa :  56%|████████▍      | 28/50 [49:33<37:45, 102.97s/it]Evaluating commonsenseqa :  58%|████████▋      | 29/50 [51:22<36:38, 104.70s/it]Evaluating commonsenseqa :  60%|█████████      | 30/50 [53:11<35:21, 106.06s/it]Evaluating commonsenseqa :  62%|█████████▎     | 31/50 [54:59<33:46, 106.68s/it]Evaluating commonsenseqa :  64%|█████████▌     | 32/50 [56:48<32:11, 107.32s/it]Evaluating commonsenseqa :  66%|██████████▌     | 33/50 [58:06<27:54, 98.53s/it]Evaluating commonsenseqa :  68%|██████████▏    | 34/50 [59:53<26:59, 101.22s/it]Evaluating commonsenseqa :  70%|█████████    | 35/50 [1:01:46<26:09, 104.66s/it]Evaluating commonsenseqa :  72%|█████████▎   | 36/50 [1:03:34<24:41, 105.82s/it]Evaluating commonsenseqa :  74%|██████████▎   | 37/50 [1:04:44<20:33, 94.90s/it]Evaluating commonsenseqa :  76%|██████████▋   | 38/50 [1:05:29<16:00, 80.04s/it]Evaluating commonsenseqa :  78%|██████████▉   | 39/50 [1:07:20<16:20, 89.10s/it]Evaluating commonsenseqa :  80%|███████████▏  | 40/50 [1:09:09<15:51, 95.20s/it]Evaluating commonsenseqa :  82%|███████████▍  | 41/50 [1:10:56<14:49, 98.80s/it]Evaluating commonsenseqa :  84%|██████████▉  | 42/50 [1:12:45<13:33, 101.74s/it]Evaluating commonsenseqa :  86%|███████████▏ | 43/50 [1:14:33<12:05, 103.71s/it]Evaluating commonsenseqa :  88%|███████████▍ | 44/50 [1:16:20<10:27, 104.65s/it]Evaluating commonsenseqa :  90%|████████████▌ | 45/50 [1:17:24<07:41, 92.34s/it]Evaluating commonsenseqa :  92%|████████████▉ | 46/50 [1:18:58<06:12, 93.06s/it]Evaluating commonsenseqa :  94%|█████████████▏| 47/50 [1:20:47<04:53, 97.87s/it]Evaluating commonsenseqa :  96%|████████████▍| 48/50 [1:22:38<03:23, 101.86s/it]Evaluating commonsenseqa :  98%|████████████▋| 49/50 [1:24:25<01:43, 103.10s/it]Evaluating commonsenseqa : 100%|█████████████| 50/50 [1:26:13<00:00, 104.87s/it]Evaluating commonsenseqa : 100%|█████████████| 50/50 [1:26:13<00:00, 103.48s/it]
name: commonsenseqa | avg. gen lenth: 282.8 | time: 5174.3274874687195s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o14-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 14
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 01:45:36,813] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 01:45:36,815] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 01:45:36,833] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 01:45:36,849] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o14-tgsm8k-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 14
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o14-tgsm8k-s10-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████| 9741/9741 [00:00<00:00, 567572.62it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:06<00:06,  6.60s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.29s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.33s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  3.89s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  4.30s/it]
[2023-08-30 01:45:46,811] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards:  50%|█████████         | 1/2 [00:09<00:09,  9.28s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.43s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.86s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.44s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.87s/it]
[2023-08-30 01:45:47,943] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 01:45:48,009] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  4.97s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  5.62s/it]
 > number of parameters: 6738415616
[2023-08-30 01:45:49,500] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 01:45:50,008] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-30 01:45:50,010] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-30 01:45:50,010] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-30 01:45:50,010] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-30 01:45:50,010] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-30 01:45:50,010] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-30 01:45:50,010] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-30 01:45:50,010] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-30 01:45:50,010] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-30 01:45:50,010] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-30 01:45:50,010] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-30 01:45:50,010] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f03743c5300>
[2023-08-30 01:45:50,010] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-30 01:45:50,010] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-30 01:45:50,011] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-30 01:45:50,012] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-30 01:45:50,012] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-30 01:45:50,012] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-30 01:45:50,012] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-30 01:45:50,012] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-30 01:45:50,012] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-30 01:45:50,012] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-30 01:45:50,012] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: 868

Input: Stella and Twinkle are filling up a truck with a capacity of 6000 stone blocks at the rate of 250 blocks per hour per person. They work for four hours and are then joined by 6 other people who also work at the same rate. How many hours did filling the truck take?
Output: 6

Input: Elijah drank 8.5 pints of coffee yesterday. Emilio drank 9.5 pints of water yesterday. How many cups of liquid did the two boys drink yesterday?
Output: 36

Input: Doris works at the Widget Factory in the packing department. She puts 3 widgets in each carton, which are 4 inches wide, 4 inches long, and 5 inches tall. She then packs those cartons into a shipping box before sending it to the loading bay. The shipping boxes are 20 inches wide, 20 inches long, and 20 inches high. How many widgets get shipped in each shipping box?
Output: 300

Input: Queenie earns $150 a day as a part-time clerk. She earns an additional $5 per hour as overtime pay. How much will Queenie receive for working 5 days with 4 hours overtime?
Output: 770

Input: Jodi starts off walking 1 mile a day for 6 days a week.  On the second week, she walks 2 miles a day, 6 days a week.  On the third week, she walks 3 miles a day, 6 days a week. Finally on the fourth week, she walks 4 miles a day, 6 days a week.  How many miles has she walked in 4 weeks?
Output: 60

Input: A club is going to get additional members so that they will have 5 more than twice their current number of their members. If the club has 10 members now, how many additional members do they need?
Output: 15

Input: Andrea buys herself a pony for her 30th birthday. She pays $500/month to rent a pasture for it, $10 a day for food, and $60/lesson for two lessons a week. How much does she spend on her pony in a year?
Output: 15890

Input: A pet shop has 2 puppies and some kittens. A puppy costs $20, and a kitten costs $15. If the stock is worth $100, how many kittens does the pet shop have?
Output: 4

Input: Noah, who loves his Grammy, calls her every week to talk about his day. If each call lasts 30 minutes and he is charged $0.05 per call minute, how much would he be billed if he makes the calls for a year?
Output: 78

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o14-tgsm8k-s10-rFalse-m4096
Evaluating commonsenseqa :   2%|▎                | 1/50 [01:09<57:04, 69.88s/it]Evaluating commonsenseqa :   4%|▌              | 2/50 [02:55<1:12:39, 90.82s/it]Evaluating commonsenseqa :   6%|▉              | 3/50 [04:43<1:17:24, 98.81s/it]Evaluating commonsenseqa :   8%|█             | 4/50 [06:29<1:17:50, 101.53s/it]Evaluating commonsenseqa :  10%|█▍            | 5/50 [08:15<1:17:25, 103.23s/it]Evaluating commonsenseqa :  12%|█▋            | 6/50 [10:01<1:16:22, 104.15s/it]Evaluating commonsenseqa :  14%|██             | 7/50 [11:04<1:05:04, 90.80s/it]Evaluating commonsenseqa :  16%|██▍            | 8/50 [12:51<1:06:58, 95.68s/it]Evaluating commonsenseqa :  18%|██▋            | 9/50 [14:35<1:07:18, 98.49s/it]Evaluating commonsenseqa :  20%|██▌          | 10/50 [16:21<1:07:10, 100.77s/it]Evaluating commonsenseqa :  22%|██▊          | 11/50 [18:09<1:06:57, 103.02s/it]Evaluating commonsenseqa :  24%|███▊            | 12/50 [18:52<53:35, 84.63s/it]Evaluating commonsenseqa :  26%|████▏           | 13/50 [20:39<56:21, 91.40s/it]Evaluating commonsenseqa :  28%|████▍           | 14/50 [22:25<57:34, 95.97s/it]Evaluating commonsenseqa :  30%|████▊           | 15/50 [24:10<57:28, 98.53s/it]Evaluating commonsenseqa :  32%|████▊          | 16/50 [25:54<56:53, 100.39s/it]Evaluating commonsenseqa :  34%|█████          | 17/50 [27:41<56:12, 102.21s/it]Evaluating commonsenseqa :  36%|█████▊          | 18/50 [29:11<52:32, 98.52s/it]Evaluating commonsenseqa :  38%|██████          | 19/50 [30:48<50:38, 98.01s/it]Evaluating commonsenseqa :  40%|██████         | 20/50 [32:32<50:01, 100.05s/it]Evaluating commonsenseqa :  42%|██████▎        | 21/50 [34:18<49:06, 101.62s/it]Evaluating commonsenseqa :  44%|██████▌        | 22/50 [36:01<47:40, 102.17s/it]Evaluating commonsenseqa :  46%|██████▉        | 23/50 [37:45<46:12, 102.70s/it]Evaluating commonsenseqa :  48%|███████▏       | 24/50 [39:30<44:44, 103.25s/it]Evaluating commonsenseqa :  50%|███████▌       | 25/50 [41:15<43:18, 103.95s/it]Evaluating commonsenseqa :  52%|███████▊       | 26/50 [42:59<41:34, 103.95s/it]Evaluating commonsenseqa :  54%|████████       | 27/50 [44:45<40:05, 104.58s/it]Evaluating commonsenseqa :  56%|████████▍      | 28/50 [46:30<38:18, 104.50s/it]Evaluating commonsenseqa :  58%|████████▋      | 29/50 [48:16<36:49, 105.21s/it]Evaluating commonsenseqa :  60%|█████████      | 30/50 [50:01<35:03, 105.17s/it]Evaluating commonsenseqa :  62%|█████████▎     | 31/50 [51:46<33:12, 104.86s/it]Evaluating commonsenseqa :  64%|█████████▌     | 32/50 [53:31<31:30, 105.04s/it]Evaluating commonsenseqa :  66%|██████████▌     | 33/50 [54:36<26:23, 93.16s/it]Evaluating commonsenseqa :  68%|██████████▉     | 34/50 [56:24<25:59, 97.49s/it]Evaluating commonsenseqa :  70%|███████████▏    | 35/50 [58:09<24:54, 99.62s/it]Evaluating commonsenseqa :  72%|██████████▊    | 36/50 [59:52<23:29, 100.65s/it]Evaluating commonsenseqa :  74%|█████████▌   | 37/50 [1:01:39<22:12, 102.53s/it]Evaluating commonsenseqa :  76%|█████████▉   | 38/50 [1:03:24<20:40, 103.40s/it]Evaluating commonsenseqa :  78%|██████████▏  | 39/50 [1:05:11<19:08, 104.44s/it]Evaluating commonsenseqa :  80%|██████████▍  | 40/50 [1:06:58<17:33, 105.34s/it]Evaluating commonsenseqa :  82%|██████████▋  | 41/50 [1:08:43<15:47, 105.24s/it]Evaluating commonsenseqa :  84%|██████████▉  | 42/50 [1:10:29<14:03, 105.46s/it]Evaluating commonsenseqa :  86%|███████████▏ | 43/50 [1:12:17<12:21, 105.99s/it]Evaluating commonsenseqa :  88%|███████████▍ | 44/50 [1:14:02<10:34, 105.79s/it]Evaluating commonsenseqa :  90%|███████████▋ | 45/50 [1:15:48<08:49, 105.98s/it]Evaluating commonsenseqa :  92%|███████████▉ | 46/50 [1:17:29<06:57, 104.42s/it]Evaluating commonsenseqa :  94%|█████████████▏| 47/50 [1:18:16<04:21, 87.11s/it]Evaluating commonsenseqa :  96%|█████████████▍| 48/50 [1:20:00<03:04, 92.19s/it]Evaluating commonsenseqa :  98%|█████████████▋| 49/50 [1:21:09<01:25, 85.17s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:22:56<00:00, 91.93s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:22:56<00:00, 99.54s/it]
name: commonsenseqa | avg. gen lenth: 289.06 | time: 4977.256418228149s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o15-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 15
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 03:13:04,570] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 03:13:04,574] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 03:13:04,600] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 03:13:04,628] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o15-tgsm8k-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 15
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o15-tgsm8k-s10-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████| 9741/9741 [00:00<00:00, 554914.84it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.41s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.43s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.49s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.52s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.25s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.73s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.25s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.73s/it]
[2023-08-30 03:13:15,401] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
 > number of parameters: 6738415616
[2023-08-30 03:13:15,414] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.36s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.83s/it]
[2023-08-30 03:13:15,594] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.44s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.90s/it]
[2023-08-30 03:13:15,747] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 03:13:16,336] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-30 03:13:16,337] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-30 03:13:16,337] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-30 03:13:16,337] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-30 03:13:16,337] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-30 03:13:16,337] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f5330fd1300>
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-30 03:13:16,338] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-30 03:13:16,339] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-30 03:13:16,339] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-30 03:13:16,339] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-30 03:13:16,339] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-30 03:13:16,339] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-30 03:13:16,339] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-30 03:13:16,339] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-30 03:13:16,339] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-30 03:13:16,339] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-30 03:13:16,339] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-30 03:13:16,339] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-30 03:13:16,339] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-30 03:13:16,339] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-30 03:13:16,339] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-30 03:13:16,339] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-30 03:13:16,339] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-30 03:13:16,339] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-30 03:13:16,339] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-30 03:13:16,339] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: 868

Input: Stella and Twinkle are filling up a truck with a capacity of 6000 stone blocks at the rate of 250 blocks per hour per person. They work for four hours and are then joined by 6 other people who also work at the same rate. How many hours did filling the truck take?
Output: 6

Input: Elijah drank 8.5 pints of coffee yesterday. Emilio drank 9.5 pints of water yesterday. How many cups of liquid did the two boys drink yesterday?
Output: 36

Input: Doris works at the Widget Factory in the packing department. She puts 3 widgets in each carton, which are 4 inches wide, 4 inches long, and 5 inches tall. She then packs those cartons into a shipping box before sending it to the loading bay. The shipping boxes are 20 inches wide, 20 inches long, and 20 inches high. How many widgets get shipped in each shipping box?
Output: 300

Input: Queenie earns $150 a day as a part-time clerk. She earns an additional $5 per hour as overtime pay. How much will Queenie receive for working 5 days with 4 hours overtime?
Output: 770

Input: Jodi starts off walking 1 mile a day for 6 days a week.  On the second week, she walks 2 miles a day, 6 days a week.  On the third week, she walks 3 miles a day, 6 days a week. Finally on the fourth week, she walks 4 miles a day, 6 days a week.  How many miles has she walked in 4 weeks?
Output: 60

Input: A club is going to get additional members so that they will have 5 more than twice their current number of their members. If the club has 10 members now, how many additional members do they need?
Output: 15

Input: Andrea buys herself a pony for her 30th birthday. She pays $500/month to rent a pasture for it, $10 a day for food, and $60/lesson for two lessons a week. How much does she spend on her pony in a year?
Output: 15890

Input: A pet shop has 2 puppies and some kittens. A puppy costs $20, and a kitten costs $15. If the stock is worth $100, how many kittens does the pet shop have?
Output: 4

Input: Noah, who loves his Grammy, calls her every week to talk about his day. If each call lasts 30 minutes and he is charged $0.05 per call minute, how much would he be billed if he makes the calls for a year?
Output: 78

Input: A merchant bought 15 keyboards and 25 printers for a total of $2050. If a keyboard costs $20, how much does a printer cost?
Output: 70

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o15-tgsm8k-s10-rFalse-m4096
Evaluating commonsenseqa :   2%|▎             | 1/50 [01:47<1:27:29, 107.14s/it]Evaluating commonsenseqa :   4%|▌             | 2/50 [03:31<1:24:17, 105.36s/it]Evaluating commonsenseqa :   6%|▊             | 3/50 [05:13<1:21:21, 103.85s/it]Evaluating commonsenseqa :   8%|█             | 4/50 [06:58<1:19:57, 104.29s/it]Evaluating commonsenseqa :  10%|█▌             | 5/50 [08:06<1:08:32, 91.38s/it]Evaluating commonsenseqa :  12%|█▊             | 6/50 [09:52<1:10:28, 96.10s/it]Evaluating commonsenseqa :  14%|██             | 7/50 [11:38<1:11:12, 99.37s/it]Evaluating commonsenseqa :  16%|██▍            | 8/50 [13:14<1:08:52, 98.39s/it]Evaluating commonsenseqa :  18%|██▋            | 9/50 [14:57<1:08:15, 99.89s/it]Evaluating commonsenseqa :  20%|██▌          | 10/50 [16:42<1:07:35, 101.38s/it]Evaluating commonsenseqa :  22%|██▊          | 11/50 [18:25<1:06:18, 102.02s/it]Evaluating commonsenseqa :  24%|███          | 12/50 [20:07<1:04:34, 101.95s/it]Evaluating commonsenseqa :  26%|███▍         | 13/50 [21:51<1:03:18, 102.66s/it]Evaluating commonsenseqa :  28%|███▋         | 14/50 [23:37<1:02:07, 103.54s/it]Evaluating commonsenseqa :  30%|████▌          | 15/50 [25:11<58:40, 100.60s/it]Evaluating commonsenseqa :  32%|████▊          | 16/50 [26:54<57:30, 101.49s/it]Evaluating commonsenseqa :  34%|█████          | 17/50 [28:38<56:14, 102.27s/it]Evaluating commonsenseqa :  36%|█████▍         | 18/50 [30:23<54:57, 103.04s/it]Evaluating commonsenseqa :  38%|██████          | 19/50 [31:16<45:28, 88.01s/it]Evaluating commonsenseqa :  40%|██████▍         | 20/50 [33:02<46:39, 93.30s/it]Evaluating commonsenseqa :  42%|██████▋         | 21/50 [34:30<44:20, 91.76s/it]Evaluating commonsenseqa :  44%|███████         | 22/50 [36:13<44:26, 95.22s/it]Evaluating commonsenseqa :  46%|███████▎        | 23/50 [37:58<44:05, 97.99s/it]Evaluating commonsenseqa :  48%|███████▏       | 24/50 [39:43<43:25, 100.20s/it]Evaluating commonsenseqa :  50%|███████▌       | 25/50 [41:28<42:20, 101.60s/it]Evaluating commonsenseqa :  52%|███████▊       | 26/50 [43:15<41:19, 103.30s/it]Evaluating commonsenseqa :  54%|████████       | 27/50 [44:58<39:33, 103.18s/it]Evaluating commonsenseqa :  56%|████████▍      | 28/50 [46:44<38:08, 104.04s/it]Evaluating commonsenseqa :  58%|█████████▎      | 29/50 [47:44<31:48, 90.89s/it]Evaluating commonsenseqa :  60%|█████████▌      | 30/50 [49:28<31:31, 94.59s/it]Evaluating commonsenseqa :  62%|█████████▉      | 31/50 [51:11<30:46, 97.18s/it]Evaluating commonsenseqa :  64%|█████████▌     | 32/50 [52:58<30:02, 100.12s/it]Evaluating commonsenseqa :  66%|█████████▉     | 33/50 [54:43<28:50, 101.78s/it]Evaluating commonsenseqa :  68%|██████████▏    | 34/50 [56:29<27:25, 102.86s/it]Evaluating commonsenseqa :  70%|███████████▏    | 35/50 [58:00<24:51, 99.45s/it]Evaluating commonsenseqa :  72%|██████████▊    | 36/50 [59:47<23:40, 101.47s/it]Evaluating commonsenseqa :  74%|█████████▌   | 37/50 [1:01:31<22:10, 102.34s/it]Evaluating commonsenseqa :  76%|█████████▉   | 38/50 [1:03:14<20:30, 102.57s/it]Evaluating commonsenseqa :  78%|██████████▏  | 39/50 [1:04:58<18:52, 102.99s/it]Evaluating commonsenseqa :  80%|██████████▍  | 40/50 [1:06:41<17:09, 102.99s/it]Evaluating commonsenseqa :  82%|██████████▋  | 41/50 [1:08:26<15:32, 103.59s/it]Evaluating commonsenseqa :  84%|██████████▉  | 42/50 [1:10:10<13:48, 103.59s/it]Evaluating commonsenseqa :  86%|███████████▏ | 43/50 [1:11:53<12:05, 103.63s/it]Evaluating commonsenseqa :  88%|████████████▎ | 44/50 [1:13:09<09:32, 95.39s/it]Evaluating commonsenseqa :  90%|████████████▌ | 45/50 [1:14:54<08:10, 98.13s/it]Evaluating commonsenseqa :  92%|████████████▉ | 46/50 [1:16:38<06:39, 99.95s/it]Evaluating commonsenseqa :  94%|████████████▏| 47/50 [1:18:24<05:05, 101.86s/it]Evaluating commonsenseqa :  96%|████████████▍| 48/50 [1:20:08<03:24, 102.48s/it]Evaluating commonsenseqa :  98%|████████████▋| 49/50 [1:21:52<01:42, 102.79s/it]Evaluating commonsenseqa : 100%|█████████████| 50/50 [1:23:33<00:00, 102.32s/it]Evaluating commonsenseqa : 100%|█████████████| 50/50 [1:23:33<00:00, 100.27s/it]
name: commonsenseqa | avg. gen lenth: 277.084 | time: 5013.974562168121s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o16-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 16
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 04:39:06,715] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 04:39:07,208] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 04:39:07,216] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 04:39:07,265] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o16-tgsm8k-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 16
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o16-tgsm8k-s10-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████| 9741/9741 [00:00<00:00, 536107.01it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.10s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.19s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:08<00:08,  8.31s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:08<00:08,  8.68s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.15s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.59s/it]
 > number of parameters: 6738415616
[2023-08-30 04:39:17,844] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.29s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.72s/it]
[2023-08-30 04:39:18,104] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  4.62s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.17s/it]
[2023-08-30 04:39:18,979] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  4.74s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.33s/it]
[2023-08-30 04:39:19,305] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 04:39:19,892] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-30 04:39:19,894] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f982dfc9300>
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-30 04:39:19,894] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-30 04:39:19,895] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-30 04:39:19,895] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: 868

Input: Stella and Twinkle are filling up a truck with a capacity of 6000 stone blocks at the rate of 250 blocks per hour per person. They work for four hours and are then joined by 6 other people who also work at the same rate. How many hours did filling the truck take?
Output: 6

Input: Elijah drank 8.5 pints of coffee yesterday. Emilio drank 9.5 pints of water yesterday. How many cups of liquid did the two boys drink yesterday?
Output: 36

Input: Doris works at the Widget Factory in the packing department. She puts 3 widgets in each carton, which are 4 inches wide, 4 inches long, and 5 inches tall. She then packs those cartons into a shipping box before sending it to the loading bay. The shipping boxes are 20 inches wide, 20 inches long, and 20 inches high. How many widgets get shipped in each shipping box?
Output: 300

Input: Queenie earns $150 a day as a part-time clerk. She earns an additional $5 per hour as overtime pay. How much will Queenie receive for working 5 days with 4 hours overtime?
Output: 770

Input: Jodi starts off walking 1 mile a day for 6 days a week.  On the second week, she walks 2 miles a day, 6 days a week.  On the third week, she walks 3 miles a day, 6 days a week. Finally on the fourth week, she walks 4 miles a day, 6 days a week.  How many miles has she walked in 4 weeks?
Output: 60

Input: A club is going to get additional members so that they will have 5 more than twice their current number of their members. If the club has 10 members now, how many additional members do they need?
Output: 15

Input: Andrea buys herself a pony for her 30th birthday. She pays $500/month to rent a pasture for it, $10 a day for food, and $60/lesson for two lessons a week. How much does she spend on her pony in a year?
Output: 15890

Input: A pet shop has 2 puppies and some kittens. A puppy costs $20, and a kitten costs $15. If the stock is worth $100, how many kittens does the pet shop have?
Output: 4

Input: Noah, who loves his Grammy, calls her every week to talk about his day. If each call lasts 30 minutes and he is charged $0.05 per call minute, how much would he be billed if he makes the calls for a year?
Output: 78

Input: A merchant bought 15 keyboards and 25 printers for a total of $2050. If a keyboard costs $20, how much does a printer cost?
Output: 70

Input: Gina has two bank accounts. Each account has a quarter of the balance in Betty's account. If Betty's account balance is $3,456, what is the combined balance of both Gina's accounts?
Output: 1728

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o16-tgsm8k-s10-rFalse-m4096
Evaluating commonsenseqa :   2%|▎             | 1/50 [01:45<1:26:19, 105.70s/it]Evaluating commonsenseqa :   4%|▌             | 2/50 [03:28<1:23:03, 103.83s/it]Evaluating commonsenseqa :   6%|▊             | 3/50 [05:10<1:20:44, 103.08s/it]Evaluating commonsenseqa :   8%|█             | 4/50 [06:52<1:18:50, 102.85s/it]Evaluating commonsenseqa :  10%|█▍            | 5/50 [08:37<1:17:37, 103.50s/it]Evaluating commonsenseqa :  12%|█▋            | 6/50 [10:21<1:15:57, 103.58s/it]Evaluating commonsenseqa :  14%|█▉            | 7/50 [11:56<1:12:17, 100.88s/it]Evaluating commonsenseqa :  16%|██▏           | 8/50 [13:39<1:10:57, 101.38s/it]Evaluating commonsenseqa :  18%|██▌           | 9/50 [15:20<1:09:12, 101.28s/it]Evaluating commonsenseqa :  20%|██▌          | 10/50 [17:02<1:07:46, 101.66s/it]Evaluating commonsenseqa :  22%|██▊          | 11/50 [18:44<1:06:12, 101.85s/it]Evaluating commonsenseqa :  24%|███          | 12/50 [20:26<1:04:31, 101.87s/it]Evaluating commonsenseqa :  26%|███▍         | 13/50 [22:08<1:02:42, 101.68s/it]Evaluating commonsenseqa :  28%|███▋         | 14/50 [23:49<1:00:57, 101.60s/it]Evaluating commonsenseqa :  30%|████▌          | 15/50 [25:30<59:10, 101.45s/it]Evaluating commonsenseqa :  32%|████▊          | 16/50 [27:12<57:37, 101.69s/it]Evaluating commonsenseqa :  34%|█████▍          | 17/50 [28:48<54:52, 99.77s/it]Evaluating commonsenseqa :  36%|█████▍         | 18/50 [30:30<53:36, 100.52s/it]Evaluating commonsenseqa :  38%|██████          | 19/50 [31:57<49:50, 96.48s/it]Evaluating commonsenseqa :  40%|██████▍         | 20/50 [33:38<48:57, 97.92s/it]Evaluating commonsenseqa :  42%|██████▋         | 21/50 [35:17<47:31, 98.32s/it]Evaluating commonsenseqa :  44%|██████▌        | 22/50 [37:02<46:41, 100.04s/it]Evaluating commonsenseqa :  46%|██████▉        | 23/50 [38:42<45:04, 100.15s/it]Evaluating commonsenseqa :  48%|███████▏       | 24/50 [40:23<43:32, 100.49s/it]Evaluating commonsenseqa :  50%|███████▌       | 25/50 [42:04<41:53, 100.53s/it]Evaluating commonsenseqa :  52%|███████▊       | 26/50 [43:46<40:27, 101.13s/it]Evaluating commonsenseqa :  54%|████████       | 27/50 [45:28<38:46, 101.15s/it]Evaluating commonsenseqa :  56%|████████▍      | 28/50 [47:10<37:14, 101.55s/it]Evaluating commonsenseqa :  58%|████████▋      | 29/50 [48:51<35:31, 101.51s/it]Evaluating commonsenseqa :  60%|█████████      | 30/50 [50:33<33:51, 101.59s/it]Evaluating commonsenseqa :  62%|█████████▎     | 31/50 [52:14<32:03, 101.22s/it]Evaluating commonsenseqa :  64%|█████████▌     | 32/50 [53:56<30:27, 101.55s/it]Evaluating commonsenseqa :  66%|█████████▉     | 33/50 [55:39<28:54, 102.02s/it]Evaluating commonsenseqa :  68%|██████████▏    | 34/50 [57:20<27:09, 101.82s/it]Evaluating commonsenseqa :  70%|██████████▌    | 35/50 [59:01<25:21, 101.46s/it]Evaluating commonsenseqa :  72%|█████████▎   | 36/50 [1:00:41<23:36, 101.15s/it]Evaluating commonsenseqa :  74%|█████████▌   | 37/50 [1:02:23<21:54, 101.14s/it]Evaluating commonsenseqa :  76%|█████████▉   | 38/50 [1:04:04<20:14, 101.25s/it]Evaluating commonsenseqa :  78%|██████████▏  | 39/50 [1:05:47<18:38, 101.70s/it]Evaluating commonsenseqa :  80%|██████████▍  | 40/50 [1:07:31<17:05, 102.50s/it]Evaluating commonsenseqa :  82%|███████████▍  | 41/50 [1:08:00<12:04, 80.45s/it]Evaluating commonsenseqa :  84%|███████████▊  | 42/50 [1:09:37<11:23, 85.46s/it]Evaluating commonsenseqa :  86%|████████████  | 43/50 [1:11:19<10:32, 90.41s/it]Evaluating commonsenseqa :  88%|████████████▎ | 44/50 [1:13:03<09:25, 94.29s/it]Evaluating commonsenseqa :  90%|████████████▌ | 45/50 [1:14:44<08:01, 96.27s/it]Evaluating commonsenseqa :  92%|████████████▉ | 46/50 [1:16:23<06:29, 97.27s/it]Evaluating commonsenseqa :  94%|█████████████▏| 47/50 [1:18:08<04:58, 99.46s/it]Evaluating commonsenseqa :  96%|████████████▍| 48/50 [1:19:52<03:21, 100.84s/it]Evaluating commonsenseqa :  98%|████████████▋| 49/50 [1:21:32<01:40, 100.77s/it]Evaluating commonsenseqa : 100%|█████████████| 50/50 [1:23:13<00:00, 100.75s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:23:13<00:00, 99.87s/it]
name: commonsenseqa | avg. gen lenth: 312.712 | time: 4993.9518048763275s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o17-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 17
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 06:02:39,220] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 06:02:39,730] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 06:02:39,767] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 06:02:39,776] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o17-tgsm8k-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 17
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o17-tgsm8k-s10-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████| 9741/9741 [00:00<00:00, 523904.79it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:06<00:06,  6.44s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.09s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.25s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.47s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  3.83s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  4.23s/it]
 > number of parameters: 6738415616
[2023-08-30 06:02:49,461] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.13s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.57s/it]
[2023-08-30 06:02:50,160] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.26s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.71s/it]
[2023-08-30 06:02:50,458] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.33s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.80s/it]
[2023-08-30 06:02:50,584] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 06:02:51,180] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-30 06:02:51,181] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fc186cc9300>
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-30 06:02:51,182] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-30 06:02:51,183] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-30 06:02:51,183] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-30 06:02:51,183] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-30 06:02:51,183] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-30 06:02:51,183] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-30 06:02:51,183] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-30 06:02:51,183] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-30 06:02:51,183] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-30 06:02:51,183] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-30 06:02:51,183] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-30 06:02:51,183] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-30 06:02:51,183] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-30 06:02:51,183] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-30 06:02:51,183] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-30 06:02:51,183] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-30 06:02:51,183] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-30 06:02:51,183] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-30 06:02:51,183] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-30 06:02:51,183] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-30 06:02:51,183] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-30 06:02:51,183] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-30 06:02:51,183] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-30 06:02:51,183] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-30 06:02:51,183] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-30 06:02:51,183] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-30 06:02:51,183] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-30 06:02:51,183] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-30 06:02:51,183] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-30 06:02:51,183] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: 868

Input: Stella and Twinkle are filling up a truck with a capacity of 6000 stone blocks at the rate of 250 blocks per hour per person. They work for four hours and are then joined by 6 other people who also work at the same rate. How many hours did filling the truck take?
Output: 6

Input: Elijah drank 8.5 pints of coffee yesterday. Emilio drank 9.5 pints of water yesterday. How many cups of liquid did the two boys drink yesterday?
Output: 36

Input: Doris works at the Widget Factory in the packing department. She puts 3 widgets in each carton, which are 4 inches wide, 4 inches long, and 5 inches tall. She then packs those cartons into a shipping box before sending it to the loading bay. The shipping boxes are 20 inches wide, 20 inches long, and 20 inches high. How many widgets get shipped in each shipping box?
Output: 300

Input: Queenie earns $150 a day as a part-time clerk. She earns an additional $5 per hour as overtime pay. How much will Queenie receive for working 5 days with 4 hours overtime?
Output: 770

Input: Jodi starts off walking 1 mile a day for 6 days a week.  On the second week, she walks 2 miles a day, 6 days a week.  On the third week, she walks 3 miles a day, 6 days a week. Finally on the fourth week, she walks 4 miles a day, 6 days a week.  How many miles has she walked in 4 weeks?
Output: 60

Input: A club is going to get additional members so that they will have 5 more than twice their current number of their members. If the club has 10 members now, how many additional members do they need?
Output: 15

Input: Andrea buys herself a pony for her 30th birthday. She pays $500/month to rent a pasture for it, $10 a day for food, and $60/lesson for two lessons a week. How much does she spend on her pony in a year?
Output: 15890

Input: A pet shop has 2 puppies and some kittens. A puppy costs $20, and a kitten costs $15. If the stock is worth $100, how many kittens does the pet shop have?
Output: 4

Input: Noah, who loves his Grammy, calls her every week to talk about his day. If each call lasts 30 minutes and he is charged $0.05 per call minute, how much would he be billed if he makes the calls for a year?
Output: 78

Input: A merchant bought 15 keyboards and 25 printers for a total of $2050. If a keyboard costs $20, how much does a printer cost?
Output: 70

Input: Gina has two bank accounts. Each account has a quarter of the balance in Betty's account. If Betty's account balance is $3,456, what is the combined balance of both Gina's accounts?
Output: 1728

Input: Zain has 10 more of each coin than Emerie. If Emerie has six quarters, seven dimes, and five nickels, how many coins does Zain have?
Output: 48

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o17-tgsm8k-s10-rFalse-m4096
Evaluating commonsenseqa :   2%|▎             | 1/50 [01:44<1:25:17, 104.44s/it]Evaluating commonsenseqa :   4%|▌             | 2/50 [03:25<1:22:02, 102.55s/it]Evaluating commonsenseqa :   6%|▉              | 3/50 [04:44<1:12:00, 91.93s/it]Evaluating commonsenseqa :   8%|█▏             | 4/50 [06:25<1:13:04, 95.31s/it]Evaluating commonsenseqa :  10%|█▌             | 5/50 [07:48<1:08:09, 90.87s/it]Evaluating commonsenseqa :  12%|█▊             | 6/50 [09:30<1:09:26, 94.70s/it]Evaluating commonsenseqa :  14%|██             | 7/50 [11:10<1:09:05, 96.41s/it]Evaluating commonsenseqa :  16%|██▋              | 8/50 [11:40<52:46, 75.39s/it]Evaluating commonsenseqa :  18%|███              | 9/50 [12:58<51:55, 75.99s/it]Evaluating commonsenseqa :  20%|███▏            | 10/50 [14:39<55:50, 83.75s/it]Evaluating commonsenseqa :  22%|███▌            | 11/50 [15:56<53:07, 81.74s/it]Evaluating commonsenseqa :  24%|███▊            | 12/50 [17:35<54:59, 86.84s/it]Evaluating commonsenseqa :  26%|████▏           | 13/50 [19:16<56:22, 91.43s/it]Evaluating commonsenseqa :  28%|████▍           | 14/50 [20:58<56:42, 94.52s/it]Evaluating commonsenseqa :  30%|████▊           | 15/50 [22:38<56:08, 96.24s/it]Evaluating commonsenseqa :  32%|█████           | 16/50 [24:18<55:07, 97.27s/it]Evaluating commonsenseqa :  34%|█████▍          | 17/50 [25:38<50:34, 91.94s/it]Evaluating commonsenseqa :  36%|█████▊          | 18/50 [26:24<41:45, 78.28s/it]Evaluating commonsenseqa :  38%|██████          | 19/50 [28:06<44:02, 85.25s/it]Evaluating commonsenseqa :  40%|██████▍         | 20/50 [29:48<45:12, 90.41s/it]Evaluating commonsenseqa :  42%|██████▋         | 21/50 [31:30<45:26, 94.03s/it]Evaluating commonsenseqa :  44%|███████         | 22/50 [33:11<44:47, 96.00s/it]Evaluating commonsenseqa :  46%|███████▎        | 23/50 [34:52<43:50, 97.43s/it]Evaluating commonsenseqa :  48%|███████▋        | 24/50 [36:30<42:22, 97.77s/it]Evaluating commonsenseqa :  50%|████████        | 25/50 [38:11<41:02, 98.50s/it]Evaluating commonsenseqa :  52%|████████▎       | 26/50 [39:25<36:32, 91.36s/it]Evaluating commonsenseqa :  54%|████████▋       | 27/50 [41:06<36:04, 94.12s/it]Evaluating commonsenseqa :  56%|████████▉       | 28/50 [42:46<35:08, 95.85s/it]Evaluating commonsenseqa :  58%|█████████▎      | 29/50 [44:27<34:04, 97.36s/it]Evaluating commonsenseqa :  60%|█████████▌      | 30/50 [46:07<32:47, 98.40s/it]Evaluating commonsenseqa :  62%|█████████▉      | 31/50 [47:38<30:24, 96.02s/it]Evaluating commonsenseqa :  64%|██████████▏     | 32/50 [49:18<29:12, 97.37s/it]Evaluating commonsenseqa :  66%|██████████▌     | 33/50 [50:34<25:42, 90.75s/it]Evaluating commonsenseqa :  68%|██████████▉     | 34/50 [51:17<20:24, 76.50s/it]Evaluating commonsenseqa :  70%|███████████▏    | 35/50 [53:01<21:12, 84.82s/it]Evaluating commonsenseqa :  72%|███████████▌    | 36/50 [54:40<20:47, 89.12s/it]Evaluating commonsenseqa :  74%|███████████▊    | 37/50 [56:20<19:59, 92.26s/it]Evaluating commonsenseqa :  76%|████████████▏   | 38/50 [58:00<18:53, 94.46s/it]Evaluating commonsenseqa :  78%|████████████▍   | 39/50 [59:42<17:45, 96.83s/it]Evaluating commonsenseqa :  80%|███████████▏  | 40/50 [1:01:22<16:17, 97.80s/it]Evaluating commonsenseqa :  82%|███████████▍  | 41/50 [1:03:03<14:48, 98.72s/it]Evaluating commonsenseqa :  84%|███████████▊  | 42/50 [1:04:44<13:16, 99.51s/it]Evaluating commonsenseqa :  86%|████████████  | 43/50 [1:06:25<11:39, 99.90s/it]Evaluating commonsenseqa :  88%|███████████▍ | 44/50 [1:08:06<10:02, 100.37s/it]Evaluating commonsenseqa :  90%|███████████▋ | 45/50 [1:09:46<08:21, 100.23s/it]Evaluating commonsenseqa :  92%|███████████▉ | 46/50 [1:11:26<06:40, 100.04s/it]Evaluating commonsenseqa :  94%|████████████▏| 47/50 [1:13:07<05:00, 100.29s/it]Evaluating commonsenseqa :  96%|█████████████▍| 48/50 [1:14:46<03:19, 99.97s/it]Evaluating commonsenseqa :  98%|████████████▋| 49/50 [1:16:27<01:40, 100.22s/it]Evaluating commonsenseqa : 100%|█████████████| 50/50 [1:18:07<00:00, 100.26s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:18:07<00:00, 93.75s/it]
name: commonsenseqa | avg. gen lenth: 282.888 | time: 4688.085840702057s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o18-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 18
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 07:25:17,191] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 07:25:17,214] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 07:25:17,242] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 07:25:17,253] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o18-tgsm8k-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 18
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o18-tgsm8k-s10-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████| 9741/9741 [00:00<00:00, 495142.89it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.01s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.25s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.31s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.46s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.11s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.54s/it]
[2023-08-30 07:25:27,805] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.29s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.73s/it]
[2023-08-30 07:25:28,186] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.41s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.85s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.44s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.89s/it]
 > number of parameters: 6738415616
[2023-08-30 07:25:28,475] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 07:25:28,586] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 07:25:29,134] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-30 07:25:29,136] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f0ad70bd300>
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-30 07:25:29,136] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-30 07:25:29,137] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-30 07:25:29,137] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: 868

Input: Stella and Twinkle are filling up a truck with a capacity of 6000 stone blocks at the rate of 250 blocks per hour per person. They work for four hours and are then joined by 6 other people who also work at the same rate. How many hours did filling the truck take?
Output: 6

Input: Elijah drank 8.5 pints of coffee yesterday. Emilio drank 9.5 pints of water yesterday. How many cups of liquid did the two boys drink yesterday?
Output: 36

Input: Doris works at the Widget Factory in the packing department. She puts 3 widgets in each carton, which are 4 inches wide, 4 inches long, and 5 inches tall. She then packs those cartons into a shipping box before sending it to the loading bay. The shipping boxes are 20 inches wide, 20 inches long, and 20 inches high. How many widgets get shipped in each shipping box?
Output: 300

Input: Queenie earns $150 a day as a part-time clerk. She earns an additional $5 per hour as overtime pay. How much will Queenie receive for working 5 days with 4 hours overtime?
Output: 770

Input: Jodi starts off walking 1 mile a day for 6 days a week.  On the second week, she walks 2 miles a day, 6 days a week.  On the third week, she walks 3 miles a day, 6 days a week. Finally on the fourth week, she walks 4 miles a day, 6 days a week.  How many miles has she walked in 4 weeks?
Output: 60

Input: A club is going to get additional members so that they will have 5 more than twice their current number of their members. If the club has 10 members now, how many additional members do they need?
Output: 15

Input: Andrea buys herself a pony for her 30th birthday. She pays $500/month to rent a pasture for it, $10 a day for food, and $60/lesson for two lessons a week. How much does she spend on her pony in a year?
Output: 15890

Input: A pet shop has 2 puppies and some kittens. A puppy costs $20, and a kitten costs $15. If the stock is worth $100, how many kittens does the pet shop have?
Output: 4

Input: Noah, who loves his Grammy, calls her every week to talk about his day. If each call lasts 30 minutes and he is charged $0.05 per call minute, how much would he be billed if he makes the calls for a year?
Output: 78

Input: A merchant bought 15 keyboards and 25 printers for a total of $2050. If a keyboard costs $20, how much does a printer cost?
Output: 70

Input: Gina has two bank accounts. Each account has a quarter of the balance in Betty's account. If Betty's account balance is $3,456, what is the combined balance of both Gina's accounts?
Output: 1728

Input: Zain has 10 more of each coin than Emerie. If Emerie has six quarters, seven dimes, and five nickels, how many coins does Zain have?
Output: 48

Input: Adonis is playing a prank on his dad by replacing his shampoo with hot sauce. Every day, after his dad showers, Adonis replaces the shampoo with 1/2 an ounce of hot sauce. He knows his dad uses 1 oz of shampoo a day from a new 10 oz bottle that no one else uses. After 4 days, what percentage of the liquid in the bottle is hot sauce?
Output: 25

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o18-tgsm8k-s10-rFalse-m4096
Evaluating commonsenseqa :   2%|▎                | 1/50 [00:36<29:33, 36.19s/it]Evaluating commonsenseqa :   4%|▋                | 2/50 [02:15<58:41, 73.36s/it]Evaluating commonsenseqa :   6%|▉              | 3/50 [03:54<1:06:26, 84.82s/it]Evaluating commonsenseqa :   8%|█▏             | 4/50 [05:32<1:09:12, 90.26s/it]Evaluating commonsenseqa :  10%|█▋               | 5/50 [06:25<57:37, 76.84s/it]Evaluating commonsenseqa :  12%|█▊             | 6/50 [08:01<1:00:58, 83.15s/it]Evaluating commonsenseqa :  14%|██             | 7/50 [09:39<1:03:07, 88.08s/it]Evaluating commonsenseqa :  16%|██▍            | 8/50 [11:17<1:04:00, 91.43s/it]Evaluating commonsenseqa :  18%|██▋            | 9/50 [12:56<1:03:54, 93.53s/it]Evaluating commonsenseqa :  20%|██▊           | 10/50 [14:35<1:03:37, 95.43s/it]Evaluating commonsenseqa :  22%|███           | 11/50 [16:14<1:02:36, 96.32s/it]Evaluating commonsenseqa :  24%|███▊            | 12/50 [17:36<58:16, 92.02s/it]Evaluating commonsenseqa :  26%|████▏           | 13/50 [19:11<57:21, 93.01s/it]Evaluating commonsenseqa :  28%|████▍           | 14/50 [20:47<56:22, 93.96s/it]Evaluating commonsenseqa :  30%|████▊           | 15/50 [22:23<55:06, 94.46s/it]Evaluating commonsenseqa :  32%|█████           | 16/50 [24:01<54:12, 95.67s/it]Evaluating commonsenseqa :  34%|█████▍          | 17/50 [25:41<53:19, 96.96s/it]Evaluating commonsenseqa :  36%|█████▊          | 18/50 [26:53<47:43, 89.48s/it]Evaluating commonsenseqa :  38%|██████          | 19/50 [28:33<47:48, 92.54s/it]Evaluating commonsenseqa :  40%|██████▍         | 20/50 [30:11<47:03, 94.12s/it]Evaluating commonsenseqa :  42%|██████▋         | 21/50 [31:48<45:54, 94.98s/it]Evaluating commonsenseqa :  44%|███████         | 22/50 [33:27<44:53, 96.18s/it]Evaluating commonsenseqa :  46%|███████▎        | 23/50 [35:05<43:35, 96.87s/it]Evaluating commonsenseqa :  48%|███████▋        | 24/50 [36:41<41:46, 96.40s/it]Evaluating commonsenseqa :  50%|████████        | 25/50 [38:17<40:09, 96.36s/it]Evaluating commonsenseqa :  52%|████████▎       | 26/50 [39:58<39:04, 97.69s/it]Evaluating commonsenseqa :  54%|████████▋       | 27/50 [41:36<37:28, 97.76s/it]Evaluating commonsenseqa :  56%|████████▉       | 28/50 [43:12<35:39, 97.25s/it]Evaluating commonsenseqa :  58%|█████████▎      | 29/50 [44:49<34:04, 97.34s/it]Evaluating commonsenseqa :  60%|█████████▌      | 30/50 [46:15<31:16, 93.82s/it]Evaluating commonsenseqa :  62%|█████████▉      | 31/50 [47:52<30:00, 94.75s/it]Evaluating commonsenseqa :  64%|██████████▏     | 32/50 [49:30<28:47, 95.96s/it]Evaluating commonsenseqa :  66%|██████████▌     | 33/50 [50:34<24:25, 86.22s/it]Evaluating commonsenseqa :  68%|██████████▉     | 34/50 [52:11<23:53, 89.60s/it]Evaluating commonsenseqa :  70%|███████████▏    | 35/50 [53:52<23:13, 92.92s/it]Evaluating commonsenseqa :  72%|███████████▌    | 36/50 [55:29<21:59, 94.23s/it]Evaluating commonsenseqa :  74%|███████████▊    | 37/50 [57:09<20:44, 95.76s/it]Evaluating commonsenseqa :  76%|████████████▏   | 38/50 [58:47<19:18, 96.56s/it]Evaluating commonsenseqa :  78%|██████████▉   | 39/50 [1:00:24<17:43, 96.69s/it]Evaluating commonsenseqa :  80%|███████████▏  | 40/50 [1:01:49<15:31, 93.18s/it]Evaluating commonsenseqa :  82%|███████████▍  | 41/50 [1:03:27<14:12, 94.67s/it]Evaluating commonsenseqa :  84%|███████████▊  | 42/50 [1:05:07<12:48, 96.09s/it]Evaluating commonsenseqa :  86%|████████████  | 43/50 [1:06:07<09:56, 85.28s/it]Evaluating commonsenseqa :  88%|████████████▎ | 44/50 [1:07:46<08:56, 89.37s/it]Evaluating commonsenseqa :  90%|████████████▌ | 45/50 [1:09:22<07:36, 91.38s/it]Evaluating commonsenseqa :  92%|████████████▉ | 46/50 [1:11:00<06:13, 93.31s/it]Evaluating commonsenseqa :  94%|█████████████▏| 47/50 [1:12:37<04:44, 94.67s/it]Evaluating commonsenseqa :  96%|█████████████▍| 48/50 [1:14:15<03:11, 95.63s/it]Evaluating commonsenseqa :  98%|█████████████▋| 49/50 [1:15:53<01:36, 96.26s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:17:31<00:00, 96.66s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:17:31<00:00, 93.02s/it]
name: commonsenseqa | avg. gen lenth: 268.04 | time: 4651.450844049454s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o19-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 19
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 08:43:34,416] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 08:43:34,423] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 08:43:34,441] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 08:43:34,454] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o19-tgsm8k-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 19
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o19-tgsm8k-s10-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████| 9741/9741 [00:00<00:00, 470314.78it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:06<00:06,  6.63s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:06<00:06,  6.48s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.39s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  3.94s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  4.34s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  3.91s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  4.29s/it]
 > number of parameters: 6738415616
[2023-08-30 08:43:44,436] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 08:43:44,472] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards:  50%|█████████         | 1/2 [00:09<00:09,  9.28s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.44s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.89s/it]
[2023-08-30 08:43:45,534] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  4.94s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  5.59s/it]
[2023-08-30 08:43:47,082] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 08:43:47,713] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-30 08:43:47,715] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-30 08:43:47,715] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-30 08:43:47,715] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-30 08:43:47,715] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-30 08:43:47,715] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7ff08d2d12d0>
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-30 08:43:47,716] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-30 08:43:47,717] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-30 08:43:47,717] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-30 08:43:47,717] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-30 08:43:47,717] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-30 08:43:47,717] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-30 08:43:47,717] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-30 08:43:47,717] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-30 08:43:47,717] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-30 08:43:47,717] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-30 08:43:47,717] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-30 08:43:47,717] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-30 08:43:47,717] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-30 08:43:47,717] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-30 08:43:47,717] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-30 08:43:47,717] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-30 08:43:47,717] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-30 08:43:47,717] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-30 08:43:47,717] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-30 08:43:47,717] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-30 08:43:47,717] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-30 08:43:47,717] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-30 08:43:47,717] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-30 08:43:47,717] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-30 08:43:47,717] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-30 08:43:47,717] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: 868

Input: Stella and Twinkle are filling up a truck with a capacity of 6000 stone blocks at the rate of 250 blocks per hour per person. They work for four hours and are then joined by 6 other people who also work at the same rate. How many hours did filling the truck take?
Output: 6

Input: Elijah drank 8.5 pints of coffee yesterday. Emilio drank 9.5 pints of water yesterday. How many cups of liquid did the two boys drink yesterday?
Output: 36

Input: Doris works at the Widget Factory in the packing department. She puts 3 widgets in each carton, which are 4 inches wide, 4 inches long, and 5 inches tall. She then packs those cartons into a shipping box before sending it to the loading bay. The shipping boxes are 20 inches wide, 20 inches long, and 20 inches high. How many widgets get shipped in each shipping box?
Output: 300

Input: Queenie earns $150 a day as a part-time clerk. She earns an additional $5 per hour as overtime pay. How much will Queenie receive for working 5 days with 4 hours overtime?
Output: 770

Input: Jodi starts off walking 1 mile a day for 6 days a week.  On the second week, she walks 2 miles a day, 6 days a week.  On the third week, she walks 3 miles a day, 6 days a week. Finally on the fourth week, she walks 4 miles a day, 6 days a week.  How many miles has she walked in 4 weeks?
Output: 60

Input: A club is going to get additional members so that they will have 5 more than twice their current number of their members. If the club has 10 members now, how many additional members do they need?
Output: 15

Input: Andrea buys herself a pony for her 30th birthday. She pays $500/month to rent a pasture for it, $10 a day for food, and $60/lesson for two lessons a week. How much does she spend on her pony in a year?
Output: 15890

Input: A pet shop has 2 puppies and some kittens. A puppy costs $20, and a kitten costs $15. If the stock is worth $100, how many kittens does the pet shop have?
Output: 4

Input: Noah, who loves his Grammy, calls her every week to talk about his day. If each call lasts 30 minutes and he is charged $0.05 per call minute, how much would he be billed if he makes the calls for a year?
Output: 78

Input: A merchant bought 15 keyboards and 25 printers for a total of $2050. If a keyboard costs $20, how much does a printer cost?
Output: 70

Input: Gina has two bank accounts. Each account has a quarter of the balance in Betty's account. If Betty's account balance is $3,456, what is the combined balance of both Gina's accounts?
Output: 1728

Input: Zain has 10 more of each coin than Emerie. If Emerie has six quarters, seven dimes, and five nickels, how many coins does Zain have?
Output: 48

Input: Adonis is playing a prank on his dad by replacing his shampoo with hot sauce. Every day, after his dad showers, Adonis replaces the shampoo with 1/2 an ounce of hot sauce. He knows his dad uses 1 oz of shampoo a day from a new 10 oz bottle that no one else uses. After 4 days, what percentage of the liquid in the bottle is hot sauce?
Output: 25

Input: Lana and Mike are taking their dog and renting a cabin in the mountains for 2 weeks.  The daily rate is $125.00  There is a $100.00 pet fee.  There is also a 20% service/cleaning fee for the rental.  They need to pay 50% of the entire bill as a security deposit.  How much is their security deposit?
Output: 1110

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o19-tgsm8k-s10-rFalse-m4096
Evaluating commonsenseqa :   2%|▎              | 1/50 [01:36<1:18:26, 96.06s/it]Evaluating commonsenseqa :   4%|▌              | 2/50 [03:11<1:16:32, 95.69s/it]Evaluating commonsenseqa :   6%|▉              | 3/50 [04:46<1:14:39, 95.32s/it]Evaluating commonsenseqa :   8%|█▏             | 4/50 [06:11<1:10:06, 91.45s/it]Evaluating commonsenseqa :  10%|█▌             | 5/50 [07:47<1:09:39, 92.87s/it]Evaluating commonsenseqa :  12%|█▊             | 6/50 [09:21<1:08:30, 93.42s/it]Evaluating commonsenseqa :  14%|██             | 7/50 [10:56<1:07:09, 93.72s/it]Evaluating commonsenseqa :  16%|██▍            | 8/50 [12:29<1:05:37, 93.74s/it]Evaluating commonsenseqa :  18%|██▋            | 9/50 [14:01<1:03:35, 93.05s/it]Evaluating commonsenseqa :  20%|██▊           | 10/50 [15:37<1:02:39, 93.99s/it]Evaluating commonsenseqa :  22%|███           | 11/50 [17:14<1:01:36, 94.77s/it]Evaluating commonsenseqa :  24%|███▊            | 12/50 [18:47<59:47, 94.42s/it]Evaluating commonsenseqa :  26%|████▏           | 13/50 [20:23<58:32, 94.94s/it]Evaluating commonsenseqa :  28%|████▍           | 14/50 [21:58<56:54, 94.86s/it]Evaluating commonsenseqa :  30%|████▊           | 15/50 [23:24<53:45, 92.16s/it]Evaluating commonsenseqa :  32%|█████           | 16/50 [24:59<52:45, 93.12s/it]Evaluating commonsenseqa :  34%|█████▍          | 17/50 [26:33<51:24, 93.46s/it]Evaluating commonsenseqa :  36%|█████▊          | 18/50 [28:08<49:56, 93.63s/it]Evaluating commonsenseqa :  38%|██████          | 19/50 [29:13<44:01, 85.21s/it]Evaluating commonsenseqa :  40%|██████▍         | 20/50 [30:47<43:58, 87.95s/it]Evaluating commonsenseqa :  42%|██████▋         | 21/50 [32:23<43:33, 90.12s/it]Evaluating commonsenseqa :  44%|███████         | 22/50 [33:58<42:44, 91.58s/it]Evaluating commonsenseqa :  46%|███████▎        | 23/50 [35:33<41:41, 92.65s/it]Evaluating commonsenseqa :  48%|███████▋        | 24/50 [37:08<40:32, 93.56s/it]Evaluating commonsenseqa :  50%|████████        | 25/50 [38:44<39:17, 94.30s/it]Evaluating commonsenseqa :  52%|████████▎       | 26/50 [40:18<37:36, 94.03s/it]Evaluating commonsenseqa :  54%|████████▋       | 27/50 [41:53<36:08, 94.27s/it]Evaluating commonsenseqa :  56%|████████▉       | 28/50 [43:26<34:29, 94.08s/it]Evaluating commonsenseqa :  58%|█████████▎      | 29/50 [45:04<33:15, 95.03s/it]Evaluating commonsenseqa :  60%|█████████▌      | 30/50 [46:38<31:39, 94.97s/it]Evaluating commonsenseqa :  62%|█████████▉      | 31/50 [48:11<29:48, 94.15s/it]Evaluating commonsenseqa :  64%|██████████▏     | 32/50 [49:45<28:15, 94.20s/it]Evaluating commonsenseqa :  66%|██████████▌     | 33/50 [51:20<26:47, 94.58s/it]Evaluating commonsenseqa :  68%|██████████▉     | 34/50 [52:54<25:10, 94.39s/it]Evaluating commonsenseqa :  70%|███████████▏    | 35/50 [54:00<21:25, 85.69s/it]Evaluating commonsenseqa :  72%|███████████▌    | 36/50 [55:03<18:25, 78.93s/it]Evaluating commonsenseqa :  74%|███████████▊    | 37/50 [56:37<18:07, 83.62s/it]Evaluating commonsenseqa :  76%|████████████▏   | 38/50 [58:14<17:29, 87.42s/it]Evaluating commonsenseqa :  78%|████████████▍   | 39/50 [59:31<15:27, 84.32s/it]Evaluating commonsenseqa :  80%|███████████▏  | 40/50 [1:01:07<14:39, 87.95s/it]Evaluating commonsenseqa :  82%|███████████▍  | 41/50 [1:02:43<13:32, 90.26s/it]Evaluating commonsenseqa :  84%|███████████▊  | 42/50 [1:04:18<12:13, 91.66s/it]Evaluating commonsenseqa :  86%|████████████  | 43/50 [1:05:51<10:45, 92.17s/it]Evaluating commonsenseqa :  88%|████████████▎ | 44/50 [1:06:56<08:22, 83.82s/it]Evaluating commonsenseqa :  90%|████████████▌ | 45/50 [1:08:33<07:19, 87.85s/it]Evaluating commonsenseqa :  92%|████████████▉ | 46/50 [1:10:07<05:59, 89.79s/it]Evaluating commonsenseqa :  94%|█████████████▏| 47/50 [1:11:44<04:35, 91.86s/it]Evaluating commonsenseqa :  96%|█████████████▍| 48/50 [1:13:07<02:58, 89.24s/it]Evaluating commonsenseqa :  98%|█████████████▋| 49/50 [1:14:41<01:30, 90.65s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:16:16<00:00, 91.95s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:16:16<00:00, 91.53s/it]
name: commonsenseqa | avg. gen lenth: 277.592 | time: 4576.751673460007s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o20-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 20
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 10:00:11,011] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 10:00:11,479] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 10:00:11,509] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 10:00:11,527] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o20-tgsm8k-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 20
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o20-tgsm8k-s10-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████| 9741/9741 [00:00<00:00, 666406.49it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:06<00:06,  6.68s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:06<00:06,  6.67s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:06<00:06,  6.94s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.04s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  4.00s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  4.40s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  3.99s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  4.39s/it]
 > number of parameters: 6738415616
[2023-08-30 10:00:21,478] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 10:00:21,523] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  4.05s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  4.48s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.07s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.52s/it]
[2023-08-30 10:00:21,788] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 10:00:21,886] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 10:00:22,466] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-30 10:00:22,467] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-30 10:00:22,467] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-30 10:00:22,467] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-30 10:00:22,467] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-30 10:00:22,467] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-30 10:00:22,467] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-30 10:00:22,467] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-30 10:00:22,467] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-30 10:00:22,467] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-30 10:00:22,467] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-30 10:00:22,467] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f9d675c92d0>
[2023-08-30 10:00:22,467] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-30 10:00:22,468] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-30 10:00:22,469] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-30 10:00:22,469] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-30 10:00:22,469] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-30 10:00:22,469] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-30 10:00:22,469] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: 868

Input: Stella and Twinkle are filling up a truck with a capacity of 6000 stone blocks at the rate of 250 blocks per hour per person. They work for four hours and are then joined by 6 other people who also work at the same rate. How many hours did filling the truck take?
Output: 6

Input: Elijah drank 8.5 pints of coffee yesterday. Emilio drank 9.5 pints of water yesterday. How many cups of liquid did the two boys drink yesterday?
Output: 36

Input: Doris works at the Widget Factory in the packing department. She puts 3 widgets in each carton, which are 4 inches wide, 4 inches long, and 5 inches tall. She then packs those cartons into a shipping box before sending it to the loading bay. The shipping boxes are 20 inches wide, 20 inches long, and 20 inches high. How many widgets get shipped in each shipping box?
Output: 300

Input: Queenie earns $150 a day as a part-time clerk. She earns an additional $5 per hour as overtime pay. How much will Queenie receive for working 5 days with 4 hours overtime?
Output: 770

Input: Jodi starts off walking 1 mile a day for 6 days a week.  On the second week, she walks 2 miles a day, 6 days a week.  On the third week, she walks 3 miles a day, 6 days a week. Finally on the fourth week, she walks 4 miles a day, 6 days a week.  How many miles has she walked in 4 weeks?
Output: 60

Input: A club is going to get additional members so that they will have 5 more than twice their current number of their members. If the club has 10 members now, how many additional members do they need?
Output: 15

Input: Andrea buys herself a pony for her 30th birthday. She pays $500/month to rent a pasture for it, $10 a day for food, and $60/lesson for two lessons a week. How much does she spend on her pony in a year?
Output: 15890

Input: A pet shop has 2 puppies and some kittens. A puppy costs $20, and a kitten costs $15. If the stock is worth $100, how many kittens does the pet shop have?
Output: 4

Input: Noah, who loves his Grammy, calls her every week to talk about his day. If each call lasts 30 minutes and he is charged $0.05 per call minute, how much would he be billed if he makes the calls for a year?
Output: 78

Input: A merchant bought 15 keyboards and 25 printers for a total of $2050. If a keyboard costs $20, how much does a printer cost?
Output: 70

Input: Gina has two bank accounts. Each account has a quarter of the balance in Betty's account. If Betty's account balance is $3,456, what is the combined balance of both Gina's accounts?
Output: 1728

Input: Zain has 10 more of each coin than Emerie. If Emerie has six quarters, seven dimes, and five nickels, how many coins does Zain have?
Output: 48

Input: Adonis is playing a prank on his dad by replacing his shampoo with hot sauce. Every day, after his dad showers, Adonis replaces the shampoo with 1/2 an ounce of hot sauce. He knows his dad uses 1 oz of shampoo a day from a new 10 oz bottle that no one else uses. After 4 days, what percentage of the liquid in the bottle is hot sauce?
Output: 25

Input: Lana and Mike are taking their dog and renting a cabin in the mountains for 2 weeks.  The daily rate is $125.00  There is a $100.00 pet fee.  There is also a 20% service/cleaning fee for the rental.  They need to pay 50% of the entire bill as a security deposit.  How much is their security deposit?
Output: 1110

Input: Abigail is trying a new recipe for a cold drink. It uses 1/4 of a cup of iced tea and 1 and 1/4 of a cup of lemonade to make one drink. If she fills a pitcher with 18 total cups of this drink, how many cups of lemonade are in the pitcher?
Output: 15

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o20-tgsm8k-s10-rFalse-m4096
Evaluating commonsenseqa :   2%|▎              | 1/50 [01:34<1:17:26, 94.82s/it]Evaluating commonsenseqa :   4%|▌              | 2/50 [03:08<1:15:05, 93.86s/it]Evaluating commonsenseqa :   6%|▉              | 3/50 [04:41<1:13:22, 93.68s/it]Evaluating commonsenseqa :   8%|█▏             | 4/50 [06:15<1:12:00, 93.92s/it]Evaluating commonsenseqa :  10%|█▌             | 5/50 [07:48<1:10:07, 93.50s/it]Evaluating commonsenseqa :  12%|█▊             | 6/50 [09:21<1:08:24, 93.29s/it]Evaluating commonsenseqa :  14%|██             | 7/50 [10:52<1:06:25, 92.69s/it]Evaluating commonsenseqa :  16%|██▍            | 8/50 [12:24<1:04:34, 92.24s/it]Evaluating commonsenseqa :  18%|██▋            | 9/50 [13:56<1:03:07, 92.38s/it]Evaluating commonsenseqa :  20%|██▊           | 10/50 [15:29<1:01:38, 92.46s/it]Evaluating commonsenseqa :  22%|███           | 11/50 [17:02<1:00:14, 92.68s/it]Evaluating commonsenseqa :  24%|███▊            | 12/50 [18:36<58:49, 92.89s/it]Evaluating commonsenseqa :  26%|████▏           | 13/50 [20:07<57:03, 92.52s/it]Evaluating commonsenseqa :  28%|████▍           | 14/50 [21:40<55:30, 92.50s/it]Evaluating commonsenseqa :  30%|████▊           | 15/50 [23:12<53:56, 92.47s/it]Evaluating commonsenseqa :  32%|█████           | 16/50 [24:45<52:25, 92.52s/it]Evaluating commonsenseqa :  34%|█████▍          | 17/50 [26:16<50:41, 92.18s/it]Evaluating commonsenseqa :  36%|█████▊          | 18/50 [27:48<49:03, 91.98s/it]Evaluating commonsenseqa :  38%|██████          | 19/50 [29:03<44:55, 86.95s/it]Evaluating commonsenseqa :  40%|██████▍         | 20/50 [30:33<43:59, 87.99s/it]Evaluating commonsenseqa :  42%|██████▋         | 21/50 [32:07<43:19, 89.63s/it]Evaluating commonsenseqa :  44%|███████         | 22/50 [33:39<42:14, 90.53s/it]Evaluating commonsenseqa :  46%|███████▎        | 23/50 [35:13<41:12, 91.56s/it]Evaluating commonsenseqa :  48%|███████▋        | 24/50 [36:45<39:40, 91.54s/it]Evaluating commonsenseqa :  50%|████████        | 25/50 [37:46<34:23, 82.56s/it]Evaluating commonsenseqa :  52%|████████▎       | 26/50 [39:20<34:17, 85.74s/it]Evaluating commonsenseqa :  54%|████████▋       | 27/50 [40:52<33:40, 87.85s/it]Evaluating commonsenseqa :  56%|████████▉       | 28/50 [42:24<32:38, 89.02s/it]Evaluating commonsenseqa :  58%|█████████▎      | 29/50 [43:54<31:17, 89.42s/it]Evaluating commonsenseqa :  60%|█████████▌      | 30/50 [45:26<29:59, 89.96s/it]Evaluating commonsenseqa :  62%|█████████▉      | 31/50 [46:57<28:39, 90.48s/it]Evaluating commonsenseqa :  64%|██████████▏     | 32/50 [48:29<27:16, 90.93s/it]Evaluating commonsenseqa :  66%|██████████▌     | 33/50 [50:03<25:59, 91.73s/it]Evaluating commonsenseqa :  68%|██████████▉     | 34/50 [51:34<24:25, 91.60s/it]Evaluating commonsenseqa :  70%|███████████▏    | 35/50 [53:06<22:54, 91.62s/it]Evaluating commonsenseqa :  72%|███████████▌    | 36/50 [54:41<21:36, 92.62s/it]Evaluating commonsenseqa :  74%|███████████▊    | 37/50 [56:14<20:07, 92.86s/it]Evaluating commonsenseqa :  76%|████████████▏   | 38/50 [57:34<17:48, 89.00s/it]Evaluating commonsenseqa :  78%|████████████▍   | 39/50 [59:06<16:29, 89.93s/it]Evaluating commonsenseqa :  80%|███████████▏  | 40/50 [1:00:40<15:11, 91.19s/it]Evaluating commonsenseqa :  82%|███████████▍  | 41/50 [1:02:13<13:43, 91.48s/it]Evaluating commonsenseqa :  84%|███████████▊  | 42/50 [1:03:46<12:16, 92.11s/it]Evaluating commonsenseqa :  86%|████████████  | 43/50 [1:05:19<10:46, 92.32s/it]Evaluating commonsenseqa :  88%|████████████▎ | 44/50 [1:06:52<09:15, 92.51s/it]Evaluating commonsenseqa :  90%|████████████▌ | 45/50 [1:08:26<07:44, 92.91s/it]Evaluating commonsenseqa :  92%|████████████▉ | 46/50 [1:09:59<06:11, 92.93s/it]Evaluating commonsenseqa :  94%|█████████████▏| 47/50 [1:11:31<04:38, 92.84s/it]Evaluating commonsenseqa :  96%|█████████████▍| 48/50 [1:13:05<03:06, 93.04s/it]Evaluating commonsenseqa :  98%|█████████████▋| 49/50 [1:14:35<01:32, 92.15s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:16:08<00:00, 92.29s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:16:08<00:00, 91.36s/it]
name: commonsenseqa | avg. gen lenth: 294.58 | time: 4568.462028026581s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o21-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 21
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 11:16:37,619] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 11:16:38,083] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 11:16:38,134] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 11:16:38,164] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o21-tgsm8k-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 21
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o21-tgsm8k-s10-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████| 9741/9741 [00:00<00:00, 447607.48it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:06<00:06,  6.59s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.17s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.17s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.55s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  3.96s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  4.35s/it]
 > number of parameters: 6738415616
[2023-08-30 11:16:48,232] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.12s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.58s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.12s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.58s/it]
[2023-08-30 11:16:48,656] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 11:16:48,678] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.33s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.82s/it]
[2023-08-30 11:16:49,185] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 11:16:49,772] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-30 11:16:49,773] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-30 11:16:49,773] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-30 11:16:49,773] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-30 11:16:49,773] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-30 11:16:49,773] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fd019cc12d0>
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-30 11:16:49,774] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-30 11:16:49,775] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-30 11:16:49,775] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-30 11:16:49,775] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-30 11:16:49,775] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-30 11:16:49,775] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-30 11:16:49,775] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-30 11:16:49,775] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-30 11:16:49,775] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-30 11:16:49,775] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-30 11:16:49,775] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-30 11:16:49,775] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-30 11:16:49,775] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-30 11:16:49,775] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-30 11:16:49,775] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-30 11:16:49,775] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-30 11:16:49,775] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-30 11:16:49,775] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-30 11:16:49,775] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-30 11:16:49,775] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-30 11:16:49,775] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-30 11:16:49,775] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-30 11:16:49,775] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-30 11:16:49,775] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-30 11:16:49,775] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-30 11:16:49,775] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-30 11:16:49,775] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-30 11:16:49,775] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-30 11:16:49,775] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: 868

Input: Stella and Twinkle are filling up a truck with a capacity of 6000 stone blocks at the rate of 250 blocks per hour per person. They work for four hours and are then joined by 6 other people who also work at the same rate. How many hours did filling the truck take?
Output: 6

Input: Elijah drank 8.5 pints of coffee yesterday. Emilio drank 9.5 pints of water yesterday. How many cups of liquid did the two boys drink yesterday?
Output: 36

Input: Doris works at the Widget Factory in the packing department. She puts 3 widgets in each carton, which are 4 inches wide, 4 inches long, and 5 inches tall. She then packs those cartons into a shipping box before sending it to the loading bay. The shipping boxes are 20 inches wide, 20 inches long, and 20 inches high. How many widgets get shipped in each shipping box?
Output: 300

Input: Queenie earns $150 a day as a part-time clerk. She earns an additional $5 per hour as overtime pay. How much will Queenie receive for working 5 days with 4 hours overtime?
Output: 770

Input: Jodi starts off walking 1 mile a day for 6 days a week.  On the second week, she walks 2 miles a day, 6 days a week.  On the third week, she walks 3 miles a day, 6 days a week. Finally on the fourth week, she walks 4 miles a day, 6 days a week.  How many miles has she walked in 4 weeks?
Output: 60

Input: A club is going to get additional members so that they will have 5 more than twice their current number of their members. If the club has 10 members now, how many additional members do they need?
Output: 15

Input: Andrea buys herself a pony for her 30th birthday. She pays $500/month to rent a pasture for it, $10 a day for food, and $60/lesson for two lessons a week. How much does she spend on her pony in a year?
Output: 15890

Input: A pet shop has 2 puppies and some kittens. A puppy costs $20, and a kitten costs $15. If the stock is worth $100, how many kittens does the pet shop have?
Output: 4

Input: Noah, who loves his Grammy, calls her every week to talk about his day. If each call lasts 30 minutes and he is charged $0.05 per call minute, how much would he be billed if he makes the calls for a year?
Output: 78

Input: A merchant bought 15 keyboards and 25 printers for a total of $2050. If a keyboard costs $20, how much does a printer cost?
Output: 70

Input: Gina has two bank accounts. Each account has a quarter of the balance in Betty's account. If Betty's account balance is $3,456, what is the combined balance of both Gina's accounts?
Output: 1728

Input: Zain has 10 more of each coin than Emerie. If Emerie has six quarters, seven dimes, and five nickels, how many coins does Zain have?
Output: 48

Input: Adonis is playing a prank on his dad by replacing his shampoo with hot sauce. Every day, after his dad showers, Adonis replaces the shampoo with 1/2 an ounce of hot sauce. He knows his dad uses 1 oz of shampoo a day from a new 10 oz bottle that no one else uses. After 4 days, what percentage of the liquid in the bottle is hot sauce?
Output: 25

Input: Lana and Mike are taking their dog and renting a cabin in the mountains for 2 weeks.  The daily rate is $125.00  There is a $100.00 pet fee.  There is also a 20% service/cleaning fee for the rental.  They need to pay 50% of the entire bill as a security deposit.  How much is their security deposit?
Output: 1110

Input: Abigail is trying a new recipe for a cold drink. It uses 1/4 of a cup of iced tea and 1 and 1/4 of a cup of lemonade to make one drink. If she fills a pitcher with 18 total cups of this drink, how many cups of lemonade are in the pitcher?
Output: 15

Input: John buys a vacuum cleaner for $250 and a dishwasher for $450.  She has a $75 off coupon.  How much did he spend?
Output: 625

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o21-tgsm8k-s10-rFalse-m4096
Evaluating commonsenseqa :   2%|▎                | 1/50 [00:51<42:25, 51.94s/it]Evaluating commonsenseqa :   4%|▋                | 2/50 [02:10<54:01, 67.54s/it]Evaluating commonsenseqa :   6%|▉              | 3/50 [03:42<1:01:41, 78.75s/it]Evaluating commonsenseqa :   8%|█▏             | 4/50 [05:14<1:04:14, 83.79s/it]Evaluating commonsenseqa :  10%|█▌             | 5/50 [06:46<1:05:05, 86.79s/it]Evaluating commonsenseqa :  12%|█▊             | 6/50 [08:16<1:04:26, 87.87s/it]Evaluating commonsenseqa :  14%|██             | 7/50 [09:47<1:03:47, 89.01s/it]Evaluating commonsenseqa :  16%|██▍            | 8/50 [11:17<1:02:33, 89.37s/it]Evaluating commonsenseqa :  18%|██▋            | 9/50 [12:48<1:01:29, 89.99s/it]Evaluating commonsenseqa :  20%|██▊           | 10/50 [14:20<1:00:19, 90.49s/it]Evaluating commonsenseqa :  22%|███▌            | 11/50 [15:17<52:03, 80.09s/it]Evaluating commonsenseqa :  24%|███▊            | 12/50 [16:47<52:41, 83.20s/it]Evaluating commonsenseqa :  26%|████▏           | 13/50 [18:17<52:40, 85.42s/it]Evaluating commonsenseqa :  28%|████▍           | 14/50 [19:49<52:21, 87.26s/it]Evaluating commonsenseqa :  30%|████▊           | 15/50 [21:19<51:21, 88.04s/it]Evaluating commonsenseqa :  32%|█████           | 16/50 [22:45<49:34, 87.48s/it]Evaluating commonsenseqa :  34%|█████▍          | 17/50 [24:15<48:34, 88.33s/it]Evaluating commonsenseqa :  36%|█████▊          | 18/50 [25:46<47:34, 89.19s/it]Evaluating commonsenseqa :  38%|██████          | 19/50 [27:16<46:04, 89.16s/it]Evaluating commonsenseqa :  40%|██████▍         | 20/50 [28:45<44:33, 89.13s/it]Evaluating commonsenseqa :  42%|██████▋         | 21/50 [30:14<43:06, 89.19s/it]Evaluating commonsenseqa :  44%|███████         | 22/50 [31:45<41:52, 89.73s/it]Evaluating commonsenseqa :  46%|███████▎        | 23/50 [33:16<40:31, 90.05s/it]Evaluating commonsenseqa :  48%|███████▋        | 24/50 [34:46<39:00, 90.04s/it]Evaluating commonsenseqa :  50%|████████        | 25/50 [36:18<37:50, 90.82s/it]Evaluating commonsenseqa :  52%|████████▎       | 26/50 [37:48<36:14, 90.60s/it]Evaluating commonsenseqa :  54%|████████▋       | 27/50 [39:19<34:43, 90.58s/it]Evaluating commonsenseqa :  56%|████████▉       | 28/50 [40:51<33:20, 90.93s/it]Evaluating commonsenseqa :  58%|█████████▎      | 29/50 [42:22<31:52, 91.06s/it]Evaluating commonsenseqa :  60%|█████████▌      | 30/50 [43:52<30:15, 90.79s/it]Evaluating commonsenseqa :  62%|█████████▉      | 31/50 [45:22<28:41, 90.62s/it]Evaluating commonsenseqa :  64%|██████████▏     | 32/50 [46:55<27:19, 91.10s/it]Evaluating commonsenseqa :  66%|██████████▌     | 33/50 [48:26<25:51, 91.29s/it]Evaluating commonsenseqa :  68%|██████████▉     | 34/50 [49:57<24:19, 91.21s/it]Evaluating commonsenseqa :  70%|███████████▏    | 35/50 [51:28<22:46, 91.09s/it]Evaluating commonsenseqa :  72%|███████████▌    | 36/50 [53:00<21:19, 91.38s/it]Evaluating commonsenseqa :  74%|███████████▊    | 37/50 [54:31<19:45, 91.16s/it]Evaluating commonsenseqa :  76%|████████████▏   | 38/50 [56:03<18:15, 91.33s/it]Evaluating commonsenseqa :  78%|████████████▍   | 39/50 [57:34<16:43, 91.19s/it]Evaluating commonsenseqa :  80%|████████████▊   | 40/50 [59:03<15:06, 90.64s/it]Evaluating commonsenseqa :  82%|███████████▍  | 41/50 [1:00:33<13:33, 90.38s/it]Evaluating commonsenseqa :  84%|███████████▊  | 42/50 [1:02:04<12:06, 90.79s/it]Evaluating commonsenseqa :  86%|████████████  | 43/50 [1:03:35<10:34, 90.69s/it]Evaluating commonsenseqa :  88%|████████████▎ | 44/50 [1:05:05<09:03, 90.55s/it]Evaluating commonsenseqa :  90%|████████████▌ | 45/50 [1:06:37<07:35, 91.09s/it]Evaluating commonsenseqa :  92%|████████████▉ | 46/50 [1:08:08<06:03, 90.79s/it]Evaluating commonsenseqa :  94%|█████████████▏| 47/50 [1:09:39<04:33, 91.06s/it]Evaluating commonsenseqa :  96%|█████████████▍| 48/50 [1:11:10<03:01, 90.96s/it]Evaluating commonsenseqa :  98%|█████████████▋| 49/50 [1:12:41<01:30, 90.87s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:13:46<00:00, 83.10s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:13:46<00:00, 88.52s/it]
name: commonsenseqa | avg. gen lenth: 310.512 | time: 4426.521736383438s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o22-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 22
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 12:31:40,080] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 12:31:40,154] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 12:31:40,165] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 12:31:40,175] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o22-tgsm8k-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 22
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o22-tgsm8k-s10-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████| 9741/9741 [00:00<00:00, 431729.44it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.17s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.18s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.21s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.31s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.20s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.64s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.20s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.66s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.25s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.69s/it]
[2023-08-30 12:31:50,958] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.31s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.76s/it]
[2023-08-30 12:31:51,115] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 12:31:51,125] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
 > number of parameters: 6738415616
[2023-08-30 12:31:51,244] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 12:31:51,835] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-30 12:31:51,836] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f24122d12d0>
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-30 12:31:51,837] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-30 12:31:51,838] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-30 12:31:51,838] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: 868

Input: Stella and Twinkle are filling up a truck with a capacity of 6000 stone blocks at the rate of 250 blocks per hour per person. They work for four hours and are then joined by 6 other people who also work at the same rate. How many hours did filling the truck take?
Output: 6

Input: Elijah drank 8.5 pints of coffee yesterday. Emilio drank 9.5 pints of water yesterday. How many cups of liquid did the two boys drink yesterday?
Output: 36

Input: Doris works at the Widget Factory in the packing department. She puts 3 widgets in each carton, which are 4 inches wide, 4 inches long, and 5 inches tall. She then packs those cartons into a shipping box before sending it to the loading bay. The shipping boxes are 20 inches wide, 20 inches long, and 20 inches high. How many widgets get shipped in each shipping box?
Output: 300

Input: Queenie earns $150 a day as a part-time clerk. She earns an additional $5 per hour as overtime pay. How much will Queenie receive for working 5 days with 4 hours overtime?
Output: 770

Input: Jodi starts off walking 1 mile a day for 6 days a week.  On the second week, she walks 2 miles a day, 6 days a week.  On the third week, she walks 3 miles a day, 6 days a week. Finally on the fourth week, she walks 4 miles a day, 6 days a week.  How many miles has she walked in 4 weeks?
Output: 60

Input: A club is going to get additional members so that they will have 5 more than twice their current number of their members. If the club has 10 members now, how many additional members do they need?
Output: 15

Input: Andrea buys herself a pony for her 30th birthday. She pays $500/month to rent a pasture for it, $10 a day for food, and $60/lesson for two lessons a week. How much does she spend on her pony in a year?
Output: 15890

Input: A pet shop has 2 puppies and some kittens. A puppy costs $20, and a kitten costs $15. If the stock is worth $100, how many kittens does the pet shop have?
Output: 4

Input: Noah, who loves his Grammy, calls her every week to talk about his day. If each call lasts 30 minutes and he is charged $0.05 per call minute, how much would he be billed if he makes the calls for a year?
Output: 78

Input: A merchant bought 15 keyboards and 25 printers for a total of $2050. If a keyboard costs $20, how much does a printer cost?
Output: 70

Input: Gina has two bank accounts. Each account has a quarter of the balance in Betty's account. If Betty's account balance is $3,456, what is the combined balance of both Gina's accounts?
Output: 1728

Input: Zain has 10 more of each coin than Emerie. If Emerie has six quarters, seven dimes, and five nickels, how many coins does Zain have?
Output: 48

Input: Adonis is playing a prank on his dad by replacing his shampoo with hot sauce. Every day, after his dad showers, Adonis replaces the shampoo with 1/2 an ounce of hot sauce. He knows his dad uses 1 oz of shampoo a day from a new 10 oz bottle that no one else uses. After 4 days, what percentage of the liquid in the bottle is hot sauce?
Output: 25

Input: Lana and Mike are taking their dog and renting a cabin in the mountains for 2 weeks.  The daily rate is $125.00  There is a $100.00 pet fee.  There is also a 20% service/cleaning fee for the rental.  They need to pay 50% of the entire bill as a security deposit.  How much is their security deposit?
Output: 1110

Input: Abigail is trying a new recipe for a cold drink. It uses 1/4 of a cup of iced tea and 1 and 1/4 of a cup of lemonade to make one drink. If she fills a pitcher with 18 total cups of this drink, how many cups of lemonade are in the pitcher?
Output: 15

Input: John buys a vacuum cleaner for $250 and a dishwasher for $450.  She has a $75 off coupon.  How much did he spend?
Output: 625

Input: Dany owns a farm, in his farm he has 4 cows and 3 sheep that eat 2 bushels a day. He also has 7 chickens that eat 3 bushels a day. How many bushels should he have to suffice the animals for a day?
Output: 35

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o22-tgsm8k-s10-rFalse-m4096
Evaluating commonsenseqa :   2%|▎              | 1/50 [01:30<1:13:34, 90.09s/it]Evaluating commonsenseqa :   4%|▋                | 2/50 [02:28<56:58, 71.21s/it]Evaluating commonsenseqa :   6%|█                | 3/50 [03:17<48:08, 61.46s/it]Evaluating commonsenseqa :   8%|█▎               | 4/50 [04:47<55:40, 72.62s/it]Evaluating commonsenseqa :  10%|█▋               | 5/50 [06:16<58:58, 78.63s/it]Evaluating commonsenseqa :  12%|█▊             | 6/50 [07:45<1:00:05, 81.94s/it]Evaluating commonsenseqa :  14%|██             | 7/50 [09:16<1:00:59, 85.11s/it]Evaluating commonsenseqa :  16%|██▍            | 8/50 [10:47<1:00:49, 86.89s/it]Evaluating commonsenseqa :  18%|███              | 9/50 [12:16<59:44, 87.43s/it]Evaluating commonsenseqa :  20%|███▏            | 10/50 [13:45<58:40, 88.02s/it]Evaluating commonsenseqa :  22%|███▌            | 11/50 [15:14<57:21, 88.25s/it]Evaluating commonsenseqa :  24%|███▊            | 12/50 [16:43<56:06, 88.60s/it]Evaluating commonsenseqa :  26%|████▏           | 13/50 [18:13<54:49, 88.89s/it]Evaluating commonsenseqa :  28%|████▍           | 14/50 [19:44<53:47, 89.66s/it]Evaluating commonsenseqa :  30%|████▊           | 15/50 [21:13<52:11, 89.47s/it]Evaluating commonsenseqa :  32%|█████           | 16/50 [22:35<49:23, 87.17s/it]Evaluating commonsenseqa :  34%|█████▍          | 17/50 [24:03<48:08, 87.52s/it]Evaluating commonsenseqa :  36%|█████▊          | 18/50 [25:33<46:56, 88.01s/it]Evaluating commonsenseqa :  38%|██████          | 19/50 [27:02<45:38, 88.33s/it]Evaluating commonsenseqa :  40%|██████▍         | 20/50 [28:23<43:07, 86.24s/it]Evaluating commonsenseqa :  42%|██████▋         | 21/50 [29:53<42:13, 87.37s/it]Evaluating commonsenseqa :  44%|███████         | 22/50 [31:23<41:08, 88.16s/it]Evaluating commonsenseqa :  46%|███████▎        | 23/50 [32:27<36:23, 80.88s/it]Evaluating commonsenseqa :  48%|███████▋        | 24/50 [33:56<36:03, 83.20s/it]Evaluating commonsenseqa :  50%|████████        | 25/50 [35:25<35:24, 84.97s/it]Evaluating commonsenseqa :  52%|████████▎       | 26/50 [36:51<34:06, 85.27s/it]Evaluating commonsenseqa :  54%|████████▋       | 27/50 [38:18<32:57, 85.99s/it]Evaluating commonsenseqa :  56%|████████▉       | 28/50 [39:47<31:52, 86.92s/it]Evaluating commonsenseqa :  58%|█████████▎      | 29/50 [41:16<30:33, 87.30s/it]Evaluating commonsenseqa :  60%|█████████▌      | 30/50 [42:45<29:16, 87.84s/it]Evaluating commonsenseqa :  62%|█████████▉      | 31/50 [44:13<27:52, 88.03s/it]Evaluating commonsenseqa :  64%|██████████▏     | 32/50 [45:44<26:40, 88.92s/it]Evaluating commonsenseqa :  66%|██████████▌     | 33/50 [47:13<25:11, 88.90s/it]Evaluating commonsenseqa :  68%|██████████▉     | 34/50 [48:42<23:44, 89.02s/it]Evaluating commonsenseqa :  70%|███████████▏    | 35/50 [50:09<22:05, 88.37s/it]Evaluating commonsenseqa :  72%|███████████▌    | 36/50 [51:39<20:41, 88.67s/it]Evaluating commonsenseqa :  74%|███████████▊    | 37/50 [53:10<19:21, 89.35s/it]Evaluating commonsenseqa :  76%|████████████▏   | 38/50 [54:38<17:47, 88.95s/it]Evaluating commonsenseqa :  78%|████████████▍   | 39/50 [56:06<16:18, 88.95s/it]Evaluating commonsenseqa :  80%|████████████▊   | 40/50 [57:33<14:43, 88.32s/it]Evaluating commonsenseqa :  82%|█████████████   | 41/50 [58:25<11:36, 77.37s/it]Evaluating commonsenseqa :  84%|█████████████▍  | 42/50 [59:55<10:49, 81.14s/it]Evaluating commonsenseqa :  86%|████████████  | 43/50 [1:01:24<09:44, 83.51s/it]Evaluating commonsenseqa :  88%|████████████▎ | 44/50 [1:02:55<08:33, 85.61s/it]Evaluating commonsenseqa :  90%|████████████▌ | 45/50 [1:04:23<07:11, 86.31s/it]Evaluating commonsenseqa :  92%|████████████▉ | 46/50 [1:05:51<05:48, 87.07s/it]Evaluating commonsenseqa :  94%|█████████████▏| 47/50 [1:07:21<04:23, 87.77s/it]Evaluating commonsenseqa :  96%|█████████████▍| 48/50 [1:08:49<02:56, 88.03s/it]Evaluating commonsenseqa :  98%|█████████████▋| 49/50 [1:10:20<01:28, 88.84s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:11:52<00:00, 89.59s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:11:52<00:00, 86.24s/it]
name: commonsenseqa | avg. gen lenth: 302.26 | time: 4312.475368261337s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o23-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 23
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 13:45:11,717] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 13:45:12,031] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 13:45:12,075] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 13:45:12,087] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o23-tgsm8k-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 23
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o23-tgsm8k-s10-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████| 9741/9741 [00:00<00:00, 421546.57it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.08s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.10s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.28s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.32s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.13s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.58s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.15s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.59s/it]
 > number of parameters: 6738415616
[2023-08-30 13:45:22,701] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 13:45:22,713] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.18s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.65s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.25s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.71s/it]
[2023-08-30 13:45:22,880] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 13:45:22,965] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 13:45:23,553] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-30 13:45:23,554] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fe33bdd1300>
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-30 13:45:23,555] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-30 13:45:23,556] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-30 13:45:23,556] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: 868

Input: Stella and Twinkle are filling up a truck with a capacity of 6000 stone blocks at the rate of 250 blocks per hour per person. They work for four hours and are then joined by 6 other people who also work at the same rate. How many hours did filling the truck take?
Output: 6

Input: Elijah drank 8.5 pints of coffee yesterday. Emilio drank 9.5 pints of water yesterday. How many cups of liquid did the two boys drink yesterday?
Output: 36

Input: Doris works at the Widget Factory in the packing department. She puts 3 widgets in each carton, which are 4 inches wide, 4 inches long, and 5 inches tall. She then packs those cartons into a shipping box before sending it to the loading bay. The shipping boxes are 20 inches wide, 20 inches long, and 20 inches high. How many widgets get shipped in each shipping box?
Output: 300

Input: Queenie earns $150 a day as a part-time clerk. She earns an additional $5 per hour as overtime pay. How much will Queenie receive for working 5 days with 4 hours overtime?
Output: 770

Input: Jodi starts off walking 1 mile a day for 6 days a week.  On the second week, she walks 2 miles a day, 6 days a week.  On the third week, she walks 3 miles a day, 6 days a week. Finally on the fourth week, she walks 4 miles a day, 6 days a week.  How many miles has she walked in 4 weeks?
Output: 60

Input: A club is going to get additional members so that they will have 5 more than twice their current number of their members. If the club has 10 members now, how many additional members do they need?
Output: 15

Input: Andrea buys herself a pony for her 30th birthday. She pays $500/month to rent a pasture for it, $10 a day for food, and $60/lesson for two lessons a week. How much does she spend on her pony in a year?
Output: 15890

Input: A pet shop has 2 puppies and some kittens. A puppy costs $20, and a kitten costs $15. If the stock is worth $100, how many kittens does the pet shop have?
Output: 4

Input: Noah, who loves his Grammy, calls her every week to talk about his day. If each call lasts 30 minutes and he is charged $0.05 per call minute, how much would he be billed if he makes the calls for a year?
Output: 78

Input: A merchant bought 15 keyboards and 25 printers for a total of $2050. If a keyboard costs $20, how much does a printer cost?
Output: 70

Input: Gina has two bank accounts. Each account has a quarter of the balance in Betty's account. If Betty's account balance is $3,456, what is the combined balance of both Gina's accounts?
Output: 1728

Input: Zain has 10 more of each coin than Emerie. If Emerie has six quarters, seven dimes, and five nickels, how many coins does Zain have?
Output: 48

Input: Adonis is playing a prank on his dad by replacing his shampoo with hot sauce. Every day, after his dad showers, Adonis replaces the shampoo with 1/2 an ounce of hot sauce. He knows his dad uses 1 oz of shampoo a day from a new 10 oz bottle that no one else uses. After 4 days, what percentage of the liquid in the bottle is hot sauce?
Output: 25

Input: Lana and Mike are taking their dog and renting a cabin in the mountains for 2 weeks.  The daily rate is $125.00  There is a $100.00 pet fee.  There is also a 20% service/cleaning fee for the rental.  They need to pay 50% of the entire bill as a security deposit.  How much is their security deposit?
Output: 1110

Input: Abigail is trying a new recipe for a cold drink. It uses 1/4 of a cup of iced tea and 1 and 1/4 of a cup of lemonade to make one drink. If she fills a pitcher with 18 total cups of this drink, how many cups of lemonade are in the pitcher?
Output: 15

Input: John buys a vacuum cleaner for $250 and a dishwasher for $450.  She has a $75 off coupon.  How much did he spend?
Output: 625

Input: Dany owns a farm, in his farm he has 4 cows and 3 sheep that eat 2 bushels a day. He also has 7 chickens that eat 3 bushels a day. How many bushels should he have to suffice the animals for a day?
Output: 35

Input: The town of Belize has 400 homes. One fourth of the town's homes are white. One fifth of the non-white homes have a fireplace. How many of the non-white homes do not have a fireplace?
Output: 240

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o23-tgsm8k-s10-rFalse-m4096
Evaluating commonsenseqa :   2%|▎              | 1/50 [01:28<1:12:40, 88.99s/it]Evaluating commonsenseqa :   4%|▌              | 2/50 [02:56<1:10:41, 88.37s/it]Evaluating commonsenseqa :   6%|▉              | 3/50 [04:25<1:09:21, 88.54s/it]Evaluating commonsenseqa :   8%|█▏             | 4/50 [05:55<1:08:23, 89.21s/it]Evaluating commonsenseqa :  10%|█▌             | 5/50 [07:25<1:06:52, 89.17s/it]Evaluating commonsenseqa :  12%|█▊             | 6/50 [08:53<1:05:08, 88.83s/it]Evaluating commonsenseqa :  14%|██             | 7/50 [10:20<1:03:22, 88.42s/it]Evaluating commonsenseqa :  16%|██▍            | 8/50 [11:48<1:01:42, 88.16s/it]Evaluating commonsenseqa :  18%|██▋            | 9/50 [13:17<1:00:26, 88.44s/it]Evaluating commonsenseqa :  20%|███▏            | 10/50 [14:44<58:38, 87.96s/it]Evaluating commonsenseqa :  22%|███▌            | 11/50 [16:14<57:37, 88.67s/it]Evaluating commonsenseqa :  24%|███▊            | 12/50 [17:34<54:28, 86.02s/it]Evaluating commonsenseqa :  26%|████▏           | 13/50 [19:02<53:25, 86.63s/it]Evaluating commonsenseqa :  28%|████▍           | 14/50 [20:29<52:00, 86.68s/it]Evaluating commonsenseqa :  30%|████▊           | 15/50 [21:57<50:46, 87.05s/it]Evaluating commonsenseqa :  32%|█████           | 16/50 [23:25<49:30, 87.38s/it]Evaluating commonsenseqa :  34%|█████▍          | 17/50 [24:53<48:11, 87.61s/it]Evaluating commonsenseqa :  36%|█████▊          | 18/50 [26:18<46:21, 86.92s/it]Evaluating commonsenseqa :  38%|██████          | 19/50 [27:45<44:55, 86.96s/it]Evaluating commonsenseqa :  40%|██████▍         | 20/50 [29:15<43:49, 87.65s/it]Evaluating commonsenseqa :  42%|██████▋         | 21/50 [30:43<42:24, 87.75s/it]Evaluating commonsenseqa :  44%|███████         | 22/50 [32:09<40:41, 87.21s/it]Evaluating commonsenseqa :  46%|███████▎        | 23/50 [33:37<39:21, 87.45s/it]Evaluating commonsenseqa :  48%|███████▋        | 24/50 [35:05<37:57, 87.60s/it]Evaluating commonsenseqa :  50%|████████        | 25/50 [36:31<36:21, 87.26s/it]Evaluating commonsenseqa :  52%|████████▎       | 26/50 [37:57<34:48, 87.02s/it]Evaluating commonsenseqa :  54%|████████▋       | 27/50 [39:25<33:25, 87.22s/it]Evaluating commonsenseqa :  56%|████████▉       | 28/50 [40:53<32:02, 87.37s/it]Evaluating commonsenseqa :  58%|█████████▎      | 29/50 [42:15<30:03, 85.88s/it]Evaluating commonsenseqa :  60%|█████████▌      | 30/50 [43:41<28:37, 85.88s/it]Evaluating commonsenseqa :  62%|█████████▉      | 31/50 [45:09<27:22, 86.44s/it]Evaluating commonsenseqa :  64%|██████████▏     | 32/50 [46:36<25:57, 86.51s/it]Evaluating commonsenseqa :  66%|██████████▌     | 33/50 [48:03<24:34, 86.72s/it]Evaluating commonsenseqa :  68%|██████████▉     | 34/50 [49:29<23:06, 86.68s/it]Evaluating commonsenseqa :  70%|███████████▏    | 35/50 [50:58<21:49, 87.28s/it]Evaluating commonsenseqa :  72%|███████████▌    | 36/50 [51:59<18:29, 79.26s/it]Evaluating commonsenseqa :  74%|███████████▊    | 37/50 [53:27<17:46, 82.01s/it]Evaluating commonsenseqa :  76%|████████████▏   | 38/50 [54:13<14:16, 71.33s/it]Evaluating commonsenseqa :  78%|████████████▍   | 39/50 [55:41<13:58, 76.25s/it]Evaluating commonsenseqa :  80%|████████████▊   | 40/50 [57:10<13:19, 79.91s/it]Evaluating commonsenseqa :  82%|█████████████   | 41/50 [58:37<12:20, 82.24s/it]Evaluating commonsenseqa :  84%|███████████▊  | 42/50 [1:00:04<11:07, 83.44s/it]Evaluating commonsenseqa :  86%|████████████  | 43/50 [1:01:31<09:51, 84.51s/it]Evaluating commonsenseqa :  88%|████████████▎ | 44/50 [1:02:58<08:31, 85.27s/it]Evaluating commonsenseqa :  90%|████████████▌ | 45/50 [1:04:26<07:10, 86.07s/it]Evaluating commonsenseqa :  92%|████████████▉ | 46/50 [1:05:54<05:46, 86.73s/it]Evaluating commonsenseqa :  94%|█████████████▏| 47/50 [1:07:22<04:21, 87.29s/it]Evaluating commonsenseqa :  96%|█████████████▍| 48/50 [1:08:51<02:55, 87.58s/it]Evaluating commonsenseqa :  98%|█████████████▋| 49/50 [1:10:17<01:27, 87.32s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:11:45<00:00, 87.32s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:11:45<00:00, 86.10s/it]
name: commonsenseqa | avg. gen lenth: 297.568 | time: 4305.621978759766s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o24-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 24
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 14:57:18,524] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 14:57:18,908] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 14:57:18,912] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 14:57:18,980] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o24-tgsm8k-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 24
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o24-tgsm8k-s10-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████| 9741/9741 [00:00<00:00, 322648.96it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.01s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.12s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.21s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.18s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.15s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.60s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.13s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.56s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.17s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.63s/it]
[2023-08-30 14:57:29,496] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 14:57:29,511] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 14:57:29,564] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.10s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.56s/it]
 > number of parameters: 6738415616
[2023-08-30 14:57:29,888] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 14:57:30,453] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-30 14:57:30,455] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-30 14:57:30,455] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-30 14:57:30,455] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-30 14:57:30,455] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-30 14:57:30,455] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-30 14:57:30,455] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-30 14:57:30,455] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-30 14:57:30,455] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-30 14:57:30,455] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-30 14:57:30,455] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-30 14:57:30,455] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fc2d0fbd2d0>
[2023-08-30 14:57:30,455] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-30 14:57:30,455] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-30 14:57:30,455] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-30 14:57:30,455] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-30 14:57:30,455] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-30 14:57:30,455] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-30 14:57:30,455] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-30 14:57:30,455] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-30 14:57:30,455] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-30 14:57:30,456] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-30 14:57:30,456] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: 868

Input: Stella and Twinkle are filling up a truck with a capacity of 6000 stone blocks at the rate of 250 blocks per hour per person. They work for four hours and are then joined by 6 other people who also work at the same rate. How many hours did filling the truck take?
Output: 6

Input: Elijah drank 8.5 pints of coffee yesterday. Emilio drank 9.5 pints of water yesterday. How many cups of liquid did the two boys drink yesterday?
Output: 36

Input: Doris works at the Widget Factory in the packing department. She puts 3 widgets in each carton, which are 4 inches wide, 4 inches long, and 5 inches tall. She then packs those cartons into a shipping box before sending it to the loading bay. The shipping boxes are 20 inches wide, 20 inches long, and 20 inches high. How many widgets get shipped in each shipping box?
Output: 300

Input: Queenie earns $150 a day as a part-time clerk. She earns an additional $5 per hour as overtime pay. How much will Queenie receive for working 5 days with 4 hours overtime?
Output: 770

Input: Jodi starts off walking 1 mile a day for 6 days a week.  On the second week, she walks 2 miles a day, 6 days a week.  On the third week, she walks 3 miles a day, 6 days a week. Finally on the fourth week, she walks 4 miles a day, 6 days a week.  How many miles has she walked in 4 weeks?
Output: 60

Input: A club is going to get additional members so that they will have 5 more than twice their current number of their members. If the club has 10 members now, how many additional members do they need?
Output: 15

Input: Andrea buys herself a pony for her 30th birthday. She pays $500/month to rent a pasture for it, $10 a day for food, and $60/lesson for two lessons a week. How much does she spend on her pony in a year?
Output: 15890

Input: A pet shop has 2 puppies and some kittens. A puppy costs $20, and a kitten costs $15. If the stock is worth $100, how many kittens does the pet shop have?
Output: 4

Input: Noah, who loves his Grammy, calls her every week to talk about his day. If each call lasts 30 minutes and he is charged $0.05 per call minute, how much would he be billed if he makes the calls for a year?
Output: 78

Input: A merchant bought 15 keyboards and 25 printers for a total of $2050. If a keyboard costs $20, how much does a printer cost?
Output: 70

Input: Gina has two bank accounts. Each account has a quarter of the balance in Betty's account. If Betty's account balance is $3,456, what is the combined balance of both Gina's accounts?
Output: 1728

Input: Zain has 10 more of each coin than Emerie. If Emerie has six quarters, seven dimes, and five nickels, how many coins does Zain have?
Output: 48

Input: Adonis is playing a prank on his dad by replacing his shampoo with hot sauce. Every day, after his dad showers, Adonis replaces the shampoo with 1/2 an ounce of hot sauce. He knows his dad uses 1 oz of shampoo a day from a new 10 oz bottle that no one else uses. After 4 days, what percentage of the liquid in the bottle is hot sauce?
Output: 25

Input: Lana and Mike are taking their dog and renting a cabin in the mountains for 2 weeks.  The daily rate is $125.00  There is a $100.00 pet fee.  There is also a 20% service/cleaning fee for the rental.  They need to pay 50% of the entire bill as a security deposit.  How much is their security deposit?
Output: 1110

Input: Abigail is trying a new recipe for a cold drink. It uses 1/4 of a cup of iced tea and 1 and 1/4 of a cup of lemonade to make one drink. If she fills a pitcher with 18 total cups of this drink, how many cups of lemonade are in the pitcher?
Output: 15

Input: John buys a vacuum cleaner for $250 and a dishwasher for $450.  She has a $75 off coupon.  How much did he spend?
Output: 625

Input: Dany owns a farm, in his farm he has 4 cows and 3 sheep that eat 2 bushels a day. He also has 7 chickens that eat 3 bushels a day. How many bushels should he have to suffice the animals for a day?
Output: 35

Input: The town of Belize has 400 homes. One fourth of the town's homes are white. One fifth of the non-white homes have a fireplace. How many of the non-white homes do not have a fireplace?
Output: 240

Input: In a race, there are eight runners. The first five runners finish the race in 8 hours, while the rest of the runners finish the race 2 hours later. Calculate the total time the eight runners took to finish the race.
Output: 70

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o24-tgsm8k-s10-rFalse-m4096
Evaluating commonsenseqa :   2%|▎              | 1/50 [01:28<1:12:20, 88.59s/it]Evaluating commonsenseqa :   4%|▌              | 2/50 [02:53<1:09:01, 86.29s/it]Evaluating commonsenseqa :   6%|▉              | 3/50 [04:20<1:08:05, 86.92s/it]Evaluating commonsenseqa :   8%|█▎               | 4/50 [05:10<55:11, 71.98s/it]Evaluating commonsenseqa :  10%|█▋               | 5/50 [06:35<57:45, 77.00s/it]Evaluating commonsenseqa :  12%|██               | 6/50 [08:01<58:43, 80.08s/it]Evaluating commonsenseqa :  14%|██▍              | 7/50 [08:35<46:32, 64.94s/it]Evaluating commonsenseqa :  16%|██▋              | 8/50 [10:03<50:30, 72.16s/it]Evaluating commonsenseqa :  18%|███              | 9/50 [11:30<52:27, 76.76s/it]Evaluating commonsenseqa :  20%|███▏            | 10/50 [12:56<53:05, 79.65s/it]Evaluating commonsenseqa :  22%|███▌            | 11/50 [14:22<53:04, 81.66s/it]Evaluating commonsenseqa :  24%|███▊            | 12/50 [15:48<52:35, 83.03s/it]Evaluating commonsenseqa :  26%|████▏           | 13/50 [17:14<51:37, 83.71s/it]Evaluating commonsenseqa :  28%|████▍           | 14/50 [18:40<50:43, 84.55s/it]Evaluating commonsenseqa :  30%|████▊           | 15/50 [20:06<49:33, 84.95s/it]Evaluating commonsenseqa :  32%|█████           | 16/50 [21:32<48:23, 85.40s/it]Evaluating commonsenseqa :  34%|█████▍          | 17/50 [22:59<47:06, 85.65s/it]Evaluating commonsenseqa :  36%|█████▊          | 18/50 [24:26<45:55, 86.11s/it]Evaluating commonsenseqa :  38%|██████          | 19/50 [25:53<44:39, 86.42s/it]Evaluating commonsenseqa :  40%|██████▍         | 20/50 [27:18<43:02, 86.08s/it]Evaluating commonsenseqa :  42%|██████▋         | 21/50 [28:44<41:37, 86.12s/it]Evaluating commonsenseqa :  44%|███████         | 22/50 [30:12<40:22, 86.53s/it]Evaluating commonsenseqa :  46%|███████▎        | 23/50 [31:13<35:30, 78.91s/it]Evaluating commonsenseqa :  48%|███████▋        | 24/50 [32:40<35:10, 81.19s/it]Evaluating commonsenseqa :  50%|████████        | 25/50 [34:05<34:24, 82.58s/it]Evaluating commonsenseqa :  52%|████████▎       | 26/50 [35:32<33:29, 83.73s/it]Evaluating commonsenseqa :  54%|████████▋       | 27/50 [36:58<32:26, 84.62s/it]Evaluating commonsenseqa :  56%|████████▉       | 28/50 [38:25<31:11, 85.06s/it]Evaluating commonsenseqa :  58%|█████████▎      | 29/50 [39:51<29:54, 85.47s/it]Evaluating commonsenseqa :  60%|█████████▌      | 30/50 [41:18<28:37, 85.86s/it]Evaluating commonsenseqa :  62%|█████████▉      | 31/50 [42:44<27:15, 86.06s/it]Evaluating commonsenseqa :  64%|██████████▏     | 32/50 [44:10<25:45, 85.87s/it]Evaluating commonsenseqa :  66%|██████████▌     | 33/50 [45:36<24:23, 86.09s/it]Evaluating commonsenseqa :  68%|██████████▉     | 34/50 [47:03<22:59, 86.23s/it]Evaluating commonsenseqa :  70%|███████████▏    | 35/50 [48:31<21:40, 86.72s/it]Evaluating commonsenseqa :  72%|███████████▌    | 36/50 [49:56<20:08, 86.34s/it]Evaluating commonsenseqa :  74%|███████████▊    | 37/50 [51:22<18:39, 86.09s/it]Evaluating commonsenseqa :  76%|████████████▏   | 38/50 [52:47<17:10, 85.87s/it]Evaluating commonsenseqa :  78%|████████████▍   | 39/50 [54:14<15:47, 86.13s/it]Evaluating commonsenseqa :  80%|████████████▊   | 40/50 [55:40<14:21, 86.11s/it]Evaluating commonsenseqa :  82%|█████████████   | 41/50 [56:25<11:04, 73.86s/it]Evaluating commonsenseqa :  84%|█████████████▍  | 42/50 [57:51<10:18, 77.32s/it]Evaluating commonsenseqa :  86%|█████████████▊  | 43/50 [59:16<09:18, 79.77s/it]Evaluating commonsenseqa :  88%|████████████▎ | 44/50 [1:00:43<08:11, 81.84s/it]Evaluating commonsenseqa :  90%|████████████▌ | 45/50 [1:02:10<06:56, 83.38s/it]Evaluating commonsenseqa :  92%|████████████▉ | 46/50 [1:03:35<05:35, 83.90s/it]Evaluating commonsenseqa :  94%|█████████████▏| 47/50 [1:05:00<04:13, 84.38s/it]Evaluating commonsenseqa :  96%|█████████████▍| 48/50 [1:06:28<02:50, 85.35s/it]Evaluating commonsenseqa :  98%|█████████████▋| 49/50 [1:07:55<01:25, 85.86s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:09:21<00:00, 86.02s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:09:21<00:00, 83.24s/it]
name: commonsenseqa | avg. gen lenth: 309.316 | time: 4162.251200675964s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o25-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 25
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 16:08:35,591] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 16:08:35,594] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 16:08:35,659] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 16:08:35,659] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o25-tgsm8k-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 25
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o25-tgsm8k-s10-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████| 9741/9741 [00:00<00:00, 396532.39it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:06<00:06,  6.44s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:06<00:06,  6.70s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.01s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.16s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  3.83s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  4.22s/it]
[2023-08-30 16:08:45,522] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  4.08s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  4.47s/it]
[2023-08-30 16:08:45,837] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.13s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.56s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.17s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.62s/it]
[2023-08-30 16:08:46,161] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
 > number of parameters: 6738415616
[2023-08-30 16:08:46,275] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 16:08:46,919] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-30 16:08:46,921] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-30 16:08:46,921] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-30 16:08:46,921] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-30 16:08:46,921] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-30 16:08:46,921] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-30 16:08:46,922] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-30 16:08:46,922] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-30 16:08:46,922] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-30 16:08:46,922] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-30 16:08:46,922] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-30 16:08:46,922] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f55a67d12d0>
[2023-08-30 16:08:46,922] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-30 16:08:46,922] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-30 16:08:46,922] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-30 16:08:46,922] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-30 16:08:46,922] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-30 16:08:46,922] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-30 16:08:46,922] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-30 16:08:46,922] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-30 16:08:46,922] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-30 16:08:46,922] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-30 16:08:46,922] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-30 16:08:46,922] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-30 16:08:46,922] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-30 16:08:46,922] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-30 16:08:46,922] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-30 16:08:46,922] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-30 16:08:46,922] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-30 16:08:46,922] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-30 16:08:46,922] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-30 16:08:46,922] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-30 16:08:46,923] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-30 16:08:46,924] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-30 16:08:46,924] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-30 16:08:46,924] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-30 16:08:46,924] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: 868

Input: Stella and Twinkle are filling up a truck with a capacity of 6000 stone blocks at the rate of 250 blocks per hour per person. They work for four hours and are then joined by 6 other people who also work at the same rate. How many hours did filling the truck take?
Output: 6

Input: Elijah drank 8.5 pints of coffee yesterday. Emilio drank 9.5 pints of water yesterday. How many cups of liquid did the two boys drink yesterday?
Output: 36

Input: Doris works at the Widget Factory in the packing department. She puts 3 widgets in each carton, which are 4 inches wide, 4 inches long, and 5 inches tall. She then packs those cartons into a shipping box before sending it to the loading bay. The shipping boxes are 20 inches wide, 20 inches long, and 20 inches high. How many widgets get shipped in each shipping box?
Output: 300

Input: Queenie earns $150 a day as a part-time clerk. She earns an additional $5 per hour as overtime pay. How much will Queenie receive for working 5 days with 4 hours overtime?
Output: 770

Input: Jodi starts off walking 1 mile a day for 6 days a week.  On the second week, she walks 2 miles a day, 6 days a week.  On the third week, she walks 3 miles a day, 6 days a week. Finally on the fourth week, she walks 4 miles a day, 6 days a week.  How many miles has she walked in 4 weeks?
Output: 60

Input: A club is going to get additional members so that they will have 5 more than twice their current number of their members. If the club has 10 members now, how many additional members do they need?
Output: 15

Input: Andrea buys herself a pony for her 30th birthday. She pays $500/month to rent a pasture for it, $10 a day for food, and $60/lesson for two lessons a week. How much does she spend on her pony in a year?
Output: 15890

Input: A pet shop has 2 puppies and some kittens. A puppy costs $20, and a kitten costs $15. If the stock is worth $100, how many kittens does the pet shop have?
Output: 4

Input: Noah, who loves his Grammy, calls her every week to talk about his day. If each call lasts 30 minutes and he is charged $0.05 per call minute, how much would he be billed if he makes the calls for a year?
Output: 78

Input: A merchant bought 15 keyboards and 25 printers for a total of $2050. If a keyboard costs $20, how much does a printer cost?
Output: 70

Input: Gina has two bank accounts. Each account has a quarter of the balance in Betty's account. If Betty's account balance is $3,456, what is the combined balance of both Gina's accounts?
Output: 1728

Input: Zain has 10 more of each coin than Emerie. If Emerie has six quarters, seven dimes, and five nickels, how many coins does Zain have?
Output: 48

Input: Adonis is playing a prank on his dad by replacing his shampoo with hot sauce. Every day, after his dad showers, Adonis replaces the shampoo with 1/2 an ounce of hot sauce. He knows his dad uses 1 oz of shampoo a day from a new 10 oz bottle that no one else uses. After 4 days, what percentage of the liquid in the bottle is hot sauce?
Output: 25

Input: Lana and Mike are taking their dog and renting a cabin in the mountains for 2 weeks.  The daily rate is $125.00  There is a $100.00 pet fee.  There is also a 20% service/cleaning fee for the rental.  They need to pay 50% of the entire bill as a security deposit.  How much is their security deposit?
Output: 1110

Input: Abigail is trying a new recipe for a cold drink. It uses 1/4 of a cup of iced tea and 1 and 1/4 of a cup of lemonade to make one drink. If she fills a pitcher with 18 total cups of this drink, how many cups of lemonade are in the pitcher?
Output: 15

Input: John buys a vacuum cleaner for $250 and a dishwasher for $450.  She has a $75 off coupon.  How much did he spend?
Output: 625

Input: Dany owns a farm, in his farm he has 4 cows and 3 sheep that eat 2 bushels a day. He also has 7 chickens that eat 3 bushels a day. How many bushels should he have to suffice the animals for a day?
Output: 35

Input: The town of Belize has 400 homes. One fourth of the town's homes are white. One fifth of the non-white homes have a fireplace. How many of the non-white homes do not have a fireplace?
Output: 240

Input: In a race, there are eight runners. The first five runners finish the race in 8 hours, while the rest of the runners finish the race 2 hours later. Calculate the total time the eight runners took to finish the race.
Output: 70

Input: Hannah is trying to figure out how much she'll get paid this week. She makes $30/hour and works 18 hours per week. Her pay is docked $5 each time she's late. If she was late 3 times this week, how much does she get paid?
Output: 525

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o25-tgsm8k-s10-rFalse-m4096
Evaluating commonsenseqa :   2%|▎              | 1/50 [01:25<1:09:58, 85.67s/it]Evaluating commonsenseqa :   4%|▌              | 2/50 [02:49<1:07:30, 84.39s/it]Evaluating commonsenseqa :   6%|▉              | 3/50 [04:13<1:06:02, 84.30s/it]Evaluating commonsenseqa :   8%|█▏             | 4/50 [05:40<1:05:23, 85.30s/it]Evaluating commonsenseqa :  10%|█▌             | 5/50 [07:03<1:03:27, 84.61s/it]Evaluating commonsenseqa :  12%|█▊             | 6/50 [08:27<1:01:55, 84.43s/it]Evaluating commonsenseqa :  14%|██             | 7/50 [09:51<1:00:28, 84.39s/it]Evaluating commonsenseqa :  16%|██▋              | 8/50 [11:16<59:04, 84.40s/it]Evaluating commonsenseqa :  18%|███              | 9/50 [12:40<57:39, 84.37s/it]Evaluating commonsenseqa :  20%|███▏            | 10/50 [14:06<56:34, 84.87s/it]Evaluating commonsenseqa :  22%|███▌            | 11/50 [15:31<55:14, 84.98s/it]Evaluating commonsenseqa :  24%|███▊            | 12/50 [16:56<53:47, 84.95s/it]Evaluating commonsenseqa :  26%|████▏           | 13/50 [18:20<52:04, 84.45s/it]Evaluating commonsenseqa :  28%|████▍           | 14/50 [19:44<50:37, 84.39s/it]Evaluating commonsenseqa :  30%|████▊           | 15/50 [21:07<49:04, 84.12s/it]Evaluating commonsenseqa :  32%|█████           | 16/50 [22:33<47:51, 84.46s/it]Evaluating commonsenseqa :  34%|█████▍          | 17/50 [23:58<46:31, 84.60s/it]Evaluating commonsenseqa :  36%|█████▊          | 18/50 [25:23<45:11, 84.75s/it]Evaluating commonsenseqa :  38%|██████          | 19/50 [26:46<43:36, 84.42s/it]Evaluating commonsenseqa :  40%|██████▍         | 20/50 [28:13<42:33, 85.13s/it]Evaluating commonsenseqa :  42%|██████▋         | 21/50 [29:39<41:12, 85.26s/it]Evaluating commonsenseqa :  44%|███████         | 22/50 [31:04<39:47, 85.28s/it]Evaluating commonsenseqa :  46%|███████▎        | 23/50 [32:29<38:18, 85.14s/it]Evaluating commonsenseqa :  48%|███████▋        | 24/50 [33:54<36:54, 85.17s/it]Evaluating commonsenseqa :  50%|████████        | 25/50 [35:20<35:33, 85.33s/it]Evaluating commonsenseqa :  52%|████████▎       | 26/50 [36:45<34:08, 85.35s/it]Evaluating commonsenseqa :  54%|████████▋       | 27/50 [38:09<32:31, 84.84s/it]Evaluating commonsenseqa :  56%|████████▉       | 28/50 [39:34<31:09, 84.98s/it]Evaluating commonsenseqa :  58%|█████████▎      | 29/50 [40:59<29:41, 84.83s/it]Evaluating commonsenseqa :  60%|█████████▌      | 30/50 [42:23<28:15, 84.80s/it]Evaluating commonsenseqa :  62%|█████████▉      | 31/50 [43:42<26:18, 83.10s/it]Evaluating commonsenseqa :  64%|██████████▏     | 32/50 [45:07<25:02, 83.47s/it]Evaluating commonsenseqa :  66%|██████████▌     | 33/50 [46:32<23:49, 84.08s/it]Evaluating commonsenseqa :  68%|██████████▉     | 34/50 [47:57<22:28, 84.26s/it]Evaluating commonsenseqa :  70%|███████████▏    | 35/50 [49:23<21:10, 84.71s/it]Evaluating commonsenseqa :  72%|███████████▌    | 36/50 [50:46<19:41, 84.41s/it]Evaluating commonsenseqa :  74%|███████████▊    | 37/50 [52:11<18:19, 84.56s/it]Evaluating commonsenseqa :  76%|████████████▏   | 38/50 [53:38<17:02, 85.21s/it]Evaluating commonsenseqa :  78%|████████████▍   | 39/50 [55:02<15:34, 84.91s/it]Evaluating commonsenseqa :  80%|████████████▊   | 40/50 [56:28<14:12, 85.25s/it]Evaluating commonsenseqa :  82%|█████████████   | 41/50 [57:51<12:39, 84.42s/it]Evaluating commonsenseqa :  84%|█████████████▍  | 42/50 [59:15<11:14, 84.33s/it]Evaluating commonsenseqa :  86%|████████████  | 43/50 [1:00:41<09:54, 84.88s/it]Evaluating commonsenseqa :  88%|████████████▎ | 44/50 [1:02:04<08:26, 84.45s/it]Evaluating commonsenseqa :  90%|████████████▌ | 45/50 [1:03:28<07:01, 84.27s/it]Evaluating commonsenseqa :  92%|████████████▉ | 46/50 [1:04:53<05:37, 84.29s/it]Evaluating commonsenseqa :  94%|█████████████▏| 47/50 [1:06:17<04:13, 84.43s/it]Evaluating commonsenseqa :  96%|█████████████▍| 48/50 [1:07:42<02:49, 84.61s/it]Evaluating commonsenseqa :  98%|█████████████▋| 49/50 [1:09:06<01:24, 84.38s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:10:31<00:00, 84.36s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:10:31<00:00, 84.62s/it]
name: commonsenseqa | avg. gen lenth: 307.52 | time: 4231.548759460449s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 17:19:27,465] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 17:19:27,484] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 17:19:27,499] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 17:19:27,506] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 1
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o1-tgsm8k-s20-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|████████████████████| 9741/9741 [00:00<00:00, 1264561.43it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.18s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.28s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.27s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.21s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.19s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.64s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.24s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.70s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.25s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.70s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.20s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.65s/it]
[2023-08-30 17:19:38,213] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 17:19:38,223] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
 > number of parameters: 6738415616
[2023-08-30 17:19:38,233] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 17:19:38,252] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 17:19:38,809] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-30 17:19:38,810] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f3001ac12d0>
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-30 17:19:38,811] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-30 17:19:38,812] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-30 17:19:38,812] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: 29

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o1-tgsm8k-s20-rFalse-m4096
Evaluating commonsenseqa :   2%|▎              | 1/50 [01:16<1:02:39, 76.73s/it]Evaluating commonsenseqa :   4%|▌             | 2/50 [03:37<1:31:37, 114.53s/it]Evaluating commonsenseqa :   6%|▊             | 3/50 [05:56<1:38:28, 125.71s/it]Evaluating commonsenseqa :   8%|█             | 4/50 [08:21<1:42:09, 133.24s/it]Evaluating commonsenseqa :  10%|█▍            | 5/50 [10:43<1:42:25, 136.57s/it]Evaluating commonsenseqa :  12%|█▋            | 6/50 [13:06<1:41:35, 138.52s/it]Evaluating commonsenseqa :  14%|█▉            | 7/50 [14:43<1:29:34, 124.99s/it]Evaluating commonsenseqa :  16%|██▏           | 8/50 [17:06<1:31:37, 130.90s/it]Evaluating commonsenseqa :  18%|██▌           | 9/50 [19:18<1:29:37, 131.16s/it]Evaluating commonsenseqa :  20%|██▌          | 10/50 [21:40<1:29:37, 134.43s/it]Evaluating commonsenseqa :  22%|██▊          | 11/50 [24:01<1:28:36, 136.32s/it]Evaluating commonsenseqa :  24%|███          | 12/50 [25:21<1:15:34, 119.33s/it]Evaluating commonsenseqa :  26%|███▍         | 13/50 [27:42<1:17:37, 125.88s/it]Evaluating commonsenseqa :  28%|███▋         | 14/50 [30:02<1:18:06, 130.17s/it]Evaluating commonsenseqa :  30%|███▉         | 15/50 [32:24<1:18:02, 133.78s/it]Evaluating commonsenseqa :  32%|████▏        | 16/50 [34:43<1:16:35, 135.16s/it]Evaluating commonsenseqa :  34%|████▍        | 17/50 [37:03<1:15:14, 136.79s/it]Evaluating commonsenseqa :  36%|████▋        | 18/50 [39:25<1:13:48, 138.39s/it]Evaluating commonsenseqa :  38%|█████▋         | 19/50 [40:10<56:59, 110.32s/it]Evaluating commonsenseqa :  40%|██████         | 20/50 [42:30<59:33, 119.13s/it]Evaluating commonsenseqa :  42%|█████▍       | 21/50 [44:49<1:00:32, 125.26s/it]Evaluating commonsenseqa :  44%|█████▋       | 22/50 [47:10<1:00:39, 129.99s/it]Evaluating commonsenseqa :  46%|█████▉       | 23/50 [49:34<1:00:22, 134.16s/it]Evaluating commonsenseqa :  48%|███████▏       | 24/50 [51:55<58:58, 136.11s/it]Evaluating commonsenseqa :  50%|███████▌       | 25/50 [52:52<46:50, 112.44s/it]Evaluating commonsenseqa :  52%|███████▊       | 26/50 [55:11<48:07, 120.32s/it]Evaluating commonsenseqa :  54%|████████       | 27/50 [56:25<40:45, 106.35s/it]Evaluating commonsenseqa :  56%|████████▍      | 28/50 [58:44<42:40, 116.39s/it]Evaluating commonsenseqa :  58%|███████▌     | 29/50 [1:01:08<43:32, 124.39s/it]Evaluating commonsenseqa :  60%|███████▊     | 30/50 [1:03:16<41:51, 125.56s/it]Evaluating commonsenseqa :  62%|████████     | 31/50 [1:05:38<41:18, 130.46s/it]Evaluating commonsenseqa :  64%|████████▎    | 32/50 [1:07:58<40:02, 133.47s/it]Evaluating commonsenseqa :  66%|████████▌    | 33/50 [1:10:22<38:41, 136.54s/it]Evaluating commonsenseqa :  68%|████████▊    | 34/50 [1:12:41<36:38, 137.40s/it]Evaluating commonsenseqa :  70%|█████████    | 35/50 [1:15:04<34:43, 138.93s/it]Evaluating commonsenseqa :  72%|█████████▎   | 36/50 [1:17:29<32:49, 140.69s/it]Evaluating commonsenseqa :  74%|█████████▌   | 37/50 [1:18:13<24:13, 111.82s/it]Evaluating commonsenseqa :  76%|█████████▉   | 38/50 [1:20:35<24:10, 120.84s/it]Evaluating commonsenseqa :  78%|██████████▏  | 39/50 [1:22:56<23:15, 126.91s/it]Evaluating commonsenseqa :  80%|██████████▍  | 40/50 [1:25:15<21:45, 130.57s/it]Evaluating commonsenseqa :  82%|██████████▋  | 41/50 [1:27:35<20:01, 133.47s/it]Evaluating commonsenseqa :  84%|██████████▉  | 42/50 [1:29:55<18:02, 135.31s/it]Evaluating commonsenseqa :  86%|███████████▏ | 43/50 [1:30:34<12:24, 106.38s/it]Evaluating commonsenseqa :  88%|███████████▍ | 44/50 [1:32:56<11:41, 116.98s/it]Evaluating commonsenseqa :  90%|███████████▋ | 45/50 [1:35:17<10:20, 124.19s/it]Evaluating commonsenseqa :  92%|███████████▉ | 46/50 [1:37:38<08:37, 129.48s/it]Evaluating commonsenseqa :  94%|████████████▏| 47/50 [1:40:01<06:40, 133.56s/it]Evaluating commonsenseqa :  96%|████████████▍| 48/50 [1:42:21<04:30, 135.41s/it]Evaluating commonsenseqa :  98%|████████████▋| 49/50 [1:44:44<02:17, 137.56s/it]Evaluating commonsenseqa : 100%|█████████████| 50/50 [1:45:31<00:00, 110.60s/it]Evaluating commonsenseqa : 100%|█████████████| 50/50 [1:45:31<00:00, 126.64s/it]
name: commonsenseqa | avg. gen lenth: 246.944 | time: 6332.196232557297s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 2
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 19:13:06,761] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 19:13:06,772] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 19:13:06,819] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 19:13:06,820] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 2
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o2-tgsm8k-s20-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|████████████████████| 9741/9741 [00:00<00:00, 1087829.90it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.44s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.55s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.60s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.68s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.23s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.71s/it]
[2023-08-30 19:13:17,562] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.38s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.85s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.39s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.87s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.39s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.88s/it]
[2023-08-30 19:13:17,755] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 19:13:17,840] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
 > number of parameters: 6738415616
[2023-08-30 19:13:17,869] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 19:13:18,383] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-30 19:13:18,384] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f7938dbd2d0>
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-30 19:13:18,385] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-30 19:13:18,386] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-30 19:13:18,386] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: 10

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o2-tgsm8k-s20-rFalse-m4096
Evaluating commonsenseqa :   2%|▎             | 1/50 [02:18<1:53:06, 138.49s/it]Evaluating commonsenseqa :   4%|▌             | 2/50 [04:30<1:47:43, 134.65s/it]Evaluating commonsenseqa :   6%|▊             | 3/50 [06:43<1:44:46, 133.76s/it]Evaluating commonsenseqa :   8%|█             | 4/50 [08:58<1:43:00, 134.37s/it]Evaluating commonsenseqa :  10%|█▍            | 5/50 [11:15<1:41:30, 135.34s/it]Evaluating commonsenseqa :  12%|█▋            | 6/50 [13:34<1:40:02, 136.41s/it]Evaluating commonsenseqa :  14%|█▉            | 7/50 [15:52<1:38:13, 137.05s/it]Evaluating commonsenseqa :  16%|██▏           | 8/50 [18:06<1:35:22, 136.25s/it]Evaluating commonsenseqa :  18%|██▌           | 9/50 [20:24<1:33:17, 136.54s/it]Evaluating commonsenseqa :  20%|██▌          | 10/50 [21:48<1:20:19, 120.50s/it]Evaluating commonsenseqa :  22%|██▊          | 11/50 [24:04<1:21:28, 125.34s/it]Evaluating commonsenseqa :  24%|███          | 12/50 [26:23<1:21:59, 129.47s/it]Evaluating commonsenseqa :  26%|███▍         | 13/50 [27:31<1:08:12, 110.61s/it]Evaluating commonsenseqa :  28%|████▍           | 14/50 [28:36<58:13, 97.04s/it]Evaluating commonsenseqa :  30%|███▉         | 15/50 [30:50<1:03:07, 108.21s/it]Evaluating commonsenseqa :  32%|████▏        | 16/50 [32:50<1:03:15, 111.63s/it]Evaluating commonsenseqa :  34%|████▍        | 17/50 [35:05<1:05:11, 118.54s/it]Evaluating commonsenseqa :  36%|████▋        | 18/50 [37:25<1:06:41, 125.04s/it]Evaluating commonsenseqa :  38%|████▉        | 19/50 [39:40<1:06:08, 128.01s/it]Evaluating commonsenseqa :  40%|██████         | 20/50 [40:37<53:22, 106.77s/it]Evaluating commonsenseqa :  42%|██████▎        | 21/50 [42:51<55:32, 114.91s/it]Evaluating commonsenseqa :  44%|██████▌        | 22/50 [45:06<56:30, 121.09s/it]Evaluating commonsenseqa :  46%|██████▉        | 23/50 [46:56<53:00, 117.80s/it]Evaluating commonsenseqa :  48%|███████▏       | 24/50 [49:10<53:08, 122.62s/it]Evaluating commonsenseqa :  50%|███████▌       | 25/50 [50:53<48:38, 116.73s/it]Evaluating commonsenseqa :  52%|███████▊       | 26/50 [53:10<49:03, 122.66s/it]Evaluating commonsenseqa :  54%|████████       | 27/50 [55:26<48:36, 126.80s/it]Evaluating commonsenseqa :  56%|████████▍      | 28/50 [57:44<47:42, 130.11s/it]Evaluating commonsenseqa :  58%|███████▌     | 29/50 [1:00:01<46:14, 132.14s/it]Evaluating commonsenseqa :  60%|███████▊     | 30/50 [1:02:07<43:24, 130.24s/it]Evaluating commonsenseqa :  62%|████████     | 31/50 [1:04:24<41:52, 132.22s/it]Evaluating commonsenseqa :  64%|████████▎    | 32/50 [1:06:43<40:18, 134.35s/it]Evaluating commonsenseqa :  66%|████████▌    | 33/50 [1:09:02<38:28, 135.78s/it]Evaluating commonsenseqa :  68%|████████▊    | 34/50 [1:10:58<34:37, 129.82s/it]Evaluating commonsenseqa :  70%|█████████    | 35/50 [1:13:13<32:49, 131.31s/it]Evaluating commonsenseqa :  72%|█████████▎   | 36/50 [1:15:26<30:48, 132.02s/it]Evaluating commonsenseqa :  74%|█████████▌   | 37/50 [1:17:17<27:14, 125.73s/it]Evaluating commonsenseqa :  76%|█████████▉   | 38/50 [1:19:10<24:21, 121.78s/it]Evaluating commonsenseqa :  78%|██████████▏  | 39/50 [1:21:22<22:51, 124.71s/it]Evaluating commonsenseqa :  80%|██████████▍  | 40/50 [1:22:54<19:09, 114.93s/it]Evaluating commonsenseqa :  82%|██████████▋  | 41/50 [1:25:12<18:17, 121.92s/it]Evaluating commonsenseqa :  84%|██████████▉  | 42/50 [1:27:27<16:46, 125.83s/it]Evaluating commonsenseqa :  86%|███████████▏ | 43/50 [1:29:40<14:56, 128.10s/it]Evaluating commonsenseqa :  88%|███████████▍ | 44/50 [1:30:46<10:56, 109.41s/it]Evaluating commonsenseqa :  90%|███████████▋ | 45/50 [1:33:02<09:47, 117.52s/it]Evaluating commonsenseqa :  92%|███████████▉ | 46/50 [1:34:10<06:50, 102.54s/it]Evaluating commonsenseqa :  94%|████████████▏| 47/50 [1:36:13<05:25, 108.62s/it]Evaluating commonsenseqa :  96%|████████████▍| 48/50 [1:38:31<03:54, 117.43s/it]Evaluating commonsenseqa :  98%|████████████▋| 49/50 [1:40:45<02:02, 122.45s/it]Evaluating commonsenseqa : 100%|█████████████| 50/50 [1:42:59<00:00, 125.96s/it]Evaluating commonsenseqa : 100%|█████████████| 50/50 [1:42:59<00:00, 123.59s/it]
name: commonsenseqa | avg. gen lenth: 237.332 | time: 6179.954509735107s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o3-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 3
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 20:59:05,747] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 20:59:05,747] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 20:59:05,747] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 20:59:05,774] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o3-tgsm8k-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 3
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o3-tgsm8k-s20-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|████████████████████| 9741/9741 [00:00<00:00, 1017373.82it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.15s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.36s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.42s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.48s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.24s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.68s/it]
[2023-08-30 20:59:16,454] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.31s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.77s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.31s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.78s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.33s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.80s/it]
[2023-08-30 20:59:16,587] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
 > number of parameters: 6738415616
[2023-08-30 20:59:16,655] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 20:59:16,671] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 20:59:17,189] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-30 20:59:17,190] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-30 20:59:17,190] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-30 20:59:17,190] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-30 20:59:17,190] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-30 20:59:17,190] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-30 20:59:17,190] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-30 20:59:17,190] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fb45f6c92d0>
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-30 20:59:17,191] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-30 20:59:17,192] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-30 20:59:17,192] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-30 20:59:17,192] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-30 20:59:17,192] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-30 20:59:17,192] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-30 20:59:17,192] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-30 20:59:17,192] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-30 20:59:17,192] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-30 20:59:17,192] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-30 20:59:17,192] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-30 20:59:17,192] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-30 20:59:17,192] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 5

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o3-tgsm8k-s20-rFalse-m4096
Evaluating commonsenseqa :   2%|▎             | 1/50 [02:15<1:50:50, 135.73s/it]Evaluating commonsenseqa :   4%|▌             | 2/50 [04:30<1:48:04, 135.09s/it]Evaluating commonsenseqa :   6%|▊             | 3/50 [06:42<1:44:55, 133.95s/it]Evaluating commonsenseqa :   8%|█             | 4/50 [09:00<1:43:45, 135.34s/it]Evaluating commonsenseqa :  10%|█▍            | 5/50 [10:28<1:28:45, 118.35s/it]Evaluating commonsenseqa :  12%|█▋            | 6/50 [12:44<1:31:09, 124.30s/it]Evaluating commonsenseqa :  14%|█▉            | 7/50 [14:58<1:31:15, 127.33s/it]Evaluating commonsenseqa :  16%|██▏           | 8/50 [17:11<1:30:24, 129.15s/it]Evaluating commonsenseqa :  18%|██▌           | 9/50 [19:26<1:29:35, 131.10s/it]Evaluating commonsenseqa :  20%|██▌          | 10/50 [21:41<1:28:07, 132.20s/it]Evaluating commonsenseqa :  22%|██▊          | 11/50 [23:57<1:26:50, 133.61s/it]Evaluating commonsenseqa :  24%|███          | 12/50 [25:43<1:19:09, 124.98s/it]Evaluating commonsenseqa :  26%|███▍         | 13/50 [27:56<1:18:32, 127.36s/it]Evaluating commonsenseqa :  28%|███▋         | 14/50 [30:07<1:17:13, 128.72s/it]Evaluating commonsenseqa :  30%|███▉         | 15/50 [32:21<1:15:52, 130.08s/it]Evaluating commonsenseqa :  32%|████▏        | 16/50 [34:32<1:13:57, 130.52s/it]Evaluating commonsenseqa :  34%|████▍        | 17/50 [36:47<1:12:31, 131.87s/it]Evaluating commonsenseqa :  36%|████▋        | 18/50 [39:01<1:10:33, 132.31s/it]Evaluating commonsenseqa :  38%|████▉        | 19/50 [41:14<1:08:30, 132.59s/it]Evaluating commonsenseqa :  40%|█████▏       | 20/50 [42:45<1:00:03, 120.13s/it]Evaluating commonsenseqa :  42%|█████▍       | 21/50 [45:00<1:00:16, 124.71s/it]Evaluating commonsenseqa :  44%|██████▌        | 22/50 [46:53<56:33, 121.18s/it]Evaluating commonsenseqa :  46%|██████▉        | 23/50 [49:09<56:29, 125.55s/it]Evaluating commonsenseqa :  48%|███████▏       | 24/50 [50:04<45:11, 104.28s/it]Evaluating commonsenseqa :  50%|███████▌       | 25/50 [52:15<46:53, 112.54s/it]Evaluating commonsenseqa :  52%|███████▊       | 26/50 [54:31<47:48, 119.52s/it]Evaluating commonsenseqa :  54%|████████       | 27/50 [56:45<47:28, 123.84s/it]Evaluating commonsenseqa :  56%|████████▍      | 28/50 [58:33<43:39, 119.09s/it]Evaluating commonsenseqa :  58%|███████▌     | 29/50 [1:00:00<38:17, 109.41s/it]Evaluating commonsenseqa :  60%|███████▊     | 30/50 [1:02:15<39:01, 117.06s/it]Evaluating commonsenseqa :  62%|████████     | 31/50 [1:04:30<38:45, 122.39s/it]Evaluating commonsenseqa :  64%|████████▎    | 32/50 [1:06:43<37:42, 125.69s/it]Evaluating commonsenseqa :  66%|████████▌    | 33/50 [1:08:57<36:20, 128.28s/it]Evaluating commonsenseqa :  68%|████████▊    | 34/50 [1:11:11<34:37, 129.82s/it]Evaluating commonsenseqa :  70%|█████████    | 35/50 [1:13:26<32:52, 131.52s/it]Evaluating commonsenseqa :  72%|█████████▎   | 36/50 [1:15:21<29:29, 126.43s/it]Evaluating commonsenseqa :  74%|█████████▌   | 37/50 [1:17:35<27:55, 128.86s/it]Evaluating commonsenseqa :  76%|█████████▉   | 38/50 [1:19:48<26:01, 130.09s/it]Evaluating commonsenseqa :  78%|██████████▏  | 39/50 [1:21:59<23:51, 130.15s/it]Evaluating commonsenseqa :  80%|██████████▍  | 40/50 [1:24:13<21:54, 131.49s/it]Evaluating commonsenseqa :  82%|██████████▋  | 41/50 [1:26:28<19:51, 132.44s/it]Evaluating commonsenseqa :  84%|██████████▉  | 42/50 [1:28:01<16:06, 120.77s/it]Evaluating commonsenseqa :  86%|███████████▏ | 43/50 [1:29:20<12:37, 108.24s/it]Evaluating commonsenseqa :  88%|███████████▍ | 44/50 [1:31:35<11:36, 116.01s/it]Evaluating commonsenseqa :  90%|███████████▋ | 45/50 [1:33:48<10:05, 121.14s/it]Evaluating commonsenseqa :  92%|███████████▉ | 46/50 [1:36:04<08:23, 125.76s/it]Evaluating commonsenseqa :  94%|████████████▏| 47/50 [1:38:17<06:23, 127.80s/it]Evaluating commonsenseqa :  96%|████████████▍| 48/50 [1:40:32<04:20, 130.17s/it]Evaluating commonsenseqa :  98%|████████████▋| 49/50 [1:41:39<01:51, 111.03s/it]Evaluating commonsenseqa : 100%|█████████████| 50/50 [1:43:32<00:00, 111.72s/it]Evaluating commonsenseqa : 100%|█████████████| 50/50 [1:43:32<00:00, 124.25s/it]
name: commonsenseqa | avg. gen lenth: 241.732 | time: 6212.946132898331s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o4-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 4
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 22:42:59,411] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 22:42:59,417] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 22:42:59,435] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 22:42:59,481] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o4-tgsm8k-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 4
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o4-tgsm8k-s20-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████| 9741/9741 [00:00<00:00, 955020.11it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:06<00:06,  6.63s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.34s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.41s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.40s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  3.92s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  4.33s/it]
 > number of parameters: 6738415616
[2023-08-30 22:43:09,312] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.19s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.67s/it]
[2023-08-30 22:43:09,971] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.27s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.74s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.27s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.74s/it]
[2023-08-30 22:43:10,136] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 22:43:10,176] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 22:43:10,818] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-30 22:43:10,819] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fdb30dc9300>
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-30 22:43:10,820] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-30 22:43:10,821] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-30 22:43:10,821] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: 600

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o4-tgsm8k-s20-rFalse-m4096
Evaluating commonsenseqa :   2%|▎             | 1/50 [02:13<1:48:57, 133.43s/it]Evaluating commonsenseqa :   4%|▌             | 2/50 [04:25<1:46:04, 132.59s/it]Evaluating commonsenseqa :   6%|▊             | 3/50 [06:35<1:43:03, 131.57s/it]Evaluating commonsenseqa :   8%|█             | 4/50 [08:51<1:42:10, 133.28s/it]Evaluating commonsenseqa :  10%|█▍            | 5/50 [11:02<1:39:21, 132.47s/it]Evaluating commonsenseqa :  12%|█▋            | 6/50 [12:45<1:29:49, 122.48s/it]Evaluating commonsenseqa :  14%|█▉            | 7/50 [14:59<1:30:19, 126.03s/it]Evaluating commonsenseqa :  16%|██▏           | 8/50 [17:09<1:29:11, 127.41s/it]Evaluating commonsenseqa :  18%|██▌           | 9/50 [19:21<1:27:57, 128.72s/it]Evaluating commonsenseqa :  20%|██▌          | 10/50 [20:41<1:15:53, 113.83s/it]Evaluating commonsenseqa :  22%|██▊          | 11/50 [22:53<1:17:30, 119.25s/it]Evaluating commonsenseqa :  24%|███          | 12/50 [25:03<1:17:44, 122.76s/it]Evaluating commonsenseqa :  26%|███▍         | 13/50 [27:14<1:17:08, 125.11s/it]Evaluating commonsenseqa :  28%|███▋         | 14/50 [29:03<1:12:12, 120.35s/it]Evaluating commonsenseqa :  30%|███▉         | 15/50 [31:16<1:12:18, 123.96s/it]Evaluating commonsenseqa :  32%|████▏        | 16/50 [33:26<1:11:20, 125.91s/it]Evaluating commonsenseqa :  34%|████▍        | 17/50 [35:37<1:10:09, 127.56s/it]Evaluating commonsenseqa :  36%|████▋        | 18/50 [37:50<1:08:45, 128.92s/it]Evaluating commonsenseqa :  38%|████▉        | 19/50 [39:53<1:05:47, 127.34s/it]Evaluating commonsenseqa :  40%|█████▏       | 20/50 [42:04<1:04:13, 128.46s/it]Evaluating commonsenseqa :  42%|█████▍       | 21/50 [44:14<1:02:17, 128.86s/it]Evaluating commonsenseqa :  44%|██████▌        | 22/50 [45:53<55:54, 119.79s/it]Evaluating commonsenseqa :  46%|██████▉        | 23/50 [48:01<55:04, 122.38s/it]Evaluating commonsenseqa :  48%|███████▏       | 24/50 [50:13<54:14, 125.18s/it]Evaluating commonsenseqa :  50%|███████▌       | 25/50 [51:49<48:29, 116.38s/it]Evaluating commonsenseqa :  52%|███████▊       | 26/50 [54:01<48:25, 121.07s/it]Evaluating commonsenseqa :  54%|████████       | 27/50 [56:13<47:39, 124.35s/it]Evaluating commonsenseqa :  56%|████████▍      | 28/50 [57:27<40:06, 109.38s/it]Evaluating commonsenseqa :  58%|████████▋      | 29/50 [59:40<40:43, 116.36s/it]Evaluating commonsenseqa :  60%|███████▊     | 30/50 [1:01:51<40:17, 120.85s/it]Evaluating commonsenseqa :  62%|████████     | 31/50 [1:04:03<39:16, 124.03s/it]Evaluating commonsenseqa :  64%|████████▎    | 32/50 [1:05:25<33:25, 111.43s/it]Evaluating commonsenseqa :  66%|████████▌    | 33/50 [1:07:39<33:30, 118.29s/it]Evaluating commonsenseqa :  68%|████████▊    | 34/50 [1:09:50<32:32, 122.04s/it]Evaluating commonsenseqa :  70%|█████████    | 35/50 [1:12:01<31:13, 124.92s/it]Evaluating commonsenseqa :  72%|█████████▎   | 36/50 [1:12:50<23:50, 102.18s/it]Evaluating commonsenseqa :  74%|█████████▌   | 37/50 [1:15:04<24:10, 111.62s/it]Evaluating commonsenseqa :  76%|█████████▉   | 38/50 [1:17:16<23:32, 117.69s/it]Evaluating commonsenseqa :  78%|██████████▏  | 39/50 [1:19:25<22:10, 120.98s/it]Evaluating commonsenseqa :  80%|██████████▍  | 40/50 [1:21:37<20:42, 124.25s/it]Evaluating commonsenseqa :  82%|██████████▋  | 41/50 [1:23:31<18:12, 121.36s/it]Evaluating commonsenseqa :  84%|██████████▉  | 42/50 [1:25:44<16:38, 124.85s/it]Evaluating commonsenseqa :  86%|███████████▏ | 43/50 [1:27:58<14:52, 127.47s/it]Evaluating commonsenseqa :  88%|███████████▍ | 44/50 [1:30:08<12:49, 128.25s/it]Evaluating commonsenseqa :  90%|███████████▋ | 45/50 [1:32:17<10:43, 128.62s/it]Evaluating commonsenseqa :  92%|███████████▉ | 46/50 [1:34:30<08:38, 129.74s/it]Evaluating commonsenseqa :  94%|████████████▏| 47/50 [1:36:41<06:31, 130.35s/it]Evaluating commonsenseqa :  96%|████████████▍| 48/50 [1:38:04<03:51, 115.99s/it]Evaluating commonsenseqa :  98%|█████████████▋| 49/50 [1:38:33<01:29, 89.83s/it]Evaluating commonsenseqa : 100%|█████████████| 50/50 [1:40:42<00:00, 101.72s/it]Evaluating commonsenseqa : 100%|█████████████| 50/50 [1:40:42<00:00, 120.85s/it]
name: commonsenseqa | avg. gen lenth: 235.972 | time: 6042.85479593277s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o5-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 5
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-31 00:25:38,067] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 00:25:38,075] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 00:25:38,143] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 00:25:38,144] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o5-tgsm8k-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 5
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o5-tgsm8k-s20-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████| 9741/9741 [00:00<00:00, 875194.72it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:06<00:06,  6.68s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.17s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.19s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.22s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  3.93s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  4.34s/it]
[2023-08-31 00:25:48,027] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.19s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.64s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.20s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.65s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.21s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.65s/it]
[2023-08-31 00:25:48,569] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 00:25:48,605] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
 > number of parameters: 6738415616
[2023-08-31 00:25:48,627] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 00:25:49,184] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-31 00:25:49,185] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-31 00:25:49,185] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-31 00:25:49,185] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-31 00:25:49,185] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-31 00:25:49,185] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fb3cb2c12d0>
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-31 00:25:49,186] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-31 00:25:49,187] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-31 00:25:49,187] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-31 00:25:49,187] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-31 00:25:49,187] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-31 00:25:49,187] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-31 00:25:49,187] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-31 00:25:49,187] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-31 00:25:49,187] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-31 00:25:49,187] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-31 00:25:49,187] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-31 00:25:49,187] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-31 00:25:49,187] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-31 00:25:49,187] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-31 00:25:49,187] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-31 00:25:49,187] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-31 00:25:49,187] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-31 00:25:49,187] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-31 00:25:49,187] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-31 00:25:49,187] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-31 00:25:49,187] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-31 00:25:49,187] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-31 00:25:49,187] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-31 00:25:49,187] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-31 00:25:49,187] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-31 00:25:49,187] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: 97

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o5-tgsm8k-s20-rFalse-m4096
Evaluating commonsenseqa :   2%|▎                | 1/50 [01:06<54:21, 66.56s/it]Evaluating commonsenseqa :   4%|▌             | 2/50 [03:11<1:20:54, 101.13s/it]Evaluating commonsenseqa :   6%|▊             | 3/50 [05:08<1:24:48, 108.26s/it]Evaluating commonsenseqa :   8%|█             | 4/50 [07:16<1:28:50, 115.89s/it]Evaluating commonsenseqa :  10%|█▍            | 5/50 [09:24<1:30:16, 120.37s/it]Evaluating commonsenseqa :  12%|█▋            | 6/50 [11:30<1:29:33, 122.13s/it]Evaluating commonsenseqa :  14%|█▉            | 7/50 [13:39<1:29:08, 124.38s/it]Evaluating commonsenseqa :  16%|██▏           | 8/50 [15:45<1:27:29, 124.99s/it]Evaluating commonsenseqa :  18%|██▌           | 9/50 [17:51<1:25:43, 125.45s/it]Evaluating commonsenseqa :  20%|██▌          | 10/50 [20:00<1:24:11, 126.29s/it]Evaluating commonsenseqa :  22%|██▊          | 11/50 [21:12<1:11:26, 109.92s/it]Evaluating commonsenseqa :  24%|███          | 12/50 [23:19<1:12:53, 115.10s/it]Evaluating commonsenseqa :  26%|███▍         | 13/50 [25:26<1:13:07, 118.58s/it]Evaluating commonsenseqa :  28%|███▋         | 14/50 [27:31<1:12:24, 120.68s/it]Evaluating commonsenseqa :  30%|███▉         | 15/50 [29:36<1:11:05, 121.88s/it]Evaluating commonsenseqa :  32%|████▏        | 16/50 [31:11<1:04:31, 113.86s/it]Evaluating commonsenseqa :  34%|████▍        | 17/50 [33:20<1:05:02, 118.25s/it]Evaluating commonsenseqa :  36%|████▋        | 18/50 [35:26<1:04:24, 120.77s/it]Evaluating commonsenseqa :  38%|████▉        | 19/50 [37:33<1:03:21, 122.64s/it]Evaluating commonsenseqa :  40%|█████▏       | 20/50 [39:40<1:01:58, 123.95s/it]Evaluating commonsenseqa :  42%|█████▍       | 21/50 [41:49<1:00:36, 125.41s/it]Evaluating commonsenseqa :  44%|██████▌        | 22/50 [43:58<58:56, 126.29s/it]Evaluating commonsenseqa :  46%|██████▉        | 23/50 [46:04<56:52, 126.40s/it]Evaluating commonsenseqa :  48%|███████▏       | 24/50 [48:11<54:49, 126.52s/it]Evaluating commonsenseqa :  50%|███████▌       | 25/50 [50:19<52:51, 126.87s/it]Evaluating commonsenseqa :  52%|███████▊       | 26/50 [52:26<50:50, 127.10s/it]Evaluating commonsenseqa :  54%|████████       | 27/50 [53:27<41:07, 107.28s/it]Evaluating commonsenseqa :  56%|████████▍      | 28/50 [55:33<41:18, 112.66s/it]Evaluating commonsenseqa :  58%|████████▋      | 29/50 [57:43<41:15, 117.89s/it]Evaluating commonsenseqa :  60%|█████████      | 30/50 [59:51<40:22, 121.10s/it]Evaluating commonsenseqa :  62%|████████     | 31/50 [1:00:48<32:12, 101.71s/it]Evaluating commonsenseqa :  64%|████████▎    | 32/50 [1:02:55<32:46, 109.27s/it]Evaluating commonsenseqa :  66%|████████▌    | 33/50 [1:05:03<32:33, 114.94s/it]Evaluating commonsenseqa :  68%|████████▊    | 34/50 [1:07:10<31:39, 118.75s/it]Evaluating commonsenseqa :  70%|█████████    | 35/50 [1:09:16<30:10, 120.69s/it]Evaluating commonsenseqa :  72%|█████████▎   | 36/50 [1:11:24<28:40, 122.90s/it]Evaluating commonsenseqa :  74%|█████████▌   | 37/50 [1:12:48<24:07, 111.33s/it]Evaluating commonsenseqa :  76%|█████████▉   | 38/50 [1:14:48<22:47, 113.96s/it]Evaluating commonsenseqa :  78%|██████████▏  | 39/50 [1:16:54<21:34, 117.66s/it]Evaluating commonsenseqa :  80%|██████████▍  | 40/50 [1:19:02<20:07, 120.72s/it]Evaluating commonsenseqa :  82%|██████████▋  | 41/50 [1:21:09<18:23, 122.58s/it]Evaluating commonsenseqa :  84%|██████████▉  | 42/50 [1:23:18<16:35, 124.44s/it]Evaluating commonsenseqa :  86%|███████████▏ | 43/50 [1:25:25<14:35, 125.12s/it]Evaluating commonsenseqa :  88%|███████████▍ | 44/50 [1:27:32<12:35, 125.91s/it]Evaluating commonsenseqa :  90%|███████████▋ | 45/50 [1:29:38<10:28, 125.78s/it]Evaluating commonsenseqa :  92%|███████████▉ | 46/50 [1:31:46<08:25, 126.41s/it]Evaluating commonsenseqa :  94%|████████████▏| 47/50 [1:33:54<06:20, 126.94s/it]Evaluating commonsenseqa :  96%|████████████▍| 48/50 [1:36:01<04:13, 126.90s/it]Evaluating commonsenseqa :  98%|████████████▋| 49/50 [1:38:11<02:08, 128.01s/it]Evaluating commonsenseqa : 100%|█████████████| 50/50 [1:39:51<00:00, 119.65s/it]Evaluating commonsenseqa : 100%|█████████████| 50/50 [1:39:51<00:00, 119.84s/it]
name: commonsenseqa | avg. gen lenth: 273.916 | time: 5992.427131414413s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 6
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-31 02:07:16,861] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 02:07:16,865] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 02:07:16,866] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 02:07:16,892] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 6
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o6-tgsm8k-s20-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████| 9741/9741 [00:00<00:00, 815535.86it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:06<00:06,  6.98s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:06<00:06,  6.99s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.22s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.39s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.14s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.57s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.13s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.56s/it]
[2023-08-31 02:07:27,314] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
 > number of parameters: 6738415616
[2023-08-31 02:07:27,329] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.21s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.66s/it]
[2023-08-31 02:07:27,535] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.30s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.77s/it]
[2023-08-31 02:07:27,759] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 02:07:28,370] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-31 02:07:28,372] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-31 02:07:28,372] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-31 02:07:28,372] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-31 02:07:28,372] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-31 02:07:28,372] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f633f0c92a0>
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-31 02:07:28,373] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-31 02:07:28,374] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-31 02:07:28,374] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-31 02:07:28,374] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-31 02:07:28,374] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-31 02:07:28,374] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-31 02:07:28,374] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-31 02:07:28,374] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-31 02:07:28,374] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-31 02:07:28,374] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-31 02:07:28,374] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-31 02:07:28,374] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-31 02:07:28,374] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-31 02:07:28,374] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-31 02:07:28,374] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-31 02:07:28,374] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-31 02:07:28,374] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-31 02:07:28,374] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-31 02:07:28,374] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-31 02:07:28,374] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-31 02:07:28,374] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-31 02:07:28,374] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: 97

Input: Nalani had two female dogs that were expecting and after a month gave birth to 10 puppies each. She then sold 3/4 of the puppies after they came of age, each at $200. Calculate the total amount of money she received from the sale of the puppies.
Output: 3000

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o6-tgsm8k-s20-rFalse-m4096
Evaluating commonsenseqa :   2%|▎             | 1/50 [02:08<1:44:41, 128.19s/it]Evaluating commonsenseqa :   4%|▌             | 2/50 [04:16<1:42:35, 128.24s/it]Evaluating commonsenseqa :   6%|▉              | 3/50 [05:22<1:18:08, 99.75s/it]Evaluating commonsenseqa :   8%|█             | 4/50 [07:27<1:24:07, 109.72s/it]Evaluating commonsenseqa :  10%|█▍            | 5/50 [09:33<1:26:37, 115.50s/it]Evaluating commonsenseqa :  12%|█▊             | 6/50 [10:38<1:12:06, 98.34s/it]Evaluating commonsenseqa :  14%|█▉            | 7/50 [12:42<1:16:31, 106.78s/it]Evaluating commonsenseqa :  16%|██▏           | 8/50 [14:19<1:12:36, 103.73s/it]Evaluating commonsenseqa :  18%|██▌           | 9/50 [16:25<1:15:42, 110.78s/it]Evaluating commonsenseqa :  20%|██▌          | 10/50 [18:31<1:16:52, 115.31s/it]Evaluating commonsenseqa :  22%|██▊          | 11/50 [20:17<1:13:14, 112.67s/it]Evaluating commonsenseqa :  24%|███          | 12/50 [22:20<1:13:14, 115.64s/it]Evaluating commonsenseqa :  26%|███▍         | 13/50 [24:23<1:12:48, 118.06s/it]Evaluating commonsenseqa :  28%|███▋         | 14/50 [26:27<1:11:45, 119.59s/it]Evaluating commonsenseqa :  30%|███▉         | 15/50 [27:42<1:02:02, 106.35s/it]Evaluating commonsenseqa :  32%|████▏        | 16/50 [29:29<1:00:19, 106.45s/it]Evaluating commonsenseqa :  34%|████▍        | 17/50 [31:32<1:01:21, 111.57s/it]Evaluating commonsenseqa :  36%|█████▊          | 18/50 [32:26<50:14, 94.20s/it]Evaluating commonsenseqa :  38%|██████          | 19/50 [33:26<43:24, 84.02s/it]Evaluating commonsenseqa :  40%|██████▍         | 20/50 [35:28<47:34, 95.16s/it]Evaluating commonsenseqa :  42%|██████▎        | 21/50 [37:33<50:26, 104.37s/it]Evaluating commonsenseqa :  44%|██████▌        | 22/50 [39:38<51:31, 110.40s/it]Evaluating commonsenseqa :  46%|██████▉        | 23/50 [41:42<51:29, 114.41s/it]Evaluating commonsenseqa :  48%|███████▏       | 24/50 [43:44<50:38, 116.86s/it]Evaluating commonsenseqa :  50%|███████▌       | 25/50 [45:48<49:34, 118.97s/it]Evaluating commonsenseqa :  52%|███████▊       | 26/50 [47:36<46:16, 115.68s/it]Evaluating commonsenseqa :  54%|████████       | 27/50 [49:39<45:13, 117.97s/it]Evaluating commonsenseqa :  56%|████████▍      | 28/50 [51:43<43:53, 119.73s/it]Evaluating commonsenseqa :  58%|█████████▎      | 29/50 [52:37<34:57, 99.89s/it]Evaluating commonsenseqa :  60%|█████████      | 30/50 [54:43<35:54, 107.73s/it]Evaluating commonsenseqa :  62%|█████████▎     | 31/50 [56:49<35:54, 113.39s/it]Evaluating commonsenseqa :  64%|█████████▌     | 32/50 [58:52<34:51, 116.21s/it]Evaluating commonsenseqa :  66%|████████▌    | 33/50 [1:00:57<33:40, 118.86s/it]Evaluating commonsenseqa :  68%|████████▊    | 34/50 [1:03:01<32:07, 120.45s/it]Evaluating commonsenseqa :  70%|█████████    | 35/50 [1:05:06<30:26, 121.77s/it]Evaluating commonsenseqa :  72%|█████████▎   | 36/50 [1:07:09<28:29, 122.10s/it]Evaluating commonsenseqa :  74%|█████████▌   | 37/50 [1:09:12<26:29, 122.28s/it]Evaluating commonsenseqa :  76%|█████████▉   | 38/50 [1:11:17<24:35, 122.99s/it]Evaluating commonsenseqa :  78%|██████████▏  | 39/50 [1:13:22<22:41, 123.79s/it]Evaluating commonsenseqa :  80%|██████████▍  | 40/50 [1:15:26<20:36, 123.68s/it]Evaluating commonsenseqa :  82%|██████████▋  | 41/50 [1:17:31<18:38, 124.22s/it]Evaluating commonsenseqa :  84%|██████████▉  | 42/50 [1:18:37<14:12, 106.62s/it]Evaluating commonsenseqa :  86%|████████████  | 43/50 [1:19:33<10:40, 91.45s/it]Evaluating commonsenseqa :  88%|███████████▍ | 44/50 [1:21:38<10:09, 101.50s/it]Evaluating commonsenseqa :  90%|████████████▌ | 45/50 [1:23:12<08:17, 99.46s/it]Evaluating commonsenseqa :  92%|███████████▉ | 46/50 [1:25:18<07:09, 107.41s/it]Evaluating commonsenseqa :  94%|████████████▏| 47/50 [1:26:49<05:07, 102.49s/it]Evaluating commonsenseqa :  96%|████████████▍| 48/50 [1:28:51<03:36, 108.30s/it]Evaluating commonsenseqa :  98%|████████████▋| 49/50 [1:30:52<01:52, 112.19s/it]Evaluating commonsenseqa : 100%|█████████████| 50/50 [1:32:28<00:00, 107.17s/it]Evaluating commonsenseqa : 100%|█████████████| 50/50 [1:32:28<00:00, 110.97s/it]
name: commonsenseqa | avg. gen lenth: 258.452 | time: 5548.7186868190765s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o7-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 7
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-31 03:45:55,291] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 03:45:55,296] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 03:45:55,309] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 03:45:55,311] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o7-tgsm8k-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 7
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o7-tgsm8k-s20-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████| 9741/9741 [00:00<00:00, 768228.86it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.25s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.46s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.52s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.81s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.27s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.72s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.29s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.78s/it]
[2023-08-31 03:46:06,076] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.31s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.78s/it]
[2023-08-31 03:46:06,213] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 03:46:06,250] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  4.56s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.04s/it]
 > number of parameters: 6738415616
[2023-08-31 03:46:06,753] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 03:46:07,284] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-31 03:46:07,285] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-31 03:46:07,285] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-31 03:46:07,285] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-31 03:46:07,285] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-31 03:46:07,285] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-31 03:46:07,285] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-31 03:46:07,285] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-31 03:46:07,285] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-31 03:46:07,285] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-31 03:46:07,285] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-31 03:46:07,285] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f7c2c5c1300>
[2023-08-31 03:46:07,285] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-31 03:46:07,285] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-31 03:46:07,285] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-31 03:46:07,285] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-31 03:46:07,286] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-31 03:46:07,287] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-31 03:46:07,287] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-31 03:46:07,287] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: 97

Input: Nalani had two female dogs that were expecting and after a month gave birth to 10 puppies each. She then sold 3/4 of the puppies after they came of age, each at $200. Calculate the total amount of money she received from the sale of the puppies.
Output: 3000

Input: Boris has 24 books and he donates a fourth of his books to the library. Cameron has 30 books and he donates a third of his books to the library. After donating their books, how many books in total do Boris and Cameron have together?
Output: 38

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o7-tgsm8k-s20-rFalse-m4096
Evaluating commonsenseqa :   2%|▎             | 1/50 [02:04<1:41:50, 124.70s/it]Evaluating commonsenseqa :   4%|▌             | 2/50 [04:09<1:39:51, 124.83s/it]Evaluating commonsenseqa :   6%|▊             | 3/50 [06:11<1:36:52, 123.67s/it]Evaluating commonsenseqa :   8%|█             | 4/50 [08:17<1:35:21, 124.38s/it]Evaluating commonsenseqa :  10%|█▍            | 5/50 [10:20<1:32:49, 123.77s/it]Evaluating commonsenseqa :  12%|█▋            | 6/50 [11:49<1:22:15, 112.17s/it]Evaluating commonsenseqa :  14%|█▉            | 7/50 [13:48<1:22:01, 114.46s/it]Evaluating commonsenseqa :  16%|██▏           | 8/50 [15:51<1:21:52, 116.96s/it]Evaluating commonsenseqa :  18%|██▌           | 9/50 [17:52<1:20:54, 118.41s/it]Evaluating commonsenseqa :  20%|██▌          | 10/50 [19:56<1:20:05, 120.14s/it]Evaluating commonsenseqa :  22%|██▊          | 11/50 [21:58<1:18:29, 120.76s/it]Evaluating commonsenseqa :  24%|███          | 12/50 [24:01<1:16:53, 121.40s/it]Evaluating commonsenseqa :  26%|███▍         | 13/50 [26:04<1:15:04, 121.74s/it]Evaluating commonsenseqa :  28%|███▋         | 14/50 [27:31<1:06:47, 111.31s/it]Evaluating commonsenseqa :  30%|███▉         | 15/50 [29:32<1:06:36, 114.19s/it]Evaluating commonsenseqa :  32%|████▏        | 16/50 [31:34<1:06:02, 116.55s/it]Evaluating commonsenseqa :  34%|████▍        | 17/50 [33:37<1:05:12, 118.55s/it]Evaluating commonsenseqa :  36%|████▋        | 18/50 [35:35<1:03:09, 118.41s/it]Evaluating commonsenseqa :  38%|████▉        | 19/50 [37:38<1:01:50, 119.70s/it]Evaluating commonsenseqa :  40%|█████▏       | 20/50 [39:43<1:00:43, 121.44s/it]Evaluating commonsenseqa :  42%|██████▎        | 21/50 [41:46<58:51, 121.79s/it]Evaluating commonsenseqa :  44%|██████▌        | 22/50 [43:47<56:43, 121.57s/it]Evaluating commonsenseqa :  46%|██████▉        | 23/50 [45:02<48:21, 107.47s/it]Evaluating commonsenseqa :  48%|███████▏       | 24/50 [46:30<44:06, 101.80s/it]Evaluating commonsenseqa :  50%|███████▌       | 25/50 [48:33<45:05, 108.21s/it]Evaluating commonsenseqa :  52%|███████▊       | 26/50 [50:28<44:03, 110.16s/it]Evaluating commonsenseqa :  54%|████████       | 27/50 [52:28<43:22, 113.14s/it]Evaluating commonsenseqa :  56%|████████▍      | 28/50 [54:33<42:46, 116.64s/it]Evaluating commonsenseqa :  58%|████████▋      | 29/50 [56:35<41:24, 118.32s/it]Evaluating commonsenseqa :  60%|█████████      | 30/50 [58:37<39:47, 119.39s/it]Evaluating commonsenseqa :  62%|████████     | 31/50 [1:00:42<38:19, 121.00s/it]Evaluating commonsenseqa :  64%|████████▎    | 32/50 [1:02:44<36:24, 121.35s/it]Evaluating commonsenseqa :  66%|████████▌    | 33/50 [1:04:47<34:31, 121.87s/it]Evaluating commonsenseqa :  68%|████████▊    | 34/50 [1:06:52<32:43, 122.74s/it]Evaluating commonsenseqa :  70%|█████████    | 35/50 [1:07:48<25:39, 102.62s/it]Evaluating commonsenseqa :  72%|██████████    | 36/50 [1:08:41<20:31, 87.97s/it]Evaluating commonsenseqa :  74%|██████████▎   | 37/50 [1:10:00<18:27, 85.21s/it]Evaluating commonsenseqa :  76%|██████████▋   | 38/50 [1:11:59<19:05, 95.43s/it]Evaluating commonsenseqa :  78%|██████████▏  | 39/50 [1:14:01<18:55, 103.27s/it]Evaluating commonsenseqa :  80%|███████████▏  | 40/50 [1:15:31<16:31, 99.20s/it]Evaluating commonsenseqa :  82%|██████████▋  | 41/50 [1:17:30<15:48, 105.34s/it]Evaluating commonsenseqa :  84%|██████████▉  | 42/50 [1:19:34<14:45, 110.68s/it]Evaluating commonsenseqa :  86%|███████████▏ | 43/50 [1:21:35<13:18, 114.06s/it]Evaluating commonsenseqa :  88%|███████████▍ | 44/50 [1:23:38<11:38, 116.47s/it]Evaluating commonsenseqa :  90%|███████████▋ | 45/50 [1:25:39<09:50, 118.06s/it]Evaluating commonsenseqa :  92%|███████████▉ | 46/50 [1:27:43<07:59, 119.82s/it]Evaluating commonsenseqa :  94%|████████████▏| 47/50 [1:29:48<06:03, 121.30s/it]Evaluating commonsenseqa :  96%|████████████▍| 48/50 [1:31:24<03:47, 113.69s/it]Evaluating commonsenseqa :  98%|█████████████▋| 49/50 [1:32:22<01:37, 97.08s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:33:36<00:00, 89.97s/it]Evaluating commonsenseqa : 100%|█████████████| 50/50 [1:33:36<00:00, 112.32s/it]
name: commonsenseqa | avg. gen lenth: 245.312 | time: 5616.452114343643s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 8
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-31 05:23:18,446] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 05:23:18,460] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 05:23:18,485] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 05:23:18,490] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 8
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o8-tgsm8k-s20-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████| 9741/9741 [00:00<00:00, 730523.45it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:06<00:06,  6.85s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.04s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.18s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:08<00:08,  8.99s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.12s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.53s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.20s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.63s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.20s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.64s/it]
[2023-08-31 05:23:29,067] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 05:23:29,083] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 05:23:29,162] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  4.84s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.46s/it]
 > number of parameters: 6738415616
[2023-08-31 05:23:30,790] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 05:23:31,348] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-31 05:23:31,349] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-31 05:23:31,349] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-31 05:23:31,349] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-31 05:23:31,349] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-31 05:23:31,349] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-31 05:23:31,349] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f81c8cc1300>
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-31 05:23:31,350] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-31 05:23:31,351] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-31 05:23:31,351] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-31 05:23:31,351] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-31 05:23:31,351] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-31 05:23:31,351] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-31 05:23:31,351] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-31 05:23:31,351] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-31 05:23:31,351] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-31 05:23:31,351] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-31 05:23:31,351] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-31 05:23:31,351] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-31 05:23:31,351] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-31 05:23:31,351] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-31 05:23:31,351] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-31 05:23:31,351] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-31 05:23:31,351] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: 97

Input: Nalani had two female dogs that were expecting and after a month gave birth to 10 puppies each. She then sold 3/4 of the puppies after they came of age, each at $200. Calculate the total amount of money she received from the sale of the puppies.
Output: 3000

Input: Boris has 24 books and he donates a fourth of his books to the library. Cameron has 30 books and he donates a third of his books to the library. After donating their books, how many books in total do Boris and Cameron have together?
Output: 38

Input: There are 3 boxes of cereal. One box holds 14 ounces of cereal. Another box holds half the amount of the first box and 5 ounces less than the third box. How much cereal is there in all 3 cereal boxes?
Output: 33

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o8-tgsm8k-s20-rFalse-m4096
Evaluating commonsenseqa :   2%|▎             | 1/50 [02:00<1:38:39, 120.82s/it]Evaluating commonsenseqa :   4%|▌             | 2/50 [04:00<1:36:11, 120.25s/it]Evaluating commonsenseqa :   6%|▊             | 3/50 [06:00<1:34:06, 120.14s/it]Evaluating commonsenseqa :   8%|█             | 4/50 [08:02<1:32:44, 120.97s/it]Evaluating commonsenseqa :  10%|█▍            | 5/50 [09:41<1:24:37, 112.84s/it]Evaluating commonsenseqa :  12%|█▋            | 6/50 [11:42<1:24:44, 115.56s/it]Evaluating commonsenseqa :  14%|█▉            | 7/50 [13:45<1:24:34, 118.02s/it]Evaluating commonsenseqa :  16%|██▏           | 8/50 [15:44<1:22:50, 118.34s/it]Evaluating commonsenseqa :  18%|██▌           | 9/50 [17:42<1:20:54, 118.41s/it]Evaluating commonsenseqa :  20%|██▌          | 10/50 [19:44<1:19:35, 119.40s/it]Evaluating commonsenseqa :  22%|██▊          | 11/50 [21:23<1:13:37, 113.28s/it]Evaluating commonsenseqa :  24%|███          | 12/50 [23:24<1:13:05, 115.41s/it]Evaluating commonsenseqa :  26%|███▍         | 13/50 [25:26<1:12:23, 117.40s/it]Evaluating commonsenseqa :  28%|███▋         | 14/50 [27:11<1:08:19, 113.88s/it]Evaluating commonsenseqa :  30%|███▉         | 15/50 [29:10<1:07:13, 115.24s/it]Evaluating commonsenseqa :  32%|████▏        | 16/50 [31:09<1:06:00, 116.49s/it]Evaluating commonsenseqa :  34%|████▍        | 17/50 [33:10<1:04:48, 117.84s/it]Evaluating commonsenseqa :  36%|█████▊          | 18/50 [34:03<52:26, 98.32s/it]Evaluating commonsenseqa :  38%|█████▋         | 19/50 [36:05<54:24, 105.31s/it]Evaluating commonsenseqa :  40%|██████         | 20/50 [38:05<54:56, 109.88s/it]Evaluating commonsenseqa :  42%|██████▎        | 21/50 [40:03<54:15, 112.27s/it]Evaluating commonsenseqa :  44%|██████▌        | 22/50 [41:47<51:13, 109.78s/it]Evaluating commonsenseqa :  46%|██████▉        | 23/50 [43:47<50:48, 112.90s/it]Evaluating commonsenseqa :  48%|███████▏       | 24/50 [45:33<47:57, 110.66s/it]Evaluating commonsenseqa :  50%|███████▌       | 25/50 [47:31<47:08, 113.14s/it]Evaluating commonsenseqa :  52%|███████▊       | 26/50 [49:29<45:47, 114.46s/it]Evaluating commonsenseqa :  54%|████████       | 27/50 [51:30<44:39, 116.49s/it]Evaluating commonsenseqa :  56%|████████▍      | 28/50 [53:21<42:07, 114.91s/it]Evaluating commonsenseqa :  58%|█████████▎      | 29/50 [54:14<33:36, 96.05s/it]Evaluating commonsenseqa :  60%|█████████      | 30/50 [56:12<34:14, 102.70s/it]Evaluating commonsenseqa :  62%|█████████▎     | 31/50 [58:11<34:06, 107.70s/it]Evaluating commonsenseqa :  64%|████████▎    | 32/50 [1:00:09<33:15, 110.88s/it]Evaluating commonsenseqa :  66%|████████▌    | 33/50 [1:01:50<30:31, 107.75s/it]Evaluating commonsenseqa :  68%|████████▊    | 34/50 [1:03:50<29:42, 111.43s/it]Evaluating commonsenseqa :  70%|█████████▊    | 35/50 [1:04:43<23:27, 93.86s/it]Evaluating commonsenseqa :  72%|█████████▎   | 36/50 [1:06:40<23:33, 100.99s/it]Evaluating commonsenseqa :  74%|██████████▎   | 37/50 [1:07:49<19:47, 91.34s/it]Evaluating commonsenseqa :  76%|██████████▋   | 38/50 [1:09:49<19:58, 99.90s/it]Evaluating commonsenseqa :  78%|██████████▏  | 39/50 [1:11:49<19:25, 105.98s/it]Evaluating commonsenseqa :  80%|██████████▍  | 40/50 [1:13:23<17:03, 102.33s/it]Evaluating commonsenseqa :  82%|██████████▋  | 41/50 [1:15:22<16:05, 107.32s/it]Evaluating commonsenseqa :  84%|██████████▉  | 42/50 [1:17:22<14:49, 111.19s/it]Evaluating commonsenseqa :  86%|███████████▏ | 43/50 [1:19:21<13:15, 113.61s/it]Evaluating commonsenseqa :  88%|███████████▍ | 44/50 [1:21:23<11:36, 116.09s/it]Evaluating commonsenseqa :  90%|███████████▋ | 45/50 [1:23:24<09:47, 117.50s/it]Evaluating commonsenseqa :  92%|███████████▉ | 46/50 [1:25:06<07:31, 112.82s/it]Evaluating commonsenseqa :  94%|████████████▏| 47/50 [1:27:09<05:47, 115.76s/it]Evaluating commonsenseqa :  96%|████████████▍| 48/50 [1:29:10<03:54, 117.43s/it]Evaluating commonsenseqa :  98%|████████████▋| 49/50 [1:31:09<01:57, 117.96s/it]Evaluating commonsenseqa : 100%|█████████████| 50/50 [1:33:08<00:00, 118.32s/it]Evaluating commonsenseqa : 100%|█████████████| 50/50 [1:33:08<00:00, 111.78s/it]
name: commonsenseqa | avg. gen lenth: 237.612 | time: 5589.129461526871s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o9-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 9
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-31 06:56:46,092] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 06:56:46,564] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 06:56:46,616] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 06:56:46,637] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o9-tgsm8k-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 9
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o9-tgsm8k-s20-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████| 9741/9741 [00:00<00:00, 687742.44it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:06<00:06,  6.57s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.07s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.13s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.39s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  3.88s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  4.29s/it]
[2023-08-31 06:56:56,482] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.22s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.64s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.26s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.69s/it]
 > number of parameters: 6738415616
[2023-08-31 06:56:57,197] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 06:56:57,269] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.29s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.76s/it]
[2023-08-31 06:56:57,424] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 06:56:57,992] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-31 06:56:57,994] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-31 06:56:57,995] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-31 06:56:57,995] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-31 06:56:57,995] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-31 06:56:57,995] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fa3b7cd12d0>
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-31 06:56:57,996] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-31 06:56:57,997] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-31 06:56:57,997] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: 97

Input: Nalani had two female dogs that were expecting and after a month gave birth to 10 puppies each. She then sold 3/4 of the puppies after they came of age, each at $200. Calculate the total amount of money she received from the sale of the puppies.
Output: 3000

Input: Boris has 24 books and he donates a fourth of his books to the library. Cameron has 30 books and he donates a third of his books to the library. After donating their books, how many books in total do Boris and Cameron have together?
Output: 38

Input: There are 3 boxes of cereal. One box holds 14 ounces of cereal. Another box holds half the amount of the first box and 5 ounces less than the third box. How much cereal is there in all 3 cereal boxes?
Output: 33

Input: A jug needs 40 cups of water to be full. A custodian at Truman Elementary School has to fill water jugs for 200 students, who drink 10 cups of water in a day. How many water jugs will the custodian fill with cups of water to provide the students with all the water they need in a day?
Output: 50

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o9-tgsm8k-s20-rFalse-m4096
Evaluating commonsenseqa :   2%|▎             | 1/50 [01:47<1:27:29, 107.13s/it]Evaluating commonsenseqa :   4%|▌              | 2/50 [03:12<1:15:24, 94.26s/it]Evaluating commonsenseqa :   6%|▊             | 3/50 [05:08<1:21:30, 104.05s/it]Evaluating commonsenseqa :   8%|█             | 4/50 [07:02<1:22:45, 107.95s/it]Evaluating commonsenseqa :  10%|█▍            | 5/50 [09:00<1:23:41, 111.59s/it]Evaluating commonsenseqa :  12%|█▋            | 6/50 [10:55<1:22:54, 113.06s/it]Evaluating commonsenseqa :  14%|█▉            | 7/50 [12:53<1:22:07, 114.59s/it]Evaluating commonsenseqa :  16%|██▏           | 8/50 [14:43<1:19:10, 113.11s/it]Evaluating commonsenseqa :  18%|██▌           | 9/50 [16:40<1:18:10, 114.40s/it]Evaluating commonsenseqa :  20%|██▌          | 10/50 [18:35<1:16:22, 114.55s/it]Evaluating commonsenseqa :  22%|██▊          | 11/50 [19:47<1:05:54, 101.41s/it]Evaluating commonsenseqa :  24%|███          | 12/50 [21:42<1:06:51, 105.55s/it]Evaluating commonsenseqa :  26%|███▍         | 13/50 [23:39<1:07:09, 108.90s/it]Evaluating commonsenseqa :  28%|███▋         | 14/50 [25:33<1:06:25, 110.70s/it]Evaluating commonsenseqa :  30%|███▉         | 15/50 [27:32<1:05:57, 113.07s/it]Evaluating commonsenseqa :  32%|████▏        | 16/50 [29:27<1:04:20, 113.54s/it]Evaluating commonsenseqa :  34%|████▍        | 17/50 [31:24<1:03:02, 114.62s/it]Evaluating commonsenseqa :  36%|████▋        | 18/50 [33:22<1:01:43, 115.72s/it]Evaluating commonsenseqa :  38%|████▉        | 19/50 [35:20<1:00:09, 116.42s/it]Evaluating commonsenseqa :  40%|██████         | 20/50 [37:17<58:18, 116.62s/it]Evaluating commonsenseqa :  42%|██████▎        | 21/50 [39:11<55:59, 115.83s/it]Evaluating commonsenseqa :  44%|██████▌        | 22/50 [40:56<52:27, 112.41s/it]Evaluating commonsenseqa :  46%|██████▉        | 23/50 [42:52<51:07, 113.61s/it]Evaluating commonsenseqa :  48%|███████▏       | 24/50 [44:48<49:36, 114.47s/it]Evaluating commonsenseqa :  50%|███████▌       | 25/50 [46:44<47:48, 114.72s/it]Evaluating commonsenseqa :  52%|███████▊       | 26/50 [48:41<46:11, 115.46s/it]Evaluating commonsenseqa :  54%|████████▋       | 27/50 [49:16<35:01, 91.39s/it]Evaluating commonsenseqa :  56%|████████▉       | 28/50 [51:13<36:21, 99.15s/it]Evaluating commonsenseqa :  58%|████████▋      | 29/50 [53:07<36:13, 103.49s/it]Evaluating commonsenseqa :  60%|█████████      | 30/50 [54:47<34:08, 102.41s/it]Evaluating commonsenseqa :  62%|█████████▎     | 31/50 [56:43<33:44, 106.54s/it]Evaluating commonsenseqa :  64%|█████████▌     | 32/50 [58:39<32:49, 109.39s/it]Evaluating commonsenseqa :  66%|████████▌    | 33/50 [1:00:35<31:34, 111.44s/it]Evaluating commonsenseqa :  68%|████████▊    | 34/50 [1:02:33<30:15, 113.44s/it]Evaluating commonsenseqa :  70%|█████████    | 35/50 [1:04:30<28:35, 114.34s/it]Evaluating commonsenseqa :  72%|█████████▎   | 36/50 [1:06:29<27:00, 115.73s/it]Evaluating commonsenseqa :  74%|█████████▌   | 37/50 [1:08:27<25:12, 116.36s/it]Evaluating commonsenseqa :  76%|█████████▉   | 38/50 [1:10:25<23:23, 116.99s/it]Evaluating commonsenseqa :  78%|██████████▏  | 39/50 [1:12:22<21:27, 117.05s/it]Evaluating commonsenseqa :  80%|██████████▍  | 40/50 [1:14:20<19:32, 117.28s/it]Evaluating commonsenseqa :  82%|██████████▋  | 41/50 [1:16:16<17:32, 116.97s/it]Evaluating commonsenseqa :  84%|██████████▉  | 42/50 [1:18:13<15:34, 116.81s/it]Evaluating commonsenseqa :  86%|███████████▏ | 43/50 [1:20:10<13:37, 116.77s/it]Evaluating commonsenseqa :  88%|████████████▎ | 44/50 [1:21:10<09:59, 99.86s/it]Evaluating commonsenseqa :  90%|████████████▌ | 45/50 [1:22:47<08:15, 99.17s/it]Evaluating commonsenseqa :  92%|███████████▉ | 46/50 [1:24:43<06:56, 104.11s/it]Evaluating commonsenseqa :  94%|█████████████▏| 47/50 [1:26:10<04:57, 99.05s/it]Evaluating commonsenseqa :  96%|████████████▍| 48/50 [1:28:07<03:28, 104.37s/it]Evaluating commonsenseqa :  98%|█████████████▋| 49/50 [1:28:53<01:26, 86.71s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:30:48<00:00, 95.39s/it]Evaluating commonsenseqa : 100%|█████████████| 50/50 [1:30:48<00:00, 108.98s/it]
name: commonsenseqa | avg. gen lenth: 258.784 | time: 5449.113453626633s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o10-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 10
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-31 08:30:14,770] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 08:30:14,799] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 08:30:14,812] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 08:30:14,833] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o10-tgsm8k-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 10
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o10-tgsm8k-s20-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████| 9741/9741 [00:00<00:00, 644875.23it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.34s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.43s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.46s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.55s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.32s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.77s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.33s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.80s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.36s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.82s/it]
[2023-08-31 08:30:25,698] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 08:30:25,719] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.40s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.88s/it]
[2023-08-31 08:30:25,778] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
 > number of parameters: 6738415616
[2023-08-31 08:30:25,897] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 08:30:26,478] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-31 08:30:26,480] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-31 08:30:26,481] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-31 08:30:26,481] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-31 08:30:26,481] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-31 08:30:26,481] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-31 08:30:26,481] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-31 08:30:26,481] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-31 08:30:26,481] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-31 08:30:26,481] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-31 08:30:26,481] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-31 08:30:26,481] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f7bf04d12a0>
[2023-08-31 08:30:26,481] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-31 08:30:26,481] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-31 08:30:26,481] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-31 08:30:26,481] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-31 08:30:26,481] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-31 08:30:26,481] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-31 08:30:26,482] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-31 08:30:26,483] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-31 08:30:26,483] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-31 08:30:26,483] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-31 08:30:26,483] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-31 08:30:26,483] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-31 08:30:26,483] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-31 08:30:26,483] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-31 08:30:26,483] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-31 08:30:26,483] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-31 08:30:26,483] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-31 08:30:26,483] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-31 08:30:26,483] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-31 08:30:26,483] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-31 08:30:26,483] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-31 08:30:26,483] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-31 08:30:26,483] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-31 08:30:26,483] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-31 08:30:26,483] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-31 08:30:26,483] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-31 08:30:26,483] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: 97

Input: Nalani had two female dogs that were expecting and after a month gave birth to 10 puppies each. She then sold 3/4 of the puppies after they came of age, each at $200. Calculate the total amount of money she received from the sale of the puppies.
Output: 3000

Input: Boris has 24 books and he donates a fourth of his books to the library. Cameron has 30 books and he donates a third of his books to the library. After donating their books, how many books in total do Boris and Cameron have together?
Output: 38

Input: There are 3 boxes of cereal. One box holds 14 ounces of cereal. Another box holds half the amount of the first box and 5 ounces less than the third box. How much cereal is there in all 3 cereal boxes?
Output: 33

Input: A jug needs 40 cups of water to be full. A custodian at Truman Elementary School has to fill water jugs for 200 students, who drink 10 cups of water in a day. How many water jugs will the custodian fill with cups of water to provide the students with all the water they need in a day?
Output: 50

Input: It takes 1 hour for refrigerated dough to come to room temperature.  It takes 15 minutes to shape the dough and 2 hours to proof.  The bread takes 30 minutes to bake and 15 minutes to cool.  If the bakery opens at 6:00 am, what is the latest time the head baker can make it to the store to start working?
Output: 2

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o10-tgsm8k-s20-rFalse-m4096
Evaluating commonsenseqa :   2%|▎             | 1/50 [01:54<1:33:09, 114.08s/it]Evaluating commonsenseqa :   4%|▌             | 2/50 [03:47<1:31:02, 113.80s/it]Evaluating commonsenseqa :   6%|▊             | 3/50 [05:41<1:29:05, 113.73s/it]Evaluating commonsenseqa :   8%|█             | 4/50 [07:38<1:28:19, 115.21s/it]Evaluating commonsenseqa :  10%|█▍            | 5/50 [09:19<1:22:21, 109.80s/it]Evaluating commonsenseqa :  12%|█▋            | 6/50 [11:10<1:21:02, 110.50s/it]Evaluating commonsenseqa :  14%|█▉            | 7/50 [13:05<1:20:02, 111.70s/it]Evaluating commonsenseqa :  16%|██▏           | 8/50 [14:58<1:18:32, 112.19s/it]Evaluating commonsenseqa :  18%|██▋            | 9/50 [15:47<1:03:10, 92.45s/it]Evaluating commonsenseqa :  20%|███▏            | 10/50 [16:38<53:12, 79.82s/it]Evaluating commonsenseqa :  22%|███▌            | 11/50 [18:29<58:00, 89.25s/it]Evaluating commonsenseqa :  24%|███▊            | 12/50 [20:12<59:11, 93.46s/it]Evaluating commonsenseqa :  26%|████▏           | 13/50 [20:59<49:01, 79.50s/it]Evaluating commonsenseqa :  28%|████▍           | 14/50 [22:50<53:20, 88.90s/it]Evaluating commonsenseqa :  30%|████▊           | 15/50 [23:57<48:00, 82.30s/it]Evaluating commonsenseqa :  32%|█████           | 16/50 [25:50<51:52, 91.54s/it]Evaluating commonsenseqa :  34%|█████▍          | 17/50 [27:44<54:03, 98.30s/it]Evaluating commonsenseqa :  36%|█████▍         | 18/50 [29:36<54:38, 102.45s/it]Evaluating commonsenseqa :  38%|█████▋         | 19/50 [31:30<54:40, 105.81s/it]Evaluating commonsenseqa :  40%|██████         | 20/50 [33:25<54:16, 108.56s/it]Evaluating commonsenseqa :  42%|██████▎        | 21/50 [35:17<52:56, 109.55s/it]Evaluating commonsenseqa :  44%|██████▌        | 22/50 [37:10<51:36, 110.59s/it]Evaluating commonsenseqa :  46%|██████▉        | 23/50 [39:03<50:05, 111.33s/it]Evaluating commonsenseqa :  48%|███████▏       | 24/50 [40:55<48:21, 111.60s/it]Evaluating commonsenseqa :  50%|███████▌       | 25/50 [42:46<46:23, 111.32s/it]Evaluating commonsenseqa :  52%|███████▊       | 26/50 [44:26<43:14, 108.10s/it]Evaluating commonsenseqa :  54%|████████       | 27/50 [46:21<42:09, 109.96s/it]Evaluating commonsenseqa :  56%|████████▍      | 28/50 [48:13<40:32, 110.59s/it]Evaluating commonsenseqa :  58%|████████▋      | 29/50 [50:05<38:52, 111.07s/it]Evaluating commonsenseqa :  60%|█████████      | 30/50 [51:59<37:22, 112.11s/it]Evaluating commonsenseqa :  62%|█████████▎     | 31/50 [53:55<35:49, 113.14s/it]Evaluating commonsenseqa :  64%|█████████▌     | 32/50 [55:14<30:52, 102.94s/it]Evaluating commonsenseqa :  66%|██████████▌     | 33/50 [56:29<26:49, 94.65s/it]Evaluating commonsenseqa :  68%|██████████▉     | 34/50 [58:12<25:53, 97.12s/it]Evaluating commonsenseqa :  70%|███████████▏    | 35/50 [59:58<24:57, 99.80s/it]Evaluating commonsenseqa :  72%|█████████▎   | 36/50 [1:01:54<24:22, 104.44s/it]Evaluating commonsenseqa :  74%|██████████▎   | 37/50 [1:03:01<20:12, 93.25s/it]Evaluating commonsenseqa :  76%|██████████▋   | 38/50 [1:04:51<19:39, 98.33s/it]Evaluating commonsenseqa :  78%|██████████▉   | 39/50 [1:06:15<17:14, 94.08s/it]Evaluating commonsenseqa :  80%|███████████▏  | 40/50 [1:08:08<16:38, 99.85s/it]Evaluating commonsenseqa :  82%|██████████▋  | 41/50 [1:10:02<15:35, 103.98s/it]Evaluating commonsenseqa :  84%|██████████▉  | 42/50 [1:11:55<14:14, 106.86s/it]Evaluating commonsenseqa :  86%|███████████▏ | 43/50 [1:13:49<12:41, 108.71s/it]Evaluating commonsenseqa :  88%|███████████▍ | 44/50 [1:15:23<10:27, 104.56s/it]Evaluating commonsenseqa :  90%|███████████▋ | 45/50 [1:17:16<08:54, 106.83s/it]Evaluating commonsenseqa :  92%|███████████▉ | 46/50 [1:18:58<07:01, 105.41s/it]Evaluating commonsenseqa :  94%|████████████▏| 47/50 [1:20:38<05:11, 103.91s/it]Evaluating commonsenseqa :  96%|█████████████▍| 48/50 [1:21:18<02:49, 84.66s/it]Evaluating commonsenseqa :  98%|█████████████▋| 49/50 [1:22:22<01:18, 78.58s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:23:44<00:00, 79.57s/it]Evaluating commonsenseqa : 100%|█████████████| 50/50 [1:23:44<00:00, 100.49s/it]
name: commonsenseqa | avg. gen lenth: 252.32 | time: 5024.854654312134s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o11-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 11
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-31 10:02:32,743] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 10:02:32,799] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 10:02:32,806] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 10:02:32,850] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o11-tgsm8k-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 11
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o11-tgsm8k-s20-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████| 9741/9741 [00:00<00:00, 617955.04it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:06<00:06,  6.44s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.05s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.09s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  3.81s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  4.21s/it]
[2023-08-31 10:02:42,588] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.25s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.68s/it]
 > number of parameters: 6738415616
[2023-08-31 10:02:43,541] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.44s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.83s/it]
[2023-08-31 10:02:43,837] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards:  50%|█████████         | 1/2 [00:10<00:10, 10.18s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:12<00:00,  5.41s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:12<00:00,  6.12s/it]
[2023-08-31 10:02:46,508] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 10:02:47,151] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-31 10:02:47,154] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-31 10:02:47,155] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-31 10:02:47,155] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-31 10:02:47,155] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-31 10:02:47,155] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-31 10:02:47,155] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-31 10:02:47,155] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-31 10:02:47,155] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-31 10:02:47,155] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-31 10:02:47,155] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f06ea7cd2d0>
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-31 10:02:47,156] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-31 10:02:47,157] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-31 10:02:47,157] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-31 10:02:47,157] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-31 10:02:47,157] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-31 10:02:47,157] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-31 10:02:47,157] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-31 10:02:47,157] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-31 10:02:47,157] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-31 10:02:47,157] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-31 10:02:47,157] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-31 10:02:47,157] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-31 10:02:47,157] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-31 10:02:47,157] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-31 10:02:47,157] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-31 10:02:47,157] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-31 10:02:47,157] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-31 10:02:47,157] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-31 10:02:47,157] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-31 10:02:47,157] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-31 10:02:47,157] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-31 10:02:47,157] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-31 10:02:47,157] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-31 10:02:47,157] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-31 10:02:47,157] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-31 10:02:47,157] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-31 10:02:47,157] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-31 10:02:47,157] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: 97

Input: Nalani had two female dogs that were expecting and after a month gave birth to 10 puppies each. She then sold 3/4 of the puppies after they came of age, each at $200. Calculate the total amount of money she received from the sale of the puppies.
Output: 3000

Input: Boris has 24 books and he donates a fourth of his books to the library. Cameron has 30 books and he donates a third of his books to the library. After donating their books, how many books in total do Boris and Cameron have together?
Output: 38

Input: There are 3 boxes of cereal. One box holds 14 ounces of cereal. Another box holds half the amount of the first box and 5 ounces less than the third box. How much cereal is there in all 3 cereal boxes?
Output: 33

Input: A jug needs 40 cups of water to be full. A custodian at Truman Elementary School has to fill water jugs for 200 students, who drink 10 cups of water in a day. How many water jugs will the custodian fill with cups of water to provide the students with all the water they need in a day?
Output: 50

Input: It takes 1 hour for refrigerated dough to come to room temperature.  It takes 15 minutes to shape the dough and 2 hours to proof.  The bread takes 30 minutes to bake and 15 minutes to cool.  If the bakery opens at 6:00 am, what is the latest time the head baker can make it to the store to start working?
Output: 2

Input: Geric had twice as many bills as Kyla who has 2 fewer bills than Jessa.  After giving 3 bills to Geric, Jessa has 7 bills left. How many bills did Geric have at the beginning?
Output: 16

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o11-tgsm8k-s20-rFalse-m4096
Evaluating commonsenseqa :   2%|▎             | 1/50 [01:52<1:31:50, 112.46s/it]Evaluating commonsenseqa :   4%|▌             | 2/50 [03:44<1:29:53, 112.36s/it]Evaluating commonsenseqa :   6%|▊             | 3/50 [05:32<1:26:26, 110.36s/it]Evaluating commonsenseqa :   8%|█             | 4/50 [07:00<1:17:48, 101.49s/it]Evaluating commonsenseqa :  10%|█▍            | 5/50 [08:50<1:18:27, 104.61s/it]Evaluating commonsenseqa :  12%|█▋            | 6/50 [10:40<1:18:00, 106.37s/it]Evaluating commonsenseqa :  14%|█▉            | 7/50 [12:32<1:17:29, 108.13s/it]Evaluating commonsenseqa :  16%|██▍            | 8/50 [13:35<1:05:36, 93.73s/it]Evaluating commonsenseqa :  18%|██▋            | 9/50 [15:25<1:07:31, 98.82s/it]Evaluating commonsenseqa :  20%|██▊           | 10/50 [16:49<1:02:47, 94.18s/it]Evaluating commonsenseqa :  22%|███           | 11/50 [18:39<1:04:23, 99.07s/it]Evaluating commonsenseqa :  24%|███          | 12/50 [20:30<1:05:07, 102.83s/it]Evaluating commonsenseqa :  26%|███▍         | 13/50 [22:19<1:04:28, 104.56s/it]Evaluating commonsenseqa :  28%|███▋         | 14/50 [24:10<1:03:52, 106.47s/it]Evaluating commonsenseqa :  30%|███▉         | 15/50 [26:01<1:03:01, 108.05s/it]Evaluating commonsenseqa :  32%|████▏        | 16/50 [27:51<1:01:31, 108.57s/it]Evaluating commonsenseqa :  34%|████▍        | 17/50 [29:45<1:00:41, 110.33s/it]Evaluating commonsenseqa :  36%|█████▍         | 18/50 [31:20<56:18, 105.58s/it]Evaluating commonsenseqa :  38%|█████▋         | 19/50 [33:12<55:29, 107.41s/it]Evaluating commonsenseqa :  40%|██████         | 20/50 [35:02<54:08, 108.28s/it]Evaluating commonsenseqa :  42%|██████▎        | 21/50 [36:54<52:52, 109.40s/it]Evaluating commonsenseqa :  44%|██████▌        | 22/50 [38:37<50:11, 107.57s/it]Evaluating commonsenseqa :  46%|██████▉        | 23/50 [40:13<46:50, 104.09s/it]Evaluating commonsenseqa :  48%|███████▏       | 24/50 [42:04<45:58, 106.11s/it]Evaluating commonsenseqa :  50%|███████▌       | 25/50 [43:55<44:50, 107.64s/it]Evaluating commonsenseqa :  52%|███████▊       | 26/50 [45:46<43:22, 108.42s/it]Evaluating commonsenseqa :  54%|████████       | 27/50 [47:38<41:58, 109.51s/it]Evaluating commonsenseqa :  56%|████████▍      | 28/50 [49:05<37:44, 102.91s/it]Evaluating commonsenseqa :  58%|████████▋      | 29/50 [50:55<36:48, 105.14s/it]Evaluating commonsenseqa :  60%|█████████      | 30/50 [52:46<35:32, 106.64s/it]Evaluating commonsenseqa :  62%|█████████▎     | 31/50 [54:36<34:06, 107.69s/it]Evaluating commonsenseqa :  64%|█████████▌     | 32/50 [56:26<32:33, 108.55s/it]Evaluating commonsenseqa :  66%|█████████▉     | 33/50 [58:17<30:56, 109.20s/it]Evaluating commonsenseqa :  68%|██████████▉     | 34/50 [59:35<26:38, 99.93s/it]Evaluating commonsenseqa :  70%|█████████    | 35/50 [1:01:26<25:47, 103.19s/it]Evaluating commonsenseqa :  72%|█████████▎   | 36/50 [1:03:19<24:47, 106.24s/it]Evaluating commonsenseqa :  74%|█████████▌   | 37/50 [1:05:10<23:18, 107.56s/it]Evaluating commonsenseqa :  76%|██████████▋   | 38/50 [1:06:25<19:34, 97.90s/it]Evaluating commonsenseqa :  78%|██████████▏  | 39/50 [1:08:18<18:43, 102.16s/it]Evaluating commonsenseqa :  80%|██████████▍  | 40/50 [1:10:08<17:25, 104.58s/it]Evaluating commonsenseqa :  82%|██████████▋  | 41/50 [1:12:01<16:03, 107.04s/it]Evaluating commonsenseqa :  84%|██████████▉  | 42/50 [1:13:52<14:26, 108.31s/it]Evaluating commonsenseqa :  86%|███████████▏ | 43/50 [1:15:43<12:43, 109.10s/it]Evaluating commonsenseqa :  88%|███████████▍ | 44/50 [1:17:35<11:00, 110.09s/it]Evaluating commonsenseqa :  90%|███████████▋ | 45/50 [1:19:25<09:10, 110.04s/it]Evaluating commonsenseqa :  92%|███████████▉ | 46/50 [1:21:18<07:23, 110.97s/it]Evaluating commonsenseqa :  94%|████████████▏| 47/50 [1:23:11<05:34, 111.57s/it]Evaluating commonsenseqa :  96%|████████████▍| 48/50 [1:25:02<03:42, 111.28s/it]Evaluating commonsenseqa :  98%|████████████▋| 49/50 [1:26:52<01:51, 111.06s/it]Evaluating commonsenseqa : 100%|█████████████| 50/50 [1:28:46<00:00, 111.89s/it]Evaluating commonsenseqa : 100%|█████████████| 50/50 [1:28:46<00:00, 106.53s/it]
name: commonsenseqa | avg. gen lenth: 271.352 | time: 5326.997772216797s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o12-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 12
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-31 11:33:10,766] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 11:33:10,767] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 11:33:10,782] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 11:33:10,793] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o12-tgsm8k-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 12
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o12-tgsm8k-s20-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████| 9741/9741 [00:00<00:00, 587494.47it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:06<00:06,  6.57s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.08s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.16s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.17s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  3.87s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  4.28s/it]
[2023-08-31 11:33:20,750] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.17s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.61s/it]
[2023-08-31 11:33:21,345] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.20s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.64s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.20s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.64s/it]
[2023-08-31 11:33:21,464] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
 > number of parameters: 6738415616
[2023-08-31 11:33:21,500] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 11:33:22,095] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-31 11:33:22,097] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-31 11:33:22,097] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-31 11:33:22,097] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-31 11:33:22,097] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-31 11:33:22,097] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-31 11:33:22,097] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-31 11:33:22,097] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-31 11:33:22,097] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-31 11:33:22,097] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-31 11:33:22,097] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-31 11:33:22,097] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f8f2b5c52a0>
[2023-08-31 11:33:22,097] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-31 11:33:22,097] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-31 11:33:22,098] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-31 11:33:22,099] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-31 11:33:22,099] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-31 11:33:22,099] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-31 11:33:22,099] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-31 11:33:22,099] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-31 11:33:22,099] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-31 11:33:22,099] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-31 11:33:22,099] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-31 11:33:22,099] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-31 11:33:22,099] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-31 11:33:22,099] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-31 11:33:22,099] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-31 11:33:22,099] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-31 11:33:22,099] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-31 11:33:22,099] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-31 11:33:22,099] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-31 11:33:22,099] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-31 11:33:22,099] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-31 11:33:22,099] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-31 11:33:22,099] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-31 11:33:22,099] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-31 11:33:22,099] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-31 11:33:22,099] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-31 11:33:22,099] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: 97

Input: Nalani had two female dogs that were expecting and after a month gave birth to 10 puppies each. She then sold 3/4 of the puppies after they came of age, each at $200. Calculate the total amount of money she received from the sale of the puppies.
Output: 3000

Input: Boris has 24 books and he donates a fourth of his books to the library. Cameron has 30 books and he donates a third of his books to the library. After donating their books, how many books in total do Boris and Cameron have together?
Output: 38

Input: There are 3 boxes of cereal. One box holds 14 ounces of cereal. Another box holds half the amount of the first box and 5 ounces less than the third box. How much cereal is there in all 3 cereal boxes?
Output: 33

Input: A jug needs 40 cups of water to be full. A custodian at Truman Elementary School has to fill water jugs for 200 students, who drink 10 cups of water in a day. How many water jugs will the custodian fill with cups of water to provide the students with all the water they need in a day?
Output: 50

Input: It takes 1 hour for refrigerated dough to come to room temperature.  It takes 15 minutes to shape the dough and 2 hours to proof.  The bread takes 30 minutes to bake and 15 minutes to cool.  If the bakery opens at 6:00 am, what is the latest time the head baker can make it to the store to start working?
Output: 2

Input: Geric had twice as many bills as Kyla who has 2 fewer bills than Jessa.  After giving 3 bills to Geric, Jessa has 7 bills left. How many bills did Geric have at the beginning?
Output: 16

Input: They say the first year of a dog's life equals 15 human years. The second year of a dog's life equals 9 human years and after that, every year of a dog's life equals 5 human years. According to this logic, how many human years has my 10-year-old dog lived?
Output: 64

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o12-tgsm8k-s20-rFalse-m4096
Evaluating commonsenseqa :   2%|▎             | 1/50 [01:53<1:32:19, 113.05s/it]Evaluating commonsenseqa :   4%|▌             | 2/50 [03:28<1:22:14, 102.81s/it]Evaluating commonsenseqa :   6%|▊             | 3/50 [05:16<1:22:17, 105.06s/it]Evaluating commonsenseqa :   8%|█▏             | 4/50 [06:38<1:13:30, 95.89s/it]Evaluating commonsenseqa :  10%|█▍            | 5/50 [08:28<1:15:48, 101.07s/it]Evaluating commonsenseqa :  12%|█▊             | 6/50 [09:43<1:07:32, 92.09s/it]Evaluating commonsenseqa :  14%|██             | 7/50 [11:29<1:09:22, 96.79s/it]Evaluating commonsenseqa :  16%|██▏           | 8/50 [13:16<1:10:05, 100.13s/it]Evaluating commonsenseqa :  18%|██▌           | 9/50 [15:04<1:10:04, 102.56s/it]Evaluating commonsenseqa :  20%|██▌          | 10/50 [16:51<1:09:16, 103.92s/it]Evaluating commonsenseqa :  22%|██▊          | 11/50 [18:41<1:08:39, 105.63s/it]Evaluating commonsenseqa :  24%|███          | 12/50 [20:29<1:07:19, 106.31s/it]Evaluating commonsenseqa :  26%|███▍         | 13/50 [22:17<1:05:53, 106.84s/it]Evaluating commonsenseqa :  28%|███▋         | 14/50 [24:06<1:04:31, 107.54s/it]Evaluating commonsenseqa :  30%|███▉         | 15/50 [25:55<1:03:05, 108.15s/it]Evaluating commonsenseqa :  32%|████▏        | 16/50 [27:43<1:01:10, 107.96s/it]Evaluating commonsenseqa :  34%|█████          | 17/50 [29:31<59:21, 107.93s/it]Evaluating commonsenseqa :  36%|█████▊          | 18/50 [30:14<47:10, 88.45s/it]Evaluating commonsenseqa :  38%|██████          | 19/50 [32:03<48:56, 94.74s/it]Evaluating commonsenseqa :  40%|██████▍         | 20/50 [33:54<49:49, 99.66s/it]Evaluating commonsenseqa :  42%|██████▎        | 21/50 [35:42<49:18, 102.03s/it]Evaluating commonsenseqa :  44%|██████▌        | 22/50 [37:30<48:24, 103.72s/it]Evaluating commonsenseqa :  46%|██████▉        | 23/50 [39:08<45:53, 101.98s/it]Evaluating commonsenseqa :  48%|███████▏       | 24/50 [41:00<45:29, 104.98s/it]Evaluating commonsenseqa :  50%|███████▌       | 25/50 [42:49<44:15, 106.21s/it]Evaluating commonsenseqa :  52%|███████▊       | 26/50 [44:38<42:51, 107.13s/it]Evaluating commonsenseqa :  54%|████████       | 27/50 [46:25<41:06, 107.22s/it]Evaluating commonsenseqa :  56%|████████▍      | 28/50 [48:12<39:17, 107.18s/it]Evaluating commonsenseqa :  58%|████████▋      | 29/50 [50:01<37:41, 107.69s/it]Evaluating commonsenseqa :  60%|█████████      | 30/50 [51:50<35:57, 107.87s/it]Evaluating commonsenseqa :  62%|█████████▎     | 31/50 [53:40<34:25, 108.72s/it]Evaluating commonsenseqa :  64%|██████████▏     | 32/50 [54:08<25:21, 84.55s/it]Evaluating commonsenseqa :  66%|██████████▌     | 33/50 [55:57<26:00, 91.79s/it]Evaluating commonsenseqa :  68%|██████████▉     | 34/50 [57:47<25:54, 97.13s/it]Evaluating commonsenseqa :  70%|███████████▏    | 35/50 [59:33<24:59, 99.99s/it]Evaluating commonsenseqa :  72%|██████████    | 36/50 [1:01:12<23:15, 99.67s/it]Evaluating commonsenseqa :  74%|█████████▌   | 37/50 [1:03:01<22:09, 102.24s/it]Evaluating commonsenseqa :  76%|█████████▉   | 38/50 [1:04:47<20:41, 103.45s/it]Evaluating commonsenseqa :  78%|██████████▉   | 39/50 [1:05:55<17:00, 92.77s/it]Evaluating commonsenseqa :  80%|███████████▏  | 40/50 [1:07:43<16:14, 97.44s/it]Evaluating commonsenseqa :  82%|██████████▋  | 41/50 [1:09:31<15:04, 100.53s/it]Evaluating commonsenseqa :  84%|██████████▉  | 42/50 [1:11:20<13:44, 103.03s/it]Evaluating commonsenseqa :  86%|███████████▏ | 43/50 [1:13:08<12:11, 104.56s/it]Evaluating commonsenseqa :  88%|███████████▍ | 44/50 [1:14:57<10:36, 106.11s/it]Evaluating commonsenseqa :  90%|███████████▋ | 45/50 [1:16:44<08:51, 106.31s/it]Evaluating commonsenseqa :  92%|███████████▉ | 46/50 [1:18:32<07:06, 106.65s/it]Evaluating commonsenseqa :  94%|████████████▏| 47/50 [1:20:22<05:22, 107.65s/it]Evaluating commonsenseqa :  96%|████████████▍| 48/50 [1:22:09<03:35, 107.60s/it]Evaluating commonsenseqa :  98%|████████████▋| 49/50 [1:23:59<01:48, 108.36s/it]Evaluating commonsenseqa : 100%|█████████████| 50/50 [1:25:46<00:00, 108.01s/it]Evaluating commonsenseqa : 100%|█████████████| 50/50 [1:25:46<00:00, 102.94s/it]
name: commonsenseqa | avg. gen lenth: 281.48 | time: 5147.317788600922s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o13-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 13
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-31 13:01:23,467] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 13:01:23,479] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 13:01:23,479] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 13:01:23,483] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o13-tgsm8k-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 13
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o13-tgsm8k-s20-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████| 9741/9741 [00:00<00:00, 563774.19it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:06<00:06,  6.82s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:06<00:06,  6.95s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.07s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.11s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.51s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.16s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.60s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.12s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.55s/it]
 > number of parameters: 6738415616
[2023-08-31 13:01:33,957] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 13:01:34,007] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 13:01:34,013] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards:  50%|█████████         | 1/2 [00:09<00:09,  9.91s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  5.25s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  5.95s/it]
[2023-08-31 13:01:36,836] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 13:01:37,506] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-31 13:01:37,509] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-31 13:01:37,510] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-31 13:01:37,510] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-31 13:01:37,510] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-31 13:01:37,510] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-31 13:01:37,511] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-31 13:01:37,511] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-31 13:01:37,511] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-31 13:01:37,511] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-31 13:01:37,511] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-31 13:01:37,511] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fc5985d1300>
[2023-08-31 13:01:37,511] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-31 13:01:37,511] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-31 13:01:37,511] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-31 13:01:37,511] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-31 13:01:37,512] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-31 13:01:37,513] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-31 13:01:37,513] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-31 13:01:37,513] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-31 13:01:37,513] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-31 13:01:37,513] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-31 13:01:37,513] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-31 13:01:37,513] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-31 13:01:37,513] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-31 13:01:37,513] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-31 13:01:37,513] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-31 13:01:37,513] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-31 13:01:37,513] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-31 13:01:37,513] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-31 13:01:37,513] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-31 13:01:37,513] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-31 13:01:37,513] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-31 13:01:37,513] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-31 13:01:37,513] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-31 13:01:37,513] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-31 13:01:37,513] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-31 13:01:37,513] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-31 13:01:37,513] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-31 13:01:37,513] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-31 13:01:37,513] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-31 13:01:37,513] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-31 13:01:37,513] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: 97

Input: Nalani had two female dogs that were expecting and after a month gave birth to 10 puppies each. She then sold 3/4 of the puppies after they came of age, each at $200. Calculate the total amount of money she received from the sale of the puppies.
Output: 3000

Input: Boris has 24 books and he donates a fourth of his books to the library. Cameron has 30 books and he donates a third of his books to the library. After donating their books, how many books in total do Boris and Cameron have together?
Output: 38

Input: There are 3 boxes of cereal. One box holds 14 ounces of cereal. Another box holds half the amount of the first box and 5 ounces less than the third box. How much cereal is there in all 3 cereal boxes?
Output: 33

Input: A jug needs 40 cups of water to be full. A custodian at Truman Elementary School has to fill water jugs for 200 students, who drink 10 cups of water in a day. How many water jugs will the custodian fill with cups of water to provide the students with all the water they need in a day?
Output: 50

Input: It takes 1 hour for refrigerated dough to come to room temperature.  It takes 15 minutes to shape the dough and 2 hours to proof.  The bread takes 30 minutes to bake and 15 minutes to cool.  If the bakery opens at 6:00 am, what is the latest time the head baker can make it to the store to start working?
Output: 2

Input: Geric had twice as many bills as Kyla who has 2 fewer bills than Jessa.  After giving 3 bills to Geric, Jessa has 7 bills left. How many bills did Geric have at the beginning?
Output: 16

Input: They say the first year of a dog's life equals 15 human years. The second year of a dog's life equals 9 human years and after that, every year of a dog's life equals 5 human years. According to this logic, how many human years has my 10-year-old dog lived?
Output: 64

Input: Company A and Company B merge. Company A receives 60% of the combined profits under the new merger, and company B receives 40% of the profits. If company B gets a total of $60000 in profit, how much does company A get?
Output: 90000

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o13-tgsm8k-s20-rFalse-m4096
Evaluating commonsenseqa :   2%|▎             | 1/50 [01:47<1:27:47, 107.50s/it]Evaluating commonsenseqa :   4%|▌             | 2/50 [03:31<1:24:09, 105.20s/it]Evaluating commonsenseqa :   6%|▊             | 3/50 [05:18<1:23:09, 106.17s/it]Evaluating commonsenseqa :   8%|█▏             | 4/50 [06:31<1:11:16, 92.97s/it]Evaluating commonsenseqa :  10%|█▌             | 5/50 [08:15<1:12:52, 97.16s/it]Evaluating commonsenseqa :  12%|█▋            | 6/50 [10:01<1:13:24, 100.11s/it]Evaluating commonsenseqa :  14%|█▉            | 7/50 [11:46<1:12:53, 101.71s/it]Evaluating commonsenseqa :  16%|██▏           | 8/50 [13:33<1:12:19, 103.32s/it]Evaluating commonsenseqa :  18%|██▌           | 9/50 [15:18<1:11:03, 103.98s/it]Evaluating commonsenseqa :  20%|██▊           | 10/50 [16:37<1:04:03, 96.10s/it]Evaluating commonsenseqa :  22%|███           | 11/50 [18:22<1:04:22, 99.03s/it]Evaluating commonsenseqa :  24%|███          | 12/50 [20:08<1:04:02, 101.12s/it]Evaluating commonsenseqa :  26%|███▍         | 13/50 [21:53<1:03:04, 102.29s/it]Evaluating commonsenseqa :  28%|███▋         | 14/50 [23:40<1:02:07, 103.55s/it]Evaluating commonsenseqa :  30%|███▉         | 15/50 [25:25<1:00:39, 103.99s/it]Evaluating commonsenseqa :  32%|█████           | 16/50 [26:11<49:01, 86.52s/it]Evaluating commonsenseqa :  34%|█████▍          | 17/50 [27:43<48:35, 88.34s/it]Evaluating commonsenseqa :  36%|█████▊          | 18/50 [28:24<39:25, 73.94s/it]Evaluating commonsenseqa :  38%|██████          | 19/50 [30:08<42:55, 83.08s/it]Evaluating commonsenseqa :  40%|██████▍         | 20/50 [31:55<45:05, 90.17s/it]Evaluating commonsenseqa :  42%|██████▋         | 21/50 [33:14<41:57, 86.83s/it]Evaluating commonsenseqa :  44%|███████         | 22/50 [35:01<43:20, 92.88s/it]Evaluating commonsenseqa :  46%|███████▎        | 23/50 [36:46<43:24, 96.48s/it]Evaluating commonsenseqa :  48%|███████▋        | 24/50 [38:32<43:01, 99.30s/it]Evaluating commonsenseqa :  50%|███████▌       | 25/50 [40:17<42:05, 101.02s/it]Evaluating commonsenseqa :  52%|███████▊       | 26/50 [42:02<40:59, 102.48s/it]Evaluating commonsenseqa :  54%|████████▋       | 27/50 [43:35<38:11, 99.61s/it]Evaluating commonsenseqa :  56%|████████▍      | 28/50 [45:22<37:18, 101.75s/it]Evaluating commonsenseqa :  58%|████████▋      | 29/50 [47:08<36:03, 103.02s/it]Evaluating commonsenseqa :  60%|█████████      | 30/50 [48:54<34:35, 103.78s/it]Evaluating commonsenseqa :  62%|█████████▎     | 31/50 [50:41<33:11, 104.80s/it]Evaluating commonsenseqa :  64%|█████████▌     | 32/50 [52:28<31:38, 105.48s/it]Evaluating commonsenseqa :  66%|█████████▉     | 33/50 [54:14<29:54, 105.53s/it]Evaluating commonsenseqa :  68%|██████████▏    | 34/50 [56:00<28:14, 105.93s/it]Evaluating commonsenseqa :  70%|██████████▌    | 35/50 [57:45<26:24, 105.66s/it]Evaluating commonsenseqa :  72%|██████████▊    | 36/50 [59:31<24:36, 105.49s/it]Evaluating commonsenseqa :  74%|█████████▌   | 37/50 [1:01:15<22:47, 105.19s/it]Evaluating commonsenseqa :  76%|█████████▉   | 38/50 [1:03:01<21:06, 105.58s/it]Evaluating commonsenseqa :  78%|██████████▏  | 39/50 [1:04:49<19:27, 106.10s/it]Evaluating commonsenseqa :  80%|███████████▏  | 40/50 [1:05:37<14:46, 88.68s/it]Evaluating commonsenseqa :  82%|███████████▍  | 41/50 [1:07:21<13:58, 93.21s/it]Evaluating commonsenseqa :  84%|███████████▊  | 42/50 [1:09:05<12:52, 96.50s/it]Evaluating commonsenseqa :  86%|████████████  | 43/50 [1:10:50<11:34, 99.26s/it]Evaluating commonsenseqa :  88%|███████████▍ | 44/50 [1:12:36<10:07, 101.21s/it]Evaluating commonsenseqa :  90%|███████████▋ | 45/50 [1:14:21<08:32, 102.41s/it]Evaluating commonsenseqa :  92%|███████████▉ | 46/50 [1:16:07<06:53, 103.48s/it]Evaluating commonsenseqa :  94%|████████████▏| 47/50 [1:17:53<05:12, 104.23s/it]Evaluating commonsenseqa :  96%|████████████▍| 48/50 [1:19:38<03:28, 104.34s/it]Evaluating commonsenseqa :  98%|████████████▋| 49/50 [1:21:20<01:43, 103.52s/it]Evaluating commonsenseqa : 100%|█████████████| 50/50 [1:23:06<00:00, 104.26s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:23:06<00:00, 99.72s/it]
name: commonsenseqa | avg. gen lenth: 306.752 | time: 4986.502933502197s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o14-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 14
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-31 14:28:56,133] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 14:28:56,168] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 14:28:56,174] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 14:28:56,186] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o14-tgsm8k-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 14
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o14-tgsm8k-s20-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████| 9741/9741 [00:00<00:00, 538325.01it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.13s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.26s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.30s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:08<00:08,  8.03s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.19s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.63s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.24s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.70s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.28s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.73s/it]
[2023-08-31 14:29:06,878] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 14:29:06,936] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 14:29:07,023] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  4.50s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.03s/it]
 > number of parameters: 6738415616
[2023-08-31 14:29:07,624] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 14:29:08,178] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-31 14:29:08,179] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-31 14:29:08,179] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-31 14:29:08,179] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-31 14:29:08,179] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-31 14:29:08,179] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f7b8f4d1300>
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-31 14:29:08,180] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-31 14:29:08,181] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-31 14:29:08,181] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-31 14:29:08,181] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-31 14:29:08,181] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-31 14:29:08,181] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-31 14:29:08,181] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-31 14:29:08,181] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-31 14:29:08,181] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-31 14:29:08,181] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-31 14:29:08,181] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-31 14:29:08,181] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-31 14:29:08,181] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-31 14:29:08,181] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-31 14:29:08,181] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-31 14:29:08,181] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-31 14:29:08,181] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-31 14:29:08,181] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-31 14:29:08,181] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-31 14:29:08,181] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-31 14:29:08,181] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-31 14:29:08,181] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-31 14:29:08,181] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-31 14:29:08,181] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-31 14:29:08,181] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: 97

Input: Nalani had two female dogs that were expecting and after a month gave birth to 10 puppies each. She then sold 3/4 of the puppies after they came of age, each at $200. Calculate the total amount of money she received from the sale of the puppies.
Output: 3000

Input: Boris has 24 books and he donates a fourth of his books to the library. Cameron has 30 books and he donates a third of his books to the library. After donating their books, how many books in total do Boris and Cameron have together?
Output: 38

Input: There are 3 boxes of cereal. One box holds 14 ounces of cereal. Another box holds half the amount of the first box and 5 ounces less than the third box. How much cereal is there in all 3 cereal boxes?
Output: 33

Input: A jug needs 40 cups of water to be full. A custodian at Truman Elementary School has to fill water jugs for 200 students, who drink 10 cups of water in a day. How many water jugs will the custodian fill with cups of water to provide the students with all the water they need in a day?
Output: 50

Input: It takes 1 hour for refrigerated dough to come to room temperature.  It takes 15 minutes to shape the dough and 2 hours to proof.  The bread takes 30 minutes to bake and 15 minutes to cool.  If the bakery opens at 6:00 am, what is the latest time the head baker can make it to the store to start working?
Output: 2

Input: Geric had twice as many bills as Kyla who has 2 fewer bills than Jessa.  After giving 3 bills to Geric, Jessa has 7 bills left. How many bills did Geric have at the beginning?
Output: 16

Input: They say the first year of a dog's life equals 15 human years. The second year of a dog's life equals 9 human years and after that, every year of a dog's life equals 5 human years. According to this logic, how many human years has my 10-year-old dog lived?
Output: 64

Input: Company A and Company B merge. Company A receives 60% of the combined profits under the new merger, and company B receives 40% of the profits. If company B gets a total of $60000 in profit, how much does company A get?
Output: 90000

Input: Sam, Sid, and Steve brought popsicle sticks for their group activity in their Art class. Sam has thrice as many as Sid, and Sid has twice as many as Steve. If Steve has 12 popsicle sticks, how many popsicle sticks can they use for their Art class activity?
Output: 108

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o14-tgsm8k-s20-rFalse-m4096
Evaluating commonsenseqa :   2%|▎             | 1/50 [01:45<1:26:08, 105.47s/it]Evaluating commonsenseqa :   4%|▌             | 2/50 [03:28<1:23:01, 103.78s/it]Evaluating commonsenseqa :   6%|▊             | 3/50 [05:13<1:21:51, 104.50s/it]Evaluating commonsenseqa :   8%|█▏             | 4/50 [05:59<1:02:30, 81.53s/it]Evaluating commonsenseqa :  10%|█▌             | 5/50 [07:44<1:07:21, 89.82s/it]Evaluating commonsenseqa :  12%|█▊             | 6/50 [09:27<1:09:19, 94.54s/it]Evaluating commonsenseqa :  14%|██▍              | 7/50 [10:25<59:09, 82.54s/it]Evaluating commonsenseqa :  16%|██▍            | 8/50 [12:09<1:02:29, 89.27s/it]Evaluating commonsenseqa :  18%|██▋            | 9/50 [13:54<1:04:15, 94.04s/it]Evaluating commonsenseqa :  20%|██▊           | 10/50 [15:36<1:04:29, 96.73s/it]Evaluating commonsenseqa :  22%|███           | 11/50 [17:19<1:04:05, 98.59s/it]Evaluating commonsenseqa :  24%|███          | 12/50 [19:03<1:03:29, 100.24s/it]Evaluating commonsenseqa :  26%|███▍         | 13/50 [20:46<1:02:18, 101.04s/it]Evaluating commonsenseqa :  28%|███▋         | 14/50 [22:30<1:01:04, 101.80s/it]Evaluating commonsenseqa :  30%|████▊           | 15/50 [23:54<56:25, 96.72s/it]Evaluating commonsenseqa :  32%|█████           | 16/50 [25:38<55:57, 98.74s/it]Evaluating commonsenseqa :  34%|█████▍          | 17/50 [27:21<54:58, 99.95s/it]Evaluating commonsenseqa :  36%|█████▍         | 18/50 [29:04<53:53, 101.04s/it]Evaluating commonsenseqa :  38%|█████▋         | 19/50 [30:48<52:41, 101.99s/it]Evaluating commonsenseqa :  40%|██████▍         | 20/50 [32:08<47:36, 95.21s/it]Evaluating commonsenseqa :  42%|██████▋         | 21/50 [33:51<47:09, 97.57s/it]Evaluating commonsenseqa :  44%|███████         | 22/50 [35:32<45:57, 98.50s/it]Evaluating commonsenseqa :  46%|███████▎        | 23/50 [37:14<44:53, 99.76s/it]Evaluating commonsenseqa :  48%|███████▏       | 24/50 [38:59<43:53, 101.30s/it]Evaluating commonsenseqa :  50%|███████▌       | 25/50 [40:44<42:40, 102.43s/it]Evaluating commonsenseqa :  52%|████████▎       | 26/50 [42:16<39:38, 99.09s/it]Evaluating commonsenseqa :  54%|████████       | 27/50 [43:58<38:23, 100.14s/it]Evaluating commonsenseqa :  56%|████████▉       | 28/50 [45:11<33:43, 91.98s/it]Evaluating commonsenseqa :  58%|█████████▎      | 29/50 [46:54<33:22, 95.33s/it]Evaluating commonsenseqa :  60%|█████████▌      | 30/50 [48:35<32:19, 97.00s/it]Evaluating commonsenseqa :  62%|█████████▉      | 31/50 [50:17<31:10, 98.43s/it]Evaluating commonsenseqa :  64%|█████████▌     | 32/50 [52:01<30:01, 100.08s/it]Evaluating commonsenseqa :  66%|█████████▉     | 33/50 [53:43<28:31, 100.67s/it]Evaluating commonsenseqa :  68%|██████████▏    | 34/50 [55:27<27:08, 101.77s/it]Evaluating commonsenseqa :  70%|██████████▌    | 35/50 [57:12<25:38, 102.57s/it]Evaluating commonsenseqa :  72%|██████████▊    | 36/50 [58:54<23:56, 102.62s/it]Evaluating commonsenseqa :  74%|██████████▎   | 37/50 [1:00:26<21:31, 99.36s/it]Evaluating commonsenseqa :  76%|█████████▉   | 38/50 [1:02:09<20:03, 100.33s/it]Evaluating commonsenseqa :  78%|██████████▏  | 39/50 [1:03:53<18:37, 101.56s/it]Evaluating commonsenseqa :  80%|██████████▍  | 40/50 [1:05:36<16:57, 101.80s/it]Evaluating commonsenseqa :  82%|██████████▋  | 41/50 [1:07:19<15:21, 102.36s/it]Evaluating commonsenseqa :  84%|██████████▉  | 42/50 [1:09:04<13:44, 103.02s/it]Evaluating commonsenseqa :  86%|███████████▏ | 43/50 [1:10:48<12:02, 103.26s/it]Evaluating commonsenseqa :  88%|███████████▍ | 44/50 [1:12:23<10:06, 101.00s/it]Evaluating commonsenseqa :  90%|███████████▋ | 45/50 [1:14:07<08:29, 101.85s/it]Evaluating commonsenseqa :  92%|███████████▉ | 46/50 [1:15:50<06:48, 102.17s/it]Evaluating commonsenseqa :  94%|████████████▏| 47/50 [1:17:33<05:07, 102.50s/it]Evaluating commonsenseqa :  96%|████████████▍| 48/50 [1:19:15<03:24, 102.37s/it]Evaluating commonsenseqa :  98%|████████████▋| 49/50 [1:20:59<01:42, 102.68s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:22:04<00:00, 91.49s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:22:04<00:00, 98.49s/it]
name: commonsenseqa | avg. gen lenth: 282.952 | time: 4925.030564785004s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o15-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 15
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-31 15:51:42,854] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
[2023-08-31 15:51:43,372] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 15:51:43,384] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 15:51:43,389] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o15-tgsm8k-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 15
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o15-tgsm8k-s20-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████| 9741/9741 [00:00<00:00, 520288.76it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.22s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.30s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.35s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.49s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.18s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.63s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.23s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.69s/it]
[2023-08-31 15:51:54,115] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.31s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.77s/it]
[2023-08-31 15:51:54,206] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.33s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.81s/it]
[2023-08-31 15:51:54,322] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
 > number of parameters: 6738415616
[2023-08-31 15:51:54,417] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 15:51:54,947] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-31 15:51:54,948] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f1ef1dc12d0>
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-31 15:51:54,949] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-31 15:51:54,950] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-31 15:51:54,950] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: 97

Input: Nalani had two female dogs that were expecting and after a month gave birth to 10 puppies each. She then sold 3/4 of the puppies after they came of age, each at $200. Calculate the total amount of money she received from the sale of the puppies.
Output: 3000

Input: Boris has 24 books and he donates a fourth of his books to the library. Cameron has 30 books and he donates a third of his books to the library. After donating their books, how many books in total do Boris and Cameron have together?
Output: 38

Input: There are 3 boxes of cereal. One box holds 14 ounces of cereal. Another box holds half the amount of the first box and 5 ounces less than the third box. How much cereal is there in all 3 cereal boxes?
Output: 33

Input: A jug needs 40 cups of water to be full. A custodian at Truman Elementary School has to fill water jugs for 200 students, who drink 10 cups of water in a day. How many water jugs will the custodian fill with cups of water to provide the students with all the water they need in a day?
Output: 50

Input: It takes 1 hour for refrigerated dough to come to room temperature.  It takes 15 minutes to shape the dough and 2 hours to proof.  The bread takes 30 minutes to bake and 15 minutes to cool.  If the bakery opens at 6:00 am, what is the latest time the head baker can make it to the store to start working?
Output: 2

Input: Geric had twice as many bills as Kyla who has 2 fewer bills than Jessa.  After giving 3 bills to Geric, Jessa has 7 bills left. How many bills did Geric have at the beginning?
Output: 16

Input: They say the first year of a dog's life equals 15 human years. The second year of a dog's life equals 9 human years and after that, every year of a dog's life equals 5 human years. According to this logic, how many human years has my 10-year-old dog lived?
Output: 64

Input: Company A and Company B merge. Company A receives 60% of the combined profits under the new merger, and company B receives 40% of the profits. If company B gets a total of $60000 in profit, how much does company A get?
Output: 90000

Input: Sam, Sid, and Steve brought popsicle sticks for their group activity in their Art class. Sam has thrice as many as Sid, and Sid has twice as many as Steve. If Steve has 12 popsicle sticks, how many popsicle sticks can they use for their Art class activity?
Output: 108

Input: The price of an iPhone fell 10% in a particular month and another 20% in the second month.  If the initial price was $1000, calculate the price after the second month.
Output: 720

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o15-tgsm8k-s20-rFalse-m4096
Evaluating commonsenseqa :   2%|▎             | 1/50 [01:44<1:25:28, 104.67s/it]Evaluating commonsenseqa :   4%|▌             | 2/50 [03:25<1:22:00, 102.51s/it]Evaluating commonsenseqa :   6%|▊             | 3/50 [05:08<1:20:31, 102.81s/it]Evaluating commonsenseqa :   8%|█             | 4/50 [06:52<1:19:03, 103.12s/it]Evaluating commonsenseqa :  10%|█▍            | 5/50 [08:34<1:17:11, 102.92s/it]Evaluating commonsenseqa :  12%|█▋            | 6/50 [10:11<1:13:54, 100.78s/it]Evaluating commonsenseqa :  14%|█▉            | 7/50 [11:53<1:12:28, 101.14s/it]Evaluating commonsenseqa :  16%|██▏           | 8/50 [13:35<1:10:59, 101.42s/it]Evaluating commonsenseqa :  18%|██▌           | 9/50 [15:16<1:09:12, 101.28s/it]Evaluating commonsenseqa :  20%|███▏            | 10/50 [16:14<58:41, 88.05s/it]Evaluating commonsenseqa :  22%|███           | 11/50 [17:58<1:00:18, 92.78s/it]Evaluating commonsenseqa :  24%|███▊            | 12/50 [19:21<56:51, 89.76s/it]Evaluating commonsenseqa :  26%|████▏           | 13/50 [21:03<57:35, 93.39s/it]Evaluating commonsenseqa :  28%|████▍           | 14/50 [22:42<57:12, 95.34s/it]Evaluating commonsenseqa :  30%|████▊           | 15/50 [24:23<56:28, 96.81s/it]Evaluating commonsenseqa :  32%|█████           | 16/50 [26:04<55:38, 98.20s/it]Evaluating commonsenseqa :  34%|█████▍          | 17/50 [27:44<54:14, 98.62s/it]Evaluating commonsenseqa :  36%|█████▊          | 18/50 [29:25<52:58, 99.32s/it]Evaluating commonsenseqa :  38%|█████▋         | 19/50 [31:07<51:46, 100.21s/it]Evaluating commonsenseqa :  40%|██████▍         | 20/50 [31:54<42:11, 84.38s/it]Evaluating commonsenseqa :  42%|██████▋         | 21/50 [33:35<43:13, 89.42s/it]Evaluating commonsenseqa :  44%|███████         | 22/50 [35:15<43:12, 92.59s/it]Evaluating commonsenseqa :  46%|███████▎        | 23/50 [36:59<43:05, 95.74s/it]Evaluating commonsenseqa :  48%|███████▋        | 24/50 [38:40<42:10, 97.33s/it]Evaluating commonsenseqa :  50%|████████        | 25/50 [40:20<40:58, 98.35s/it]Evaluating commonsenseqa :  52%|████████▎       | 26/50 [41:40<37:09, 92.88s/it]Evaluating commonsenseqa :  54%|████████▋       | 27/50 [43:22<36:38, 95.60s/it]Evaluating commonsenseqa :  56%|████████▉       | 28/50 [44:45<33:35, 91.61s/it]Evaluating commonsenseqa :  58%|█████████▎      | 29/50 [46:26<33:07, 94.66s/it]Evaluating commonsenseqa :  60%|█████████▌      | 30/50 [48:08<32:12, 96.63s/it]Evaluating commonsenseqa :  62%|█████████▉      | 31/50 [49:49<31:04, 98.12s/it]Evaluating commonsenseqa :  64%|██████████▏     | 32/50 [51:32<29:51, 99.52s/it]Evaluating commonsenseqa :  66%|█████████▉     | 33/50 [53:15<28:29, 100.58s/it]Evaluating commonsenseqa :  68%|██████████▉     | 34/50 [54:18<23:49, 89.32s/it]Evaluating commonsenseqa :  70%|███████████▏    | 35/50 [56:00<23:16, 93.11s/it]Evaluating commonsenseqa :  72%|███████████▌    | 36/50 [57:42<22:20, 95.75s/it]Evaluating commonsenseqa :  74%|███████████▊    | 37/50 [58:49<18:52, 87.12s/it]Evaluating commonsenseqa :  76%|██████████▋   | 38/50 [1:00:30<18:14, 91.23s/it]Evaluating commonsenseqa :  78%|██████████▉   | 39/50 [1:02:11<17:17, 94.28s/it]Evaluating commonsenseqa :  80%|███████████▏  | 40/50 [1:03:52<16:03, 96.35s/it]Evaluating commonsenseqa :  82%|███████████▍  | 41/50 [1:05:35<14:43, 98.16s/it]Evaluating commonsenseqa :  84%|███████████▊  | 42/50 [1:07:18<13:17, 99.69s/it]Evaluating commonsenseqa :  86%|███████████▏ | 43/50 [1:09:00<11:42, 100.33s/it]Evaluating commonsenseqa :  88%|███████████▍ | 44/50 [1:10:41<10:03, 100.65s/it]Evaluating commonsenseqa :  90%|███████████▋ | 45/50 [1:12:22<08:22, 100.58s/it]Evaluating commonsenseqa :  92%|███████████▉ | 46/50 [1:14:04<06:44, 101.01s/it]Evaluating commonsenseqa :  94%|████████████▏| 47/50 [1:15:45<05:02, 100.97s/it]Evaluating commonsenseqa :  96%|████████████▍| 48/50 [1:17:25<03:21, 100.95s/it]Evaluating commonsenseqa :  98%|████████████▋| 49/50 [1:19:08<01:41, 101.38s/it]Evaluating commonsenseqa : 100%|█████████████| 50/50 [1:20:49<00:00, 101.21s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:20:49<00:00, 96.98s/it]
name: commonsenseqa | avg. gen lenth: 297.952 | time: 4849.532727241516s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o16-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 16
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-31 17:12:50,486] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 17:12:50,565] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 17:12:50,565] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 17:12:50,604] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o16-tgsm8k-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 16
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o16-tgsm8k-s20-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████| 9741/9741 [00:00<00:00, 505934.19it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.01s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.06s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.61s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.14s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.58s/it]
 > number of parameters: 6738415616
[2023-08-31 17:13:01,184] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.21s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.63s/it]
[2023-08-31 17:13:01,358] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards:  50%|█████████         | 1/2 [00:09<00:09,  9.55s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  4.65s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.09s/it]
[2023-08-31 17:13:02,353] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  5.13s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  5.79s/it]
[2023-08-31 17:13:03,652] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 17:13:04,310] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-31 17:13:04,311] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f35dbbc1300>
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-31 17:13:04,312] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-31 17:13:04,313] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-31 17:13:04,313] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: 97

Input: Nalani had two female dogs that were expecting and after a month gave birth to 10 puppies each. She then sold 3/4 of the puppies after they came of age, each at $200. Calculate the total amount of money she received from the sale of the puppies.
Output: 3000

Input: Boris has 24 books and he donates a fourth of his books to the library. Cameron has 30 books and he donates a third of his books to the library. After donating their books, how many books in total do Boris and Cameron have together?
Output: 38

Input: There are 3 boxes of cereal. One box holds 14 ounces of cereal. Another box holds half the amount of the first box and 5 ounces less than the third box. How much cereal is there in all 3 cereal boxes?
Output: 33

Input: A jug needs 40 cups of water to be full. A custodian at Truman Elementary School has to fill water jugs for 200 students, who drink 10 cups of water in a day. How many water jugs will the custodian fill with cups of water to provide the students with all the water they need in a day?
Output: 50

Input: It takes 1 hour for refrigerated dough to come to room temperature.  It takes 15 minutes to shape the dough and 2 hours to proof.  The bread takes 30 minutes to bake and 15 minutes to cool.  If the bakery opens at 6:00 am, what is the latest time the head baker can make it to the store to start working?
Output: 2

Input: Geric had twice as many bills as Kyla who has 2 fewer bills than Jessa.  After giving 3 bills to Geric, Jessa has 7 bills left. How many bills did Geric have at the beginning?
Output: 16

Input: They say the first year of a dog's life equals 15 human years. The second year of a dog's life equals 9 human years and after that, every year of a dog's life equals 5 human years. According to this logic, how many human years has my 10-year-old dog lived?
Output: 64

Input: Company A and Company B merge. Company A receives 60% of the combined profits under the new merger, and company B receives 40% of the profits. If company B gets a total of $60000 in profit, how much does company A get?
Output: 90000

Input: Sam, Sid, and Steve brought popsicle sticks for their group activity in their Art class. Sam has thrice as many as Sid, and Sid has twice as many as Steve. If Steve has 12 popsicle sticks, how many popsicle sticks can they use for their Art class activity?
Output: 108

Input: The price of an iPhone fell 10% in a particular month and another 20% in the second month.  If the initial price was $1000, calculate the price after the second month.
Output: 720

Input: John uses a 75-watt electric fan for 8 hours a day. How much kWh of electric energy does he consume per month (30 days) for using the electric fan?
Output: 18

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o16-tgsm8k-s20-rFalse-m4096
Evaluating commonsenseqa :   2%|▎             | 1/50 [01:43<1:24:13, 103.13s/it]Evaluating commonsenseqa :   4%|▌             | 2/50 [03:23<1:21:08, 101.43s/it]Evaluating commonsenseqa :   6%|▉              | 3/50 [04:28<1:06:23, 84.75s/it]Evaluating commonsenseqa :   8%|█▏             | 4/50 [06:07<1:09:19, 90.43s/it]Evaluating commonsenseqa :  10%|█▌             | 5/50 [07:49<1:10:59, 94.66s/it]Evaluating commonsenseqa :  12%|█▊             | 6/50 [09:28<1:10:29, 96.13s/it]Evaluating commonsenseqa :  14%|██▍              | 7/50 [10:05<55:06, 76.90s/it]Evaluating commonsenseqa :  16%|██▋              | 8/50 [11:46<59:11, 84.56s/it]Evaluating commonsenseqa :  18%|██▋            | 9/50 [13:29<1:01:35, 90.13s/it]Evaluating commonsenseqa :  20%|██▊           | 10/50 [15:01<1:00:33, 90.85s/it]Evaluating commonsenseqa :  22%|███           | 11/50 [16:43<1:01:12, 94.17s/it]Evaluating commonsenseqa :  24%|███▎          | 12/50 [18:20<1:00:15, 95.16s/it]Evaluating commonsenseqa :  26%|████▏           | 13/50 [19:59<59:21, 96.25s/it]Evaluating commonsenseqa :  28%|████▍           | 14/50 [21:38<58:11, 96.99s/it]Evaluating commonsenseqa :  30%|████▊           | 15/50 [23:18<57:05, 97.86s/it]Evaluating commonsenseqa :  32%|█████           | 16/50 [25:00<56:13, 99.22s/it]Evaluating commonsenseqa :  34%|█████▍          | 17/50 [26:41<54:55, 99.86s/it]Evaluating commonsenseqa :  36%|█████▊          | 18/50 [28:20<53:05, 99.53s/it]Evaluating commonsenseqa :  38%|██████          | 19/50 [30:00<51:29, 99.67s/it]Evaluating commonsenseqa :  40%|██████▍         | 20/50 [31:40<49:55, 99.83s/it]Evaluating commonsenseqa :  42%|██████▋         | 21/50 [32:44<43:00, 88.98s/it]Evaluating commonsenseqa :  44%|███████         | 22/50 [34:27<43:26, 93.07s/it]Evaluating commonsenseqa :  46%|███████▎        | 23/50 [36:05<42:36, 94.67s/it]Evaluating commonsenseqa :  48%|███████▋        | 24/50 [37:44<41:36, 96.01s/it]Evaluating commonsenseqa :  50%|████████        | 25/50 [39:24<40:28, 97.16s/it]Evaluating commonsenseqa :  52%|████████▎       | 26/50 [40:16<33:27, 83.64s/it]Evaluating commonsenseqa :  54%|████████▋       | 27/50 [41:55<33:48, 88.20s/it]Evaluating commonsenseqa :  56%|████████▉       | 28/50 [43:36<33:45, 92.09s/it]Evaluating commonsenseqa :  58%|█████████▎      | 29/50 [45:17<33:11, 94.83s/it]Evaluating commonsenseqa :  60%|█████████▌      | 30/50 [46:57<32:07, 96.40s/it]Evaluating commonsenseqa :  62%|█████████▉      | 31/50 [48:36<30:47, 97.22s/it]Evaluating commonsenseqa :  64%|██████████▏     | 32/50 [50:11<28:53, 96.30s/it]Evaluating commonsenseqa :  66%|██████████▌     | 33/50 [51:52<27:40, 97.69s/it]Evaluating commonsenseqa :  68%|██████████▉     | 34/50 [53:34<26:25, 99.07s/it]Evaluating commonsenseqa :  70%|███████████▏    | 35/50 [54:51<23:09, 92.61s/it]Evaluating commonsenseqa :  72%|███████████▌    | 36/50 [55:47<19:01, 81.56s/it]Evaluating commonsenseqa :  74%|███████████▊    | 37/50 [57:28<18:55, 87.38s/it]Evaluating commonsenseqa :  76%|████████████▏   | 38/50 [58:43<16:44, 83.71s/it]Evaluating commonsenseqa :  78%|██████████▉   | 39/50 [1:00:24<16:16, 88.81s/it]Evaluating commonsenseqa :  80%|███████████▏  | 40/50 [1:02:04<15:20, 92.07s/it]Evaluating commonsenseqa :  82%|███████████▍  | 41/50 [1:03:45<14:12, 94.77s/it]Evaluating commonsenseqa :  84%|███████████▊  | 42/50 [1:05:26<12:53, 96.70s/it]Evaluating commonsenseqa :  86%|████████████  | 43/50 [1:07:06<11:24, 97.82s/it]Evaluating commonsenseqa :  88%|████████████▎ | 44/50 [1:08:40<09:38, 96.49s/it]Evaluating commonsenseqa :  90%|████████████▌ | 45/50 [1:10:19<08:06, 97.29s/it]Evaluating commonsenseqa :  92%|████████████▉ | 46/50 [1:11:58<06:30, 97.73s/it]Evaluating commonsenseqa :  94%|█████████████▏| 47/50 [1:13:38<04:55, 98.37s/it]Evaluating commonsenseqa :  96%|█████████████▍| 48/50 [1:15:17<03:17, 98.65s/it]Evaluating commonsenseqa :  98%|█████████████▋| 49/50 [1:16:56<01:38, 98.87s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:18:38<00:00, 99.89s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:18:38<00:00, 94.38s/it]
name: commonsenseqa | avg. gen lenth: 287.368 | time: 4719.3405747413635s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o17-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 17
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-31 18:34:57,963] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 18:34:57,979] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 18:34:58,015] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 18:34:58,077] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o17-tgsm8k-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 17
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o17-tgsm8k-s20-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████| 9741/9741 [00:00<00:00, 482159.10it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:06<00:06,  6.81s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.27s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.32s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.32s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.09s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.50s/it]
[2023-08-31 18:35:08,517] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.24s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.70s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.27s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.72s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.27s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.73s/it]
[2023-08-31 18:35:08,914] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 18:35:08,991] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
 > number of parameters: 6738415616
[2023-08-31 18:35:09,105] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 18:35:09,659] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-31 18:35:09,661] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-31 18:35:09,661] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-31 18:35:09,661] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-31 18:35:09,661] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-31 18:35:09,661] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-31 18:35:09,661] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-31 18:35:09,661] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-31 18:35:09,661] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-31 18:35:09,661] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-31 18:35:09,661] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-31 18:35:09,661] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f23832c92a0>
[2023-08-31 18:35:09,661] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-31 18:35:09,661] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-31 18:35:09,661] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-31 18:35:09,661] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-31 18:35:09,661] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-31 18:35:09,661] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-31 18:35:09,661] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-31 18:35:09,661] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-31 18:35:09,661] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-31 18:35:09,661] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-31 18:35:09,661] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-31 18:35:09,661] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-31 18:35:09,661] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-31 18:35:09,662] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-31 18:35:09,662] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: 97

Input: Nalani had two female dogs that were expecting and after a month gave birth to 10 puppies each. She then sold 3/4 of the puppies after they came of age, each at $200. Calculate the total amount of money she received from the sale of the puppies.
Output: 3000

Input: Boris has 24 books and he donates a fourth of his books to the library. Cameron has 30 books and he donates a third of his books to the library. After donating their books, how many books in total do Boris and Cameron have together?
Output: 38

Input: There are 3 boxes of cereal. One box holds 14 ounces of cereal. Another box holds half the amount of the first box and 5 ounces less than the third box. How much cereal is there in all 3 cereal boxes?
Output: 33

Input: A jug needs 40 cups of water to be full. A custodian at Truman Elementary School has to fill water jugs for 200 students, who drink 10 cups of water in a day. How many water jugs will the custodian fill with cups of water to provide the students with all the water they need in a day?
Output: 50

Input: It takes 1 hour for refrigerated dough to come to room temperature.  It takes 15 minutes to shape the dough and 2 hours to proof.  The bread takes 30 minutes to bake and 15 minutes to cool.  If the bakery opens at 6:00 am, what is the latest time the head baker can make it to the store to start working?
Output: 2

Input: Geric had twice as many bills as Kyla who has 2 fewer bills than Jessa.  After giving 3 bills to Geric, Jessa has 7 bills left. How many bills did Geric have at the beginning?
Output: 16

Input: They say the first year of a dog's life equals 15 human years. The second year of a dog's life equals 9 human years and after that, every year of a dog's life equals 5 human years. According to this logic, how many human years has my 10-year-old dog lived?
Output: 64

Input: Company A and Company B merge. Company A receives 60% of the combined profits under the new merger, and company B receives 40% of the profits. If company B gets a total of $60000 in profit, how much does company A get?
Output: 90000

Input: Sam, Sid, and Steve brought popsicle sticks for their group activity in their Art class. Sam has thrice as many as Sid, and Sid has twice as many as Steve. If Steve has 12 popsicle sticks, how many popsicle sticks can they use for their Art class activity?
Output: 108

Input: The price of an iPhone fell 10% in a particular month and another 20% in the second month.  If the initial price was $1000, calculate the price after the second month.
Output: 720

Input: John uses a 75-watt electric fan for 8 hours a day. How much kWh of electric energy does he consume per month (30 days) for using the electric fan?
Output: 18

Input: Barbara Blackburn can type 212 words per minute.  Due to Carpal tunnel syndrome, Barbara cannot use her left hand for a while so her typing speed is now 40 words less per minute. If she is supposed to type a document with 3440 words, how many minutes will it take her to finish typing the document?
Output: 20

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o17-tgsm8k-s20-rFalse-m4096
Evaluating commonsenseqa :   2%|▎             | 1/50 [01:41<1:22:58, 101.59s/it]Evaluating commonsenseqa :   4%|▌              | 2/50 [03:19<1:19:41, 99.61s/it]Evaluating commonsenseqa :   6%|▉              | 3/50 [04:59<1:17:56, 99.49s/it]Evaluating commonsenseqa :   8%|█▏             | 4/50 [06:39<1:16:29, 99.77s/it]Evaluating commonsenseqa :  10%|█▌             | 5/50 [08:00<1:09:51, 93.15s/it]Evaluating commonsenseqa :  12%|█▊             | 6/50 [09:40<1:09:56, 95.37s/it]Evaluating commonsenseqa :  14%|██             | 7/50 [11:18<1:08:53, 96.12s/it]Evaluating commonsenseqa :  16%|██▋              | 8/50 [11:59<55:10, 78.81s/it]Evaluating commonsenseqa :  18%|███              | 9/50 [13:38<58:02, 84.95s/it]Evaluating commonsenseqa :  20%|███▏            | 10/50 [15:15<59:03, 88.59s/it]Evaluating commonsenseqa :  22%|███▌            | 11/50 [16:53<59:35, 91.68s/it]Evaluating commonsenseqa :  24%|███▊            | 12/50 [18:33<59:38, 94.17s/it]Evaluating commonsenseqa :  26%|████▏           | 13/50 [20:10<58:34, 94.99s/it]Evaluating commonsenseqa :  28%|████▍           | 14/50 [21:49<57:39, 96.11s/it]Evaluating commonsenseqa :  30%|████▊           | 15/50 [23:28<56:37, 97.06s/it]Evaluating commonsenseqa :  32%|█████           | 16/50 [24:34<49:43, 87.74s/it]Evaluating commonsenseqa :  34%|█████▍          | 17/50 [26:13<50:03, 91.02s/it]Evaluating commonsenseqa :  36%|█████▊          | 18/50 [27:49<49:20, 92.50s/it]Evaluating commonsenseqa :  38%|██████          | 19/50 [29:25<48:23, 93.66s/it]Evaluating commonsenseqa :  40%|██████▍         | 20/50 [31:04<47:40, 95.34s/it]Evaluating commonsenseqa :  42%|██████▋         | 21/50 [32:44<46:43, 96.68s/it]Evaluating commonsenseqa :  44%|███████         | 22/50 [34:25<45:43, 97.99s/it]Evaluating commonsenseqa :  46%|███████▎        | 23/50 [35:25<38:54, 86.47s/it]Evaluating commonsenseqa :  48%|███████▋        | 24/50 [37:03<38:57, 89.90s/it]Evaluating commonsenseqa :  50%|████████        | 25/50 [38:28<36:57, 88.69s/it]Evaluating commonsenseqa :  52%|████████▎       | 26/50 [40:07<36:41, 91.74s/it]Evaluating commonsenseqa :  54%|████████▋       | 27/50 [40:45<28:56, 75.51s/it]Evaluating commonsenseqa :  56%|████████▉       | 28/50 [42:24<30:14, 82.50s/it]Evaluating commonsenseqa :  58%|█████████▎      | 29/50 [43:57<30:01, 85.79s/it]Evaluating commonsenseqa :  60%|█████████▌      | 30/50 [45:35<29:46, 89.34s/it]Evaluating commonsenseqa :  62%|█████████▉      | 31/50 [47:12<29:02, 91.72s/it]Evaluating commonsenseqa :  64%|██████████▏     | 32/50 [48:48<27:53, 92.99s/it]Evaluating commonsenseqa :  66%|██████████▌     | 33/50 [50:01<24:40, 87.08s/it]Evaluating commonsenseqa :  68%|██████████▉     | 34/50 [51:38<23:59, 89.99s/it]Evaluating commonsenseqa :  70%|███████████▏    | 35/50 [53:16<23:05, 92.36s/it]Evaluating commonsenseqa :  72%|███████████▌    | 36/50 [54:55<21:59, 94.26s/it]Evaluating commonsenseqa :  74%|███████████▊    | 37/50 [56:34<20:43, 95.63s/it]Evaluating commonsenseqa :  76%|████████████▏   | 38/50 [57:55<18:18, 91.51s/it]Evaluating commonsenseqa :  78%|████████████▍   | 39/50 [59:35<17:11, 93.77s/it]Evaluating commonsenseqa :  80%|███████████▏  | 40/50 [1:01:11<15:45, 94.57s/it]Evaluating commonsenseqa :  82%|███████████▍  | 41/50 [1:02:49<14:20, 95.63s/it]Evaluating commonsenseqa :  84%|███████████▊  | 42/50 [1:04:27<12:51, 96.45s/it]Evaluating commonsenseqa :  86%|████████████  | 43/50 [1:06:04<11:15, 96.52s/it]Evaluating commonsenseqa :  88%|████████████▎ | 44/50 [1:07:43<09:43, 97.28s/it]Evaluating commonsenseqa :  90%|████████████▌ | 45/50 [1:09:24<08:11, 98.33s/it]Evaluating commonsenseqa :  92%|████████████▉ | 46/50 [1:11:03<06:34, 98.55s/it]Evaluating commonsenseqa :  94%|█████████████▏| 47/50 [1:12:42<04:56, 98.82s/it]Evaluating commonsenseqa :  96%|█████████████▍| 48/50 [1:14:05<03:07, 93.85s/it]Evaluating commonsenseqa :  98%|█████████████▋| 49/50 [1:15:09<01:24, 84.93s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:16:47<00:00, 88.93s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:16:47<00:00, 92.15s/it]
name: commonsenseqa | avg. gen lenth: 276.892 | time: 4607.952689170837s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o18-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 18
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-31 19:54:09,525] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 19:54:10,093] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 19:54:10,093] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 19:54:10,098] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o18-tgsm8k-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 18
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o18-tgsm8k-s20-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████| 9741/9741 [00:00<00:00, 454316.86it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.28s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.43s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.45s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.50s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.27s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.72s/it]
[2023-08-31 19:54:20,984] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.39s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.85s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.40s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.86s/it]
[2023-08-31 19:54:21,262] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 19:54:21,293] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.50s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.95s/it]
 > number of parameters: 6738415616
[2023-08-31 19:54:21,496] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 19:54:22,040] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-31 19:54:22,041] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-31 19:54:22,041] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fe2b6fbd2d0>
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-31 19:54:22,042] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-31 19:54:22,043] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-31 19:54:22,043] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-31 19:54:22,043] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-31 19:54:22,043] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-31 19:54:22,043] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-31 19:54:22,043] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-31 19:54:22,043] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-31 19:54:22,043] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-31 19:54:22,043] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-31 19:54:22,043] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-31 19:54:22,043] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-31 19:54:22,043] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-31 19:54:22,043] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-31 19:54:22,043] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-31 19:54:22,043] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-31 19:54:22,043] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-31 19:54:22,043] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-31 19:54:22,043] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-31 19:54:22,043] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-31 19:54:22,043] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-31 19:54:22,043] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-31 19:54:22,043] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-31 19:54:22,043] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-31 19:54:22,043] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-31 19:54:22,043] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-31 19:54:22,043] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-31 19:54:22,043] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-31 19:54:22,043] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-31 19:54:22,043] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: 97

Input: Nalani had two female dogs that were expecting and after a month gave birth to 10 puppies each. She then sold 3/4 of the puppies after they came of age, each at $200. Calculate the total amount of money she received from the sale of the puppies.
Output: 3000

Input: Boris has 24 books and he donates a fourth of his books to the library. Cameron has 30 books and he donates a third of his books to the library. After donating their books, how many books in total do Boris and Cameron have together?
Output: 38

Input: There are 3 boxes of cereal. One box holds 14 ounces of cereal. Another box holds half the amount of the first box and 5 ounces less than the third box. How much cereal is there in all 3 cereal boxes?
Output: 33

Input: A jug needs 40 cups of water to be full. A custodian at Truman Elementary School has to fill water jugs for 200 students, who drink 10 cups of water in a day. How many water jugs will the custodian fill with cups of water to provide the students with all the water they need in a day?
Output: 50

Input: It takes 1 hour for refrigerated dough to come to room temperature.  It takes 15 minutes to shape the dough and 2 hours to proof.  The bread takes 30 minutes to bake and 15 minutes to cool.  If the bakery opens at 6:00 am, what is the latest time the head baker can make it to the store to start working?
Output: 2

Input: Geric had twice as many bills as Kyla who has 2 fewer bills than Jessa.  After giving 3 bills to Geric, Jessa has 7 bills left. How many bills did Geric have at the beginning?
Output: 16

Input: They say the first year of a dog's life equals 15 human years. The second year of a dog's life equals 9 human years and after that, every year of a dog's life equals 5 human years. According to this logic, how many human years has my 10-year-old dog lived?
Output: 64

Input: Company A and Company B merge. Company A receives 60% of the combined profits under the new merger, and company B receives 40% of the profits. If company B gets a total of $60000 in profit, how much does company A get?
Output: 90000

Input: Sam, Sid, and Steve brought popsicle sticks for their group activity in their Art class. Sam has thrice as many as Sid, and Sid has twice as many as Steve. If Steve has 12 popsicle sticks, how many popsicle sticks can they use for their Art class activity?
Output: 108

Input: The price of an iPhone fell 10% in a particular month and another 20% in the second month.  If the initial price was $1000, calculate the price after the second month.
Output: 720

Input: John uses a 75-watt electric fan for 8 hours a day. How much kWh of electric energy does he consume per month (30 days) for using the electric fan?
Output: 18

Input: Barbara Blackburn can type 212 words per minute.  Due to Carpal tunnel syndrome, Barbara cannot use her left hand for a while so her typing speed is now 40 words less per minute. If she is supposed to type a document with 3440 words, how many minutes will it take her to finish typing the document?
Output: 20

Input: Max fills up water balloons for 30 minutes at a rate of 2 water balloons every minute. Max’s friend Zach fills up water balloons for 40 minutes at a rate of 3 water balloons every minute. In the process, 10 of the water balloons pop on the ground. How many filled water balloons do Max and Zach have in total?
Output: 170

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o18-tgsm8k-s20-rFalse-m4096
Evaluating commonsenseqa :   2%|▎              | 1/50 [01:33<1:16:04, 93.14s/it]Evaluating commonsenseqa :   4%|▌              | 2/50 [03:07<1:14:51, 93.57s/it]Evaluating commonsenseqa :   6%|▉              | 3/50 [04:40<1:13:09, 93.40s/it]Evaluating commonsenseqa :   8%|█▏             | 4/50 [06:16<1:12:36, 94.71s/it]Evaluating commonsenseqa :  10%|█▌             | 5/50 [07:47<1:09:57, 93.27s/it]Evaluating commonsenseqa :  12%|█▊             | 6/50 [09:21<1:08:39, 93.64s/it]Evaluating commonsenseqa :  14%|██             | 7/50 [10:55<1:07:02, 93.56s/it]Evaluating commonsenseqa :  16%|██▍            | 8/50 [12:29<1:05:31, 93.61s/it]Evaluating commonsenseqa :  18%|██▋            | 9/50 [14:05<1:04:38, 94.61s/it]Evaluating commonsenseqa :  20%|██▊           | 10/50 [15:41<1:03:13, 94.85s/it]Evaluating commonsenseqa :  22%|███           | 11/50 [17:15<1:01:30, 94.63s/it]Evaluating commonsenseqa :  24%|███▊            | 12/50 [18:48<59:38, 94.17s/it]Evaluating commonsenseqa :  26%|████▏           | 13/50 [20:22<58:04, 94.18s/it]Evaluating commonsenseqa :  28%|████▍           | 14/50 [20:58<45:50, 76.40s/it]Evaluating commonsenseqa :  30%|████▊           | 15/50 [22:30<47:20, 81.17s/it]Evaluating commonsenseqa :  32%|█████           | 16/50 [24:02<47:56, 84.61s/it]Evaluating commonsenseqa :  34%|█████▍          | 17/50 [25:39<48:26, 88.08s/it]Evaluating commonsenseqa :  36%|█████▊          | 18/50 [27:12<47:53, 89.79s/it]Evaluating commonsenseqa :  38%|██████          | 19/50 [28:46<47:02, 91.06s/it]Evaluating commonsenseqa :  40%|██████▍         | 20/50 [30:20<45:51, 91.72s/it]Evaluating commonsenseqa :  42%|██████▋         | 21/50 [31:56<44:59, 93.07s/it]Evaluating commonsenseqa :  44%|███████         | 22/50 [33:33<43:57, 94.21s/it]Evaluating commonsenseqa :  46%|███████▎        | 23/50 [35:06<42:12, 93.80s/it]Evaluating commonsenseqa :  48%|███████▋        | 24/50 [36:40<40:46, 94.11s/it]Evaluating commonsenseqa :  50%|████████        | 25/50 [38:17<39:34, 94.96s/it]Evaluating commonsenseqa :  52%|████████▎       | 26/50 [39:00<31:39, 79.14s/it]Evaluating commonsenseqa :  54%|████████▋       | 27/50 [40:34<32:03, 83.61s/it]Evaluating commonsenseqa :  56%|████████▉       | 28/50 [42:09<31:54, 87.03s/it]Evaluating commonsenseqa :  58%|█████████▎      | 29/50 [43:43<31:12, 89.16s/it]Evaluating commonsenseqa :  60%|█████████▌      | 30/50 [45:20<30:30, 91.51s/it]Evaluating commonsenseqa :  62%|█████████▉      | 31/50 [46:54<29:16, 92.47s/it]Evaluating commonsenseqa :  64%|██████████▏     | 32/50 [48:30<28:02, 93.50s/it]Evaluating commonsenseqa :  66%|██████████▌     | 33/50 [50:06<26:39, 94.11s/it]Evaluating commonsenseqa :  68%|██████████▉     | 34/50 [51:40<25:07, 94.21s/it]Evaluating commonsenseqa :  70%|███████████▏    | 35/50 [53:15<23:36, 94.45s/it]Evaluating commonsenseqa :  72%|███████████▌    | 36/50 [54:49<21:59, 94.26s/it]Evaluating commonsenseqa :  74%|███████████▊    | 37/50 [56:25<20:29, 94.59s/it]Evaluating commonsenseqa :  76%|████████████▏   | 38/50 [57:43<17:55, 89.65s/it]Evaluating commonsenseqa :  78%|████████████▍   | 39/50 [59:17<16:40, 90.95s/it]Evaluating commonsenseqa :  80%|███████████▏  | 40/50 [1:00:53<15:26, 92.61s/it]Evaluating commonsenseqa :  82%|███████████▍  | 41/50 [1:02:26<13:53, 92.57s/it]Evaluating commonsenseqa :  84%|███████████▊  | 42/50 [1:03:59<12:23, 92.91s/it]Evaluating commonsenseqa :  86%|████████████  | 43/50 [1:05:33<10:51, 93.04s/it]Evaluating commonsenseqa :  88%|████████████▎ | 44/50 [1:07:07<09:21, 93.58s/it]Evaluating commonsenseqa :  90%|████████████▌ | 45/50 [1:08:44<07:51, 94.40s/it]Evaluating commonsenseqa :  92%|████████████▉ | 46/50 [1:10:18<06:17, 94.36s/it]Evaluating commonsenseqa :  94%|█████████████▏| 47/50 [1:11:53<04:43, 94.55s/it]Evaluating commonsenseqa :  96%|█████████████▍| 48/50 [1:13:28<03:09, 94.76s/it]Evaluating commonsenseqa :  98%|█████████████▋| 49/50 [1:15:03<01:34, 94.63s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:16:35<00:00, 94.07s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:16:35<00:00, 91.92s/it]
name: commonsenseqa | avg. gen lenth: 300.496 | time: 4596.2724397182465s
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o19-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 19
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-31 21:11:47,337] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 21:11:47,350] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 21:11:47,351] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 21:11:47,359] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 4
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o19-tgsm8k-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 19
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o19-tgsm8k-s20-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading data:   0%|                                    | 0/9741 [00:00<?, ?it/s]Loading data: 100%|█████████████████████| 9741/9741 [00:00<00:00, 435159.77it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████████         | 1/2 [00:06<00:06,  6.82s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.23s/it]Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.32s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  4.00s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  4.42s/it]
[2023-08-31 21:11:57,788] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.28s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.74s/it]
Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.29s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.73s/it]
[2023-08-31 21:11:58,347] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
 > number of parameters: 6738415616
[2023-08-31 21:11:58,375] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards:  50%|█████████         | 1/2 [00:09<00:09,  9.77s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  5.20s/it]Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  5.88s/it]
[2023-08-31 21:12:00,683] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 21:12:01,327] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-31 21:12:01,330] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-31 21:12:01,331] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-31 21:12:01,331] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-31 21:12:01,331] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-31 21:12:01,331] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-31 21:12:01,331] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-31 21:12:01,331] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-31 21:12:01,331] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-31 21:12:01,331] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-31 21:12:01,331] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-31 21:12:01,331] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7ff7967cd300>
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-31 21:12:01,332] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-31 21:12:01,333] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-31 21:12:01,333] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-31 21:12:01,333] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-31 21:12:01,333] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-31 21:12:01,333] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-31 21:12:01,333] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-31 21:12:01,333] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-31 21:12:01,333] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-31 21:12:01,333] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-31 21:12:01,333] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-31 21:12:01,333] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-31 21:12:01,333] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-31 21:12:01,333] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-31 21:12:01,333] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-31 21:12:01,333] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-31 21:12:01,333] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-31 21:12:01,333] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-31 21:12:01,333] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-31 21:12:01,333] [INFO] [config.py:964:print]   train_batch_size ............. 4
[2023-08-31 21:12:01,333] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-31 21:12:01,333] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-31 21:12:01,333] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-31 21:12:01,333] [INFO] [config.py:964:print]   world_size ................... 4
[2023-08-31 21:12:01,333] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-31 21:12:01,333] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-31 21:12:01,333] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-31 21:12:01,333] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-31 21:12:01,333] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-31 21:12:01,333] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|                         | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: 97

Input: Nalani had two female dogs that were expecting and after a month gave birth to 10 puppies each. She then sold 3/4 of the puppies after they came of age, each at $200. Calculate the total amount of money she received from the sale of the puppies.
Output: 3000

Input: Boris has 24 books and he donates a fourth of his books to the library. Cameron has 30 books and he donates a third of his books to the library. After donating their books, how many books in total do Boris and Cameron have together?
Output: 38

Input: There are 3 boxes of cereal. One box holds 14 ounces of cereal. Another box holds half the amount of the first box and 5 ounces less than the third box. How much cereal is there in all 3 cereal boxes?
Output: 33

Input: A jug needs 40 cups of water to be full. A custodian at Truman Elementary School has to fill water jugs for 200 students, who drink 10 cups of water in a day. How many water jugs will the custodian fill with cups of water to provide the students with all the water they need in a day?
Output: 50

Input: It takes 1 hour for refrigerated dough to come to room temperature.  It takes 15 minutes to shape the dough and 2 hours to proof.  The bread takes 30 minutes to bake and 15 minutes to cool.  If the bakery opens at 6:00 am, what is the latest time the head baker can make it to the store to start working?
Output: 2

Input: Geric had twice as many bills as Kyla who has 2 fewer bills than Jessa.  After giving 3 bills to Geric, Jessa has 7 bills left. How many bills did Geric have at the beginning?
Output: 16

Input: They say the first year of a dog's life equals 15 human years. The second year of a dog's life equals 9 human years and after that, every year of a dog's life equals 5 human years. According to this logic, how many human years has my 10-year-old dog lived?
Output: 64

Input: Company A and Company B merge. Company A receives 60% of the combined profits under the new merger, and company B receives 40% of the profits. If company B gets a total of $60000 in profit, how much does company A get?
Output: 90000

Input: Sam, Sid, and Steve brought popsicle sticks for their group activity in their Art class. Sam has thrice as many as Sid, and Sid has twice as many as Steve. If Steve has 12 popsicle sticks, how many popsicle sticks can they use for their Art class activity?
Output: 108

Input: The price of an iPhone fell 10% in a particular month and another 20% in the second month.  If the initial price was $1000, calculate the price after the second month.
Output: 720

Input: John uses a 75-watt electric fan for 8 hours a day. How much kWh of electric energy does he consume per month (30 days) for using the electric fan?
Output: 18

Input: Barbara Blackburn can type 212 words per minute.  Due to Carpal tunnel syndrome, Barbara cannot use her left hand for a while so her typing speed is now 40 words less per minute. If she is supposed to type a document with 3440 words, how many minutes will it take her to finish typing the document?
Output: 20

Input: Max fills up water balloons for 30 minutes at a rate of 2 water balloons every minute. Max’s friend Zach fills up water balloons for 40 minutes at a rate of 3 water balloons every minute. In the process, 10 of the water balloons pop on the ground. How many filled water balloons do Max and Zach have in total?
Output: 170

Input: John has 54 pieces of gum, Cole has 45 pieces of gum and Aubrey has no pieces of gum. They decide to share the gum equally between the 3 of them. How many pieces of gum will each one get?
Output: 33

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o19-tgsm8k-s20-rFalse-m4096
Evaluating commonsenseqa :   2%|▎              | 1/50 [01:34<1:17:18, 94.67s/it]Evaluating commonsenseqa :   4%|▌              | 2/50 [03:07<1:15:00, 93.77s/it]Evaluating commonsenseqa :   6%|▉              | 3/50 [04:40<1:13:11, 93.43s/it]Evaluating commonsenseqa :   8%|█▏             | 4/50 [06:16<1:12:18, 94.31s/it]Evaluating commonsenseqa :  10%|█▌             | 5/50 [07:49<1:10:21, 93.81s/it]Evaluating commonsenseqa :  12%|█▊             | 6/50 [09:22<1:08:29, 93.40s/it]Evaluating commonsenseqa :  14%|██             | 7/50 [10:55<1:06:54, 93.35s/it]Evaluating commonsenseqa :  16%|██▍            | 8/50 [12:27<1:05:04, 92.96s/it]Evaluating commonsenseqa :  18%|███              | 9/50 [13:17<54:21, 79.54s/it]Evaluating commonsenseqa :  20%|███▏            | 10/50 [14:50<55:49, 83.73s/it]Evaluating commonsenseqa :  22%|███▌            | 11/50 [16:07<53:00, 81.56s/it]Evaluating commonsenseqa :  24%|███▊            | 12/50 [17:40<53:50, 85.01s/it]Evaluating commonsenseqa :  26%|████▏           | 13/50 [19:12<53:44, 87.14s/it]Evaluating commonsenseqa :  28%|████▍           | 14/50 [20:34<51:29, 85.82s/it]Evaluating commonsenseqa :  30%|████▊           | 15/50 [22:07<51:17, 87.93s/it]Evaluating commonsenseqa :  32%|█████           | 16/50 [23:40<50:41, 89.45s/it]Evaluating commonsenseqa :  34%|█████▍          | 17/50 [25:13<49:43, 90.40s/it]Evaluating commonsenseqa :  36%|█████▊          | 18/50 [26:47<48:47, 91.49s/it]Evaluating commonsenseqa :  38%|██████          | 19/50 [28:15<46:46, 90.54s/it]Evaluating commonsenseqa :  40%|██████▍         | 20/50 [29:47<45:31, 91.06s/it]Evaluating commonsenseqa :  42%|██████▋         | 21/50 [31:19<44:03, 91.17s/it]Evaluating commonsenseqa :  44%|███████         | 22/50 [32:51<42:39, 91.40s/it]Evaluating commonsenseqa :  46%|███████▎        | 23/50 [34:23<41:18, 91.79s/it]Evaluating commonsenseqa :  48%|███████▋        | 24/50 [35:58<40:08, 92.62s/it]Evaluating commonsenseqa :  50%|████████        | 25/50 [37:32<38:46, 93.06s/it]Evaluating commonsenseqa :  52%|████████▎       | 26/50 [39:07<37:25, 93.57s/it]Evaluating commonsenseqa :  54%|████████▋       | 27/50 [40:39<35:43, 93.21s/it]Evaluating commonsenseqa :  56%|████████▉       | 28/50 [42:12<34:04, 92.94s/it]Evaluating commonsenseqa :  58%|█████████▎      | 29/50 [43:45<32:33, 93.04s/it]Evaluating commonsenseqa :  60%|█████████▌      | 30/50 [45:17<30:58, 92.92s/it]Evaluating commonsenseqa :  62%|█████████▉      | 31/50 [46:51<29:30, 93.20s/it]Evaluating commonsenseqa :  64%|██████████▏     | 32/50 [48:24<27:52, 92.92s/it]Evaluating commonsenseqa :  66%|██████████▌     | 33/50 [49:18<23:00, 81.22s/it]Evaluating commonsenseqa :  68%|██████████▉     | 34/50 [50:49<22:31, 84.44s/it]Evaluating commonsenseqa :  70%|███████████▏    | 35/50 [52:22<21:43, 86.89s/it]Evaluating commonsenseqa :  72%|███████████▌    | 36/50 [53:56<20:43, 88.86s/it]Evaluating commonsenseqa :  74%|███████████▊    | 37/50 [55:28<19:28, 89.88s/it]Evaluating commonsenseqa :  76%|████████████▏   | 38/50 [57:03<18:16, 91.35s/it]Evaluating commonsenseqa :  78%|████████████▍   | 39/50 [58:35<16:47, 91.57s/it]Evaluating commonsenseqa :  80%|███████████▏  | 40/50 [1:00:09<15:23, 92.38s/it]Evaluating commonsenseqa :  82%|███████████▍  | 41/50 [1:01:43<13:55, 92.82s/it]Evaluating commonsenseqa :  84%|███████████▊  | 42/50 [1:03:16<12:23, 92.89s/it]Evaluating commonsenseqa :  86%|████████████  | 43/50 [1:04:50<10:52, 93.15s/it]Evaluating commonsenseqa :  88%|████████████▎ | 44/50 [1:06:22<09:18, 93.07s/it]Evaluating commonsenseqa :  90%|████████████▌ | 45/50 [1:06:48<06:04, 72.95s/it]Evaluating commonsenseqa :  92%|████████████▉ | 46/50 [1:08:24<05:18, 79.69s/it]Evaluating commonsenseqa :  94%|█████████████▏| 47/50 [1:09:58<04:11, 83.91s/it]Evaluating commonsenseqa :  96%|█████████████▍| 48/50 [1:11:29<02:52, 86.22s/it]Evaluating commonsenseqa :  98%|█████████████▋| 49/50 [1:12:00<01:09, 69.45s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:13:02<00:00, 67.36s/it]Evaluating commonsenseqa : 100%|██████████████| 50/50 [1:13:02<00:00, 87.65s/it]
name: commonsenseqa | avg. gen lenth: 314.184 | time: 4382.978824853897s
