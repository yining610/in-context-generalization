WORLD_SIZE=1
MASTER_ADDR=icgpu04
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 12081 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o16-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 16 16 17 18 19 20 False 4096 10
[2023-09-01 17:54:49,909] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 12081 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o17-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 17 16 17 18 19 20 False 4096 10
[2023-09-01 17:54:56,782] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 12081 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o18-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 18 16 17 18 19 20 False 4096 10
[2023-09-01 17:55:03,589] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 12081 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o19-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 19 16 17 18 19 20 False 4096 10
[2023-09-01 17:55:10,442] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 12081 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o20-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 20 16 17 18 19 20 False 4096 10
[2023-09-01 17:55:17,301] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 12081 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o16-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 16 16 17 18 19 20 False 4096 10
[2023-09-01 17:55:24,142] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 12081 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o17-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 17 16 17 18 19 20 False 4096 10
[2023-09-01 17:55:30,978] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 12081 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o18-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 18 16 17 18 19 20 False 4096 10
[2023-09-01 17:55:37,765] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 12081 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o19-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 19 16 17 18 19 20 False 4096 10
[2023-09-01 17:55:44,597] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 12081 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o20-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 20 16 17 18 19 20 False 4096 10
[2023-09-01 17:55:51,441] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 12081 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o16-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 16 16 17 18 19 20 False 4096 10
[2023-09-01 17:55:58,359] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 12081 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o17-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 17 16 17 18 19 20 False 4096 10
[2023-09-01 17:56:05,162] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 12081 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o18-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 18 16 17 18 19 20 False 4096 10
[2023-09-01 17:56:11,958] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 12081 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o19-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 19 16 17 18 19 20 False 4096 10
[2023-09-01 17:56:18,785] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 12081 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o20-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 20 16 17 18 19 20 False 4096 10
[2023-09-01 17:56:25,614] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 12081 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o16-tgsm8k-s30-rFalse --seed 30 --max-prompt-length 4096 --num-out-domain 16 16 17 18 19 20 False 4096 10
[2023-09-01 17:56:32,418] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o16-tgsm8k-s30-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 16
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o16-tgsm8k-s30-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 10
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 562439.29it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.88s/it]
 > number of parameters: 6738415616
[2023-09-01 17:56:43,521] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-01 17:56:43,725] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-01 17:56:43,726] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-01 17:56:43,727] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-01 17:56:43,727] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-01 17:56:43,727] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-01 17:56:43,727] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-01 17:56:43,727] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-01 17:56:43,727] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-01 17:56:43,727] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-01 17:56:43,727] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-01 17:56:43,727] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-01 17:56:43,727] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f27340>
[2023-09-01 17:56:43,727] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-01 17:56:43,727] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-01 17:56:43,727] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-01 17:56:43,727] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-01 17:56:43,727] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-01 17:56:43,727] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-01 17:56:43,727] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-01 17:56:43,727] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-01 17:56:43,727] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-01 17:56:43,727] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-01 17:56:43,727] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-01 17:56:43,727] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-01 17:56:43,727] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-01 17:56:43,727] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-01 17:56:43,727] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-01 17:56:43,727] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-01 17:56:43,727] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-01 17:56:43,727] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-01 17:56:43,728] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-01 17:56:43,729] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/100 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: The car-rental agency charges $30/day for a car, or $190 for the first week for a rental that lasts an entire week or longer. Jennie rented a car for 11 days. How much, in dollars, did she pay for the rental?
Output: 310

Input: A hurricane is approaching the southern coast of Texas, and a rancher is planning to move 400 head of cattle 60 miles to higher ground to protect them from possible inland flooding that might occur.  His animal transport truck holds 20 head of cattle.  Traveling at 60 miles per hour, what is the total driving time, in hours, it will take to transport all of his cattle to higher ground?
Output: 40

Input: Jason has a carriage house that he rents out.  He’s charging $50.00 per day or $500.00 for 14 days.  Eric wants to rent the house for 20 days.  How much will it cost him?
Output: 800

Input: Melissa works on a poultry farm. She drives to town twice each month to buy supplies. If it takes her 3 hours to drive to town and back, how many hours does Melissa spend driving in a year?
Output: 72

Input: The ratio of boys to girls in a family is 5:7. The total number of children in the family is 180. If the boys are given $3900 to share, how much money does each boy receive?
Output: 52

Input: Josephine receives a bill from the hospital for 5000$.  50 percent of the bill is for medication.  25 percent of the remaining bill is for overnight stays, and 175$ is for food.  The rest of the bill is for the ambulance ride.  How much did the ambulance ride cost?
Output: 1700

Input: It was time for Kelly to harvest her carrots that she had planted in three different beds.  In the first bed she pulled out 55 carrots.  In the second bed she pulled out 101 carrots and in the third bed she pulled out 78 carrots.  She found that 6 carrots weighed one pound.  How many pounds of carrots did Kelly harvest?
Output: 39

Input: Iris’ family is planning a surprise birthday party for her. The party will include her 3 uncles and 4 aunts who have a son and daughter each as well as her brother and mother. In total, how many people are coming to Iris’ birthday party?
Output: 23

Input: Lyra bought a pair of shoes at a 20% discount.  If she paid $480, how much was the original price of the pair of shoes?
Output: 600

Input: Rhett has been late on two of his monthly rent payments, but his landlord does not charge late fees and so he will be able to pay their total cost with 3/5 of his next month's salary after taxes. If he is currently paid $5000 per month and has to pay 10% tax, calculate his rent expense per month?
Output: 1350

Input: Ten friends decide to get an end-of-year gift for their teacher. They plan to split the cost of the gift equally. But four of the group drop out. The remaining friends split the cost equally among themselves. If each share is now $8 more, how much does the gift cost, in dollars?
Output: 120

Input: At the feline sanctuary, there were 12 lions, 14 tigers, and several cougars.  If there were half as many cougars as lions and tigers combined, then what was the total number of big cats at the feline sanctuary?
Output: 39

Input: A pea patch is twice as big as a radish patch. If one sixth of the pea patch is 5 square feet.  How much is a whole radish patch in square feet?
Output: 15

Input: Phoebe has two pizzas to share with her and three friends. One has pepperoni and the other has cheese. They both have 16 slices. They all eat the same amount. One friend eats only pepperoni, while the rest have an equal number of slices of each. At the end, there is one slice of pepperoni left and 7 slices of cheese, how many slices does each person eat?
Output: 6

Input: Jeremy buys 30 watermelons. He eats 3 watermelons per week. Each week he gives 2 to his dad. How many weeks will the watermelons last?
Output: 6

Input: Jackson has 5 times more money than Williams. Together, they have $150. How much money, in dollars, does Jackson have?
Output: 125

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o16-tgsm8k-s30-rFalse-m4096
Evaluating commonsenseqa :   1%|          | 1/100 [03:52<6:23:50, 232.63s/it]Evaluating commonsenseqa :   1%|          | 1/100 [04:19<7:08:18, 259.58s/it]Evaluating commonsenseqa :   1%|          | 1/100 [02:11<3:37:28, 131.80s/it]Evaluating commonsenseqa :   2%|▏         | 2/100 [07:38<6:13:27, 228.65s/it]Evaluating commonsenseqa :   2%|▏         | 2/100 [08:31<6:56:25, 254.96s/it]Evaluating commonsenseqa :   2%|▏         | 2/100 [05:37<4:46:13, 175.24s/it]Evaluating commonsenseqa :   3%|▎         | 3/100 [11:20<6:04:36, 225.53s/it]Evaluating commonsenseqa :   3%|▎         | 3/100 [08:54<4:59:23, 185.19s/it]Evaluating commonsenseqa :   3%|▎         | 3/100 [12:38<6:46:06, 251.20s/it]Evaluating commonsenseqa :   4%|▍         | 4/100 [12:12<5:04:10, 190.11s/it]Evaluating commonsenseqa :   4%|▍         | 4/100 [15:07<6:02:03, 226.29s/it]Evaluating commonsenseqa :   4%|▍         | 4/100 [16:51<6:43:32, 252.21s/it]Evaluating commonsenseqa :   5%|▌         | 5/100 [15:30<5:05:28, 192.93s/it]Evaluating commonsenseqa :   5%|▌         | 5/100 [18:50<5:56:25, 225.12s/it]Evaluating commonsenseqa :   5%|▌         | 5/100 [21:02<6:38:16, 251.54s/it]Evaluating commonsenseqa :   6%|▌         | 6/100 [18:51<5:06:41, 195.76s/it]Evaluating commonsenseqa :   6%|▌         | 6/100 [22:36<5:52:57, 225.29s/it]Evaluating commonsenseqa :   7%|▋         | 7/100 [22:11<5:05:34, 197.15s/it]Evaluating commonsenseqa :   6%|▌         | 6/100 [25:15<6:35:14, 252.28s/it]Evaluating commonsenseqa :   7%|▋         | 7/100 [26:25<5:51:07, 226.54s/it]Evaluating commonsenseqa :   8%|▊         | 8/100 [25:33<5:04:37, 198.67s/it]Evaluating commonsenseqa :   7%|▋         | 7/100 [29:24<6:28:57, 250.95s/it]Evaluating commonsenseqa :   8%|▊         | 8/100 [30:07<5:45:20, 225.22s/it]Evaluating commonsenseqa :   9%|▉         | 9/100 [28:52<5:01:25, 198.74s/it]Evaluating commonsenseqa :   8%|▊         | 8/100 [33:33<6:24:00, 250.44s/it]Evaluating commonsenseqa :   9%|▉         | 9/100 [33:58<5:44:12, 226.95s/it]Evaluating commonsenseqa :  10%|█         | 10/100 [32:10<4:57:56, 198.63s/it]Evaluating commonsenseqa :  10%|█         | 10/100 [37:49<5:42:25, 228.28s/it]Evaluating commonsenseqa :   9%|▉         | 9/100 [37:49<6:22:25, 252.15s/it]Evaluating commonsenseqa :  11%|█         | 11/100 [35:29<4:54:36, 198.61s/it]Evaluating commonsenseqa :  10%|█         | 10/100 [40:27<5:34:48, 223.20s/it]Evaluating commonsenseqa :  11%|█         | 11/100 [41:37<5:38:24, 228.14s/it]Evaluating commonsenseqa :  12%|█▏        | 12/100 [38:45<4:50:10, 197.84s/it]Evaluating commonsenseqa :  12%|█▏        | 12/100 [44:05<4:58:57, 203.83s/it]Evaluating commonsenseqa :  13%|█▎        | 13/100 [41:32<4:33:27, 188.59s/it]Evaluating commonsenseqa :  11%|█         | 11/100 [44:40<5:44:18, 232.12s/it]Evaluating commonsenseqa :  14%|█▍        | 14/100 [44:54<4:36:15, 192.74s/it]Evaluating commonsenseqa :  13%|█▎        | 13/100 [47:55<5:06:56, 211.69s/it]Evaluating commonsenseqa :  12%|█▏        | 12/100 [48:45<5:46:21, 236.15s/it]Evaluating commonsenseqa :  15%|█▌        | 15/100 [48:15<4:36:15, 195.01s/it]Evaluating commonsenseqa :  14%|█▍        | 14/100 [51:40<5:09:02, 215.61s/it]Evaluating commonsenseqa :  13%|█▎        | 13/100 [52:53<5:47:50, 239.89s/it]Evaluating commonsenseqa :  16%|█▌        | 16/100 [51:36<4:35:35, 196.85s/it]Evaluating commonsenseqa :  15%|█▌        | 15/100 [55:27<5:10:29, 219.17s/it]Evaluating commonsenseqa :  14%|█▍        | 14/100 [57:00<5:46:56, 242.05s/it]Evaluating commonsenseqa :  17%|█▋        | 17/100 [54:58<4:34:24, 198.37s/it]Evaluating commonsenseqa :  16%|█▌        | 16/100 [59:17<5:11:20, 222.38s/it]Evaluating commonsenseqa :  15%|█▌        | 15/100 [1:01:05<5:44:00, 242.83s/it]Evaluating commonsenseqa :  18%|█▊        | 18/100 [58:14<4:30:28, 197.90s/it]Evaluating commonsenseqa :  17%|█▋        | 17/100 [1:03:02<5:08:32, 223.04s/it]Evaluating commonsenseqa :  19%|█▉        | 19/100 [1:01:08<4:17:19, 190.61s/it]Evaluating commonsenseqa :  16%|█▌        | 16/100 [1:05:18<5:44:11, 245.85s/it]Evaluating commonsenseqa :  18%|█▊        | 18/100 [1:06:51<5:07:16, 224.84s/it]Evaluating commonsenseqa :  20%|██        | 20/100 [1:04:25<4:16:43, 192.55s/it]Evaluating commonsenseqa :  17%|█▋        | 17/100 [1:09:26<5:41:09, 246.62s/it]Evaluating commonsenseqa :  19%|█▉        | 19/100 [1:10:32<5:02:15, 223.89s/it]Evaluating commonsenseqa :  21%|██        | 21/100 [1:07:46<4:16:37, 194.90s/it]Evaluating commonsenseqa :  18%|█▊        | 18/100 [1:13:36<5:38:16, 247.52s/it]Evaluating commonsenseqa :  22%|██▏       | 22/100 [1:11:05<4:15:06, 196.24s/it]Evaluating commonsenseqa :  20%|██        | 20/100 [1:14:19<4:59:22, 224.53s/it]Evaluating commonsenseqa :  23%|██▎       | 23/100 [1:14:23<4:12:23, 196.67s/it]Evaluating commonsenseqa :  19%|█▉        | 19/100 [1:17:47<5:35:30, 248.52s/it]Evaluating commonsenseqa :  21%|██        | 21/100 [1:18:02<4:55:07, 224.15s/it]Evaluating commonsenseqa :  24%|██▍       | 24/100 [1:17:40<4:09:25, 196.91s/it]Evaluating commonsenseqa :  22%|██▏       | 22/100 [1:21:50<4:52:53, 225.30s/it]Evaluating commonsenseqa :  20%|██        | 20/100 [1:22:02<5:33:54, 250.43s/it]Evaluating commonsenseqa :  25%|██▌       | 25/100 [1:21:01<4:07:39, 198.13s/it]Evaluating commonsenseqa :  23%|██▎       | 23/100 [1:25:37<4:49:46, 225.80s/it]Evaluating commonsenseqa :  21%|██        | 21/100 [1:26:17<5:31:37, 251.87s/it]Evaluating commonsenseqa :  26%|██▌       | 26/100 [1:24:22<4:05:26, 199.00s/it]Evaluating commonsenseqa :  24%|██▍       | 24/100 [1:29:19<4:44:45, 224.80s/it]Evaluating commonsenseqa :  27%|██▋       | 27/100 [1:27:40<4:01:40, 198.64s/it]Evaluating commonsenseqa :  22%|██▏       | 22/100 [1:30:37<5:30:43, 254.40s/it]Evaluating commonsenseqa :  25%|██▌       | 25/100 [1:33:07<4:42:00, 225.61s/it]Evaluating commonsenseqa :  28%|██▊       | 28/100 [1:30:56<3:57:26, 197.87s/it]Evaluating commonsenseqa :  23%|██▎       | 23/100 [1:34:45<5:24:05, 252.53s/it]Evaluating commonsenseqa :  26%|██▌       | 26/100 [1:36:51<4:37:52, 225.30s/it]Evaluating commonsenseqa :  29%|██▉       | 29/100 [1:34:14<3:54:12, 197.93s/it]Evaluating commonsenseqa :  24%|██▍       | 24/100 [1:39:00<5:20:47, 253.26s/it]Evaluating commonsenseqa :  30%|███       | 30/100 [1:37:34<3:51:36, 198.52s/it]Evaluating commonsenseqa :  27%|██▋       | 27/100 [1:40:41<4:35:51, 226.73s/it]Evaluating commonsenseqa :  25%|██▌       | 25/100 [1:43:12<5:15:50, 252.67s/it]Evaluating commonsenseqa :  31%|███       | 31/100 [1:40:53<3:48:28, 198.68s/it]Evaluating commonsenseqa :  28%|██▊       | 28/100 [1:44:32<4:33:35, 227.99s/it]Evaluating commonsenseqa :  32%|███▏      | 32/100 [1:44:14<3:46:08, 199.53s/it]Evaluating commonsenseqa :  26%|██▌       | 26/100 [1:47:17<5:08:54, 250.47s/it]Evaluating commonsenseqa :  29%|██▉       | 29/100 [1:48:23<4:30:48, 228.86s/it]Evaluating commonsenseqa :  33%|███▎      | 33/100 [1:46:56<3:29:57, 188.02s/it]Evaluating commonsenseqa :  27%|██▋       | 27/100 [1:51:28<5:04:50, 250.56s/it]Evaluating commonsenseqa :  30%|███       | 30/100 [1:52:09<4:25:56, 227.95s/it]Evaluating commonsenseqa :  34%|███▍      | 34/100 [1:50:14<3:30:12, 191.10s/it]Evaluating commonsenseqa :  28%|██▊       | 28/100 [1:55:43<5:02:16, 251.90s/it]Evaluating commonsenseqa :  31%|███       | 31/100 [1:55:50<4:19:45, 225.88s/it]Evaluating commonsenseqa :  35%|███▌      | 35/100 [1:53:34<3:30:05, 193.93s/it]Evaluating commonsenseqa :  32%|███▏      | 32/100 [1:59:36<4:15:53, 225.79s/it]Evaluating commonsenseqa :  36%|███▌      | 36/100 [1:56:51<3:27:37, 194.64s/it]Evaluating commonsenseqa :  29%|██▉       | 29/100 [1:59:49<4:56:11, 250.30s/it]Evaluating commonsenseqa :  37%|███▋      | 37/100 [2:00:08<3:25:03, 195.30s/it]Evaluating commonsenseqa :  33%|███▎      | 33/100 [2:03:24<4:13:07, 226.68s/it]Evaluating commonsenseqa :  30%|███       | 30/100 [2:04:03<4:53:03, 251.20s/it]Evaluating commonsenseqa :  38%|███▊      | 38/100 [2:03:26<3:22:45, 196.22s/it]Evaluating commonsenseqa :  34%|███▍      | 34/100 [2:07:12<4:09:30, 226.83s/it]Evaluating commonsenseqa :  31%|███       | 31/100 [2:08:12<4:48:21, 250.74s/it]Evaluating commonsenseqa :  39%|███▉      | 39/100 [2:06:40<3:18:54, 195.65s/it]Evaluating commonsenseqa :  35%|███▌      | 35/100 [2:10:58<4:05:31, 226.63s/it]Evaluating commonsenseqa :  32%|███▏      | 32/100 [2:12:26<4:45:06, 251.57s/it]Evaluating commonsenseqa :  40%|████      | 40/100 [2:09:57<3:15:53, 195.89s/it]Evaluating commonsenseqa :  36%|███▌      | 36/100 [2:14:46<4:02:22, 227.23s/it]Evaluating commonsenseqa :  41%|████      | 41/100 [2:13:16<3:13:45, 197.04s/it]Evaluating commonsenseqa :  33%|███▎      | 33/100 [2:16:41<4:42:10, 252.69s/it]Evaluating commonsenseqa :  37%|███▋      | 37/100 [2:18:34<3:58:52, 227.50s/it]Evaluating commonsenseqa :  42%|████▏     | 42/100 [2:16:35<3:10:54, 197.48s/it]Evaluating commonsenseqa :  34%|███▍      | 34/100 [2:20:54<4:37:58, 252.70s/it]Evaluating commonsenseqa :  38%|███▊      | 38/100 [2:22:18<3:53:43, 226.19s/it]Evaluating commonsenseqa :  43%|████▎     | 43/100 [2:19:51<3:07:11, 197.05s/it]Evaluating commonsenseqa :  35%|███▌      | 35/100 [2:25:08<4:34:13, 253.13s/it]Evaluating commonsenseqa :  39%|███▉      | 39/100 [2:26:05<3:50:14, 226.47s/it]Evaluating commonsenseqa :  44%|████▍     | 44/100 [2:23:12<3:05:07, 198.34s/it]Evaluating commonsenseqa :  45%|████▌     | 45/100 [2:26:28<3:01:02, 197.49s/it]Evaluating commonsenseqa :  36%|███▌      | 36/100 [2:29:23<4:30:41, 253.77s/it]Evaluating commonsenseqa :  40%|████      | 40/100 [2:29:53<3:47:04, 227.07s/it]Evaluating commonsenseqa :  46%|████▌     | 46/100 [2:29:46<2:57:58, 197.74s/it]Evaluating commonsenseqa :  37%|███▋      | 37/100 [2:33:34<4:25:36, 252.96s/it]Evaluating commonsenseqa :  41%|████      | 41/100 [2:33:36<3:41:56, 225.71s/it]Evaluating commonsenseqa :  47%|████▋     | 47/100 [2:33:09<2:56:08, 199.40s/it]Evaluating commonsenseqa :  42%|████▏     | 42/100 [2:37:22<3:38:28, 226.00s/it]Evaluating commonsenseqa :  38%|███▊      | 38/100 [2:37:46<4:21:00, 252.59s/it]Evaluating commonsenseqa :  48%|████▊     | 48/100 [2:36:32<2:53:34, 200.27s/it]Evaluating commonsenseqa :  43%|████▎     | 43/100 [2:40:21<3:21:11, 211.78s/it]Evaluating commonsenseqa :  39%|███▉      | 39/100 [2:41:55<4:15:42, 251.51s/it]Evaluating commonsenseqa :  49%|████▉     | 49/100 [2:39:47<2:48:53, 198.70s/it]Evaluating commonsenseqa :  44%|████▍     | 44/100 [2:44:07<3:21:45, 216.17s/it]Evaluating commonsenseqa :  50%|█████     | 50/100 [2:43:04<2:45:05, 198.11s/it]Evaluating commonsenseqa :  40%|████      | 40/100 [2:46:09<4:12:17, 252.29s/it]Evaluating commonsenseqa :  45%|████▌     | 45/100 [2:47:49<3:19:32, 217.69s/it]Evaluating commonsenseqa :  51%|█████     | 51/100 [2:46:26<2:42:57, 199.53s/it]Evaluating commonsenseqa :  41%|████      | 41/100 [2:50:22<4:08:11, 252.39s/it]Evaluating commonsenseqa :  46%|████▌     | 46/100 [2:51:31<3:17:07, 219.02s/it]Evaluating commonsenseqa :  52%|█████▏    | 52/100 [2:49:45<2:39:27, 199.33s/it]Evaluating commonsenseqa :  42%|████▏     | 42/100 [2:54:40<4:05:36, 254.07s/it]Evaluating commonsenseqa :  47%|████▋     | 47/100 [2:55:17<3:15:25, 221.24s/it]Evaluating commonsenseqa :  53%|█████▎    | 53/100 [2:53:04<2:36:04, 199.25s/it]Evaluating commonsenseqa :  43%|████▎     | 43/100 [2:58:53<4:01:05, 253.79s/it]Evaluating commonsenseqa :  48%|████▊     | 48/100 [2:59:08<3:14:12, 224.09s/it]Evaluating commonsenseqa :  54%|█████▍    | 54/100 [2:56:23<2:32:41, 199.16s/it]Evaluating commonsenseqa :  55%|█████▌    | 55/100 [2:59:42<2:29:17, 199.06s/it]Evaluating commonsenseqa :  49%|████▉     | 49/100 [3:02:54<3:10:57, 224.66s/it]Evaluating commonsenseqa :  44%|████▍     | 44/100 [3:03:04<3:56:01, 252.89s/it]Evaluating commonsenseqa :  56%|█████▌    | 56/100 [3:03:02<2:26:16, 199.47s/it]Evaluating commonsenseqa :  50%|█████     | 50/100 [3:06:39<3:07:19, 224.79s/it]Evaluating commonsenseqa :  45%|████▌     | 45/100 [3:07:15<3:51:24, 252.44s/it]Evaluating commonsenseqa :  57%|█████▋    | 57/100 [3:06:17<2:21:53, 197.99s/it]Evaluating commonsenseqa :  51%|█████     | 51/100 [3:10:10<3:00:06, 220.54s/it]Evaluating commonsenseqa :  46%|████▌     | 46/100 [3:11:27<3:47:06, 252.34s/it]Evaluating commonsenseqa :  58%|█████▊    | 58/100 [3:09:39<2:19:21, 199.08s/it]Evaluating commonsenseqa :  52%|█████▏    | 52/100 [3:13:57<2:57:57, 222.45s/it]Evaluating commonsenseqa :  47%|████▋     | 47/100 [3:15:39<3:42:46, 252.20s/it]Evaluating commonsenseqa :  59%|█████▉    | 59/100 [3:12:59<2:16:20, 199.52s/it]Evaluating commonsenseqa :  53%|█████▎    | 53/100 [3:17:38<2:54:05, 222.24s/it]Evaluating commonsenseqa :  60%|██████    | 60/100 [3:15:16<2:00:27, 180.69s/it]Evaluating commonsenseqa :  48%|████▊     | 48/100 [3:19:55<3:39:27, 253.23s/it]Evaluating commonsenseqa :  54%|█████▍    | 54/100 [3:21:27<2:51:55, 224.25s/it]Evaluating commonsenseqa :  61%|██████    | 61/100 [3:18:32<2:00:29, 185.38s/it]Evaluating commonsenseqa :  49%|████▉     | 49/100 [3:24:10<3:35:42, 253.77s/it]Evaluating commonsenseqa :  62%|██████▏   | 62/100 [3:21:51<1:59:52, 189.27s/it]Evaluating commonsenseqa :  55%|█████▌    | 55/100 [3:25:18<2:49:45, 226.35s/it]Evaluating commonsenseqa :  63%|██████▎   | 63/100 [3:25:06<1:57:53, 191.19s/it]Evaluating commonsenseqa :  50%|█████     | 50/100 [3:28:20<3:30:39, 252.79s/it]Evaluating commonsenseqa :  56%|█████▌    | 56/100 [3:29:07<2:46:22, 226.87s/it]Evaluating commonsenseqa :  64%|██████▍   | 64/100 [3:28:23<1:55:43, 192.86s/it]Evaluating commonsenseqa :  51%|█████     | 51/100 [3:31:59<3:17:59, 242.44s/it]Evaluating commonsenseqa :  57%|█████▋    | 57/100 [3:32:52<2:42:19, 226.49s/it]Evaluating commonsenseqa :  65%|██████▌   | 65/100 [3:31:37<1:52:37, 193.06s/it]Evaluating commonsenseqa :  52%|█████▏    | 52/100 [3:36:09<3:15:57, 244.95s/it]Evaluating commonsenseqa :  58%|█████▊    | 58/100 [3:36:40<2:38:51, 226.94s/it]Evaluating commonsenseqa :  66%|██████▌   | 66/100 [3:34:52<1:49:47, 193.74s/it]Evaluating commonsenseqa :  53%|█████▎    | 53/100 [3:40:27<3:14:50, 248.73s/it]Evaluating commonsenseqa :  59%|█████▉    | 59/100 [3:40:29<2:35:27, 227.49s/it]Evaluating commonsenseqa :  67%|██████▋   | 67/100 [3:38:09<1:47:09, 194.84s/it]Evaluating commonsenseqa :  60%|██████    | 60/100 [3:44:14<2:31:11, 226.79s/it]Evaluating commonsenseqa :  68%|██████▊   | 68/100 [3:41:26<1:44:11, 195.37s/it]Evaluating commonsenseqa :  54%|█████▍    | 54/100 [3:44:39<3:11:27, 249.73s/it]Evaluating commonsenseqa :  69%|██████▉   | 69/100 [3:44:43<1:41:15, 195.99s/it]Evaluating commonsenseqa :  61%|██████    | 61/100 [3:48:06<2:28:26, 228.38s/it]Evaluating commonsenseqa :  55%|█████▌    | 55/100 [3:48:54<3:08:27, 251.27s/it]Evaluating commonsenseqa :  70%|███████   | 70/100 [3:47:59<1:37:56, 195.89s/it]Evaluating commonsenseqa :  62%|██████▏   | 62/100 [3:51:54<2:24:36, 228.33s/it]Evaluating commonsenseqa :  56%|█████▌    | 56/100 [3:53:08<3:04:51, 252.08s/it]Evaluating commonsenseqa :  71%|███████   | 71/100 [3:51:16<1:34:51, 196.26s/it]Evaluating commonsenseqa :  63%|██████▎   | 63/100 [3:55:47<2:21:40, 229.74s/it]Evaluating commonsenseqa :  57%|█████▋    | 57/100 [3:57:20<3:00:42, 252.14s/it]Evaluating commonsenseqa :  72%|███████▏  | 72/100 [3:54:36<1:32:09, 197.47s/it]Evaluating commonsenseqa :  64%|██████▍   | 64/100 [3:59:29<2:16:18, 227.18s/it]Evaluating commonsenseqa :  73%|███████▎  | 73/100 [3:57:58<1:29:28, 198.84s/it]Evaluating commonsenseqa :  58%|█████▊    | 58/100 [4:01:31<2:56:09, 251.66s/it]Evaluating commonsenseqa :  65%|██████▌   | 65/100 [4:03:10<2:11:30, 225.43s/it]Evaluating commonsenseqa :  74%|███████▍  | 74/100 [4:01:16<1:25:57, 198.38s/it]Evaluating commonsenseqa :  59%|█████▉    | 59/100 [4:05:40<2:51:30, 250.99s/it]Evaluating commonsenseqa :  66%|██████▌   | 66/100 [4:07:03<2:09:01, 227.70s/it]Evaluating commonsenseqa :  75%|███████▌  | 75/100 [4:04:35<1:22:48, 198.73s/it]Evaluating commonsenseqa :  60%|██████    | 60/100 [4:09:49<2:46:53, 250.34s/it]Evaluating commonsenseqa :  76%|███████▌  | 76/100 [4:07:52<1:19:16, 198.17s/it]Evaluating commonsenseqa :  67%|██████▋   | 67/100 [4:10:50<2:05:03, 227.37s/it]Evaluating commonsenseqa :  61%|██████    | 61/100 [4:14:02<2:43:14, 251.14s/it]Evaluating commonsenseqa :  77%|███████▋  | 77/100 [4:11:11<1:16:03, 198.40s/it]Evaluating commonsenseqa :  68%|██████▊   | 68/100 [4:14:33<2:00:33, 226.04s/it]Evaluating commonsenseqa :  78%|███████▊  | 78/100 [4:14:35<1:13:20, 200.04s/it]Evaluating commonsenseqa :  69%|██████▉   | 69/100 [4:18:16<1:56:19, 225.13s/it]Evaluating commonsenseqa :  62%|██████▏   | 62/100 [4:18:19<2:40:11, 252.93s/it]Evaluating commonsenseqa :  79%|███████▉  | 79/100 [4:17:55<1:09:58, 199.95s/it]Evaluating commonsenseqa :  70%|███████   | 70/100 [4:22:08<1:53:39, 227.31s/it]Evaluating commonsenseqa :  63%|██████▎   | 63/100 [4:22:31<2:35:47, 252.62s/it]Evaluating commonsenseqa :  80%|████████  | 80/100 [4:21:14<1:06:35, 199.76s/it]Evaluating commonsenseqa :  71%|███████   | 71/100 [4:25:54<1:49:39, 226.88s/it]Evaluating commonsenseqa :  64%|██████▍   | 64/100 [4:26:45<2:31:51, 253.10s/it]Evaluating commonsenseqa :  81%|████████  | 81/100 [4:24:36<1:03:25, 200.31s/it]Evaluating commonsenseqa :  72%|███████▏  | 72/100 [4:29:45<1:46:25, 228.06s/it]Evaluating commonsenseqa :  82%|████████▏ | 82/100 [4:27:56<1:00:04, 200.27s/it]Evaluating commonsenseqa :  65%|██████▌   | 65/100 [4:30:55<2:27:02, 252.08s/it]Evaluating commonsenseqa :  73%|███████▎  | 73/100 [4:33:32<1:42:29, 227.74s/it]Evaluating commonsenseqa :  83%|████████▎ | 83/100 [4:31:15<56:37, 199.87s/it]  Evaluating commonsenseqa :  66%|██████▌   | 66/100 [4:35:04<2:22:24, 251.32s/it]Evaluating commonsenseqa :  74%|███████▍  | 74/100 [4:37:09<1:37:21, 224.67s/it]Evaluating commonsenseqa :  84%|████████▍ | 84/100 [4:34:35<53:20, 200.03s/it]Evaluating commonsenseqa :  67%|██████▋   | 67/100 [4:39:14<2:18:00, 250.91s/it]Evaluating commonsenseqa :  85%|████████▌ | 85/100 [4:37:53<49:51, 199.45s/it]Evaluating commonsenseqa :  75%|███████▌  | 75/100 [4:40:57<1:33:58, 225.54s/it]Evaluating commonsenseqa :  86%|████████▌ | 86/100 [4:40:18<42:41, 182.99s/it]Evaluating commonsenseqa :  68%|██████▊   | 68/100 [4:43:27<2:14:07, 251.50s/it]Evaluating commonsenseqa :  76%|███████▌  | 76/100 [4:44:42<1:30:11, 225.50s/it]Evaluating commonsenseqa :  87%|████████▋ | 87/100 [4:43:38<40:44, 188.07s/it]Evaluating commonsenseqa :  69%|██████▉   | 69/100 [4:47:39<2:09:59, 251.61s/it]Evaluating commonsenseqa :  77%|███████▋  | 77/100 [4:48:29<1:26:38, 226.02s/it]Evaluating commonsenseqa :  88%|████████▊ | 88/100 [4:46:58<38:20, 191.74s/it]Evaluating commonsenseqa :  70%|███████   | 70/100 [4:51:01<1:58:24, 236.81s/it]Evaluating commonsenseqa :  78%|███████▊  | 78/100 [4:52:19<1:23:15, 227.07s/it]Evaluating commonsenseqa :  89%|████████▉ | 89/100 [4:50:14<35:23, 193.07s/it]Evaluating commonsenseqa :  71%|███████   | 71/100 [4:55:14<1:56:44, 241.52s/it]Evaluating commonsenseqa :  79%|███████▉  | 79/100 [4:56:06<1:19:31, 227.20s/it]Evaluating commonsenseqa :  90%|█████████ | 90/100 [4:53:31<32:20, 194.06s/it]Evaluating commonsenseqa :  72%|███████▏  | 72/100 [4:59:27<1:54:20, 245.04s/it]Evaluating commonsenseqa :  91%|█████████ | 91/100 [4:56:50<29:22, 195.78s/it]Evaluating commonsenseqa :  80%|████████  | 80/100 [4:59:55<1:15:50, 227.52s/it]Evaluating commonsenseqa :  92%|█████████▏| 92/100 [5:00:09<26:12, 196.61s/it]Evaluating commonsenseqa :  73%|███████▎  | 73/100 [5:03:32<1:50:18, 245.13s/it]Evaluating commonsenseqa :  81%|████████  | 81/100 [5:03:42<1:12:02, 227.52s/it]Evaluating commonsenseqa :  93%|█████████▎| 93/100 [5:03:32<23:08, 198.40s/it]Evaluating commonsenseqa :  82%|████████▏ | 82/100 [5:07:27<1:08:02, 226.83s/it]Evaluating commonsenseqa :  74%|███████▍  | 74/100 [5:07:44<1:47:06, 247.19s/it]Evaluating commonsenseqa :  94%|█████████▍| 94/100 [5:06:53<19:56, 199.45s/it]Evaluating commonsenseqa :  83%|████████▎ | 83/100 [5:11:11<1:03:59, 225.85s/it]Evaluating commonsenseqa :  75%|███████▌  | 75/100 [5:11:54<1:43:21, 248.06s/it]Evaluating commonsenseqa :  95%|█████████▌| 95/100 [5:10:07<16:28, 197.66s/it]Evaluating commonsenseqa :  84%|████████▍ | 84/100 [5:15:02<1:00:39, 227.49s/it]Evaluating commonsenseqa :  76%|███████▌  | 76/100 [5:16:01<1:39:05, 247.74s/it]Evaluating commonsenseqa :  96%|█████████▌| 96/100 [5:13:27<13:13, 198.38s/it]Evaluating commonsenseqa :  85%|████████▌ | 85/100 [5:18:43<56:24, 225.62s/it]  Evaluating commonsenseqa :  97%|█████████▋| 97/100 [5:16:45<09:54, 198.31s/it]Evaluating commonsenseqa :  77%|███████▋  | 77/100 [5:20:17<1:35:48, 249.95s/it]Evaluating commonsenseqa :  86%|████████▌ | 86/100 [5:22:32<52:50, 226.46s/it]Evaluating commonsenseqa :  98%|█████████▊| 98/100 [5:20:02<06:35, 197.79s/it]Evaluating commonsenseqa :  78%|███████▊  | 78/100 [5:24:26<1:31:35, 249.81s/it]Evaluating commonsenseqa :  87%|████████▋ | 87/100 [5:26:14<48:45, 225.04s/it]Evaluating commonsenseqa :  99%|█████████▉| 99/100 [5:23:20<03:17, 197.80s/it]Evaluating commonsenseqa :  79%|███████▉  | 79/100 [5:28:35<1:27:22, 249.63s/it]Evaluating commonsenseqa : 100%|██████████| 100/100 [5:26:37<00:00, 197.80s/it]Evaluating commonsenseqa : 100%|██████████| 100/100 [5:26:37<00:00, 195.98s/it]
name: commonsenseqa | avg. gen lenth: 265.141 | time: 19599.617725372314s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 12081 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o17-tgsm8k-s30-rFalse --seed 30 --max-prompt-length 4096 --num-out-domain 17 16 17 18 19 20 False 4096 10
[2023-09-01 23:23:29,130] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o17-tgsm8k-s30-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 17
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o17-tgsm8k-s30-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 10
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 531877.67it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.58s/it]
 > number of parameters: 6738415616
[2023-09-01 23:23:41,829] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-01 23:23:42,241] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-01 23:23:42,243] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-01 23:23:42,243] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-01 23:23:42,243] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-01 23:23:42,243] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-01 23:23:42,243] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f27340>
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-01 23:23:42,244] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-01 23:23:42,245] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-01 23:23:42,245] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-01 23:23:42,245] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-01 23:23:42,245] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-01 23:23:42,245] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-01 23:23:42,245] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-01 23:23:42,245] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-01 23:23:42,245] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-01 23:23:42,245] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-01 23:23:42,245] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-01 23:23:42,245] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-01 23:23:42,245] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-01 23:23:42,245] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-01 23:23:42,245] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-01 23:23:42,245] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-01 23:23:42,245] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-01 23:23:42,245] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-01 23:23:42,245] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-01 23:23:42,245] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-01 23:23:42,245] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-01 23:23:42,245] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-01 23:23:42,245] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-01 23:23:42,245] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-01 23:23:42,245] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-01 23:23:42,245] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/100 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: The car-rental agency charges $30/day for a car, or $190 for the first week for a rental that lasts an entire week or longer. Jennie rented a car for 11 days. How much, in dollars, did she pay for the rental?
Output: 310

Input: A hurricane is approaching the southern coast of Texas, and a rancher is planning to move 400 head of cattle 60 miles to higher ground to protect them from possible inland flooding that might occur.  His animal transport truck holds 20 head of cattle.  Traveling at 60 miles per hour, what is the total driving time, in hours, it will take to transport all of his cattle to higher ground?
Output: 40

Input: Jason has a carriage house that he rents out.  He’s charging $50.00 per day or $500.00 for 14 days.  Eric wants to rent the house for 20 days.  How much will it cost him?
Output: 800

Input: Melissa works on a poultry farm. She drives to town twice each month to buy supplies. If it takes her 3 hours to drive to town and back, how many hours does Melissa spend driving in a year?
Output: 72

Input: The ratio of boys to girls in a family is 5:7. The total number of children in the family is 180. If the boys are given $3900 to share, how much money does each boy receive?
Output: 52

Input: Josephine receives a bill from the hospital for 5000$.  50 percent of the bill is for medication.  25 percent of the remaining bill is for overnight stays, and 175$ is for food.  The rest of the bill is for the ambulance ride.  How much did the ambulance ride cost?
Output: 1700

Input: It was time for Kelly to harvest her carrots that she had planted in three different beds.  In the first bed she pulled out 55 carrots.  In the second bed she pulled out 101 carrots and in the third bed she pulled out 78 carrots.  She found that 6 carrots weighed one pound.  How many pounds of carrots did Kelly harvest?
Output: 39

Input: Iris’ family is planning a surprise birthday party for her. The party will include her 3 uncles and 4 aunts who have a son and daughter each as well as her brother and mother. In total, how many people are coming to Iris’ birthday party?
Output: 23

Input: Lyra bought a pair of shoes at a 20% discount.  If she paid $480, how much was the original price of the pair of shoes?
Output: 600

Input: Rhett has been late on two of his monthly rent payments, but his landlord does not charge late fees and so he will be able to pay their total cost with 3/5 of his next month's salary after taxes. If he is currently paid $5000 per month and has to pay 10% tax, calculate his rent expense per month?
Output: 1350

Input: Ten friends decide to get an end-of-year gift for their teacher. They plan to split the cost of the gift equally. But four of the group drop out. The remaining friends split the cost equally among themselves. If each share is now $8 more, how much does the gift cost, in dollars?
Output: 120

Input: At the feline sanctuary, there were 12 lions, 14 tigers, and several cougars.  If there were half as many cougars as lions and tigers combined, then what was the total number of big cats at the feline sanctuary?
Output: 39

Input: A pea patch is twice as big as a radish patch. If one sixth of the pea patch is 5 square feet.  How much is a whole radish patch in square feet?
Output: 15

Input: Phoebe has two pizzas to share with her and three friends. One has pepperoni and the other has cheese. They both have 16 slices. They all eat the same amount. One friend eats only pepperoni, while the rest have an equal number of slices of each. At the end, there is one slice of pepperoni left and 7 slices of cheese, how many slices does each person eat?
Output: 6

Input: Jeremy buys 30 watermelons. He eats 3 watermelons per week. Each week he gives 2 to his dad. How many weeks will the watermelons last?
Output: 6

Input: Jackson has 5 times more money than Williams. Together, they have $150. How much money, in dollars, does Jackson have?
Output: 125

Input: Janet counts 30 crows on the powerlines and 60% more hawks than crows. How many birds does she count total?
Output: 78

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o17-tgsm8k-s30-rFalse-m4096
Evaluating commonsenseqa :  88%|████████▊ | 88/100 [5:30:01<45:07, 225.65s/it]Evaluating commonsenseqa :  80%|████████  | 80/100 [5:32:45<1:23:14, 249.72s/it]Evaluating commonsenseqa :   1%|          | 1/100 [03:19<5:28:26, 199.06s/it]Evaluating commonsenseqa :  89%|████████▉ | 89/100 [5:33:40<41:00, 223.64s/it]Evaluating commonsenseqa :   2%|▏         | 2/100 [06:32<5:19:49, 195.81s/it]Evaluating commonsenseqa :  81%|████████  | 81/100 [5:36:53<1:18:51, 249.01s/it]Evaluating commonsenseqa :  90%|█████████ | 90/100 [5:37:30<37:35, 225.56s/it]Evaluating commonsenseqa :   3%|▎         | 3/100 [09:48<5:16:28, 195.76s/it]Evaluating commonsenseqa :  82%|████████▏ | 82/100 [5:41:05<1:14:59, 249.96s/it]Evaluating commonsenseqa :  91%|█████████ | 91/100 [5:41:17<33:54, 226.01s/it]Evaluating commonsenseqa :   4%|▍         | 4/100 [13:04<5:13:39, 196.03s/it]Evaluating commonsenseqa :  92%|█████████▏| 92/100 [5:45:01<30:03, 225.48s/it]Evaluating commonsenseqa :  83%|████████▎ | 83/100 [5:45:17<1:11:02, 250.73s/it]Evaluating commonsenseqa :   5%|▌         | 5/100 [16:18<5:08:49, 195.05s/it]Evaluating commonsenseqa :  93%|█████████▎| 93/100 [5:48:44<26:14, 224.87s/it]Evaluating commonsenseqa :   6%|▌         | 6/100 [19:34<5:06:30, 195.64s/it]Evaluating commonsenseqa :  84%|████████▍ | 84/100 [5:49:30<1:07:01, 251.36s/it]Evaluating commonsenseqa :  94%|█████████▍| 94/100 [5:52:31<22:31, 225.31s/it]Evaluating commonsenseqa :   7%|▋         | 7/100 [22:52<5:04:21, 196.36s/it]Evaluating commonsenseqa :  85%|████████▌ | 85/100 [5:53:40<1:02:44, 250.96s/it]Evaluating commonsenseqa :   8%|▊         | 8/100 [26:07<5:00:06, 195.73s/it]Evaluating commonsenseqa :  95%|█████████▌| 95/100 [5:56:18<18:49, 225.93s/it]Evaluating commonsenseqa :  86%|████████▌ | 86/100 [5:57:54<58:44, 251.75s/it]  Evaluating commonsenseqa :   9%|▉         | 9/100 [29:23<4:57:00, 195.83s/it]Evaluating commonsenseqa :  96%|█████████▌| 96/100 [6:00:10<15:10, 227.69s/it]Evaluating commonsenseqa :  87%|████████▋ | 87/100 [6:02:11<54:53, 253.33s/it]Evaluating commonsenseqa :  10%|█         | 10/100 [32:37<4:53:09, 195.44s/it]Evaluating commonsenseqa :  97%|█████████▋| 97/100 [6:03:55<11:20, 226.91s/it]Evaluating commonsenseqa :  11%|█         | 11/100 [35:56<4:51:15, 196.36s/it]Evaluating commonsenseqa :  88%|████████▊ | 88/100 [6:06:29<50:58, 254.85s/it]Evaluating commonsenseqa :  98%|█████████▊| 98/100 [6:07:37<07:31, 225.50s/it]Evaluating commonsenseqa :  12%|█▏        | 12/100 [39:12<4:47:48, 196.23s/it]Evaluating commonsenseqa :  89%|████████▉ | 89/100 [6:10:44<46:44, 254.97s/it]Evaluating commonsenseqa :  99%|█████████▉| 99/100 [6:11:23<03:45, 225.46s/it]Evaluating commonsenseqa :  13%|█▎        | 13/100 [42:27<4:44:16, 196.05s/it]Evaluating commonsenseqa :  90%|█████████ | 90/100 [6:14:55<42:16, 253.67s/it]Evaluating commonsenseqa : 100%|██████████| 100/100 [6:15:07<00:00, 225.14s/it]Evaluating commonsenseqa : 100%|██████████| 100/100 [6:15:07<00:00, 225.07s/it]
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 97, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 94, in main
    inference_main(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 96, in inference_main
    f.write(q.replace("\n", "<n>") + "\t\t" + r.replace("\n", "<n>") + "\n")
UnicodeEncodeError: 'ascii' codec can't encode character '\u2019' in position 773: ordinal not in range(128)
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 3346654) of binary: /home/ylu130/.conda/envs/ood/bin/python
Traceback (most recent call last):
  File "/home/ylu130/.conda/envs/ood/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/ylu130/.conda/envs/ood/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/ylu130/.conda/envs/ood/lib/python3.9/site-packages/torch/distributed/run.py", line 794, in main
    run(args)
  File "/home/ylu130/.conda/envs/ood/lib/python3.9/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/home/ylu130/.conda/envs/ood/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/ylu130/.conda/envs/ood/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/ylu130/workspace/in-context-generalization/inference.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-09-02_00:08:59
  host      : icgpu04.cm.cluster
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3346654)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 10955 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o12-tgsm8k-s30-rFalse --seed 30 --max-prompt-length 4096 --num-out-domain 12 11 12 13 14 15 False 4096 10
[2023-09-02 00:09:03,290] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o12-tgsm8k-s30-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 12
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o12-tgsm8k-s30-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 10
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 637330.60it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.74s/it]
 > number of parameters: 6738415616
[2023-09-02 00:09:16,272] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-02 00:09:16,479] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-02 00:09:16,481] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-02 00:09:16,481] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-02 00:09:16,481] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-02 00:09:16,481] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-02 00:09:16,481] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-02 00:09:16,481] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-02 00:09:16,481] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-02 00:09:16,481] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-02 00:09:16,481] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-02 00:09:16,481] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-02 00:09:16,481] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f86460>
[2023-09-02 00:09:16,481] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-02 00:09:16,481] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-02 00:09:16,481] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-02 00:09:16,481] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-02 00:09:16,481] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-02 00:09:16,481] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-02 00:09:16,481] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-02 00:09:16,482] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-02 00:09:16,483] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-02 00:09:16,483] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-02 00:09:16,483] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-02 00:09:16,483] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-02 00:09:16,483] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-02 00:09:16,483] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-02 00:09:16,483] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-02 00:09:16,483] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/100 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: The car-rental agency charges $30/day for a car, or $190 for the first week for a rental that lasts an entire week or longer. Jennie rented a car for 11 days. How much, in dollars, did she pay for the rental?
Output: 310

Input: A hurricane is approaching the southern coast of Texas, and a rancher is planning to move 400 head of cattle 60 miles to higher ground to protect them from possible inland flooding that might occur.  His animal transport truck holds 20 head of cattle.  Traveling at 60 miles per hour, what is the total driving time, in hours, it will take to transport all of his cattle to higher ground?
Output: 40

Input: Jason has a carriage house that he rents out.  He’s charging $50.00 per day or $500.00 for 14 days.  Eric wants to rent the house for 20 days.  How much will it cost him?
Output: 800

Input: Melissa works on a poultry farm. She drives to town twice each month to buy supplies. If it takes her 3 hours to drive to town and back, how many hours does Melissa spend driving in a year?
Output: 72

Input: The ratio of boys to girls in a family is 5:7. The total number of children in the family is 180. If the boys are given $3900 to share, how much money does each boy receive?
Output: 52

Input: Josephine receives a bill from the hospital for 5000$.  50 percent of the bill is for medication.  25 percent of the remaining bill is for overnight stays, and 175$ is for food.  The rest of the bill is for the ambulance ride.  How much did the ambulance ride cost?
Output: 1700

Input: It was time for Kelly to harvest her carrots that she had planted in three different beds.  In the first bed she pulled out 55 carrots.  In the second bed she pulled out 101 carrots and in the third bed she pulled out 78 carrots.  She found that 6 carrots weighed one pound.  How many pounds of carrots did Kelly harvest?
Output: 39

Input: Iris’ family is planning a surprise birthday party for her. The party will include her 3 uncles and 4 aunts who have a son and daughter each as well as her brother and mother. In total, how many people are coming to Iris’ birthday party?
Output: 23

Input: Lyra bought a pair of shoes at a 20% discount.  If she paid $480, how much was the original price of the pair of shoes?
Output: 600

Input: Rhett has been late on two of his monthly rent payments, but his landlord does not charge late fees and so he will be able to pay their total cost with 3/5 of his next month's salary after taxes. If he is currently paid $5000 per month and has to pay 10% tax, calculate his rent expense per month?
Output: 1350

Input: Ten friends decide to get an end-of-year gift for their teacher. They plan to split the cost of the gift equally. But four of the group drop out. The remaining friends split the cost equally among themselves. If each share is now $8 more, how much does the gift cost, in dollars?
Output: 120

Input: At the feline sanctuary, there were 12 lions, 14 tigers, and several cougars.  If there were half as many cougars as lions and tigers combined, then what was the total number of big cats at the feline sanctuary?
Output: 39

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o12-tgsm8k-s30-rFalse-m4096
Evaluating commonsenseqa :  14%|█▍        | 14/100 [45:41<4:39:57, 195.32s/it]Evaluating commonsenseqa :  15%|█▌        | 15/100 [48:53<4:35:27, 194.44s/it]Evaluating commonsenseqa :  91%|█████████ | 91/100 [6:19:08<38:00, 253.42s/it]Evaluating commonsenseqa :   1%|          | 1/100 [03:45<6:11:31, 225.17s/it]Evaluating commonsenseqa :  16%|█▌        | 16/100 [52:09<4:32:49, 194.88s/it]Evaluating commonsenseqa :   2%|▏         | 2/100 [07:25<6:02:42, 222.06s/it]Evaluating commonsenseqa :  92%|█████████▏| 92/100 [6:23:15<33:32, 251.62s/it]Evaluating commonsenseqa :  17%|█▋        | 17/100 [55:27<4:30:52, 195.82s/it]Evaluating commonsenseqa :   3%|▎         | 3/100 [11:01<5:54:31, 219.30s/it]Evaluating commonsenseqa :  93%|█████████▎| 93/100 [6:27:27<29:20, 251.56s/it]Evaluating commonsenseqa :  18%|█▊        | 18/100 [58:39<4:26:04, 194.69s/it]Evaluating commonsenseqa :   4%|▍         | 4/100 [14:38<5:49:57, 218.72s/it]Evaluating commonsenseqa :  94%|█████████▍| 94/100 [6:31:44<25:19, 253.30s/it]Evaluating commonsenseqa :  19%|█▉        | 19/100 [1:01:52<4:22:10, 194.21s/it]Evaluating commonsenseqa :   5%|▌         | 5/100 [18:17<5:46:24, 218.78s/it]Evaluating commonsenseqa :  20%|██        | 20/100 [1:05:06<4:18:48, 194.11s/it]Evaluating commonsenseqa :  95%|█████████▌| 95/100 [6:35:53<21:00, 252.07s/it]Evaluating commonsenseqa :   6%|▌         | 6/100 [22:00<5:44:56, 220.17s/it]Evaluating commonsenseqa :  21%|██        | 21/100 [1:08:18<4:14:36, 193.38s/it]Evaluating commonsenseqa :  96%|█████████▌| 96/100 [6:40:06<16:48, 252.16s/it]Evaluating commonsenseqa :   7%|▋         | 7/100 [25:44<5:43:01, 221.31s/it]Evaluating commonsenseqa :  22%|██▏       | 22/100 [1:11:35<4:12:45, 194.43s/it]Evaluating commonsenseqa :  97%|█████████▋| 97/100 [6:44:19<12:37, 252.61s/it]Evaluating commonsenseqa :  23%|██▎       | 23/100 [1:14:50<4:09:44, 194.60s/it]Evaluating commonsenseqa :   8%|▊         | 8/100 [29:20<5:36:36, 219.53s/it]Evaluating commonsenseqa :  24%|██▍       | 24/100 [1:18:04<4:06:32, 194.63s/it]Evaluating commonsenseqa :  98%|█████████▊| 98/100 [6:48:27<08:22, 251.18s/it]Evaluating commonsenseqa :   9%|▉         | 9/100 [33:02<5:34:16, 220.40s/it]Evaluating commonsenseqa :  25%|██▌       | 25/100 [1:21:19<4:03:10, 194.55s/it]Evaluating commonsenseqa :  99%|█████████▉| 99/100 [6:51:42<03:54, 234.36s/it]Evaluating commonsenseqa :  10%|█         | 10/100 [36:45<5:31:40, 221.12s/it]Evaluating commonsenseqa :  26%|██▌       | 26/100 [1:24:33<3:59:52, 194.49s/it]Evaluating commonsenseqa :  11%|█         | 11/100 [40:23<5:26:52, 220.36s/it]Evaluating commonsenseqa : 100%|██████████| 100/100 [6:55:56<00:00, 240.19s/it]Evaluating commonsenseqa : 100%|██████████| 100/100 [6:55:56<00:00, 249.57s/it]
name: commonsenseqa | avg. gen lenth: 278.184 | time: 24958.020137310028s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 10954 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s30-rFalse --seed 30 --max-prompt-length 4096 --num-out-domain 8 6 7 8 9 10 False 4096 10
[2023-09-02 00:49:57,078] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s30-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 8
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o8-tgsm8k-s30-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 10
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 774696.43it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.53s/it]
 > number of parameters: 6738415616
[2023-09-02 00:50:09,493] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-02 00:50:09,706] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-02 00:50:09,707] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-02 00:50:09,708] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-02 00:50:09,708] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-02 00:50:09,708] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-02 00:50:09,708] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-02 00:50:09,708] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-02 00:50:09,708] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-02 00:50:09,708] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-02 00:50:09,708] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-02 00:50:09,708] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-02 00:50:09,708] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f27340>
[2023-09-02 00:50:09,708] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-02 00:50:09,708] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-02 00:50:09,708] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-02 00:50:09,708] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-02 00:50:09,708] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-02 00:50:09,708] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-02 00:50:09,708] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-02 00:50:09,708] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-02 00:50:09,708] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-02 00:50:09,708] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-02 00:50:09,708] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-02 00:50:09,708] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-02 00:50:09,708] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-02 00:50:09,708] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-02 00:50:09,708] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-02 00:50:09,708] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-02 00:50:09,708] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-02 00:50:09,708] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-02 00:50:09,708] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-02 00:50:09,709] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-02 00:50:09,709] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/100 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: The car-rental agency charges $30/day for a car, or $190 for the first week for a rental that lasts an entire week or longer. Jennie rented a car for 11 days. How much, in dollars, did she pay for the rental?
Output: 310

Input: A hurricane is approaching the southern coast of Texas, and a rancher is planning to move 400 head of cattle 60 miles to higher ground to protect them from possible inland flooding that might occur.  His animal transport truck holds 20 head of cattle.  Traveling at 60 miles per hour, what is the total driving time, in hours, it will take to transport all of his cattle to higher ground?
Output: 40

Input: Jason has a carriage house that he rents out.  He’s charging $50.00 per day or $500.00 for 14 days.  Eric wants to rent the house for 20 days.  How much will it cost him?
Output: 800

Input: Melissa works on a poultry farm. She drives to town twice each month to buy supplies. If it takes her 3 hours to drive to town and back, how many hours does Melissa spend driving in a year?
Output: 72

Input: The ratio of boys to girls in a family is 5:7. The total number of children in the family is 180. If the boys are given $3900 to share, how much money does each boy receive?
Output: 52

Input: Josephine receives a bill from the hospital for 5000$.  50 percent of the bill is for medication.  25 percent of the remaining bill is for overnight stays, and 175$ is for food.  The rest of the bill is for the ambulance ride.  How much did the ambulance ride cost?
Output: 1700

Input: It was time for Kelly to harvest her carrots that she had planted in three different beds.  In the first bed she pulled out 55 carrots.  In the second bed she pulled out 101 carrots and in the third bed she pulled out 78 carrots.  She found that 6 carrots weighed one pound.  How many pounds of carrots did Kelly harvest?
Output: 39

Input: Iris’ family is planning a surprise birthday party for her. The party will include her 3 uncles and 4 aunts who have a son and daughter each as well as her brother and mother. In total, how many people are coming to Iris’ birthday party?
Output: 23

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o8-tgsm8k-s30-rFalse-m4096
Evaluating commonsenseqa :  27%|██▋       | 27/100 [1:27:48<3:56:37, 194.49s/it]Evaluating commonsenseqa :  12%|█▏        | 12/100 [44:05<5:23:54, 220.85s/it]Evaluating commonsenseqa :   1%|          | 1/100 [04:15<7:02:04, 255.81s/it]Evaluating commonsenseqa :  28%|██▊       | 28/100 [1:31:05<3:54:22, 195.32s/it]Evaluating commonsenseqa :  13%|█▎        | 13/100 [47:50<5:22:02, 222.10s/it]Evaluating commonsenseqa :  29%|██▉       | 29/100 [1:34:22<3:51:46, 195.87s/it]Evaluating commonsenseqa :   2%|▏         | 2/100 [08:24<6:51:06, 251.70s/it]Evaluating commonsenseqa :  14%|█▍        | 14/100 [51:31<5:17:37, 221.60s/it]Evaluating commonsenseqa :  30%|███       | 30/100 [1:37:38<3:48:30, 195.87s/it]Evaluating commonsenseqa :   3%|▎         | 3/100 [12:25<6:39:12, 246.94s/it]Evaluating commonsenseqa :  15%|█▌        | 15/100 [55:10<5:12:56, 220.89s/it]Evaluating commonsenseqa :  31%|███       | 31/100 [1:40:54<3:45:28, 196.07s/it]Evaluating commonsenseqa :   4%|▍         | 4/100 [16:30<6:33:40, 246.04s/it]Evaluating commonsenseqa :  32%|███▏      | 32/100 [1:44:08<3:41:20, 195.30s/it]Evaluating commonsenseqa :  16%|█▌        | 16/100 [58:50<5:09:04, 220.77s/it]Evaluating commonsenseqa :   5%|▌         | 5/100 [20:34<6:28:38, 245.45s/it]Evaluating commonsenseqa :  33%|███▎      | 33/100 [1:47:23<3:38:05, 195.31s/it]Evaluating commonsenseqa :  17%|█▋        | 17/100 [1:02:32<5:05:47, 221.06s/it]Evaluating commonsenseqa :  34%|███▍      | 34/100 [1:50:38<3:34:29, 194.99s/it]Evaluating commonsenseqa :   6%|▌         | 6/100 [24:46<6:27:46, 247.51s/it]Evaluating commonsenseqa :  18%|█▊        | 18/100 [1:06:09<5:00:13, 219.68s/it]Evaluating commonsenseqa :  35%|███▌      | 35/100 [1:53:50<3:30:31, 194.33s/it]Evaluating commonsenseqa :   7%|▋         | 7/100 [28:54<6:24:04, 247.79s/it]Evaluating commonsenseqa :  19%|█▉        | 19/100 [1:09:48<4:56:25, 219.57s/it]Evaluating commonsenseqa :  36%|███▌      | 36/100 [1:57:03<3:26:48, 193.88s/it]Evaluating commonsenseqa :  20%|██        | 20/100 [1:13:26<4:52:08, 219.11s/it]Evaluating commonsenseqa :   8%|▊         | 8/100 [33:00<6:18:56, 247.13s/it]Evaluating commonsenseqa :  37%|███▋      | 37/100 [2:00:18<3:23:49, 194.12s/it]Evaluating commonsenseqa :  21%|██        | 21/100 [1:16:58<4:45:53, 217.13s/it]Evaluating commonsenseqa :  38%|███▊      | 38/100 [2:03:32<3:20:45, 194.28s/it]Evaluating commonsenseqa :   9%|▉         | 9/100 [37:10<6:16:06, 247.98s/it]Evaluating commonsenseqa :  22%|██▏       | 22/100 [1:20:37<4:42:59, 217.69s/it]Evaluating commonsenseqa :  39%|███▉      | 39/100 [2:06:44<3:16:34, 193.35s/it]Evaluating commonsenseqa :  10%|█         | 10/100 [41:22<6:14:00, 249.34s/it]Evaluating commonsenseqa :  23%|██▎       | 23/100 [1:24:21<4:41:35, 219.42s/it]Evaluating commonsenseqa :  40%|████      | 40/100 [2:09:58<3:13:43, 193.72s/it]Evaluating commonsenseqa :  11%|█         | 11/100 [45:29<6:08:31, 248.44s/it]Evaluating commonsenseqa :  41%|████      | 41/100 [2:12:58<3:06:31, 189.68s/it]Evaluating commonsenseqa :  24%|██▍       | 24/100 [1:28:04<4:39:22, 220.56s/it]Evaluating commonsenseqa :  12%|█▏        | 12/100 [49:37<6:04:27, 248.49s/it]Evaluating commonsenseqa :  42%|████▏     | 42/100 [2:16:16<3:05:44, 192.15s/it]Evaluating commonsenseqa :  25%|██▌       | 25/100 [1:31:41<4:34:15, 219.40s/it]Evaluating commonsenseqa :  43%|████▎     | 43/100 [2:19:29<3:02:42, 192.33s/it]Evaluating commonsenseqa :  13%|█▎        | 13/100 [53:46<6:00:26, 248.58s/it]Evaluating commonsenseqa :  26%|██▌       | 26/100 [1:35:19<4:30:16, 219.14s/it]Evaluating commonsenseqa :  44%|████▍     | 44/100 [2:22:45<3:00:31, 193.42s/it]Evaluating commonsenseqa :  14%|█▍        | 14/100 [57:52<5:54:55, 247.62s/it]Evaluating commonsenseqa :  27%|██▋       | 27/100 [1:38:54<4:25:02, 217.84s/it]Evaluating commonsenseqa :  45%|████▌     | 45/100 [2:25:59<2:57:29, 193.63s/it]Evaluating commonsenseqa :  28%|██▊       | 28/100 [1:42:32<4:21:21, 217.80s/it]Evaluating commonsenseqa :  15%|█▌        | 15/100 [1:01:57<5:50:02, 247.09s/it]Evaluating commonsenseqa :  46%|████▌     | 46/100 [2:29:17<2:55:29, 194.98s/it]Evaluating commonsenseqa :  29%|██▉       | 29/100 [1:46:08<4:17:05, 217.26s/it]Evaluating commonsenseqa :  47%|████▋     | 47/100 [2:32:31<2:51:53, 194.60s/it]Evaluating commonsenseqa :  16%|█▌        | 16/100 [1:06:04<5:45:56, 247.10s/it]Evaluating commonsenseqa :  30%|███       | 30/100 [1:49:44<4:12:57, 216.82s/it]Evaluating commonsenseqa :  48%|████▊     | 48/100 [2:35:45<2:48:26, 194.35s/it]Evaluating commonsenseqa :  17%|█▋        | 17/100 [1:10:13<5:42:22, 247.50s/it]Evaluating commonsenseqa :  31%|███       | 31/100 [1:53:24<4:10:29, 217.82s/it]Evaluating commonsenseqa :  49%|████▉     | 49/100 [2:39:02<2:45:52, 195.15s/it]Evaluating commonsenseqa :  18%|█▊        | 18/100 [1:14:18<5:37:26, 246.91s/it]Evaluating commonsenseqa :  50%|█████     | 50/100 [2:41:45<2:34:37, 185.54s/it]Evaluating commonsenseqa :  32%|███▏      | 32/100 [1:57:02<4:07:05, 218.02s/it]Evaluating commonsenseqa :  19%|█▉        | 19/100 [1:18:24<5:32:49, 246.54s/it]Evaluating commonsenseqa :  51%|█████     | 51/100 [2:45:00<2:33:57, 188.52s/it]Evaluating commonsenseqa :  33%|███▎      | 33/100 [2:00:43<4:04:15, 218.73s/it]Evaluating commonsenseqa :  52%|█████▏    | 52/100 [2:48:15<2:32:12, 190.27s/it]Evaluating commonsenseqa :  20%|██        | 20/100 [1:22:28<5:27:51, 245.89s/it]Evaluating commonsenseqa :  34%|███▍      | 34/100 [2:04:21<4:00:20, 218.49s/it]Evaluating commonsenseqa :  53%|█████▎    | 53/100 [2:51:31<2:30:23, 191.99s/it]Evaluating commonsenseqa :  21%|██        | 21/100 [1:26:29<5:21:26, 244.14s/it]Evaluating commonsenseqa :  35%|███▌      | 35/100 [2:08:00<3:57:01, 218.79s/it]Evaluating commonsenseqa :  54%|█████▍    | 54/100 [2:54:50<2:28:57, 194.28s/it]Evaluating commonsenseqa :  22%|██▏       | 22/100 [1:30:38<5:19:32, 245.80s/it]Evaluating commonsenseqa :  36%|███▌      | 36/100 [2:11:40<3:53:39, 219.06s/it]Evaluating commonsenseqa :  55%|█████▌    | 55/100 [2:58:07<2:26:10, 194.90s/it]Evaluating commonsenseqa :  37%|███▋      | 37/100 [2:15:16<3:49:05, 218.19s/it]Evaluating commonsenseqa :  56%|█████▌    | 56/100 [3:01:03<2:18:52, 189.38s/it]Evaluating commonsenseqa :  23%|██▎       | 23/100 [1:34:49<5:17:13, 247.18s/it]Evaluating commonsenseqa :  57%|█████▋    | 57/100 [3:04:16<2:16:31, 190.50s/it]Evaluating commonsenseqa :  38%|███▊      | 38/100 [2:18:56<3:46:05, 218.80s/it]Evaluating commonsenseqa :  24%|██▍       | 24/100 [1:38:56<5:13:12, 247.27s/it]Evaluating commonsenseqa :  58%|█████▊    | 58/100 [3:07:31<2:14:09, 191.67s/it]Evaluating commonsenseqa :  39%|███▉      | 39/100 [2:22:30<3:40:58, 217.34s/it]Evaluating commonsenseqa :  25%|██▌       | 25/100 [1:43:00<5:07:53, 246.31s/it]Evaluating commonsenseqa :  59%|█████▉    | 59/100 [3:10:43<2:11:01, 191.73s/it]Evaluating commonsenseqa :  40%|████      | 40/100 [2:26:07<3:37:06, 217.11s/it]Evaluating commonsenseqa :  26%|██▌       | 26/100 [1:46:20<4:46:27, 232.26s/it]Evaluating commonsenseqa :  60%|██████    | 60/100 [3:13:58<2:08:28, 192.72s/it]Evaluating commonsenseqa :  41%|████      | 41/100 [2:29:49<3:34:58, 218.62s/it]Evaluating commonsenseqa :  27%|██▋       | 27/100 [1:50:21<4:45:56, 235.03s/it]Evaluating commonsenseqa :  61%|██████    | 61/100 [3:17:16<2:06:17, 194.29s/it]Evaluating commonsenseqa :  42%|████▏     | 42/100 [2:33:31<3:32:26, 219.76s/it]Evaluating commonsenseqa :  62%|██████▏   | 62/100 [3:20:30<2:02:59, 194.20s/it]Evaluating commonsenseqa :  28%|██▊       | 28/100 [1:54:31<4:47:22, 239.48s/it]Evaluating commonsenseqa :  43%|████▎     | 43/100 [2:37:15<3:29:55, 220.97s/it]Evaluating commonsenseqa :  63%|██████▎   | 63/100 [3:23:46<2:00:07, 194.81s/it]Evaluating commonsenseqa :  29%|██▉       | 29/100 [1:58:31<4:43:30, 239.59s/it]Evaluating commonsenseqa :  44%|████▍     | 44/100 [2:40:52<3:25:11, 219.84s/it]Evaluating commonsenseqa :  64%|██████▍   | 64/100 [3:26:59<1:56:36, 194.34s/it]Evaluating commonsenseqa :  30%|███       | 30/100 [2:02:37<4:41:40, 241.44s/it]Evaluating commonsenseqa :  45%|████▌     | 45/100 [2:44:27<3:20:04, 218.27s/it]Evaluating commonsenseqa :  65%|██████▌   | 65/100 [3:30:12<1:53:04, 193.84s/it]Evaluating commonsenseqa :  31%|███       | 31/100 [2:06:41<4:38:37, 242.28s/it]Evaluating commonsenseqa :  66%|██████▌   | 66/100 [3:33:27<1:50:01, 194.15s/it]Evaluating commonsenseqa :  46%|████▌     | 46/100 [2:48:08<3:17:08, 219.04s/it]Evaluating commonsenseqa :  67%|██████▋   | 67/100 [3:36:41<1:46:52, 194.32s/it]Evaluating commonsenseqa :  32%|███▏      | 32/100 [2:10:43<4:34:25, 242.14s/it]Evaluating commonsenseqa :  47%|████▋     | 47/100 [2:51:43<3:12:32, 217.98s/it]Evaluating commonsenseqa :  68%|██████▊   | 68/100 [3:39:54<1:43:26, 193.95s/it]Evaluating commonsenseqa :  48%|████▊     | 48/100 [2:55:20<3:08:44, 217.77s/it]Evaluating commonsenseqa :  33%|███▎      | 33/100 [2:14:49<4:31:57, 243.54s/it]Evaluating commonsenseqa :  69%|██████▉   | 69/100 [3:43:13<1:40:59, 195.46s/it]Evaluating commonsenseqa :  49%|████▉     | 49/100 [2:58:59<3:05:16, 217.96s/it]Evaluating commonsenseqa :  34%|███▍      | 34/100 [2:18:55<4:28:24, 244.01s/it]Evaluating commonsenseqa :  70%|███████   | 70/100 [3:46:30<1:37:51, 195.70s/it]Evaluating commonsenseqa :  50%|█████     | 50/100 [3:02:26<2:58:53, 214.66s/it]Evaluating commonsenseqa :  35%|███▌      | 35/100 [2:23:05<4:26:22, 245.88s/it]Evaluating commonsenseqa :  71%|███████   | 71/100 [3:49:44<1:34:19, 195.16s/it]Evaluating commonsenseqa :  51%|█████     | 51/100 [3:06:07<2:56:57, 216.69s/it]Evaluating commonsenseqa :  72%|███████▏  | 72/100 [3:53:01<1:31:25, 195.92s/it]Evaluating commonsenseqa :  36%|███▌      | 36/100 [2:27:16<4:24:03, 247.56s/it]Evaluating commonsenseqa :  52%|█████▏    | 52/100 [3:09:49<2:54:38, 218.30s/it]Evaluating commonsenseqa :  73%|███████▎  | 73/100 [3:56:17<1:28:09, 195.90s/it]Evaluating commonsenseqa :  37%|███▋      | 37/100 [2:31:23<4:19:33, 247.19s/it]Evaluating commonsenseqa :  74%|███████▍  | 74/100 [3:58:58<1:20:17, 185.30s/it]Evaluating commonsenseqa :  53%|█████▎    | 53/100 [3:13:26<2:50:32, 217.71s/it]Evaluating commonsenseqa :  38%|███▊      | 38/100 [2:35:30<4:15:37, 247.39s/it]Evaluating commonsenseqa :  75%|███████▌  | 75/100 [4:02:13<1:18:25, 188.24s/it]Evaluating commonsenseqa :  54%|█████▍    | 54/100 [3:17:02<2:46:30, 217.17s/it]Evaluating commonsenseqa :  76%|███████▌  | 76/100 [4:05:29<1:16:13, 190.57s/it]Evaluating commonsenseqa :  39%|███▉      | 39/100 [2:39:39<4:11:43, 247.59s/it]Evaluating commonsenseqa :  55%|█████▌    | 55/100 [3:20:41<2:43:18, 217.74s/it]Evaluating commonsenseqa :  77%|███████▋  | 77/100 [4:08:44<1:13:34, 191.95s/it]Evaluating commonsenseqa :  56%|█████▌    | 56/100 [3:24:23<2:40:36, 219.01s/it]Evaluating commonsenseqa :  40%|████      | 40/100 [2:43:45<4:07:23, 247.39s/it]Evaluating commonsenseqa :  78%|███████▊  | 78/100 [4:11:57<1:10:31, 192.32s/it]Evaluating commonsenseqa :  57%|█████▋    | 57/100 [3:28:03<2:37:16, 219.46s/it]Evaluating commonsenseqa :  41%|████      | 41/100 [2:47:50<4:02:27, 246.57s/it]Evaluating commonsenseqa :  79%|███████▉  | 79/100 [4:15:10<1:07:20, 192.43s/it]Evaluating commonsenseqa :  58%|█████▊    | 58/100 [3:31:44<2:33:56, 219.92s/it]Evaluating commonsenseqa :  80%|████████  | 80/100 [4:18:20<1:03:57, 191.87s/it]Evaluating commonsenseqa :  42%|████▏     | 42/100 [2:51:59<3:59:03, 247.30s/it]Evaluating commonsenseqa :  59%|█████▉    | 59/100 [3:35:18<2:28:56, 217.96s/it]Evaluating commonsenseqa :  81%|████████  | 81/100 [4:21:34<1:00:55, 192.41s/it]Evaluating commonsenseqa :  43%|████▎     | 43/100 [2:56:02<3:53:40, 245.97s/it]Evaluating commonsenseqa :  60%|██████    | 60/100 [3:39:01<2:26:21, 219.53s/it]Evaluating commonsenseqa :  82%|████████▏ | 82/100 [4:24:49<57:55, 193.08s/it]  Evaluating commonsenseqa :  44%|████▍     | 44/100 [3:00:07<3:49:19, 245.70s/it]Evaluating commonsenseqa :  83%|████████▎ | 83/100 [4:28:01<54:39, 192.90s/it]Evaluating commonsenseqa :  61%|██████    | 61/100 [3:42:38<2:22:15, 218.86s/it]Evaluating commonsenseqa :  45%|████▌     | 45/100 [3:04:14<3:45:29, 245.99s/it]Evaluating commonsenseqa :  84%|████████▍ | 84/100 [4:31:21<51:58, 194.89s/it]Evaluating commonsenseqa :  62%|██████▏   | 62/100 [3:46:19<2:18:55, 219.35s/it]Evaluating commonsenseqa :  85%|████████▌ | 85/100 [4:34:37<48:48, 195.26s/it]Evaluating commonsenseqa :  46%|████▌     | 46/100 [3:08:26<3:43:01, 247.81s/it]Evaluating commonsenseqa :  63%|██████▎   | 63/100 [3:49:57<2:15:04, 219.05s/it]Evaluating commonsenseqa :  86%|████████▌ | 86/100 [4:37:51<45:29, 194.97s/it]Evaluating commonsenseqa :  47%|████▋     | 47/100 [3:12:29<3:37:44, 246.49s/it]Evaluating commonsenseqa :  64%|██████▍   | 64/100 [3:53:42<2:12:27, 220.76s/it]Evaluating commonsenseqa :  87%|████████▋ | 87/100 [4:41:04<42:07, 194.43s/it]Evaluating commonsenseqa :  65%|██████▌   | 65/100 [3:57:22<2:08:37, 220.51s/it]Evaluating commonsenseqa :  48%|████▊     | 48/100 [3:16:34<3:33:05, 245.87s/it]Evaluating commonsenseqa :  88%|████████▊ | 88/100 [4:44:18<38:50, 194.18s/it]Evaluating commonsenseqa :  66%|██████▌   | 66/100 [4:00:59<2:04:30, 219.71s/it]Evaluating commonsenseqa :  49%|████▉     | 49/100 [3:20:38<3:28:30, 245.30s/it]Evaluating commonsenseqa :  89%|████████▉ | 89/100 [4:47:33<35:39, 194.54s/it]Evaluating commonsenseqa :  67%|██████▋   | 67/100 [4:04:38<2:00:37, 219.31s/it]Evaluating commonsenseqa :  90%|█████████ | 90/100 [4:50:43<32:12, 193.21s/it]Evaluating commonsenseqa :  50%|█████     | 50/100 [3:24:42<3:24:06, 244.94s/it]Evaluating commonsenseqa :  68%|██████▊   | 68/100 [4:08:21<1:57:35, 220.49s/it]Evaluating commonsenseqa :  91%|█████████ | 91/100 [4:53:58<29:01, 193.50s/it]Evaluating commonsenseqa :  51%|█████     | 51/100 [3:28:49<3:20:31, 245.54s/it]Evaluating commonsenseqa :  92%|█████████▏| 92/100 [4:57:12<25:49, 193.64s/it]Evaluating commonsenseqa :  69%|██████▉   | 69/100 [4:12:01<1:53:53, 220.42s/it]Evaluating commonsenseqa :  52%|█████▏    | 52/100 [3:32:59<3:17:40, 247.10s/it]Evaluating commonsenseqa :  93%|█████████▎| 93/100 [5:00:26<22:37, 193.88s/it]Evaluating commonsenseqa :  70%|███████   | 70/100 [4:15:41<1:50:02, 220.08s/it]Evaluating commonsenseqa :  53%|█████▎    | 53/100 [3:37:03<3:12:44, 246.06s/it]Evaluating commonsenseqa :  94%|█████████▍| 94/100 [5:03:42<19:27, 194.63s/it]Evaluating commonsenseqa :  71%|███████   | 71/100 [4:19:16<1:45:39, 218.62s/it]Evaluating commonsenseqa :  95%|█████████▌| 95/100 [5:06:55<16:09, 193.94s/it]Evaluating commonsenseqa :  54%|█████▍    | 54/100 [3:41:12<3:09:20, 246.98s/it]Evaluating commonsenseqa :  72%|███████▏  | 72/100 [4:23:00<1:42:47, 220.26s/it]Evaluating commonsenseqa :  96%|█████████▌| 96/100 [5:10:09<12:55, 193.93s/it]Evaluating commonsenseqa :  55%|█████▌    | 55/100 [3:45:18<3:04:56, 246.60s/it]Evaluating commonsenseqa :  73%|███████▎  | 73/100 [4:26:34<1:38:21, 218.56s/it]Evaluating commonsenseqa :  97%|█████████▋| 97/100 [5:13:22<09:41, 193.85s/it]Evaluating commonsenseqa :  74%|███████▍  | 74/100 [4:30:15<1:34:58, 219.16s/it]Evaluating commonsenseqa :  56%|█████▌    | 56/100 [3:49:23<3:00:26, 246.06s/it]Evaluating commonsenseqa :  98%|█████████▊| 98/100 [5:16:36<06:27, 193.71s/it]Evaluating commonsenseqa :  75%|███████▌  | 75/100 [4:33:51<1:30:57, 218.31s/it]Evaluating commonsenseqa :  99%|█████████▉| 99/100 [5:19:51<03:14, 194.25s/it]Evaluating commonsenseqa :  57%|█████▋    | 57/100 [3:53:28<2:56:08, 245.78s/it]Evaluating commonsenseqa :  76%|███████▌  | 76/100 [4:37:31<1:27:27, 218.65s/it]Evaluating commonsenseqa : 100%|██████████| 100/100 [5:23:08<00:00, 194.90s/it]Evaluating commonsenseqa : 100%|██████████| 100/100 [5:23:08<00:00, 193.88s/it]
name: commonsenseqa | avg. gen lenth: 275.991 | time: 19389.938979625702s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 12081 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o18-tgsm8k-s30-rFalse --seed 30 --max-prompt-length 4096 --num-out-domain 18 16 17 18 19 20 False 4096 10
[2023-09-02 04:47:00,489] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o18-tgsm8k-s30-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 18
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o18-tgsm8k-s30-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 10
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 524409.13it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.40s/it]
 > number of parameters: 6738415616
[2023-09-02 04:47:12,768] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-02 04:47:12,974] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-02 04:47:12,975] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f27340>
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-02 04:47:12,976] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-02 04:47:12,977] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-02 04:47:12,977] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/100 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: The car-rental agency charges $30/day for a car, or $190 for the first week for a rental that lasts an entire week or longer. Jennie rented a car for 11 days. How much, in dollars, did she pay for the rental?
Output: 310

Input: A hurricane is approaching the southern coast of Texas, and a rancher is planning to move 400 head of cattle 60 miles to higher ground to protect them from possible inland flooding that might occur.  His animal transport truck holds 20 head of cattle.  Traveling at 60 miles per hour, what is the total driving time, in hours, it will take to transport all of his cattle to higher ground?
Output: 40

Input: Jason has a carriage house that he rents out.  He’s charging $50.00 per day or $500.00 for 14 days.  Eric wants to rent the house for 20 days.  How much will it cost him?
Output: 800

Input: Melissa works on a poultry farm. She drives to town twice each month to buy supplies. If it takes her 3 hours to drive to town and back, how many hours does Melissa spend driving in a year?
Output: 72

Input: The ratio of boys to girls in a family is 5:7. The total number of children in the family is 180. If the boys are given $3900 to share, how much money does each boy receive?
Output: 52

Input: Josephine receives a bill from the hospital for 5000$.  50 percent of the bill is for medication.  25 percent of the remaining bill is for overnight stays, and 175$ is for food.  The rest of the bill is for the ambulance ride.  How much did the ambulance ride cost?
Output: 1700

Input: It was time for Kelly to harvest her carrots that she had planted in three different beds.  In the first bed she pulled out 55 carrots.  In the second bed she pulled out 101 carrots and in the third bed she pulled out 78 carrots.  She found that 6 carrots weighed one pound.  How many pounds of carrots did Kelly harvest?
Output: 39

Input: Iris’ family is planning a surprise birthday party for her. The party will include her 3 uncles and 4 aunts who have a son and daughter each as well as her brother and mother. In total, how many people are coming to Iris’ birthday party?
Output: 23

Input: Lyra bought a pair of shoes at a 20% discount.  If she paid $480, how much was the original price of the pair of shoes?
Output: 600

Input: Rhett has been late on two of his monthly rent payments, but his landlord does not charge late fees and so he will be able to pay their total cost with 3/5 of his next month's salary after taxes. If he is currently paid $5000 per month and has to pay 10% tax, calculate his rent expense per month?
Output: 1350

Input: Ten friends decide to get an end-of-year gift for their teacher. They plan to split the cost of the gift equally. But four of the group drop out. The remaining friends split the cost equally among themselves. If each share is now $8 more, how much does the gift cost, in dollars?
Output: 120

Input: At the feline sanctuary, there were 12 lions, 14 tigers, and several cougars.  If there were half as many cougars as lions and tigers combined, then what was the total number of big cats at the feline sanctuary?
Output: 39

Input: A pea patch is twice as big as a radish patch. If one sixth of the pea patch is 5 square feet.  How much is a whole radish patch in square feet?
Output: 15

Input: Phoebe has two pizzas to share with her and three friends. One has pepperoni and the other has cheese. They both have 16 slices. They all eat the same amount. One friend eats only pepperoni, while the rest have an equal number of slices of each. At the end, there is one slice of pepperoni left and 7 slices of cheese, how many slices does each person eat?
Output: 6

Input: Jeremy buys 30 watermelons. He eats 3 watermelons per week. Each week he gives 2 to his dad. How many weeks will the watermelons last?
Output: 6

Input: Jackson has 5 times more money than Williams. Together, they have $150. How much money, in dollars, does Jackson have?
Output: 125

Input: Janet counts 30 crows on the powerlines and 60% more hawks than crows. How many birds does she count total?
Output: 78

Input: There are 290 liters of oil in 24 cans. If 10 of the cans are holding 8 liters each, how much oil is each of the remaining cans holding?
Output: 15

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o18-tgsm8k-s30-rFalse-m4096
Evaluating commonsenseqa :  58%|█████▊    | 58/100 [3:57:39<2:53:08, 247.35s/it]Evaluating commonsenseqa :   1%|          | 1/100 [02:37<4:19:16, 157.14s/it]Evaluating commonsenseqa :  77%|███████▋  | 77/100 [4:41:10<1:23:52, 218.80s/it]Evaluating commonsenseqa :  59%|█████▉    | 59/100 [4:00:41<2:35:40, 227.81s/it]Evaluating commonsenseqa :   2%|▏         | 2/100 [05:23<4:25:53, 162.79s/it]Evaluating commonsenseqa :  78%|███████▊  | 78/100 [4:44:48<1:20:09, 218.62s/it]Evaluating commonsenseqa :  60%|██████    | 60/100 [4:04:55<2:37:04, 235.60s/it]Evaluating commonsenseqa :   3%|▎         | 3/100 [08:33<4:43:03, 175.08s/it]Evaluating commonsenseqa :  79%|███████▉  | 79/100 [4:48:22<1:16:03, 217.29s/it]Evaluating commonsenseqa :   4%|▍         | 4/100 [11:43<4:49:13, 180.76s/it]Evaluating commonsenseqa :  61%|██████    | 61/100 [4:09:03<2:35:40, 239.49s/it]Evaluating commonsenseqa :  80%|████████  | 80/100 [4:52:01<1:12:35, 217.77s/it]Evaluating commonsenseqa :   5%|▌         | 5/100 [14:53<4:51:40, 184.22s/it]Evaluating commonsenseqa :  62%|██████▏   | 62/100 [4:13:11<2:33:18, 242.07s/it]Evaluating commonsenseqa :  81%|████████  | 81/100 [4:55:37<1:08:49, 217.32s/it]Evaluating commonsenseqa :   6%|▌         | 6/100 [18:06<4:53:23, 187.27s/it]Evaluating commonsenseqa :  63%|██████▎   | 63/100 [4:17:19<2:30:14, 243.63s/it]Evaluating commonsenseqa :   7%|▋         | 7/100 [21:15<4:51:03, 187.78s/it]Evaluating commonsenseqa :  82%|████████▏ | 82/100 [4:59:15<1:05:13, 217.40s/it]Evaluating commonsenseqa :  64%|██████▍   | 64/100 [4:21:27<2:26:59, 244.99s/it]Evaluating commonsenseqa :   8%|▊         | 8/100 [24:29<4:50:48, 189.66s/it]Evaluating commonsenseqa :  83%|████████▎ | 83/100 [5:02:54<1:01:42, 217.78s/it]Evaluating commonsenseqa :   9%|▉         | 9/100 [27:40<4:48:17, 190.08s/it]Evaluating commonsenseqa :  65%|██████▌   | 65/100 [4:25:35<2:23:31, 246.04s/it]Evaluating commonsenseqa :  84%|████████▍ | 84/100 [5:06:36<58:24, 219.05s/it]  Evaluating commonsenseqa :  10%|█         | 10/100 [30:51<4:45:50, 190.56s/it]Evaluating commonsenseqa :  85%|████████▌ | 85/100 [5:10:10<54:23, 217.54s/it]Evaluating commonsenseqa :  66%|██████▌   | 66/100 [4:29:45<2:19:58, 247.01s/it]Evaluating commonsenseqa :  11%|█         | 11/100 [34:00<4:42:00, 190.12s/it]Evaluating commonsenseqa :  86%|████████▌ | 86/100 [5:13:52<51:05, 218.95s/it]Evaluating commonsenseqa :  67%|██████▋   | 67/100 [4:33:48<2:15:10, 245.78s/it]Evaluating commonsenseqa :  12%|█▏        | 12/100 [37:10<4:38:36, 189.96s/it]Evaluating commonsenseqa :  87%|████████▋ | 87/100 [5:17:35<47:43, 220.24s/it]Evaluating commonsenseqa :  13%|█▎        | 13/100 [40:19<4:34:48, 189.52s/it]Evaluating commonsenseqa :  68%|██████▊   | 68/100 [4:37:50<2:10:36, 244.90s/it]Evaluating commonsenseqa :  88%|████████▊ | 88/100 [5:21:15<44:01, 220.16s/it]Evaluating commonsenseqa :  14%|█▍        | 14/100 [43:28<4:31:36, 189.49s/it]Evaluating commonsenseqa :  69%|██████▉   | 69/100 [4:41:56<2:06:38, 245.12s/it]Evaluating commonsenseqa :  15%|█▌        | 15/100 [46:42<4:30:31, 190.96s/it]Evaluating commonsenseqa :  89%|████████▉ | 89/100 [5:24:55<40:22, 220.18s/it]Evaluating commonsenseqa :  70%|███████   | 70/100 [4:46:08<2:03:34, 247.16s/it]Evaluating commonsenseqa :  16%|█▌        | 16/100 [49:54<4:27:38, 191.17s/it]Evaluating commonsenseqa :  90%|█████████ | 90/100 [5:28:34<36:35, 219.55s/it]Evaluating commonsenseqa :  17%|█▋        | 17/100 [53:07<4:25:25, 191.87s/it]Evaluating commonsenseqa :  71%|███████   | 71/100 [4:50:17<1:59:44, 247.76s/it]Evaluating commonsenseqa :  91%|█████████ | 91/100 [5:32:13<32:55, 219.54s/it]Evaluating commonsenseqa :  18%|█▊        | 18/100 [56:17<4:21:13, 191.14s/it]Evaluating commonsenseqa :  72%|███████▏  | 72/100 [4:54:24<1:55:27, 247.41s/it]Evaluating commonsenseqa :  92%|█████████▏| 92/100 [5:35:50<29:09, 218.75s/it]Evaluating commonsenseqa :  19%|█▉        | 19/100 [59:27<4:17:38, 190.85s/it]Evaluating commonsenseqa :  73%|███████▎  | 73/100 [4:58:30<1:51:10, 247.06s/it]Evaluating commonsenseqa :  93%|█████████▎| 93/100 [5:39:33<25:39, 219.97s/it]Evaluating commonsenseqa :  20%|██        | 20/100 [1:02:40<4:15:17, 191.47s/it]Evaluating commonsenseqa :  94%|█████████▍| 94/100 [5:43:10<21:54, 219.01s/it]Evaluating commonsenseqa :  74%|███████▍  | 74/100 [5:02:42<1:47:39, 248.46s/it]Evaluating commonsenseqa :  21%|██        | 21/100 [1:05:48<4:10:53, 190.54s/it]Evaluating commonsenseqa :  95%|█████████▌| 95/100 [5:46:49<18:16, 219.21s/it]Evaluating commonsenseqa :  22%|██▏       | 22/100 [1:09:01<4:08:21, 191.05s/it]Evaluating commonsenseqa :  75%|███████▌  | 75/100 [5:06:50<1:43:34, 248.57s/it]Evaluating commonsenseqa :  23%|██▎       | 23/100 [1:12:14<4:06:05, 191.76s/it]Evaluating commonsenseqa :  96%|█████████▌| 96/100 [5:50:32<14:40, 220.20s/it]Evaluating commonsenseqa :  76%|███████▌  | 76/100 [5:10:57<1:39:09, 247.92s/it]Evaluating commonsenseqa :  24%|██▍       | 24/100 [1:15:24<4:02:18, 191.30s/it]Evaluating commonsenseqa :  97%|█████████▋| 97/100 [5:54:10<10:59, 219.70s/it]Evaluating commonsenseqa :  77%|███████▋  | 77/100 [5:15:04<1:34:57, 247.71s/it]Evaluating commonsenseqa :  25%|██▌       | 25/100 [1:18:33<3:58:18, 190.65s/it]Evaluating commonsenseqa :  98%|█████████▊| 98/100 [5:57:15<06:58, 209.32s/it]Evaluating commonsenseqa :  26%|██▌       | 26/100 [1:21:44<3:55:16, 190.76s/it]Evaluating commonsenseqa :  78%|███████▊  | 78/100 [5:19:11<1:30:43, 247.42s/it]Evaluating commonsenseqa :  99%|█████████▉| 99/100 [6:00:58<03:33, 213.46s/it]Evaluating commonsenseqa :  27%|██▋       | 27/100 [1:24:53<3:51:21, 190.16s/it]Evaluating commonsenseqa :  79%|███████▉  | 79/100 [5:23:14<1:26:08, 246.12s/it]Evaluating commonsenseqa : 100%|██████████| 100/100 [6:04:37<00:00, 215.04s/it]Evaluating commonsenseqa : 100%|██████████| 100/100 [6:04:37<00:00, 218.78s/it]
name: commonsenseqa | avg. gen lenth: 259.117 | time: 21879.346828460693s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 10955 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o13-tgsm8k-s30-rFalse --seed 30 --max-prompt-length 4096 --num-out-domain 13 11 12 13 14 15 False 4096 10
[2023-09-02 06:14:02,102] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o13-tgsm8k-s30-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 13
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o13-tgsm8k-s30-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 10
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 614368.22it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.08s/it]
 > number of parameters: 6738415616
[2023-09-02 06:14:13,693] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-02 06:14:13,902] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-02 06:14:13,903] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-02 06:14:13,904] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-02 06:14:13,904] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-02 06:14:13,904] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-02 06:14:13,904] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-02 06:14:13,904] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-02 06:14:13,904] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-02 06:14:13,904] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-02 06:14:13,904] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-02 06:14:13,904] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-02 06:14:13,904] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554ba3c0310>
[2023-09-02 06:14:13,904] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-02 06:14:13,904] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-02 06:14:13,904] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-02 06:14:13,904] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-02 06:14:13,904] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-02 06:14:13,904] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-02 06:14:13,904] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-02 06:14:13,904] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-02 06:14:13,904] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-02 06:14:13,904] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-02 06:14:13,904] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-02 06:14:13,904] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-02 06:14:13,904] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-02 06:14:13,904] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-02 06:14:13,904] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-02 06:14:13,904] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-02 06:14:13,905] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-02 06:14:13,906] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-02 06:14:13,906] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/100 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: The car-rental agency charges $30/day for a car, or $190 for the first week for a rental that lasts an entire week or longer. Jennie rented a car for 11 days. How much, in dollars, did she pay for the rental?
Output: 310

Input: A hurricane is approaching the southern coast of Texas, and a rancher is planning to move 400 head of cattle 60 miles to higher ground to protect them from possible inland flooding that might occur.  His animal transport truck holds 20 head of cattle.  Traveling at 60 miles per hour, what is the total driving time, in hours, it will take to transport all of his cattle to higher ground?
Output: 40

Input: Jason has a carriage house that he rents out.  He’s charging $50.00 per day or $500.00 for 14 days.  Eric wants to rent the house for 20 days.  How much will it cost him?
Output: 800

Input: Melissa works on a poultry farm. She drives to town twice each month to buy supplies. If it takes her 3 hours to drive to town and back, how many hours does Melissa spend driving in a year?
Output: 72

Input: The ratio of boys to girls in a family is 5:7. The total number of children in the family is 180. If the boys are given $3900 to share, how much money does each boy receive?
Output: 52

Input: Josephine receives a bill from the hospital for 5000$.  50 percent of the bill is for medication.  25 percent of the remaining bill is for overnight stays, and 175$ is for food.  The rest of the bill is for the ambulance ride.  How much did the ambulance ride cost?
Output: 1700

Input: It was time for Kelly to harvest her carrots that she had planted in three different beds.  In the first bed she pulled out 55 carrots.  In the second bed she pulled out 101 carrots and in the third bed she pulled out 78 carrots.  She found that 6 carrots weighed one pound.  How many pounds of carrots did Kelly harvest?
Output: 39

Input: Iris’ family is planning a surprise birthday party for her. The party will include her 3 uncles and 4 aunts who have a son and daughter each as well as her brother and mother. In total, how many people are coming to Iris’ birthday party?
Output: 23

Input: Lyra bought a pair of shoes at a 20% discount.  If she paid $480, how much was the original price of the pair of shoes?
Output: 600

Input: Rhett has been late on two of his monthly rent payments, but his landlord does not charge late fees and so he will be able to pay their total cost with 3/5 of his next month's salary after taxes. If he is currently paid $5000 per month and has to pay 10% tax, calculate his rent expense per month?
Output: 1350

Input: Ten friends decide to get an end-of-year gift for their teacher. They plan to split the cost of the gift equally. But four of the group drop out. The remaining friends split the cost equally among themselves. If each share is now $8 more, how much does the gift cost, in dollars?
Output: 120

Input: At the feline sanctuary, there were 12 lions, 14 tigers, and several cougars.  If there were half as many cougars as lions and tigers combined, then what was the total number of big cats at the feline sanctuary?
Output: 39

Input: A pea patch is twice as big as a radish patch. If one sixth of the pea patch is 5 square feet.  How much is a whole radish patch in square feet?
Output: 15

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o13-tgsm8k-s30-rFalse-m4096
Evaluating commonsenseqa :  28%|██▊       | 28/100 [1:28:06<3:49:14, 191.03s/it]Evaluating commonsenseqa :  80%|████████  | 80/100 [5:27:25<1:22:32, 247.64s/it]Evaluating commonsenseqa :   1%|          | 1/100 [03:41<6:05:37, 221.59s/it]Evaluating commonsenseqa :  29%|██▉       | 29/100 [1:31:15<3:45:21, 190.44s/it]Evaluating commonsenseqa :   2%|▏         | 2/100 [07:17<5:56:19, 218.15s/it]Evaluating commonsenseqa :  30%|███       | 30/100 [1:34:22<3:41:02, 189.46s/it]Evaluating commonsenseqa :  81%|████████  | 81/100 [5:31:30<1:18:07, 246.70s/it]Evaluating commonsenseqa :  31%|███       | 31/100 [1:37:32<3:37:45, 189.35s/it]Evaluating commonsenseqa :   3%|▎         | 3/100 [10:52<5:50:23, 216.74s/it]Evaluating commonsenseqa :  82%|████████▏ | 82/100 [5:35:36<1:13:56, 246.47s/it]Evaluating commonsenseqa :  32%|███▏      | 32/100 [1:40:42<3:34:57, 189.66s/it]Evaluating commonsenseqa :   4%|▍         | 4/100 [14:25<5:44:42, 215.44s/it]Evaluating commonsenseqa :  83%|████████▎ | 83/100 [5:39:41<1:09:44, 246.13s/it]Evaluating commonsenseqa :  33%|███▎      | 33/100 [1:43:56<3:33:10, 190.91s/it]Evaluating commonsenseqa :   5%|▌         | 5/100 [18:01<5:41:24, 215.63s/it]Evaluating commonsenseqa :  84%|████████▍ | 84/100 [5:43:48<1:05:41, 246.36s/it]Evaluating commonsenseqa :  34%|███▍      | 34/100 [1:47:03<3:28:46, 189.79s/it]Evaluating commonsenseqa :   6%|▌         | 6/100 [21:38<5:38:25, 216.01s/it]Evaluating commonsenseqa :  85%|████████▌ | 85/100 [5:47:11<58:22, 233.48s/it]  Evaluating commonsenseqa :  35%|███▌      | 35/100 [1:50:14<3:25:53, 190.06s/it]Evaluating commonsenseqa :   7%|▋         | 7/100 [25:17<5:36:18, 216.97s/it]Evaluating commonsenseqa :  36%|███▌      | 36/100 [1:53:21<3:21:56, 189.33s/it]Evaluating commonsenseqa :  86%|████████▌ | 86/100 [5:51:19<55:26, 237.64s/it]Evaluating commonsenseqa :   8%|▊         | 8/100 [28:50<5:30:39, 215.65s/it]Evaluating commonsenseqa :  37%|███▋      | 37/100 [1:56:29<3:18:20, 188.89s/it]Evaluating commonsenseqa :  87%|████████▋ | 87/100 [5:55:26<52:07, 240.56s/it]Evaluating commonsenseqa :   9%|▉         | 9/100 [32:31<5:29:47, 217.45s/it]Evaluating commonsenseqa :  38%|███▊      | 38/100 [1:59:41<3:16:08, 189.82s/it]Evaluating commonsenseqa :  88%|████████▊ | 88/100 [5:59:35<48:36, 243.05s/it]Evaluating commonsenseqa :  39%|███▉      | 39/100 [2:02:51<3:12:55, 189.77s/it]Evaluating commonsenseqa :  10%|█         | 10/100 [36:08<5:25:38, 217.10s/it]Evaluating commonsenseqa :  40%|████      | 40/100 [2:06:03<3:10:30, 190.50s/it]Evaluating commonsenseqa :  89%|████████▉ | 89/100 [6:03:41<44:43, 243.96s/it]Evaluating commonsenseqa :  11%|█         | 11/100 [39:45<5:22:17, 217.27s/it]Evaluating commonsenseqa :  41%|████      | 41/100 [2:09:09<3:05:56, 189.09s/it]Evaluating commonsenseqa :  12%|█▏        | 12/100 [43:26<5:20:00, 218.19s/it]Evaluating commonsenseqa :  90%|█████████ | 90/100 [6:07:49<40:52, 245.24s/it]Evaluating commonsenseqa :  42%|████▏     | 42/100 [2:12:18<3:02:54, 189.21s/it]Evaluating commonsenseqa :  13%|█▎        | 13/100 [47:04<5:16:42, 218.42s/it]Evaluating commonsenseqa :  91%|█████████ | 91/100 [6:11:59<37:00, 246.72s/it]Evaluating commonsenseqa :  43%|████▎     | 43/100 [2:15:29<3:00:18, 189.80s/it]Evaluating commonsenseqa :  14%|█▍        | 14/100 [50:40<5:11:41, 217.46s/it]Evaluating commonsenseqa :  44%|████▍     | 44/100 [2:18:41<2:57:35, 190.28s/it]Evaluating commonsenseqa :  92%|█████████▏| 92/100 [6:16:05<32:51, 246.47s/it]Evaluating commonsenseqa :  15%|█▌        | 15/100 [54:15<5:07:13, 216.86s/it]Evaluating commonsenseqa :  45%|████▌     | 45/100 [2:21:53<2:54:57, 190.87s/it]Evaluating commonsenseqa :  93%|█████████▎| 93/100 [6:20:11<28:44, 246.39s/it]Evaluating commonsenseqa :  16%|█▌        | 16/100 [57:12<4:46:39, 204.75s/it]Evaluating commonsenseqa :  46%|████▌     | 46/100 [2:25:02<2:51:11, 190.22s/it]Evaluating commonsenseqa :  94%|█████████▍| 94/100 [6:24:23<24:47, 247.99s/it]Evaluating commonsenseqa :  17%|█▋        | 17/100 [1:00:46<4:47:13, 207.63s/it]Evaluating commonsenseqa :  47%|████▋     | 47/100 [2:28:13<2:48:12, 190.42s/it]Evaluating commonsenseqa :  18%|█▊        | 18/100 [1:04:18<4:45:39, 209.02s/it]Evaluating commonsenseqa :  95%|█████████▌| 95/100 [6:28:27<20:34, 246.84s/it]Evaluating commonsenseqa :  48%|████▊     | 48/100 [2:31:25<2:45:32, 191.02s/it]Evaluating commonsenseqa :  49%|████▉     | 49/100 [2:34:34<2:41:49, 190.38s/it]Evaluating commonsenseqa :  19%|█▉        | 19/100 [1:07:49<4:42:37, 209.36s/it]Evaluating commonsenseqa :  96%|█████████▌| 96/100 [6:32:36<16:30, 247.51s/it]Evaluating commonsenseqa :  50%|█████     | 50/100 [2:37:31<2:35:17, 186.35s/it]Evaluating commonsenseqa :  20%|██        | 20/100 [1:11:24<4:41:36, 211.21s/it]Evaluating commonsenseqa :  97%|█████████▋| 97/100 [6:36:45<12:24, 248.01s/it]Evaluating commonsenseqa :  51%|█████     | 51/100 [2:40:38<2:32:23, 186.60s/it]Evaluating commonsenseqa :  21%|██        | 21/100 [1:14:58<4:39:19, 212.15s/it]Evaluating commonsenseqa :  98%|█████████▊| 98/100 [6:40:52<08:15, 247.57s/it]Evaluating commonsenseqa :  52%|█████▏    | 52/100 [2:43:49<2:30:25, 188.03s/it]Evaluating commonsenseqa :  22%|██▏       | 22/100 [1:18:42<4:40:08, 215.49s/it]Evaluating commonsenseqa :  53%|█████▎    | 53/100 [2:47:01<2:28:03, 189.01s/it]Evaluating commonsenseqa :  99%|█████████▉| 99/100 [6:45:02<04:08, 248.42s/it]Evaluating commonsenseqa :  23%|██▎       | 23/100 [1:22:16<4:36:06, 215.14s/it]Evaluating commonsenseqa :  54%|█████▍    | 54/100 [2:50:13<2:25:35, 189.91s/it]Evaluating commonsenseqa : 100%|██████████| 100/100 [6:49:17<00:00, 250.37s/it]Evaluating commonsenseqa : 100%|██████████| 100/100 [6:49:17<00:00, 245.58s/it]
name: commonsenseqa | avg. gen lenth: 264.977 | time: 24559.331560373306s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 10954 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o9-tgsm8k-s30-rFalse --seed 30 --max-prompt-length 4096 --num-out-domain 9 6 7 8 9 10 False 4096 10
[2023-09-02 07:39:33,783] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o9-tgsm8k-s30-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 9
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o9-tgsm8k-s30-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 10
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 746650.50it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.56s/it]
 > number of parameters: 6738415616
[2023-09-02 07:39:46,313] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-02 07:39:46,526] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-02 07:39:46,527] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f27340>
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-02 07:39:46,528] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-02 07:39:46,529] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-02 07:39:46,529] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/100 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: The car-rental agency charges $30/day for a car, or $190 for the first week for a rental that lasts an entire week or longer. Jennie rented a car for 11 days. How much, in dollars, did she pay for the rental?
Output: 310

Input: A hurricane is approaching the southern coast of Texas, and a rancher is planning to move 400 head of cattle 60 miles to higher ground to protect them from possible inland flooding that might occur.  His animal transport truck holds 20 head of cattle.  Traveling at 60 miles per hour, what is the total driving time, in hours, it will take to transport all of his cattle to higher ground?
Output: 40

Input: Jason has a carriage house that he rents out.  He’s charging $50.00 per day or $500.00 for 14 days.  Eric wants to rent the house for 20 days.  How much will it cost him?
Output: 800

Input: Melissa works on a poultry farm. She drives to town twice each month to buy supplies. If it takes her 3 hours to drive to town and back, how many hours does Melissa spend driving in a year?
Output: 72

Input: The ratio of boys to girls in a family is 5:7. The total number of children in the family is 180. If the boys are given $3900 to share, how much money does each boy receive?
Output: 52

Input: Josephine receives a bill from the hospital for 5000$.  50 percent of the bill is for medication.  25 percent of the remaining bill is for overnight stays, and 175$ is for food.  The rest of the bill is for the ambulance ride.  How much did the ambulance ride cost?
Output: 1700

Input: It was time for Kelly to harvest her carrots that she had planted in three different beds.  In the first bed she pulled out 55 carrots.  In the second bed she pulled out 101 carrots and in the third bed she pulled out 78 carrots.  She found that 6 carrots weighed one pound.  How many pounds of carrots did Kelly harvest?
Output: 39

Input: Iris’ family is planning a surprise birthday party for her. The party will include her 3 uncles and 4 aunts who have a son and daughter each as well as her brother and mother. In total, how many people are coming to Iris’ birthday party?
Output: 23

Input: Lyra bought a pair of shoes at a 20% discount.  If she paid $480, how much was the original price of the pair of shoes?
Output: 600

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o9-tgsm8k-s30-rFalse-m4096
Evaluating commonsenseqa :  24%|██▍       | 24/100 [1:25:48<4:31:17, 214.18s/it]Evaluating commonsenseqa :  55%|█████▌    | 55/100 [2:53:21<2:22:08, 189.53s/it]Evaluating commonsenseqa :  25%|██▌       | 25/100 [1:29:23<4:28:06, 214.49s/it]Evaluating commonsenseqa :  56%|█████▌    | 56/100 [2:56:30<2:18:52, 189.36s/it]Evaluating commonsenseqa :   1%|          | 1/100 [04:10<6:53:04, 250.34s/it]Evaluating commonsenseqa :  57%|█████▋    | 57/100 [2:59:40<2:15:42, 189.36s/it]Evaluating commonsenseqa :  26%|██▌       | 26/100 [1:32:55<4:23:36, 213.73s/it]Evaluating commonsenseqa :   2%|▏         | 2/100 [08:10<6:39:10, 244.40s/it]Evaluating commonsenseqa :  58%|█████▊    | 58/100 [3:02:54<2:13:36, 190.87s/it]Evaluating commonsenseqa :  27%|██▋       | 27/100 [1:36:36<4:22:49, 216.02s/it]Evaluating commonsenseqa :   3%|▎         | 3/100 [12:06<6:28:51, 240.54s/it]Evaluating commonsenseqa :  59%|█████▉    | 59/100 [3:06:04<2:10:08, 190.46s/it]Evaluating commonsenseqa :  28%|██▊       | 28/100 [1:40:09<4:18:00, 215.00s/it]Evaluating commonsenseqa :   4%|▍         | 4/100 [16:09<6:26:30, 241.57s/it]Evaluating commonsenseqa :  60%|██████    | 60/100 [3:09:16<2:07:20, 191.02s/it]Evaluating commonsenseqa :  29%|██▉       | 29/100 [1:43:43<4:14:00, 214.66s/it]Evaluating commonsenseqa :  61%|██████    | 61/100 [3:12:25<2:03:46, 190.43s/it]Evaluating commonsenseqa :   5%|▌         | 5/100 [20:09<6:21:28, 240.93s/it]Evaluating commonsenseqa :  30%|███       | 30/100 [1:47:19<4:10:57, 215.11s/it]Evaluating commonsenseqa :  62%|██████▏   | 62/100 [3:15:35<2:00:30, 190.28s/it]Evaluating commonsenseqa :   6%|▌         | 6/100 [24:14<6:19:31, 242.25s/it]Evaluating commonsenseqa :  31%|███       | 31/100 [1:50:54<4:07:09, 214.93s/it]Evaluating commonsenseqa :  63%|██████▎   | 63/100 [3:18:47<1:57:44, 190.92s/it]Evaluating commonsenseqa :   7%|▋         | 7/100 [28:20<6:17:19, 243.43s/it]Evaluating commonsenseqa :  32%|███▏      | 32/100 [1:54:25<4:02:13, 213.73s/it]Evaluating commonsenseqa :  64%|██████▍   | 64/100 [3:21:59<1:54:42, 191.18s/it]Evaluating commonsenseqa :   8%|▊         | 8/100 [32:16<6:09:40, 241.09s/it]Evaluating commonsenseqa :  33%|███▎      | 33/100 [1:57:56<3:57:46, 212.93s/it]Evaluating commonsenseqa :  65%|██████▌   | 65/100 [3:25:10<1:51:22, 190.93s/it]Evaluating commonsenseqa :  66%|██████▌   | 66/100 [3:28:19<1:47:53, 190.40s/it]Evaluating commonsenseqa :  34%|███▍      | 34/100 [2:01:29<3:54:29, 213.17s/it]Evaluating commonsenseqa :   9%|▉         | 9/100 [36:22<6:07:53, 242.56s/it]Evaluating commonsenseqa :  67%|██████▋   | 67/100 [3:31:28<1:44:32, 190.09s/it]Evaluating commonsenseqa :  35%|███▌      | 35/100 [2:05:02<3:50:49, 213.06s/it]Evaluating commonsenseqa :  10%|█         | 10/100 [40:27<6:05:14, 243.49s/it]Evaluating commonsenseqa :  68%|██████▊   | 68/100 [3:34:36<1:41:04, 189.52s/it]Evaluating commonsenseqa :  36%|███▌      | 36/100 [2:08:37<3:47:49, 213.59s/it]Evaluating commonsenseqa :  11%|█         | 11/100 [44:31<6:01:24, 243.65s/it]Evaluating commonsenseqa :  69%|██████▉   | 69/100 [3:37:51<1:38:39, 190.95s/it]Evaluating commonsenseqa :  37%|███▋      | 37/100 [2:12:15<3:45:46, 215.02s/it]Evaluating commonsenseqa :  70%|███████   | 70/100 [3:40:59<1:35:10, 190.34s/it]Evaluating commonsenseqa :  12%|█▏        | 12/100 [48:33<5:56:23, 242.99s/it]Evaluating commonsenseqa :  38%|███▊      | 38/100 [2:15:49<3:41:40, 214.53s/it]Evaluating commonsenseqa :  71%|███████   | 71/100 [3:44:07<1:31:35, 189.49s/it]Evaluating commonsenseqa :  13%|█▎        | 13/100 [52:37<5:52:57, 243.42s/it]Evaluating commonsenseqa :  39%|███▉      | 39/100 [2:19:21<3:37:17, 213.73s/it]Evaluating commonsenseqa :  72%|███████▏  | 72/100 [3:47:16<1:28:23, 189.41s/it]Evaluating commonsenseqa :  14%|█▍        | 14/100 [56:32<5:45:26, 241.01s/it]Evaluating commonsenseqa :  40%|████      | 40/100 [2:22:58<3:34:42, 214.72s/it]Evaluating commonsenseqa :  73%|███████▎  | 73/100 [3:50:26<1:25:14, 189.43s/it]Evaluating commonsenseqa :  15%|█▌        | 15/100 [1:00:34<5:41:44, 241.23s/it]Evaluating commonsenseqa :  41%|████      | 41/100 [2:26:27<3:29:39, 213.21s/it]Evaluating commonsenseqa :  74%|███████▍  | 74/100 [3:53:33<1:21:49, 188.81s/it]Evaluating commonsenseqa :  75%|███████▌  | 75/100 [3:56:45<1:19:05, 189.82s/it]Evaluating commonsenseqa :  42%|████▏     | 42/100 [2:30:02<3:26:37, 213.75s/it]Evaluating commonsenseqa :  16%|█▌        | 16/100 [1:04:35<5:37:23, 240.99s/it]Evaluating commonsenseqa :  76%|███████▌  | 76/100 [3:59:58<1:16:20, 190.85s/it]Evaluating commonsenseqa :  43%|████▎     | 43/100 [2:33:38<3:23:40, 214.39s/it]Evaluating commonsenseqa :  17%|█▋        | 17/100 [1:08:33<5:32:28, 240.34s/it]Evaluating commonsenseqa :  77%|███████▋  | 77/100 [4:03:07<1:12:55, 190.23s/it]Evaluating commonsenseqa :  44%|████▍     | 44/100 [2:37:15<3:20:46, 215.12s/it]Evaluating commonsenseqa :  18%|█▊        | 18/100 [1:12:16<5:21:10, 235.00s/it]Evaluating commonsenseqa :  78%|███████▊  | 78/100 [4:06:15<1:09:25, 189.35s/it]Evaluating commonsenseqa :  45%|████▌     | 45/100 [2:40:44<3:15:37, 213.41s/it]Evaluating commonsenseqa :  19%|█▉        | 19/100 [1:16:13<5:18:08, 235.67s/it]Evaluating commonsenseqa :  79%|███████▉  | 79/100 [4:09:24<1:06:17, 189.39s/it]Evaluating commonsenseqa :  46%|████▌     | 46/100 [2:44:15<3:11:13, 212.48s/it]Evaluating commonsenseqa :  80%|████████  | 80/100 [4:12:37<1:03:29, 190.46s/it]Evaluating commonsenseqa :  20%|██        | 20/100 [1:20:13<5:15:50, 236.88s/it]Evaluating commonsenseqa :  47%|████▋     | 47/100 [2:47:43<3:06:27, 211.08s/it]Evaluating commonsenseqa :  81%|████████  | 81/100 [4:15:46<1:00:09, 189.95s/it]Evaluating commonsenseqa :  21%|██        | 21/100 [1:24:11<5:12:27, 237.31s/it]Evaluating commonsenseqa :  48%|████▊     | 48/100 [2:51:16<3:03:26, 211.66s/it]Evaluating commonsenseqa :  82%|████████▏ | 82/100 [4:18:57<57:08, 190.47s/it]  Evaluating commonsenseqa :  22%|██▏       | 22/100 [1:28:10<5:09:10, 237.83s/it]Evaluating commonsenseqa :  49%|████▉     | 49/100 [2:54:26<2:54:31, 205.32s/it]Evaluating commonsenseqa :  83%|████████▎ | 83/100 [4:22:06<53:46, 189.82s/it]Evaluating commonsenseqa :  23%|██▎       | 23/100 [1:32:08<5:05:12, 237.83s/it]Evaluating commonsenseqa :  50%|█████     | 50/100 [2:57:58<2:52:51, 207.43s/it]Evaluating commonsenseqa :  84%|████████▍ | 84/100 [4:25:19<50:51, 190.74s/it]Evaluating commonsenseqa :  85%|████████▌ | 85/100 [4:27:58<45:18, 181.23s/it]Evaluating commonsenseqa :  51%|█████     | 51/100 [3:01:31<2:50:46, 209.11s/it]Evaluating commonsenseqa :  24%|██▍       | 24/100 [1:36:07<5:01:34, 238.08s/it]Evaluating commonsenseqa :  86%|████████▌ | 86/100 [4:31:09<42:58, 184.17s/it]Evaluating commonsenseqa :  52%|█████▏    | 52/100 [3:05:07<2:48:45, 210.95s/it]Evaluating commonsenseqa :  25%|██▌       | 25/100 [1:40:09<4:59:04, 239.26s/it]Evaluating commonsenseqa :  87%|████████▋ | 87/100 [4:34:21<40:24, 186.53s/it]Evaluating commonsenseqa :  53%|█████▎    | 53/100 [3:08:43<2:46:31, 212.59s/it]Evaluating commonsenseqa :  26%|██▌       | 26/100 [1:44:08<4:55:03, 239.23s/it]Evaluating commonsenseqa :  88%|████████▊ | 88/100 [4:37:30<37:28, 187.39s/it]Evaluating commonsenseqa :  54%|█████▍    | 54/100 [3:12:12<2:42:13, 211.60s/it]Evaluating commonsenseqa :  27%|██▋       | 27/100 [1:48:05<4:50:07, 238.46s/it]Evaluating commonsenseqa :  89%|████████▉ | 89/100 [4:40:41<34:32, 188.40s/it]Evaluating commonsenseqa :  55%|█████▌    | 55/100 [3:15:48<2:39:29, 212.65s/it]Evaluating commonsenseqa :  90%|█████████ | 90/100 [4:43:53<31:34, 189.44s/it]Evaluating commonsenseqa :  28%|██▊       | 28/100 [1:52:11<4:48:52, 240.73s/it]Evaluating commonsenseqa :  56%|█████▌    | 56/100 [3:19:26<2:37:11, 214.35s/it]Evaluating commonsenseqa :  91%|█████████ | 91/100 [4:47:01<28:20, 188.98s/it]Evaluating commonsenseqa :  29%|██▉       | 29/100 [1:56:09<4:44:10, 240.14s/it]Evaluating commonsenseqa :  57%|█████▋    | 57/100 [3:23:00<2:33:29, 214.17s/it]Evaluating commonsenseqa :  92%|█████████▏| 92/100 [4:50:11<25:14, 189.37s/it]Evaluating commonsenseqa :  30%|███       | 30/100 [2:00:13<4:41:15, 241.07s/it]Evaluating commonsenseqa :  93%|█████████▎| 93/100 [4:53:18<22:01, 188.80s/it]Evaluating commonsenseqa :  58%|█████▊    | 58/100 [3:26:30<2:29:04, 212.96s/it]Evaluating commonsenseqa :  94%|█████████▍| 94/100 [4:56:30<18:58, 189.69s/it]Evaluating commonsenseqa :  31%|███       | 31/100 [2:04:12<4:36:40, 240.59s/it]Evaluating commonsenseqa :  59%|█████▉    | 59/100 [3:30:03<2:25:38, 213.15s/it]Evaluating commonsenseqa :  95%|█████████▌| 95/100 [4:59:41<15:49, 189.98s/it]Evaluating commonsenseqa :  60%|██████    | 60/100 [3:33:41<2:22:58, 214.47s/it]Evaluating commonsenseqa :  32%|███▏      | 32/100 [2:08:13<4:32:37, 240.55s/it]Evaluating commonsenseqa :  96%|█████████▌| 96/100 [5:02:29<12:13, 183.44s/it]Evaluating commonsenseqa :  61%|██████    | 61/100 [3:37:16<2:19:29, 214.61s/it]Evaluating commonsenseqa :  33%|███▎      | 33/100 [2:12:13<4:28:40, 240.60s/it]Evaluating commonsenseqa :  97%|█████████▋| 97/100 [5:05:37<09:14, 184.95s/it]Evaluating commonsenseqa :  62%|██████▏   | 62/100 [3:40:53<2:16:20, 215.28s/it]Evaluating commonsenseqa :  34%|███▍      | 34/100 [2:16:17<4:25:38, 241.50s/it]Evaluating commonsenseqa :  98%|█████████▊| 98/100 [5:08:51<06:14, 187.46s/it]Evaluating commonsenseqa :  63%|██████▎   | 63/100 [3:44:29<2:12:58, 215.63s/it]Evaluating commonsenseqa :  99%|█████████▉| 99/100 [5:11:59<03:07, 187.61s/it]Evaluating commonsenseqa :  35%|███▌      | 35/100 [2:20:20<4:22:01, 241.87s/it]Evaluating commonsenseqa :  64%|██████▍   | 64/100 [3:48:06<2:09:32, 215.91s/it]Evaluating commonsenseqa : 100%|██████████| 100/100 [5:15:10<00:00, 188.64s/it]Evaluating commonsenseqa : 100%|██████████| 100/100 [5:15:10<00:00, 189.10s/it]
name: commonsenseqa | avg. gen lenth: 281.789 | time: 18912.12141561508s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 12081 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o19-tgsm8k-s30-rFalse --seed 30 --max-prompt-length 4096 --num-out-domain 19 16 17 18 19 20 False 4096 10
[2023-09-02 10:02:31,462] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o19-tgsm8k-s30-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 19
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o19-tgsm8k-s30-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 10
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 516402.28it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.55s/it]
 > number of parameters: 6738415616
[2023-09-02 10:02:43,985] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-02 10:02:44,202] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-02 10:02:44,204] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-02 10:02:44,204] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-02 10:02:44,204] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-02 10:02:44,204] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-02 10:02:44,204] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-02 10:02:44,204] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-02 10:02:44,204] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-02 10:02:44,204] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-02 10:02:44,204] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-02 10:02:44,204] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-02 10:02:44,204] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f86460>
[2023-09-02 10:02:44,204] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-02 10:02:44,204] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-02 10:02:44,204] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-02 10:02:44,204] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-02 10:02:44,205] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-02 10:02:44,206] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-02 10:02:44,206] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-02 10:02:44,206] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-02 10:02:44,206] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-02 10:02:44,206] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-02 10:02:44,206] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-02 10:02:44,206] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-02 10:02:44,206] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-02 10:02:44,206] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-02 10:02:44,206] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-02 10:02:44,206] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/100 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: The car-rental agency charges $30/day for a car, or $190 for the first week for a rental that lasts an entire week or longer. Jennie rented a car for 11 days. How much, in dollars, did she pay for the rental?
Output: 310

Input: A hurricane is approaching the southern coast of Texas, and a rancher is planning to move 400 head of cattle 60 miles to higher ground to protect them from possible inland flooding that might occur.  His animal transport truck holds 20 head of cattle.  Traveling at 60 miles per hour, what is the total driving time, in hours, it will take to transport all of his cattle to higher ground?
Output: 40

Input: Jason has a carriage house that he rents out.  He’s charging $50.00 per day or $500.00 for 14 days.  Eric wants to rent the house for 20 days.  How much will it cost him?
Output: 800

Input: Melissa works on a poultry farm. She drives to town twice each month to buy supplies. If it takes her 3 hours to drive to town and back, how many hours does Melissa spend driving in a year?
Output: 72

Input: The ratio of boys to girls in a family is 5:7. The total number of children in the family is 180. If the boys are given $3900 to share, how much money does each boy receive?
Output: 52

Input: Josephine receives a bill from the hospital for 5000$.  50 percent of the bill is for medication.  25 percent of the remaining bill is for overnight stays, and 175$ is for food.  The rest of the bill is for the ambulance ride.  How much did the ambulance ride cost?
Output: 1700

Input: It was time for Kelly to harvest her carrots that she had planted in three different beds.  In the first bed she pulled out 55 carrots.  In the second bed she pulled out 101 carrots and in the third bed she pulled out 78 carrots.  She found that 6 carrots weighed one pound.  How many pounds of carrots did Kelly harvest?
Output: 39

Input: Iris’ family is planning a surprise birthday party for her. The party will include her 3 uncles and 4 aunts who have a son and daughter each as well as her brother and mother. In total, how many people are coming to Iris’ birthday party?
Output: 23

Input: Lyra bought a pair of shoes at a 20% discount.  If she paid $480, how much was the original price of the pair of shoes?
Output: 600

Input: Rhett has been late on two of his monthly rent payments, but his landlord does not charge late fees and so he will be able to pay their total cost with 3/5 of his next month's salary after taxes. If he is currently paid $5000 per month and has to pay 10% tax, calculate his rent expense per month?
Output: 1350

Input: Ten friends decide to get an end-of-year gift for their teacher. They plan to split the cost of the gift equally. But four of the group drop out. The remaining friends split the cost equally among themselves. If each share is now $8 more, how much does the gift cost, in dollars?
Output: 120

Input: At the feline sanctuary, there were 12 lions, 14 tigers, and several cougars.  If there were half as many cougars as lions and tigers combined, then what was the total number of big cats at the feline sanctuary?
Output: 39

Input: A pea patch is twice as big as a radish patch. If one sixth of the pea patch is 5 square feet.  How much is a whole radish patch in square feet?
Output: 15

Input: Phoebe has two pizzas to share with her and three friends. One has pepperoni and the other has cheese. They both have 16 slices. They all eat the same amount. One friend eats only pepperoni, while the rest have an equal number of slices of each. At the end, there is one slice of pepperoni left and 7 slices of cheese, how many slices does each person eat?
Output: 6

Input: Jeremy buys 30 watermelons. He eats 3 watermelons per week. Each week he gives 2 to his dad. How many weeks will the watermelons last?
Output: 6

Input: Jackson has 5 times more money than Williams. Together, they have $150. How much money, in dollars, does Jackson have?
Output: 125

Input: Janet counts 30 crows on the powerlines and 60% more hawks than crows. How many birds does she count total?
Output: 78

Input: There are 290 liters of oil in 24 cans. If 10 of the cans are holding 8 liters each, how much oil is each of the remaining cans holding?
Output: 15

Input: Bill had to finish a project from work that was to take him 4 days. If he took 6 seven-hour naps in the four days, how long did he spend working on the project?
Output: 54

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o19-tgsm8k-s30-rFalse-m4096
Evaluating commonsenseqa :  36%|███▌      | 36/100 [2:24:22<4:18:03, 241.93s/it]Evaluating commonsenseqa :  65%|██████▌   | 65/100 [3:51:37<2:05:12, 214.64s/it]Evaluating commonsenseqa :   1%|          | 1/100 [03:14<5:20:19, 194.13s/it]Evaluating commonsenseqa :  37%|███▋      | 37/100 [2:28:25<4:14:33, 242.43s/it]Evaluating commonsenseqa :   2%|▏         | 2/100 [06:20<5:09:33, 189.53s/it]Evaluating commonsenseqa :  66%|██████▌   | 66/100 [3:55:13<2:01:52, 215.08s/it]Evaluating commonsenseqa :  38%|███▊      | 38/100 [2:32:23<4:08:56, 240.92s/it]Evaluating commonsenseqa :   3%|▎         | 3/100 [09:26<5:03:47, 187.91s/it]Evaluating commonsenseqa :  67%|██████▋   | 67/100 [3:58:15<1:52:49, 205.13s/it]Evaluating commonsenseqa :   4%|▍         | 4/100 [12:32<4:59:29, 187.18s/it]Evaluating commonsenseqa :  68%|██████▊   | 68/100 [4:01:54<1:51:35, 209.24s/it]Evaluating commonsenseqa :  39%|███▉      | 39/100 [2:36:23<4:04:42, 240.70s/it]Evaluating commonsenseqa :   5%|▌         | 5/100 [15:42<4:58:03, 188.24s/it]Evaluating commonsenseqa :  69%|██████▉   | 69/100 [4:05:28<1:48:49, 210.62s/it]Evaluating commonsenseqa :  40%|████      | 40/100 [2:40:25<4:01:06, 241.12s/it]Evaluating commonsenseqa :   6%|▌         | 6/100 [18:50<4:54:39, 188.08s/it]Evaluating commonsenseqa :  70%|███████   | 70/100 [4:09:11<1:47:06, 214.21s/it]Evaluating commonsenseqa :  41%|████      | 41/100 [2:44:25<3:56:41, 240.71s/it]Evaluating commonsenseqa :   7%|▋         | 7/100 [21:57<4:51:07, 187.82s/it]Evaluating commonsenseqa :  71%|███████   | 71/100 [4:12:45<1:43:36, 214.35s/it]Evaluating commonsenseqa :   8%|▊         | 8/100 [25:07<4:48:46, 188.34s/it]Evaluating commonsenseqa :  42%|████▏     | 42/100 [2:48:24<3:52:24, 240.42s/it]Evaluating commonsenseqa :  72%|███████▏  | 72/100 [4:16:20<1:40:08, 214.59s/it]Evaluating commonsenseqa :   9%|▉         | 9/100 [28:14<4:45:25, 188.20s/it]Evaluating commonsenseqa :  43%|████▎     | 43/100 [2:52:25<3:48:33, 240.58s/it]Evaluating commonsenseqa :  10%|█         | 10/100 [31:22<4:41:56, 187.96s/it]Evaluating commonsenseqa :  73%|███████▎  | 73/100 [4:19:55<1:36:34, 214.60s/it]Evaluating commonsenseqa :  44%|████▍     | 44/100 [2:56:25<3:44:19, 240.35s/it]Evaluating commonsenseqa :  11%|█         | 11/100 [34:30<4:38:41, 187.89s/it]Evaluating commonsenseqa :  74%|███████▍  | 74/100 [4:23:30<1:33:04, 214.78s/it]Evaluating commonsenseqa :  45%|████▌     | 45/100 [3:00:26<3:40:30, 240.55s/it]Evaluating commonsenseqa :  12%|█▏        | 12/100 [37:39<4:36:16, 188.36s/it]Evaluating commonsenseqa :  75%|███████▌  | 75/100 [4:27:09<1:30:00, 216.02s/it]Evaluating commonsenseqa :  13%|█▎        | 13/100 [39:59<4:12:01, 173.81s/it]Evaluating commonsenseqa :  46%|████▌     | 46/100 [3:04:26<3:36:09, 240.18s/it]Evaluating commonsenseqa :  76%|███████▌  | 76/100 [4:30:46<1:26:28, 216.20s/it]Evaluating commonsenseqa :  14%|█▍        | 14/100 [43:08<4:15:31, 178.27s/it]Evaluating commonsenseqa :  47%|████▋     | 47/100 [3:08:23<3:31:22, 239.29s/it]Evaluating commonsenseqa :  77%|███████▋  | 77/100 [4:34:19<1:22:33, 215.39s/it]Evaluating commonsenseqa :  15%|█▌        | 15/100 [46:12<4:14:56, 179.96s/it]Evaluating commonsenseqa :  16%|█▌        | 16/100 [49:19<4:14:45, 181.97s/it]Evaluating commonsenseqa :  78%|███████▊  | 78/100 [4:37:58<1:19:18, 216.31s/it]Evaluating commonsenseqa :  48%|████▊     | 48/100 [3:12:26<3:28:23, 240.45s/it]Evaluating commonsenseqa :  17%|█▋        | 17/100 [52:26<4:14:02, 183.65s/it]Evaluating commonsenseqa :  79%|███████▉  | 79/100 [4:41:33<1:15:35, 215.96s/it]Evaluating commonsenseqa :  49%|████▉     | 49/100 [3:16:24<3:23:43, 239.67s/it]Evaluating commonsenseqa :  18%|█▊        | 18/100 [55:31<4:11:21, 183.92s/it]Evaluating commonsenseqa :  80%|████████  | 80/100 [4:45:10<1:12:03, 216.19s/it]Evaluating commonsenseqa :  50%|█████     | 50/100 [3:20:26<3:20:18, 240.37s/it]Evaluating commonsenseqa :  19%|█▉        | 19/100 [58:36<4:08:45, 184.27s/it]Evaluating commonsenseqa :  81%|████████  | 81/100 [4:48:42<1:08:05, 215.00s/it]Evaluating commonsenseqa :  51%|█████     | 51/100 [3:23:30<3:02:34, 223.56s/it]Evaluating commonsenseqa :  20%|██        | 20/100 [1:01:42<4:06:31, 184.90s/it]Evaluating commonsenseqa :  82%|████████▏ | 82/100 [4:52:16<1:04:25, 214.75s/it]Evaluating commonsenseqa :  52%|█████▏    | 52/100 [3:27:29<3:02:26, 228.06s/it]Evaluating commonsenseqa :  21%|██        | 21/100 [1:04:51<4:05:07, 186.18s/it]Evaluating commonsenseqa :  83%|████████▎ | 83/100 [4:55:52<1:00:57, 215.13s/it]Evaluating commonsenseqa :  22%|██▏       | 22/100 [1:08:00<4:03:10, 187.05s/it]Evaluating commonsenseqa :  53%|█████▎    | 53/100 [3:31:23<3:00:13, 230.08s/it]Evaluating commonsenseqa :  84%|████████▍ | 84/100 [4:59:26<57:18, 214.89s/it]  Evaluating commonsenseqa :  23%|██▎       | 23/100 [1:11:06<3:59:40, 186.75s/it]Evaluating commonsenseqa :  54%|█████▍    | 54/100 [3:35:27<2:59:23, 233.99s/it]Evaluating commonsenseqa :  24%|██▍       | 24/100 [1:14:12<3:56:03, 186.37s/it]Evaluating commonsenseqa :  85%|████████▌ | 85/100 [5:03:06<54:06, 216.41s/it]Evaluating commonsenseqa :  55%|█████▌    | 55/100 [3:39:27<2:56:49, 235.78s/it]Evaluating commonsenseqa :  25%|██▌       | 25/100 [1:17:17<3:52:41, 186.15s/it]Evaluating commonsenseqa :  86%|████████▌ | 86/100 [5:06:40<50:18, 215.58s/it]Evaluating commonsenseqa :  26%|██▌       | 26/100 [1:20:24<3:49:33, 186.13s/it]Evaluating commonsenseqa :  56%|█████▌    | 56/100 [3:43:25<2:53:35, 236.72s/it]Evaluating commonsenseqa :  87%|████████▋ | 87/100 [5:10:13<46:32, 214.80s/it]Evaluating commonsenseqa :  27%|██▋       | 27/100 [1:23:26<3:45:06, 185.02s/it]Evaluating commonsenseqa :  57%|█████▋    | 57/100 [3:47:26<2:50:30, 237.91s/it]Evaluating commonsenseqa :  88%|████████▊ | 88/100 [5:13:44<42:45, 213.82s/it]Evaluating commonsenseqa :  28%|██▊       | 28/100 [1:26:38<3:44:32, 187.11s/it]Evaluating commonsenseqa :  58%|█████▊    | 58/100 [3:51:32<2:48:09, 240.22s/it]Evaluating commonsenseqa :  89%|████████▉ | 89/100 [5:17:19<39:15, 214.10s/it]Evaluating commonsenseqa :  29%|██▉       | 29/100 [1:29:47<3:42:03, 187.66s/it]Evaluating commonsenseqa :  90%|█████████ | 90/100 [5:20:57<35:52, 215.20s/it]Evaluating commonsenseqa :  59%|█████▉    | 59/100 [3:55:36<2:44:53, 241.31s/it]Evaluating commonsenseqa :  30%|███       | 30/100 [1:32:54<3:38:44, 187.49s/it]Evaluating commonsenseqa :  31%|███       | 31/100 [1:35:57<3:34:11, 186.25s/it]Evaluating commonsenseqa :  91%|█████████ | 91/100 [5:24:29<32:07, 214.17s/it]Evaluating commonsenseqa :  60%|██████    | 60/100 [3:59:38<2:41:03, 241.58s/it]Evaluating commonsenseqa :  32%|███▏      | 32/100 [1:39:03<3:30:42, 185.93s/it]Evaluating commonsenseqa :  92%|█████████▏| 92/100 [5:28:01<28:27, 213.44s/it]Evaluating commonsenseqa :  61%|██████    | 61/100 [4:03:41<2:37:20, 242.07s/it]Evaluating commonsenseqa :  33%|███▎      | 33/100 [1:42:11<3:28:27, 186.68s/it]Evaluating commonsenseqa :  93%|█████████▎| 93/100 [5:31:33<24:51, 213.06s/it]Evaluating commonsenseqa :  62%|██████▏   | 62/100 [4:07:42<2:33:04, 241.69s/it]Evaluating commonsenseqa :  34%|███▍      | 34/100 [1:45:19<3:25:45, 187.05s/it]Evaluating commonsenseqa :  94%|█████████▍| 94/100 [5:35:04<21:14, 212.45s/it]Evaluating commonsenseqa :  35%|███▌      | 35/100 [1:48:26<3:22:37, 187.05s/it]Evaluating commonsenseqa :  63%|██████▎   | 63/100 [4:11:44<2:29:03, 241.73s/it]Evaluating commonsenseqa :  95%|█████████▌| 95/100 [5:38:38<17:44, 212.98s/it]Evaluating commonsenseqa :  36%|███▌      | 36/100 [1:51:34<3:19:52, 187.38s/it]Evaluating commonsenseqa :  64%|██████▍   | 64/100 [4:15:44<2:24:41, 241.16s/it]Evaluating commonsenseqa :  96%|█████████▌| 96/100 [5:42:13<14:14, 213.67s/it]Evaluating commonsenseqa :  37%|███▋      | 37/100 [1:54:42<3:16:48, 187.44s/it]Evaluating commonsenseqa :  65%|██████▌   | 65/100 [4:19:47<2:21:07, 241.93s/it]Evaluating commonsenseqa :  97%|█████████▋| 97/100 [5:45:47<10:41, 213.79s/it]Evaluating commonsenseqa :  38%|███▊      | 38/100 [1:57:51<3:14:07, 187.87s/it]Evaluating commonsenseqa :  98%|█████████▊| 98/100 [5:49:22<07:08, 214.11s/it]Evaluating commonsenseqa :  66%|██████▌   | 66/100 [4:23:51<2:17:28, 242.61s/it]Evaluating commonsenseqa :  39%|███▉      | 39/100 [2:00:58<3:10:51, 187.73s/it]Evaluating commonsenseqa :  40%|████      | 40/100 [2:04:05<3:07:38, 187.63s/it]Evaluating commonsenseqa :  99%|█████████▉| 99/100 [5:52:57<03:34, 214.19s/it]Evaluating commonsenseqa :  67%|██████▋   | 67/100 [4:27:51<2:12:59, 241.82s/it]Evaluating commonsenseqa :  41%|████      | 41/100 [2:07:12<3:04:13, 187.35s/it]Evaluating commonsenseqa : 100%|██████████| 100/100 [5:56:35<00:00, 215.58s/it]Evaluating commonsenseqa : 100%|██████████| 100/100 [5:56:35<00:00, 213.96s/it]
name: commonsenseqa | avg. gen lenth: 267.833 | time: 21397.511254310608s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 10955 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o14-tgsm8k-s30-rFalse --seed 30 --max-prompt-length 4096 --num-out-domain 14 11 12 13 14 15 False 4096 10
[2023-09-02 12:11:00,652] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o14-tgsm8k-s30-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 14
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o14-tgsm8k-s30-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 10
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 566455.21it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.76s/it]
 > number of parameters: 6738415616
[2023-09-02 12:11:13,696] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-02 12:11:13,904] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-02 12:11:13,906] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-02 12:11:13,906] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-02 12:11:13,906] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-02 12:11:13,906] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-02 12:11:13,906] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-02 12:11:13,906] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f27340>
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-02 12:11:13,907] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-02 12:11:13,908] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-02 12:11:13,908] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-02 12:11:13,908] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-02 12:11:13,908] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-02 12:11:13,908] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-02 12:11:13,908] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-02 12:11:13,908] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-02 12:11:13,908] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-02 12:11:13,908] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-02 12:11:13,908] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-02 12:11:13,908] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-02 12:11:13,908] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-02 12:11:13,908] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-02 12:11:13,908] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-02 12:11:13,908] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-02 12:11:13,908] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-02 12:11:13,908] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-02 12:11:13,908] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-02 12:11:13,908] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-02 12:11:13,908] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-02 12:11:13,908] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-02 12:11:13,908] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/100 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: The car-rental agency charges $30/day for a car, or $190 for the first week for a rental that lasts an entire week or longer. Jennie rented a car for 11 days. How much, in dollars, did she pay for the rental?
Output: 310

Input: A hurricane is approaching the southern coast of Texas, and a rancher is planning to move 400 head of cattle 60 miles to higher ground to protect them from possible inland flooding that might occur.  His animal transport truck holds 20 head of cattle.  Traveling at 60 miles per hour, what is the total driving time, in hours, it will take to transport all of his cattle to higher ground?
Output: 40

Input: Jason has a carriage house that he rents out.  He’s charging $50.00 per day or $500.00 for 14 days.  Eric wants to rent the house for 20 days.  How much will it cost him?
Output: 800

Input: Melissa works on a poultry farm. She drives to town twice each month to buy supplies. If it takes her 3 hours to drive to town and back, how many hours does Melissa spend driving in a year?
Output: 72

Input: The ratio of boys to girls in a family is 5:7. The total number of children in the family is 180. If the boys are given $3900 to share, how much money does each boy receive?
Output: 52

Input: Josephine receives a bill from the hospital for 5000$.  50 percent of the bill is for medication.  25 percent of the remaining bill is for overnight stays, and 175$ is for food.  The rest of the bill is for the ambulance ride.  How much did the ambulance ride cost?
Output: 1700

Input: It was time for Kelly to harvest her carrots that she had planted in three different beds.  In the first bed she pulled out 55 carrots.  In the second bed she pulled out 101 carrots and in the third bed she pulled out 78 carrots.  She found that 6 carrots weighed one pound.  How many pounds of carrots did Kelly harvest?
Output: 39

Input: Iris’ family is planning a surprise birthday party for her. The party will include her 3 uncles and 4 aunts who have a son and daughter each as well as her brother and mother. In total, how many people are coming to Iris’ birthday party?
Output: 23

Input: Lyra bought a pair of shoes at a 20% discount.  If she paid $480, how much was the original price of the pair of shoes?
Output: 600

Input: Rhett has been late on two of his monthly rent payments, but his landlord does not charge late fees and so he will be able to pay their total cost with 3/5 of his next month's salary after taxes. If he is currently paid $5000 per month and has to pay 10% tax, calculate his rent expense per month?
Output: 1350

Input: Ten friends decide to get an end-of-year gift for their teacher. They plan to split the cost of the gift equally. But four of the group drop out. The remaining friends split the cost equally among themselves. If each share is now $8 more, how much does the gift cost, in dollars?
Output: 120

Input: At the feline sanctuary, there were 12 lions, 14 tigers, and several cougars.  If there were half as many cougars as lions and tigers combined, then what was the total number of big cats at the feline sanctuary?
Output: 39

Input: A pea patch is twice as big as a radish patch. If one sixth of the pea patch is 5 square feet.  How much is a whole radish patch in square feet?
Output: 15

Input: Phoebe has two pizzas to share with her and three friends. One has pepperoni and the other has cheese. They both have 16 slices. They all eat the same amount. One friend eats only pepperoni, while the rest have an equal number of slices of each. At the end, there is one slice of pepperoni left and 7 slices of cheese, how many slices does each person eat?
Output: 6

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o14-tgsm8k-s30-rFalse-m4096
Evaluating commonsenseqa :  68%|██████▊   | 68/100 [4:31:52<2:08:43, 241.36s/it]Evaluating commonsenseqa :  42%|████▏     | 42/100 [2:10:21<3:01:27, 187.72s/it]Evaluating commonsenseqa :   1%|          | 1/100 [03:34<5:54:01, 214.56s/it]Evaluating commonsenseqa :  69%|██████▉   | 69/100 [4:35:53<2:04:44, 241.44s/it]Evaluating commonsenseqa :  43%|████▎     | 43/100 [2:13:26<2:57:41, 187.04s/it]Evaluating commonsenseqa :   2%|▏         | 2/100 [07:01<5:43:13, 210.13s/it]Evaluating commonsenseqa :  44%|████▍     | 44/100 [2:16:36<2:55:18, 187.82s/it]Evaluating commonsenseqa :  70%|███████   | 70/100 [4:39:48<1:59:41, 239.38s/it]Evaluating commonsenseqa :   3%|▎         | 3/100 [10:27<5:36:49, 208.34s/it]Evaluating commonsenseqa :  45%|████▌     | 45/100 [2:19:47<2:53:04, 188.81s/it]Evaluating commonsenseqa :  71%|███████   | 71/100 [4:43:50<1:56:03, 240.12s/it]Evaluating commonsenseqa :   4%|▍         | 4/100 [13:52<5:31:15, 207.04s/it]Evaluating commonsenseqa :  46%|████▌     | 46/100 [2:22:54<2:49:31, 188.37s/it]Evaluating commonsenseqa :  72%|███████▏  | 72/100 [4:47:48<1:51:44, 239.46s/it]Evaluating commonsenseqa :   5%|▌         | 5/100 [17:19<5:27:20, 206.74s/it]Evaluating commonsenseqa :  47%|████▋     | 47/100 [2:26:00<2:45:46, 187.67s/it]Evaluating commonsenseqa :  73%|███████▎  | 73/100 [4:51:50<1:48:09, 240.34s/it]Evaluating commonsenseqa :  48%|████▊     | 48/100 [2:29:06<2:42:07, 187.07s/it]Evaluating commonsenseqa :   6%|▌         | 6/100 [20:46<5:24:29, 207.12s/it]Evaluating commonsenseqa :  49%|████▉     | 49/100 [2:32:17<2:40:02, 188.28s/it]Evaluating commonsenseqa :   7%|▋         | 7/100 [24:18<5:23:05, 208.44s/it]Evaluating commonsenseqa :  74%|███████▍  | 74/100 [4:55:54<1:44:37, 241.44s/it]Evaluating commonsenseqa :  50%|█████     | 50/100 [2:35:23<2:36:17, 187.55s/it]Evaluating commonsenseqa :   8%|▊         | 8/100 [27:42<5:17:39, 207.16s/it]Evaluating commonsenseqa :  75%|███████▌  | 75/100 [4:59:58<1:40:54, 242.19s/it]Evaluating commonsenseqa :  51%|█████     | 51/100 [2:38:30<2:33:03, 187.42s/it]Evaluating commonsenseqa :   9%|▉         | 9/100 [31:08<5:13:32, 206.73s/it]Evaluating commonsenseqa :  76%|███████▌  | 76/100 [5:03:58<1:36:37, 241.55s/it]Evaluating commonsenseqa :  52%|█████▏    | 52/100 [2:41:37<2:29:49, 187.28s/it]Evaluating commonsenseqa :  10%|█         | 10/100 [34:37<5:11:03, 207.37s/it]Evaluating commonsenseqa :  53%|█████▎    | 53/100 [2:44:46<2:27:02, 187.70s/it]Evaluating commonsenseqa :  77%|███████▋  | 77/100 [5:07:59<1:32:32, 241.42s/it]Evaluating commonsenseqa :  11%|█         | 11/100 [38:06<5:08:29, 207.97s/it]Evaluating commonsenseqa :  54%|█████▍    | 54/100 [2:47:03<2:12:13, 172.47s/it]Evaluating commonsenseqa :  78%|███████▊  | 78/100 [5:11:36<1:25:50, 234.09s/it]Evaluating commonsenseqa :  12%|█▏        | 12/100 [41:36<5:05:48, 208.50s/it]Evaluating commonsenseqa :  55%|█████▌    | 55/100 [2:50:09<2:12:25, 176.57s/it]Evaluating commonsenseqa :  79%|███████▉  | 79/100 [5:15:36<1:22:33, 235.90s/it]Evaluating commonsenseqa :  56%|█████▌    | 56/100 [2:53:16<2:11:45, 179.68s/it]Evaluating commonsenseqa :  13%|█▎        | 13/100 [45:03<5:01:46, 208.12s/it]Evaluating commonsenseqa :  57%|█████▋    | 57/100 [2:56:20<2:09:50, 181.18s/it]Evaluating commonsenseqa :  80%|████████  | 80/100 [5:19:40<1:19:26, 238.31s/it]Evaluating commonsenseqa :  14%|█▍        | 14/100 [48:27<4:56:45, 207.04s/it]Evaluating commonsenseqa :  58%|█████▊    | 58/100 [2:59:27<2:07:57, 182.79s/it]Evaluating commonsenseqa :  15%|█▌        | 15/100 [51:51<4:51:55, 206.06s/it]Evaluating commonsenseqa :  81%|████████  | 81/100 [5:23:40<1:15:39, 238.91s/it]Evaluating commonsenseqa :  59%|█████▉    | 59/100 [3:02:33<2:05:32, 183.72s/it]Evaluating commonsenseqa :  16%|█▌        | 16/100 [55:18<4:48:34, 206.13s/it]Evaluating commonsenseqa :  82%|████████▏ | 82/100 [5:27:37<1:11:25, 238.08s/it]Evaluating commonsenseqa :  60%|██████    | 60/100 [3:05:41<2:03:18, 184.97s/it]Evaluating commonsenseqa :  17%|█▋        | 17/100 [58:45<4:45:32, 206.42s/it]Evaluating commonsenseqa :  83%|████████▎ | 83/100 [5:31:38<1:07:46, 239.19s/it]Evaluating commonsenseqa :  61%|██████    | 61/100 [3:08:45<2:00:10, 184.88s/it]Evaluating commonsenseqa :  18%|█▊        | 18/100 [1:02:07<4:40:19, 205.12s/it]Evaluating commonsenseqa :  62%|██████▏   | 62/100 [3:11:54<1:57:46, 185.96s/it]Evaluating commonsenseqa :  84%|████████▍ | 84/100 [5:35:39<1:03:55, 239.73s/it]Evaluating commonsenseqa :  19%|█▉        | 19/100 [1:05:33<4:37:24, 205.49s/it]Evaluating commonsenseqa :  63%|██████▎   | 63/100 [3:14:59<1:54:30, 185.69s/it]Evaluating commonsenseqa :  85%|████████▌ | 85/100 [5:39:41<1:00:02, 240.20s/it]Evaluating commonsenseqa :  20%|██        | 20/100 [1:08:57<4:33:26, 205.09s/it]Evaluating commonsenseqa :  64%|██████▍   | 64/100 [3:18:04<1:51:17, 185.50s/it]Evaluating commonsenseqa :  86%|████████▌ | 86/100 [5:43:35<55:39, 238.50s/it]  Evaluating commonsenseqa :  21%|██        | 21/100 [1:12:20<4:29:05, 204.37s/it]Evaluating commonsenseqa :  65%|██████▌   | 65/100 [3:21:12<1:48:41, 186.32s/it]Evaluating commonsenseqa :  22%|██▏       | 22/100 [1:15:46<4:26:25, 204.94s/it]Evaluating commonsenseqa :  66%|██████▌   | 66/100 [3:24:19<1:45:44, 186.60s/it]Evaluating commonsenseqa :  87%|████████▋ | 87/100 [5:47:34<51:41, 238.58s/it]Evaluating commonsenseqa :  67%|██████▋   | 67/100 [3:27:27<1:42:52, 187.03s/it]Evaluating commonsenseqa :  23%|██▎       | 23/100 [1:19:16<4:25:00, 206.50s/it]Evaluating commonsenseqa :  88%|████████▊ | 88/100 [5:51:37<48:00, 240.01s/it]Evaluating commonsenseqa :  68%|██████▊   | 68/100 [3:30:37<1:40:06, 187.70s/it]Evaluating commonsenseqa :  24%|██▍       | 24/100 [1:22:44<4:21:51, 206.74s/it]Evaluating commonsenseqa :  89%|████████▉ | 89/100 [5:55:39<44:04, 240.36s/it]Evaluating commonsenseqa :  69%|██████▉   | 69/100 [3:33:46<1:37:09, 188.06s/it]Evaluating commonsenseqa :  25%|██▌       | 25/100 [1:26:12<4:19:02, 207.23s/it]Evaluating commonsenseqa :  90%|█████████ | 90/100 [5:59:44<40:19, 241.97s/it]Evaluating commonsenseqa :  70%|███████   | 70/100 [3:36:51<1:33:42, 187.41s/it]Evaluating commonsenseqa :  26%|██▌       | 26/100 [1:29:34<4:13:45, 205.75s/it]Evaluating commonsenseqa :  71%|███████   | 71/100 [3:39:57<1:30:14, 186.72s/it]Evaluating commonsenseqa :  91%|█████████ | 91/100 [6:03:44<36:11, 241.31s/it]Evaluating commonsenseqa :  27%|██▋       | 27/100 [1:33:01<4:10:32, 205.92s/it]Evaluating commonsenseqa :  72%|███████▏  | 72/100 [3:43:02<1:26:54, 186.23s/it]Evaluating commonsenseqa :  92%|█████████▏| 92/100 [6:07:45<32:09, 241.21s/it]Evaluating commonsenseqa :  28%|██▊       | 28/100 [1:36:30<4:08:16, 206.90s/it]Evaluating commonsenseqa :  73%|███████▎  | 73/100 [3:46:05<1:23:27, 185.45s/it]Evaluating commonsenseqa :  29%|██▉       | 29/100 [1:39:57<4:04:47, 206.87s/it]Evaluating commonsenseqa :  93%|█████████▎| 93/100 [6:11:44<28:03, 240.49s/it]Evaluating commonsenseqa :  74%|███████▍  | 74/100 [3:49:12<1:20:28, 185.73s/it]Evaluating commonsenseqa :  30%|███       | 30/100 [1:43:22<4:00:51, 206.46s/it]Evaluating commonsenseqa :  75%|███████▌  | 75/100 [3:52:15<1:17:05, 185.00s/it]Evaluating commonsenseqa :  94%|█████████▍| 94/100 [6:15:41<23:57, 239.65s/it]Evaluating commonsenseqa :  31%|███       | 31/100 [1:46:53<3:58:57, 207.78s/it]Evaluating commonsenseqa :  95%|█████████▌| 95/100 [6:18:20<17:57, 215.43s/it]Evaluating commonsenseqa :  76%|███████▌  | 76/100 [3:55:23<1:14:23, 185.96s/it]Evaluating commonsenseqa :  77%|███████▋  | 77/100 [3:58:30<1:11:25, 186.31s/it]Evaluating commonsenseqa :  32%|███▏      | 32/100 [1:50:15<3:53:34, 206.09s/it]Evaluating commonsenseqa :  96%|█████████▌| 96/100 [6:22:20<14:50, 222.70s/it]Evaluating commonsenseqa :  78%|███████▊  | 78/100 [4:01:41<1:08:49, 187.68s/it]Evaluating commonsenseqa :  33%|███▎      | 33/100 [1:53:43<3:50:43, 206.62s/it]Evaluating commonsenseqa :  97%|█████████▋| 97/100 [6:26:19<11:22, 227.49s/it]Evaluating commonsenseqa :  79%|███████▉  | 79/100 [4:04:50<1:05:50, 188.13s/it]Evaluating commonsenseqa :  34%|███▍      | 34/100 [1:57:11<3:47:54, 207.19s/it]Evaluating commonsenseqa :  98%|█████████▊| 98/100 [6:30:17<07:41, 230.75s/it]Evaluating commonsenseqa :  80%|████████  | 80/100 [4:07:59<1:02:48, 188.43s/it]Evaluating commonsenseqa :  35%|███▌      | 35/100 [2:00:38<3:44:05, 206.85s/it]Evaluating commonsenseqa :  81%|████████  | 81/100 [4:11:06<59:31, 187.96s/it]  Evaluating commonsenseqa :  99%|█████████▉| 99/100 [6:34:15<03:52, 232.94s/it]Evaluating commonsenseqa :  36%|███▌      | 36/100 [2:04:01<3:39:43, 205.99s/it]Evaluating commonsenseqa :  82%|████████▏ | 82/100 [4:14:15<56:26, 188.14s/it]Evaluating commonsenseqa : 100%|██████████| 100/100 [6:38:13<00:00, 234.41s/it]Evaluating commonsenseqa : 100%|██████████| 100/100 [6:38:13<00:00, 238.93s/it]
name: commonsenseqa | avg. gen lenth: 272.846 | time: 23895.009243249893s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 10954 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o10-tgsm8k-s30-rFalse --seed 30 --max-prompt-length 4096 --num-out-domain 10 6 7 8 9 10 False 4096 10
[2023-09-02 14:18:09,258] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o10-tgsm8k-s30-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 10
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o10-tgsm8k-s30-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 10
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 696334.24it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.22s/it]
 > number of parameters: 6738415616
[2023-09-02 14:18:21,163] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-02 14:18:21,376] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-02 14:18:21,378] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-02 14:18:21,378] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-02 14:18:21,378] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-02 14:18:21,378] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-02 14:18:21,378] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-02 14:18:21,378] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-02 14:18:21,378] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-02 14:18:21,378] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-02 14:18:21,378] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-02 14:18:21,378] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-02 14:18:21,378] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f27340>
[2023-09-02 14:18:21,378] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-02 14:18:21,378] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-02 14:18:21,378] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-02 14:18:21,378] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-02 14:18:21,378] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-02 14:18:21,378] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-02 14:18:21,378] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-02 14:18:21,378] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-02 14:18:21,378] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-02 14:18:21,378] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-02 14:18:21,378] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-02 14:18:21,379] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-02 14:18:21,380] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-02 14:18:21,380] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-02 14:18:21,380] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-02 14:18:21,380] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-02 14:18:21,380] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/100 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: The car-rental agency charges $30/day for a car, or $190 for the first week for a rental that lasts an entire week or longer. Jennie rented a car for 11 days. How much, in dollars, did she pay for the rental?
Output: 310

Input: A hurricane is approaching the southern coast of Texas, and a rancher is planning to move 400 head of cattle 60 miles to higher ground to protect them from possible inland flooding that might occur.  His animal transport truck holds 20 head of cattle.  Traveling at 60 miles per hour, what is the total driving time, in hours, it will take to transport all of his cattle to higher ground?
Output: 40

Input: Jason has a carriage house that he rents out.  He’s charging $50.00 per day or $500.00 for 14 days.  Eric wants to rent the house for 20 days.  How much will it cost him?
Output: 800

Input: Melissa works on a poultry farm. She drives to town twice each month to buy supplies. If it takes her 3 hours to drive to town and back, how many hours does Melissa spend driving in a year?
Output: 72

Input: The ratio of boys to girls in a family is 5:7. The total number of children in the family is 180. If the boys are given $3900 to share, how much money does each boy receive?
Output: 52

Input: Josephine receives a bill from the hospital for 5000$.  50 percent of the bill is for medication.  25 percent of the remaining bill is for overnight stays, and 175$ is for food.  The rest of the bill is for the ambulance ride.  How much did the ambulance ride cost?
Output: 1700

Input: It was time for Kelly to harvest her carrots that she had planted in three different beds.  In the first bed she pulled out 55 carrots.  In the second bed she pulled out 101 carrots and in the third bed she pulled out 78 carrots.  She found that 6 carrots weighed one pound.  How many pounds of carrots did Kelly harvest?
Output: 39

Input: Iris’ family is planning a surprise birthday party for her. The party will include her 3 uncles and 4 aunts who have a son and daughter each as well as her brother and mother. In total, how many people are coming to Iris’ birthday party?
Output: 23

Input: Lyra bought a pair of shoes at a 20% discount.  If she paid $480, how much was the original price of the pair of shoes?
Output: 600

Input: Rhett has been late on two of his monthly rent payments, but his landlord does not charge late fees and so he will be able to pay their total cost with 3/5 of his next month's salary after taxes. If he is currently paid $5000 per month and has to pay 10% tax, calculate his rent expense per month?
Output: 1350

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o10-tgsm8k-s30-rFalse-m4096
Evaluating commonsenseqa :  37%|███▋      | 37/100 [2:07:25<3:35:25, 205.17s/it]Evaluating commonsenseqa :  83%|████████▎ | 83/100 [4:17:21<53:08, 187.54s/it]Evaluating commonsenseqa :  38%|███▊      | 38/100 [2:10:53<3:33:04, 206.20s/it]Evaluating commonsenseqa :   1%|          | 1/100 [03:57<6:31:55, 237.53s/it]Evaluating commonsenseqa :  84%|████████▍ | 84/100 [4:20:28<49:55, 187.22s/it]Evaluating commonsenseqa :  39%|███▉      | 39/100 [2:14:20<3:29:38, 206.20s/it]Evaluating commonsenseqa :   2%|▏         | 2/100 [07:49<6:23:05, 234.55s/it]Evaluating commonsenseqa :  85%|████████▌ | 85/100 [4:23:36<46:54, 187.66s/it]Evaluating commonsenseqa :  40%|████      | 40/100 [2:17:49<3:27:03, 207.07s/it]Evaluating commonsenseqa :  86%|████████▌ | 86/100 [4:26:39<43:26, 186.18s/it]Evaluating commonsenseqa :   3%|▎         | 3/100 [11:41<6:16:58, 233.18s/it]Evaluating commonsenseqa :  41%|████      | 41/100 [2:21:13<3:22:44, 206.18s/it]Evaluating commonsenseqa :  87%|████████▋ | 87/100 [4:29:43<40:12, 185.56s/it]Evaluating commonsenseqa :   4%|▍         | 4/100 [15:32<6:11:46, 232.36s/it]Evaluating commonsenseqa :  88%|████████▊ | 88/100 [4:32:51<37:15, 186.30s/it]Evaluating commonsenseqa :  42%|████▏     | 42/100 [2:24:41<3:20:02, 206.94s/it]Evaluating commonsenseqa :   5%|▌         | 5/100 [19:23<6:06:48, 231.66s/it]Evaluating commonsenseqa :  89%|████████▉ | 89/100 [4:35:55<34:02, 185.71s/it]Evaluating commonsenseqa :  43%|████▎     | 43/100 [2:28:10<3:16:57, 207.32s/it]Evaluating commonsenseqa :   6%|▌         | 6/100 [23:16<6:03:55, 232.30s/it]Evaluating commonsenseqa :  90%|█████████ | 90/100 [4:38:59<30:49, 184.97s/it]Evaluating commonsenseqa :  44%|████▍     | 44/100 [2:31:34<3:12:44, 206.51s/it]Evaluating commonsenseqa :  91%|█████████ | 91/100 [4:42:07<27:53, 185.90s/it]Evaluating commonsenseqa :   7%|▋         | 7/100 [27:13<6:02:18, 233.75s/it]Evaluating commonsenseqa :  45%|████▌     | 45/100 [2:34:57<3:08:12, 205.33s/it]Evaluating commonsenseqa :  92%|█████████▏| 92/100 [4:45:12<24:45, 185.74s/it]Evaluating commonsenseqa :   8%|▊         | 8/100 [31:04<5:56:59, 232.82s/it]Evaluating commonsenseqa :  46%|████▌     | 46/100 [2:38:23<3:04:54, 205.45s/it]Evaluating commonsenseqa :  93%|█████████▎| 93/100 [4:48:22<21:49, 187.04s/it]Evaluating commonsenseqa :  47%|████▋     | 47/100 [2:41:52<3:02:25, 206.52s/it]Evaluating commonsenseqa :   9%|▉         | 9/100 [34:58<5:53:49, 233.29s/it]Evaluating commonsenseqa :  94%|█████████▍| 94/100 [4:51:25<18:34, 185.69s/it]Evaluating commonsenseqa :  48%|████▊     | 48/100 [2:45:17<2:58:47, 206.30s/it]Evaluating commonsenseqa :  95%|█████████▌| 95/100 [4:54:33<15:31, 186.34s/it]Evaluating commonsenseqa :  10%|█         | 10/100 [38:56<5:52:18, 234.87s/it]Evaluating commonsenseqa :  49%|████▉     | 49/100 [2:48:43<2:55:14, 206.17s/it]Evaluating commonsenseqa :  96%|█████████▌| 96/100 [4:57:16<11:58, 179.56s/it]Evaluating commonsenseqa :  11%|█         | 11/100 [42:51<5:48:26, 234.90s/it]Evaluating commonsenseqa :  97%|█████████▋| 97/100 [5:00:23<09:04, 181.65s/it]Evaluating commonsenseqa :  50%|█████     | 50/100 [2:52:08<2:51:29, 205.80s/it]Evaluating commonsenseqa :  12%|█▏        | 12/100 [46:48<5:45:13, 235.39s/it]Evaluating commonsenseqa :  98%|█████████▊| 98/100 [5:03:27<06:04, 182.30s/it]Evaluating commonsenseqa :  51%|█████     | 51/100 [2:55:32<2:47:31, 205.14s/it]Evaluating commonsenseqa :  13%|█▎        | 13/100 [50:48<5:43:12, 236.70s/it]Evaluating commonsenseqa :  99%|█████████▉| 99/100 [5:06:34<03:03, 183.94s/it]Evaluating commonsenseqa :  52%|█████▏    | 52/100 [2:58:56<2:43:58, 204.98s/it]Evaluating commonsenseqa : 100%|██████████| 100/100 [5:09:41<00:00, 184.64s/it]Evaluating commonsenseqa : 100%|██████████| 100/100 [5:09:41<00:00, 185.81s/it]
name: commonsenseqa | avg. gen lenth: 269.909 | time: 18583.06910920143s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 12081 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o20-tgsm8k-s30-rFalse --seed 30 --max-prompt-length 4096 --num-out-domain 20 16 17 18 19 20 False 4096 10
[2023-09-02 15:12:36,756] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o20-tgsm8k-s30-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 20
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o20-tgsm8k-s30-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 10
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 504428.80it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.73s/it]
 > number of parameters: 6738415616
[2023-09-02 15:12:47,729] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-02 15:12:47,937] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-02 15:12:47,939] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-02 15:12:47,939] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-02 15:12:47,939] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-02 15:12:47,939] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-02 15:12:47,939] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554ba3be310>
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-02 15:12:47,940] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-02 15:12:47,941] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-02 15:12:47,941] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-02 15:12:47,941] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-02 15:12:47,941] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-02 15:12:47,941] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-02 15:12:47,941] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-02 15:12:47,941] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-02 15:12:47,941] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-02 15:12:47,941] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-02 15:12:47,941] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-02 15:12:47,941] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-02 15:12:47,941] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-02 15:12:47,941] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-02 15:12:47,941] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-02 15:12:47,941] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-02 15:12:47,941] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-02 15:12:47,941] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-02 15:12:47,941] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-02 15:12:47,941] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-02 15:12:47,941] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-02 15:12:47,941] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-02 15:12:47,941] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-02 15:12:47,941] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/100 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: The car-rental agency charges $30/day for a car, or $190 for the first week for a rental that lasts an entire week or longer. Jennie rented a car for 11 days. How much, in dollars, did she pay for the rental?
Output: 310

Input: A hurricane is approaching the southern coast of Texas, and a rancher is planning to move 400 head of cattle 60 miles to higher ground to protect them from possible inland flooding that might occur.  His animal transport truck holds 20 head of cattle.  Traveling at 60 miles per hour, what is the total driving time, in hours, it will take to transport all of his cattle to higher ground?
Output: 40

Input: Jason has a carriage house that he rents out.  He’s charging $50.00 per day or $500.00 for 14 days.  Eric wants to rent the house for 20 days.  How much will it cost him?
Output: 800

Input: Melissa works on a poultry farm. She drives to town twice each month to buy supplies. If it takes her 3 hours to drive to town and back, how many hours does Melissa spend driving in a year?
Output: 72

Input: The ratio of boys to girls in a family is 5:7. The total number of children in the family is 180. If the boys are given $3900 to share, how much money does each boy receive?
Output: 52

Input: Josephine receives a bill from the hospital for 5000$.  50 percent of the bill is for medication.  25 percent of the remaining bill is for overnight stays, and 175$ is for food.  The rest of the bill is for the ambulance ride.  How much did the ambulance ride cost?
Output: 1700

Input: It was time for Kelly to harvest her carrots that she had planted in three different beds.  In the first bed she pulled out 55 carrots.  In the second bed she pulled out 101 carrots and in the third bed she pulled out 78 carrots.  She found that 6 carrots weighed one pound.  How many pounds of carrots did Kelly harvest?
Output: 39

Input: Iris’ family is planning a surprise birthday party for her. The party will include her 3 uncles and 4 aunts who have a son and daughter each as well as her brother and mother. In total, how many people are coming to Iris’ birthday party?
Output: 23

Input: Lyra bought a pair of shoes at a 20% discount.  If she paid $480, how much was the original price of the pair of shoes?
Output: 600

Input: Rhett has been late on two of his monthly rent payments, but his landlord does not charge late fees and so he will be able to pay their total cost with 3/5 of his next month's salary after taxes. If he is currently paid $5000 per month and has to pay 10% tax, calculate his rent expense per month?
Output: 1350

Input: Ten friends decide to get an end-of-year gift for their teacher. They plan to split the cost of the gift equally. But four of the group drop out. The remaining friends split the cost equally among themselves. If each share is now $8 more, how much does the gift cost, in dollars?
Output: 120

Input: At the feline sanctuary, there were 12 lions, 14 tigers, and several cougars.  If there were half as many cougars as lions and tigers combined, then what was the total number of big cats at the feline sanctuary?
Output: 39

Input: A pea patch is twice as big as a radish patch. If one sixth of the pea patch is 5 square feet.  How much is a whole radish patch in square feet?
Output: 15

Input: Phoebe has two pizzas to share with her and three friends. One has pepperoni and the other has cheese. They both have 16 slices. They all eat the same amount. One friend eats only pepperoni, while the rest have an equal number of slices of each. At the end, there is one slice of pepperoni left and 7 slices of cheese, how many slices does each person eat?
Output: 6

Input: Jeremy buys 30 watermelons. He eats 3 watermelons per week. Each week he gives 2 to his dad. How many weeks will the watermelons last?
Output: 6

Input: Jackson has 5 times more money than Williams. Together, they have $150. How much money, in dollars, does Jackson have?
Output: 125

Input: Janet counts 30 crows on the powerlines and 60% more hawks than crows. How many birds does she count total?
Output: 78

Input: There are 290 liters of oil in 24 cans. If 10 of the cans are holding 8 liters each, how much oil is each of the remaining cans holding?
Output: 15

Input: Bill had to finish a project from work that was to take him 4 days. If he took 6 seven-hour naps in the four days, how long did he spend working on the project?
Output: 54

Input: There are 120 cards in a box. If 2/5 of the cards are red, exactly 5/9 of the remainder are black, and the rest are green, calculate the number of green cards in the box?
Output: 32

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o20-tgsm8k-s30-rFalse-m4096
Evaluating commonsenseqa :  14%|█▍        | 14/100 [54:42<5:38:14, 235.99s/it]Evaluating commonsenseqa :  53%|█████▎    | 53/100 [3:02:20<2:40:10, 204.49s/it]Evaluating commonsenseqa :   1%|          | 1/100 [03:05<5:06:46, 185.93s/it]Evaluating commonsenseqa :  15%|█▌        | 15/100 [58:35<5:32:57, 235.03s/it]Evaluating commonsenseqa :  54%|█████▍    | 54/100 [3:05:48<2:37:33, 205.50s/it]Evaluating commonsenseqa :   2%|▏         | 2/100 [06:08<5:00:12, 183.80s/it]Evaluating commonsenseqa :  55%|█████▌    | 55/100 [3:09:16<2:34:48, 206.42s/it]Evaluating commonsenseqa :  16%|█▌        | 16/100 [1:02:26<5:27:15, 233.76s/it]Evaluating commonsenseqa :   3%|▎         | 3/100 [09:11<4:56:58, 183.69s/it]Evaluating commonsenseqa :  56%|█████▌    | 56/100 [3:12:43<2:31:33, 206.68s/it]Evaluating commonsenseqa :  17%|█▋        | 17/100 [1:06:18<5:23:01, 233.52s/it]Evaluating commonsenseqa :   4%|▍         | 4/100 [12:17<4:54:51, 184.29s/it]Evaluating commonsenseqa :  57%|█████▋    | 57/100 [3:16:09<2:27:49, 206.27s/it]Evaluating commonsenseqa :   5%|▌         | 5/100 [15:20<4:51:31, 184.12s/it]Evaluating commonsenseqa :  18%|█▊        | 18/100 [1:10:11<5:18:42, 233.20s/it]Evaluating commonsenseqa :  58%|█████▊    | 58/100 [3:19:34<2:24:10, 205.96s/it]Evaluating commonsenseqa :   6%|▌         | 6/100 [18:27<4:49:34, 184.84s/it]Evaluating commonsenseqa :  19%|█▉        | 19/100 [1:14:05<5:15:04, 233.39s/it]Evaluating commonsenseqa :  59%|█████▉    | 59/100 [3:23:01<2:20:59, 206.34s/it]Evaluating commonsenseqa :   7%|▋         | 7/100 [21:27<4:44:29, 183.54s/it]Evaluating commonsenseqa :  20%|██        | 20/100 [1:17:55<5:10:06, 232.58s/it]Evaluating commonsenseqa :   8%|▊         | 8/100 [24:29<4:40:31, 182.95s/it]Evaluating commonsenseqa :  60%|██████    | 60/100 [3:26:29<2:17:56, 206.91s/it]Evaluating commonsenseqa :  21%|██        | 21/100 [1:21:42<5:03:46, 230.72s/it]Evaluating commonsenseqa :   9%|▉         | 9/100 [27:29<4:35:57, 181.95s/it]Evaluating commonsenseqa :  61%|██████    | 61/100 [3:29:55<2:14:08, 206.38s/it]Evaluating commonsenseqa :  10%|█         | 10/100 [30:29<4:32:08, 181.42s/it]Evaluating commonsenseqa :  22%|██▏       | 22/100 [1:25:34<5:00:32, 231.19s/it]Evaluating commonsenseqa :  62%|██████▏   | 62/100 [3:33:23<2:11:01, 206.88s/it]Evaluating commonsenseqa :  11%|█         | 11/100 [33:33<4:30:04, 182.07s/it]Evaluating commonsenseqa :  23%|██▎       | 23/100 [1:29:31<4:59:01, 233.01s/it]Evaluating commonsenseqa :  63%|██████▎   | 63/100 [3:36:47<2:07:06, 206.13s/it]Evaluating commonsenseqa :  12%|█▏        | 12/100 [36:36<4:27:35, 182.45s/it]Evaluating commonsenseqa :  64%|██████▍   | 64/100 [3:40:09<2:03:00, 205.01s/it]Evaluating commonsenseqa :  24%|██▍       | 24/100 [1:33:27<4:56:03, 233.73s/it]Evaluating commonsenseqa :  13%|█▎        | 13/100 [39:39<4:24:39, 182.52s/it]Evaluating commonsenseqa :  65%|██████▌   | 65/100 [3:43:34<1:59:27, 204.79s/it]Evaluating commonsenseqa :  14%|█▍        | 14/100 [42:41<4:21:25, 182.39s/it]Evaluating commonsenseqa :  25%|██▌       | 25/100 [1:37:19<4:51:34, 233.26s/it]Evaluating commonsenseqa :  66%|██████▌   | 66/100 [3:46:59<1:56:03, 204.81s/it]Evaluating commonsenseqa :  15%|█▌        | 15/100 [45:39<4:16:41, 181.19s/it]Evaluating commonsenseqa :  26%|██▌       | 26/100 [1:41:12<4:47:37, 233.20s/it]Evaluating commonsenseqa :  16%|█▌        | 16/100 [48:40<4:13:36, 181.14s/it]Evaluating commonsenseqa :  67%|██████▋   | 67/100 [3:50:29<1:53:31, 206.41s/it]Evaluating commonsenseqa :  27%|██▋       | 27/100 [1:44:58<4:41:09, 231.08s/it]Evaluating commonsenseqa :  17%|█▋        | 17/100 [51:40<4:10:12, 180.87s/it]Evaluating commonsenseqa :  68%|██████▊   | 68/100 [3:53:57<1:50:25, 207.06s/it]Evaluating commonsenseqa :  28%|██▊       | 28/100 [1:48:55<4:39:19, 232.77s/it]Evaluating commonsenseqa :  18%|█▊        | 18/100 [54:41<4:07:11, 180.87s/it]Evaluating commonsenseqa :  69%|██████▉   | 69/100 [3:57:23<1:46:44, 206.59s/it]Evaluating commonsenseqa :  19%|█▉        | 19/100 [57:40<4:03:25, 180.31s/it]Evaluating commonsenseqa :  29%|██▉       | 29/100 [1:52:47<4:35:03, 232.44s/it]Evaluating commonsenseqa :  70%|███████   | 70/100 [4:00:48<1:43:08, 206.27s/it]Evaluating commonsenseqa :  20%|██        | 20/100 [1:00:42<4:01:03, 180.79s/it]Evaluating commonsenseqa :  30%|███       | 30/100 [1:56:35<4:29:50, 231.29s/it]Evaluating commonsenseqa :  71%|███████   | 71/100 [4:04:10<1:38:58, 204.76s/it]Evaluating commonsenseqa :  21%|██        | 21/100 [1:03:45<3:58:45, 181.34s/it]Evaluating commonsenseqa :  72%|███████▏  | 72/100 [4:07:31<1:35:05, 203.76s/it]Evaluating commonsenseqa :  31%|███       | 31/100 [2:00:33<4:28:11, 233.21s/it]Evaluating commonsenseqa :  22%|██▏       | 22/100 [1:06:47<3:56:09, 181.67s/it]Evaluating commonsenseqa :  73%|███████▎  | 73/100 [4:10:53<1:31:23, 203.09s/it]Evaluating commonsenseqa :  23%|██▎       | 23/100 [1:09:46<3:51:57, 180.75s/it]Evaluating commonsenseqa :  32%|███▏      | 32/100 [2:04:28<4:24:49, 233.67s/it]Evaluating commonsenseqa :  24%|██▍       | 24/100 [1:12:45<3:48:26, 180.35s/it]Evaluating commonsenseqa :  74%|███████▍  | 74/100 [4:14:22<1:28:46, 204.87s/it]Evaluating commonsenseqa :  33%|███▎      | 33/100 [2:08:21<4:20:58, 233.71s/it]Evaluating commonsenseqa :  25%|██▌       | 25/100 [1:15:47<3:46:04, 180.87s/it]Evaluating commonsenseqa :  75%|███████▌  | 75/100 [4:17:44<1:25:04, 204.18s/it]Evaluating commonsenseqa :  34%|███▍      | 34/100 [2:12:18<4:17:55, 234.47s/it]Evaluating commonsenseqa :  26%|██▌       | 26/100 [1:18:55<3:45:26, 182.80s/it]Evaluating commonsenseqa :  76%|███████▌  | 76/100 [4:21:12<1:22:10, 205.43s/it]Evaluating commonsenseqa :  35%|███▌      | 35/100 [2:16:12<4:13:57, 234.42s/it]Evaluating commonsenseqa :  27%|██▋       | 27/100 [1:21:56<3:41:46, 182.28s/it]Evaluating commonsenseqa :  77%|███████▋  | 77/100 [4:24:43<1:19:20, 206.99s/it]Evaluating commonsenseqa :  28%|██▊       | 28/100 [1:25:01<3:39:41, 183.08s/it]Evaluating commonsenseqa :  36%|███▌      | 36/100 [2:20:02<4:08:33, 233.03s/it]Evaluating commonsenseqa :  78%|███████▊  | 78/100 [4:28:12<1:16:04, 207.48s/it]Evaluating commonsenseqa :  29%|██▉       | 29/100 [1:28:03<3:36:14, 182.74s/it]Evaluating commonsenseqa :  37%|███▋      | 37/100 [2:23:54<4:04:31, 232.88s/it]Evaluating commonsenseqa :  79%|███████▉  | 79/100 [4:31:38<1:12:30, 207.16s/it]Evaluating commonsenseqa :  30%|███       | 30/100 [1:31:02<3:32:06, 181.80s/it]Evaluating commonsenseqa :  38%|███▊      | 38/100 [2:27:47<4:00:41, 232.93s/it]Evaluating commonsenseqa :  80%|████████  | 80/100 [4:35:05<1:09:03, 207.19s/it]Evaluating commonsenseqa :  31%|███       | 31/100 [1:34:06<3:29:37, 182.28s/it]Evaluating commonsenseqa :  81%|████████  | 81/100 [4:38:32<1:05:35, 207.12s/it]Evaluating commonsenseqa :  32%|███▏      | 32/100 [1:37:07<3:26:06, 181.86s/it]Evaluating commonsenseqa :  39%|███▉      | 39/100 [2:31:41<3:57:03, 233.18s/it]Evaluating commonsenseqa :  33%|███▎      | 33/100 [1:40:10<3:23:33, 182.30s/it]Evaluating commonsenseqa :  82%|████████▏ | 82/100 [4:41:59<1:02:05, 206.99s/it]Evaluating commonsenseqa :  40%|████      | 40/100 [2:35:35<3:53:30, 233.51s/it]Evaluating commonsenseqa :  34%|███▍      | 34/100 [1:43:08<3:19:07, 181.03s/it]Evaluating commonsenseqa :  83%|████████▎ | 83/100 [4:45:27<58:42, 207.19s/it]  Evaluating commonsenseqa :  41%|████      | 41/100 [2:39:27<3:49:02, 232.92s/it]Evaluating commonsenseqa :  35%|███▌      | 35/100 [1:46:11<3:16:49, 181.68s/it]Evaluating commonsenseqa :  84%|████████▍ | 84/100 [4:48:51<55:02, 206.38s/it]Evaluating commonsenseqa :  42%|████▏     | 42/100 [2:43:22<3:45:46, 233.55s/it]Evaluating commonsenseqa :  36%|███▌      | 36/100 [1:49:13<3:14:00, 181.88s/it]Evaluating commonsenseqa :  85%|████████▌ | 85/100 [4:52:16<51:29, 205.99s/it]Evaluating commonsenseqa :  37%|███▋      | 37/100 [1:52:16<3:11:10, 182.07s/it]Evaluating commonsenseqa :  43%|████▎     | 43/100 [2:47:16<3:41:55, 233.60s/it]Evaluating commonsenseqa :  86%|████████▌ | 86/100 [4:55:43<48:08, 206.33s/it]Evaluating commonsenseqa :  38%|███▊      | 38/100 [1:55:20<3:08:41, 182.60s/it]Evaluating commonsenseqa :  44%|████▍     | 44/100 [2:51:07<3:37:20, 232.87s/it]Evaluating commonsenseqa :  87%|████████▋ | 87/100 [4:59:10<44:44, 206.50s/it]Evaluating commonsenseqa :  39%|███▉      | 39/100 [1:58:16<3:03:50, 180.83s/it]Evaluating commonsenseqa :  45%|████▌     | 45/100 [2:54:59<3:33:21, 232.76s/it]Evaluating commonsenseqa :  88%|████████▊ | 88/100 [5:02:35<41:12, 206.02s/it]Evaluating commonsenseqa :  40%|████      | 40/100 [2:01:16<3:00:31, 180.52s/it]Evaluating commonsenseqa :  89%|████████▉ | 89/100 [5:04:45<33:35, 183.24s/it]Evaluating commonsenseqa :  41%|████      | 41/100 [2:04:14<2:56:45, 179.76s/it]Evaluating commonsenseqa :  46%|████▌     | 46/100 [2:58:51<3:29:08, 232.39s/it]Evaluating commonsenseqa :  90%|█████████ | 90/100 [5:08:14<31:48, 190.81s/it]Evaluating commonsenseqa :  47%|████▋     | 47/100 [3:01:17<3:02:21, 206.45s/it]Evaluating commonsenseqa :  42%|████▏     | 42/100 [2:07:16<2:54:20, 180.35s/it]Evaluating commonsenseqa :  91%|█████████ | 91/100 [5:11:41<29:21, 195.71s/it]Evaluating commonsenseqa :  43%|████▎     | 43/100 [2:10:19<2:52:05, 181.15s/it]Evaluating commonsenseqa :  48%|████▊     | 48/100 [3:05:08<3:05:26, 213.96s/it]Evaluating commonsenseqa :  44%|████▍     | 44/100 [2:13:19<2:48:51, 180.92s/it]Evaluating commonsenseqa :  92%|█████████▏| 92/100 [5:15:07<26:31, 198.96s/it]Evaluating commonsenseqa :  49%|████▉     | 49/100 [3:08:54<3:04:45, 217.36s/it]Evaluating commonsenseqa :  45%|████▌     | 45/100 [2:16:18<2:45:09, 180.17s/it]Evaluating commonsenseqa :  93%|█████████▎| 93/100 [5:18:37<23:35, 202.28s/it]Evaluating commonsenseqa :  50%|█████     | 50/100 [3:12:45<3:04:42, 221.65s/it]Evaluating commonsenseqa :  46%|████▌     | 46/100 [2:18:35<2:30:38, 167.38s/it]Evaluating commonsenseqa :  94%|█████████▍| 94/100 [5:22:02<20:17, 202.87s/it]Evaluating commonsenseqa :  47%|████▋     | 47/100 [2:21:39<2:32:01, 172.11s/it]Evaluating commonsenseqa :  51%|█████     | 51/100 [3:16:39<3:03:55, 225.21s/it]Evaluating commonsenseqa :  95%|█████████▌| 95/100 [5:25:27<16:57, 203.53s/it]Evaluating commonsenseqa :  48%|████▊     | 48/100 [2:24:40<2:31:35, 174.90s/it]Evaluating commonsenseqa :  52%|█████▏    | 52/100 [3:20:31<3:01:58, 227.46s/it]Evaluating commonsenseqa :  96%|█████████▌| 96/100 [5:28:50<13:33, 203.45s/it]Evaluating commonsenseqa :  49%|████▉     | 49/100 [2:27:42<2:30:31, 177.08s/it]Evaluating commonsenseqa :  53%|█████▎    | 53/100 [3:24:23<2:59:14, 228.81s/it]Evaluating commonsenseqa :  97%|█████████▋| 97/100 [5:32:15<10:11, 203.75s/it]Evaluating commonsenseqa :  50%|█████     | 50/100 [2:30:43<2:28:34, 178.29s/it]Evaluating commonsenseqa :  51%|█████     | 51/100 [2:33:46<2:26:46, 179.73s/it]Evaluating commonsenseqa :  54%|█████▍    | 54/100 [3:28:16<2:56:12, 229.83s/it]Evaluating commonsenseqa :  98%|█████████▊| 98/100 [5:35:41<06:49, 204.57s/it]Evaluating commonsenseqa :  52%|█████▏    | 52/100 [2:36:48<2:24:20, 180.43s/it]Evaluating commonsenseqa :  99%|█████████▉| 99/100 [5:39:09<03:25, 205.50s/it]Evaluating commonsenseqa :  55%|█████▌    | 55/100 [3:32:07<2:52:40, 230.24s/it]Evaluating commonsenseqa :  53%|█████▎    | 53/100 [2:39:47<2:20:57, 179.96s/it]Evaluating commonsenseqa : 100%|██████████| 100/100 [5:42:35<00:00, 205.79s/it]Evaluating commonsenseqa : 100%|██████████| 100/100 [5:42:35<00:00, 205.56s/it]
name: commonsenseqa | avg. gen lenth: 281.375 | time: 20557.407826662064s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 10955 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o15-tgsm8k-s30-rFalse --seed 30 --max-prompt-length 4096 --num-out-domain 15 11 12 13 14 15 False 4096 10
[2023-09-02 17:53:58,247] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o15-tgsm8k-s30-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 15
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o15-tgsm8k-s30-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 10
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 564428.42it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.16s/it]
 > number of parameters: 6738415616
[2023-09-02 17:54:08,095] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-02 17:54:08,304] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-02 17:54:08,306] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-02 17:54:08,306] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-02 17:54:08,306] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-02 17:54:08,306] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-02 17:54:08,306] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-02 17:54:08,306] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-02 17:54:08,306] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-02 17:54:08,306] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-02 17:54:08,306] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-02 17:54:08,306] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-02 17:54:08,306] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f86490>
[2023-09-02 17:54:08,306] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-02 17:54:08,306] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-02 17:54:08,306] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-02 17:54:08,306] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-02 17:54:08,306] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-02 17:54:08,306] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-02 17:54:08,306] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-02 17:54:08,306] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-02 17:54:08,306] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-02 17:54:08,307] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-02 17:54:08,308] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-02 17:54:08,308] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-02 17:54:08,308] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-02 17:54:08,308] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-02 17:54:08,308] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-02 17:54:08,308] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/100 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: The car-rental agency charges $30/day for a car, or $190 for the first week for a rental that lasts an entire week or longer. Jennie rented a car for 11 days. How much, in dollars, did she pay for the rental?
Output: 310

Input: A hurricane is approaching the southern coast of Texas, and a rancher is planning to move 400 head of cattle 60 miles to higher ground to protect them from possible inland flooding that might occur.  His animal transport truck holds 20 head of cattle.  Traveling at 60 miles per hour, what is the total driving time, in hours, it will take to transport all of his cattle to higher ground?
Output: 40

Input: Jason has a carriage house that he rents out.  He’s charging $50.00 per day or $500.00 for 14 days.  Eric wants to rent the house for 20 days.  How much will it cost him?
Output: 800

Input: Melissa works on a poultry farm. She drives to town twice each month to buy supplies. If it takes her 3 hours to drive to town and back, how many hours does Melissa spend driving in a year?
Output: 72

Input: The ratio of boys to girls in a family is 5:7. The total number of children in the family is 180. If the boys are given $3900 to share, how much money does each boy receive?
Output: 52

Input: Josephine receives a bill from the hospital for 5000$.  50 percent of the bill is for medication.  25 percent of the remaining bill is for overnight stays, and 175$ is for food.  The rest of the bill is for the ambulance ride.  How much did the ambulance ride cost?
Output: 1700

Input: It was time for Kelly to harvest her carrots that she had planted in three different beds.  In the first bed she pulled out 55 carrots.  In the second bed she pulled out 101 carrots and in the third bed she pulled out 78 carrots.  She found that 6 carrots weighed one pound.  How many pounds of carrots did Kelly harvest?
Output: 39

Input: Iris’ family is planning a surprise birthday party for her. The party will include her 3 uncles and 4 aunts who have a son and daughter each as well as her brother and mother. In total, how many people are coming to Iris’ birthday party?
Output: 23

Input: Lyra bought a pair of shoes at a 20% discount.  If she paid $480, how much was the original price of the pair of shoes?
Output: 600

Input: Rhett has been late on two of his monthly rent payments, but his landlord does not charge late fees and so he will be able to pay their total cost with 3/5 of his next month's salary after taxes. If he is currently paid $5000 per month and has to pay 10% tax, calculate his rent expense per month?
Output: 1350

Input: Ten friends decide to get an end-of-year gift for their teacher. They plan to split the cost of the gift equally. But four of the group drop out. The remaining friends split the cost equally among themselves. If each share is now $8 more, how much does the gift cost, in dollars?
Output: 120

Input: At the feline sanctuary, there were 12 lions, 14 tigers, and several cougars.  If there were half as many cougars as lions and tigers combined, then what was the total number of big cats at the feline sanctuary?
Output: 39

Input: A pea patch is twice as big as a radish patch. If one sixth of the pea patch is 5 square feet.  How much is a whole radish patch in square feet?
Output: 15

Input: Phoebe has two pizzas to share with her and three friends. One has pepperoni and the other has cheese. They both have 16 slices. They all eat the same amount. One friend eats only pepperoni, while the rest have an equal number of slices of each. At the end, there is one slice of pepperoni left and 7 slices of cheese, how many slices does each person eat?
Output: 6

Input: Jeremy buys 30 watermelons. He eats 3 watermelons per week. Each week he gives 2 to his dad. How many weeks will the watermelons last?
Output: 6

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o15-tgsm8k-s30-rFalse-m4096
Evaluating commonsenseqa :  56%|█████▌    | 56/100 [3:35:58<2:49:01, 230.49s/it]Evaluating commonsenseqa :  54%|█████▍    | 54/100 [2:42:45<2:17:21, 179.17s/it]Evaluating commonsenseqa :   1%|          | 1/100 [03:28<5:44:15, 208.64s/it]Evaluating commonsenseqa :  57%|█████▋    | 57/100 [3:39:54<2:46:28, 232.30s/it]Evaluating commonsenseqa :  55%|█████▌    | 55/100 [2:45:41<2:13:50, 178.46s/it]Evaluating commonsenseqa :   2%|▏         | 2/100 [06:49<5:33:26, 204.15s/it]Evaluating commonsenseqa :  56%|█████▌    | 56/100 [2:48:50<2:13:04, 181.46s/it]Evaluating commonsenseqa :  58%|█████▊    | 58/100 [3:43:44<2:42:08, 231.62s/it]Evaluating commonsenseqa :   3%|▎         | 3/100 [10:10<5:27:42, 202.70s/it]Evaluating commonsenseqa :  57%|█████▋    | 57/100 [2:51:53<2:10:25, 181.98s/it]Evaluating commonsenseqa :  59%|█████▉    | 59/100 [3:47:34<2:37:50, 230.98s/it]Evaluating commonsenseqa :   4%|▍         | 4/100 [13:31<5:23:28, 202.17s/it]Evaluating commonsenseqa :  58%|█████▊    | 58/100 [2:54:57<2:07:49, 182.61s/it]Evaluating commonsenseqa :  60%|██████    | 60/100 [3:51:26<2:34:08, 231.21s/it]Evaluating commonsenseqa :  59%|█████▉    | 59/100 [2:58:02<2:05:10, 183.19s/it]Evaluating commonsenseqa :   5%|▌         | 5/100 [16:56<5:21:26, 203.02s/it]Evaluating commonsenseqa :  61%|██████    | 61/100 [3:55:16<2:30:03, 230.86s/it]Evaluating commonsenseqa :  60%|██████    | 60/100 [3:01:05<2:02:11, 183.28s/it]Evaluating commonsenseqa :   6%|▌         | 6/100 [20:21<5:19:12, 203.75s/it]Evaluating commonsenseqa :  61%|██████    | 61/100 [3:04:05<1:58:32, 182.36s/it]Evaluating commonsenseqa :  62%|██████▏   | 62/100 [3:59:07<2:26:19, 231.03s/it]Evaluating commonsenseqa :   7%|▋         | 7/100 [23:47<5:16:47, 204.38s/it]Evaluating commonsenseqa :  62%|██████▏   | 62/100 [3:07:10<1:55:54, 183.02s/it]Evaluating commonsenseqa :  63%|██████▎   | 63/100 [4:01:56<2:10:56, 212.35s/it]Evaluating commonsenseqa :   8%|▊         | 8/100 [27:06<5:10:41, 202.62s/it]Evaluating commonsenseqa :  63%|██████▎   | 63/100 [3:10:10<1:52:17, 182.09s/it]Evaluating commonsenseqa :  64%|██████▍   | 64/100 [4:05:50<2:11:16, 218.78s/it]Evaluating commonsenseqa :   9%|▉         | 9/100 [30:32<5:09:08, 203.83s/it]Evaluating commonsenseqa :  64%|██████▍   | 64/100 [3:13:10<1:48:53, 181.49s/it]Evaluating commonsenseqa :  65%|██████▌   | 65/100 [4:09:40<2:09:33, 222.10s/it]Evaluating commonsenseqa :  10%|█         | 10/100 [33:59<5:06:57, 204.63s/it]Evaluating commonsenseqa :  65%|██████▌   | 65/100 [3:16:08<1:45:18, 180.53s/it]Evaluating commonsenseqa :  11%|█         | 11/100 [37:26<5:04:43, 205.43s/it]Evaluating commonsenseqa :  66%|██████▌   | 66/100 [3:19:06<1:41:53, 179.81s/it]Evaluating commonsenseqa :  66%|██████▌   | 66/100 [4:13:35<2:08:04, 226.02s/it]Evaluating commonsenseqa :  67%|██████▋   | 67/100 [3:22:08<1:39:15, 180.46s/it]Evaluating commonsenseqa :  12%|█▏        | 12/100 [40:49<5:00:14, 204.71s/it]Evaluating commonsenseqa :  67%|██████▋   | 67/100 [4:17:26<2:05:12, 227.66s/it]Evaluating commonsenseqa :  68%|██████▊   | 68/100 [3:25:10<1:36:28, 180.88s/it]Evaluating commonsenseqa :  13%|█▎        | 13/100 [44:12<4:56:15, 204.31s/it]Evaluating commonsenseqa :  68%|██████▊   | 68/100 [4:21:16<2:01:46, 228.33s/it]Evaluating commonsenseqa :  69%|██████▉   | 69/100 [3:28:10<1:33:22, 180.72s/it]Evaluating commonsenseqa :  14%|█▍        | 14/100 [47:34<4:51:47, 203.58s/it]Evaluating commonsenseqa :  69%|██████▉   | 69/100 [4:25:09<1:58:39, 229.67s/it]Evaluating commonsenseqa :  70%|███████   | 70/100 [3:31:13<1:30:39, 181.30s/it]Evaluating commonsenseqa :  15%|█▌        | 15/100 [50:52<4:45:59, 201.87s/it]Evaluating commonsenseqa :  71%|███████   | 71/100 [3:34:17<1:28:01, 182.12s/it]Evaluating commonsenseqa :  70%|███████   | 70/100 [4:29:07<1:56:06, 232.20s/it]Evaluating commonsenseqa :  16%|█▌        | 16/100 [54:13<4:42:11, 201.56s/it]Evaluating commonsenseqa :  72%|███████▏  | 72/100 [3:37:21<1:25:09, 182.49s/it]Evaluating commonsenseqa :  71%|███████   | 71/100 [4:33:03<1:52:43, 233.24s/it]Evaluating commonsenseqa :  17%|█▋        | 17/100 [57:35<4:39:00, 201.69s/it]Evaluating commonsenseqa :  73%|███████▎  | 73/100 [3:40:22<1:21:55, 182.06s/it]Evaluating commonsenseqa :  18%|█▊        | 18/100 [1:00:56<4:35:26, 201.54s/it]Evaluating commonsenseqa :  72%|███████▏  | 72/100 [4:37:00<1:49:24, 234.43s/it]Evaluating commonsenseqa :  74%|███████▍  | 74/100 [3:43:26<1:19:09, 182.68s/it]Evaluating commonsenseqa :  19%|█▉        | 19/100 [1:04:17<4:31:44, 201.30s/it]Evaluating commonsenseqa :  73%|███████▎  | 73/100 [4:40:53<1:45:22, 234.15s/it]Evaluating commonsenseqa :  75%|███████▌  | 75/100 [3:46:29<1:16:10, 182.83s/it]Evaluating commonsenseqa :  20%|██        | 20/100 [1:07:39<4:28:32, 201.41s/it]Evaluating commonsenseqa :  76%|███████▌  | 76/100 [3:49:29<1:12:46, 181.95s/it]Evaluating commonsenseqa :  74%|███████▍  | 74/100 [4:44:47<1:41:21, 233.92s/it]Evaluating commonsenseqa :  21%|██        | 21/100 [1:10:57<4:24:01, 200.53s/it]Evaluating commonsenseqa :  77%|███████▋  | 77/100 [3:52:30<1:09:40, 181.76s/it]Evaluating commonsenseqa :  75%|███████▌  | 75/100 [4:48:38<1:37:09, 233.20s/it]Evaluating commonsenseqa :  22%|██▏       | 22/100 [1:13:34<4:03:44, 187.50s/it]Evaluating commonsenseqa :  78%|███████▊  | 78/100 [3:55:38<1:07:22, 183.74s/it]Evaluating commonsenseqa :  76%|███████▌  | 76/100 [4:52:35<1:33:43, 234.32s/it]Evaluating commonsenseqa :  23%|██▎       | 23/100 [1:17:00<4:07:47, 193.09s/it]Evaluating commonsenseqa :  79%|███████▉  | 79/100 [3:58:38<1:03:50, 182.39s/it]Evaluating commonsenseqa :  80%|████████  | 80/100 [4:01:40<1:00:47, 182.36s/it]Evaluating commonsenseqa :  24%|██▍       | 24/100 [1:20:25<4:09:10, 196.72s/it]Evaluating commonsenseqa :  77%|███████▋  | 77/100 [4:56:25<1:29:15, 232.86s/it]Evaluating commonsenseqa :  81%|████████  | 81/100 [4:04:42<57:41, 182.18s/it]  Evaluating commonsenseqa :  25%|██▌       | 25/100 [1:23:47<4:07:44, 198.19s/it]Evaluating commonsenseqa :  78%|███████▊  | 78/100 [5:00:20<1:25:39, 233.60s/it]Evaluating commonsenseqa :  82%|████████▏ | 82/100 [4:07:44<54:42, 182.35s/it]Evaluating commonsenseqa :  26%|██▌       | 26/100 [1:27:08<4:05:33, 199.11s/it]Evaluating commonsenseqa :  79%|███████▉  | 79/100 [5:04:14<1:21:45, 233.59s/it]Evaluating commonsenseqa :  83%|████████▎ | 83/100 [4:10:44<51:26, 181.53s/it]Evaluating commonsenseqa :  27%|██▋       | 27/100 [1:30:28<4:02:26, 199.27s/it]Evaluating commonsenseqa :  80%|████████  | 80/100 [5:08:07<1:17:52, 233.61s/it]Evaluating commonsenseqa :  84%|████████▍ | 84/100 [4:13:48<48:36, 182.27s/it]Evaluating commonsenseqa :  28%|██▊       | 28/100 [1:33:53<4:01:03, 200.88s/it]Evaluating commonsenseqa :  85%|████████▌ | 85/100 [4:16:50<45:31, 182.12s/it]Evaluating commonsenseqa :  81%|████████  | 81/100 [5:11:59<1:13:48, 233.05s/it]Evaluating commonsenseqa :  29%|██▉       | 29/100 [1:37:15<3:58:09, 201.27s/it]Evaluating commonsenseqa :  86%|████████▌ | 86/100 [4:19:53<42:35, 182.53s/it]Evaluating commonsenseqa :  82%|████████▏ | 82/100 [5:15:47<1:09:29, 231.65s/it]Evaluating commonsenseqa :  30%|███       | 30/100 [1:40:37<3:55:08, 201.55s/it]Evaluating commonsenseqa :  87%|████████▋ | 87/100 [4:22:54<39:25, 181.95s/it]Evaluating commonsenseqa :  83%|████████▎ | 83/100 [5:19:34<1:05:11, 230.07s/it]Evaluating commonsenseqa :  31%|███       | 31/100 [1:43:59<3:51:56, 201.68s/it]Evaluating commonsenseqa :  88%|████████▊ | 88/100 [4:25:53<36:13, 181.13s/it]Evaluating commonsenseqa :  32%|███▏      | 32/100 [1:47:20<3:48:13, 201.38s/it]Evaluating commonsenseqa :  89%|████████▉ | 89/100 [4:28:55<33:15, 181.39s/it]Evaluating commonsenseqa :  84%|████████▍ | 84/100 [5:23:30<1:01:51, 231.94s/it]Evaluating commonsenseqa :  90%|█████████ | 90/100 [4:31:57<30:14, 181.49s/it]Evaluating commonsenseqa :  33%|███▎      | 33/100 [1:50:39<3:44:10, 200.76s/it]Evaluating commonsenseqa :  85%|████████▌ | 85/100 [5:27:27<58:19, 233.32s/it]  Evaluating commonsenseqa :  91%|█████████ | 91/100 [4:35:01<27:19, 182.19s/it]Evaluating commonsenseqa :  34%|███▍      | 34/100 [1:53:59<3:40:32, 200.49s/it]Evaluating commonsenseqa :  86%|████████▌ | 86/100 [5:31:22<54:34, 233.87s/it]Evaluating commonsenseqa :  92%|█████████▏| 92/100 [4:38:02<24:15, 181.93s/it]Evaluating commonsenseqa :  35%|███▌      | 35/100 [1:57:20<3:37:18, 200.60s/it]Evaluating commonsenseqa :  93%|█████████▎| 93/100 [4:39:45<18:26, 158.10s/it]Evaluating commonsenseqa :  87%|████████▋ | 87/100 [5:35:16<50:43, 234.10s/it]Evaluating commonsenseqa :  36%|███▌      | 36/100 [2:00:43<3:34:49, 201.40s/it]Evaluating commonsenseqa :  94%|█████████▍| 94/100 [4:42:45<16:29, 164.84s/it]Evaluating commonsenseqa :  88%|████████▊ | 88/100 [5:39:11<46:51, 234.32s/it]Evaluating commonsenseqa :  37%|███▋      | 37/100 [2:04:06<3:31:54, 201.82s/it]Evaluating commonsenseqa :  95%|█████████▌| 95/100 [4:45:44<14:05, 169.16s/it]Evaluating commonsenseqa :  89%|████████▉ | 89/100 [5:43:04<42:53, 233.93s/it]Evaluating commonsenseqa :  96%|█████████▌| 96/100 [4:48:48<11:33, 173.41s/it]Evaluating commonsenseqa :  38%|███▊      | 38/100 [2:07:31<3:29:30, 202.75s/it]Evaluating commonsenseqa :  97%|█████████▋| 97/100 [4:51:48<08:46, 175.41s/it]Evaluating commonsenseqa :  39%|███▉      | 39/100 [2:10:54<3:26:09, 202.78s/it]Evaluating commonsenseqa :  90%|█████████ | 90/100 [5:46:58<39:00, 234.03s/it]Evaluating commonsenseqa :  98%|█████████▊| 98/100 [4:54:51<05:55, 177.75s/it]Evaluating commonsenseqa :  40%|████      | 40/100 [2:14:15<3:22:16, 202.28s/it]Evaluating commonsenseqa :  91%|█████████ | 91/100 [5:50:48<34:55, 232.78s/it]Evaluating commonsenseqa :  99%|█████████▉| 99/100 [4:57:46<02:56, 176.79s/it]Evaluating commonsenseqa :  41%|████      | 41/100 [2:17:37<3:19:00, 202.38s/it]Evaluating commonsenseqa :  92%|█████████▏| 92/100 [5:54:46<31:15, 234.39s/it]Evaluating commonsenseqa : 100%|██████████| 100/100 [5:00:45<00:00, 177.61s/it]Evaluating commonsenseqa : 100%|██████████| 100/100 [5:00:45<00:00, 180.46s/it]
name: commonsenseqa | avg. gen lenth: 275.942 | time: 18047.472161769867s
Evaluating commonsenseqa :  42%|████▏     | 42/100 [2:21:06<3:17:22, 204.18s/it]Evaluating commonsenseqa :  93%|█████████▎| 93/100 [5:58:34<27:06, 232.31s/it]Evaluating commonsenseqa :  43%|████▎     | 43/100 [2:24:25<3:12:43, 202.86s/it]Evaluating commonsenseqa :  94%|█████████▍| 94/100 [6:02:31<23:22, 233.78s/it]Evaluating commonsenseqa :  44%|████▍     | 44/100 [2:27:43<3:07:51, 201.28s/it]Evaluating commonsenseqa :  95%|█████████▌| 95/100 [6:06:24<19:27, 233.55s/it]Evaluating commonsenseqa :  45%|████▌     | 45/100 [2:31:05<3:04:40, 201.46s/it]Evaluating commonsenseqa :  46%|████▌     | 46/100 [2:34:26<3:01:06, 201.24s/it]Evaluating commonsenseqa :  96%|█████████▌| 96/100 [6:10:18<15:34, 233.71s/it]Evaluating commonsenseqa :  47%|████▋     | 47/100 [2:37:41<2:56:14, 199.51s/it]Evaluating commonsenseqa :  97%|█████████▋| 97/100 [6:14:13<11:42, 234.05s/it]Evaluating commonsenseqa :  48%|████▊     | 48/100 [2:41:00<2:52:42, 199.29s/it]Evaluating commonsenseqa :  98%|█████████▊| 98/100 [6:18:09<07:49, 234.57s/it]Evaluating commonsenseqa :  49%|████▉     | 49/100 [2:44:28<2:51:38, 201.94s/it]Evaluating commonsenseqa :  99%|█████████▉| 99/100 [6:21:58<03:52, 232.83s/it]Evaluating commonsenseqa :  50%|█████     | 50/100 [2:47:51<2:48:33, 202.28s/it]Evaluating commonsenseqa : 100%|██████████| 100/100 [6:25:47<00:00, 231.87s/it]Evaluating commonsenseqa : 100%|██████████| 100/100 [6:25:47<00:00, 231.48s/it]
name: commonsenseqa | avg. gen lenth: 263.761 | time: 23149.351320505142s
Evaluating commonsenseqa :  51%|█████     | 51/100 [2:51:12<2:44:55, 201.94s/it]Evaluating commonsenseqa :  52%|█████▏    | 52/100 [2:54:30<2:40:37, 200.78s/it]Evaluating commonsenseqa :  53%|█████▎    | 53/100 [2:56:25<2:17:08, 175.07s/it]Evaluating commonsenseqa :  54%|█████▍    | 54/100 [2:59:41<2:19:03, 181.39s/it]Evaluating commonsenseqa :  55%|█████▌    | 55/100 [3:03:00<2:19:57, 186.60s/it]Evaluating commonsenseqa :  56%|█████▌    | 56/100 [3:06:17<2:18:58, 189.50s/it]Evaluating commonsenseqa :  57%|█████▋    | 57/100 [3:09:37<2:18:10, 192.81s/it]Evaluating commonsenseqa :  58%|█████▊    | 58/100 [3:13:02<2:17:28, 196.39s/it]Evaluating commonsenseqa :  59%|█████▉    | 59/100 [3:16:21<2:14:46, 197.23s/it]Evaluating commonsenseqa :  60%|██████    | 60/100 [3:19:45<2:12:51, 199.29s/it]Evaluating commonsenseqa :  61%|██████    | 61/100 [3:23:10<2:10:34, 200.88s/it]Evaluating commonsenseqa :  62%|██████▏   | 62/100 [3:26:34<2:07:50, 201.85s/it]Evaluating commonsenseqa :  63%|██████▎   | 63/100 [3:29:57<2:04:40, 202.18s/it]Evaluating commonsenseqa :  64%|██████▍   | 64/100 [3:33:18<2:01:08, 201.90s/it]Evaluating commonsenseqa :  65%|██████▌   | 65/100 [3:36:38<1:57:22, 201.22s/it]Evaluating commonsenseqa :  66%|██████▌   | 66/100 [3:39:58<1:53:50, 200.89s/it]Evaluating commonsenseqa :  67%|██████▋   | 67/100 [3:43:20<1:50:38, 201.17s/it]Evaluating commonsenseqa :  68%|██████▊   | 68/100 [3:46:37<1:46:40, 200.01s/it]Evaluating commonsenseqa :  69%|██████▉   | 69/100 [3:49:58<1:43:28, 200.27s/it]Evaluating commonsenseqa :  70%|███████   | 70/100 [3:53:14<1:39:36, 199.21s/it]Evaluating commonsenseqa :  71%|███████   | 71/100 [3:56:39<1:37:01, 200.75s/it]Evaluating commonsenseqa :  72%|███████▏  | 72/100 [4:00:00<1:33:47, 200.98s/it]Evaluating commonsenseqa :  73%|███████▎  | 73/100 [4:03:21<1:30:25, 200.96s/it]Evaluating commonsenseqa :  74%|███████▍  | 74/100 [4:06:45<1:27:25, 201.73s/it]Evaluating commonsenseqa :  75%|███████▌  | 75/100 [4:10:08<1:24:10, 202.03s/it]Evaluating commonsenseqa :  76%|███████▌  | 76/100 [4:13:30<1:20:55, 202.31s/it]Evaluating commonsenseqa :  77%|███████▋  | 77/100 [4:16:49<1:17:09, 201.29s/it]Evaluating commonsenseqa :  78%|███████▊  | 78/100 [4:20:11<1:13:53, 201.50s/it]Evaluating commonsenseqa :  79%|███████▉  | 79/100 [4:23:11<1:08:14, 194.99s/it]Evaluating commonsenseqa :  80%|████████  | 80/100 [4:26:33<1:05:41, 197.06s/it]Evaluating commonsenseqa :  81%|████████  | 81/100 [4:29:49<1:02:20, 196.84s/it]Evaluating commonsenseqa :  82%|████████▏ | 82/100 [4:33:11<59:29, 198.33s/it]  Evaluating commonsenseqa :  83%|████████▎ | 83/100 [4:36:35<56:37, 199.83s/it]Evaluating commonsenseqa :  84%|████████▍ | 84/100 [4:39:58<53:36, 201.03s/it]Evaluating commonsenseqa :  85%|████████▌ | 85/100 [4:43:20<50:17, 201.18s/it]Evaluating commonsenseqa :  86%|████████▌ | 86/100 [4:46:39<46:49, 200.70s/it]Evaluating commonsenseqa :  87%|████████▋ | 87/100 [4:50:04<43:44, 201.89s/it]Evaluating commonsenseqa :  88%|████████▊ | 88/100 [4:53:28<40:30, 202.58s/it]Evaluating commonsenseqa :  89%|████████▉ | 89/100 [4:56:49<37:01, 201.96s/it]Evaluating commonsenseqa :  90%|█████████ | 90/100 [5:00:13<33:44, 202.47s/it]Evaluating commonsenseqa :  91%|█████████ | 91/100 [5:03:31<30:12, 201.39s/it]Evaluating commonsenseqa :  92%|█████████▏| 92/100 [5:06:50<26:44, 200.61s/it]Evaluating commonsenseqa :  93%|█████████▎| 93/100 [5:10:14<23:30, 201.51s/it]Evaluating commonsenseqa :  94%|█████████▍| 94/100 [5:13:31<20:00, 200.10s/it]Evaluating commonsenseqa :  95%|█████████▌| 95/100 [5:16:52<16:42, 200.45s/it]Evaluating commonsenseqa :  96%|█████████▌| 96/100 [5:20:12<13:21, 200.44s/it]Evaluating commonsenseqa :  97%|█████████▋| 97/100 [5:23:31<09:59, 199.80s/it]Evaluating commonsenseqa :  98%|█████████▊| 98/100 [5:26:49<06:38, 199.40s/it]Evaluating commonsenseqa :  99%|█████████▉| 99/100 [5:30:11<03:20, 200.22s/it]Evaluating commonsenseqa : 100%|██████████| 100/100 [5:33:31<00:00, 200.19s/it]Evaluating commonsenseqa : 100%|██████████| 100/100 [5:33:31<00:00, 200.12s/it]
name: commonsenseqa | avg. gen lenth: 266.145 | time: 20013.565309762955s
