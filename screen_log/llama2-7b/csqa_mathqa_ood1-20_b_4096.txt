WORLD_SIZE=1
MASTER_ADDR=ia1
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10136 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o17-tmathqa-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 17 17 19 True False 4096 5
WORLD_SIZE=1
MASTER_ADDR=ia1
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10137 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tmathqa-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 1 1 3 True False 4096 5
WORLD_SIZE=1
MASTER_ADDR=ia1
WORLD_SIZE=1
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10139 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o9-tmathqa-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 9 9 11 True False 4096 5
MASTER_ADDR=ia1
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10140 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o13-tmathqa-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 13 13 15 True False 4096 5
WORLD_SIZE=1
MASTER_ADDR=ia1
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10138 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o5-tmathqa-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 5 5 7 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2023-09-19 18:56:47,860] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
[2023-09-19 18:56:49,927] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o17-tmathqa-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 17
  out_domain_data_name ......... mathqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o17-tmathqa-s1-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
[2023-09-19 18:56:49,980] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-19 18:56:50,230] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-19 18:56:50,230] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 255075.48it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]using world size: 1
Answers already exist, exiting...
using world size: 1
Answers already exist, exiting...
using world size: 1
Answers already exist, exiting...
using world size: 1
Answers already exist, exiting...
Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.33s/it]python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10139 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o11-tmathqa-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 11 9 11 True False 4096 5
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10140 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o15-tmathqa-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 15 13 15 True False 4096 5
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10138 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o7-tmathqa-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 7 5 7 True False 4096 5
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10137 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o3-tmathqa-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 3 1 3 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.94s/it]
 > number of parameters: 6738415616
[2023-09-19 18:57:00,676] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.3, git-hash=unknown, git-branch=unknown
[2023-09-19 18:57:00,676] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-09-19 18:57:01,004] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-19 18:57:01,005] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2023-09-19 18:57:01,005] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-19 18:57:01,005] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-19 18:57:01,005] [INFO] [config.py:971:print]   amp_enabled .................. False
[2023-09-19 18:57:01,005] [INFO] [config.py:971:print]   amp_params ................... False
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fcae1a0ada0>
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   communication_data_type ...... None
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   disable_allgather ............ False
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   dump_state ................... False
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   global_rank .................. 0
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   gradient_clipping ............ 0.0
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 2048
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   loss_scale ................... 0
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   optimizer_name ............... None
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   optimizer_params ............. None
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-19 18:57:01,006] [INFO] [config.py:971:print]   pld_enabled .................. False
[2023-09-19 18:57:01,007] [INFO] [config.py:971:print]   pld_params ................... False
[2023-09-19 18:57:01,007] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2023-09-19 18:57:01,007] [INFO] [config.py:971:print]   scheduler_name ............... None
[2023-09-19 18:57:01,007] [INFO] [config.py:971:print]   scheduler_params ............. None
[2023-09-19 18:57:01,007] [INFO] [config.py:971:print]   sparse_attention ............. None
[2023-09-19 18:57:01,007] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2023-09-19 18:57:01,007] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2023-09-19 18:57:01,007] [INFO] [config.py:971:print]   train_batch_size ............. 1
[2023-09-19 18:57:01,007] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  1
[2023-09-19 18:57:01,007] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2023-09-19 18:57:01,007] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2023-09-19 18:57:01,007] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2023-09-19 18:57:01,007] [INFO] [config.py:971:print]   world_size ................... 1
[2023-09-19 18:57:01,007] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  True
[2023-09-19 18:57:01,007] [INFO] [config.py:971:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2023-09-19 18:57:01,007] [INFO] [config.py:971:print]   zero_enabled ................. False
[2023-09-19 18:57:01,007] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-19 18:57:01,007] [INFO] [config.py:971:print]   zero_optimization_stage ...... 0
[2023-09-19 18:57:01,007] [INFO] [config.py:957:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/200 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: what is 12 percent of 80? a ) 11.21, b ) 9.6, c ) 8.66, d ) 12.23, e ) 13.1
Output: "we assume that 80 is 100 % assume'x'is value we looking for here, 80 = 100 % and x = 12 % therefore, 80 / x = 100 % / 12 % 80 / x = 8.33 x = 9.6 b"
So the final answer is b

Input: a and b started a business investing rs. 92,000 and rs 20,000 respectively. in what ratio the profit earned after 2 years be divided between a and b respectively? a ) 9 : 2, b ) 3 : 2, c ) 23 : 5, d ) 18 : 4, e ) 17 : 4
Output: a : b = 92000 : 20000 = 92 : 20 = 46 : 10 = 23 : 5 answer : c
So the final answer is c

Input: a merchant purchased a jacket for $ 60 and then determined a selling price that equalled the purchase price of the jacket plus a markup that was 20 percent of the selling price. during a sale, the merchant discounted the selling price by 20 percent and sold the jacket. what was the merchant ’ s gross profit on this sale? a ) $ 0, b ) $ 3, c ) $ 4, d ) $ 12, e ) $ 15
Output: "actual cost = $ 60 sp = actual cost + mark up = actual cost + 20 % sp = 60 * 100 / 80 on sale sp = 80 / 100 ( 60 * 100 / 80 ) = 60 gross profit = $ 0 answer is a"
So the final answer is a

Input: on a two - dimensional coordinate plane, the line q = x ^ 2 - x ^ 3 touches the x - axis in how many places? a ) 0, b ) 1, c ) 2, d ) 3, e ) 4
Output: "apparently it's q = x ^ 2 - x ^ 3 instead of q = x ^ 2 - q ^ 3. in this case : the x - intercept is the value ( s ) of x for q = 0. 0 = x ^ 2 - x ^ 3 ; 0 = x ^ 2 ( 1 - x ) ; x = 0 or x = 1. answer : c."
So the final answer is c

Input: angelo and isabella are both salespersons. in any given week, angelo makes $ 550 in base salary plus 8 percent of the portion of his sales above $ 3,000 for that week. isabella makes 10 percent of her total sales for any given week. for what amount of weekly sales would angelo and isabella earn the same amount of money? a ) 23,500, b ) 15,500, c ) 25,500, d ) 26,500, e ) 27,500
Output: "official solution : the problem asks for the amount of weekly sales it takes for angelo and isabella to earn the same amount of money. you can write an equation that sets angelo ’ s and isabella ’ s weekly earnings equal to each other, with x representing weekly sales. weekly earnings for each salesperson equal base salary plus commission. so angelo ’ s earnings are 550 + ( 0.08 ) ( x – 3,000 ), and isabella ’ s are 0.10 x. set up the equation and solve : 550 + ( 0.08 ) ( x – 3,000 ) = 0.10 x distribute the 0.08 : 550 + 0.08 x – 240 = 0.10 x combine terms and subtract 0.08 x from both sides : 310 = 0.02 x divide both sides by 0.02 : 15,500 = x your answer is b."
So the final answer is b

Input: find the total number of prime factors in the expression ( 4 ) ^ 11 x ( 7 ) ^ 5 x ( 11 ) ^ 3 a ) 26, b ) 22, c ) 25, d ) 30, e ) 29
Output: "( 4 ) ^ 11 x ( 7 ) ^ 5 x ( 11 ) ^ 3 = ( 2 x 2 ) ^ 11 x ( 7 ) ^ 5 x ( 11 ) ^ 3 = 2 ^ 11 x 2 ^ 11 x 7 ^ 5 x 11 ^ 3 = 2 ^ 22 x 7 ^ 5 x 11 ^ 3 total number of prime factors = ( 22 + 5 + 3 ) = 30. answer is d."
So the final answer is d

Input: the length of the bridge, which a train 140 m long and traveling at 45 km / hr can cross in 30 sec is? a ) 235, b ) 240, c ) 245, d ) 250, e ) 255
Output: "speed = 45 * 5 / 18 = 25 / 2 m / sec. time = 30 sec let the length of bridge be x meters. then, ( 140 + x ) / 30 = 25 / 2 x = 235 m. answer : option a"
So the final answer is a

Input: 360 metres long yard, 31 trees are palnted at equal distances, one tree being at each end of the yard. what is the distance between 2 consecutive trees a ) 10, b ) 12, c ) 14, d ) 16, e ) 17
Output: "31 trees have 30 gaps between them, required distance ( 360 / 30 ) = 12 b"
So the final answer is b

Input: a vessel of capacity 45 litres is fully filled with pure milk. nine litres of milk is removed from the vessel and replaced with water. nine litres of the solution thus formed is removed and replaced with water. find the quantity of pure milk in the final milk solution? a ) 28.8, b ) 72.9, c ) 38.3, d ) 78.3, e ) 79.3
Output: "explanation : let the initial quantity of milk in vessel be t litres. let us say y litres of the mixture is taken out and replaced by water for n times, alternatively. quantity of milk finally in the vessel is then given by [ ( t - y ) / t ] ^ n * t for the given problem, t = 45, y = 9 and n = 2. hence, quantity of milk finally in the vessel = [ ( 45 - 9 ) / 45 ] ^ 2 ( 45 ) = 28.8 litres. answer : option a"
So the final answer is a

Input: a certain telescope increases the visual range at a particular location from 90 kilometers to 150 kilometers. by what percent is the visual range increased by using the telescope? a ) 30 %, b ) 33 1 / 2 %, c ) 40 %, d ) 60 %, e ) 66 2 / 3 %
Output: "original visual range = 90 km new visual range = 150 km percent increase in the visual range by using the telescope = ( 150 - 90 ) / 90 * 100 % = 2 / 3 * 100 % = 66.67 % answer e"
So the final answer is e

Input: a bag contains 6 black and 3 white balls. one ball is drawn at random. what is the probability that the ball drawn is white? a ) 3 / 4, b ) 1 / 3, c ) 1 / 7, d ) 1 / 8, e ) 4 / 3
Output: "let number of balls = ( 6 + 3 ) = 9. number of white balls = 3. p ( drawing a white ball ) = 3 / 9 = 1 / 3. option b."
So the final answer is b

Input: rajat, vikas and abhishek are submitting questions in the ratio 7 : 3 : 2. if total number of questions submitted by them is 24. find the number of questions submitted by vikas. a ) 3, b ) 4, c ) 5, d ) 6, e ) 7
Output: explanation : number of questions submitted by vikas = ( 24 * 3 ) / ( 7 + 3 + 2 ) = 6 answer : d
So the final answer is d

Input: at a certain restaurant, the ratio of the number of cooks to the number of waiters is 3 to 8. when 12 more waiters are hired, the ratio of the number of cooks to the number of waiters changes to 1 to 4. how many cooks does the restaurant have? a ) 4, b ) 6, c ) 9, d ) 12, e ) 15
Output: originally there were 3 k cooks and 8 k waiters. the new ratio is 1 : 4 which equals 3 : 12. 12 k = 8 k + 12 k = 3 there are 9 cooks. the answer is c.
So the final answer is c

Input: if 7 ^ k + 7 ^ k = ( 7 ^ 9 ) ^ ( 7 ^ 9 ) - 7 ^ k, then k =? a ) 11 / 3, b ) 11 / 2, c ) 242, d ) 3 ^ 10, e ) 7 ^ 11 - 1
Output: "7 ^ k + 7 ^ k = ( 7 ^ 9 ) ^ 7 ^ 9 - 7 ^ k 7 * ( 7 ^ k ) = 7 ^ ( 49 * 7 ^ 9 ) = 7 ^ ( 7 ^ 2 * 7 ^ 9 ) = 7 ^ ( 7 ^ 11 ) 7 ^ k + 1 = 7 ^ ( 7 ^ 11 ) so k + 1 = 7 ^ 11 so k = 7 ^ 11 - 1 answer is e"
So the final answer is e

Input: average of 10 matches is 32, how many runs one should should score to increase his average by 4 runs. a ) 70, b ) 76, c ) 78, d ) 80, e ) 88
Output: "explanation : average after 11 innings should be 36 so, required score = ( 11 * 36 ) - ( 10 * 32 ) = 396 - 320 = 76 answer : option b"
So the final answer is b

Input: a ’ s speed is 20 / 19 times that of b. if a and b run a race, what part of the length of the race should a give b as a head start, so that the race ends in a dead heat? a ) 1 / 19, b ) 3 / 19, c ) 1 / 10, d ) 1 / 20, e ) 3 / 10
Output: "let d be the full distance. let x be the fraction of the distance that b runs. let v be the speed at which b runs. the time should be the same for both runners. time = d / ( 20 v / 19 ) = xd / v ( 19 / 20 ) * d / v = x * d / v x = 19 / 20 b should have a head start of 1 / 20 of the full distance. the answer is d."
So the final answer is d

Input: the length of a rectangular plot is 10 mtr more than its width. the cost of fencing the plot along its perimeter at the rate of rs. 6.5 mtr is rs. 2210. the perimeter of the plot is? a ) 126, b ) 156, c ) 340, d ) 321, e ) 260
Output: "sol. let width = x, length = ( 10 + x ) perimeter = 2 ( x + ( 10 + x ) ) = 2 ( 2 x = 10 ) & 2 ( 2 x + 10 ) * 6.5 = 2210 x = 80 required perimeter = 2 ( 80 + 90 ) = 340 c"
So the final answer is c

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o17-tmathqa-s1-rTrue-m4096
[2023-09-19 18:57:02,587] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-19 18:57:02,587] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-19 18:57:02,848] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-19 18:57:02,848] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
using world size: 1
Answers already exist, exiting...
Answers already exist, exiting...
using world size: 1using world size: 1

Answers already exist, exiting...Answers already exist, exiting...

python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10140 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o13-tmathqa-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 13 13 15 True False 4096 5
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10139 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o9-tmathqa-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 9 9 11 True False 4096 5
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10137 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tmathqa-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 1 1 3 True False 4096 5
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10138 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o5-tmathqa-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 5 5 7 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2023-09-19 18:57:15,213] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-19 18:57:15,213] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-19 18:57:15,482] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-19 18:57:15,482] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
using world size: 1
Answers already exist, exiting...
using world size: 1
Answers already exist, exiting...
using world size: 1
Answers already exist, exiting...
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10139 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o11-tmathqa-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 11 9 11 True False 4096 5
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10140 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o15-tmathqa-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 15 13 15 True False 4096 5
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10137 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o3-tmathqa-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 3 1 3 True False 4096 5
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10138 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o7-tmathqa-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 7 5 7 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2023-09-19 18:57:27,799] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-19 18:57:27,799] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-19 18:57:28,037] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-19 18:57:28,137] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
using world size: 1
Answers already exist, exiting...
Answers already exist, exiting...
using world size: 1
Answers already exist, exiting...
using world size: 1
Answers already exist, exiting...
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10140 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o13-tmathqa-s10-rTrue --seed 10 --max-prompt-length 4096 --rationales --num-out-domain 13 13 15 True False 4096 5
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10139 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o9-tmathqa-s10-rTrue --seed 10 --max-prompt-length 4096 --rationales --num-out-domain 9 9 11 True False 4096 5
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10137 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tmathqa-s10-rTrue --seed 10 --max-prompt-length 4096 --rationales --num-out-domain 1 1 3 True False 4096 5
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10138 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o5-tmathqa-s10-rTrue --seed 10 --max-prompt-length 4096 --rationales --num-out-domain 5 5 7 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2023-09-19 18:57:40,417] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-19 18:57:40,417] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-19 18:57:40,736] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-19 18:57:40,736] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
using world size: 1
Answers already exist, exiting...
using world size: 1
Answers already exist, exiting...
using world size: 1
Answers already exist, exiting...
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10139 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o11-tmathqa-s10-rTrue --seed 10 --max-prompt-length 4096 --rationales --num-out-domain 11 9 11 True False 4096 5
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10140 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o15-tmathqa-s10-rTrue --seed 10 --max-prompt-length 4096 --rationales --num-out-domain 15 13 15 True False 4096 5
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10137 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o3-tmathqa-s10-rTrue --seed 10 --max-prompt-length 4096 --rationales --num-out-domain 3 1 3 True False 4096 5
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10138 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o7-tmathqa-s10-rTrue --seed 10 --max-prompt-length 4096 --rationales --num-out-domain 7 5 7 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2023-09-19 18:57:52,910] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-19 18:57:52,910] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-19 18:57:53,368] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-19 18:57:53,368] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
using world size: 1
Answers already exist, exiting...
using world size: 1
using world size: 1
Answers already exist, exiting...
Answers already exist, exiting...
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10140 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o13-tmathqa-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 13 13 15 True False 4096 5
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10139 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o9-tmathqa-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 9 9 11 True False 4096 5
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10138 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o5-tmathqa-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 5 5 7 True False 4096 5
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10137 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tmathqa-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 1 1 3 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2023-09-19 18:58:05,477] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-19 18:58:05,531] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-19 18:58:05,907] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-19 18:58:05,942] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Evaluating commonsenseqa :   0%|          | 1/200 [01:07<3:43:24, 67.36s/it]using world size: 1
Answers already exist, exiting...
using world size: 1
Answers already exist, exiting...
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tmathqa-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 1
  out_domain_data_name ......... mathqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o1-tmathqa-s10-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
using world size: 1
Answers already exist, exiting...
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 1015755.05it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10139 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o11-tmathqa-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 11 9 11 True False 4096 5
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10140 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o15-tmathqa-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 15 13 15 True False 4096 5
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10138 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o7-tmathqa-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 7 5 7 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.35s/it][2023-09-19 18:58:18,272] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-19 18:58:18,298] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-19 18:58:18,430] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.73s/it]
 > number of parameters: 6738415616
[2023-09-19 18:58:21,214] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.3, git-hash=unknown, git-branch=unknown
[2023-09-19 18:58:21,215] [INFO] [comm.py:637:init_distributed] cdb=None
using world size: 1
Answers already exist, exiting...
using world size: 1
Answers already exist, exiting...
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o7-tmathqa-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 7
  out_domain_data_name ......... mathqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o7-tmathqa-s10-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
[2023-09-19 18:58:21,604] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-19 18:58:21,605] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2023-09-19 18:58:21,605] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   amp_enabled .................. False
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   amp_params ................... False
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f4f0c222d70>
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   communication_data_type ...... None
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   disable_allgather ............ False
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   dump_state ................... False
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   global_rank .................. 0
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   gradient_clipping ............ 0.0
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2023-09-19 18:58:21,606] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 2048
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   loss_scale ................... 0
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   optimizer_name ............... None
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   optimizer_params ............. None
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   pld_enabled .................. False
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   pld_params ................... False
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   scheduler_name ............... None
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   scheduler_params ............. None
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   sparse_attention ............. None
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   train_batch_size ............. 1
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  1
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   world_size ................... 1
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  True
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   zero_enabled ................. False
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-19 18:58:21,607] [INFO] [config.py:971:print]   zero_optimization_stage ...... 0
[2023-09-19 18:58:21,607] [INFO] [config.py:957:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/200 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: in a recent head - to - head run - off election, 12000 absentee ballets were cast. 1 / 6 of the absentee ballets were thrown out and 3 / 5 of the remaining absentee ballets were cast for candidate a. how many absentee votes did candidate b receive? a ) 2,000, b ) 3,000, c ) 4,000, d ) 8,000, e ) 9,000
Output: c

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o1-tmathqa-s10-rFalse-m4096
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 569233.23it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10139 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o9-tmathqa-s20-rTrue --seed 20 --max-prompt-length 4096 --rationales --num-out-domain 9 9 11 True False 4096 5
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10140 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o13-tmathqa-s20-rTrue --seed 20 --max-prompt-length 4096 --rationales --num-out-domain 13 13 15 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2023-09-19 18:58:30,886] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-19 18:58:30,907] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.29s/it]using world size: 1
Answers already exist, exiting...
using world size: 1
Answers already exist, exiting...
Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.27s/it]
 > number of parameters: 6738415616
[2023-09-19 18:58:34,950] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.3, git-hash=unknown, git-branch=unknown
[2023-09-19 18:58:34,950] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-09-19 18:58:35,409] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-19 18:58:35,411] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2023-09-19 18:58:35,412] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-19 18:58:35,412] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-19 18:58:35,412] [INFO] [config.py:971:print]   amp_enabled .................. False
[2023-09-19 18:58:35,412] [INFO] [config.py:971:print]   amp_params ................... False
[2023-09-19 18:58:35,412] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-19 18:58:35,412] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2023-09-19 18:58:35,412] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2023-09-19 18:58:35,412] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2023-09-19 18:58:35,412] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2023-09-19 18:58:35,412] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f5970c22d70>
[2023-09-19 18:58:35,412] [INFO] [config.py:971:print]   communication_data_type ...... None
[2023-09-19 18:58:35,412] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-19 18:58:35,412] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2023-09-19 18:58:35,412] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2023-09-19 18:58:35,412] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-19 18:58:35,412] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2023-09-19 18:58:35,412] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   disable_allgather ............ False
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   dump_state ................... False
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   global_rank .................. 0
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   gradient_clipping ............ 0.0
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 2048
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   loss_scale ................... 0
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   optimizer_name ............... None
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   optimizer_params ............. None
[2023-09-19 18:58:35,413] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-19 18:58:35,414] [INFO] [config.py:971:print]   pld_enabled .................. False
[2023-09-19 18:58:35,414] [INFO] [config.py:971:print]   pld_params ................... False
[2023-09-19 18:58:35,414] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2023-09-19 18:58:35,414] [INFO] [config.py:971:print]   scheduler_name ............... None
[2023-09-19 18:58:35,414] [INFO] [config.py:971:print]   scheduler_params ............. None
[2023-09-19 18:58:35,414] [INFO] [config.py:971:print]   sparse_attention ............. None
[2023-09-19 18:58:35,414] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2023-09-19 18:58:35,414] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2023-09-19 18:58:35,414] [INFO] [config.py:971:print]   train_batch_size ............. 1
[2023-09-19 18:58:35,414] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  1
[2023-09-19 18:58:35,414] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2023-09-19 18:58:35,414] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2023-09-19 18:58:35,414] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2023-09-19 18:58:35,414] [INFO] [config.py:971:print]   world_size ................... 1
[2023-09-19 18:58:35,414] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  True
[2023-09-19 18:58:35,414] [INFO] [config.py:971:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2023-09-19 18:58:35,414] [INFO] [config.py:971:print]   zero_enabled ................. False
[2023-09-19 18:58:35,414] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-19 18:58:35,414] [INFO] [config.py:971:print]   zero_optimization_stage ...... 0
[2023-09-19 18:58:35,414] [INFO] [config.py:957:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/200 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: in a recent head - to - head run - off election, 12000 absentee ballets were cast. 1 / 6 of the absentee ballets were thrown out and 3 / 5 of the remaining absentee ballets were cast for candidate a. how many absentee votes did candidate b receive? a ) 2,000, b ) 3,000, c ) 4,000, d ) 8,000, e ) 9,000
Output: c

Input: the total age of a and b is 11 years more than the total age of b and c. c is how many years younger than a.? a ) 16, b ) 12, c ) 11, d ) 20, e ) 10
Output: c

Input: the scoring system in a certain football competition goes as follows : 3 points for victory, 1 point for a draw, and 0 points for defeat. each team plays 20 matches. if a team scored 14 points after 5 games, what is the least number of the remaining matches it has to win to reach the 40 - point mark by the end of the tournament? a ) 6, b ) 7, c ) 8, d ) 9, e ) 10
Output: a

Input: how much water should be added to 10 liters of a 20 % - solution of alcohol to reduce the concentration of alcohol in the solution by 75 %? a ) 25 liters, b ) 27 liters, c ) 30 liters, d ) 32 liters, e ) 35 liters
Output: c

Input: a goods train runs at the speed of 72 kmph and crosses a 250 m long platform in 36 seconds. what is the length of the goods train? a ) 470 m, b ) 240 m, c ) 260 m, d ) 270 m, e ) none of these
Output: a

Input: the volume of a cube is 1728 cc. find its surface. a ) 864, b ) 556, c ) 255, d ) 287, e ) 267
Output: a

Input: a certain drink of type a is prepared by mixing 4 parts milk with 3 parts fruit juice. another drink of type b is prepared by mixing 4 parts of fruit juice and 3 parts of milk. how many liters of fruit juice must be added to 63 liters of drink a to convert it to drink b? a ) 7, b ) 14, c ) 21, d ) 28, e ) 35
Output: c

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o7-tmathqa-s10-rFalse-m4096
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10140 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o15-tmathqa-s20-rTrue --seed 20 --max-prompt-length 4096 --rationales --num-out-domain 15 13 15 True False 4096 5
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10139 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o11-tmathqa-s20-rTrue --seed 20 --max-prompt-length 4096 --rationales --num-out-domain 11 9 11 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2023-09-19 18:58:43,315] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-19 18:58:43,365] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o11-tmathqa-s20-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 11
  out_domain_data_name ......... mathqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o11-tmathqa-s20-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
using world size: 1
Answers already exist, exiting...
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 336915.36it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10140 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o13-tmathqa-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 13 13 15 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.20s/it][2023-09-19 18:58:55,899] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.67s/it]
 > number of parameters: 6738415616
[2023-09-19 18:58:58,715] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.3, git-hash=unknown, git-branch=unknown
[2023-09-19 18:58:58,715] [INFO] [comm.py:637:init_distributed] cdb=None
using world size: 1
Answers already exist, exiting...
[2023-09-19 18:58:59,123] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-19 18:58:59,126] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2023-09-19 18:58:59,126] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-19 18:58:59,126] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-19 18:58:59,126] [INFO] [config.py:971:print]   amp_enabled .................. False
[2023-09-19 18:58:59,126] [INFO] [config.py:971:print]   amp_params ................... False
[2023-09-19 18:58:59,127] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-19 18:58:59,127] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2023-09-19 18:58:59,127] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2023-09-19 18:58:59,127] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2023-09-19 18:58:59,127] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2023-09-19 18:58:59,127] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fc590632da0>
[2023-09-19 18:58:59,127] [INFO] [config.py:971:print]   communication_data_type ...... None
[2023-09-19 18:58:59,127] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-19 18:58:59,127] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2023-09-19 18:58:59,127] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2023-09-19 18:58:59,127] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-19 18:58:59,127] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2023-09-19 18:58:59,127] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2023-09-19 18:58:59,127] [INFO] [config.py:971:print]   disable_allgather ............ False
[2023-09-19 18:58:59,127] [INFO] [config.py:971:print]   dump_state ................... False
[2023-09-19 18:58:59,127] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-19 18:58:59,127] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2023-09-19 18:58:59,127] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-19 18:58:59,127] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-19 18:58:59,127] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2023-09-19 18:58:59,127] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2023-09-19 18:58:59,127] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2023-09-19 18:58:59,127] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2023-09-19 18:58:59,127] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2023-09-19 18:58:59,127] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   global_rank .................. 0
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   gradient_clipping ............ 0.0
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 2048
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   loss_scale ................... 0
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   optimizer_name ............... None
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   optimizer_params ............. None
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   pld_enabled .................. False
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   pld_params ................... False
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   scheduler_name ............... None
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   scheduler_params ............. None
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   sparse_attention ............. None
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   train_batch_size ............. 1
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  1
[2023-09-19 18:58:59,128] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2023-09-19 18:58:59,129] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2023-09-19 18:58:59,129] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2023-09-19 18:58:59,129] [INFO] [config.py:971:print]   world_size ................... 1
[2023-09-19 18:58:59,129] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  True
[2023-09-19 18:58:59,129] [INFO] [config.py:971:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2023-09-19 18:58:59,129] [INFO] [config.py:971:print]   zero_enabled ................. False
[2023-09-19 18:58:59,129] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-19 18:58:59,129] [INFO] [config.py:971:print]   zero_optimization_stage ...... 0
[2023-09-19 18:58:59,129] [INFO] [config.py:957:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/200 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: a man cycling along the road noticed that every 18 minutes a bus overtakes him and every 6 minutes he meets an oncoming bus. if all buses and the cyclist move at a constant speed, what is the time interval between consecutive buses? a ) 5 minutes, b ) 6 minutes, c ) 8 minutes, d ) 9 minutes, e ) 10 minutes
Output: let's say the distance between the buses is d. we want to determine interval = \ frac { d } { b }, where b is the speed of bus. let the speed of cyclist be c. every 18 minutes a bus overtakes cyclist : \ frac { d } { b - c } = 18, d = 18 b - 18 c ; every 6 minutes cyclist meets an oncoming bus : \ frac { d } { b + c } = 6, d = 6 b + 6 c ; d = 18 b - 18 c = 6 b + 6 c, - - > b = 2 c, - - > d = 18 b - 9 b = 9 b. interval = \ frac { d } { b } = \ frac { 9 b } { b } = 9 answer : d ( 9 minutes ).
So the final answer is d

Input: an athlete runs 200 metres race in 24 seconds. what is his speed? a ) 20 km / hr, b ) 30 km / hr, c ) 25 km / hr, d ) 35 km / hr, e ) 40 km / hr
Output: speed = dist / time = 200 / 24 200 / 24 * 18 / 5 = 40 * 3 / 4 = 30 km / hr answer b
So the final answer is b

Input: two numbers are in the ratio 3 : 4. if the sum of numbers is 63, find the numbers. a ) 27 and 36., b ) 25 and 30., c ) 23 and 44., d ) 63 and 12., e ) 12 and 36.
Output: "sum of the terms of the ratio = 3 + 4 = 7 sum of numbers = 63 therefore, first number = 3 / 7 × 63 = 27 second number = 4 / 7 × 63 = 36 therefore, the two numbers are 27 and 36. answer is a"
So the final answer is a

Input: a company wants to spend equal amounts of money for the purchase of two types of computer printers costing $ 375 and $ 150 per unit, respectively. what is the fewest number of computer printers that the company can purchase? a ) 3, b ) 4, c ) 5, d ) 6, e ) 7
Output: the smallest amount that the company can spend is the lcm of 375 and 150, which is 750 for each, which is total 1500. the number of 1 st type of computers which costing $ 375 = 750 / 375 = 2. the number of 2 nd type of computers which costing $ 150 = 750 / 150 = 5. total = 2 + 5 = 7 answer is e.
So the final answer is e

Input: a certain music store stocks 800 cellos and 600 violas. of these instruments, there are 80 cello - viola pairs, such that a cello and a viola were both made with wood from the same tree ( each tree can make at most one viola and one cello, so there are no pairs other than these 90 ). if one viola and one cello are chosen at random, what is the probability that the two instruments are made with wood from the same tree? a ) 3 / 16,000, b ) 1 / 8,100, c ) 1 / 600, d ) 1 / 90, e ) 2 / 45
Output: "solution provided by stanford 2012 is correct : 80 / 800 choosing one of the cellos which has a pair viola, 1 / 600 choosing the viola which is the pair of chosen cello - - > p = 80 / 800 * 1 / 600 = 1 / 6,000. answer : c."
So the final answer is c

Input: what is the difference between local value & face value of 7 in the numeral 65793? a ) 693, b ) 656, c ) 691, d ) 9890, e ) 10000
Output: ( local value of 7 ) - ( face value of 7 ) = ( 700 - 7 ) = 693 a
So the final answer is a

Input: in an office in singapore there are 60 % female employees. 50 % of all the male employees are computer literate. if there are total 62 % employees computer literate out of total 1100 employees, then the no. of female employees who are computer literate? a ) 462, b ) 674, c ) 672, d ) 960, e ) none
Output: "solution : total employees, = 1100 female employees, 60 % of 1100. = ( 60 * 1100 ) / 100 = 660. then male employees, = 440 50 % of male are computer literate, = 220 male computer literate. 62 % of total employees are computer literate, = ( 62 * 1100 ) / 100 = 682 computer literate. thus, female computer literate = 682 - 220 = 462. answer : option a"
So the final answer is a

Input: the cost price of 16 articles is the same as the selling price of 12 articles. find the loss / profit percentages. a ) 30 %, b ) 32.50 %, c ) 33 1 / 3 %, d ) 40 %, e ) 50 %
Output: "explanation : the gain is 4 out of 12 articles. therefore, gain percentage = 4 x 100 / 12 = 100 / 3 = 33 1 / 3 % answer : option c"
So the final answer is c

Input: mike drives his new corvette from san francisco to las vegas, a journey of 640 miles. he drives the first half of the trip at an average rate of 80 miles per hour, but has to slow down for the second half of his journey. if the second half of the trip takes him 200 percent longer than the first half, what is his average rate q in miles per hour for the entire trip? a ) q = 26.7, b ) q = 30.0, c ) q = 40.0, d ) q = 53.3, e ) q = 60.0
Output: "veritas prepofficial solution correct answer : c using the formula : time = distance / rate, we find that mike takes 4 hours to cover the first 320 miles of his trip. since the 2 nd 320 miles take 200 % longer than the first, it takes mike 8 hours longer, or 12 hours. ( note : 200 % longer than the first half is not 200 % of the first half. ) the overall time is 4 hours + 12 hours or 16 hours. since the definition of average rate = total distance traveled / total time of travel, mike's average rate = 640 / 16 or 40 miles per hour. answer choice c is correct."
So the final answer is c

Input: lisa and robert have taken the same number of photos on their school trip. lisa has taken 3 times as many photos as claire and robert has taken 20 more photos than claire. how many photos has claire taken? a ) 6, b ) 8, c ) 10, d ) 12, e ) 14
Output: "l = r l = 3 c r = c + 20 3 c = c + 20 c = 10 the answer is c."
So the final answer is c

Input: meena wrote all the numbers from 1 to 69,999 inclusive. how many digits did she write in total? a ) 278,889, b ) 308,889, c ) 338,889, d ) 368,889, e ) 398,889
Output: "1 - 9 = > 1 * 9 digits 10 - 99 = > 2 * 90 = 180 ( numbers between 10 - 99 is 90 where each has 2 digits ) 100 - 999 = > 3 * 900 = 2700 1000 - 9999 = > 4 * 9000 = 36,000 10000 - 69999 = > 5 * 60,000 = 300,000 the answer is 338,889 the answer is c."
So the final answer is c

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o11-tmathqa-s20-rTrue-m4096
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10140 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o15-tmathqa-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 15 13 15 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2023-09-19 18:59:07,926] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o15-tmathqa-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 15
  out_domain_data_name ......... mathqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o15-tmathqa-s20-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 372651.04it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Evaluating commonsenseqa :   1%|          | 2/200 [02:14<3:41:17, 67.06s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.19s/it]
 > number of parameters: 6738415616
[2023-09-19 18:59:24,205] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.3, git-hash=unknown, git-branch=unknown
[2023-09-19 18:59:24,206] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-09-19 18:59:24,649] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-19 18:59:24,652] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2023-09-19 18:59:24,652] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-19 18:59:24,652] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-19 18:59:24,653] [INFO] [config.py:971:print]   amp_enabled .................. False
[2023-09-19 18:59:24,653] [INFO] [config.py:971:print]   amp_params ................... False
[2023-09-19 18:59:24,653] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-19 18:59:24,653] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2023-09-19 18:59:24,653] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2023-09-19 18:59:24,653] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2023-09-19 18:59:24,653] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2023-09-19 18:59:24,653] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fe8ed406d70>
[2023-09-19 18:59:24,654] [INFO] [config.py:971:print]   communication_data_type ...... None
[2023-09-19 18:59:24,654] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-19 18:59:24,654] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2023-09-19 18:59:24,654] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2023-09-19 18:59:24,654] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-19 18:59:24,654] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2023-09-19 18:59:24,654] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2023-09-19 18:59:24,654] [INFO] [config.py:971:print]   disable_allgather ............ False
[2023-09-19 18:59:24,654] [INFO] [config.py:971:print]   dump_state ................... False
[2023-09-19 18:59:24,654] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-19 18:59:24,654] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2023-09-19 18:59:24,654] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-19 18:59:24,654] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-19 18:59:24,654] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2023-09-19 18:59:24,654] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2023-09-19 18:59:24,654] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2023-09-19 18:59:24,654] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2023-09-19 18:59:24,654] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2023-09-19 18:59:24,654] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2023-09-19 18:59:24,654] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-19 18:59:24,654] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2023-09-19 18:59:24,654] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2023-09-19 18:59:24,654] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2023-09-19 18:59:24,654] [INFO] [config.py:971:print]   global_rank .................. 0
[2023-09-19 18:59:24,654] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2023-09-19 18:59:24,654] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2023-09-19 18:59:24,655] [INFO] [config.py:971:print]   gradient_clipping ............ 0.0
[2023-09-19 18:59:24,655] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2023-09-19 18:59:24,655] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-19 18:59:24,655] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 2048
[2023-09-19 18:59:24,655] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2023-09-19 18:59:24,655] [INFO] [config.py:971:print]   loss_scale ................... 0
[2023-09-19 18:59:24,655] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2023-09-19 18:59:24,655] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2023-09-19 18:59:24,655] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2023-09-19 18:59:24,655] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-19 18:59:24,655] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-19 18:59:24,655] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2023-09-19 18:59:24,655] [INFO] [config.py:971:print]   optimizer_name ............... None
[2023-09-19 18:59:24,655] [INFO] [config.py:971:print]   optimizer_params ............. None
[2023-09-19 18:59:24,655] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-19 18:59:24,655] [INFO] [config.py:971:print]   pld_enabled .................. False
[2023-09-19 18:59:24,655] [INFO] [config.py:971:print]   pld_params ................... False
[2023-09-19 18:59:24,655] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2023-09-19 18:59:24,655] [INFO] [config.py:971:print]   scheduler_name ............... None
[2023-09-19 18:59:24,655] [INFO] [config.py:971:print]   scheduler_params ............. None
[2023-09-19 18:59:24,655] [INFO] [config.py:971:print]   sparse_attention ............. None
[2023-09-19 18:59:24,655] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2023-09-19 18:59:24,655] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2023-09-19 18:59:24,656] [INFO] [config.py:971:print]   train_batch_size ............. 1
[2023-09-19 18:59:24,656] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  1
[2023-09-19 18:59:24,656] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2023-09-19 18:59:24,656] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2023-09-19 18:59:24,656] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2023-09-19 18:59:24,656] [INFO] [config.py:971:print]   world_size ................... 1
[2023-09-19 18:59:24,656] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  True
[2023-09-19 18:59:24,656] [INFO] [config.py:971:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2023-09-19 18:59:24,656] [INFO] [config.py:971:print]   zero_enabled ................. False
[2023-09-19 18:59:24,656] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-19 18:59:24,656] [INFO] [config.py:971:print]   zero_optimization_stage ...... 0
[2023-09-19 18:59:24,656] [INFO] [config.py:957:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/200 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: a man cycling along the road noticed that every 18 minutes a bus overtakes him and every 6 minutes he meets an oncoming bus. if all buses and the cyclist move at a constant speed, what is the time interval between consecutive buses? a ) 5 minutes, b ) 6 minutes, c ) 8 minutes, d ) 9 minutes, e ) 10 minutes
Output: d

Input: an athlete runs 200 metres race in 24 seconds. what is his speed? a ) 20 km / hr, b ) 30 km / hr, c ) 25 km / hr, d ) 35 km / hr, e ) 40 km / hr
Output: b

Input: two numbers are in the ratio 3 : 4. if the sum of numbers is 63, find the numbers. a ) 27 and 36., b ) 25 and 30., c ) 23 and 44., d ) 63 and 12., e ) 12 and 36.
Output: a

Input: a company wants to spend equal amounts of money for the purchase of two types of computer printers costing $ 375 and $ 150 per unit, respectively. what is the fewest number of computer printers that the company can purchase? a ) 3, b ) 4, c ) 5, d ) 6, e ) 7
Output: e

Input: a certain music store stocks 800 cellos and 600 violas. of these instruments, there are 80 cello - viola pairs, such that a cello and a viola were both made with wood from the same tree ( each tree can make at most one viola and one cello, so there are no pairs other than these 90 ). if one viola and one cello are chosen at random, what is the probability that the two instruments are made with wood from the same tree? a ) 3 / 16,000, b ) 1 / 8,100, c ) 1 / 600, d ) 1 / 90, e ) 2 / 45
Output: c

Input: what is the difference between local value & face value of 7 in the numeral 65793? a ) 693, b ) 656, c ) 691, d ) 9890, e ) 10000
Output: a

Input: in an office in singapore there are 60 % female employees. 50 % of all the male employees are computer literate. if there are total 62 % employees computer literate out of total 1100 employees, then the no. of female employees who are computer literate? a ) 462, b ) 674, c ) 672, d ) 960, e ) none
Output: a

Input: the cost price of 16 articles is the same as the selling price of 12 articles. find the loss / profit percentages. a ) 30 %, b ) 32.50 %, c ) 33 1 / 3 %, d ) 40 %, e ) 50 %
Output: c

Input: mike drives his new corvette from san francisco to las vegas, a journey of 640 miles. he drives the first half of the trip at an average rate of 80 miles per hour, but has to slow down for the second half of his journey. if the second half of the trip takes him 200 percent longer than the first half, what is his average rate q in miles per hour for the entire trip? a ) q = 26.7, b ) q = 30.0, c ) q = 40.0, d ) q = 53.3, e ) q = 60.0
Output: c

Input: lisa and robert have taken the same number of photos on their school trip. lisa has taken 3 times as many photos as claire and robert has taken 20 more photos than claire. how many photos has claire taken? a ) 6, b ) 8, c ) 10, d ) 12, e ) 14
Output: c

Input: meena wrote all the numbers from 1 to 69,999 inclusive. how many digits did she write in total? a ) 278,889, b ) 308,889, c ) 338,889, d ) 368,889, e ) 398,889
Output: c

Input: a pipe takes a hours to fill the tank. but because of a leakage it took 2 times of its original time. find the time taken by the leakage to empty the tank a ) 50 min, b ) 60 min, c ) 90 min, d ) 80 min, e ) 120 min
Output: e

Input: if x is an integer such that 0 < x < 7, 0 < x < 15, 5 > x > – 1, 3 > x > 0, and x + 2 < 4, then x is a ) 1, b ) 2, c ) 3, d ) 4, e ) 5
Output: a

Input: a and b put in rs. 200 and rs. 400 respectively into a business. a reinvests into the business his share of the first year's profit of rs. 210 where as b does not. in what ratio should they divide the second year's profit? a ) 39 : 40, b ) 39 : 49, c ) 39 : 42, d ) 39 : 47, e ) 17 : 20
Output: e

Input: what least number must be subtracted from 427398 so that remaining no. is divisible by 10 a ) 3, b ) 5, c ) 6, d ) 7, e ) 8
Output: e

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o15-tmathqa-s20-rFalse-m4096
Evaluating commonsenseqa :   0%|          | 1/200 [00:35<1:58:21, 35.69s/it]Evaluating commonsenseqa :   2%|▏         | 3/200 [03:20<3:39:30, 66.86s/it]Evaluating commonsenseqa :   0%|          | 1/200 [01:25<4:43:32, 85.49s/it]Evaluating commonsenseqa :   0%|          | 1/200 [02:08<7:06:46, 128.68s/it]Evaluating commonsenseqa :   0%|          | 1/200 [02:27<8:09:29, 147.59s/it]Evaluating commonsenseqa :   2%|▏         | 4/200 [04:27<3:37:47, 66.67s/it]Evaluating commonsenseqa :   1%|          | 2/200 [02:17<4:05:32, 74.41s/it]Evaluating commonsenseqa :   1%|          | 2/200 [02:48<4:37:40, 84.14s/it]Evaluating commonsenseqa :   2%|▎         | 5/200 [05:33<3:36:30, 66.62s/it]Evaluating commonsenseqa :   1%|          | 2/200 [04:16<7:03:17, 128.27s/it]Evaluating commonsenseqa :   2%|▏         | 3/200 [04:11<4:34:29, 83.60s/it]Evaluating commonsenseqa :   1%|          | 2/200 [04:54<8:05:44, 147.19s/it]Evaluating commonsenseqa :   2%|▏         | 3/200 [03:57<4:43:16, 86.28s/it]Evaluating commonsenseqa :   3%|▎         | 6/200 [06:39<3:34:15, 66.26s/it]Evaluating commonsenseqa :   2%|▏         | 4/200 [05:34<4:31:54, 83.24s/it]Evaluating commonsenseqa :   2%|▏         | 4/200 [05:12<4:26:35, 81.61s/it]Evaluating commonsenseqa :   4%|▎         | 7/200 [07:45<3:32:45, 66.14s/it]Evaluating commonsenseqa :   2%|▏         | 3/200 [06:24<7:01:11, 128.28s/it]Evaluating commonsenseqa :   2%|▏         | 3/200 [07:23<8:05:19, 147.82s/it]Evaluating commonsenseqa :   4%|▍         | 8/200 [08:48<3:28:41, 65.22s/it]Evaluating commonsenseqa :   2%|▎         | 5/200 [06:58<4:31:10, 83.44s/it]Evaluating commonsenseqa :   2%|▎         | 5/200 [06:53<4:48:47, 88.86s/it]Evaluating commonsenseqa :   4%|▍         | 9/200 [09:54<3:27:59, 65.34s/it]Evaluating commonsenseqa :   2%|▏         | 4/200 [08:34<7:00:02, 128.58s/it]Evaluating commonsenseqa :   3%|▎         | 6/200 [08:20<4:28:16, 82.97s/it]Evaluating commonsenseqa :   3%|▎         | 6/200 [08:34<5:00:19, 92.88s/it]Evaluating commonsenseqa :   5%|▌         | 10/200 [10:59<3:27:04, 65.39s/it]Evaluating commonsenseqa :   2%|▏         | 4/200 [09:50<8:01:53, 147.52s/it]Evaluating commonsenseqa :   4%|▎         | 7/200 [09:42<4:26:38, 82.90s/it]Evaluating commonsenseqa :   6%|▌         | 11/200 [12:05<3:26:23, 65.52s/it]Evaluating commonsenseqa :   2%|▎         | 5/200 [10:43<6:58:41, 128.83s/it]Evaluating commonsenseqa :   4%|▎         | 7/200 [10:16<5:08:10, 95.80s/it]Evaluating commonsenseqa :   4%|▍         | 8/200 [11:05<4:24:58, 82.80s/it]Evaluating commonsenseqa :   3%|▎         | 6/200 [11:36<5:33:28, 103.14s/it]Evaluating commonsenseqa :   6%|▌         | 12/200 [13:11<3:25:31, 65.59s/it]Evaluating commonsenseqa :   2%|▎         | 5/200 [12:20<8:02:15, 148.39s/it]Evaluating commonsenseqa :   6%|▋         | 13/200 [14:16<3:24:21, 65.57s/it]Evaluating commonsenseqa :   4%|▍         | 8/200 [11:59<5:14:37, 98.32s/it]Evaluating commonsenseqa :   4%|▍         | 9/200 [12:29<4:25:05, 83.27s/it]Evaluating commonsenseqa :   4%|▎         | 7/200 [13:44<5:58:11, 111.35s/it]Evaluating commonsenseqa :   7%|▋         | 14/200 [15:22<3:24:00, 65.81s/it]Evaluating commonsenseqa :   5%|▌         | 10/200 [13:54<4:25:26, 83.82s/it]Evaluating commonsenseqa :   3%|▎         | 6/200 [14:33<7:43:26, 143.33s/it]Evaluating commonsenseqa :   4%|▍         | 9/200 [13:40<5:15:28, 99.10s/it]Evaluating commonsenseqa :   8%|▊         | 15/200 [16:28<3:22:58, 65.83s/it]Evaluating commonsenseqa :   5%|▌         | 10/200 [14:24<4:19:54, 82.08s/it]Evaluating commonsenseqa :   6%|▌         | 11/200 [15:18<4:23:34, 83.68s/it]Evaluating commonsenseqa :   4%|▍         | 8/200 [15:56<6:16:39, 117.71s/it]Evaluating commonsenseqa :   8%|▊         | 16/200 [17:35<3:22:16, 65.96s/it]Evaluating commonsenseqa :   4%|▎         | 7/200 [17:02<7:46:50, 145.13s/it]Evaluating commonsenseqa :   6%|▌         | 11/200 [16:06<4:37:54, 88.23s/it]Evaluating commonsenseqa :   6%|▌         | 12/200 [16:41<4:21:40, 83.51s/it]Evaluating commonsenseqa :   8%|▊         | 17/200 [18:41<3:21:22, 66.02s/it]Evaluating commonsenseqa :   4%|▍         | 9/200 [17:40<6:01:33, 113.58s/it]Evaluating commonsenseqa :   6%|▌         | 12/200 [17:13<4:15:44, 81.62s/it]Evaluating commonsenseqa :   9%|▉         | 18/200 [19:46<3:19:51, 65.89s/it]Evaluating commonsenseqa :   6%|▋         | 13/200 [18:03<4:18:50, 83.05s/it]Evaluating commonsenseqa :  10%|▉         | 19/200 [20:53<3:19:10, 66.03s/it]Evaluating commonsenseqa :   4%|▍         | 8/200 [19:32<7:49:43, 146.79s/it]Evaluating commonsenseqa :   6%|▋         | 13/200 [18:53<4:31:33, 87.13s/it]Evaluating commonsenseqa :   5%|▌         | 10/200 [19:47<6:12:15, 117.56s/it]Evaluating commonsenseqa :   7%|▋         | 14/200 [19:27<4:18:01, 83.24s/it]Evaluating commonsenseqa :  10%|█         | 20/200 [21:59<3:17:51, 65.95s/it]Evaluating commonsenseqa :   7%|▋         | 14/200 [20:05<4:16:37, 82.78s/it]Evaluating commonsenseqa :   8%|▊         | 15/200 [20:49<4:15:45, 82.95s/it]Evaluating commonsenseqa :  10%|█         | 21/200 [23:04<3:16:39, 65.92s/it]Evaluating commonsenseqa :   4%|▍         | 9/200 [22:03<7:51:03, 147.97s/it]Evaluating commonsenseqa :   6%|▌         | 11/200 [21:55<6:20:46, 120.88s/it]Evaluating commonsenseqa :  11%|█         | 22/200 [24:10<3:15:29, 65.89s/it]Evaluating commonsenseqa :   8%|▊         | 16/200 [22:13<4:15:32, 83.33s/it]Evaluating commonsenseqa :   8%|▊         | 15/200 [21:48<4:33:38, 88.75s/it]Evaluating commonsenseqa :  12%|█▏        | 23/200 [25:16<3:14:09, 65.82s/it]Evaluating commonsenseqa :   8%|▊         | 17/200 [23:36<4:13:47, 83.21s/it]Evaluating commonsenseqa :   6%|▌         | 12/200 [24:08<6:29:58, 124.46s/it]Evaluating commonsenseqa :   5%|▌         | 10/200 [24:29<7:47:09, 147.52s/it]Evaluating commonsenseqa :   8%|▊         | 16/200 [23:31<4:44:49, 92.88s/it]Evaluating commonsenseqa :  12%|█▏        | 24/200 [26:22<3:13:10, 65.85s/it]Evaluating commonsenseqa :   9%|▉         | 18/200 [24:58<4:11:10, 82.80s/it]Evaluating commonsenseqa :  12%|█▎        | 25/200 [27:27<3:11:56, 65.81s/it]Evaluating commonsenseqa :   8%|▊         | 17/200 [25:13<4:51:58, 95.73s/it]Evaluating commonsenseqa :   6%|▋         | 13/200 [26:17<6:32:44, 126.01s/it]Evaluating commonsenseqa :   9%|▉         | 18/200 [25:52<3:58:19, 78.57s/it]Evaluating commonsenseqa :   6%|▌         | 11/200 [26:57<7:44:58, 147.61s/it]Evaluating commonsenseqa :  10%|▉         | 19/200 [26:21<4:10:05, 82.90s/it]Evaluating commonsenseqa :  13%|█▎        | 26/200 [28:34<3:11:05, 65.89s/it]Evaluating commonsenseqa :  14%|█▎        | 27/200 [29:39<3:09:41, 65.79s/it]Evaluating commonsenseqa :  10%|█         | 20/200 [27:45<4:10:11, 83.40s/it]Evaluating commonsenseqa :  10%|▉         | 19/200 [27:33<4:17:36, 85.39s/it]Evaluating commonsenseqa :   7%|▋         | 14/200 [28:28<6:35:10, 127.47s/it]Evaluating commonsenseqa :   6%|▌         | 12/200 [29:24<7:41:38, 147.33s/it]Evaluating commonsenseqa :  14%|█▍        | 28/200 [30:45<3:08:35, 65.79s/it]Evaluating commonsenseqa :  10%|█         | 21/200 [29:08<4:08:08, 83.17s/it]Evaluating commonsenseqa :  10%|█         | 20/200 [28:54<4:12:27, 84.16s/it]Evaluating commonsenseqa :  14%|█▍        | 29/200 [31:51<3:07:54, 65.93s/it]Evaluating commonsenseqa :   8%|▊         | 15/200 [30:37<6:33:55, 127.76s/it]Evaluating commonsenseqa :  11%|█         | 22/200 [30:30<4:05:48, 82.86s/it]Evaluating commonsenseqa :  15%|█▌        | 30/200 [32:58<3:07:12, 66.08s/it]Evaluating commonsenseqa :  10%|█         | 21/200 [30:36<4:27:11, 89.56s/it]Evaluating commonsenseqa :   6%|▋         | 13/200 [31:50<7:38:02, 146.97s/it]Evaluating commonsenseqa :  12%|█▏        | 23/200 [31:54<4:05:17, 83.15s/it]Evaluating commonsenseqa :  16%|█▌        | 31/200 [34:03<3:05:51, 65.99s/it]Evaluating commonsenseqa :   8%|▊         | 16/200 [32:46<6:32:58, 128.14s/it]Evaluating commonsenseqa :  11%|█         | 22/200 [32:18<4:36:12, 93.11s/it]Evaluating commonsenseqa :  16%|█▌        | 32/200 [35:09<3:04:44, 65.98s/it]Evaluating commonsenseqa :  12%|█▏        | 24/200 [33:18<4:04:35, 83.38s/it]Evaluating commonsenseqa :   7%|▋         | 14/200 [34:01<7:20:19, 142.04s/it]Evaluating commonsenseqa :  12%|█▏        | 23/200 [33:26<4:12:22, 85.55s/it]Evaluating commonsenseqa :  16%|█▋        | 33/200 [36:15<3:03:07, 65.80s/it]Evaluating commonsenseqa :   8%|▊         | 17/200 [34:54<6:31:19, 128.31s/it]Evaluating commonsenseqa :  12%|█▎        | 25/200 [34:40<4:01:48, 82.91s/it]Evaluating commonsenseqa :   8%|▊         | 15/200 [35:30<6:29:22, 126.28s/it]Evaluating commonsenseqa :  17%|█▋        | 34/200 [37:20<3:01:54, 65.75s/it]Evaluating commonsenseqa :   8%|▊         | 16/200 [36:11<5:07:47, 100.37s/it]Evaluating commonsenseqa :  12%|█▏        | 24/200 [35:08<4:25:55, 90.66s/it]Evaluating commonsenseqa :   9%|▉         | 18/200 [36:07<5:38:29, 111.59s/it]Evaluating commonsenseqa :  13%|█▎        | 26/200 [36:04<4:01:18, 83.21s/it]Evaluating commonsenseqa :  10%|▉         | 19/200 [36:35<4:20:52, 86.48s/it] Evaluating commonsenseqa :  18%|█▊        | 35/200 [38:26<3:00:53, 65.78s/it]Evaluating commonsenseqa :   8%|▊         | 17/200 [37:18<4:35:49, 90.43s/it] Evaluating commonsenseqa :  12%|█▎        | 25/200 [36:48<4:32:53, 93.56s/it]Evaluating commonsenseqa :  14%|█▎        | 27/200 [37:27<4:00:02, 83.25s/it]Evaluating commonsenseqa :  18%|█▊        | 36/200 [39:32<2:59:57, 65.84s/it]Evaluating commonsenseqa :  10%|█         | 20/200 [38:00<4:18:24, 86.14s/it]Evaluating commonsenseqa :  14%|█▍        | 28/200 [38:37<3:46:51, 79.14s/it]Evaluating commonsenseqa :  18%|█▊        | 37/200 [40:38<2:58:34, 65.74s/it]Evaluating commonsenseqa :  13%|█▎        | 26/200 [38:31<4:38:53, 96.17s/it]Evaluating commonsenseqa :   9%|▉         | 18/200 [39:46<5:27:08, 107.85s/it]Evaluating commonsenseqa :  10%|█         | 21/200 [40:08<4:54:05, 98.58s/it]Evaluating commonsenseqa :  19%|█▉        | 38/200 [41:44<2:57:43, 65.82s/it]Evaluating commonsenseqa :  14%|█▍        | 29/200 [39:59<3:47:53, 79.96s/it]Evaluating commonsenseqa :  14%|█▎        | 27/200 [40:14<4:43:30, 98.33s/it]Evaluating commonsenseqa :  20%|█▉        | 39/200 [42:50<2:57:05, 66.00s/it]Evaluating commonsenseqa :  10%|▉         | 19/200 [41:44<5:34:25, 110.86s/it]Evaluating commonsenseqa :  15%|█▌        | 30/200 [41:22<3:49:21, 80.95s/it]Evaluating commonsenseqa :  11%|█         | 22/200 [42:15<5:17:50, 107.14s/it]Evaluating commonsenseqa :  20%|██        | 40/200 [43:56<2:56:02, 66.01s/it]Evaluating commonsenseqa :  14%|█▍        | 28/200 [41:58<4:46:53, 100.08s/it]Evaluating commonsenseqa :  16%|█▌        | 31/200 [42:45<3:50:16, 81.75s/it]Evaluating commonsenseqa :  20%|██        | 41/200 [45:02<2:54:45, 65.95s/it]Evaluating commonsenseqa :  10%|█         | 20/200 [44:12<6:05:32, 121.85s/it]Evaluating commonsenseqa :  12%|█▏        | 23/200 [44:26<5:37:26, 114.39s/it]Evaluating commonsenseqa :  14%|█▍        | 29/200 [43:40<4:46:46, 100.62s/it]Evaluating commonsenseqa :  16%|█▌        | 32/200 [44:09<3:50:47, 82.42s/it]Evaluating commonsenseqa :  21%|██        | 42/200 [46:08<2:53:34, 65.91s/it]Evaluating commonsenseqa :  22%|██▏       | 43/200 [47:14<2:52:53, 66.07s/it]Evaluating commonsenseqa :  12%|█▏        | 24/200 [45:42<5:01:20, 102.73s/it]Evaluating commonsenseqa :  10%|█         | 21/200 [46:06<5:57:02, 119.68s/it]Evaluating commonsenseqa :  16%|█▋        | 33/200 [45:33<3:50:42, 82.89s/it]Evaluating commonsenseqa :  15%|█▌        | 30/200 [45:21<4:45:22, 100.72s/it]Evaluating commonsenseqa :  22%|██▏       | 44/200 [48:20<2:51:36, 66.00s/it]Evaluating commonsenseqa :  17%|█▋        | 34/200 [46:57<3:49:38, 83.00s/it]Evaluating commonsenseqa :  22%|██▎       | 45/200 [49:25<2:49:59, 65.80s/it]Evaluating commonsenseqa :  12%|█▎        | 25/200 [47:52<5:23:23, 110.88s/it]Evaluating commonsenseqa :  16%|█▌        | 31/200 [47:03<4:44:47, 101.11s/it]Evaluating commonsenseqa :  11%|█         | 22/200 [48:37<6:22:40, 128.99s/it]Evaluating commonsenseqa :  18%|█▊        | 35/200 [48:20<3:48:26, 83.07s/it]Evaluating commonsenseqa :  23%|██▎       | 46/200 [50:30<2:48:22, 65.60s/it]Evaluating commonsenseqa :  16%|█▌        | 32/200 [48:47<4:45:13, 101.87s/it]Evaluating commonsenseqa :  13%|█▎        | 26/200 [50:00<5:36:34, 116.06s/it]Evaluating commonsenseqa :  24%|██▎       | 47/200 [51:36<2:46:57, 65.47s/it]Evaluating commonsenseqa :  18%|█▊        | 36/200 [49:42<3:46:16, 82.78s/it]Evaluating commonsenseqa :  12%|█▏        | 23/200 [51:04<6:36:30, 134.41s/it]Evaluating commonsenseqa :  24%|██▍       | 48/200 [52:41<2:45:49, 65.46s/it]Evaluating commonsenseqa :  16%|█▋        | 33/200 [50:27<4:42:12, 101.39s/it]Evaluating commonsenseqa :  14%|█▎        | 27/200 [51:17<5:00:43, 104.30s/it]Evaluating commonsenseqa :  18%|█▊        | 37/200 [51:04<3:44:34, 82.66s/it]Evaluating commonsenseqa :  24%|██▍       | 49/200 [53:47<2:45:04, 65.59s/it]Evaluating commonsenseqa :  19%|█▉        | 38/200 [52:10<3:29:40, 77.66s/it]Evaluating commonsenseqa :  14%|█▍        | 28/200 [52:47<4:47:09, 100.17s/it]Evaluating commonsenseqa :  17%|█▋        | 34/200 [52:08<4:39:48, 101.13s/it]Evaluating commonsenseqa :  12%|█▏        | 24/200 [53:29<6:43:50, 137.67s/it]Evaluating commonsenseqa :  25%|██▌       | 50/200 [54:53<2:43:56, 65.57s/it]Evaluating commonsenseqa :  20%|█▉        | 39/200 [53:32<3:31:35, 78.85s/it]Evaluating commonsenseqa :  12%|█▎        | 25/200 [54:31<5:34:41, 114.75s/it]Evaluating commonsenseqa :  26%|██▌       | 51/200 [55:58<2:42:48, 65.56s/it]Evaluating commonsenseqa :  18%|█▊        | 35/200 [53:36<4:27:29, 97.27s/it] Evaluating commonsenseqa :  20%|██        | 40/200 [54:12<2:58:49, 67.06s/it]Evaluating commonsenseqa :  14%|█▍        | 29/200 [54:57<5:10:26, 108.93s/it]Evaluating commonsenseqa :  26%|██▌       | 52/200 [57:03<2:41:25, 65.44s/it]Evaluating commonsenseqa :  18%|█▊        | 36/200 [54:58<4:13:47, 92.85s/it]Evaluating commonsenseqa :  20%|██        | 41/200 [55:31<3:07:37, 70.80s/it]Evaluating commonsenseqa :  15%|█▌        | 30/200 [56:07<4:35:58, 97.40s/it] Evaluating commonsenseqa :  26%|██▋       | 53/200 [58:10<2:41:03, 65.74s/it]Evaluating commonsenseqa :  13%|█▎        | 26/200 [56:57<6:00:40, 124.37s/it]Evaluating commonsenseqa :  21%|██        | 42/200 [56:55<3:16:45, 74.72s/it]Evaluating commonsenseqa :  18%|█▊        | 37/200 [56:40<4:19:46, 95.62s/it]Evaluating commonsenseqa :  27%|██▋       | 54/200 [59:15<2:39:26, 65.53s/it]Evaluating commonsenseqa :  16%|█▌        | 31/200 [58:04<4:51:00, 103.32s/it]Evaluating commonsenseqa :  22%|██▏       | 43/200 [58:16<3:20:52, 76.77s/it]Evaluating commonsenseqa :  28%|██▊       | 55/200 [1:00:20<2:38:16, 65.49s/it]Evaluating commonsenseqa :  19%|█▉        | 38/200 [58:24<4:24:21, 97.91s/it]Evaluating commonsenseqa :  14%|█▎        | 27/200 [59:28<6:21:41, 132.38s/it]Evaluating commonsenseqa :  16%|█▌        | 32/200 [59:24<4:29:31, 96.26s/it] Evaluating commonsenseqa :  28%|██▊       | 56/200 [1:01:26<2:37:13, 65.51s/it]Evaluating commonsenseqa :  22%|██▏       | 44/200 [59:38<3:23:26, 78.25s/it]Evaluating commonsenseqa :  20%|█▉        | 39/200 [1:00:06<4:26:10, 99.20s/it]Evaluating commonsenseqa :  28%|██▊       | 57/200 [1:02:31<2:36:18, 65.59s/it]Evaluating commonsenseqa :  14%|█▍        | 28/200 [1:01:17<5:59:14, 125.32s/it]Evaluating commonsenseqa :  22%|██▎       | 45/200 [1:01:00<3:25:04, 79.38s/it]Evaluating commonsenseqa :  16%|█▋        | 33/200 [1:01:30<4:52:36, 105.13s/it]Evaluating commonsenseqa :  20%|██        | 40/200 [1:00:58<3:46:34, 84.96s/it]Evaluating commonsenseqa :  29%|██▉       | 58/200 [1:03:37<2:35:23, 65.66s/it]Evaluating commonsenseqa :  23%|██▎       | 46/200 [1:02:23<3:26:31, 80.46s/it]Evaluating commonsenseqa :  30%|██▉       | 59/200 [1:04:42<2:33:51, 65.47s/it]Evaluating commonsenseqa :  20%|██        | 41/200 [1:02:37<3:56:27, 89.23s/it]Evaluating commonsenseqa :  14%|█▍        | 29/200 [1:03:46<6:17:32, 132.47s/it]Evaluating commonsenseqa :  17%|█▋        | 34/200 [1:03:38<5:09:58, 112.04s/it]Evaluating commonsenseqa :  24%|██▎       | 47/200 [1:03:47<3:27:42, 81.45s/it]Evaluating commonsenseqa :  30%|███       | 60/200 [1:05:48<2:32:54, 65.54s/it]Evaluating commonsenseqa :  21%|██        | 42/200 [1:04:16<4:03:11, 92.35s/it]Evaluating commonsenseqa :  30%|███       | 61/200 [1:06:54<2:31:53, 65.56s/it]Evaluating commonsenseqa :  24%|██▍       | 48/200 [1:05:11<3:28:04, 82.14s/it]Evaluating commonsenseqa :  18%|█▊        | 35/200 [1:05:44<5:20:03, 116.38s/it]Evaluating commonsenseqa :  15%|█▌        | 30/200 [1:06:17<6:30:45, 137.91s/it]Evaluating commonsenseqa :  22%|██▏       | 43/200 [1:05:30<3:46:36, 86.60s/it]Evaluating commonsenseqa :  31%|███       | 62/200 [1:07:59<2:30:31, 65.44s/it]Evaluating commonsenseqa :  24%|██▍       | 49/200 [1:06:33<3:26:46, 82.16s/it]Evaluating commonsenseqa :  32%|███▏      | 63/200 [1:09:04<2:29:37, 65.53s/it]Evaluating commonsenseqa :  18%|█▊        | 36/200 [1:07:53<5:27:40, 119.88s/it]Evaluating commonsenseqa :  22%|██▏       | 44/200 [1:07:09<3:55:23, 90.53s/it]Evaluating commonsenseqa :  25%|██▌       | 50/200 [1:07:56<3:26:13, 82.49s/it]Evaluating commonsenseqa :  16%|█▌        | 31/200 [1:08:40<6:32:50, 139.47s/it]Evaluating commonsenseqa :  32%|███▏      | 64/200 [1:10:09<2:28:08, 65.36s/it]Evaluating commonsenseqa :  22%|██▎       | 45/200 [1:08:48<3:59:50, 92.84s/it]Evaluating commonsenseqa :  32%|███▎      | 65/200 [1:11:15<2:27:14, 65.44s/it]Evaluating commonsenseqa :  26%|██▌       | 51/200 [1:09:18<3:24:38, 82.40s/it]Evaluating commonsenseqa :  18%|█▊        | 37/200 [1:10:02<5:33:09, 122.64s/it]Evaluating commonsenseqa :  33%|███▎      | 66/200 [1:12:22<2:26:57, 65.80s/it]Evaluating commonsenseqa :  16%|█▌        | 32/200 [1:11:10<6:39:03, 142.52s/it]Evaluating commonsenseqa :  26%|██▌       | 52/200 [1:10:41<3:23:22, 82.45s/it]Evaluating commonsenseqa :  23%|██▎       | 46/200 [1:10:19<3:57:28, 92.52s/it]Evaluating commonsenseqa :  34%|███▎      | 67/200 [1:13:27<2:25:36, 65.69s/it]Evaluating commonsenseqa :  19%|█▉        | 38/200 [1:12:09<5:35:05, 124.11s/it]Evaluating commonsenseqa :  26%|██▋       | 53/200 [1:12:04<3:22:13, 82.54s/it]Evaluating commonsenseqa :  24%|██▎       | 47/200 [1:12:02<4:03:53, 95.64s/it]Evaluating commonsenseqa :  34%|███▍      | 68/200 [1:14:32<2:24:16, 65.58s/it]Evaluating commonsenseqa :  16%|█▋        | 33/200 [1:13:42<6:44:28, 145.32s/it]Evaluating commonsenseqa :  27%|██▋       | 54/200 [1:13:26<3:20:52, 82.55s/it]Evaluating commonsenseqa :  24%|██▍       | 48/200 [1:13:12<3:42:54, 87.99s/it]Evaluating commonsenseqa :  34%|███▍      | 69/200 [1:15:38<2:23:17, 65.63s/it]Evaluating commonsenseqa :  20%|█▉        | 39/200 [1:14:18<5:36:40, 125.47s/it]Evaluating commonsenseqa :  35%|███▌      | 70/200 [1:16:44<2:22:12, 65.64s/it]Evaluating commonsenseqa :  28%|██▊       | 55/200 [1:14:48<3:19:17, 82.47s/it]Evaluating commonsenseqa :  24%|██▍       | 49/200 [1:14:54<3:51:38, 92.04s/it]Evaluating commonsenseqa :  17%|█▋        | 34/200 [1:16:12<6:46:05, 146.78s/it]Evaluating commonsenseqa :  36%|███▌      | 71/200 [1:17:49<2:20:54, 65.54s/it]Evaluating commonsenseqa :  20%|██        | 40/200 [1:16:27<5:37:59, 126.75s/it]Evaluating commonsenseqa :  28%|██▊       | 56/200 [1:16:11<3:17:44, 82.39s/it]Evaluating commonsenseqa :  36%|███▌      | 72/200 [1:18:55<2:19:42, 65.48s/it]Evaluating commonsenseqa :  25%|██▌       | 50/200 [1:16:36<3:57:54, 95.16s/it]Evaluating commonsenseqa :  28%|██▊       | 57/200 [1:17:34<3:17:02, 82.67s/it]Evaluating commonsenseqa :  18%|█▊        | 35/200 [1:18:38<6:43:16, 146.65s/it]Evaluating commonsenseqa :  36%|███▋      | 73/200 [1:20:00<2:18:41, 65.52s/it]Evaluating commonsenseqa :  20%|██        | 41/200 [1:18:37<5:37:54, 127.51s/it]Evaluating commonsenseqa :  26%|██▌       | 51/200 [1:18:18<4:01:03, 97.07s/it]Evaluating commonsenseqa :  29%|██▉       | 58/200 [1:18:56<3:15:06, 82.44s/it]Evaluating commonsenseqa :  37%|███▋      | 74/200 [1:21:06<2:17:48, 65.62s/it]Evaluating commonsenseqa :  26%|██▌       | 52/200 [1:19:08<3:24:49, 83.03s/it]Evaluating commonsenseqa :  38%|███▊      | 75/200 [1:22:11<2:16:37, 65.58s/it]Evaluating commonsenseqa :  30%|██▉       | 59/200 [1:20:18<3:13:28, 82.33s/it]Evaluating commonsenseqa :  21%|██        | 42/200 [1:20:47<5:37:35, 128.20s/it]Evaluating commonsenseqa :  18%|█▊        | 36/200 [1:21:07<6:42:36, 147.30s/it]Evaluating commonsenseqa :  26%|██▋       | 53/200 [1:20:49<3:36:44, 88.46s/it]Evaluating commonsenseqa :  22%|██▏       | 43/200 [1:21:42<4:38:26, 106.41s/it]Evaluating commonsenseqa :  38%|███▊      | 76/200 [1:23:17<2:15:36, 65.62s/it]Evaluating commonsenseqa :  30%|███       | 60/200 [1:21:42<3:13:33, 82.95s/it]Evaluating commonsenseqa :  27%|██▋       | 54/200 [1:21:18<2:51:46, 70.59s/it]Evaluating commonsenseqa :  18%|█▊        | 37/200 [1:23:02<6:13:33, 137.50s/it]Evaluating commonsenseqa :  38%|███▊      | 77/200 [1:24:22<2:14:15, 65.49s/it]Evaluating commonsenseqa :  30%|███       | 61/200 [1:23:05<3:12:03, 82.91s/it]Evaluating commonsenseqa :  28%|██▊       | 55/200 [1:23:00<3:13:13, 79.95s/it]Evaluating commonsenseqa :  22%|██▏       | 44/200 [1:23:52<4:55:01, 113.47s/it]Evaluating commonsenseqa :  39%|███▉      | 78/200 [1:25:28<2:13:02, 65.43s/it]Evaluating commonsenseqa :  31%|███       | 62/200 [1:24:27<3:10:00, 82.61s/it]Evaluating commonsenseqa :  40%|███▉      | 79/200 [1:26:33<2:11:54, 65.41s/it]Evaluating commonsenseqa :  28%|██▊       | 56/200 [1:24:21<3:12:51, 80.36s/it]Evaluating commonsenseqa :  19%|█▉        | 38/200 [1:25:28<6:18:47, 140.29s/it]Evaluating commonsenseqa :  22%|██▎       | 45/200 [1:25:31<4:42:01, 109.17s/it]Evaluating commonsenseqa :  40%|████      | 80/200 [1:27:39<2:11:06, 65.56s/it]Evaluating commonsenseqa :  32%|███▏      | 63/200 [1:25:51<3:09:16, 82.89s/it]Evaluating commonsenseqa :  28%|██▊       | 57/200 [1:26:03<3:26:44, 86.75s/it]Evaluating commonsenseqa :  20%|█▉        | 39/200 [1:27:19<5:52:50, 131.49s/it]Evaluating commonsenseqa :  40%|████      | 81/200 [1:28:44<2:09:42, 65.40s/it]Evaluating commonsenseqa :  23%|██▎       | 46/200 [1:27:37<4:53:19, 114.28s/it]Evaluating commonsenseqa :  32%|███▏      | 64/200 [1:27:14<3:08:24, 83.12s/it]Evaluating commonsenseqa :  29%|██▉       | 58/200 [1:26:53<2:59:07, 75.68s/it]Evaluating commonsenseqa :  41%|████      | 82/200 [1:29:50<2:08:47, 65.49s/it]Evaluating commonsenseqa :  32%|███▎      | 65/200 [1:28:39<3:07:58, 83.54s/it]Evaluating commonsenseqa :  24%|██▎       | 47/200 [1:29:19<4:41:51, 110.53s/it]Evaluating commonsenseqa :  42%|████▏     | 83/200 [1:30:55<2:07:53, 65.59s/it]Evaluating commonsenseqa :  30%|██▉       | 59/200 [1:28:33<3:15:27, 83.17s/it]Evaluating commonsenseqa :  20%|██        | 40/200 [1:29:45<6:02:01, 135.76s/it]Evaluating commonsenseqa :  33%|███▎      | 66/200 [1:30:01<3:05:52, 83.23s/it]Evaluating commonsenseqa :  42%|████▏     | 84/200 [1:32:01<2:06:58, 65.68s/it]Evaluating commonsenseqa :  30%|███       | 60/200 [1:30:16<3:27:33, 88.95s/it]Evaluating commonsenseqa :  24%|██▍       | 48/200 [1:31:27<4:53:17, 115.77s/it]Evaluating commonsenseqa :  42%|████▎     | 85/200 [1:33:07<2:05:47, 65.63s/it]Evaluating commonsenseqa :  34%|███▎      | 67/200 [1:31:24<3:04:18, 83.15s/it]Evaluating commonsenseqa :  20%|██        | 41/200 [1:32:14<6:10:20, 139.75s/it]Evaluating commonsenseqa :  43%|████▎     | 86/200 [1:34:13<2:04:50, 65.70s/it]Evaluating commonsenseqa :  24%|██▍       | 49/200 [1:32:42<4:20:30, 103.51s/it]Evaluating commonsenseqa :  30%|███       | 61/200 [1:31:57<3:34:33, 92.61s/it]Evaluating commonsenseqa :  34%|███▍      | 68/200 [1:32:47<3:02:32, 82.97s/it]Evaluating commonsenseqa :  44%|████▎     | 87/200 [1:35:18<2:03:32, 65.60s/it]Evaluating commonsenseqa :  25%|██▌       | 50/200 [1:33:57<3:57:11, 94.88s/it] Evaluating commonsenseqa :  21%|██        | 42/200 [1:34:41<6:13:37, 141.88s/it]Evaluating commonsenseqa :  31%|███       | 62/200 [1:33:40<3:40:28, 95.86s/it]Evaluating commonsenseqa :  34%|███▍      | 69/200 [1:34:09<3:00:46, 82.79s/it]Evaluating commonsenseqa :  44%|████▍     | 88/200 [1:36:24<2:02:35, 65.68s/it]Evaluating commonsenseqa :  44%|████▍     | 89/200 [1:37:29<2:01:18, 65.57s/it]Evaluating commonsenseqa :  35%|███▌      | 70/200 [1:35:32<2:59:14, 82.73s/it]Evaluating commonsenseqa :  26%|██▌       | 51/200 [1:36:05<4:20:41, 104.98s/it]Evaluating commonsenseqa :  32%|███▏      | 63/200 [1:35:23<3:43:25, 97.85s/it]Evaluating commonsenseqa :  22%|██▏       | 43/200 [1:37:08<6:15:12, 143.39s/it]Evaluating commonsenseqa :  45%|████▌     | 90/200 [1:38:35<2:00:06, 65.51s/it]Evaluating commonsenseqa :  36%|███▌      | 71/200 [1:36:54<2:57:44, 82.67s/it]Evaluating commonsenseqa :  32%|███▏      | 64/200 [1:37:06<3:45:28, 99.47s/it]Evaluating commonsenseqa :  46%|████▌     | 91/200 [1:39:40<1:59:06, 65.57s/it]Evaluating commonsenseqa :  26%|██▌       | 52/200 [1:38:14<4:36:25, 112.06s/it]Evaluating commonsenseqa :  36%|███▌      | 72/200 [1:38:18<2:56:48, 82.88s/it]Evaluating commonsenseqa :  46%|████▌     | 92/200 [1:40:46<1:58:16, 65.71s/it]Evaluating commonsenseqa :  22%|██▏       | 44/200 [1:39:37<6:17:16, 145.10s/it]Evaluating commonsenseqa :  32%|███▎      | 65/200 [1:38:41<3:40:52, 98.16s/it]Evaluating commonsenseqa :  36%|███▋      | 73/200 [1:39:41<2:55:24, 82.87s/it]Evaluating commonsenseqa :  46%|████▋     | 93/200 [1:41:52<1:56:57, 65.58s/it]Evaluating commonsenseqa :  26%|██▋       | 53/200 [1:40:21<4:45:16, 116.44s/it]Evaluating commonsenseqa :  33%|███▎      | 66/200 [1:39:40<3:13:01, 86.43s/it]Evaluating commonsenseqa :  47%|████▋     | 94/200 [1:42:58<1:56:00, 65.67s/it]Evaluating commonsenseqa :  37%|███▋      | 74/200 [1:41:03<2:53:39, 82.70s/it]Evaluating commonsenseqa :  22%|██▎       | 45/200 [1:42:03<6:15:10, 145.23s/it]Evaluating commonsenseqa :  34%|███▎      | 67/200 [1:41:22<3:21:30, 90.91s/it]Evaluating commonsenseqa :  27%|██▋       | 54/200 [1:42:25<4:49:26, 118.95s/it]Evaluating commonsenseqa :  48%|████▊     | 95/200 [1:44:04<1:55:09, 65.81s/it]Evaluating commonsenseqa :  38%|███▊      | 75/200 [1:42:26<2:52:45, 82.92s/it]Evaluating commonsenseqa :  34%|███▍      | 68/200 [1:42:12<2:53:02, 78.66s/it]Evaluating commonsenseqa :  28%|██▊       | 55/200 [1:43:29<4:07:25, 102.38s/it]Evaluating commonsenseqa :  48%|████▊     | 96/200 [1:45:10<1:54:22, 65.99s/it]Evaluating commonsenseqa :  38%|███▊      | 76/200 [1:43:48<2:50:44, 82.61s/it]Evaluating commonsenseqa :  23%|██▎       | 46/200 [1:44:31<6:15:17, 146.22s/it]Evaluating commonsenseqa :  48%|████▊     | 97/200 [1:46:16<1:53:15, 65.97s/it]Evaluating commonsenseqa :  34%|███▍      | 69/200 [1:43:56<3:08:11, 86.19s/it]Evaluating commonsenseqa :  38%|███▊      | 77/200 [1:45:11<2:49:35, 82.73s/it]Evaluating commonsenseqa :  28%|██▊       | 56/200 [1:45:37<4:24:12, 110.09s/it]Evaluating commonsenseqa :  49%|████▉     | 98/200 [1:47:21<1:51:52, 65.81s/it]Evaluating commonsenseqa :  24%|██▎       | 47/200 [1:46:14<5:39:25, 133.11s/it]Evaluating commonsenseqa :  35%|███▌      | 70/200 [1:45:39<3:18:07, 91.44s/it]Evaluating commonsenseqa :  28%|██▊       | 57/200 [1:46:39<3:47:39, 95.52s/it] Evaluating commonsenseqa :  50%|████▉     | 99/200 [1:48:27<1:50:49, 65.83s/it]Evaluating commonsenseqa :  39%|███▉      | 78/200 [1:46:35<2:48:35, 82.92s/it]Evaluating commonsenseqa :  50%|█████     | 100/200 [1:49:33<1:49:27, 65.67s/it]Evaluating commonsenseqa :  29%|██▉       | 58/200 [1:48:03<3:38:22, 92.27s/it]Evaluating commonsenseqa :  36%|███▌      | 71/200 [1:47:21<3:22:56, 94.39s/it]Evaluating commonsenseqa :  40%|███▉      | 79/200 [1:47:56<2:46:36, 82.61s/it]Evaluating commonsenseqa :  30%|██▉       | 59/200 [1:48:27<2:48:03, 71.51s/it]Evaluating commonsenseqa :  24%|██▍       | 48/200 [1:48:41<5:48:13, 137.46s/it]Evaluating commonsenseqa :  50%|█████     | 101/200 [1:50:38<1:48:09, 65.55s/it]Evaluating commonsenseqa :  40%|████      | 80/200 [1:49:20<2:45:35, 82.79s/it]Evaluating commonsenseqa :  36%|███▌      | 72/200 [1:49:01<3:25:23, 96.28s/it]Evaluating commonsenseqa :  51%|█████     | 102/200 [1:51:44<1:47:05, 65.57s/it]Evaluating commonsenseqa :  30%|███       | 60/200 [1:50:35<3:26:40, 88.57s/it]Evaluating commonsenseqa :  36%|███▋      | 73/200 [1:50:06<3:03:47, 86.83s/it]Evaluating commonsenseqa :  24%|██▍       | 49/200 [1:51:11<5:55:33, 141.28s/it]Evaluating commonsenseqa :  40%|████      | 81/200 [1:50:41<2:43:29, 82.43s/it]Evaluating commonsenseqa :  52%|█████▏    | 103/200 [1:52:50<1:46:13, 65.70s/it]Evaluating commonsenseqa :  52%|█████▏    | 104/200 [1:53:56<1:45:16, 65.80s/it]Evaluating commonsenseqa :  41%|████      | 82/200 [1:52:03<2:41:45, 82.25s/it]Evaluating commonsenseqa :  37%|███▋      | 74/200 [1:51:48<3:11:59, 91.43s/it]Evaluating commonsenseqa :  30%|███       | 61/200 [1:52:42<3:52:10, 100.22s/it]Evaluating commonsenseqa :  52%|█████▎    | 105/200 [1:55:01<1:43:54, 65.62s/it]Evaluating commonsenseqa :  25%|██▌       | 50/200 [1:53:41<5:59:29, 143.79s/it]Evaluating commonsenseqa :  42%|████▏     | 83/200 [1:53:26<2:40:37, 82.37s/it]Evaluating commonsenseqa :  38%|███▊      | 75/200 [1:53:30<3:16:41, 94.41s/it]Evaluating commonsenseqa :  53%|█████▎    | 106/200 [1:56:06<1:42:42, 65.55s/it]Evaluating commonsenseqa :  31%|███       | 62/200 [1:54:48<4:08:07, 107.88s/it]Evaluating commonsenseqa :  42%|████▏     | 84/200 [1:54:42<2:35:36, 80.49s/it]Evaluating commonsenseqa :  54%|█████▎    | 107/200 [1:57:12<1:41:42, 65.62s/it]Evaluating commonsenseqa :  26%|██▌       | 51/200 [1:56:11<6:01:40, 145.64s/it]Evaluating commonsenseqa :  32%|███▏      | 63/200 [1:55:59<3:40:55, 96.75s/it] Evaluating commonsenseqa :  38%|███▊      | 76/200 [1:55:12<3:19:58, 96.76s/it]Evaluating commonsenseqa :  42%|████▎     | 85/200 [1:56:06<2:36:07, 81.45s/it]Evaluating commonsenseqa :  54%|█████▍    | 108/200 [1:58:17<1:40:32, 65.58s/it]Evaluating commonsenseqa :  38%|███▊      | 77/200 [1:56:54<3:21:55, 98.50s/it]Evaluating commonsenseqa :  55%|█████▍    | 109/200 [1:59:23<1:39:38, 65.70s/it]Evaluating commonsenseqa :  43%|████▎     | 86/200 [1:57:29<2:35:46, 81.99s/it]Evaluating commonsenseqa :  32%|███▏      | 64/200 [1:58:08<4:01:17, 106.45s/it]Evaluating commonsenseqa :  26%|██▌       | 52/200 [1:58:40<6:01:53, 146.71s/it]Evaluating commonsenseqa :  55%|█████▌    | 110/200 [2:00:30<1:39:07, 66.08s/it]Evaluating commonsenseqa :  39%|███▉      | 78/200 [1:58:18<3:11:07, 93.99s/it]Evaluating commonsenseqa :  44%|████▎     | 87/200 [1:58:51<2:34:30, 82.04s/it]Evaluating commonsenseqa :  32%|███▎      | 65/200 [1:59:23<3:38:33, 97.14s/it] Evaluating commonsenseqa :  56%|█████▌    | 111/200 [2:01:36<1:37:39, 65.84s/it]Evaluating commonsenseqa :  26%|██▋       | 53/200 [2:00:19<5:24:04, 132.27s/it]Evaluating commonsenseqa :  44%|████▍     | 88/200 [2:00:16<2:34:36, 82.83s/it]Evaluating commonsenseqa :  40%|███▉      | 79/200 [1:59:59<3:14:00, 96.20s/it]Evaluating commonsenseqa :  33%|███▎      | 66/200 [2:00:57<3:34:18, 95.96s/it]Evaluating commonsenseqa :  56%|█████▌    | 112/200 [2:02:42<1:36:49, 66.01s/it]Evaluating commonsenseqa :  44%|████▍     | 89/200 [2:01:38<2:33:04, 82.74s/it]Evaluating commonsenseqa :  56%|█████▋    | 113/200 [2:03:48<1:35:40, 65.99s/it]Evaluating commonsenseqa :  34%|███▎      | 67/200 [2:02:16<3:21:23, 90.85s/it]Evaluating commonsenseqa :  40%|████      | 80/200 [2:01:40<3:14:58, 97.49s/it]Evaluating commonsenseqa :  27%|██▋       | 54/200 [2:02:48<5:33:57, 137.24s/it]Evaluating commonsenseqa :  57%|█████▋    | 114/200 [2:04:54<1:34:26, 65.89s/it]Evaluating commonsenseqa :  45%|████▌     | 90/200 [2:03:02<2:32:15, 83.05s/it]Evaluating commonsenseqa :  40%|████      | 81/200 [2:03:22<3:16:03, 98.85s/it]Evaluating commonsenseqa :  34%|███▍      | 68/200 [2:04:24<3:44:26, 102.02s/it]Evaluating commonsenseqa :  57%|█████▊    | 115/200 [2:05:59<1:33:17, 65.85s/it]Evaluating commonsenseqa :  46%|████▌     | 91/200 [2:04:25<2:30:42, 82.96s/it]Evaluating commonsenseqa :  28%|██▊       | 55/200 [2:05:16<5:39:41, 140.56s/it]Evaluating commonsenseqa :  58%|█████▊    | 116/200 [2:07:06<1:32:24, 66.00s/it]Evaluating commonsenseqa :  41%|████      | 82/200 [2:04:57<3:12:26, 97.85s/it]Evaluating commonsenseqa :  46%|████▌     | 92/200 [2:05:47<2:29:12, 82.90s/it]Evaluating commonsenseqa :  58%|█████▊    | 117/200 [2:07:51<1:22:51, 59.90s/it]Evaluating commonsenseqa :  34%|███▍      | 69/200 [2:06:20<3:52:24, 106.44s/it]Evaluating commonsenseqa :  59%|█████▉    | 118/200 [2:08:57<1:24:12, 61.62s/it]Evaluating commonsenseqa :  42%|████▏     | 83/200 [2:06:41<3:14:23, 99.68s/it]Evaluating commonsenseqa :  28%|██▊       | 56/200 [2:07:45<5:43:46, 143.24s/it]Evaluating commonsenseqa :  46%|████▋     | 93/200 [2:07:10<2:27:29, 82.70s/it]Evaluating commonsenseqa :  35%|███▌      | 70/200 [2:07:52<3:40:46, 101.90s/it]Evaluating commonsenseqa :  60%|█████▉    | 119/200 [2:10:02<1:24:38, 62.70s/it]Evaluating commonsenseqa :  42%|████▏     | 84/200 [2:07:40<2:49:03, 87.44s/it]Evaluating commonsenseqa :  47%|████▋     | 94/200 [2:08:32<2:26:05, 82.69s/it]Evaluating commonsenseqa :  42%|████▎     | 85/200 [2:08:39<2:31:04, 78.82s/it]Evaluating commonsenseqa :  60%|██████    | 120/200 [2:11:08<1:24:47, 63.60s/it]Evaluating commonsenseqa :  28%|██▊       | 57/200 [2:09:47<5:26:09, 136.85s/it]Evaluating commonsenseqa :  36%|███▌      | 71/200 [2:10:02<3:57:23, 110.42s/it]Evaluating commonsenseqa :  48%|████▊     | 95/200 [2:09:55<2:24:45, 82.72s/it]Evaluating commonsenseqa :  60%|██████    | 121/200 [2:12:14<1:24:44, 64.36s/it]Evaluating commonsenseqa :  43%|████▎     | 86/200 [2:10:20<2:42:29, 85.52s/it]Evaluating commonsenseqa :  48%|████▊     | 96/200 [2:11:17<2:23:07, 82.58s/it]Evaluating commonsenseqa :  61%|██████    | 122/200 [2:13:20<1:24:04, 64.67s/it]Evaluating commonsenseqa :  29%|██▉       | 58/200 [2:12:15<5:31:25, 140.04s/it]Evaluating commonsenseqa :  36%|███▌      | 72/200 [2:12:09<4:06:05, 115.35s/it]Evaluating commonsenseqa :  44%|████▎     | 87/200 [2:11:40<2:37:47, 83.78s/it]Evaluating commonsenseqa :  62%|██████▏   | 123/200 [2:14:26<1:23:30, 65.07s/it]Evaluating commonsenseqa :  48%|████▊     | 97/200 [2:12:41<2:22:11, 82.83s/it]Evaluating commonsenseqa :  62%|██████▏   | 124/200 [2:15:31<1:22:36, 65.22s/it]Evaluating commonsenseqa :  44%|████▍     | 88/200 [2:13:21<2:46:29, 89.19s/it]Evaluating commonsenseqa :  36%|███▋      | 73/200 [2:14:18<4:12:54, 119.48s/it]Evaluating commonsenseqa :  49%|████▉     | 98/200 [2:14:03<2:20:39, 82.74s/it]Evaluating commonsenseqa :  30%|██▉       | 59/200 [2:14:43<5:34:51, 142.50s/it]Evaluating commonsenseqa :  62%|██████▎   | 125/200 [2:16:36<1:21:33, 65.25s/it]Evaluating commonsenseqa :  44%|████▍     | 89/200 [2:14:23<2:29:24, 80.76s/it]Evaluating commonsenseqa :  50%|████▉     | 99/200 [2:15:25<2:18:53, 82.51s/it]Evaluating commonsenseqa :  63%|██████▎   | 126/200 [2:17:43<1:20:51, 65.55s/it]Evaluating commonsenseqa :  37%|███▋      | 74/200 [2:16:29<4:18:06, 122.91s/it]Evaluating commonsenseqa :  45%|████▌     | 90/200 [2:16:04<2:39:21, 86.93s/it]Evaluating commonsenseqa :  30%|███       | 60/200 [2:17:13<5:37:40, 144.72s/it]Evaluating commonsenseqa :  50%|█████     | 100/200 [2:16:48<2:17:38, 82.58s/it]Evaluating commonsenseqa :  64%|██████▎   | 127/200 [2:18:49<1:19:56, 65.70s/it]Evaluating commonsenseqa :  38%|███▊      | 75/200 [2:18:02<3:57:45, 114.12s/it]Evaluating commonsenseqa :  64%|██████▍   | 128/200 [2:19:54<1:18:48, 65.68s/it]Evaluating commonsenseqa :  50%|█████     | 101/200 [2:18:10<2:16:03, 82.46s/it]Evaluating commonsenseqa :  46%|████▌     | 91/200 [2:17:46<2:46:16, 91.53s/it]Evaluating commonsenseqa :  64%|██████▍   | 129/200 [2:21:01<1:17:55, 65.85s/it]Evaluating commonsenseqa :  30%|███       | 61/200 [2:19:43<5:38:46, 146.23s/it]Evaluating commonsenseqa :  51%|█████     | 102/200 [2:19:34<2:15:16, 82.82s/it]Evaluating commonsenseqa :  38%|███▊      | 76/200 [2:20:13<4:06:18, 119.18s/it]Evaluating commonsenseqa :  46%|████▌     | 92/200 [2:19:28<2:50:28, 94.71s/it]Evaluating commonsenseqa :  65%|██████▌   | 130/200 [2:22:06<1:16:49, 65.84s/it]Evaluating commonsenseqa :  52%|█████▏    | 103/200 [2:20:56<2:13:24, 82.52s/it]Evaluating commonsenseqa :  38%|███▊      | 77/200 [2:21:24<3:34:25, 104.60s/it]Evaluating commonsenseqa :  66%|██████▌   | 131/200 [2:23:12<1:15:35, 65.74s/it]Evaluating commonsenseqa :  31%|███       | 62/200 [2:22:09<5:36:31, 146.32s/it]Evaluating commonsenseqa :  46%|████▋     | 93/200 [2:21:09<2:52:13, 96.58s/it]Evaluating commonsenseqa :  52%|█████▏    | 104/200 [2:22:18<2:11:44, 82.34s/it]Evaluating commonsenseqa :  66%|██████▌   | 132/200 [2:24:18<1:14:34, 65.81s/it]Evaluating commonsenseqa :  39%|███▉      | 78/200 [2:23:31<3:46:12, 111.25s/it]Evaluating commonsenseqa :  47%|████▋     | 94/200 [2:22:51<2:53:26, 98.17s/it]Evaluating commonsenseqa :  66%|██████▋   | 133/200 [2:25:23<1:13:18, 65.65s/it]Evaluating commonsenseqa :  52%|█████▎    | 105/200 [2:23:41<2:11:01, 82.75s/it]Evaluating commonsenseqa :  32%|███▏      | 63/200 [2:24:37<5:34:48, 146.63s/it]Evaluating commonsenseqa :  67%|██████▋   | 134/200 [2:26:29<1:12:11, 65.62s/it]Evaluating commonsenseqa :  48%|████▊     | 95/200 [2:24:33<2:53:47, 99.31s/it]Evaluating commonsenseqa :  53%|█████▎    | 106/200 [2:25:05<2:09:55, 82.93s/it]Evaluating commonsenseqa :  40%|███▉      | 79/200 [2:25:39<3:54:52, 116.47s/it]Evaluating commonsenseqa :  68%|██████▊   | 135/200 [2:27:35<1:11:18, 65.82s/it]Evaluating commonsenseqa :  32%|███▏      | 64/200 [2:26:28<5:08:15, 135.99s/it]Evaluating commonsenseqa :  54%|█████▎    | 107/200 [2:26:29<2:09:14, 83.38s/it]Evaluating commonsenseqa :  48%|████▊     | 96/200 [2:26:15<2:53:34, 100.14s/it]Evaluating commonsenseqa :  68%|██████▊   | 136/200 [2:28:41<1:10:06, 65.73s/it]Evaluating commonsenseqa :  40%|████      | 80/200 [2:27:36<3:53:13, 116.61s/it]Evaluating commonsenseqa :  68%|██████▊   | 137/200 [2:29:46<1:09:00, 65.71s/it]Evaluating commonsenseqa :  54%|█████▍    | 108/200 [2:27:52<2:07:32, 83.18s/it]Evaluating commonsenseqa :  32%|███▎      | 65/200 [2:28:56<5:14:31, 139.79s/it]Evaluating commonsenseqa :  48%|████▊     | 97/200 [2:27:58<2:53:16, 100.94s/it]Evaluating commonsenseqa :  69%|██████▉   | 138/200 [2:30:48<1:06:45, 64.61s/it]Evaluating commonsenseqa :  55%|█████▍    | 109/200 [2:29:15<2:05:57, 83.05s/it]Evaluating commonsenseqa :  40%|████      | 81/200 [2:29:45<3:58:08, 120.07s/it]Evaluating commonsenseqa :  70%|██████▉   | 139/200 [2:31:54<1:06:04, 64.99s/it]Evaluating commonsenseqa :  49%|████▉     | 98/200 [2:29:39<2:51:44, 101.02s/it]Evaluating commonsenseqa :  41%|████      | 82/200 [2:30:34<3:14:43, 99.02s/it] Evaluating commonsenseqa :  55%|█████▌    | 110/200 [2:30:37<2:04:17, 82.86s/it]Evaluating commonsenseqa :  33%|███▎      | 66/200 [2:31:25<5:17:50, 142.32s/it]Evaluating commonsenseqa :  70%|███████   | 140/200 [2:32:54<1:03:28, 63.47s/it]Evaluating commonsenseqa :  50%|████▉     | 99/200 [2:31:20<2:50:03, 101.02s/it]Evaluating commonsenseqa :  56%|█████▌    | 111/200 [2:32:00<2:03:09, 83.02s/it]Evaluating commonsenseqa :  70%|███████   | 141/200 [2:34:00<1:03:05, 64.17s/it]Evaluating commonsenseqa :  42%|████▏     | 83/200 [2:32:42<3:29:51, 107.62s/it]Evaluating commonsenseqa :  71%|███████   | 142/200 [2:35:06<1:02:30, 64.66s/it]Evaluating commonsenseqa :  34%|███▎      | 67/200 [2:33:52<5:18:49, 143.83s/it]Evaluating commonsenseqa :  42%|████▏     | 84/200 [2:33:47<3:03:29, 94.91s/it] Evaluating commonsenseqa :  56%|█████▌    | 112/200 [2:33:24<2:02:00, 83.18s/it]Evaluating commonsenseqa :  50%|█████     | 100/200 [2:33:02<2:48:44, 101.25s/it]Evaluating commonsenseqa :  72%|███████▏  | 143/200 [2:36:11<1:01:45, 65.01s/it]Evaluating commonsenseqa :  56%|█████▋    | 113/200 [2:34:48<2:00:48, 83.31s/it]Evaluating commonsenseqa :  50%|█████     | 101/200 [2:34:44<2:47:23, 101.45s/it]Evaluating commonsenseqa :  72%|███████▏  | 144/200 [2:37:17<1:00:52, 65.23s/it]Evaluating commonsenseqa :  42%|████▎     | 85/200 [2:35:56<3:21:27, 105.11s/it]Evaluating commonsenseqa :  34%|███▍      | 68/200 [2:36:19<5:18:28, 144.76s/it]Evaluating commonsenseqa :  57%|█████▋    | 114/200 [2:36:10<1:58:50, 82.91s/it]Evaluating commonsenseqa :  72%|███████▎  | 145/200 [2:38:24<1:00:10, 65.64s/it]Evaluating commonsenseqa :  51%|█████     | 102/200 [2:36:28<2:46:51, 102.16s/it]Evaluating commonsenseqa :  73%|███████▎  | 146/200 [2:39:29<59:00, 65.56s/it]  Evaluating commonsenseqa :  57%|█████▊    | 115/200 [2:37:32<1:57:20, 82.83s/it]Evaluating commonsenseqa :  43%|████▎     | 86/200 [2:38:06<3:33:37, 112.43s/it]Evaluating commonsenseqa :  34%|███▍      | 69/200 [2:38:48<5:18:52, 146.05s/it]Evaluating commonsenseqa :  52%|█████▏    | 103/200 [2:38:11<2:45:33, 102.41s/it]Evaluating commonsenseqa :  74%|███████▎  | 147/200 [2:40:35<58:02, 65.70s/it]Evaluating commonsenseqa :  58%|█████▊    | 116/200 [2:38:55<1:56:09, 82.97s/it]Evaluating commonsenseqa :  74%|███████▍  | 148/200 [2:41:41<56:57, 65.73s/it]Evaluating commonsenseqa :  52%|█████▏    | 104/200 [2:39:19<2:27:19, 92.07s/it] Evaluating commonsenseqa :  44%|████▎     | 87/200 [2:40:15<3:41:09, 117.43s/it]Evaluating commonsenseqa :  58%|█████▊    | 117/200 [2:40:19<1:54:54, 83.06s/it]Evaluating commonsenseqa :  35%|███▌      | 70/200 [2:41:15<5:17:18, 146.45s/it]Evaluating commonsenseqa :  74%|███████▍  | 149/200 [2:42:46<55:46, 65.62s/it]Evaluating commonsenseqa :  52%|█████▎    | 105/200 [2:40:59<2:29:54, 94.68s/it]Evaluating commonsenseqa :  59%|█████▉    | 118/200 [2:41:41<1:53:00, 82.69s/it]Evaluating commonsenseqa :  75%|███████▌  | 150/200 [2:43:52<54:48, 65.77s/it]Evaluating commonsenseqa :  44%|████▍     | 88/200 [2:42:25<3:46:07, 121.14s/it]Evaluating commonsenseqa :  76%|███████▌  | 151/200 [2:44:59<53:47, 65.87s/it]Evaluating commonsenseqa :  36%|███▌      | 71/200 [2:43:41<5:14:05, 146.09s/it]Evaluating commonsenseqa :  60%|█████▉    | 119/200 [2:43:03<1:51:37, 82.69s/it]Evaluating commonsenseqa :  53%|█████▎    | 106/200 [2:42:42<2:32:01, 97.04s/it]Evaluating commonsenseqa :  54%|█████▎    | 107/200 [2:43:39<2:11:46, 85.02s/it]Evaluating commonsenseqa :  76%|███████▌  | 152/200 [2:46:04<52:41, 65.87s/it]Evaluating commonsenseqa :  44%|████▍     | 89/200 [2:44:33<3:48:07, 123.31s/it]Evaluating commonsenseqa :  60%|██████    | 120/200 [2:44:26<1:50:12, 82.66s/it]Evaluating commonsenseqa :  76%|███████▋  | 153/200 [2:47:10<51:35, 65.85s/it]Evaluating commonsenseqa :  36%|███▌      | 72/200 [2:46:08<5:12:24, 146.44s/it]Evaluating commonsenseqa :  54%|█████▍    | 108/200 [2:45:20<2:17:44, 89.83s/it]Evaluating commonsenseqa :  60%|██████    | 121/200 [2:45:49<1:49:03, 82.83s/it]Evaluating commonsenseqa :  77%|███████▋  | 154/200 [2:48:16<50:21, 65.69s/it]Evaluating commonsenseqa :  45%|████▌     | 90/200 [2:46:43<3:49:30, 125.19s/it]Evaluating commonsenseqa :  61%|██████    | 122/200 [2:47:12<1:47:45, 82.88s/it]Evaluating commonsenseqa :  78%|███████▊  | 155/200 [2:49:21<49:11, 65.59s/it]Evaluating commonsenseqa :  55%|█████▍    | 109/200 [2:47:01<2:21:30, 93.30s/it]Evaluating commonsenseqa :  36%|███▋      | 73/200 [2:48:37<5:11:50, 147.33s/it]Evaluating commonsenseqa :  46%|████▌     | 91/200 [2:48:49<3:48:10, 125.60s/it]Evaluating commonsenseqa :  78%|███████▊  | 156/200 [2:50:27<48:08, 65.64s/it]Evaluating commonsenseqa :  62%|██████▏   | 123/200 [2:48:35<1:46:23, 82.91s/it]Evaluating commonsenseqa :  55%|█████▌    | 110/200 [2:48:45<2:24:40, 96.46s/it]Evaluating commonsenseqa :  37%|███▋      | 74/200 [2:49:56<4:25:51, 126.60s/it]Evaluating commonsenseqa :  78%|███████▊  | 157/200 [2:51:32<46:58, 65.54s/it]Evaluating commonsenseqa :  62%|██████▏   | 124/200 [2:49:59<1:45:17, 83.12s/it]Evaluating commonsenseqa :  46%|████▌     | 92/200 [2:51:00<3:49:08, 127.30s/it]Evaluating commonsenseqa :  79%|███████▉  | 158/200 [2:52:37<45:50, 65.49s/it]Evaluating commonsenseqa :  56%|█████▌    | 111/200 [2:50:27<2:25:30, 98.09s/it]Evaluating commonsenseqa :  62%|██████▎   | 125/200 [2:51:21<1:43:30, 82.81s/it]Evaluating commonsenseqa :  38%|███▊      | 75/200 [2:52:23<4:36:56, 132.93s/it]Evaluating commonsenseqa :  80%|███████▉  | 159/200 [2:53:44<45:02, 65.91s/it]Evaluating commonsenseqa :  56%|█████▌    | 112/200 [2:52:10<2:25:59, 99.54s/it]Evaluating commonsenseqa :  63%|██████▎   | 126/200 [2:52:44<1:42:16, 82.93s/it]Evaluating commonsenseqa :  46%|████▋     | 93/200 [2:53:08<3:47:16, 127.44s/it]Evaluating commonsenseqa :  80%|████████  | 160/200 [2:54:50<43:52, 65.81s/it]Evaluating commonsenseqa :  80%|████████  | 161/200 [2:55:55<42:43, 65.72s/it]Evaluating commonsenseqa :  64%|██████▎   | 127/200 [2:54:07<1:40:51, 82.90s/it]Evaluating commonsenseqa :  38%|███▊      | 76/200 [2:54:53<4:44:58, 137.89s/it]Evaluating commonsenseqa :  56%|█████▋    | 113/200 [2:53:51<2:24:50, 99.89s/it]Evaluating commonsenseqa :  47%|████▋     | 94/200 [2:55:18<3:46:24, 128.16s/it]Evaluating commonsenseqa :  81%|████████  | 162/200 [2:56:55<40:31, 63.99s/it]Evaluating commonsenseqa :  57%|█████▋    | 114/200 [2:54:53<2:07:03, 88.65s/it]Evaluating commonsenseqa :  64%|██████▍   | 128/200 [2:55:29<1:39:25, 82.85s/it]Evaluating commonsenseqa :  82%|████████▏ | 163/200 [2:58:01<39:50, 64.61s/it]Evaluating commonsenseqa :  38%|███▊      | 77/200 [2:57:21<4:49:21, 141.15s/it]Evaluating commonsenseqa :  64%|██████▍   | 129/200 [2:56:53<1:38:06, 82.91s/it]Evaluating commonsenseqa :  57%|█████▊    | 115/200 [2:56:35<2:11:04, 92.53s/it]Evaluating commonsenseqa :  48%|████▊     | 95/200 [2:57:25<3:43:32, 127.74s/it]Evaluating commonsenseqa :  82%|████████▏ | 164/200 [2:59:07<38:55, 64.88s/it]Evaluating commonsenseqa :  82%|████████▎ | 165/200 [3:00:13<38:05, 65.30s/it]Evaluating commonsenseqa :  65%|██████▌   | 130/200 [2:58:16<1:36:53, 83.04s/it]Evaluating commonsenseqa :  58%|█████▊    | 116/200 [2:58:17<2:13:44, 95.53s/it]Evaluating commonsenseqa :  48%|████▊     | 96/200 [2:59:35<3:42:53, 128.59s/it]Evaluating commonsenseqa :  39%|███▉      | 78/200 [2:59:50<4:51:41, 143.46s/it]Evaluating commonsenseqa :  83%|████████▎ | 166/200 [3:01:20<37:12, 65.65s/it]Evaluating commonsenseqa :  66%|██████▌   | 131/200 [2:59:39<1:35:22, 82.94s/it]Evaluating commonsenseqa :  58%|█████▊    | 117/200 [2:59:58<2:14:12, 97.02s/it]Evaluating commonsenseqa :  84%|████████▎ | 167/200 [3:02:26<36:10, 65.78s/it]Evaluating commonsenseqa :  66%|██████▌   | 132/200 [3:01:02<1:34:00, 82.96s/it]Evaluating commonsenseqa :  48%|████▊     | 97/200 [3:01:45<3:41:02, 128.76s/it]Evaluating commonsenseqa :  84%|████████▍ | 168/200 [3:03:31<35:01, 65.67s/it]Evaluating commonsenseqa :  59%|█████▉    | 118/200 [3:01:14<2:04:17, 90.95s/it]Evaluating commonsenseqa :  40%|███▉      | 79/200 [3:02:18<4:51:48, 144.70s/it]Evaluating commonsenseqa :  66%|██████▋   | 133/200 [3:02:26<1:32:58, 83.26s/it]Evaluating commonsenseqa :  60%|█████▉    | 119/200 [3:02:12<1:49:17, 80.95s/it]Evaluating commonsenseqa :  84%|████████▍ | 169/200 [3:04:37<33:54, 65.63s/it]Evaluating commonsenseqa :  40%|████      | 80/200 [3:03:52<4:18:45, 129.38s/it]Evaluating commonsenseqa :  49%|████▉     | 98/200 [3:03:54<3:39:16, 128.98s/it]Evaluating commonsenseqa :  60%|██████    | 120/200 [3:03:08<1:38:04, 73.55s/it]Evaluating commonsenseqa :  85%|████████▌ | 170/200 [3:05:42<32:50, 65.67s/it]Evaluating commonsenseqa :  67%|██████▋   | 134/200 [3:03:48<1:31:21, 83.05s/it]Evaluating commonsenseqa :  86%|████████▌ | 171/200 [3:06:49<31:52, 65.96s/it]Evaluating commonsenseqa :  68%|██████▊   | 135/200 [3:05:12<1:30:17, 83.35s/it]Evaluating commonsenseqa :  60%|██████    | 121/200 [3:04:52<1:48:31, 82.43s/it]Evaluating commonsenseqa :  50%|████▉     | 99/200 [3:06:04<3:37:36, 129.27s/it]Evaluating commonsenseqa :  40%|████      | 81/200 [3:06:19<4:27:28, 134.86s/it]Evaluating commonsenseqa :  86%|████████▌ | 172/200 [3:07:55<30:50, 66.09s/it]Evaluating commonsenseqa :  68%|██████▊   | 136/200 [3:06:37<1:29:14, 83.67s/it]Evaluating commonsenseqa :  61%|██████    | 122/200 [3:06:34<1:55:02, 88.49s/it]Evaluating commonsenseqa :  86%|████████▋ | 173/200 [3:09:01<29:41, 65.98s/it]Evaluating commonsenseqa :  41%|████      | 82/200 [3:08:24<4:19:31, 131.96s/it]Evaluating commonsenseqa :  50%|█████     | 100/200 [3:08:11<3:34:24, 128.65s/it]Evaluating commonsenseqa :  68%|██████▊   | 137/200 [3:08:01<1:27:56, 83.76s/it]Evaluating commonsenseqa :  87%|████████▋ | 174/200 [3:10:05<28:16, 65.27s/it]Evaluating commonsenseqa :  62%|██████▏   | 123/200 [3:08:09<1:56:07, 90.49s/it]Evaluating commonsenseqa :  88%|████████▊ | 175/200 [3:11:11<27:18, 65.53s/it]Evaluating commonsenseqa :  69%|██████▉   | 138/200 [3:09:23<1:26:16, 83.49s/it]Evaluating commonsenseqa :  50%|█████     | 101/200 [3:10:22<3:33:21, 129.31s/it]Evaluating commonsenseqa :  42%|████▏     | 83/200 [3:10:53<4:27:01, 136.93s/it]Evaluating commonsenseqa :  62%|██████▏   | 124/200 [3:09:51<1:58:45, 93.75s/it]Evaluating commonsenseqa :  88%|████████▊ | 176/200 [3:12:17<26:16, 65.69s/it]Evaluating commonsenseqa :  70%|██████▉   | 139/200 [3:10:46<1:24:43, 83.33s/it]Evaluating commonsenseqa :  88%|████████▊ | 177/200 [3:13:23<25:15, 65.91s/it]Evaluating commonsenseqa :  42%|████▏     | 84/200 [3:12:18<3:54:40, 121.39s/it]Evaluating commonsenseqa :  62%|██████▎   | 125/200 [3:11:34<2:00:37, 96.50s/it]Evaluating commonsenseqa :  51%|█████     | 102/200 [3:12:30<3:30:43, 129.01s/it]Evaluating commonsenseqa :  70%|███████   | 140/200 [3:12:11<1:23:46, 83.77s/it]Evaluating commonsenseqa :  89%|████████▉ | 178/200 [3:14:29<24:06, 65.76s/it]Evaluating commonsenseqa :  70%|███████   | 141/200 [3:13:33<1:21:53, 83.28s/it]Evaluating commonsenseqa :  90%|████████▉ | 179/200 [3:15:35<23:00, 65.74s/it]Evaluating commonsenseqa :  63%|██████▎   | 126/200 [3:13:16<2:01:19, 98.38s/it]Evaluating commonsenseqa :  42%|████▎     | 85/200 [3:14:47<4:08:25, 129.61s/it]Evaluating commonsenseqa :  52%|█████▏    | 103/200 [3:14:39<3:28:37, 129.05s/it]Evaluating commonsenseqa :  90%|█████████ | 180/200 [3:16:36<21:28, 64.45s/it]Evaluating commonsenseqa :  71%|███████   | 142/200 [3:14:57<1:20:29, 83.26s/it]Evaluating commonsenseqa :  64%|██████▎   | 127/200 [3:15:00<2:01:35, 99.94s/it]Evaluating commonsenseqa :  90%|█████████ | 181/200 [3:17:24<18:53, 59.64s/it]Evaluating commonsenseqa :  43%|████▎     | 86/200 [3:16:47<4:00:41, 126.68s/it]Evaluating commonsenseqa :  72%|███████▏  | 143/200 [3:16:20<1:19:02, 83.20s/it]Evaluating commonsenseqa :  52%|█████▏    | 104/200 [3:16:47<3:25:45, 128.60s/it]Evaluating commonsenseqa :  91%|█████████ | 182/200 [3:18:30<18:25, 61.43s/it]Evaluating commonsenseqa :  64%|██████▍   | 128/200 [3:16:41<2:00:21, 100.29s/it]Evaluating commonsenseqa :  92%|█████████▏| 183/200 [3:19:36<17:47, 62.79s/it]Evaluating commonsenseqa :  72%|███████▏  | 144/200 [3:17:42<1:17:19, 82.86s/it]Evaluating commonsenseqa :  52%|█████▎    | 105/200 [3:18:47<3:19:43, 126.14s/it]Evaluating commonsenseqa :  44%|████▎     | 87/200 [3:19:14<4:10:20, 132.92s/it]Evaluating commonsenseqa :  92%|█████████▏| 184/200 [3:20:42<17:01, 63.86s/it]Evaluating commonsenseqa :  64%|██████▍   | 129/200 [3:18:23<1:59:14, 100.77s/it]Evaluating commonsenseqa :  72%|███████▎  | 145/200 [3:19:04<1:15:55, 82.83s/it]Evaluating commonsenseqa :  92%|█████████▎| 185/200 [3:21:49<16:10, 64.71s/it]Evaluating commonsenseqa :  44%|████▍     | 88/200 [3:20:51<3:47:48, 122.04s/it]Evaluating commonsenseqa :  73%|███████▎  | 146/200 [3:20:28<1:14:37, 82.92s/it]Evaluating commonsenseqa :  65%|██████▌   | 130/200 [3:20:04<1:57:33, 100.76s/it]Evaluating commonsenseqa :  53%|█████▎    | 106/200 [3:20:56<3:18:55, 126.98s/it]Evaluating commonsenseqa :  93%|█████████▎| 186/200 [3:22:55<15:10, 65.03s/it]Evaluating commonsenseqa :  74%|███████▎  | 147/200 [3:21:51<1:13:17, 82.96s/it]Evaluating commonsenseqa :  66%|██████▌   | 131/200 [3:21:34<1:52:15, 97.61s/it] Evaluating commonsenseqa :  94%|█████████▎| 187/200 [3:24:00<14:07, 65.19s/it]Evaluating commonsenseqa :  54%|█████▎    | 107/200 [3:23:03<3:16:34, 126.83s/it]Evaluating commonsenseqa :  44%|████▍     | 89/200 [3:23:19<4:00:05, 129.78s/it]Evaluating commonsenseqa :  94%|█████████▍| 188/200 [3:25:06<13:04, 65.41s/it]Evaluating commonsenseqa :  74%|███████▍  | 148/200 [3:23:14<1:11:53, 82.95s/it]Evaluating commonsenseqa :  66%|██████▌   | 132/200 [3:23:18<1:52:41, 99.44s/it]Evaluating commonsenseqa :  94%|█████████▍| 189/200 [3:26:12<12:00, 65.50s/it]Evaluating commonsenseqa :  74%|███████▍  | 149/200 [3:24:38<1:10:54, 83.42s/it]Evaluating commonsenseqa :  45%|████▌     | 90/200 [3:25:23<3:54:55, 128.14s/it]Evaluating commonsenseqa :  54%|█████▍    | 108/200 [3:25:10<3:14:39, 126.95s/it]Evaluating commonsenseqa :  95%|█████████▌| 190/200 [3:27:18<10:56, 65.66s/it]Evaluating commonsenseqa :  66%|██████▋   | 133/200 [3:24:59<1:51:39, 100.00s/it]Evaluating commonsenseqa :  55%|█████▍    | 109/200 [3:26:14<2:44:04, 108.18s/it]Evaluating commonsenseqa :  75%|███████▌  | 150/200 [3:26:01<1:09:25, 83.31s/it]Evaluating commonsenseqa :  96%|█████████▌| 191/200 [3:28:24<09:50, 65.63s/it]Evaluating commonsenseqa :  67%|██████▋   | 134/200 [3:26:41<1:50:44, 100.67s/it]Evaluating commonsenseqa :  46%|████▌     | 91/200 [3:27:51<4:03:23, 133.98s/it]Evaluating commonsenseqa :  76%|███████▌  | 151/200 [3:27:24<1:08:02, 83.32s/it]Evaluating commonsenseqa :  96%|█████████▌| 192/200 [3:29:30<08:46, 65.85s/it]Evaluating commonsenseqa :  55%|█████▌    | 110/200 [3:28:26<2:52:46, 115.19s/it]Evaluating commonsenseqa :  96%|█████████▋| 193/200 [3:30:36<07:41, 65.91s/it]Evaluating commonsenseqa :  46%|████▌     | 92/200 [3:29:17<3:35:36, 119.78s/it]Evaluating commonsenseqa :  76%|███████▌  | 152/200 [3:28:49<1:06:51, 83.58s/it]Evaluating commonsenseqa :  68%|██████▊   | 135/200 [3:28:24<1:49:39, 101.22s/it]Evaluating commonsenseqa :  97%|█████████▋| 194/200 [3:31:42<06:35, 65.92s/it]Evaluating commonsenseqa :  56%|█████▌    | 111/200 [3:30:34<2:56:24, 118.93s/it]Evaluating commonsenseqa :  76%|███████▋  | 153/200 [3:30:12<1:05:21, 83.43s/it]Evaluating commonsenseqa :  68%|██████▊   | 136/200 [3:30:05<1:48:02, 101.30s/it]Evaluating commonsenseqa :  98%|█████████▊| 195/200 [3:32:48<05:29, 65.82s/it]Evaluating commonsenseqa :  46%|████▋     | 93/200 [3:31:46<3:49:05, 128.47s/it]Evaluating commonsenseqa :  77%|███████▋  | 154/200 [3:31:34<1:03:48, 83.22s/it]Evaluating commonsenseqa :  98%|█████████▊| 196/200 [3:33:53<04:23, 65.80s/it]Evaluating commonsenseqa :  68%|██████▊   | 137/200 [3:31:46<1:46:12, 101.15s/it]Evaluating commonsenseqa :  56%|█████▌    | 112/200 [3:32:43<2:59:08, 122.14s/it]Evaluating commonsenseqa :  78%|███████▊  | 155/200 [3:32:58<1:02:34, 83.44s/it]Evaluating commonsenseqa :  98%|█████████▊| 197/200 [3:34:59<03:17, 65.73s/it]Evaluating commonsenseqa :  47%|████▋     | 94/200 [3:34:12<3:56:09, 133.67s/it]Evaluating commonsenseqa :  69%|██████▉   | 138/200 [3:33:30<1:45:28, 102.07s/it]Evaluating commonsenseqa :  99%|█████████▉| 198/200 [3:36:05<02:11, 65.75s/it]Evaluating commonsenseqa :  78%|███████▊  | 156/200 [3:34:22<1:01:11, 83.44s/it]Evaluating commonsenseqa :  56%|█████▋    | 113/200 [3:34:55<3:01:03, 124.86s/it]Evaluating commonsenseqa : 100%|█████████▉| 199/200 [3:37:10<01:05, 65.74s/it]Evaluating commonsenseqa :  70%|██████▉   | 139/200 [3:35:14<1:44:22, 102.67s/it]Evaluating commonsenseqa :  78%|███████▊  | 157/200 [3:35:44<59:28, 82.98s/it]  Evaluating commonsenseqa :  48%|████▊     | 95/200 [3:36:39<4:01:14, 137.85s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [3:38:16<00:00, 65.72s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [3:38:16<00:00, 65.48s/it]
name: commonsenseqa | avg. gen lenth: 383.517 | time: 13098.939425706863s
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10136 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o19-tmathqa-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 19 17 19 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2023-09-19 22:35:26,960] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o19-tmathqa-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 19
  out_domain_data_name ......... mathqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o19-tmathqa-s1-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 291141.18it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Evaluating commonsenseqa :  57%|█████▋    | 114/200 [3:37:01<2:59:36, 125.31s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.02s/it]
 > number of parameters: 6738415616
[2023-09-19 22:35:40,116] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.3, git-hash=unknown, git-branch=unknown
[2023-09-19 22:35:40,116] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-09-19 22:35:40,450] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-19 22:35:40,451] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2023-09-19 22:35:40,451] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-19 22:35:40,451] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-19 22:35:40,451] [INFO] [config.py:971:print]   amp_enabled .................. False
[2023-09-19 22:35:40,451] [INFO] [config.py:971:print]   amp_params ................... False
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f453023ada0>
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   communication_data_type ...... None
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   disable_allgather ............ False
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   dump_state ................... False
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   global_rank .................. 0
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   gradient_clipping ............ 0.0
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 2048
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   loss_scale ................... 0
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-19 22:35:40,452] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-19 22:35:40,453] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2023-09-19 22:35:40,453] [INFO] [config.py:971:print]   optimizer_name ............... None
[2023-09-19 22:35:40,453] [INFO] [config.py:971:print]   optimizer_params ............. None
[2023-09-19 22:35:40,453] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-19 22:35:40,453] [INFO] [config.py:971:print]   pld_enabled .................. False
[2023-09-19 22:35:40,453] [INFO] [config.py:971:print]   pld_params ................... False
[2023-09-19 22:35:40,453] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2023-09-19 22:35:40,453] [INFO] [config.py:971:print]   scheduler_name ............... None
[2023-09-19 22:35:40,453] [INFO] [config.py:971:print]   scheduler_params ............. None
[2023-09-19 22:35:40,453] [INFO] [config.py:971:print]   sparse_attention ............. None
[2023-09-19 22:35:40,453] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2023-09-19 22:35:40,453] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2023-09-19 22:35:40,453] [INFO] [config.py:971:print]   train_batch_size ............. 1
[2023-09-19 22:35:40,453] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  1
[2023-09-19 22:35:40,453] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2023-09-19 22:35:40,453] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2023-09-19 22:35:40,453] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2023-09-19 22:35:40,453] [INFO] [config.py:971:print]   world_size ................... 1
[2023-09-19 22:35:40,453] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  True
[2023-09-19 22:35:40,453] [INFO] [config.py:971:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2023-09-19 22:35:40,453] [INFO] [config.py:971:print]   zero_enabled ................. False
[2023-09-19 22:35:40,453] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-19 22:35:40,453] [INFO] [config.py:971:print]   zero_optimization_stage ...... 0
[2023-09-19 22:35:40,453] [INFO] [config.py:957:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/200 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: what is 12 percent of 80? a ) 11.21, b ) 9.6, c ) 8.66, d ) 12.23, e ) 13.1
Output: "we assume that 80 is 100 % assume'x'is value we looking for here, 80 = 100 % and x = 12 % therefore, 80 / x = 100 % / 12 % 80 / x = 8.33 x = 9.6 b"
So the final answer is b

Input: a and b started a business investing rs. 92,000 and rs 20,000 respectively. in what ratio the profit earned after 2 years be divided between a and b respectively? a ) 9 : 2, b ) 3 : 2, c ) 23 : 5, d ) 18 : 4, e ) 17 : 4
Output: a : b = 92000 : 20000 = 92 : 20 = 46 : 10 = 23 : 5 answer : c
So the final answer is c

Input: a merchant purchased a jacket for $ 60 and then determined a selling price that equalled the purchase price of the jacket plus a markup that was 20 percent of the selling price. during a sale, the merchant discounted the selling price by 20 percent and sold the jacket. what was the merchant ’ s gross profit on this sale? a ) $ 0, b ) $ 3, c ) $ 4, d ) $ 12, e ) $ 15
Output: "actual cost = $ 60 sp = actual cost + mark up = actual cost + 20 % sp = 60 * 100 / 80 on sale sp = 80 / 100 ( 60 * 100 / 80 ) = 60 gross profit = $ 0 answer is a"
So the final answer is a

Input: on a two - dimensional coordinate plane, the line q = x ^ 2 - x ^ 3 touches the x - axis in how many places? a ) 0, b ) 1, c ) 2, d ) 3, e ) 4
Output: "apparently it's q = x ^ 2 - x ^ 3 instead of q = x ^ 2 - q ^ 3. in this case : the x - intercept is the value ( s ) of x for q = 0. 0 = x ^ 2 - x ^ 3 ; 0 = x ^ 2 ( 1 - x ) ; x = 0 or x = 1. answer : c."
So the final answer is c

Input: angelo and isabella are both salespersons. in any given week, angelo makes $ 550 in base salary plus 8 percent of the portion of his sales above $ 3,000 for that week. isabella makes 10 percent of her total sales for any given week. for what amount of weekly sales would angelo and isabella earn the same amount of money? a ) 23,500, b ) 15,500, c ) 25,500, d ) 26,500, e ) 27,500
Output: "official solution : the problem asks for the amount of weekly sales it takes for angelo and isabella to earn the same amount of money. you can write an equation that sets angelo ’ s and isabella ’ s weekly earnings equal to each other, with x representing weekly sales. weekly earnings for each salesperson equal base salary plus commission. so angelo ’ s earnings are 550 + ( 0.08 ) ( x – 3,000 ), and isabella ’ s are 0.10 x. set up the equation and solve : 550 + ( 0.08 ) ( x – 3,000 ) = 0.10 x distribute the 0.08 : 550 + 0.08 x – 240 = 0.10 x combine terms and subtract 0.08 x from both sides : 310 = 0.02 x divide both sides by 0.02 : 15,500 = x your answer is b."
So the final answer is b

Input: find the total number of prime factors in the expression ( 4 ) ^ 11 x ( 7 ) ^ 5 x ( 11 ) ^ 3 a ) 26, b ) 22, c ) 25, d ) 30, e ) 29
Output: "( 4 ) ^ 11 x ( 7 ) ^ 5 x ( 11 ) ^ 3 = ( 2 x 2 ) ^ 11 x ( 7 ) ^ 5 x ( 11 ) ^ 3 = 2 ^ 11 x 2 ^ 11 x 7 ^ 5 x 11 ^ 3 = 2 ^ 22 x 7 ^ 5 x 11 ^ 3 total number of prime factors = ( 22 + 5 + 3 ) = 30. answer is d."
So the final answer is d

Input: the length of the bridge, which a train 140 m long and traveling at 45 km / hr can cross in 30 sec is? a ) 235, b ) 240, c ) 245, d ) 250, e ) 255
Output: "speed = 45 * 5 / 18 = 25 / 2 m / sec. time = 30 sec let the length of bridge be x meters. then, ( 140 + x ) / 30 = 25 / 2 x = 235 m. answer : option a"
So the final answer is a

Input: 360 metres long yard, 31 trees are palnted at equal distances, one tree being at each end of the yard. what is the distance between 2 consecutive trees a ) 10, b ) 12, c ) 14, d ) 16, e ) 17
Output: "31 trees have 30 gaps between them, required distance ( 360 / 30 ) = 12 b"
So the final answer is b

Input: a vessel of capacity 45 litres is fully filled with pure milk. nine litres of milk is removed from the vessel and replaced with water. nine litres of the solution thus formed is removed and replaced with water. find the quantity of pure milk in the final milk solution? a ) 28.8, b ) 72.9, c ) 38.3, d ) 78.3, e ) 79.3
Output: "explanation : let the initial quantity of milk in vessel be t litres. let us say y litres of the mixture is taken out and replaced by water for n times, alternatively. quantity of milk finally in the vessel is then given by [ ( t - y ) / t ] ^ n * t for the given problem, t = 45, y = 9 and n = 2. hence, quantity of milk finally in the vessel = [ ( 45 - 9 ) / 45 ] ^ 2 ( 45 ) = 28.8 litres. answer : option a"
So the final answer is a

Input: a certain telescope increases the visual range at a particular location from 90 kilometers to 150 kilometers. by what percent is the visual range increased by using the telescope? a ) 30 %, b ) 33 1 / 2 %, c ) 40 %, d ) 60 %, e ) 66 2 / 3 %
Output: "original visual range = 90 km new visual range = 150 km percent increase in the visual range by using the telescope = ( 150 - 90 ) / 90 * 100 % = 2 / 3 * 100 % = 66.67 % answer e"
So the final answer is e

Input: a bag contains 6 black and 3 white balls. one ball is drawn at random. what is the probability that the ball drawn is white? a ) 3 / 4, b ) 1 / 3, c ) 1 / 7, d ) 1 / 8, e ) 4 / 3
Output: "let number of balls = ( 6 + 3 ) = 9. number of white balls = 3. p ( drawing a white ball ) = 3 / 9 = 1 / 3. option b."
So the final answer is b

Input: rajat, vikas and abhishek are submitting questions in the ratio 7 : 3 : 2. if total number of questions submitted by them is 24. find the number of questions submitted by vikas. a ) 3, b ) 4, c ) 5, d ) 6, e ) 7
Output: explanation : number of questions submitted by vikas = ( 24 * 3 ) / ( 7 + 3 + 2 ) = 6 answer : d
So the final answer is d

Input: at a certain restaurant, the ratio of the number of cooks to the number of waiters is 3 to 8. when 12 more waiters are hired, the ratio of the number of cooks to the number of waiters changes to 1 to 4. how many cooks does the restaurant have? a ) 4, b ) 6, c ) 9, d ) 12, e ) 15
Output: originally there were 3 k cooks and 8 k waiters. the new ratio is 1 : 4 which equals 3 : 12. 12 k = 8 k + 12 k = 3 there are 9 cooks. the answer is c.
So the final answer is c

Input: if 7 ^ k + 7 ^ k = ( 7 ^ 9 ) ^ ( 7 ^ 9 ) - 7 ^ k, then k =? a ) 11 / 3, b ) 11 / 2, c ) 242, d ) 3 ^ 10, e ) 7 ^ 11 - 1
Output: "7 ^ k + 7 ^ k = ( 7 ^ 9 ) ^ 7 ^ 9 - 7 ^ k 7 * ( 7 ^ k ) = 7 ^ ( 49 * 7 ^ 9 ) = 7 ^ ( 7 ^ 2 * 7 ^ 9 ) = 7 ^ ( 7 ^ 11 ) 7 ^ k + 1 = 7 ^ ( 7 ^ 11 ) so k + 1 = 7 ^ 11 so k = 7 ^ 11 - 1 answer is e"
So the final answer is e

Input: average of 10 matches is 32, how many runs one should should score to increase his average by 4 runs. a ) 70, b ) 76, c ) 78, d ) 80, e ) 88
Output: "explanation : average after 11 innings should be 36 so, required score = ( 11 * 36 ) - ( 10 * 32 ) = 396 - 320 = 76 answer : option b"
So the final answer is b

Input: a ’ s speed is 20 / 19 times that of b. if a and b run a race, what part of the length of the race should a give b as a head start, so that the race ends in a dead heat? a ) 1 / 19, b ) 3 / 19, c ) 1 / 10, d ) 1 / 20, e ) 3 / 10
Output: "let d be the full distance. let x be the fraction of the distance that b runs. let v be the speed at which b runs. the time should be the same for both runners. time = d / ( 20 v / 19 ) = xd / v ( 19 / 20 ) * d / v = x * d / v x = 19 / 20 b should have a head start of 1 / 20 of the full distance. the answer is d."
So the final answer is d

Input: the length of a rectangular plot is 10 mtr more than its width. the cost of fencing the plot along its perimeter at the rate of rs. 6.5 mtr is rs. 2210. the perimeter of the plot is? a ) 126, b ) 156, c ) 340, d ) 321, e ) 260
Output: "sol. let width = x, length = ( 10 + x ) perimeter = 2 ( x + ( 10 + x ) ) = 2 ( 2 x = 10 ) & 2 ( 2 x + 10 ) * 6.5 = 2210 x = 80 required perimeter = 2 ( 80 + 90 ) = 340 c"
So the final answer is c

Input: if n = 2 ^ 0.1 and n ^ b = 16, b must equal a ) 3 / 80, b ) 3 / 5, c ) 40, d ) 5 / 3, e ) 80 / 3
Output: 10 / 100 = 1 / 10 n = 2 ^ 1 / 10 n ^ b = 2 ^ 4 ( 2 ^ 1 / 10 ) ^ b = 2 ^ 4 b = 40 answer : c
So the final answer is c

Input: 150 ml of 30 % sulphuric acid was added to approximate 400 ml of 12 % sulphuric acid solution. find the approximate concentration c of the acid in the mixture? a ) 1 / 2, b ) 1 / 3, c ) 1 / 4, d ) 1 / 6, e ) 1 / 5
Output: "do not need any computation 30 % - - - - - - - - - - - 21 % - - - - - - - - - 12 % if volume of both sol. were equal the concentration c would be 21 % = 1 / 5, but 12 % is more than 3 times only possibility is 1 / 6 d"
So the final answer is d

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o19-tmathqa-s1-rTrue-m4096
Evaluating commonsenseqa :   0%|          | 0/200 [00:07<?, ?it/s]
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 97, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 94, in main
    inference_main(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 90, in inference_main
    query_ids, response_ids, answers, indices = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 65, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 1942626) of binary: /home/ylu130/.conda/envs/ood/bin/python
Traceback (most recent call last):
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py", line 196, in <module>
    main()
  File "/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py", line 192, in main
    launch(args)
  File "/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py", line 177, in launch
    run(args)
  File "/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/ylu130/workspace/in-context-generalization/inference.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-09-19_22:35:50
  host      : ia1.wse.jhu.edu
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 1942626)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10136 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o17-tmathqa-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 17 17 19 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2023-09-19 22:35:53,452] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o17-tmathqa-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 17
  out_domain_data_name ......... mathqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o17-tmathqa-s1-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 292760.06it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.05s/it]
 > number of parameters: 6738415616
[2023-09-19 22:36:06,428] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.3, git-hash=unknown, git-branch=unknown
[2023-09-19 22:36:06,428] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-09-19 22:36:06,782] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-19 22:36:06,783] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2023-09-19 22:36:06,783] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-19 22:36:06,783] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-19 22:36:06,783] [INFO] [config.py:971:print]   amp_enabled .................. False
[2023-09-19 22:36:06,783] [INFO] [config.py:971:print]   amp_params ................... False
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f75504f2da0>
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   communication_data_type ...... None
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   disable_allgather ............ False
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   dump_state ................... False
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   global_rank .................. 0
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   gradient_clipping ............ 0.0
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 2048
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   loss_scale ................... 0
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-19 22:36:06,784] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-19 22:36:06,785] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2023-09-19 22:36:06,785] [INFO] [config.py:971:print]   optimizer_name ............... None
[2023-09-19 22:36:06,785] [INFO] [config.py:971:print]   optimizer_params ............. None
[2023-09-19 22:36:06,785] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-19 22:36:06,785] [INFO] [config.py:971:print]   pld_enabled .................. False
[2023-09-19 22:36:06,785] [INFO] [config.py:971:print]   pld_params ................... False
[2023-09-19 22:36:06,785] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2023-09-19 22:36:06,785] [INFO] [config.py:971:print]   scheduler_name ............... None
[2023-09-19 22:36:06,785] [INFO] [config.py:971:print]   scheduler_params ............. None
[2023-09-19 22:36:06,785] [INFO] [config.py:971:print]   sparse_attention ............. None
[2023-09-19 22:36:06,785] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2023-09-19 22:36:06,785] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2023-09-19 22:36:06,785] [INFO] [config.py:971:print]   train_batch_size ............. 1
[2023-09-19 22:36:06,785] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  1
[2023-09-19 22:36:06,785] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2023-09-19 22:36:06,785] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2023-09-19 22:36:06,785] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2023-09-19 22:36:06,785] [INFO] [config.py:971:print]   world_size ................... 1
[2023-09-19 22:36:06,785] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  True
[2023-09-19 22:36:06,785] [INFO] [config.py:971:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2023-09-19 22:36:06,785] [INFO] [config.py:971:print]   zero_enabled ................. False
[2023-09-19 22:36:06,785] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-19 22:36:06,785] [INFO] [config.py:971:print]   zero_optimization_stage ...... 0
[2023-09-19 22:36:06,785] [INFO] [config.py:957:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/200 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: what is 12 percent of 80? a ) 11.21, b ) 9.6, c ) 8.66, d ) 12.23, e ) 13.1
Output: b

Input: a and b started a business investing rs. 92,000 and rs 20,000 respectively. in what ratio the profit earned after 2 years be divided between a and b respectively? a ) 9 : 2, b ) 3 : 2, c ) 23 : 5, d ) 18 : 4, e ) 17 : 4
Output: c

Input: a merchant purchased a jacket for $ 60 and then determined a selling price that equalled the purchase price of the jacket plus a markup that was 20 percent of the selling price. during a sale, the merchant discounted the selling price by 20 percent and sold the jacket. what was the merchant ’ s gross profit on this sale? a ) $ 0, b ) $ 3, c ) $ 4, d ) $ 12, e ) $ 15
Output: a

Input: on a two - dimensional coordinate plane, the line q = x ^ 2 - x ^ 3 touches the x - axis in how many places? a ) 0, b ) 1, c ) 2, d ) 3, e ) 4
Output: c

Input: angelo and isabella are both salespersons. in any given week, angelo makes $ 550 in base salary plus 8 percent of the portion of his sales above $ 3,000 for that week. isabella makes 10 percent of her total sales for any given week. for what amount of weekly sales would angelo and isabella earn the same amount of money? a ) 23,500, b ) 15,500, c ) 25,500, d ) 26,500, e ) 27,500
Output: b

Input: find the total number of prime factors in the expression ( 4 ) ^ 11 x ( 7 ) ^ 5 x ( 11 ) ^ 3 a ) 26, b ) 22, c ) 25, d ) 30, e ) 29
Output: d

Input: the length of the bridge, which a train 140 m long and traveling at 45 km / hr can cross in 30 sec is? a ) 235, b ) 240, c ) 245, d ) 250, e ) 255
Output: a

Input: 360 metres long yard, 31 trees are palnted at equal distances, one tree being at each end of the yard. what is the distance between 2 consecutive trees a ) 10, b ) 12, c ) 14, d ) 16, e ) 17
Output: b

Input: a vessel of capacity 45 litres is fully filled with pure milk. nine litres of milk is removed from the vessel and replaced with water. nine litres of the solution thus formed is removed and replaced with water. find the quantity of pure milk in the final milk solution? a ) 28.8, b ) 72.9, c ) 38.3, d ) 78.3, e ) 79.3
Output: a

Input: a certain telescope increases the visual range at a particular location from 90 kilometers to 150 kilometers. by what percent is the visual range increased by using the telescope? a ) 30 %, b ) 33 1 / 2 %, c ) 40 %, d ) 60 %, e ) 66 2 / 3 %
Output: e

Input: a bag contains 6 black and 3 white balls. one ball is drawn at random. what is the probability that the ball drawn is white? a ) 3 / 4, b ) 1 / 3, c ) 1 / 7, d ) 1 / 8, e ) 4 / 3
Output: b

Input: rajat, vikas and abhishek are submitting questions in the ratio 7 : 3 : 2. if total number of questions submitted by them is 24. find the number of questions submitted by vikas. a ) 3, b ) 4, c ) 5, d ) 6, e ) 7
Output: d

Input: at a certain restaurant, the ratio of the number of cooks to the number of waiters is 3 to 8. when 12 more waiters are hired, the ratio of the number of cooks to the number of waiters changes to 1 to 4. how many cooks does the restaurant have? a ) 4, b ) 6, c ) 9, d ) 12, e ) 15
Output: c

Input: if 7 ^ k + 7 ^ k = ( 7 ^ 9 ) ^ ( 7 ^ 9 ) - 7 ^ k, then k =? a ) 11 / 3, b ) 11 / 2, c ) 242, d ) 3 ^ 10, e ) 7 ^ 11 - 1
Output: e

Input: average of 10 matches is 32, how many runs one should should score to increase his average by 4 runs. a ) 70, b ) 76, c ) 78, d ) 80, e ) 88
Output: b

Input: a ’ s speed is 20 / 19 times that of b. if a and b run a race, what part of the length of the race should a give b as a head start, so that the race ends in a dead heat? a ) 1 / 19, b ) 3 / 19, c ) 1 / 10, d ) 1 / 20, e ) 3 / 10
Output: d

Input: the length of a rectangular plot is 10 mtr more than its width. the cost of fencing the plot along its perimeter at the rate of rs. 6.5 mtr is rs. 2210. the perimeter of the plot is? a ) 126, b ) 156, c ) 340, d ) 321, e ) 260
Output: c

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o17-tmathqa-s1-rFalse-m4096
Evaluating commonsenseqa :  79%|███████▉  | 158/200 [3:37:08<58:20, 83.34s/it]Evaluating commonsenseqa :  70%|███████   | 140/200 [3:36:55<1:42:01, 102.02s/it]Evaluating commonsenseqa :  48%|████▊     | 96/200 [3:39:04<4:02:26, 139.87s/it]Evaluating commonsenseqa :  80%|███████▉  | 159/200 [3:38:30<56:36, 82.84s/it]Evaluating commonsenseqa :   0%|          | 1/200 [01:33<5:09:44, 93.39s/it]Evaluating commonsenseqa :  57%|█████▊    | 115/200 [3:39:10<2:59:13, 126.51s/it]Evaluating commonsenseqa :  70%|███████   | 141/200 [3:38:34<1:39:25, 101.12s/it]Evaluating commonsenseqa :  80%|████████  | 160/200 [3:39:51<54:56, 82.41s/it]Evaluating commonsenseqa :   1%|          | 2/200 [03:07<5:08:55, 93.61s/it]Evaluating commonsenseqa :  71%|███████   | 142/200 [3:40:17<1:38:16, 101.67s/it]Evaluating commonsenseqa :  58%|█████▊    | 116/200 [3:41:17<2:57:08, 126.53s/it]Evaluating commonsenseqa :  48%|████▊     | 97/200 [3:41:32<4:04:23, 142.36s/it]Evaluating commonsenseqa :  80%|████████  | 161/200 [3:41:13<53:31, 82.34s/it]Evaluating commonsenseqa :  72%|███████▏  | 143/200 [3:41:11<1:22:58, 87.34s/it] Evaluating commonsenseqa :   2%|▏         | 3/200 [04:40<5:06:17, 93.29s/it]Evaluating commonsenseqa :  81%|████████  | 162/200 [3:42:36<52:10, 82.37s/it]Evaluating commonsenseqa :  72%|███████▏  | 144/200 [3:42:26<1:18:05, 83.67s/it]Evaluating commonsenseqa :  58%|█████▊    | 117/200 [3:43:27<2:56:30, 127.59s/it]Evaluating commonsenseqa :   2%|▏         | 4/200 [06:12<5:03:57, 93.05s/it]Evaluating commonsenseqa :  49%|████▉     | 98/200 [3:44:00<4:04:42, 143.94s/it]Evaluating commonsenseqa :  72%|███████▎  | 145/200 [3:43:24<1:09:48, 76.15s/it]Evaluating commonsenseqa :  82%|████████▏ | 163/200 [3:43:58<50:50, 82.44s/it]Evaluating commonsenseqa :  50%|████▉     | 99/200 [3:44:51<3:15:41, 116.26s/it]Evaluating commonsenseqa :   2%|▎         | 5/200 [07:46<5:03:01, 93.24s/it]Evaluating commonsenseqa :  59%|█████▉    | 118/200 [3:45:33<2:53:45, 127.14s/it]Evaluating commonsenseqa :  82%|████████▏ | 164/200 [3:45:20<49:22, 82.29s/it]Evaluating commonsenseqa :  73%|███████▎  | 146/200 [3:45:03<1:14:44, 83.04s/it]Evaluating commonsenseqa :   3%|▎         | 6/200 [09:19<5:00:58, 93.09s/it]Evaluating commonsenseqa :  50%|█████     | 100/200 [3:47:20<3:29:40, 125.81s/it]Evaluating commonsenseqa :  82%|████████▎ | 165/200 [3:46:43<48:02, 82.37s/it]Evaluating commonsenseqa :  74%|███████▎  | 147/200 [3:46:25<1:12:58, 82.62s/it]Evaluating commonsenseqa :  60%|█████▉    | 119/200 [3:47:20<2:43:30, 121.12s/it]Evaluating commonsenseqa :   4%|▎         | 7/200 [10:52<4:59:45, 93.19s/it]Evaluating commonsenseqa :  83%|████████▎ | 166/200 [3:48:04<46:31, 82.10s/it]Evaluating commonsenseqa :  74%|███████▍  | 148/200 [3:48:05<1:16:04, 87.79s/it]Evaluating commonsenseqa :  50%|█████     | 101/200 [3:49:37<3:33:27, 129.37s/it]Evaluating commonsenseqa :  60%|██████    | 120/200 [3:49:28<2:44:18, 123.24s/it]Evaluating commonsenseqa :  84%|████████▎ | 167/200 [3:49:26<45:03, 81.93s/it]Evaluating commonsenseqa :   4%|▍         | 8/200 [12:26<4:58:38, 93.33s/it]Evaluating commonsenseqa :  74%|███████▍  | 149/200 [3:49:46<1:18:04, 91.86s/it]Evaluating commonsenseqa :  84%|████████▍ | 168/200 [3:50:49<43:54, 82.32s/it]Evaluating commonsenseqa :   4%|▍         | 9/200 [13:59<4:57:00, 93.30s/it]Evaluating commonsenseqa :  60%|██████    | 121/200 [3:51:36<2:44:04, 124.61s/it]Evaluating commonsenseqa :  51%|█████     | 102/200 [3:52:04<3:39:46, 134.56s/it]Evaluating commonsenseqa :  75%|███████▌  | 150/200 [3:51:28<1:19:05, 94.91s/it]Evaluating commonsenseqa :   5%|▌         | 10/200 [14:51<4:14:59, 80.53s/it]Evaluating commonsenseqa :  84%|████████▍ | 169/200 [3:52:12<42:41, 82.64s/it]Evaluating commonsenseqa :  76%|███████▌  | 151/200 [3:52:05<1:03:20, 77.56s/it]Evaluating commonsenseqa :  52%|█████▏    | 103/200 [3:53:38<3:18:05, 122.53s/it]Evaluating commonsenseqa :  61%|██████    | 122/200 [3:53:44<2:43:14, 125.57s/it]Evaluating commonsenseqa :   6%|▌         | 11/200 [16:15<4:16:44, 81.50s/it]Evaluating commonsenseqa :  85%|████████▌ | 170/200 [3:53:34<41:12, 82.41s/it]Evaluating commonsenseqa :  76%|███████▌  | 152/200 [3:53:48<1:07:57, 84.96s/it]Evaluating commonsenseqa :  62%|██████▏   | 123/200 [3:54:58<2:21:16, 110.08s/it]Evaluating commonsenseqa :   6%|▌         | 12/200 [17:27<4:06:42, 78.73s/it]Evaluating commonsenseqa :  86%|████████▌ | 171/200 [3:54:58<39:59, 82.73s/it]Evaluating commonsenseqa :  52%|█████▏    | 104/200 [3:56:08<3:29:03, 130.66s/it]Evaluating commonsenseqa :   6%|▋         | 13/200 [18:33<3:53:47, 75.01s/it]Evaluating commonsenseqa :  76%|███████▋  | 153/200 [3:55:29<1:10:28, 89.96s/it]Evaluating commonsenseqa :  86%|████████▌ | 172/200 [3:56:19<38:26, 82.37s/it]Evaluating commonsenseqa :  62%|██████▏   | 124/200 [3:57:06<2:26:15, 115.47s/it]Evaluating commonsenseqa :  52%|█████▎    | 105/200 [3:57:22<2:59:57, 113.66s/it]Evaluating commonsenseqa :   7%|▋         | 14/200 [19:56<3:59:31, 77.27s/it]Evaluating commonsenseqa :  77%|███████▋  | 154/200 [3:57:13<1:12:06, 94.05s/it]Evaluating commonsenseqa :  86%|████████▋ | 173/200 [3:57:42<37:09, 82.57s/it]Evaluating commonsenseqa :  53%|█████▎    | 106/200 [3:58:28<2:35:32, 99.28s/it] Evaluating commonsenseqa :   8%|▊         | 15/200 [21:29<4:13:17, 82.15s/it]Evaluating commonsenseqa :  62%|██████▎   | 125/200 [3:59:16<2:29:51, 119.89s/it]Evaluating commonsenseqa :  87%|████████▋ | 174/200 [3:59:05<35:50, 82.72s/it]Evaluating commonsenseqa :  78%|███████▊  | 155/200 [3:58:55<1:12:22, 96.50s/it]Evaluating commonsenseqa :   8%|▊         | 16/200 [23:03<4:22:37, 85.64s/it]Evaluating commonsenseqa :  54%|█████▎    | 107/200 [4:00:55<2:56:16, 113.73s/it]Evaluating commonsenseqa :  88%|████████▊ | 175/200 [4:00:29<34:33, 82.92s/it]Evaluating commonsenseqa :  63%|██████▎   | 126/200 [4:01:26<2:31:28, 122.82s/it]Evaluating commonsenseqa :  78%|███████▊  | 156/200 [4:00:37<1:11:54, 98.05s/it]Evaluating commonsenseqa :   8%|▊         | 17/200 [24:35<4:26:44, 87.46s/it]Evaluating commonsenseqa :  88%|████████▊ | 176/200 [4:01:51<33:03, 82.65s/it]Evaluating commonsenseqa :  78%|███████▊  | 157/200 [4:02:19<1:11:15, 99.44s/it]Evaluating commonsenseqa :  54%|█████▍    | 108/200 [4:03:25<3:10:47, 124.43s/it]Evaluating commonsenseqa :  64%|██████▎   | 127/200 [4:03:34<2:31:34, 124.59s/it]Evaluating commonsenseqa :  88%|████████▊ | 177/200 [4:03:13<31:36, 82.44s/it]Evaluating commonsenseqa :   9%|▉         | 18/200 [26:07<4:30:06, 89.05s/it]Evaluating commonsenseqa :  79%|███████▉  | 158/200 [4:04:01<1:09:57, 99.94s/it]Evaluating commonsenseqa :  89%|████████▉ | 178/200 [4:04:36<30:18, 82.64s/it]Evaluating commonsenseqa :  10%|▉         | 19/200 [27:42<4:33:17, 90.59s/it]Evaluating commonsenseqa :  55%|█████▍    | 109/200 [4:05:51<3:18:38, 130.97s/it]Evaluating commonsenseqa :  64%|██████▍   | 128/200 [4:05:45<2:31:52, 126.56s/it]Evaluating commonsenseqa :  90%|████████▉ | 179/200 [4:06:00<29:02, 83.00s/it]Evaluating commonsenseqa :  80%|███████▉  | 159/200 [4:05:42<1:08:39, 100.47s/it]Evaluating commonsenseqa :  10%|█         | 20/200 [29:14<4:33:33, 91.19s/it]Evaluating commonsenseqa :  90%|█████████ | 180/200 [4:07:22<27:35, 82.75s/it]Evaluating commonsenseqa :  55%|█████▌    | 110/200 [4:08:02<3:16:42, 131.14s/it]Evaluating commonsenseqa :  64%|██████▍   | 129/200 [4:07:54<2:30:34, 127.25s/it]Evaluating commonsenseqa :  80%|████████  | 160/200 [4:07:23<1:07:07, 100.68s/it]Evaluating commonsenseqa :  10%|█         | 21/200 [30:46<4:32:34, 91.36s/it]Evaluating commonsenseqa :  90%|█████████ | 181/200 [4:08:45<26:16, 82.95s/it]Evaluating commonsenseqa :  11%|█         | 22/200 [32:18<4:31:10, 91.41s/it]Evaluating commonsenseqa :  80%|████████  | 161/200 [4:09:06<1:05:48, 101.24s/it]Evaluating commonsenseqa :  65%|██████▌   | 130/200 [4:10:04<2:29:14, 127.92s/it]Evaluating commonsenseqa :  56%|█████▌    | 111/200 [4:10:30<3:21:40, 135.97s/it]Evaluating commonsenseqa :  91%|█████████ | 182/200 [4:10:07<24:45, 82.55s/it]Evaluating commonsenseqa :  12%|█▏        | 23/200 [32:59<3:45:39, 76.50s/it]Evaluating commonsenseqa :  81%|████████  | 162/200 [4:09:57<54:39, 86.31s/it]   Evaluating commonsenseqa :  92%|█████████▏| 183/200 [4:11:29<23:20, 82.36s/it]Evaluating commonsenseqa :  12%|█▏        | 24/200 [34:32<3:58:42, 81.38s/it]Evaluating commonsenseqa :  66%|██████▌   | 131/200 [4:12:12<2:27:01, 127.85s/it]Evaluating commonsenseqa :  82%|████████▏ | 163/200 [4:11:40<56:14, 91.21s/it]Evaluating commonsenseqa :  56%|█████▌    | 112/200 [4:12:57<3:24:28, 139.41s/it]Evaluating commonsenseqa :  92%|█████████▏| 184/200 [4:12:51<21:57, 82.33s/it]Evaluating commonsenseqa :  12%|█▎        | 25/200 [36:04<4:06:43, 84.59s/it]Evaluating commonsenseqa :  66%|██████▌   | 132/200 [4:13:39<2:11:03, 115.64s/it]Evaluating commonsenseqa :  82%|████████▏ | 164/200 [4:13:09<54:15, 90.43s/it]Evaluating commonsenseqa :  92%|█████████▎| 185/200 [4:14:14<20:39, 82.60s/it]Evaluating commonsenseqa :  13%|█▎        | 26/200 [37:26<4:03:01, 83.80s/it]Evaluating commonsenseqa :  56%|█████▋    | 113/200 [4:15:24<3:25:33, 141.77s/it]Evaluating commonsenseqa :  66%|██████▋   | 133/200 [4:15:13<2:01:53, 109.16s/it]Evaluating commonsenseqa :  14%|█▎        | 27/200 [38:00<3:18:13, 68.75s/it]Evaluating commonsenseqa :  82%|████████▎ | 165/200 [4:14:51<54:47, 93.92s/it]Evaluating commonsenseqa :  93%|█████████▎| 186/200 [4:15:37<19:15, 82.53s/it]Evaluating commonsenseqa :  14%|█▍        | 28/200 [39:33<3:38:08, 76.10s/it]Evaluating commonsenseqa :  67%|██████▋   | 134/200 [4:17:10<2:02:41, 111.53s/it]Evaluating commonsenseqa :  83%|████████▎ | 166/200 [4:16:33<54:35, 96.34s/it]Evaluating commonsenseqa :  94%|█████████▎| 187/200 [4:16:59<17:52, 82.53s/it]Evaluating commonsenseqa :  57%|█████▋    | 114/200 [4:17:54<3:26:27, 144.04s/it]Evaluating commonsenseqa :  68%|██████▊   | 135/200 [4:18:21<1:47:43, 99.43s/it] Evaluating commonsenseqa :  14%|█▍        | 29/200 [41:05<3:50:54, 81.02s/it]Evaluating commonsenseqa :  57%|█████▊    | 115/200 [4:18:52<2:47:33, 118.28s/it]Evaluating commonsenseqa :  94%|█████████▍| 188/200 [4:18:22<16:30, 82.53s/it]Evaluating commonsenseqa :  84%|████████▎ | 167/200 [4:18:14<53:47, 97.81s/it]Evaluating commonsenseqa :  94%|█████████▍| 189/200 [4:19:44<15:08, 82.56s/it]Evaluating commonsenseqa :  15%|█▌        | 30/200 [42:41<4:01:30, 85.24s/it]Evaluating commonsenseqa :  68%|██████▊   | 136/200 [4:20:31<1:55:47, 108.55s/it]Evaluating commonsenseqa :  84%|████████▍ | 168/200 [4:19:55<52:43, 98.87s/it]Evaluating commonsenseqa :  58%|█████▊    | 116/200 [4:21:22<2:59:09, 127.97s/it]Evaluating commonsenseqa :  95%|█████████▌| 190/200 [4:21:06<13:44, 82.44s/it]Evaluating commonsenseqa :  16%|█▌        | 31/200 [44:14<4:07:07, 87.74s/it]Evaluating commonsenseqa :  68%|██████▊   | 137/200 [4:22:15<1:52:37, 107.26s/it]Evaluating commonsenseqa :  84%|████████▍ | 169/200 [4:21:31<50:37, 97.99s/it]Evaluating commonsenseqa :  16%|█▌        | 32/200 [45:01<3:31:28, 75.53s/it]Evaluating commonsenseqa :  96%|█████████▌| 191/200 [4:22:30<12:24, 82.76s/it]Evaluating commonsenseqa :  58%|█████▊    | 117/200 [4:23:52<3:05:50, 134.34s/it]Evaluating commonsenseqa :  85%|████████▌ | 170/200 [4:23:10<49:07, 98.24s/it]Evaluating commonsenseqa :  16%|█▋        | 33/200 [46:35<3:45:45, 81.11s/it]Evaluating commonsenseqa :  96%|█████████▌| 192/200 [4:23:53<11:02, 82.87s/it]Evaluating commonsenseqa :  69%|██████▉   | 138/200 [4:24:20<1:56:14, 112.49s/it]Evaluating commonsenseqa :  17%|█▋        | 34/200 [47:00<2:57:41, 64.22s/it]Evaluating commonsenseqa :  96%|█████████▋| 193/200 [4:25:16<09:39, 82.75s/it]Evaluating commonsenseqa :  86%|████████▌ | 171/200 [4:24:50<47:44, 98.77s/it]Evaluating commonsenseqa :  18%|█▊        | 35/200 [48:33<3:20:18, 72.84s/it]Evaluating commonsenseqa :  59%|█████▉    | 118/200 [4:26:25<3:11:17, 139.97s/it]Evaluating commonsenseqa :  70%|██████▉   | 139/200 [4:26:27<1:58:57, 117.01s/it]Evaluating commonsenseqa :  18%|█▊        | 36/200 [49:13<2:51:47, 62.85s/it]Evaluating commonsenseqa :  97%|█████████▋| 194/200 [4:26:38<08:15, 82.54s/it]Evaluating commonsenseqa :  86%|████████▌ | 172/200 [4:26:33<46:39, 100.00s/it]Evaluating commonsenseqa :  18%|█▊        | 37/200 [50:43<3:13:37, 71.27s/it]Evaluating commonsenseqa :  98%|█████████▊| 195/200 [4:28:01<06:53, 82.70s/it]Evaluating commonsenseqa :  70%|███████   | 140/200 [4:28:37<2:00:44, 120.74s/it]Evaluating commonsenseqa :  60%|█████▉    | 119/200 [4:28:54<3:12:55, 142.90s/it]Evaluating commonsenseqa :  86%|████████▋ | 173/200 [4:28:12<44:53, 99.75s/it] Evaluating commonsenseqa :  87%|████████▋ | 174/200 [4:28:55<35:50, 82.73s/it]Evaluating commonsenseqa :  98%|█████████▊| 196/200 [4:29:24<05:31, 82.80s/it]Evaluating commonsenseqa :  19%|█▉        | 38/200 [52:17<3:30:03, 77.80s/it]Evaluating commonsenseqa :  70%|███████   | 141/200 [4:30:44<2:00:47, 122.84s/it]Evaluating commonsenseqa :  60%|██████    | 120/200 [4:31:22<3:12:15, 144.19s/it]Evaluating commonsenseqa :  98%|█████████▊| 197/200 [4:30:48<04:09, 83.13s/it]Evaluating commonsenseqa :  20%|█▉        | 39/200 [53:52<3:42:45, 83.02s/it]Evaluating commonsenseqa :  88%|████████▊ | 175/200 [4:30:39<37:04, 88.97s/it]Evaluating commonsenseqa :  99%|█████████▉| 198/200 [4:32:10<02:45, 82.92s/it]Evaluating commonsenseqa :  71%|███████   | 142/200 [4:32:52<1:59:58, 124.11s/it]Evaluating commonsenseqa :  20%|██        | 40/200 [55:26<3:50:03, 86.27s/it]Evaluating commonsenseqa :  88%|████████▊ | 176/200 [4:32:22<37:16, 93.20s/it]Evaluating commonsenseqa :  60%|██████    | 121/200 [4:33:50<3:11:38, 145.55s/it]Evaluating commonsenseqa : 100%|█████████▉| 199/200 [4:33:34<01:23, 83.08s/it]Evaluating commonsenseqa :  88%|████████▊ | 177/200 [4:33:35<33:23, 87.13s/it]Evaluating commonsenseqa :  20%|██        | 41/200 [56:58<3:53:45, 88.21s/it]Evaluating commonsenseqa :  72%|███████▏  | 143/200 [4:35:02<1:59:40, 125.98s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [4:34:57<00:00, 83.16s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [4:34:57<00:00, 82.49s/it]
name: commonsenseqa | avg. gen lenth: 363.452 | time: 16501.11366724968s
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10139 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o9-tmathqa-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 9 9 11 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2023-09-19 23:34:06,069] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Evaluating commonsenseqa :  89%|████████▉ | 178/200 [4:34:41<29:40, 80.92s/it]using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o9-tmathqa-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 9
  out_domain_data_name ......... mathqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o9-tmathqa-s20-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 474680.68it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.27s/it]
 > number of parameters: 6738415616
[2023-09-19 23:34:22,596] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.3, git-hash=unknown, git-branch=unknown
[2023-09-19 23:34:22,596] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-09-19 23:34:23,009] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-19 23:34:23,012] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2023-09-19 23:34:23,012] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-19 23:34:23,012] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-19 23:34:23,012] [INFO] [config.py:971:print]   amp_enabled .................. False
[2023-09-19 23:34:23,012] [INFO] [config.py:971:print]   amp_params ................... False
[2023-09-19 23:34:23,013] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-19 23:34:23,013] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2023-09-19 23:34:23,013] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2023-09-19 23:34:23,013] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2023-09-19 23:34:23,013] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2023-09-19 23:34:23,013] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f7e4c5d6d10>
[2023-09-19 23:34:23,013] [INFO] [config.py:971:print]   communication_data_type ...... None
[2023-09-19 23:34:23,013] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-19 23:34:23,013] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2023-09-19 23:34:23,013] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2023-09-19 23:34:23,013] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-19 23:34:23,013] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2023-09-19 23:34:23,013] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2023-09-19 23:34:23,013] [INFO] [config.py:971:print]   disable_allgather ............ False
[2023-09-19 23:34:23,013] [INFO] [config.py:971:print]   dump_state ................... False
[2023-09-19 23:34:23,013] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-19 23:34:23,013] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2023-09-19 23:34:23,013] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-19 23:34:23,013] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-19 23:34:23,013] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2023-09-19 23:34:23,013] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2023-09-19 23:34:23,013] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2023-09-19 23:34:23,016] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2023-09-19 23:34:23,016] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2023-09-19 23:34:23,016] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2023-09-19 23:34:23,017] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-19 23:34:23,017] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2023-09-19 23:34:23,017] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2023-09-19 23:34:23,017] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2023-09-19 23:34:23,017] [INFO] [config.py:971:print]   global_rank .................. 0
[2023-09-19 23:34:23,017] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2023-09-19 23:34:23,017] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2023-09-19 23:34:23,017] [INFO] [config.py:971:print]   gradient_clipping ............ 0.0
[2023-09-19 23:34:23,017] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2023-09-19 23:34:23,017] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-19 23:34:23,017] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 2048
[2023-09-19 23:34:23,017] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2023-09-19 23:34:23,017] [INFO] [config.py:971:print]   loss_scale ................... 0
[2023-09-19 23:34:23,017] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2023-09-19 23:34:23,017] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2023-09-19 23:34:23,017] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2023-09-19 23:34:23,017] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-19 23:34:23,017] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-19 23:34:23,017] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2023-09-19 23:34:23,017] [INFO] [config.py:971:print]   optimizer_name ............... None
[2023-09-19 23:34:23,017] [INFO] [config.py:971:print]   optimizer_params ............. None
[2023-09-19 23:34:23,017] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-19 23:34:23,017] [INFO] [config.py:971:print]   pld_enabled .................. False
[2023-09-19 23:34:23,017] [INFO] [config.py:971:print]   pld_params ................... False
[2023-09-19 23:34:23,017] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2023-09-19 23:34:23,017] [INFO] [config.py:971:print]   scheduler_name ............... None
[2023-09-19 23:34:23,017] [INFO] [config.py:971:print]   scheduler_params ............. None
[2023-09-19 23:34:23,018] [INFO] [config.py:971:print]   sparse_attention ............. None
[2023-09-19 23:34:23,018] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2023-09-19 23:34:23,018] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2023-09-19 23:34:23,018] [INFO] [config.py:971:print]   train_batch_size ............. 1
[2023-09-19 23:34:23,018] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  1
[2023-09-19 23:34:23,018] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2023-09-19 23:34:23,018] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2023-09-19 23:34:23,018] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2023-09-19 23:34:23,018] [INFO] [config.py:971:print]   world_size ................... 1
[2023-09-19 23:34:23,018] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  True
[2023-09-19 23:34:23,018] [INFO] [config.py:971:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2023-09-19 23:34:23,018] [INFO] [config.py:971:print]   zero_enabled ................. False
[2023-09-19 23:34:23,018] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-19 23:34:23,018] [INFO] [config.py:971:print]   zero_optimization_stage ...... 0
[2023-09-19 23:34:23,018] [INFO] [config.py:957:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/200 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: a man cycling along the road noticed that every 18 minutes a bus overtakes him and every 6 minutes he meets an oncoming bus. if all buses and the cyclist move at a constant speed, what is the time interval between consecutive buses? a ) 5 minutes, b ) 6 minutes, c ) 8 minutes, d ) 9 minutes, e ) 10 minutes
Output: d

Input: an athlete runs 200 metres race in 24 seconds. what is his speed? a ) 20 km / hr, b ) 30 km / hr, c ) 25 km / hr, d ) 35 km / hr, e ) 40 km / hr
Output: b

Input: two numbers are in the ratio 3 : 4. if the sum of numbers is 63, find the numbers. a ) 27 and 36., b ) 25 and 30., c ) 23 and 44., d ) 63 and 12., e ) 12 and 36.
Output: a

Input: a company wants to spend equal amounts of money for the purchase of two types of computer printers costing $ 375 and $ 150 per unit, respectively. what is the fewest number of computer printers that the company can purchase? a ) 3, b ) 4, c ) 5, d ) 6, e ) 7
Output: e

Input: a certain music store stocks 800 cellos and 600 violas. of these instruments, there are 80 cello - viola pairs, such that a cello and a viola were both made with wood from the same tree ( each tree can make at most one viola and one cello, so there are no pairs other than these 90 ). if one viola and one cello are chosen at random, what is the probability that the two instruments are made with wood from the same tree? a ) 3 / 16,000, b ) 1 / 8,100, c ) 1 / 600, d ) 1 / 90, e ) 2 / 45
Output: c

Input: what is the difference between local value & face value of 7 in the numeral 65793? a ) 693, b ) 656, c ) 691, d ) 9890, e ) 10000
Output: a

Input: in an office in singapore there are 60 % female employees. 50 % of all the male employees are computer literate. if there are total 62 % employees computer literate out of total 1100 employees, then the no. of female employees who are computer literate? a ) 462, b ) 674, c ) 672, d ) 960, e ) none
Output: a

Input: the cost price of 16 articles is the same as the selling price of 12 articles. find the loss / profit percentages. a ) 30 %, b ) 32.50 %, c ) 33 1 / 3 %, d ) 40 %, e ) 50 %
Output: c

Input: mike drives his new corvette from san francisco to las vegas, a journey of 640 miles. he drives the first half of the trip at an average rate of 80 miles per hour, but has to slow down for the second half of his journey. if the second half of the trip takes him 200 percent longer than the first half, what is his average rate q in miles per hour for the entire trip? a ) q = 26.7, b ) q = 30.0, c ) q = 40.0, d ) q = 53.3, e ) q = 60.0
Output: c

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o9-tmathqa-s20-rFalse-m4096
Evaluating commonsenseqa :  21%|██        | 42/200 [58:33<3:57:03, 90.03s/it]Evaluating commonsenseqa :  61%|██████    | 122/200 [4:36:20<3:10:41, 146.69s/it]Evaluating commonsenseqa :  72%|███████▏  | 144/200 [4:37:12<1:58:38, 127.12s/it]Evaluating commonsenseqa :  90%|████████▉ | 179/200 [4:36:24<30:39, 87.61s/it]Evaluating commonsenseqa :  22%|██▏       | 43/200 [1:00:05<3:57:04, 90.60s/it]Evaluating commonsenseqa :   0%|          | 1/200 [02:00<6:39:45, 120.53s/it]Evaluating commonsenseqa :  62%|██████▏   | 123/200 [4:38:42<3:06:27, 145.29s/it]Evaluating commonsenseqa :   1%|          | 2/200 [02:50<4:20:07, 78.82s/it] Evaluating commonsenseqa :  90%|█████████ | 180/200 [4:38:05<30:33, 91.66s/it]Evaluating commonsenseqa :  22%|██▏       | 44/200 [1:01:37<3:57:20, 91.29s/it]Evaluating commonsenseqa :  72%|███████▎  | 145/200 [4:39:20<1:56:56, 127.57s/it]Evaluating commonsenseqa :  62%|██████▏   | 124/200 [4:39:52<2:35:28, 122.74s/it]Evaluating commonsenseqa :   2%|▏         | 3/200 [04:44<5:12:26, 95.16s/it]Evaluating commonsenseqa :  90%|█████████ | 181/200 [4:39:49<30:06, 95.08s/it]Evaluating commonsenseqa :  22%|██▎       | 45/200 [1:03:10<3:56:46, 91.65s/it]Evaluating commonsenseqa :  73%|███████▎  | 146/200 [4:41:29<1:55:04, 127.86s/it]Evaluating commonsenseqa :  62%|██████▎   | 125/200 [4:42:24<2:44:19, 131.46s/it]Evaluating commonsenseqa :  23%|██▎       | 46/200 [1:04:41<3:55:03, 91.58s/it]Evaluating commonsenseqa :  91%|█████████ | 182/200 [4:41:31<29:11, 97.32s/it]Evaluating commonsenseqa :   2%|▏         | 4/200 [06:39<5:35:47, 102.79s/it]Evaluating commonsenseqa :  74%|███████▎  | 147/200 [4:43:36<1:52:43, 127.61s/it]Evaluating commonsenseqa :  24%|██▎       | 47/200 [1:06:13<3:53:33, 91.59s/it]Evaluating commonsenseqa :  92%|█████████▏| 183/200 [4:43:14<28:04, 99.07s/it]Evaluating commonsenseqa :   2%|▎         | 5/200 [08:39<5:54:24, 109.05s/it]Evaluating commonsenseqa :  63%|██████▎   | 126/200 [4:44:50<2:47:33, 135.85s/it]Evaluating commonsenseqa :  24%|██▍       | 48/200 [1:07:45<3:52:06, 91.62s/it]Evaluating commonsenseqa :  64%|██████▎   | 127/200 [4:45:49<2:17:24, 112.94s/it]Evaluating commonsenseqa :  74%|███████▍  | 148/200 [4:45:42<1:50:05, 127.04s/it]Evaluating commonsenseqa :  92%|█████████▏| 184/200 [4:44:57<26:41, 100.09s/it]Evaluating commonsenseqa :   3%|▎         | 6/200 [10:35<6:00:51, 111.61s/it]Evaluating commonsenseqa :  24%|██▍       | 49/200 [1:09:15<3:49:46, 91.30s/it]Evaluating commonsenseqa :  64%|██████▍   | 128/200 [4:47:12<2:04:30, 103.76s/it]Evaluating commonsenseqa :  92%|█████████▎| 185/200 [4:46:14<23:18, 93.24s/it] Evaluating commonsenseqa :  74%|███████▍  | 149/200 [4:47:50<1:48:23, 127.53s/it]Evaluating commonsenseqa :  25%|██▌       | 50/200 [1:10:48<3:49:03, 91.62s/it]Evaluating commonsenseqa :   4%|▎         | 7/200 [12:35<6:07:06, 114.13s/it]Evaluating commonsenseqa :  93%|█████████▎| 186/200 [4:47:59<22:33, 96.66s/it]Evaluating commonsenseqa :  64%|██████▍   | 129/200 [4:49:43<2:19:37, 117.99s/it]Evaluating commonsenseqa :  26%|██▌       | 51/200 [1:12:20<3:48:26, 91.99s/it]Evaluating commonsenseqa :  75%|███████▌  | 150/200 [4:49:56<1:45:47, 126.95s/it]Evaluating commonsenseqa :   4%|▍         | 8/200 [14:33<6:09:07, 115.35s/it]Evaluating commonsenseqa :  94%|█████████▎| 187/200 [4:49:42<21:22, 98.65s/it]Evaluating commonsenseqa :  26%|██▌       | 52/200 [1:13:54<3:47:50, 92.37s/it]Evaluating commonsenseqa :  65%|██████▌   | 130/200 [4:52:11<2:28:14, 127.07s/it]Evaluating commonsenseqa :  76%|███████▌  | 151/200 [4:52:01<1:43:07, 126.28s/it]Evaluating commonsenseqa :  94%|█████████▍| 188/200 [4:51:25<20:01, 100.13s/it]Evaluating commonsenseqa :   4%|▍         | 9/200 [16:29<6:07:44, 115.52s/it]Evaluating commonsenseqa :  26%|██▋       | 53/200 [1:15:27<3:46:56, 92.63s/it]Evaluating commonsenseqa :  94%|█████████▍| 189/200 [4:52:40<16:55, 92.34s/it] Evaluating commonsenseqa :   5%|▌         | 10/200 [17:54<5:36:30, 106.27s/it]Evaluating commonsenseqa :  76%|███████▌  | 152/200 [4:53:46<1:35:54, 119.89s/it]Evaluating commonsenseqa :  66%|██████▌   | 131/200 [4:54:38<2:33:05, 133.12s/it]Evaluating commonsenseqa :  27%|██▋       | 54/200 [1:16:59<3:45:15, 92.57s/it]Evaluating commonsenseqa :  76%|███████▋  | 153/200 [4:54:41<1:18:49, 100.63s/it]Evaluating commonsenseqa :  95%|█████████▌| 190/200 [4:54:23<15:56, 95.68s/it]Evaluating commonsenseqa :  28%|██▊       | 55/200 [1:17:48<3:11:57, 79.43s/it]Evaluating commonsenseqa :   6%|▌         | 11/200 [19:52<5:45:44, 109.76s/it]Evaluating commonsenseqa :  77%|███████▋  | 154/200 [4:56:49<1:23:23, 108.77s/it]Evaluating commonsenseqa :  28%|██▊       | 56/200 [1:19:20<3:19:14, 83.02s/it]Evaluating commonsenseqa :  66%|██████▌   | 132/200 [4:57:06<2:35:47, 137.46s/it]Evaluating commonsenseqa :  96%|█████████▌| 191/200 [4:56:04<14:35, 97.30s/it]Evaluating commonsenseqa :   6%|▌         | 12/200 [21:50<5:51:31, 112.19s/it]Evaluating commonsenseqa :  28%|██▊       | 57/200 [1:20:51<3:23:51, 85.53s/it]Evaluating commonsenseqa :  96%|█████████▌| 192/200 [4:57:46<13:08, 98.61s/it]Evaluating commonsenseqa :  78%|███████▊  | 155/200 [4:58:58<1:26:04, 114.77s/it]Evaluating commonsenseqa :  66%|██████▋   | 133/200 [4:59:36<2:37:47, 141.31s/it]Evaluating commonsenseqa :   6%|▋         | 13/200 [23:46<5:53:26, 113.41s/it]Evaluating commonsenseqa :  29%|██▉       | 58/200 [1:22:25<3:28:26, 88.08s/it]Evaluating commonsenseqa :  96%|█████████▋| 193/200 [4:59:28<11:37, 99.69s/it]Evaluating commonsenseqa :  78%|███████▊  | 156/200 [5:00:24<1:17:58, 106.34s/it]Evaluating commonsenseqa :  30%|██▉       | 59/200 [1:23:57<3:29:40, 89.22s/it]Evaluating commonsenseqa :   7%|▋         | 14/200 [25:41<5:53:07, 113.91s/it]Evaluating commonsenseqa :  97%|█████████▋| 194/200 [5:00:42<09:11, 91.85s/it]Evaluating commonsenseqa :  67%|██████▋   | 134/200 [5:02:06<2:38:09, 143.78s/it]Evaluating commonsenseqa :  30%|███       | 60/200 [1:24:44<2:58:25, 76.47s/it]Evaluating commonsenseqa :  78%|███████▊  | 157/200 [5:02:34<1:21:15, 113.38s/it]Evaluating commonsenseqa :  98%|█████████▊| 195/200 [5:02:27<07:58, 95.80s/it]Evaluating commonsenseqa :   8%|▊         | 15/200 [27:39<5:55:25, 115.27s/it]Evaluating commonsenseqa :  30%|███       | 61/200 [1:26:14<3:07:12, 80.81s/it]Evaluating commonsenseqa :  68%|██████▊   | 135/200 [5:04:32<2:36:36, 144.55s/it]Evaluating commonsenseqa :  79%|███████▉  | 158/200 [5:04:45<1:23:02, 118.62s/it]Evaluating commonsenseqa :  98%|█████████▊| 196/200 [5:04:11<06:33, 98.27s/it]Evaluating commonsenseqa :  31%|███       | 62/200 [1:27:45<3:12:50, 83.85s/it]Evaluating commonsenseqa :   8%|▊         | 16/200 [29:36<5:55:03, 115.78s/it]Evaluating commonsenseqa :  80%|███████▉  | 159/200 [5:06:03<1:12:40, 106.36s/it]Evaluating commonsenseqa :  32%|███▏      | 63/200 [1:28:35<2:47:40, 73.44s/it]Evaluating commonsenseqa :  68%|██████▊   | 136/200 [5:06:46<2:30:39, 141.24s/it]Evaluating commonsenseqa :  98%|█████████▊| 197/200 [5:05:56<05:01, 100.52s/it]Evaluating commonsenseqa :   8%|▊         | 17/200 [31:34<5:55:02, 116.41s/it]Evaluating commonsenseqa :  80%|████████  | 160/200 [5:07:25<1:06:04, 99.12s/it] Evaluating commonsenseqa :  32%|███▏      | 64/200 [1:30:09<3:00:34, 79.66s/it]Evaluating commonsenseqa :  99%|█████████▉| 198/200 [5:07:40<03:22, 101.36s/it]Evaluating commonsenseqa :  68%|██████▊   | 137/200 [5:09:12<2:29:57, 142.82s/it]Evaluating commonsenseqa :  32%|███▎      | 65/200 [1:31:42<3:08:24, 83.74s/it]Evaluating commonsenseqa : 100%|█████████▉| 199/200 [5:08:29<01:25, 85.73s/it] Evaluating commonsenseqa :   9%|▉         | 18/200 [33:33<5:54:59, 117.03s/it]Evaluating commonsenseqa :  80%|████████  | 161/200 [5:09:32<1:09:56, 107.60s/it]Evaluating commonsenseqa :  69%|██████▉   | 138/200 [5:10:33<2:08:22, 124.23s/it]Evaluating commonsenseqa :  33%|███▎      | 66/200 [1:33:15<3:13:29, 86.64s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [5:10:10<00:00, 90.36s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [5:10:10<00:00, 93.05s/it]
name: commonsenseqa | avg. gen lenth: 253.723 | time: 18613.366878032684s
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10140 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o13-tmathqa-s30-rTrue --seed 30 --max-prompt-length 4096 --rationales --num-out-domain 13 13 15 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2023-09-20 00:09:48,150] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Evaluating commonsenseqa :  10%|▉         | 19/200 [35:28<5:51:08, 116.40s/it]using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o13-tmathqa-s30-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 13
  out_domain_data_name ......... mathqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o13-tmathqa-s30-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 238862.51it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.17s/it]
 > number of parameters: 6738415616
[2023-09-20 00:10:04,459] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.3, git-hash=unknown, git-branch=unknown
[2023-09-20 00:10:04,459] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-09-20 00:10:04,901] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-20 00:10:04,904] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2023-09-20 00:10:04,904] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-20 00:10:04,904] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-20 00:10:04,904] [INFO] [config.py:971:print]   amp_enabled .................. False
[2023-09-20 00:10:04,904] [INFO] [config.py:971:print]   amp_params ................... False
[2023-09-20 00:10:04,904] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-20 00:10:04,904] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f79c3e2eda0>
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   communication_data_type ...... None
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   disable_allgather ............ False
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   dump_state ................... False
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   global_rank .................. 0
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   gradient_clipping ............ 0.0
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2023-09-20 00:10:04,905] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 2048
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   loss_scale ................... 0
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   optimizer_name ............... None
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   optimizer_params ............. None
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   pld_enabled .................. False
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   pld_params ................... False
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   scheduler_name ............... None
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   scheduler_params ............. None
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   sparse_attention ............. None
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   train_batch_size ............. 1
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  1
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   world_size ................... 1
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  True
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   zero_enabled ................. False
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-20 00:10:04,906] [INFO] [config.py:971:print]   zero_optimization_stage ...... 0
[2023-09-20 00:10:04,906] [INFO] [config.py:957:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/200 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: the mean of 30 values was 140. it was detected on rechecking that one value 145 was wrongly copied as 135 for the computation of the mean. find the correct mean. a ) 151, b ) 140.33, c ) 152, d ) 148, e ) none of the above
Output: "corrected mean = 140 × 30 − 135 + 145 / 30 = 4200 − 135 + 145 / 30 = 4210 / 30 = 140.33 answer b"
So the final answer is b

Input: the measurement of a rectangular box with lid is 25 cmx 24 cmx 18 cm. find the volume of the largest sphere that can be inscribed in the box ( in terms of π cm 3 ). ( hint : the lowest measure of rectangular box represents the diameter of the largest sphere ) a ) 288, b ) 2302, c ) 2304, d ) 8640, e ) 964
Output: "d = 24, r = 12 ; volume of the largest sphere = 4 / 3 π r 3 = 4 / 3 * π * 12 * 12 * 12 = 2304 π cm 3 answer : c"
So the final answer is c

Input: a certain fraction has the same ratio to 1 / 33, as 3 / 4 does to 7 / 11. what is this certain fraction? a ) 1 / 14, b ) 1 / 18, c ) 1 / 21, d ) 1 / 25, e ) 1 / 28
Output: "x / ( 1 / 33 ) = ( 3 / 4 ) / ( 7 / 11 ) x = 3 * 11 * 1 / 33 * 4 * 7 = 1 / 28 the answer is e."
So the final answer is e

Input: what is the sum of all remainders obtained when the first 110 natural numbers are divided by 9? a ) 397, b ) 401, c ) 403, d ) 405, e ) 399
Output: "a positive integer can give only the following 9 remainders when divided by 9 : 1, 2, 3, 4, 5, 6, 7, 8, and 0. 1 divided by 9 gives the remainder of 1 ; 2 divided by 9 gives the remainder of 2 ;... 8 divided by 9 gives the remainder of 8 ; 9 divided by 9 gives the remainder of 0. we'll have 11 such blocks, since 99 / 9 = 11. the last will be : 91 divided by 9 gives the remainder of 1 ; 92 divided by 9 gives the remainder of 2 ;... 98 divided by 9 gives the remainder of 8 ; 99 divided by 9 gives the remainder of 0. the last number, 100, gives the remainder of 1 when divided by 9, thus the sum of all remainders will be : 11 ( 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 0 ) + 1 = 403. answer : c."
So the final answer is c

Input: a ’ s speed is 20 / 15 times that of b. if a and b run a race, what part of the length of the race should a give b as a head start, so that the race ends in a dead heat? a ) 1 / 17, b ) 3 / 17, c ) 1 / 10, d ) 5 / 20, e ) 3 / 10
Output: "we have the ratio of a ’ s speed and b ’ s speed. this means, we know how much distance a covers compared with b in the same time. this is what the beginning of the race will look like : ( start ) a _________ b ______________________________ if a covers 20 meters, b covers 15 meters in that time. so if the race is 20 meters long, when a reaches the finish line, b would be 5 meters behind him. if we want the race to end in a dead heat, we want b to be at the finish line too at the same time. this means b should get a head start of 5 meters so that he doesn ’ t need to cover that. in that case, the time required by a ( to cover 20 meters ) would be the same as the time required by b ( to cover 15 meters ) to reach the finish line. so b should get a head start of 5 / 20 th of the race. answer ( d )"
So the final answer is d

Input: find the average of all the numbers between 6 and 34 which are divisible by 7. a ) 18, b ) 20, c ) 17.5, d ) 30, e ) 32
Output: "solution average = ( 7 + 14 + 21 + 28 ) / 4 ) = 70 / 4 = 17.5. answer c"
So the final answer is c

Input: instead of multiplying a number by 5, the number is divided by 10. what is the percentage of error obtained? a ) 96 %, b ) 98 %, c ) 95 %, d ) 97 %, e ) 96 %
Output: "let the number be x the right number is 5 x the wrong number is x / 10 error is ( 5 x - x / 10 ) = 49 x / 10 percentage of error is ( ( 49 x / 10 ) / 5 x ) * 100 = 98 % answer : b"
So the final answer is b

Input: by selling an article at rs. 150, a profit of 25 % is made. find its cost price? a ) s. 486, b ) s. 455, c ) s. 487, d ) s. 120, e ) s. 489
Output: "sp = 150 cp = ( sp ) * [ 100 / ( 100 + p ) ] = 150 * [ 100 / ( 100 + 25 ) ] = 150 * [ 100 / 125 ] = rs. 120 answer : d"
So the final answer is d

Input: if 1 = 6, 2 = 12, 3 = 18, 4 = 24, 5 = 30, then 6 =? a ) 5, b ) 3, c ) 1, d ) 7, e ) 9
Output: solution : 1 as stated 1 = 6 = > 6 = 1 answer c
So the final answer is c

Input: 62 small identical cubes are used to form a large cube. how many more cubes are needed to add one top layer of small cube all over the surface of the large cube? a ) 64, b ) 128, c ) 152, d ) 154, e ) 256
Output: "62 small cube will make a large cube with 4 cubes in each line i. e. adding one layer will require one cube at each end and hence new cube will have 6 cubes in each line. total number of small cubes in new cube = 6 ^ 3 = 216 extra cube required = 216 - 62 = 154 hence, d is the answer."
So the final answer is d

Input: a boat running upstream takes 640 min to cover a certain distance, while it takes 280 min to cover the same distance running down stream. what is the ratio between the speed of the boat and speed of water current respectively? a ) 23 : 7, b ) 22 : 9, c ) 23 : 8, d ) 23 : 9, e ) 23 : 11
Output: let the speed of the boat = x and speed of the current = y relative speed in upstream = x - y and in downstream = x + y let the distance'd'is to be covered in downstream and upstream, then time taken in upstream = d / ( x - y ) = 640 or d = 640 ( x - y ) - - - - ( i ) and time taken in downstream = d / ( x + y ) = 280 or d = 280 ( x + y ) - - - - ( ii ) comparing ( i ) & ( ii ), 640 ( x - y ) = 280 ( x + y ) = > 16 ( x - y ) = 7 ( x + y ) = > 16 x - 16 y = 7 x - 7 y = > 9 x = 23 y = > x / y = 23 / 9 answer : d
So the final answer is d

Input: there are 2 positive integers x and y. what is the probability that x + y is odd? a ) 1 / 4, b ) 1 / 2, c ) 1 / 3, d ) 1 / 5, e ) 1 / 9
Output: explanation : the addition of two integer results in an odd number only if any one of the integers is an odd number. the probability of an odd among the two integer is 1 / 2. hence, the required probability is 1 / 2. answer : b
So the final answer is b

Input: two numbers have a h. c. f of 9 and a product of two numbers is 1800. find the l. c. m of the two numbers? a ) 200, b ) 150, c ) 160, d ) 170, e ) 180
Output: "l. c. m of two numbers is given by ( product of the two numbers ) / ( h. c. f of the two numbers ) = 1800 / 9 = 200. answer : a"
So the final answer is a

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o13-tmathqa-s30-rTrue-m4096
Evaluating commonsenseqa :  81%|████████  | 162/200 [5:11:41<1:12:11, 113.98s/it]Evaluating commonsenseqa :  34%|███▎      | 67/200 [1:34:49<3:16:23, 88.60s/it]Evaluating commonsenseqa :   0%|          | 1/200 [01:19<4:25:03, 79.92s/it]Evaluating commonsenseqa :  70%|██████▉   | 139/200 [5:13:05<2:14:41, 132.48s/it]Evaluating commonsenseqa :  10%|█         | 20/200 [37:24<5:49:34, 116.53s/it]Evaluating commonsenseqa :  82%|████████▏ | 163/200 [5:13:46<1:12:19, 117.28s/it]Evaluating commonsenseqa :  34%|███▍      | 68/200 [1:36:21<3:17:36, 89.82s/it]Evaluating commonsenseqa :   1%|          | 2/200 [02:39<4:22:50, 79.65s/it]Evaluating commonsenseqa :  34%|███▍      | 69/200 [1:37:10<2:49:20, 77.56s/it]Evaluating commonsenseqa :  70%|███████   | 140/200 [5:15:12<2:11:04, 131.07s/it]Evaluating commonsenseqa :  10%|█         | 21/200 [39:22<5:48:58, 116.98s/it]Evaluating commonsenseqa :   2%|▏         | 3/200 [03:58<4:20:53, 79.46s/it]Evaluating commonsenseqa :  82%|████████▏ | 164/200 [5:15:56<1:12:32, 120.90s/it]Evaluating commonsenseqa :  11%|█         | 22/200 [40:16<4:50:18, 97.86s/it] Evaluating commonsenseqa :  35%|███▌      | 70/200 [1:38:42<2:57:09, 81.76s/it]Evaluating commonsenseqa :   2%|▏         | 4/200 [05:17<4:18:23, 79.10s/it]Evaluating commonsenseqa :  70%|███████   | 141/200 [5:17:39<2:13:31, 135.79s/it]Evaluating commonsenseqa :  12%|█▏        | 23/200 [41:46<4:41:41, 95.49s/it]Evaluating commonsenseqa :  36%|███▌      | 71/200 [1:40:14<3:02:28, 84.87s/it]Evaluating commonsenseqa :  82%|████████▎ | 165/200 [5:18:05<1:12:01, 123.46s/it]Evaluating commonsenseqa :   2%|▎         | 5/200 [06:36<4:17:16, 79.16s/it]Evaluating commonsenseqa :  36%|███▌      | 72/200 [1:41:45<3:04:50, 86.65s/it]Evaluating commonsenseqa :   3%|▎         | 6/200 [07:55<4:15:21, 78.98s/it]Evaluating commonsenseqa :  12%|█▏        | 24/200 [43:42<4:58:43, 101.84s/it]Evaluating commonsenseqa :  71%|███████   | 142/200 [5:20:09<2:15:12, 139.88s/it]Evaluating commonsenseqa :  83%|████████▎ | 166/200 [5:20:12<1:10:29, 124.40s/it]Evaluating commonsenseqa :   4%|▎         | 7/200 [09:14<4:15:03, 79.29s/it]Evaluating commonsenseqa :  36%|███▋      | 73/200 [1:43:17<3:06:54, 88.30s/it]Evaluating commonsenseqa :  12%|█▎        | 25/200 [45:38<5:09:14, 106.03s/it]Evaluating commonsenseqa :   4%|▍         | 8/200 [10:34<4:14:20, 79.48s/it]Evaluating commonsenseqa :  37%|███▋      | 74/200 [1:44:49<3:08:04, 89.56s/it]Evaluating commonsenseqa :  84%|████████▎ | 167/200 [5:22:22<1:09:22, 126.14s/it]Evaluating commonsenseqa :  72%|███████▏  | 143/200 [5:22:36<2:15:05, 142.20s/it]Evaluating commonsenseqa :  13%|█▎        | 26/200 [46:56<4:43:06, 97.62s/it] Evaluating commonsenseqa :   4%|▍         | 9/200 [11:53<4:11:58, 79.15s/it]Evaluating commonsenseqa :  38%|███▊      | 75/200 [1:46:23<3:09:09, 90.80s/it]Evaluating commonsenseqa :  72%|███████▏  | 144/200 [5:24:44<2:08:46, 137.97s/it]Evaluating commonsenseqa :  84%|████████▍ | 168/200 [5:24:32<1:07:55, 127.37s/it]Evaluating commonsenseqa :  14%|█▎        | 27/200 [48:52<4:56:53, 102.97s/it]Evaluating commonsenseqa :   5%|▌         | 10/200 [13:13<4:11:54, 79.55s/it]Evaluating commonsenseqa :  72%|███████▎  | 145/200 [5:25:31<1:41:22, 110.59s/it]Evaluating commonsenseqa :  38%|███▊      | 76/200 [1:47:55<3:08:16, 91.10s/it]Evaluating commonsenseqa :   6%|▌         | 11/200 [14:34<4:12:12, 80.07s/it]Evaluating commonsenseqa :  14%|█▍        | 28/200 [50:51<5:08:59, 107.79s/it]Evaluating commonsenseqa :  84%|████████▍ | 169/200 [5:26:41<1:05:58, 127.70s/it]Evaluating commonsenseqa :  38%|███▊      | 77/200 [1:49:28<3:07:44, 91.58s/it]Evaluating commonsenseqa :   6%|▌         | 12/200 [15:55<4:10:54, 80.08s/it]Evaluating commonsenseqa :  73%|███████▎  | 146/200 [5:28:01<1:50:11, 122.43s/it]Evaluating commonsenseqa :  14%|█▍        | 29/200 [52:25<4:55:49, 103.80s/it]Evaluating commonsenseqa :  39%|███▉      | 78/200 [1:51:00<3:07:00, 91.98s/it]Evaluating commonsenseqa :   6%|▋         | 13/200 [17:06<4:01:01, 77.33s/it]Evaluating commonsenseqa :  85%|████████▌ | 170/200 [5:28:49<1:04:00, 128.01s/it]Evaluating commonsenseqa :  74%|███████▎  | 147/200 [5:29:51<1:44:50, 118.68s/it]Evaluating commonsenseqa :   7%|▋         | 14/200 [18:25<4:01:47, 78.00s/it]Evaluating commonsenseqa :  40%|███▉      | 79/200 [1:52:35<3:06:55, 92.69s/it]Evaluating commonsenseqa :  15%|█▌        | 30/200 [54:21<5:04:15, 107.39s/it]Evaluating commonsenseqa :  86%|████████▌ | 171/200 [5:30:59<1:02:08, 128.56s/it]Evaluating commonsenseqa :   8%|▊         | 15/200 [19:45<4:01:59, 78.49s/it]Evaluating commonsenseqa :  40%|████      | 80/200 [1:53:52<2:56:06, 88.06s/it]Evaluating commonsenseqa :  16%|█▌        | 31/200 [56:18<5:10:35, 110.27s/it]Evaluating commonsenseqa :  74%|███████▍  | 148/200 [5:32:19<1:50:36, 127.62s/it]Evaluating commonsenseqa :   8%|▊         | 16/200 [21:04<4:01:41, 78.81s/it]Evaluating commonsenseqa :  40%|████      | 81/200 [1:55:24<2:56:52, 89.18s/it]Evaluating commonsenseqa :  86%|████████▌ | 172/200 [5:33:10<1:00:15, 129.12s/it]Evaluating commonsenseqa :  41%|████      | 82/200 [1:56:11<2:30:39, 76.60s/it]Evaluating commonsenseqa :   8%|▊         | 17/200 [22:23<4:00:09, 78.74s/it]Evaluating commonsenseqa :  16%|█▌        | 32/200 [58:17<5:15:48, 112.79s/it]Evaluating commonsenseqa :  74%|███████▍  | 149/200 [5:34:38<1:51:13, 130.86s/it]Evaluating commonsenseqa :  86%|████████▋ | 173/200 [5:34:43<53:14, 118.32s/it]  Evaluating commonsenseqa :  42%|████▏     | 83/200 [1:57:16<2:22:20, 73.00s/it]Evaluating commonsenseqa :   9%|▉         | 18/200 [23:41<3:58:38, 78.67s/it]Evaluating commonsenseqa :  42%|████▏     | 84/200 [1:58:09<2:09:53, 67.19s/it]Evaluating commonsenseqa :  16%|█▋        | 33/200 [1:00:12<5:16:08, 113.58s/it]Evaluating commonsenseqa :  10%|▉         | 19/200 [25:00<3:57:06, 78.60s/it]Evaluating commonsenseqa :  75%|███████▌  | 150/200 [5:37:08<1:53:52, 136.65s/it]Evaluating commonsenseqa :  87%|████████▋ | 174/200 [5:36:54<53:00, 122.32s/it]Evaluating commonsenseqa :  42%|████▎     | 85/200 [1:59:42<2:23:36, 74.93s/it]Evaluating commonsenseqa :  17%|█▋        | 34/200 [1:01:59<5:08:28, 111.49s/it]Evaluating commonsenseqa :  10%|█         | 20/200 [26:20<3:57:04, 79.02s/it]Evaluating commonsenseqa :  43%|████▎     | 86/200 [2:01:07<2:27:50, 77.81s/it]Evaluating commonsenseqa :  88%|████████▊ | 175/200 [5:39:03<51:47, 124.29s/it]Evaluating commonsenseqa :  10%|█         | 21/200 [27:39<3:55:52, 79.06s/it]Evaluating commonsenseqa :  76%|███████▌  | 151/200 [5:39:35<1:54:14, 139.88s/it]Evaluating commonsenseqa :  18%|█▊        | 35/200 [1:03:58<5:12:49, 113.75s/it]Evaluating commonsenseqa :  44%|████▎     | 87/200 [2:02:41<2:35:56, 82.80s/it]Evaluating commonsenseqa :  11%|█         | 22/200 [28:59<3:55:02, 79.23s/it]Evaluating commonsenseqa :  88%|████████▊ | 176/200 [5:41:14<50:26, 126.11s/it]Evaluating commonsenseqa :  18%|█▊        | 36/200 [1:05:52<5:11:32, 113.98s/it]Evaluating commonsenseqa :  44%|████▍     | 88/200 [2:04:14<2:39:58, 85.70s/it]Evaluating commonsenseqa :  12%|█▏        | 23/200 [30:18<3:53:42, 79.22s/it]Evaluating commonsenseqa :  76%|███████▌  | 152/200 [5:42:03<1:53:50, 142.30s/it]Evaluating commonsenseqa :  12%|█▏        | 24/200 [31:38<3:53:23, 79.56s/it]Evaluating commonsenseqa :  44%|████▍     | 89/200 [2:05:47<2:43:00, 88.11s/it]Evaluating commonsenseqa :  88%|████████▊ | 177/200 [5:43:22<48:36, 126.80s/it]Evaluating commonsenseqa :  18%|█▊        | 37/200 [1:07:47<5:10:36, 114.34s/it]Evaluating commonsenseqa :  76%|███████▋  | 153/200 [5:44:30<1:52:32, 143.68s/it]Evaluating commonsenseqa :  12%|█▎        | 25/200 [32:59<3:53:03, 79.91s/it]Evaluating commonsenseqa :  45%|████▌     | 90/200 [2:07:22<2:44:59, 90.00s/it]Evaluating commonsenseqa :  19%|█▉        | 38/200 [1:09:44<5:10:44, 115.09s/it]Evaluating commonsenseqa :  89%|████████▉ | 178/200 [5:45:32<46:49, 127.72s/it]Evaluating commonsenseqa :  13%|█▎        | 26/200 [34:19<3:52:02, 80.01s/it]Evaluating commonsenseqa :  77%|███████▋  | 154/200 [5:46:09<1:39:42, 130.05s/it]Evaluating commonsenseqa :  46%|████▌     | 91/200 [2:08:56<2:45:46, 91.25s/it]Evaluating commonsenseqa :  14%|█▎        | 27/200 [35:39<3:50:11, 79.83s/it]Evaluating commonsenseqa :  20%|█▉        | 39/200 [1:11:40<5:09:35, 115.37s/it]Evaluating commonsenseqa :  90%|████████▉ | 179/200 [5:47:37<44:28, 127.06s/it]Evaluating commonsenseqa :  46%|████▌     | 92/200 [2:10:07<2:33:06, 85.06s/it]Evaluating commonsenseqa :  78%|███████▊  | 155/200 [5:48:37<1:41:37, 135.49s/it]Evaluating commonsenseqa :  14%|█▍        | 28/200 [36:58<3:48:05, 79.57s/it]Evaluating commonsenseqa :  46%|████▋     | 93/200 [2:11:32<2:31:49, 85.13s/it]Evaluating commonsenseqa :  20%|██        | 40/200 [1:13:39<5:10:22, 116.39s/it]Evaluating commonsenseqa :  90%|█████████ | 180/200 [5:49:45<42:24, 127.25s/it]Evaluating commonsenseqa :  14%|█▍        | 29/200 [38:16<3:45:58, 79.29s/it]Evaluating commonsenseqa :  90%|█████████ | 181/200 [5:50:21<31:39, 99.96s/it] Evaluating commonsenseqa :  47%|████▋     | 94/200 [2:13:05<2:34:51, 87.66s/it]Evaluating commonsenseqa :  78%|███████▊  | 156/200 [5:51:03<1:41:45, 138.76s/it]Evaluating commonsenseqa :  20%|██        | 41/200 [1:15:08<4:46:27, 108.10s/it]Evaluating commonsenseqa :  15%|█▌        | 30/200 [39:36<3:45:32, 79.61s/it]Evaluating commonsenseqa :  91%|█████████ | 182/200 [5:51:31<27:17, 90.97s/it]Evaluating commonsenseqa :  48%|████▊     | 95/200 [2:14:38<2:35:50, 89.05s/it]Evaluating commonsenseqa :  16%|█▌        | 31/200 [40:57<3:44:34, 79.73s/it]Evaluating commonsenseqa :  21%|██        | 42/200 [1:17:04<4:51:02, 110.52s/it]Evaluating commonsenseqa :  78%|███████▊  | 157/200 [5:53:33<1:41:43, 141.95s/it]Evaluating commonsenseqa :  92%|█████████▏| 183/200 [5:53:38<28:50, 101.80s/it]Evaluating commonsenseqa :  48%|████▊     | 96/200 [2:16:13<2:37:24, 90.82s/it]Evaluating commonsenseqa :  16%|█▌        | 32/200 [42:16<3:43:09, 79.70s/it]Evaluating commonsenseqa :  22%|██▏       | 43/200 [1:18:43<4:40:21, 107.15s/it]Evaluating commonsenseqa :  92%|█████████▏| 184/200 [5:54:38<23:47, 89.22s/it] Evaluating commonsenseqa :  16%|█▋        | 33/200 [43:36<3:41:48, 79.69s/it]Evaluating commonsenseqa :  48%|████▊     | 97/200 [2:17:44<2:35:54, 90.82s/it]Evaluating commonsenseqa :  79%|███████▉  | 158/200 [5:56:00<1:40:29, 143.57s/it]Evaluating commonsenseqa :  17%|█▋        | 34/200 [44:55<3:40:27, 79.68s/it]Evaluating commonsenseqa :  22%|██▏       | 44/200 [1:20:43<4:48:12, 110.85s/it]Evaluating commonsenseqa :  49%|████▉     | 98/200 [2:19:10<2:31:59, 89.41s/it]Evaluating commonsenseqa :  92%|█████████▎| 185/200 [5:56:47<25:15, 101.04s/it]Evaluating commonsenseqa :  22%|██▎       | 45/200 [1:21:34<4:00:26, 93.07s/it] Evaluating commonsenseqa :  18%|█▊        | 35/200 [46:16<3:39:37, 79.86s/it]Evaluating commonsenseqa :  50%|████▉     | 99/200 [2:20:22<2:22:07, 84.43s/it]Evaluating commonsenseqa :  80%|███████▉  | 159/200 [5:58:27<1:38:53, 144.71s/it]Evaluating commonsenseqa :  93%|█████████▎| 186/200 [5:58:59<25:43, 110.25s/it]Evaluating commonsenseqa :  18%|█▊        | 36/200 [47:35<3:37:53, 79.72s/it]Evaluating commonsenseqa :  23%|██▎       | 46/200 [1:23:19<4:07:58, 96.61s/it]Evaluating commonsenseqa :  50%|█████     | 100/200 [2:21:56<2:25:12, 87.13s/it]Evaluating commonsenseqa :  18%|█▊        | 37/200 [48:54<3:36:16, 79.61s/it]Evaluating commonsenseqa :  80%|████████  | 160/200 [6:00:58<1:37:44, 146.62s/it]Evaluating commonsenseqa :  50%|█████     | 101/200 [2:23:28<2:26:15, 88.64s/it]Evaluating commonsenseqa :  24%|██▎       | 47/200 [1:25:16<4:21:59, 102.74s/it]Evaluating commonsenseqa :  94%|█████████▎| 187/200 [6:01:04<24:52, 114.78s/it]Evaluating commonsenseqa :  19%|█▉        | 38/200 [50:14<3:34:47, 79.55s/it]Evaluating commonsenseqa :  24%|██▍       | 48/200 [1:26:32<3:59:44, 94.63s/it] Evaluating commonsenseqa :  51%|█████     | 102/200 [2:25:02<2:27:21, 90.22s/it]Evaluating commonsenseqa :  20%|█▉        | 39/200 [51:32<3:32:39, 79.25s/it]Evaluating commonsenseqa :  94%|█████████▍| 188/200 [6:03:09<23:35, 117.93s/it]Evaluating commonsenseqa :  80%|████████  | 161/200 [6:03:26<1:35:33, 147.01s/it]Evaluating commonsenseqa :  24%|██▍       | 49/200 [1:27:57<3:51:08, 91.85s/it]Evaluating commonsenseqa :  52%|█████▏    | 103/200 [2:26:34<2:26:51, 90.85s/it]Evaluating commonsenseqa :  20%|██        | 40/200 [52:52<3:31:20, 79.25s/it]Evaluating commonsenseqa :  94%|█████████▍| 189/200 [6:05:17<22:08, 120.77s/it]Evaluating commonsenseqa :  52%|█████▏    | 104/200 [2:28:08<2:26:32, 91.59s/it]Evaluating commonsenseqa :  25%|██▌       | 50/200 [1:29:53<4:07:24, 98.96s/it]Evaluating commonsenseqa :  20%|██        | 41/200 [54:11<3:30:03, 79.27s/it]Evaluating commonsenseqa :  81%|████████  | 162/200 [6:05:58<1:33:58, 148.37s/it]Evaluating commonsenseqa :  52%|█████▎    | 105/200 [2:28:48<2:00:46, 76.28s/it]Evaluating commonsenseqa :  21%|██        | 42/200 [55:30<3:28:39, 79.24s/it]Evaluating commonsenseqa :  53%|█████▎    | 106/200 [2:29:46<1:50:44, 70.69s/it]Evaluating commonsenseqa :  95%|█████████▌| 190/200 [6:07:27<20:36, 123.64s/it]Evaluating commonsenseqa :  26%|██▌       | 51/200 [1:31:48<4:18:07, 103.94s/it]Evaluating commonsenseqa :  82%|████████▏ | 163/200 [6:08:27<1:31:40, 148.67s/it]Evaluating commonsenseqa :  22%|██▏       | 43/200 [56:50<3:27:50, 79.43s/it]Evaluating commonsenseqa :  26%|██▌       | 52/200 [1:32:50<3:45:20, 91.36s/it] Evaluating commonsenseqa :  82%|████████▏ | 164/200 [6:08:57<1:07:50, 113.06s/it]Evaluating commonsenseqa :  96%|█████████▌| 191/200 [6:08:50<16:44, 111.58s/it]Evaluating commonsenseqa :  54%|█████▎    | 107/200 [2:31:20<2:00:39, 77.85s/it]Evaluating commonsenseqa :  22%|██▏       | 44/200 [58:10<3:26:55, 79.58s/it]Evaluating commonsenseqa :  26%|██▋       | 53/200 [1:34:18<3:41:14, 90.31s/it]Evaluating commonsenseqa :  82%|████████▎ | 165/200 [6:10:30<1:02:21, 106.91s/it]Evaluating commonsenseqa :  54%|█████▍    | 108/200 [2:32:54<2:06:29, 82.50s/it]Evaluating commonsenseqa :  22%|██▎       | 45/200 [59:29<3:25:21, 79.50s/it]Evaluating commonsenseqa :  96%|█████████▌| 192/200 [6:11:02<15:39, 117.45s/it]Evaluating commonsenseqa :  55%|█████▍    | 109/200 [2:34:26<2:09:25, 85.34s/it]Evaluating commonsenseqa :  27%|██▋       | 54/200 [1:36:16<3:59:44, 98.52s/it]Evaluating commonsenseqa :  23%|██▎       | 46/200 [1:00:48<3:23:29, 79.28s/it]Evaluating commonsenseqa :  96%|█████████▋| 193/200 [6:12:43<13:08, 112.66s/it]Evaluating commonsenseqa :  83%|████████▎ | 166/200 [6:12:57<1:07:31, 119.16s/it]Evaluating commonsenseqa :  55%|█████▌    | 110/200 [2:36:00<2:12:14, 88.17s/it]Evaluating commonsenseqa :  24%|██▎       | 47/200 [1:02:09<3:23:05, 79.65s/it]Evaluating commonsenseqa :  28%|██▊       | 55/200 [1:38:13<4:11:17, 103.98s/it]Evaluating commonsenseqa :  84%|████████▎ | 167/200 [6:14:21<59:38, 108.45s/it]  Evaluating commonsenseqa :  97%|█████████▋| 194/200 [6:14:50<11:41, 116.97s/it]Evaluating commonsenseqa :  24%|██▍       | 48/200 [1:03:29<3:22:17, 79.85s/it]Evaluating commonsenseqa :  56%|█████▌    | 111/200 [2:37:33<2:12:34, 89.37s/it]Evaluating commonsenseqa :  84%|████████▍ | 168/200 [6:16:01<56:34, 106.07s/it]Evaluating commonsenseqa :  28%|██▊       | 56/200 [1:40:08<4:17:58, 107.49s/it]Evaluating commonsenseqa :  24%|██▍       | 49/200 [1:04:41<3:15:16, 77.59s/it]Evaluating commonsenseqa :  56%|█████▌    | 112/200 [2:39:05<2:12:20, 90.23s/it]Evaluating commonsenseqa :  98%|█████████▊| 195/200 [6:17:00<10:03, 120.73s/it]Evaluating commonsenseqa :  25%|██▌       | 50/200 [1:06:02<3:16:32, 78.61s/it]Evaluating commonsenseqa :  28%|██▊       | 57/200 [1:42:06<4:23:21, 110.50s/it]Evaluating commonsenseqa :  56%|█████▋    | 113/200 [2:40:38<2:12:05, 91.10s/it]Evaluating commonsenseqa :  84%|████████▍ | 169/200 [6:18:29<1:01:11, 118.45s/it]Evaluating commonsenseqa :  26%|██▌       | 51/200 [1:07:23<3:17:02, 79.35s/it]Evaluating commonsenseqa :  98%|█████████▊| 196/200 [6:19:08<08:12, 123.05s/it]Evaluating commonsenseqa :  57%|█████▋    | 114/200 [2:42:12<2:11:59, 92.09s/it]Evaluating commonsenseqa :  29%|██▉       | 58/200 [1:44:02<4:25:14, 112.08s/it]Evaluating commonsenseqa :  26%|██▌       | 52/200 [1:08:43<3:16:11, 79.54s/it]Evaluating commonsenseqa :  57%|█████▊    | 115/200 [2:42:56<1:49:42, 77.44s/it]Evaluating commonsenseqa :  85%|████████▌ | 170/200 [6:20:55<1:03:25, 126.85s/it]Evaluating commonsenseqa :  98%|█████████▊| 197/200 [6:21:16<06:13, 124.44s/it]Evaluating commonsenseqa :  26%|██▋       | 53/200 [1:10:03<3:15:09, 79.66s/it]Evaluating commonsenseqa :  30%|██▉       | 59/200 [1:46:01<4:28:53, 114.42s/it]Evaluating commonsenseqa :  58%|█████▊    | 116/200 [2:44:27<1:54:14, 81.60s/it]Evaluating commonsenseqa :  27%|██▋       | 54/200 [1:11:23<3:13:38, 79.58s/it]Evaluating commonsenseqa :  86%|████████▌ | 171/200 [6:23:10<1:02:31, 129.36s/it]Evaluating commonsenseqa :  99%|█████████▉| 198/200 [6:23:23<04:10, 125.19s/it]Evaluating commonsenseqa :  30%|███       | 60/200 [1:47:38<4:14:22, 109.02s/it]Evaluating commonsenseqa :  58%|█████▊    | 117/200 [2:46:00<1:57:42, 85.09s/it]Evaluating commonsenseqa :  28%|██▊       | 55/200 [1:12:42<3:12:11, 79.53s/it]Evaluating commonsenseqa :  86%|████████▌ | 172/200 [6:24:45<55:28, 118.87s/it]  Evaluating commonsenseqa :  59%|█████▉    | 118/200 [2:47:34<1:59:52, 87.71s/it]Evaluating commonsenseqa : 100%|█████████▉| 199/200 [6:25:15<02:01, 121.30s/it]Evaluating commonsenseqa :  30%|███       | 61/200 [1:49:35<4:18:31, 111.60s/it]Evaluating commonsenseqa :  28%|██▊       | 56/200 [1:14:01<3:10:44, 79.47s/it]Evaluating commonsenseqa :  60%|█████▉    | 119/200 [2:49:08<2:00:54, 89.56s/it]Evaluating commonsenseqa :  28%|██▊       | 57/200 [1:15:21<3:09:22, 79.46s/it]Evaluating commonsenseqa :  86%|████████▋ | 173/200 [6:27:13<57:26, 127.67s/it]Evaluating commonsenseqa :  31%|███       | 62/200 [1:51:33<4:20:48, 113.40s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [6:27:25<00:00, 124.00s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [6:27:25<00:00, 116.23s/it]
name: commonsenseqa | avg. gen lenth: 240.558 | time: 23247.75519514084s
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10138 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o5-tmathqa-s20-rTrue --seed 20 --max-prompt-length 4096 --rationales --num-out-domain 5 5 7 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2023-09-20 01:26:13,303] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o5-tmathqa-s20-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 5
  out_domain_data_name ......... mathqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o5-tmathqa-s20-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 440024.50it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.32s/it]
 > number of parameters: 6738415616
[2023-09-20 01:26:29,936] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.3, git-hash=unknown, git-branch=unknown
[2023-09-20 01:26:29,936] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-09-20 01:26:30,433] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-20 01:26:30,435] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2023-09-20 01:26:30,436] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-20 01:26:30,436] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-20 01:26:30,436] [INFO] [config.py:971:print]   amp_enabled .................. False
[2023-09-20 01:26:30,436] [INFO] [config.py:971:print]   amp_params ................... False
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fa38602ada0>
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   communication_data_type ...... None
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   disable_allgather ............ False
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   dump_state ................... False
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   global_rank .................. 0
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   gradient_clipping ............ 0.0
[2023-09-20 01:26:30,437] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 2048
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   loss_scale ................... 0
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   optimizer_name ............... None
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   optimizer_params ............. None
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   pld_enabled .................. False
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   pld_params ................... False
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   scheduler_name ............... None
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   scheduler_params ............. None
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   sparse_attention ............. None
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   train_batch_size ............. 1
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  1
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   world_size ................... 1
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  True
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   zero_enabled ................. False
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-20 01:26:30,438] [INFO] [config.py:971:print]   zero_optimization_stage ...... 0
[2023-09-20 01:26:30,439] [INFO] [config.py:957:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/200 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: a man cycling along the road noticed that every 18 minutes a bus overtakes him and every 6 minutes he meets an oncoming bus. if all buses and the cyclist move at a constant speed, what is the time interval between consecutive buses? a ) 5 minutes, b ) 6 minutes, c ) 8 minutes, d ) 9 minutes, e ) 10 minutes
Output: let's say the distance between the buses is d. we want to determine interval = \ frac { d } { b }, where b is the speed of bus. let the speed of cyclist be c. every 18 minutes a bus overtakes cyclist : \ frac { d } { b - c } = 18, d = 18 b - 18 c ; every 6 minutes cyclist meets an oncoming bus : \ frac { d } { b + c } = 6, d = 6 b + 6 c ; d = 18 b - 18 c = 6 b + 6 c, - - > b = 2 c, - - > d = 18 b - 9 b = 9 b. interval = \ frac { d } { b } = \ frac { 9 b } { b } = 9 answer : d ( 9 minutes ).
So the final answer is d

Input: an athlete runs 200 metres race in 24 seconds. what is his speed? a ) 20 km / hr, b ) 30 km / hr, c ) 25 km / hr, d ) 35 km / hr, e ) 40 km / hr
Output: speed = dist / time = 200 / 24 200 / 24 * 18 / 5 = 40 * 3 / 4 = 30 km / hr answer b
So the final answer is b

Input: two numbers are in the ratio 3 : 4. if the sum of numbers is 63, find the numbers. a ) 27 and 36., b ) 25 and 30., c ) 23 and 44., d ) 63 and 12., e ) 12 and 36.
Output: "sum of the terms of the ratio = 3 + 4 = 7 sum of numbers = 63 therefore, first number = 3 / 7 × 63 = 27 second number = 4 / 7 × 63 = 36 therefore, the two numbers are 27 and 36. answer is a"
So the final answer is a

Input: a company wants to spend equal amounts of money for the purchase of two types of computer printers costing $ 375 and $ 150 per unit, respectively. what is the fewest number of computer printers that the company can purchase? a ) 3, b ) 4, c ) 5, d ) 6, e ) 7
Output: the smallest amount that the company can spend is the lcm of 375 and 150, which is 750 for each, which is total 1500. the number of 1 st type of computers which costing $ 375 = 750 / 375 = 2. the number of 2 nd type of computers which costing $ 150 = 750 / 150 = 5. total = 2 + 5 = 7 answer is e.
So the final answer is e

Input: a certain music store stocks 800 cellos and 600 violas. of these instruments, there are 80 cello - viola pairs, such that a cello and a viola were both made with wood from the same tree ( each tree can make at most one viola and one cello, so there are no pairs other than these 90 ). if one viola and one cello are chosen at random, what is the probability that the two instruments are made with wood from the same tree? a ) 3 / 16,000, b ) 1 / 8,100, c ) 1 / 600, d ) 1 / 90, e ) 2 / 45
Output: "solution provided by stanford 2012 is correct : 80 / 800 choosing one of the cellos which has a pair viola, 1 / 600 choosing the viola which is the pair of chosen cello - - > p = 80 / 800 * 1 / 600 = 1 / 6,000. answer : c."
So the final answer is c

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o5-tmathqa-s20-rTrue-m4096
Evaluating commonsenseqa :  29%|██▉       | 58/200 [1:16:41<3:08:50, 79.80s/it]Evaluating commonsenseqa :  60%|██████    | 120/200 [2:50:41<2:00:54, 90.68s/it]Evaluating commonsenseqa :  60%|██████    | 121/200 [2:51:27<1:41:32, 77.12s/it]Evaluating commonsenseqa :  32%|███▏      | 63/200 [1:53:31<4:22:23, 114.91s/it]Evaluating commonsenseqa :  87%|████████▋ | 174/200 [6:29:39<57:39, 133.06s/it]Evaluating commonsenseqa :  30%|██▉       | 59/200 [1:18:00<3:06:54, 79.54s/it]Evaluating commonsenseqa :   0%|          | 1/200 [01:52<6:11:32, 112.02s/it]Evaluating commonsenseqa :  61%|██████    | 122/200 [2:52:42<1:39:24, 76.47s/it]Evaluating commonsenseqa :  32%|███▏      | 64/200 [1:54:40<3:49:12, 101.12s/it]Evaluating commonsenseqa :  30%|███       | 60/200 [1:19:19<3:05:21, 79.44s/it]Evaluating commonsenseqa :  88%|████████▊ | 175/200 [6:31:52<55:29, 133.19s/it]Evaluating commonsenseqa :   1%|          | 2/200 [03:45<6:12:17, 112.81s/it]Evaluating commonsenseqa :  62%|██████▏   | 123/200 [2:54:16<1:44:55, 81.76s/it]Evaluating commonsenseqa :  30%|███       | 61/200 [1:20:39<3:04:06, 79.47s/it]Evaluating commonsenseqa :  32%|███▎      | 65/200 [1:56:36<3:57:29, 105.55s/it]Evaluating commonsenseqa :  62%|██████▏   | 124/200 [2:55:48<1:47:27, 84.84s/it]Evaluating commonsenseqa :  31%|███       | 62/200 [1:21:59<3:02:59, 79.56s/it]Evaluating commonsenseqa :   2%|▏         | 3/200 [05:37<6:10:03, 112.71s/it]Evaluating commonsenseqa :  88%|████████▊ | 176/200 [6:34:21<55:11, 137.99s/it]Evaluating commonsenseqa :  33%|███▎      | 66/200 [1:58:34<4:03:39, 109.10s/it]Evaluating commonsenseqa :  32%|███▏      | 63/200 [1:23:19<3:02:12, 79.80s/it]Evaluating commonsenseqa :  62%|██████▎   | 125/200 [2:57:19<1:48:38, 86.92s/it]Evaluating commonsenseqa :   2%|▏         | 4/200 [07:30<6:07:25, 112.48s/it]Evaluating commonsenseqa :  32%|███▏      | 64/200 [1:24:39<3:00:33, 79.66s/it]Evaluating commonsenseqa :  34%|███▎      | 67/200 [2:00:32<4:08:02, 111.90s/it]Evaluating commonsenseqa :  63%|██████▎   | 126/200 [2:58:54<1:49:52, 89.08s/it]Evaluating commonsenseqa :  88%|████████▊ | 177/200 [6:36:52<54:17, 141.65s/it]Evaluating commonsenseqa :   2%|▎         | 5/200 [09:23<6:06:22, 112.73s/it]Evaluating commonsenseqa :  64%|██████▎   | 127/200 [2:59:56<1:38:31, 80.98s/it]Evaluating commonsenseqa :  32%|███▎      | 65/200 [1:25:59<2:59:34, 79.81s/it]Evaluating commonsenseqa :  34%|███▍      | 68/200 [2:02:28<4:09:02, 113.20s/it]Evaluating commonsenseqa :  33%|███▎      | 66/200 [1:27:17<2:57:28, 79.46s/it]Evaluating commonsenseqa :  64%|██████▍   | 128/200 [3:01:29<1:41:30, 84.60s/it]Evaluating commonsenseqa :  89%|████████▉ | 178/200 [6:39:23<53:02, 144.65s/it]Evaluating commonsenseqa :   3%|▎         | 6/200 [11:16<6:05:11, 112.94s/it]Evaluating commonsenseqa :  34%|███▎      | 67/200 [1:28:36<2:55:42, 79.27s/it]Evaluating commonsenseqa :  34%|███▍      | 69/200 [2:04:25<4:09:37, 114.33s/it]Evaluating commonsenseqa :  64%|██████▍   | 129/200 [3:03:02<1:43:19, 87.32s/it]Evaluating commonsenseqa :  65%|██████▌   | 130/200 [3:03:27<1:19:48, 68.41s/it]Evaluating commonsenseqa :  90%|████████▉ | 179/200 [6:41:17<47:24, 135.47s/it]Evaluating commonsenseqa :   4%|▎         | 7/200 [13:10<6:04:25, 113.29s/it]Evaluating commonsenseqa :  34%|███▍      | 68/200 [1:29:57<2:55:18, 79.68s/it]Evaluating commonsenseqa :  35%|███▌      | 70/200 [2:06:22<4:09:23, 115.11s/it]Evaluating commonsenseqa :  66%|██████▌   | 131/200 [3:05:01<1:27:41, 76.25s/it]Evaluating commonsenseqa :  34%|███▍      | 69/200 [1:31:17<2:54:30, 79.93s/it]Evaluating commonsenseqa :   4%|▍         | 8/200 [15:04<6:02:45, 113.36s/it]Evaluating commonsenseqa :  90%|█████████ | 180/200 [6:43:46<46:26, 139.32s/it]Evaluating commonsenseqa :  36%|███▌      | 71/200 [2:08:18<4:07:58, 115.34s/it]Evaluating commonsenseqa :  66%|██████▌   | 132/200 [3:06:35<1:32:15, 81.40s/it]Evaluating commonsenseqa :  35%|███▌      | 70/200 [1:32:37<2:52:47, 79.75s/it]Evaluating commonsenseqa :   4%|▍         | 9/200 [16:57<6:00:25, 113.22s/it]Evaluating commonsenseqa :  36%|███▌      | 71/200 [1:33:57<2:51:34, 79.81s/it]Evaluating commonsenseqa :  66%|██████▋   | 133/200 [3:08:09<1:35:10, 85.24s/it]Evaluating commonsenseqa :  90%|█████████ | 181/200 [6:46:13<44:53, 141.76s/it]Evaluating commonsenseqa :  36%|███▌      | 72/200 [2:10:15<4:06:58, 115.77s/it]Evaluating commonsenseqa :  36%|███▌      | 72/200 [1:35:16<2:49:50, 79.62s/it]Evaluating commonsenseqa :   5%|▌         | 10/200 [18:52<6:01:08, 114.04s/it]Evaluating commonsenseqa :  67%|██████▋   | 134/200 [3:09:43<1:36:47, 88.00s/it]Evaluating commonsenseqa :  36%|███▋      | 73/200 [2:12:08<4:03:36, 115.09s/it]Evaluating commonsenseqa :  36%|███▋      | 73/200 [1:36:36<2:49:07, 79.90s/it]Evaluating commonsenseqa :  91%|█████████ | 182/200 [6:48:41<43:07, 143.73s/it]Evaluating commonsenseqa :   6%|▌         | 11/200 [20:44<5:56:40, 113.23s/it]Evaluating commonsenseqa :  68%|██████▊   | 135/200 [3:11:16<1:36:53, 89.44s/it]Evaluating commonsenseqa :  37%|███▋      | 74/200 [1:37:56<2:47:22, 79.71s/it]Evaluating commonsenseqa :  92%|█████████▏| 183/200 [6:49:40<33:29, 118.23s/it]Evaluating commonsenseqa :  37%|███▋      | 74/200 [2:14:05<4:02:21, 115.41s/it]Evaluating commonsenseqa :  68%|██████▊   | 136/200 [3:12:49<1:36:30, 90.47s/it]Evaluating commonsenseqa :   6%|▌         | 12/200 [22:40<5:57:26, 114.08s/it]Evaluating commonsenseqa :  38%|███▊      | 75/200 [1:39:16<2:46:38, 79.99s/it]Evaluating commonsenseqa :  38%|███▊      | 75/200 [2:15:05<3:26:21, 99.05s/it] Evaluating commonsenseqa :  38%|███▊      | 76/200 [2:15:41<2:45:18, 79.99s/it]Evaluating commonsenseqa :  68%|██████▊   | 137/200 [3:14:21<1:35:33, 91.01s/it]Evaluating commonsenseqa :  92%|█████████▏| 184/200 [6:52:06<33:46, 126.67s/it]Evaluating commonsenseqa :  38%|███▊      | 76/200 [1:40:37<2:45:40, 80.17s/it]Evaluating commonsenseqa :   6%|▋         | 13/200 [24:32<5:54:07, 113.62s/it]Evaluating commonsenseqa :  69%|██████▉   | 138/200 [3:15:55<1:34:46, 91.71s/it]Evaluating commonsenseqa :  38%|███▊      | 77/200 [1:41:57<2:44:34, 80.28s/it]Evaluating commonsenseqa :  38%|███▊      | 77/200 [2:17:41<3:08:25, 91.91s/it]Evaluating commonsenseqa :  92%|█████████▎| 185/200 [6:54:34<33:12, 132.85s/it]Evaluating commonsenseqa :   7%|▋         | 14/200 [26:25<5:51:15, 113.31s/it]Evaluating commonsenseqa :  39%|███▉      | 78/200 [1:43:16<2:42:29, 79.92s/it]Evaluating commonsenseqa :  70%|██████▉   | 139/200 [3:17:27<1:33:26, 91.92s/it]Evaluating commonsenseqa :  39%|███▉      | 78/200 [2:19:41<3:24:15, 100.45s/it]Evaluating commonsenseqa :  70%|███████   | 140/200 [3:17:59<1:13:50, 73.84s/it]Evaluating commonsenseqa :  40%|███▉      | 79/200 [1:44:37<2:41:24, 80.04s/it]Evaluating commonsenseqa :   8%|▊         | 15/200 [28:16<5:47:17, 112.63s/it]Evaluating commonsenseqa :  40%|███▉      | 79/200 [2:20:42<2:58:44, 88.63s/it] Evaluating commonsenseqa :  93%|█████████▎| 186/200 [6:57:00<31:56, 136.92s/it]Evaluating commonsenseqa :  40%|████      | 80/200 [2:21:11<2:21:13, 70.62s/it]Evaluating commonsenseqa :  70%|███████   | 141/200 [3:19:31<1:18:00, 79.33s/it]Evaluating commonsenseqa :  40%|████      | 80/200 [1:45:56<2:39:43, 79.86s/it]Evaluating commonsenseqa :   8%|▊         | 16/200 [30:08<5:44:17, 112.27s/it]Evaluating commonsenseqa :  40%|████      | 81/200 [2:22:30<2:25:00, 73.11s/it]Evaluating commonsenseqa :  71%|███████   | 142/200 [3:21:03<1:20:33, 83.34s/it]Evaluating commonsenseqa :  40%|████      | 81/200 [1:47:16<2:38:24, 79.87s/it]Evaluating commonsenseqa :  94%|█████████▎| 187/200 [6:59:26<30:13, 139.49s/it]Evaluating commonsenseqa :  72%|███████▏  | 143/200 [3:21:49<1:08:19, 71.91s/it]Evaluating commonsenseqa :   8%|▊         | 17/200 [31:59<5:42:00, 112.13s/it]Evaluating commonsenseqa :  41%|████      | 82/200 [1:48:37<2:37:33, 80.12s/it]Evaluating commonsenseqa :  41%|████      | 82/200 [2:24:27<2:49:56, 86.41s/it]Evaluating commonsenseqa :  72%|███████▏  | 144/200 [3:23:23<1:13:22, 78.61s/it]Evaluating commonsenseqa :  42%|████▏     | 83/200 [1:49:56<2:35:51, 79.93s/it]Evaluating commonsenseqa :  94%|█████████▍| 188/200 [7:01:53<28:22, 141.87s/it]Evaluating commonsenseqa :   9%|▉         | 18/200 [33:52<5:40:24, 112.22s/it]Evaluating commonsenseqa :  42%|████▏     | 83/200 [2:26:23<3:05:59, 95.38s/it]Evaluating commonsenseqa :  72%|███████▎  | 145/200 [3:24:56<1:15:57, 82.86s/it]Evaluating commonsenseqa :  42%|████▏     | 84/200 [1:51:16<2:34:21, 79.84s/it]Evaluating commonsenseqa :  10%|▉         | 19/200 [35:43<5:37:57, 112.03s/it]Evaluating commonsenseqa :  73%|███████▎  | 146/200 [3:26:28<1:17:01, 85.58s/it]Evaluating commonsenseqa :  42%|████▎     | 85/200 [1:52:35<2:32:30, 79.57s/it]Evaluating commonsenseqa :  94%|█████████▍| 189/200 [7:04:19<26:15, 143.22s/it]Evaluating commonsenseqa :  42%|████▏     | 84/200 [2:28:19<3:16:21, 101.56s/it]Evaluating commonsenseqa :  43%|████▎     | 86/200 [1:53:54<2:31:10, 79.57s/it]Evaluating commonsenseqa :  74%|███████▎  | 147/200 [3:27:59<1:17:09, 87.35s/it]Evaluating commonsenseqa :  10%|█         | 20/200 [37:39<5:39:34, 113.19s/it]Evaluating commonsenseqa :  42%|████▎     | 85/200 [2:30:18<3:24:14, 106.56s/it]Evaluating commonsenseqa :  95%|█████████▌| 190/200 [7:06:44<23:56, 143.67s/it]Evaluating commonsenseqa :  44%|████▎     | 87/200 [1:55:13<2:29:29, 79.37s/it]Evaluating commonsenseqa :  74%|███████▍  | 148/200 [3:29:30<1:16:33, 88.33s/it]Evaluating commonsenseqa :  10%|█         | 21/200 [39:31<5:36:16, 112.72s/it]Evaluating commonsenseqa :  44%|████▍     | 88/200 [1:56:34<2:28:44, 79.68s/it]Evaluating commonsenseqa :  43%|████▎     | 86/200 [2:32:18<3:30:13, 110.65s/it]Evaluating commonsenseqa :  74%|███████▍  | 149/200 [3:31:03<1:16:18, 89.77s/it]Evaluating commonsenseqa :  96%|█████████▌| 191/200 [7:09:09<21:36, 144.06s/it]Evaluating commonsenseqa :  75%|███████▌  | 150/200 [3:31:44<1:02:34, 75.09s/it]Evaluating commonsenseqa :  11%|█         | 22/200 [41:22<5:33:14, 112.33s/it]Evaluating commonsenseqa :  44%|████▍     | 89/200 [1:57:53<2:27:03, 79.49s/it]Evaluating commonsenseqa :  44%|████▎     | 87/200 [2:34:14<3:31:22, 112.23s/it]Evaluating commonsenseqa :  45%|████▌     | 90/200 [1:59:13<2:26:06, 79.70s/it]Evaluating commonsenseqa :  96%|█████████▌| 192/200 [7:10:57<17:45, 133.16s/it]Evaluating commonsenseqa :  76%|███████▌  | 151/200 [3:33:17<1:05:46, 80.54s/it]Evaluating commonsenseqa :  12%|█▏        | 23/200 [43:15<5:32:03, 112.56s/it]Evaluating commonsenseqa :  44%|████▍     | 88/200 [2:36:09<3:31:24, 113.25s/it]Evaluating commonsenseqa :  46%|████▌     | 91/200 [2:00:33<2:24:50, 79.73s/it]Evaluating commonsenseqa :  96%|█████████▋| 193/200 [7:12:31<14:09, 121.36s/it]Evaluating commonsenseqa :  76%|███████▌  | 152/200 [3:34:49<1:07:07, 83.91s/it]Evaluating commonsenseqa :  76%|███████▋  | 153/200 [3:35:18<52:48, 67.42s/it]  Evaluating commonsenseqa :  12%|█▏        | 24/200 [45:07<5:29:30, 112.33s/it]Evaluating commonsenseqa :  46%|████▌     | 92/200 [2:01:52<2:23:21, 79.64s/it]Evaluating commonsenseqa :  44%|████▍     | 89/200 [2:38:05<3:30:57, 114.03s/it]Evaluating commonsenseqa :  77%|███████▋  | 154/200 [3:36:52<57:56, 75.58s/it]Evaluating commonsenseqa :  46%|████▋     | 93/200 [2:03:11<2:21:47, 79.51s/it]Evaluating commonsenseqa :  45%|████▌     | 90/200 [2:38:56<2:54:30, 95.19s/it] Evaluating commonsenseqa :  97%|█████████▋| 194/200 [7:14:59<12:56, 129.49s/it]Evaluating commonsenseqa :  12%|█▎        | 25/200 [47:00<5:27:53, 112.42s/it]Evaluating commonsenseqa :  78%|███████▊  | 155/200 [3:37:39<50:12, 66.95s/it]Evaluating commonsenseqa :  47%|████▋     | 94/200 [2:04:31<2:20:33, 79.56s/it]Evaluating commonsenseqa :  78%|███████▊  | 156/200 [3:38:48<49:32, 67.56s/it]Evaluating commonsenseqa :  98%|█████████▊| 195/200 [7:16:48<10:16, 123.28s/it]Evaluating commonsenseqa :  46%|████▌     | 91/200 [2:40:54<3:05:07, 101.91s/it]Evaluating commonsenseqa :  13%|█▎        | 26/200 [48:53<5:26:52, 112.71s/it]Evaluating commonsenseqa :  78%|███████▊  | 157/200 [3:39:31<43:11, 60.26s/it]Evaluating commonsenseqa :  48%|████▊     | 95/200 [2:05:51<2:19:23, 79.65s/it]Evaluating commonsenseqa :  79%|███████▉  | 158/200 [3:40:26<40:56, 58.48s/it]Evaluating commonsenseqa :  46%|████▌     | 92/200 [2:42:50<3:10:50, 106.02s/it]Evaluating commonsenseqa :  48%|████▊     | 96/200 [2:07:10<2:17:49, 79.52s/it]Evaluating commonsenseqa :  14%|█▎        | 27/200 [50:45<5:24:33, 112.57s/it]Evaluating commonsenseqa :  98%|█████████▊| 196/200 [7:19:19<08:46, 131.51s/it]Evaluating commonsenseqa :  80%|███████▉  | 159/200 [3:41:37<42:35, 62.33s/it]Evaluating commonsenseqa :  48%|████▊     | 97/200 [2:08:31<2:16:59, 79.80s/it]Evaluating commonsenseqa :  46%|████▋     | 93/200 [2:44:19<3:00:06, 101.00s/it]Evaluating commonsenseqa :  80%|████████  | 160/200 [3:42:58<45:11, 67.79s/it]Evaluating commonsenseqa :  14%|█▍        | 28/200 [52:36<5:21:18, 112.09s/it]Evaluating commonsenseqa :  49%|████▉     | 98/200 [2:09:51<2:15:57, 79.98s/it]Evaluating commonsenseqa :  98%|█████████▊| 197/200 [7:21:45<06:47, 135.99s/it]Evaluating commonsenseqa :  47%|████▋     | 94/200 [2:45:57<2:57:09, 100.28s/it]Evaluating commonsenseqa :  80%|████████  | 161/200 [3:44:30<48:53, 75.21s/it]Evaluating commonsenseqa :  14%|█▍        | 29/200 [54:30<5:20:23, 112.42s/it]Evaluating commonsenseqa :  50%|████▉     | 99/200 [2:11:11<2:14:34, 79.95s/it]Evaluating commonsenseqa :  81%|████████  | 162/200 [3:46:03<51:00, 80.54s/it]Evaluating commonsenseqa :  48%|████▊     | 95/200 [2:47:55<3:04:34, 105.47s/it]Evaluating commonsenseqa :  99%|█████████▉| 198/200 [7:24:13<04:39, 139.54s/it]Evaluating commonsenseqa :  50%|█████     | 100/200 [2:12:32<2:13:39, 80.19s/it]Evaluating commonsenseqa :  15%|█▌        | 30/200 [56:23<5:19:22, 112.72s/it]Evaluating commonsenseqa :  82%|████████▏ | 163/200 [3:47:36<52:00, 84.33s/it]Evaluating commonsenseqa :  50%|█████     | 101/200 [2:13:52<2:12:17, 80.18s/it]Evaluating commonsenseqa :  48%|████▊     | 96/200 [2:49:55<3:10:26, 109.87s/it]Evaluating commonsenseqa :  16%|█▌        | 31/200 [58:16<5:17:57, 112.89s/it]Evaluating commonsenseqa : 100%|█████████▉| 199/200 [7:26:39<02:21, 141.49s/it]Evaluating commonsenseqa :  51%|█████     | 102/200 [2:15:11<2:10:37, 79.98s/it]Evaluating commonsenseqa :  82%|████████▏ | 164/200 [3:49:10<52:21, 87.25s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [7:27:53<00:00, 121.38s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [7:27:53<00:00, 134.37s/it]
Evaluating commonsenseqa :  48%|████▊     | 97/200 [2:51:52<3:12:12, 111.96s/it]name: commonsenseqa | avg. gen lenth: 251.251 | time: 26875.583769083023s
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10137 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o3-tmathqa-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 3 1 3 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2023-09-20 02:26:24,027] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o3-tmathqa-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 3
  out_domain_data_name ......... mathqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o3-tmathqa-s10-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 741676.17it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Evaluating commonsenseqa :  52%|█████▏    | 103/200 [2:16:31<2:09:04, 79.84s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.32s/it]
 > number of parameters: 6738415616
[2023-09-20 02:26:40,514] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.3, git-hash=unknown, git-branch=unknown
[2023-09-20 02:26:40,514] [INFO] [comm.py:637:init_distributed] cdb=None
Evaluating commonsenseqa :  16%|█▌        | 32/200 [1:00:10<5:16:44, 113.12s/it][2023-09-20 02:26:40,973] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-20 02:26:40,976] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2023-09-20 02:26:40,976] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-20 02:26:40,976] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-20 02:26:40,976] [INFO] [config.py:971:print]   amp_enabled .................. False
[2023-09-20 02:26:40,976] [INFO] [config.py:971:print]   amp_params ................... False
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fb95db2ed70>
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   communication_data_type ...... None
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   disable_allgather ............ False
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   dump_state ................... False
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2023-09-20 02:26:40,977] [INFO] [config.py:971:print]   global_rank .................. 0
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   gradient_clipping ............ 0.0
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 2048
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   loss_scale ................... 0
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   optimizer_name ............... None
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   optimizer_params ............. None
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   pld_enabled .................. False
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   pld_params ................... False
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   scheduler_name ............... None
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   scheduler_params ............. None
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   sparse_attention ............. None
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   train_batch_size ............. 1
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  1
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   world_size ................... 1
[2023-09-20 02:26:40,978] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  True
[2023-09-20 02:26:40,979] [INFO] [config.py:971:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2023-09-20 02:26:40,979] [INFO] [config.py:971:print]   zero_enabled ................. False
[2023-09-20 02:26:40,979] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-20 02:26:40,979] [INFO] [config.py:971:print]   zero_optimization_stage ...... 0
[2023-09-20 02:26:40,979] [INFO] [config.py:957:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/200 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: in a recent head - to - head run - off election, 12000 absentee ballets were cast. 1 / 6 of the absentee ballets were thrown out and 3 / 5 of the remaining absentee ballets were cast for candidate a. how many absentee votes did candidate b receive? a ) 2,000, b ) 3,000, c ) 4,000, d ) 8,000, e ) 9,000
Output: c

Input: the total age of a and b is 11 years more than the total age of b and c. c is how many years younger than a.? a ) 16, b ) 12, c ) 11, d ) 20, e ) 10
Output: c

Input: the scoring system in a certain football competition goes as follows : 3 points for victory, 1 point for a draw, and 0 points for defeat. each team plays 20 matches. if a team scored 14 points after 5 games, what is the least number of the remaining matches it has to win to reach the 40 - point mark by the end of the tournament? a ) 6, b ) 7, c ) 8, d ) 9, e ) 10
Output: a

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o3-tmathqa-s10-rFalse-m4096
Evaluating commonsenseqa :  82%|████████▎ | 165/200 [3:50:43<51:54, 88.99s/it]Evaluating commonsenseqa :  52%|█████▏    | 104/200 [2:17:50<2:07:37, 79.77s/it]Evaluating commonsenseqa :  49%|████▉     | 98/200 [2:53:49<3:13:02, 113.55s/it]Evaluating commonsenseqa :  83%|████████▎ | 166/200 [3:52:16<51:06, 90.19s/it]Evaluating commonsenseqa :  16%|█▋        | 33/200 [1:02:02<5:14:13, 112.90s/it]Evaluating commonsenseqa :   0%|          | 1/200 [02:18<7:37:52, 138.06s/it]Evaluating commonsenseqa :  52%|█████▎    | 105/200 [2:19:10<2:06:11, 79.70s/it]Evaluating commonsenseqa :  84%|████████▎ | 167/200 [3:53:50<50:14, 91.36s/it]Evaluating commonsenseqa :  50%|████▉     | 99/200 [2:55:46<3:12:33, 114.39s/it]Evaluating commonsenseqa :  17%|█▋        | 34/200 [1:03:52<5:09:40, 111.93s/it]Evaluating commonsenseqa :  53%|█████▎    | 106/200 [2:20:30<2:05:00, 79.79s/it]Evaluating commonsenseqa :   1%|          | 2/200 [04:35<7:34:52, 137.84s/it]Evaluating commonsenseqa :  84%|████████▍ | 168/200 [3:55:24<49:04, 92.01s/it]Evaluating commonsenseqa :  50%|█████     | 100/200 [2:57:30<3:05:40, 111.41s/it]Evaluating commonsenseqa :  54%|█████▎    | 107/200 [2:21:49<2:03:14, 79.51s/it]Evaluating commonsenseqa :  18%|█▊        | 35/200 [1:05:38<5:03:06, 110.22s/it]Evaluating commonsenseqa :  84%|████████▍ | 169/200 [3:56:57<47:42, 92.33s/it]Evaluating commonsenseqa :  54%|█████▍    | 108/200 [2:23:09<2:02:16, 79.75s/it]Evaluating commonsenseqa :  50%|█████     | 101/200 [2:58:59<2:52:37, 104.62s/it]Evaluating commonsenseqa :   2%|▏         | 3/200 [06:55<7:34:44, 138.50s/it]Evaluating commonsenseqa :  18%|█▊        | 36/200 [1:07:33<5:04:54, 111.55s/it]Evaluating commonsenseqa :  55%|█████▍    | 109/200 [2:24:29<2:01:13, 79.93s/it]Evaluating commonsenseqa :  85%|████████▌ | 170/200 [3:58:31<46:22, 92.77s/it]Evaluating commonsenseqa :  51%|█████     | 102/200 [3:00:33<2:45:43, 101.46s/it]Evaluating commonsenseqa :  18%|█▊        | 37/200 [1:09:24<5:02:22, 111.31s/it]Evaluating commonsenseqa :  55%|█████▌    | 110/200 [2:25:50<2:00:11, 80.13s/it]Evaluating commonsenseqa :   2%|▏         | 4/200 [09:14<7:34:18, 139.07s/it]Evaluating commonsenseqa :  86%|████████▌ | 171/200 [4:00:02<44:37, 92.33s/it]Evaluating commonsenseqa :  52%|█████▏    | 103/200 [3:02:29<2:51:11, 105.89s/it]Evaluating commonsenseqa :  86%|████████▌ | 172/200 [4:00:55<37:33, 80.47s/it]Evaluating commonsenseqa :  56%|█████▌    | 111/200 [2:27:10<1:58:47, 80.09s/it]Evaluating commonsenseqa :  19%|█▉        | 38/200 [1:11:14<4:59:50, 111.05s/it]Evaluating commonsenseqa :  52%|█████▏    | 104/200 [3:03:50<2:37:12, 98.26s/it] Evaluating commonsenseqa :   2%|▎         | 5/200 [11:36<7:34:22, 139.81s/it]Evaluating commonsenseqa :  56%|█████▌    | 112/200 [2:28:30<1:57:17, 79.97s/it]Evaluating commonsenseqa :  86%|████████▋ | 173/200 [4:02:30<38:10, 84.84s/it]Evaluating commonsenseqa :  87%|████████▋ | 174/200 [4:03:17<31:54, 73.63s/it]Evaluating commonsenseqa :  20%|█▉        | 39/200 [1:13:08<5:00:01, 111.81s/it]Evaluating commonsenseqa :  56%|█████▋    | 113/200 [2:29:50<1:56:03, 80.04s/it]Evaluating commonsenseqa :  52%|█████▎    | 105/200 [3:05:50<2:45:51, 104.75s/it]Evaluating commonsenseqa :   3%|▎         | 6/200 [13:57<7:33:19, 140.20s/it]Evaluating commonsenseqa :  88%|████████▊ | 175/200 [4:04:49<32:55, 79.03s/it]Evaluating commonsenseqa :  57%|█████▋    | 114/200 [2:31:10<1:54:32, 79.92s/it]Evaluating commonsenseqa :  53%|█████▎    | 106/200 [3:07:00<2:28:04, 94.51s/it] Evaluating commonsenseqa :  20%|██        | 40/200 [1:15:03<5:00:51, 112.82s/it]Evaluating commonsenseqa :  88%|████████▊ | 176/200 [4:06:10<31:49, 79.56s/it]Evaluating commonsenseqa :  57%|█████▊    | 115/200 [2:32:29<1:53:06, 79.84s/it]Evaluating commonsenseqa :  54%|█████▎    | 107/200 [3:08:20<2:19:40, 90.11s/it]Evaluating commonsenseqa :   4%|▎         | 7/200 [16:16<7:30:34, 140.07s/it]Evaluating commonsenseqa :  20%|██        | 41/200 [1:16:56<4:59:22, 112.97s/it]Evaluating commonsenseqa :  88%|████████▊ | 177/200 [4:07:42<32:00, 83.48s/it]Evaluating commonsenseqa :  58%|█████▊    | 116/200 [2:33:50<1:51:57, 79.98s/it]Evaluating commonsenseqa :  54%|█████▍    | 108/200 [3:10:16<2:30:12, 97.96s/it]Evaluating commonsenseqa :  58%|█████▊    | 117/200 [2:35:10<1:50:45, 80.06s/it]Evaluating commonsenseqa :   4%|▍         | 8/200 [18:36<7:27:30, 139.85s/it]Evaluating commonsenseqa :  21%|██        | 42/200 [1:18:48<4:56:42, 112.67s/it]Evaluating commonsenseqa :  89%|████████▉ | 178/200 [4:09:17<31:49, 86.82s/it]Evaluating commonsenseqa :  55%|█████▍    | 109/200 [3:11:47<2:25:07, 95.68s/it]Evaluating commonsenseqa :  59%|█████▉    | 118/200 [2:36:29<1:49:13, 79.91s/it]Evaluating commonsenseqa :  90%|████████▉ | 179/200 [4:10:51<31:05, 88.86s/it]Evaluating commonsenseqa :  22%|██▏       | 43/200 [1:20:40<4:54:14, 112.45s/it]Evaluating commonsenseqa :  90%|█████████ | 180/200 [4:11:28<24:28, 73.43s/it]Evaluating commonsenseqa :   4%|▍         | 9/200 [20:56<7:25:26, 139.93s/it]Evaluating commonsenseqa :  60%|█████▉    | 119/200 [2:37:50<1:47:59, 80.00s/it]Evaluating commonsenseqa :  55%|█████▌    | 110/200 [3:13:41<2:32:08, 101.42s/it]Evaluating commonsenseqa :  90%|█████████ | 181/200 [4:12:51<24:11, 76.41s/it]Evaluating commonsenseqa :  22%|██▏       | 44/200 [1:22:33<4:52:35, 112.54s/it]Evaluating commonsenseqa :  60%|██████    | 120/200 [2:39:09<1:46:34, 79.94s/it]Evaluating commonsenseqa :   5%|▌         | 10/200 [23:15<7:21:58, 139.57s/it]Evaluating commonsenseqa :  56%|█████▌    | 111/200 [3:15:39<2:37:35, 106.24s/it]Evaluating commonsenseqa :  91%|█████████ | 182/200 [4:14:25<24:27, 81.55s/it]Evaluating commonsenseqa :  60%|██████    | 121/200 [2:40:28<1:44:55, 79.69s/it]Evaluating commonsenseqa :  22%|██▎       | 45/200 [1:24:25<4:50:34, 112.48s/it]Evaluating commonsenseqa :  56%|█████▌    | 112/200 [3:16:54<2:21:58, 96.80s/it] Evaluating commonsenseqa :  92%|█████████▏| 183/200 [4:15:37<22:16, 78.62s/it]Evaluating commonsenseqa :  61%|██████    | 122/200 [2:41:50<1:44:15, 80.20s/it]Evaluating commonsenseqa :  56%|█████▋    | 113/200 [3:17:35<1:56:18, 80.22s/it]Evaluating commonsenseqa :   6%|▌         | 11/200 [25:34<7:19:14, 139.44s/it]Evaluating commonsenseqa :  23%|██▎       | 46/200 [1:26:19<4:49:52, 112.94s/it]Evaluating commonsenseqa :  92%|█████████▏| 184/200 [4:17:06<21:46, 81.67s/it]Evaluating commonsenseqa :  62%|██████▏   | 123/200 [2:43:10<1:42:50, 80.13s/it]Evaluating commonsenseqa :  57%|█████▋    | 114/200 [3:19:31<2:10:21, 90.95s/it]Evaluating commonsenseqa :  62%|██████▏   | 124/200 [2:44:06<1:32:27, 73.00s/it]Evaluating commonsenseqa :   6%|▌         | 12/200 [27:32<6:56:31, 132.94s/it]Evaluating commonsenseqa :  24%|██▎       | 47/200 [1:28:14<4:49:18, 113.46s/it]Evaluating commonsenseqa :  92%|█████████▎| 185/200 [4:18:38<21:11, 84.78s/it]Evaluating commonsenseqa :  62%|██████▎   | 125/200 [2:45:25<1:33:35, 74.88s/it]Evaluating commonsenseqa :  57%|█████▊    | 115/200 [3:21:27<2:19:15, 98.29s/it]Evaluating commonsenseqa :   6%|▋         | 13/200 [29:27<6:37:13, 127.45s/it]Evaluating commonsenseqa :  93%|█████████▎| 186/200 [4:20:10<20:19, 87.12s/it]Evaluating commonsenseqa :  24%|██▍       | 48/200 [1:30:06<4:46:42, 113.18s/it]Evaluating commonsenseqa :  63%|██████▎   | 126/200 [2:46:46<1:34:33, 76.67s/it]Evaluating commonsenseqa :  58%|█████▊    | 116/200 [3:23:21<2:24:15, 103.04s/it]Evaluating commonsenseqa :  94%|█████████▎| 187/200 [4:21:45<19:21, 89.34s/it]Evaluating commonsenseqa :  64%|██████▎   | 127/200 [2:48:05<1:34:08, 77.37s/it]Evaluating commonsenseqa :   7%|▋         | 14/200 [31:47<6:46:52, 131.25s/it]Evaluating commonsenseqa :  24%|██▍       | 49/200 [1:32:01<4:45:47, 113.56s/it]Evaluating commonsenseqa :  58%|█████▊    | 117/200 [3:24:50<2:16:56, 99.00s/it] Evaluating commonsenseqa :  94%|█████████▍| 188/200 [4:23:18<18:06, 90.55s/it]Evaluating commonsenseqa :  64%|██████▍   | 128/200 [2:49:25<1:33:43, 78.11s/it]Evaluating commonsenseqa :  25%|██▌       | 50/200 [1:33:53<4:42:58, 113.19s/it]Evaluating commonsenseqa :   8%|▊         | 15/200 [34:08<6:53:55, 134.24s/it]Evaluating commonsenseqa :  64%|██████▍   | 129/200 [2:50:45<1:33:00, 78.60s/it]Evaluating commonsenseqa :  94%|█████████▍| 189/200 [4:24:51<16:44, 91.28s/it]Evaluating commonsenseqa :  59%|█████▉    | 118/200 [3:26:45<2:21:35, 103.61s/it]Evaluating commonsenseqa :  60%|█████▉    | 119/200 [3:27:31<1:56:36, 86.38s/it] Evaluating commonsenseqa :  65%|██████▌   | 130/200 [2:52:04<1:31:51, 78.74s/it]Evaluating commonsenseqa :  26%|██▌       | 51/200 [1:35:47<4:41:58, 113.55s/it]Evaluating commonsenseqa :  95%|█████████▌| 190/200 [4:26:24<15:16, 91.63s/it]Evaluating commonsenseqa :   8%|▊         | 16/200 [36:27<6:55:56, 135.63s/it]Evaluating commonsenseqa :  66%|██████▌   | 131/200 [2:53:24<1:31:05, 79.22s/it]Evaluating commonsenseqa :  60%|██████    | 120/200 [3:29:25<2:06:06, 94.58s/it]Evaluating commonsenseqa :  96%|█████████▌| 191/200 [4:27:56<13:47, 91.92s/it]Evaluating commonsenseqa :  26%|██▌       | 52/200 [1:37:40<4:39:32, 113.33s/it]Evaluating commonsenseqa :  66%|██████▌   | 132/200 [2:54:44<1:29:58, 79.39s/it]Evaluating commonsenseqa :   8%|▊         | 17/200 [38:47<6:58:17, 137.15s/it]Evaluating commonsenseqa :  96%|█████████▌| 192/200 [4:29:30<12:19, 92.39s/it]Evaluating commonsenseqa :  60%|██████    | 121/200 [3:31:22<2:13:26, 101.35s/it]Evaluating commonsenseqa :  26%|██▋       | 53/200 [1:39:34<4:37:46, 113.38s/it]Evaluating commonsenseqa :  66%|██████▋   | 133/200 [2:56:04<1:28:50, 79.56s/it]Evaluating commonsenseqa :  61%|██████    | 122/200 [3:32:21<1:55:15, 88.66s/it] Evaluating commonsenseqa :  96%|█████████▋| 193/200 [4:31:01<10:44, 92.07s/it]Evaluating commonsenseqa :  67%|██████▋   | 134/200 [2:57:23<1:27:21, 79.41s/it]Evaluating commonsenseqa :   9%|▉         | 18/200 [41:08<6:59:18, 138.23s/it]Evaluating commonsenseqa :  27%|██▋       | 54/200 [1:41:25<4:34:39, 112.87s/it]Evaluating commonsenseqa :  62%|██████▏   | 123/200 [3:34:16<2:03:54, 96.56s/it]Evaluating commonsenseqa :  97%|█████████▋| 194/200 [4:32:33<09:12, 92.10s/it]Evaluating commonsenseqa :  68%|██████▊   | 135/200 [2:58:43<1:26:06, 79.48s/it]Evaluating commonsenseqa :  28%|██▊       | 55/200 [1:43:18<4:32:31, 112.77s/it]Evaluating commonsenseqa :  68%|██████▊   | 136/200 [3:00:02<1:24:37, 79.33s/it]Evaluating commonsenseqa :  10%|▉         | 19/200 [43:29<6:58:56, 138.87s/it]Evaluating commonsenseqa :  98%|█████████▊| 195/200 [4:34:06<07:41, 92.29s/it]Evaluating commonsenseqa :  62%|██████▏   | 124/200 [3:36:14<2:10:25, 102.96s/it]Evaluating commonsenseqa :  68%|██████▊   | 137/200 [3:01:21<1:23:24, 79.44s/it]Evaluating commonsenseqa :  28%|██▊       | 56/200 [1:45:08<4:28:54, 112.05s/it]Evaluating commonsenseqa :  98%|█████████▊| 196/200 [4:35:38<06:09, 92.33s/it]Evaluating commonsenseqa :  62%|██████▎   | 125/200 [3:37:57<2:08:53, 103.11s/it]Evaluating commonsenseqa :  10%|█         | 20/200 [45:48<6:57:07, 139.04s/it]Evaluating commonsenseqa :  69%|██████▉   | 138/200 [3:02:42<1:22:20, 79.68s/it]Evaluating commonsenseqa :  98%|█████████▊| 197/200 [4:37:12<04:37, 92.61s/it]Evaluating commonsenseqa :  63%|██████▎   | 126/200 [3:38:57<1:51:07, 90.11s/it] Evaluating commonsenseqa :  28%|██▊       | 57/200 [1:47:02<4:28:00, 112.45s/it]Evaluating commonsenseqa :  70%|██████▉   | 139/200 [3:04:01<1:21:01, 79.70s/it]Evaluating commonsenseqa :  10%|█         | 21/200 [47:31<6:22:59, 128.38s/it]Evaluating commonsenseqa :  99%|█████████▉| 198/200 [4:38:45<03:05, 92.76s/it]Evaluating commonsenseqa :  64%|██████▎   | 127/200 [3:40:37<1:53:19, 93.15s/it]Evaluating commonsenseqa :  29%|██▉       | 58/200 [1:48:53<4:25:23, 112.14s/it]Evaluating commonsenseqa :  64%|██████▍   | 128/200 [3:41:02<1:27:02, 72.53s/it]Evaluating commonsenseqa :  70%|███████   | 140/200 [3:05:22<1:19:53, 79.89s/it]Evaluating commonsenseqa : 100%|█████████▉| 199/200 [4:40:16<01:32, 92.47s/it]Evaluating commonsenseqa :  64%|██████▍   | 129/200 [3:42:05<1:22:29, 69.71s/it]Evaluating commonsenseqa :  11%|█         | 22/200 [49:51<6:30:49, 131.74s/it]Evaluating commonsenseqa :  70%|███████   | 141/200 [3:06:42<1:18:43, 80.06s/it]Evaluating commonsenseqa :  30%|██▉       | 59/200 [1:50:43<4:22:12, 111.58s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [4:41:49<00:00, 92.42s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [4:41:49<00:00, 84.55s/it]
name: commonsenseqa | avg. gen lenth: 235.99 | time: 16910.697227478027s
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10136 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o19-tmathqa-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 19 17 19 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2023-09-20 03:18:06,633] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Evaluating commonsenseqa :  71%|███████   | 142/200 [3:08:01<1:17:09, 79.82s/it]using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o19-tmathqa-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 19
  out_domain_data_name ......... mathqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o19-tmathqa-s1-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 521783.80it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.96s/it]
 > number of parameters: 6738415616
[2023-09-20 03:18:19,468] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.3, git-hash=unknown, git-branch=unknown
[2023-09-20 03:18:19,468] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-09-20 03:18:19,775] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-20 03:18:19,777] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2023-09-20 03:18:19,777] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-20 03:18:19,777] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-20 03:18:19,777] [INFO] [config.py:971:print]   amp_enabled .................. False
[2023-09-20 03:18:19,777] [INFO] [config.py:971:print]   amp_params ................... False
[2023-09-20 03:18:19,777] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-20 03:18:19,777] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2023-09-20 03:18:19,777] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2023-09-20 03:18:19,777] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2023-09-20 03:18:19,777] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2023-09-20 03:18:19,777] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f08adc2eef0>
[2023-09-20 03:18:19,777] [INFO] [config.py:971:print]   communication_data_type ...... None
[2023-09-20 03:18:19,777] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-20 03:18:19,777] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2023-09-20 03:18:19,777] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2023-09-20 03:18:19,777] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-20 03:18:19,777] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2023-09-20 03:18:19,777] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   disable_allgather ............ False
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   dump_state ................... False
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   global_rank .................. 0
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   gradient_clipping ............ 0.0
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 2048
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   loss_scale ................... 0
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   optimizer_name ............... None
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   optimizer_params ............. None
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   pld_enabled .................. False
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   pld_params ................... False
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   scheduler_name ............... None
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   scheduler_params ............. None
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   sparse_attention ............. None
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   train_batch_size ............. 1
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  1
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   world_size ................... 1
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  True
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   zero_enabled ................. False
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-20 03:18:19,778] [INFO] [config.py:971:print]   zero_optimization_stage ...... 0
[2023-09-20 03:18:19,779] [INFO] [config.py:957:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/200 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: what is 12 percent of 80? a ) 11.21, b ) 9.6, c ) 8.66, d ) 12.23, e ) 13.1
Output: b

Input: a and b started a business investing rs. 92,000 and rs 20,000 respectively. in what ratio the profit earned after 2 years be divided between a and b respectively? a ) 9 : 2, b ) 3 : 2, c ) 23 : 5, d ) 18 : 4, e ) 17 : 4
Output: c

Input: a merchant purchased a jacket for $ 60 and then determined a selling price that equalled the purchase price of the jacket plus a markup that was 20 percent of the selling price. during a sale, the merchant discounted the selling price by 20 percent and sold the jacket. what was the merchant ’ s gross profit on this sale? a ) $ 0, b ) $ 3, c ) $ 4, d ) $ 12, e ) $ 15
Output: a

Input: on a two - dimensional coordinate plane, the line q = x ^ 2 - x ^ 3 touches the x - axis in how many places? a ) 0, b ) 1, c ) 2, d ) 3, e ) 4
Output: c

Input: angelo and isabella are both salespersons. in any given week, angelo makes $ 550 in base salary plus 8 percent of the portion of his sales above $ 3,000 for that week. isabella makes 10 percent of her total sales for any given week. for what amount of weekly sales would angelo and isabella earn the same amount of money? a ) 23,500, b ) 15,500, c ) 25,500, d ) 26,500, e ) 27,500
Output: b

Input: find the total number of prime factors in the expression ( 4 ) ^ 11 x ( 7 ) ^ 5 x ( 11 ) ^ 3 a ) 26, b ) 22, c ) 25, d ) 30, e ) 29
Output: d

Input: the length of the bridge, which a train 140 m long and traveling at 45 km / hr can cross in 30 sec is? a ) 235, b ) 240, c ) 245, d ) 250, e ) 255
Output: a

Input: 360 metres long yard, 31 trees are palnted at equal distances, one tree being at each end of the yard. what is the distance between 2 consecutive trees a ) 10, b ) 12, c ) 14, d ) 16, e ) 17
Output: b

Input: a vessel of capacity 45 litres is fully filled with pure milk. nine litres of milk is removed from the vessel and replaced with water. nine litres of the solution thus formed is removed and replaced with water. find the quantity of pure milk in the final milk solution? a ) 28.8, b ) 72.9, c ) 38.3, d ) 78.3, e ) 79.3
Output: a

Input: a certain telescope increases the visual range at a particular location from 90 kilometers to 150 kilometers. by what percent is the visual range increased by using the telescope? a ) 30 %, b ) 33 1 / 2 %, c ) 40 %, d ) 60 %, e ) 66 2 / 3 %
Output: e

Input: a bag contains 6 black and 3 white balls. one ball is drawn at random. what is the probability that the ball drawn is white? a ) 3 / 4, b ) 1 / 3, c ) 1 / 7, d ) 1 / 8, e ) 4 / 3
Output: b

Input: rajat, vikas and abhishek are submitting questions in the ratio 7 : 3 : 2. if total number of questions submitted by them is 24. find the number of questions submitted by vikas. a ) 3, b ) 4, c ) 5, d ) 6, e ) 7
Output: d

Input: at a certain restaurant, the ratio of the number of cooks to the number of waiters is 3 to 8. when 12 more waiters are hired, the ratio of the number of cooks to the number of waiters changes to 1 to 4. how many cooks does the restaurant have? a ) 4, b ) 6, c ) 9, d ) 12, e ) 15
Output: c

Input: if 7 ^ k + 7 ^ k = ( 7 ^ 9 ) ^ ( 7 ^ 9 ) - 7 ^ k, then k =? a ) 11 / 3, b ) 11 / 2, c ) 242, d ) 3 ^ 10, e ) 7 ^ 11 - 1
Output: e

Input: average of 10 matches is 32, how many runs one should should score to increase his average by 4 runs. a ) 70, b ) 76, c ) 78, d ) 80, e ) 88
Output: b

Input: a ’ s speed is 20 / 19 times that of b. if a and b run a race, what part of the length of the race should a give b as a head start, so that the race ends in a dead heat? a ) 1 / 19, b ) 3 / 19, c ) 1 / 10, d ) 1 / 20, e ) 3 / 10
Output: d

Input: the length of a rectangular plot is 10 mtr more than its width. the cost of fencing the plot along its perimeter at the rate of rs. 6.5 mtr is rs. 2210. the perimeter of the plot is? a ) 126, b ) 156, c ) 340, d ) 321, e ) 260
Output: c

Input: if n = 2 ^ 0.1 and n ^ b = 16, b must equal a ) 3 / 80, b ) 3 / 5, c ) 40, d ) 5 / 3, e ) 80 / 3
Output: c

Input: 150 ml of 30 % sulphuric acid was added to approximate 400 ml of 12 % sulphuric acid solution. find the approximate concentration c of the acid in the mixture? a ) 1 / 2, b ) 1 / 3, c ) 1 / 4, d ) 1 / 6, e ) 1 / 5
Output: d

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o19-tmathqa-s1-rFalse-m4096
Evaluating commonsenseqa :  65%|██████▌   | 130/200 [3:44:02<1:38:04, 84.07s/it]Evaluating commonsenseqa :  12%|█▏        | 23/200 [52:07<6:32:35, 133.08s/it]Evaluating commonsenseqa :  30%|███       | 60/200 [1:52:38<4:22:27, 112.48s/it]Evaluating commonsenseqa :  72%|███████▏  | 143/200 [3:09:21<1:15:39, 79.64s/it]Evaluating commonsenseqa :   0%|          | 1/200 [01:29<4:56:16, 89.33s/it]Evaluating commonsenseqa :  30%|███       | 61/200 [1:53:42<3:46:40, 97.84s/it] Evaluating commonsenseqa :  66%|██████▌   | 131/200 [3:45:58<1:47:41, 93.65s/it]Evaluating commonsenseqa :  72%|███████▏  | 144/200 [3:10:40<1:14:13, 79.53s/it]Evaluating commonsenseqa :  12%|█▏        | 24/200 [54:28<6:36:40, 135.23s/it]Evaluating commonsenseqa :   1%|          | 2/200 [02:58<4:53:40, 88.99s/it]Evaluating commonsenseqa :  72%|███████▎  | 145/200 [3:11:59<1:12:53, 79.52s/it]Evaluating commonsenseqa :  31%|███       | 62/200 [1:55:34<3:55:14, 102.28s/it]Evaluating commonsenseqa :  66%|██████▌   | 132/200 [3:47:56<1:54:20, 100.89s/it]Evaluating commonsenseqa :   2%|▏         | 3/200 [04:26<4:50:52, 88.59s/it]Evaluating commonsenseqa :  12%|█▎        | 25/200 [56:44<6:35:18, 135.53s/it]Evaluating commonsenseqa :  73%|███████▎  | 146/200 [3:13:21<1:12:06, 80.12s/it]Evaluating commonsenseqa :  32%|███▏      | 63/200 [1:57:30<4:02:32, 106.22s/it]Evaluating commonsenseqa :   2%|▏         | 4/200 [05:54<4:49:35, 88.65s/it]Evaluating commonsenseqa :  66%|██████▋   | 133/200 [3:49:54<1:58:30, 106.13s/it]Evaluating commonsenseqa :  74%|███████▎  | 147/200 [3:14:41<1:10:38, 79.96s/it]Evaluating commonsenseqa :   2%|▎         | 5/200 [07:23<4:47:52, 88.58s/it]Evaluating commonsenseqa :  13%|█▎        | 26/200 [59:05<6:37:40, 137.13s/it]Evaluating commonsenseqa :  32%|███▏      | 64/200 [1:59:22<4:04:32, 107.89s/it]Evaluating commonsenseqa :  74%|███████▍  | 148/200 [3:16:00<1:09:15, 79.92s/it]Evaluating commonsenseqa :  67%|██████▋   | 134/200 [3:51:50<1:59:45, 108.87s/it]Evaluating commonsenseqa :   3%|▎         | 6/200 [08:23<4:15:33, 79.04s/it]Evaluating commonsenseqa :  32%|███▎      | 65/200 [2:00:38<3:41:11, 98.31s/it] Evaluating commonsenseqa :  74%|███████▍  | 149/200 [3:17:20<1:07:56, 79.93s/it]Evaluating commonsenseqa :  14%|█▎        | 27/200 [1:01:24<6:37:45, 137.95s/it]Evaluating commonsenseqa :   4%|▎         | 7/200 [09:52<4:24:19, 82.17s/it]Evaluating commonsenseqa :  68%|██████▊   | 135/200 [3:53:50<2:01:34, 112.23s/it]Evaluating commonsenseqa :  75%|███████▌  | 150/200 [3:18:39<1:06:24, 79.69s/it]Evaluating commonsenseqa :  33%|███▎      | 66/200 [2:02:28<3:47:58, 102.07s/it]Evaluating commonsenseqa :   4%|▍         | 8/200 [11:21<4:29:42, 84.29s/it]Evaluating commonsenseqa :  76%|███████▌  | 151/200 [3:19:59<1:05:00, 79.61s/it]Evaluating commonsenseqa :  68%|██████▊   | 136/200 [3:55:45<2:00:47, 113.25s/it]Evaluating commonsenseqa :  14%|█▍        | 28/200 [1:03:43<6:35:55, 138.11s/it]Evaluating commonsenseqa :  34%|███▎      | 67/200 [2:04:22<3:53:48, 105.47s/it]Evaluating commonsenseqa :   4%|▍         | 9/200 [12:50<4:32:59, 85.76s/it]Evaluating commonsenseqa :  76%|███████▌  | 152/200 [3:21:18<1:03:37, 79.52s/it]Evaluating commonsenseqa :  68%|██████▊   | 137/200 [3:57:43<2:00:16, 114.55s/it]Evaluating commonsenseqa :   5%|▌         | 10/200 [14:17<4:33:04, 86.24s/it]Evaluating commonsenseqa :  34%|███▍      | 68/200 [2:06:14<3:56:16, 107.40s/it]Evaluating commonsenseqa :  76%|███████▋  | 153/200 [3:22:39<1:02:42, 80.06s/it]Evaluating commonsenseqa :  14%|█▍        | 29/200 [1:06:05<6:36:44, 139.21s/it]Evaluating commonsenseqa :  69%|██████▉   | 138/200 [3:58:46<1:42:22, 99.08s/it] Evaluating commonsenseqa :  77%|███████▋  | 154/200 [3:24:00<1:01:33, 80.30s/it]Evaluating commonsenseqa :   6%|▌         | 11/200 [15:46<4:34:24, 87.11s/it]Evaluating commonsenseqa :  34%|███▍      | 69/200 [2:08:08<3:58:55, 109.43s/it]Evaluating commonsenseqa :  15%|█▌        | 30/200 [1:08:24<6:34:34, 139.26s/it]Evaluating commonsenseqa :  70%|██████▉   | 139/200 [4:00:44<1:46:29, 104.74s/it]Evaluating commonsenseqa :  78%|███████▊  | 155/200 [3:25:21<1:00:22, 80.50s/it]Evaluating commonsenseqa :   6%|▌         | 12/200 [17:15<4:34:25, 87.58s/it]Evaluating commonsenseqa :  35%|███▌      | 70/200 [2:10:02<4:00:19, 110.92s/it]Evaluating commonsenseqa :  78%|███████▊  | 156/200 [3:26:43<59:15, 80.81s/it]  Evaluating commonsenseqa :   6%|▋         | 13/200 [18:43<4:33:47, 87.85s/it]Evaluating commonsenseqa :  70%|███████   | 140/200 [4:02:43<1:48:57, 108.96s/it]Evaluating commonsenseqa :  16%|█▌        | 31/200 [1:10:45<6:33:17, 139.63s/it]Evaluating commonsenseqa :  78%|███████▊  | 157/200 [3:28:04<57:54, 80.80s/it]Evaluating commonsenseqa :  36%|███▌      | 71/200 [2:11:56<4:00:32, 111.88s/it]Evaluating commonsenseqa :   7%|▋         | 14/200 [20:14<4:34:33, 88.57s/it]Evaluating commonsenseqa :  16%|█▌        | 32/200 [1:12:06<5:41:51, 122.09s/it]Evaluating commonsenseqa :  70%|███████   | 141/200 [4:04:35<1:48:05, 109.92s/it]Evaluating commonsenseqa :  79%|███████▉  | 158/200 [3:29:25<56:37, 80.89s/it]Evaluating commonsenseqa :   8%|▊         | 15/200 [21:41<4:32:11, 88.28s/it]Evaluating commonsenseqa :  36%|███▌      | 72/200 [2:13:49<3:59:27, 112.25s/it]Evaluating commonsenseqa :  16%|█▋        | 33/200 [1:13:57<5:30:59, 118.92s/it]Evaluating commonsenseqa :  80%|███████▉  | 159/200 [3:30:44<54:57, 80.42s/it]Evaluating commonsenseqa :  71%|███████   | 142/200 [4:06:30<1:47:43, 111.44s/it]Evaluating commonsenseqa :   8%|▊         | 16/200 [22:59<4:21:20, 85.22s/it]Evaluating commonsenseqa :  80%|████████  | 160/200 [3:32:05<53:45, 80.64s/it]Evaluating commonsenseqa :  36%|███▋      | 73/200 [2:15:44<3:58:51, 112.85s/it]Evaluating commonsenseqa :   8%|▊         | 17/200 [23:55<3:52:49, 76.34s/it]Evaluating commonsenseqa :  72%|███████▏  | 143/200 [4:08:28<1:47:49, 113.49s/it]Evaluating commonsenseqa :  17%|█▋        | 34/200 [1:16:15<5:44:40, 124.58s/it]Evaluating commonsenseqa :  80%|████████  | 161/200 [3:33:26<52:21, 80.55s/it]Evaluating commonsenseqa :   9%|▉         | 18/200 [25:24<4:02:42, 80.01s/it]Evaluating commonsenseqa :  37%|███▋      | 74/200 [2:17:36<3:56:24, 112.57s/it]Evaluating commonsenseqa :  72%|███████▏  | 144/200 [4:10:26<1:47:07, 114.78s/it]Evaluating commonsenseqa :  81%|████████  | 162/200 [3:34:47<51:06, 80.69s/it]Evaluating commonsenseqa :  10%|▉         | 19/200 [26:53<4:10:01, 82.88s/it]Evaluating commonsenseqa :  18%|█▊        | 35/200 [1:18:36<5:56:28, 129.63s/it]Evaluating commonsenseqa :  38%|███▊      | 75/200 [2:19:29<3:55:09, 112.87s/it]Evaluating commonsenseqa :  82%|████████▏ | 163/200 [3:36:06<49:35, 80.42s/it]Evaluating commonsenseqa :  10%|█         | 20/200 [28:23<4:14:54, 84.97s/it]Evaluating commonsenseqa :  72%|███████▎  | 145/200 [4:12:21<1:45:23, 114.98s/it]Evaluating commonsenseqa :  73%|███████▎  | 146/200 [4:12:55<1:21:27, 90.51s/it] Evaluating commonsenseqa :  10%|█         | 21/200 [29:05<3:35:07, 72.11s/it]Evaluating commonsenseqa :  82%|████████▏ | 164/200 [3:37:27<48:13, 80.38s/it]Evaluating commonsenseqa :  18%|█▊        | 36/200 [1:20:57<6:03:05, 132.84s/it]Evaluating commonsenseqa :  38%|███▊      | 76/200 [2:21:23<3:54:04, 113.26s/it]Evaluating commonsenseqa :  11%|█         | 22/200 [30:00<3:18:56, 67.06s/it]Evaluating commonsenseqa :  82%|████████▎ | 165/200 [3:38:47<46:57, 80.51s/it]Evaluating commonsenseqa :  74%|███████▎  | 147/200 [4:14:50<1:26:26, 97.86s/it]Evaluating commonsenseqa :  38%|███▊      | 77/200 [2:23:18<3:52:44, 113.54s/it]Evaluating commonsenseqa :  12%|█▏        | 23/200 [31:29<3:37:03, 73.58s/it]Evaluating commonsenseqa :  18%|█▊        | 37/200 [1:23:18<6:07:23, 135.23s/it]Evaluating commonsenseqa :  83%|████████▎ | 166/200 [3:40:07<45:26, 80.19s/it]Evaluating commonsenseqa :  74%|███████▍  | 148/200 [4:16:32<1:25:52, 99.09s/it]Evaluating commonsenseqa :  12%|█▏        | 24/200 [32:58<3:49:26, 78.22s/it]Evaluating commonsenseqa :  74%|███████▍  | 149/200 [4:16:56<1:05:10, 76.68s/it]Evaluating commonsenseqa :  84%|████████▎ | 167/200 [3:41:27<44:07, 80.24s/it]Evaluating commonsenseqa :  39%|███▉      | 78/200 [2:25:11<3:50:41, 113.46s/it]Evaluating commonsenseqa :  19%|█▉        | 38/200 [1:25:38<6:09:35, 136.89s/it]Evaluating commonsenseqa :  12%|█▎        | 25/200 [34:25<3:55:47, 80.84s/it]Evaluating commonsenseqa :  84%|████████▍ | 168/200 [3:42:48<42:52, 80.39s/it]Evaluating commonsenseqa :  75%|███████▌  | 150/200 [4:18:53<1:13:59, 88.80s/it]Evaluating commonsenseqa :  40%|███▉      | 79/200 [2:27:01<3:47:02, 112.58s/it]Evaluating commonsenseqa :  13%|█▎        | 26/200 [35:52<3:59:56, 82.74s/it]Evaluating commonsenseqa :  84%|████████▍ | 169/200 [3:44:09<41:35, 80.49s/it]Evaluating commonsenseqa :  20%|█▉        | 39/200 [1:27:58<6:09:38, 137.75s/it]Evaluating commonsenseqa :  76%|███████▌  | 151/200 [4:20:51<1:19:36, 97.48s/it]Evaluating commonsenseqa :  85%|████████▌ | 170/200 [3:45:14<37:59, 75.98s/it]Evaluating commonsenseqa :  40%|████      | 80/200 [2:28:54<3:45:11, 112.60s/it]Evaluating commonsenseqa :  14%|█▎        | 27/200 [37:21<4:04:02, 84.64s/it]Evaluating commonsenseqa :  86%|████████▌ | 171/200 [3:46:34<37:15, 77.10s/it]Evaluating commonsenseqa :  20%|██        | 40/200 [1:30:16<6:07:01, 137.64s/it]Evaluating commonsenseqa :  76%|███████▌  | 152/200 [4:22:46<1:22:10, 102.72s/it]Evaluating commonsenseqa :  14%|█▍        | 28/200 [38:50<4:05:59, 85.81s/it]Evaluating commonsenseqa :  40%|████      | 81/200 [2:30:47<3:43:27, 112.67s/it]Evaluating commonsenseqa :  86%|████████▌ | 172/200 [3:47:53<36:14, 77.66s/it]Evaluating commonsenseqa :  14%|█▍        | 29/200 [40:20<4:08:07, 87.06s/it]Evaluating commonsenseqa :  76%|███████▋  | 153/200 [4:24:41<1:23:17, 106.33s/it]Evaluating commonsenseqa :  41%|████      | 82/200 [2:32:35<3:38:37, 111.17s/it]Evaluating commonsenseqa :  20%|██        | 41/200 [1:32:36<6:06:58, 138.48s/it]Evaluating commonsenseqa :  86%|████████▋ | 173/200 [3:49:13<35:17, 78.41s/it]Evaluating commonsenseqa :  77%|███████▋  | 154/200 [4:25:29<1:08:08, 88.89s/it] Evaluating commonsenseqa :  15%|█▌        | 30/200 [41:50<4:09:17, 87.98s/it]Evaluating commonsenseqa :  87%|████████▋ | 174/200 [3:50:32<34:02, 78.55s/it]Evaluating commonsenseqa :  42%|████▏     | 83/200 [2:34:29<3:38:36, 112.10s/it]Evaluating commonsenseqa :  21%|██        | 42/200 [1:34:55<6:04:53, 138.57s/it]Evaluating commonsenseqa :  16%|█▌        | 31/200 [43:18<4:08:07, 88.09s/it]Evaluating commonsenseqa :  78%|███████▊  | 155/200 [4:27:28<1:13:23, 97.85s/it]Evaluating commonsenseqa :  88%|████████▊ | 175/200 [3:51:53<33:02, 79.31s/it]Evaluating commonsenseqa :  42%|████▏     | 84/200 [2:36:20<3:36:14, 111.85s/it]Evaluating commonsenseqa :  16%|█▌        | 32/200 [44:47<4:07:20, 88.34s/it]Evaluating commonsenseqa :  88%|████████▊ | 176/200 [3:53:13<31:51, 79.65s/it]Evaluating commonsenseqa :  78%|███████▊  | 156/200 [4:29:23<1:15:38, 103.14s/it]Evaluating commonsenseqa :  22%|██▏       | 43/200 [1:37:17<6:05:31, 139.69s/it]Evaluating commonsenseqa :  16%|█▋        | 33/200 [45:45<3:40:13, 79.12s/it]Evaluating commonsenseqa :  88%|████████▊ | 177/200 [3:54:34<30:35, 79.82s/it]Evaluating commonsenseqa :  42%|████▎     | 85/200 [2:38:12<3:34:41, 112.02s/it]Evaluating commonsenseqa :  17%|█▋        | 34/200 [47:09<3:42:56, 80.58s/it]Evaluating commonsenseqa :  78%|███████▊  | 157/200 [4:31:18<1:16:27, 106.69s/it]Evaluating commonsenseqa :  89%|████████▉ | 178/200 [3:55:55<29:28, 80.36s/it]Evaluating commonsenseqa :  22%|██▏       | 44/200 [1:39:39<6:04:38, 140.25s/it]Evaluating commonsenseqa :  18%|█▊        | 35/200 [48:07<3:23:04, 73.85s/it]Evaluating commonsenseqa :  43%|████▎     | 86/200 [2:40:05<3:32:58, 112.09s/it]Evaluating commonsenseqa :  90%|████████▉ | 179/200 [3:57:16<28:11, 80.56s/it]Evaluating commonsenseqa :  79%|███████▉  | 158/200 [4:33:14<1:16:38, 109.49s/it]Evaluating commonsenseqa :  18%|█▊        | 36/200 [49:37<3:34:56, 78.63s/it]Evaluating commonsenseqa :  22%|██▎       | 45/200 [1:41:40<5:47:52, 134.66s/it]Evaluating commonsenseqa :  44%|████▎     | 87/200 [2:41:57<3:31:23, 112.25s/it]Evaluating commonsenseqa :  90%|█████████ | 180/200 [3:58:35<26:40, 80.04s/it]Evaluating commonsenseqa :  18%|█▊        | 37/200 [51:07<3:42:53, 82.05s/it]Evaluating commonsenseqa :  80%|███████▉  | 159/200 [4:35:04<1:14:56, 109.66s/it]Evaluating commonsenseqa :  90%|█████████ | 181/200 [3:59:55<25:17, 79.86s/it]Evaluating commonsenseqa :  44%|████▍     | 88/200 [2:43:49<3:29:03, 112.00s/it]Evaluating commonsenseqa :  23%|██▎       | 46/200 [1:43:59<5:48:58, 135.96s/it]Evaluating commonsenseqa :  80%|████████  | 160/200 [4:36:20<1:06:24, 99.61s/it] Evaluating commonsenseqa :  19%|█▉        | 38/200 [52:35<3:46:34, 83.92s/it]Evaluating commonsenseqa :  91%|█████████ | 182/200 [4:01:15<23:58, 79.90s/it]Evaluating commonsenseqa :  44%|████▍     | 89/200 [2:45:42<3:27:43, 112.28s/it]Evaluating commonsenseqa :  20%|█▉        | 39/200 [54:03<3:48:35, 85.19s/it]Evaluating commonsenseqa :  92%|█████████▏| 183/200 [4:02:35<22:39, 79.98s/it]Evaluating commonsenseqa :  80%|████████  | 161/200 [4:38:20<1:08:39, 105.64s/it]Evaluating commonsenseqa :  24%|██▎       | 47/200 [1:46:20<5:50:05, 137.29s/it]Evaluating commonsenseqa :  81%|████████  | 162/200 [4:38:49<52:18, 82.59s/it]   Evaluating commonsenseqa :  20%|██        | 40/200 [54:59<3:23:56, 76.48s/it]Evaluating commonsenseqa :  92%|█████████▏| 184/200 [4:03:55<21:21, 80.09s/it]Evaluating commonsenseqa :  45%|████▌     | 90/200 [2:47:35<3:26:27, 112.61s/it]Evaluating commonsenseqa :  20%|██        | 41/200 [56:29<3:33:21, 80.51s/it]Evaluating commonsenseqa :  82%|████████▏ | 163/200 [4:40:44<56:57, 92.35s/it]Evaluating commonsenseqa :  92%|█████████▎| 185/200 [4:05:14<19:57, 79.82s/it]Evaluating commonsenseqa :  24%|██▍       | 48/200 [1:48:38<5:48:58, 137.76s/it]Evaluating commonsenseqa :  21%|██        | 42/200 [57:12<3:02:04, 69.14s/it]Evaluating commonsenseqa :  46%|████▌     | 91/200 [2:49:27<3:24:25, 112.52s/it]Evaluating commonsenseqa :  82%|████████▏ | 164/200 [4:41:45<49:43, 82.89s/it]Evaluating commonsenseqa :  93%|█████████▎| 186/200 [4:06:35<18:39, 79.98s/it]Evaluating commonsenseqa :  22%|██▏       | 43/200 [58:41<3:16:09, 74.97s/it]Evaluating commonsenseqa :  24%|██▍       | 49/200 [1:50:57<5:47:20, 138.01s/it]Evaluating commonsenseqa :  46%|████▌     | 92/200 [2:51:21<3:23:12, 112.89s/it]Evaluating commonsenseqa :  94%|█████████▎| 187/200 [4:07:54<17:19, 79.93s/it]Evaluating commonsenseqa :  82%|████████▎ | 165/200 [4:43:41<54:08, 92.82s/it]Evaluating commonsenseqa :  22%|██▏       | 44/200 [1:00:10<3:26:20, 79.36s/it]Evaluating commonsenseqa :  94%|█████████▍| 188/200 [4:09:14<15:59, 79.95s/it]Evaluating commonsenseqa :  83%|████████▎ | 166/200 [4:45:20<53:39, 94.69s/it]Evaluating commonsenseqa :  46%|████▋     | 93/200 [2:53:14<3:21:04, 112.76s/it]Evaluating commonsenseqa :  25%|██▌       | 50/200 [1:53:17<5:46:11, 138.48s/it]Evaluating commonsenseqa :  22%|██▎       | 45/200 [1:01:38<3:31:42, 81.95s/it]Evaluating commonsenseqa :  94%|█████████▍| 189/200 [4:10:35<14:40, 80.07s/it]Evaluating commonsenseqa :  23%|██▎       | 46/200 [1:03:08<3:36:27, 84.33s/it]Evaluating commonsenseqa :  47%|████▋     | 94/200 [2:55:06<3:18:53, 112.58s/it]Evaluating commonsenseqa :  84%|████████▎ | 167/200 [4:47:18<55:57, 101.73s/it]Evaluating commonsenseqa :  95%|█████████▌| 190/200 [4:11:54<13:17, 79.79s/it]Evaluating commonsenseqa :  26%|██▌       | 51/200 [1:55:41<5:48:18, 140.26s/it]Evaluating commonsenseqa :  24%|██▎       | 47/200 [1:04:17<3:23:09, 79.67s/it]Evaluating commonsenseqa :  96%|█████████▌| 191/200 [4:13:14<12:00, 80.03s/it]Evaluating commonsenseqa :  48%|████▊     | 95/200 [2:57:02<3:18:59, 113.71s/it]Evaluating commonsenseqa :  84%|████████▍ | 168/200 [4:49:17<57:04, 107.02s/it]Evaluating commonsenseqa :  24%|██▍       | 48/200 [1:05:46<3:29:23, 82.66s/it]Evaluating commonsenseqa :  96%|█████████▌| 192/200 [4:14:36<10:44, 80.50s/it]Evaluating commonsenseqa :  26%|██▌       | 52/200 [1:58:02<5:46:39, 140.54s/it]Evaluating commonsenseqa :  48%|████▊     | 96/200 [2:58:57<3:17:32, 113.96s/it]Evaluating commonsenseqa :  24%|██▍       | 49/200 [1:07:16<3:33:08, 84.69s/it]Evaluating commonsenseqa :  84%|████████▍ | 169/200 [4:51:15<56:53, 110.12s/it]Evaluating commonsenseqa :  96%|█████████▋| 193/200 [4:15:57<09:24, 80.59s/it]Evaluating commonsenseqa :  85%|████████▌ | 170/200 [4:52:26<49:11, 98.40s/it] Evaluating commonsenseqa :  25%|██▌       | 50/200 [1:08:45<3:34:53, 85.96s/it]Evaluating commonsenseqa :  26%|██▋       | 53/200 [2:00:24<5:45:06, 140.86s/it]Evaluating commonsenseqa :  48%|████▊     | 97/200 [3:00:49<3:15:03, 113.62s/it]Evaluating commonsenseqa :  97%|█████████▋| 194/200 [4:17:18<08:03, 80.64s/it]Evaluating commonsenseqa :  86%|████████▌ | 171/200 [4:53:28<42:15, 87.44s/it]Evaluating commonsenseqa :  26%|██▌       | 51/200 [1:10:14<3:35:48, 86.90s/it]Evaluating commonsenseqa :  98%|█████████▊| 195/200 [4:18:37<06:41, 80.30s/it]Evaluating commonsenseqa :  49%|████▉     | 98/200 [3:02:43<3:12:53, 113.47s/it]Evaluating commonsenseqa :  27%|██▋       | 54/200 [2:02:42<5:40:36, 139.98s/it]Evaluating commonsenseqa :  86%|████████▌ | 172/200 [4:55:26<45:04, 96.60s/it]Evaluating commonsenseqa :  98%|█████████▊| 196/200 [4:19:56<05:19, 79.89s/it]Evaluating commonsenseqa :  26%|██▌       | 52/200 [1:11:42<3:35:30, 87.37s/it]Evaluating commonsenseqa :  50%|████▉     | 99/200 [3:04:35<3:10:40, 113.27s/it]Evaluating commonsenseqa :  98%|█████████▊| 197/200 [4:21:16<03:59, 79.84s/it]Evaluating commonsenseqa :  26%|██▋       | 53/200 [1:13:13<3:36:04, 88.19s/it]Evaluating commonsenseqa :  28%|██▊       | 55/200 [2:05:02<5:38:42, 140.15s/it]Evaluating commonsenseqa :  86%|████████▋ | 173/200 [4:57:21<46:03, 102.35s/it]Evaluating commonsenseqa :  99%|█████████▉| 198/200 [4:22:36<02:39, 79.91s/it]Evaluating commonsenseqa :  87%|████████▋ | 174/200 [4:58:23<39:03, 90.12s/it] Evaluating commonsenseqa :  27%|██▋       | 54/200 [1:14:39<3:33:06, 87.58s/it]Evaluating commonsenseqa :  50%|█████     | 100/200 [3:06:28<3:08:33, 113.14s/it]Evaluating commonsenseqa : 100%|█████████▉| 199/200 [4:23:56<01:19, 79.88s/it]Evaluating commonsenseqa :  28%|██▊       | 56/200 [2:07:23<5:36:42, 140.30s/it]Evaluating commonsenseqa :  88%|████████▊ | 175/200 [4:59:44<36:25, 87.44s/it]Evaluating commonsenseqa :  28%|██▊       | 55/200 [1:16:07<3:32:21, 87.87s/it]Evaluating commonsenseqa :  50%|█████     | 101/200 [3:08:21<3:06:42, 113.15s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [4:25:15<00:00, 79.59s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [4:25:15<00:00, 79.58s/it]
name: commonsenseqa | avg. gen lenth: 366.854 | time: 15919.208696126938s
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10140 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o15-tmathqa-s30-rTrue --seed 30 --max-prompt-length 4096 --rationales --num-out-domain 15 13 15 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2023-09-20 04:35:30,737] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o15-tmathqa-s30-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 15
  out_domain_data_name ......... mathqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o15-tmathqa-s30-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 221938.81it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.31s/it]
 > number of parameters: 6738415616
[2023-09-20 04:35:47,635] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.3, git-hash=unknown, git-branch=unknown
[2023-09-20 04:35:47,635] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-09-20 04:35:48,054] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-20 04:35:48,056] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2023-09-20 04:35:48,056] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-20 04:35:48,056] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-20 04:35:48,056] [INFO] [config.py:971:print]   amp_enabled .................. False
[2023-09-20 04:35:48,056] [INFO] [config.py:971:print]   amp_params ................... False
[2023-09-20 04:35:48,057] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-20 04:35:48,057] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2023-09-20 04:35:48,057] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2023-09-20 04:35:48,057] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2023-09-20 04:35:48,057] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2023-09-20 04:35:48,057] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f4670592da0>
[2023-09-20 04:35:48,057] [INFO] [config.py:971:print]   communication_data_type ...... None
[2023-09-20 04:35:48,057] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-20 04:35:48,057] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2023-09-20 04:35:48,057] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2023-09-20 04:35:48,057] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-20 04:35:48,057] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2023-09-20 04:35:48,057] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2023-09-20 04:35:48,057] [INFO] [config.py:971:print]   disable_allgather ............ False
[2023-09-20 04:35:48,057] [INFO] [config.py:971:print]   dump_state ................... False
[2023-09-20 04:35:48,057] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-20 04:35:48,057] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2023-09-20 04:35:48,057] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-20 04:35:48,057] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-20 04:35:48,057] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2023-09-20 04:35:48,057] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2023-09-20 04:35:48,057] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2023-09-20 04:35:48,057] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2023-09-20 04:35:48,057] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2023-09-20 04:35:48,057] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2023-09-20 04:35:48,057] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-20 04:35:48,057] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   global_rank .................. 0
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   gradient_clipping ............ 0.0
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 2048
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   loss_scale ................... 0
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   optimizer_name ............... None
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   optimizer_params ............. None
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   pld_enabled .................. False
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   pld_params ................... False
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   scheduler_name ............... None
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   scheduler_params ............. None
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   sparse_attention ............. None
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   train_batch_size ............. 1
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  1
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   world_size ................... 1
[2023-09-20 04:35:48,058] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  True
[2023-09-20 04:35:48,059] [INFO] [config.py:971:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2023-09-20 04:35:48,059] [INFO] [config.py:971:print]   zero_enabled ................. False
[2023-09-20 04:35:48,059] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-20 04:35:48,059] [INFO] [config.py:971:print]   zero_optimization_stage ...... 0
[2023-09-20 04:35:48,059] [INFO] [config.py:957:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/200 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: the mean of 30 values was 140. it was detected on rechecking that one value 145 was wrongly copied as 135 for the computation of the mean. find the correct mean. a ) 151, b ) 140.33, c ) 152, d ) 148, e ) none of the above
Output: "corrected mean = 140 × 30 − 135 + 145 / 30 = 4200 − 135 + 145 / 30 = 4210 / 30 = 140.33 answer b"
So the final answer is b

Input: the measurement of a rectangular box with lid is 25 cmx 24 cmx 18 cm. find the volume of the largest sphere that can be inscribed in the box ( in terms of π cm 3 ). ( hint : the lowest measure of rectangular box represents the diameter of the largest sphere ) a ) 288, b ) 2302, c ) 2304, d ) 8640, e ) 964
Output: "d = 24, r = 12 ; volume of the largest sphere = 4 / 3 π r 3 = 4 / 3 * π * 12 * 12 * 12 = 2304 π cm 3 answer : c"
So the final answer is c

Input: a certain fraction has the same ratio to 1 / 33, as 3 / 4 does to 7 / 11. what is this certain fraction? a ) 1 / 14, b ) 1 / 18, c ) 1 / 21, d ) 1 / 25, e ) 1 / 28
Output: "x / ( 1 / 33 ) = ( 3 / 4 ) / ( 7 / 11 ) x = 3 * 11 * 1 / 33 * 4 * 7 = 1 / 28 the answer is e."
So the final answer is e

Input: what is the sum of all remainders obtained when the first 110 natural numbers are divided by 9? a ) 397, b ) 401, c ) 403, d ) 405, e ) 399
Output: "a positive integer can give only the following 9 remainders when divided by 9 : 1, 2, 3, 4, 5, 6, 7, 8, and 0. 1 divided by 9 gives the remainder of 1 ; 2 divided by 9 gives the remainder of 2 ;... 8 divided by 9 gives the remainder of 8 ; 9 divided by 9 gives the remainder of 0. we'll have 11 such blocks, since 99 / 9 = 11. the last will be : 91 divided by 9 gives the remainder of 1 ; 92 divided by 9 gives the remainder of 2 ;... 98 divided by 9 gives the remainder of 8 ; 99 divided by 9 gives the remainder of 0. the last number, 100, gives the remainder of 1 when divided by 9, thus the sum of all remainders will be : 11 ( 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 0 ) + 1 = 403. answer : c."
So the final answer is c

Input: a ’ s speed is 20 / 15 times that of b. if a and b run a race, what part of the length of the race should a give b as a head start, so that the race ends in a dead heat? a ) 1 / 17, b ) 3 / 17, c ) 1 / 10, d ) 5 / 20, e ) 3 / 10
Output: "we have the ratio of a ’ s speed and b ’ s speed. this means, we know how much distance a covers compared with b in the same time. this is what the beginning of the race will look like : ( start ) a _________ b ______________________________ if a covers 20 meters, b covers 15 meters in that time. so if the race is 20 meters long, when a reaches the finish line, b would be 5 meters behind him. if we want the race to end in a dead heat, we want b to be at the finish line too at the same time. this means b should get a head start of 5 meters so that he doesn ’ t need to cover that. in that case, the time required by a ( to cover 20 meters ) would be the same as the time required by b ( to cover 15 meters ) to reach the finish line. so b should get a head start of 5 / 20 th of the race. answer ( d )"
So the final answer is d

Input: find the average of all the numbers between 6 and 34 which are divisible by 7. a ) 18, b ) 20, c ) 17.5, d ) 30, e ) 32
Output: "solution average = ( 7 + 14 + 21 + 28 ) / 4 ) = 70 / 4 = 17.5. answer c"
So the final answer is c

Input: instead of multiplying a number by 5, the number is divided by 10. what is the percentage of error obtained? a ) 96 %, b ) 98 %, c ) 95 %, d ) 97 %, e ) 96 %
Output: "let the number be x the right number is 5 x the wrong number is x / 10 error is ( 5 x - x / 10 ) = 49 x / 10 percentage of error is ( ( 49 x / 10 ) / 5 x ) * 100 = 98 % answer : b"
So the final answer is b

Input: by selling an article at rs. 150, a profit of 25 % is made. find its cost price? a ) s. 486, b ) s. 455, c ) s. 487, d ) s. 120, e ) s. 489
Output: "sp = 150 cp = ( sp ) * [ 100 / ( 100 + p ) ] = 150 * [ 100 / ( 100 + 25 ) ] = 150 * [ 100 / 125 ] = rs. 120 answer : d"
So the final answer is d

Input: if 1 = 6, 2 = 12, 3 = 18, 4 = 24, 5 = 30, then 6 =? a ) 5, b ) 3, c ) 1, d ) 7, e ) 9
Output: solution : 1 as stated 1 = 6 = > 6 = 1 answer c
So the final answer is c

Input: 62 small identical cubes are used to form a large cube. how many more cubes are needed to add one top layer of small cube all over the surface of the large cube? a ) 64, b ) 128, c ) 152, d ) 154, e ) 256
Output: "62 small cube will make a large cube with 4 cubes in each line i. e. adding one layer will require one cube at each end and hence new cube will have 6 cubes in each line. total number of small cubes in new cube = 6 ^ 3 = 216 extra cube required = 216 - 62 = 154 hence, d is the answer."
So the final answer is d

Input: a boat running upstream takes 640 min to cover a certain distance, while it takes 280 min to cover the same distance running down stream. what is the ratio between the speed of the boat and speed of water current respectively? a ) 23 : 7, b ) 22 : 9, c ) 23 : 8, d ) 23 : 9, e ) 23 : 11
Output: let the speed of the boat = x and speed of the current = y relative speed in upstream = x - y and in downstream = x + y let the distance'd'is to be covered in downstream and upstream, then time taken in upstream = d / ( x - y ) = 640 or d = 640 ( x - y ) - - - - ( i ) and time taken in downstream = d / ( x + y ) = 280 or d = 280 ( x + y ) - - - - ( ii ) comparing ( i ) & ( ii ), 640 ( x - y ) = 280 ( x + y ) = > 16 ( x - y ) = 7 ( x + y ) = > 16 x - 16 y = 7 x - 7 y = > 9 x = 23 y = > x / y = 23 / 9 answer : d
So the final answer is d

Input: there are 2 positive integers x and y. what is the probability that x + y is odd? a ) 1 / 4, b ) 1 / 2, c ) 1 / 3, d ) 1 / 5, e ) 1 / 9
Output: explanation : the addition of two integer results in an odd number only if any one of the integers is an odd number. the probability of an odd among the two integer is 1 / 2. hence, the required probability is 1 / 2. answer : b
So the final answer is b

Input: two numbers have a h. c. f of 9 and a product of two numbers is 1800. find the l. c. m of the two numbers? a ) 200, b ) 150, c ) 160, d ) 170, e ) 180
Output: "l. c. m of two numbers is given by ( product of the two numbers ) / ( h. c. f of the two numbers ) = 1800 / 9 = 200. answer : a"
So the final answer is a

Input: a metallic sheet is of rectangular shape with dimensions 48 m x 36 m. from each of its corners, a square is cut off so as to make an open box. if the length of the square is 8 m, the volume of the box ( in m 3 ) is a ) 3220, b ) 4830, c ) 5120, d ) 6420, e ) none
Output: "solution clearly, l = ( 48 - 16 ) m = 32 m ‹ = › b = ( 36 - 16 ) m = 20 m, ‹ = › h = 8 m.. volume of the box = ( 32 x 20 x 8 ) m 3 = 5120 m 3. answer c"
So the final answer is c

Input: amar takes as much time in running 24 meters as a car takes in covering 60 meters. what will be the distance covered by amar during the time the car covers 2.2 km? a ) 700 m, b ) 500 m, c ) 870 m, d ) 880 m, e ) 840 m
Output: "distance covered by amar = 24 / 60 ( 2.2 km ) = 2 / 5 ( 2200 ) = 880 m answer : d"
So the final answer is d

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o15-tmathqa-s30-rTrue-m4096
Evaluating commonsenseqa :  28%|██▊       | 56/200 [1:17:32<3:28:30, 86.88s/it]Evaluating commonsenseqa :  88%|████████▊ | 176/200 [5:01:40<38:25, 96.05s/it]Evaluating commonsenseqa :  28%|██▊       | 57/200 [2:09:43<5:34:11, 140.22s/it]Evaluating commonsenseqa :  28%|██▊       | 57/200 [1:18:20<2:59:46, 75.43s/it]Evaluating commonsenseqa :  51%|█████     | 102/200 [3:10:18<3:06:39, 114.28s/it]Evaluating commonsenseqa :   0%|          | 1/200 [01:15<4:10:18, 75.47s/it]Evaluating commonsenseqa :  29%|██▉       | 58/200 [2:10:41<4:33:11, 115.43s/it]Evaluating commonsenseqa :  88%|████████▊ | 177/200 [5:03:38<39:18, 102.54s/it]Evaluating commonsenseqa :  29%|██▉       | 58/200 [1:19:49<3:07:51, 79.37s/it]Evaluating commonsenseqa :   1%|          | 2/200 [02:29<4:07:07, 74.89s/it]Evaluating commonsenseqa :  52%|█████▏    | 103/200 [3:12:13<3:04:47, 114.30s/it]Evaluating commonsenseqa :  89%|████████▉ | 178/200 [5:04:30<32:03, 87.43s/it] Evaluating commonsenseqa :  30%|██▉       | 59/200 [2:12:21<4:20:28, 110.84s/it]Evaluating commonsenseqa :   2%|▏         | 3/200 [03:45<4:06:16, 75.01s/it]Evaluating commonsenseqa :  30%|██▉       | 59/200 [1:21:16<3:12:03, 81.73s/it]Evaluating commonsenseqa :  52%|█████▏    | 104/200 [3:14:03<3:00:56, 113.09s/it]Evaluating commonsenseqa :  90%|████████▉ | 179/200 [5:06:21<33:06, 94.62s/it]Evaluating commonsenseqa :   2%|▏         | 4/200 [04:59<4:04:34, 74.87s/it]Evaluating commonsenseqa :  30%|███       | 60/200 [1:22:45<3:15:50, 83.93s/it]Evaluating commonsenseqa :  30%|███       | 60/200 [2:14:44<4:41:12, 120.52s/it]Evaluating commonsenseqa :  90%|█████████ | 180/200 [5:07:36<29:32, 88.64s/it]Evaluating commonsenseqa :   2%|▎         | 5/200 [06:14<4:03:42, 74.99s/it]Evaluating commonsenseqa :  52%|█████▎    | 105/200 [3:15:53<2:57:43, 112.25s/it]Evaluating commonsenseqa :  30%|███       | 61/200 [1:24:14<3:17:46, 85.37s/it]Evaluating commonsenseqa :   3%|▎         | 6/200 [07:30<4:02:51, 75.11s/it]Evaluating commonsenseqa :  30%|███       | 61/200 [2:17:04<4:52:59, 126.47s/it]Evaluating commonsenseqa :  90%|█████████ | 181/200 [5:09:32<30:40, 96.86s/it]Evaluating commonsenseqa :  31%|███       | 62/200 [1:25:43<3:18:36, 86.35s/it]Evaluating commonsenseqa :  53%|█████▎    | 106/200 [3:17:46<2:55:57, 112.31s/it]Evaluating commonsenseqa :   4%|▎         | 7/200 [08:44<4:00:35, 74.79s/it]Evaluating commonsenseqa :  32%|███▏      | 63/200 [1:26:58<3:09:28, 82.98s/it]Evaluating commonsenseqa :   4%|▍         | 8/200 [09:59<3:59:44, 74.92s/it]Evaluating commonsenseqa :  91%|█████████ | 182/200 [5:11:28<30:43, 102.44s/it]Evaluating commonsenseqa :  31%|███       | 62/200 [2:19:25<5:00:26, 130.63s/it]Evaluating commonsenseqa :  54%|█████▎    | 107/200 [3:19:39<2:54:22, 112.50s/it]Evaluating commonsenseqa :  32%|███▏      | 64/200 [1:28:27<3:12:25, 84.89s/it]Evaluating commonsenseqa :   4%|▍         | 9/200 [11:14<3:58:50, 75.03s/it]Evaluating commonsenseqa :  92%|█████████▏| 183/200 [5:13:25<30:15, 106.80s/it]Evaluating commonsenseqa :  32%|███▎      | 65/200 [1:29:42<3:03:56, 81.75s/it]Evaluating commonsenseqa :  54%|█████▍    | 108/200 [3:21:32<2:53:03, 112.86s/it]Evaluating commonsenseqa :   5%|▌         | 10/200 [12:30<3:58:12, 75.22s/it]Evaluating commonsenseqa :  92%|█████████▏| 184/200 [5:13:56<22:27, 84.22s/it] Evaluating commonsenseqa :  32%|███▏      | 63/200 [2:21:43<5:03:36, 132.96s/it]Evaluating commonsenseqa :  33%|███▎      | 66/200 [1:31:11<3:07:51, 84.11s/it]Evaluating commonsenseqa :   6%|▌         | 11/200 [13:46<3:57:50, 75.51s/it]Evaluating commonsenseqa :  55%|█████▍    | 109/200 [3:23:24<2:50:38, 112.51s/it]Evaluating commonsenseqa :  92%|█████████▎| 185/200 [5:15:53<23:28, 93.92s/it]Evaluating commonsenseqa :  32%|███▏      | 64/200 [2:24:04<5:06:56, 135.41s/it]Evaluating commonsenseqa :   6%|▌         | 12/200 [15:01<3:55:52, 75.28s/it]Evaluating commonsenseqa :  34%|███▎      | 67/200 [1:32:40<3:09:16, 85.39s/it]Evaluating commonsenseqa :  55%|█████▌    | 110/200 [3:25:17<2:49:11, 112.80s/it]Evaluating commonsenseqa :   6%|▋         | 13/200 [16:17<3:55:37, 75.60s/it]Evaluating commonsenseqa :  93%|█████████▎| 186/200 [5:17:49<23:28, 100.59s/it]Evaluating commonsenseqa :  34%|███▍      | 68/200 [1:34:07<3:08:51, 85.84s/it]Evaluating commonsenseqa :  32%|███▎      | 65/200 [2:26:23<5:07:03, 136.47s/it]Evaluating commonsenseqa :   7%|▋         | 14/200 [17:33<3:54:09, 75.53s/it]Evaluating commonsenseqa :  56%|█████▌    | 111/200 [3:27:13<2:48:37, 113.68s/it]Evaluating commonsenseqa :  34%|███▍      | 69/200 [1:35:24<3:02:09, 83.43s/it]Evaluating commonsenseqa :  94%|█████████▎| 187/200 [5:19:44<22:42, 104.83s/it]Evaluating commonsenseqa :  35%|███▌      | 70/200 [1:36:04<2:32:16, 70.28s/it]Evaluating commonsenseqa :   8%|▊         | 15/200 [18:47<3:51:51, 75.20s/it]Evaluating commonsenseqa :  33%|███▎      | 66/200 [2:28:47<5:09:58, 138.79s/it]Evaluating commonsenseqa :  56%|█████▌    | 112/200 [3:29:08<2:47:08, 113.96s/it]Evaluating commonsenseqa :   8%|▊         | 16/200 [20:02<3:49:55, 74.98s/it]Evaluating commonsenseqa :  36%|███▌      | 71/200 [1:37:33<2:43:08, 75.88s/it]Evaluating commonsenseqa :  94%|█████████▍| 188/200 [5:21:40<21:39, 108.31s/it]Evaluating commonsenseqa :   8%|▊         | 17/200 [21:18<3:49:52, 75.37s/it]Evaluating commonsenseqa :  36%|███▌      | 72/200 [1:39:01<2:49:27, 79.44s/it]Evaluating commonsenseqa :  34%|███▎      | 67/200 [2:30:47<4:54:43, 132.96s/it]Evaluating commonsenseqa :  56%|█████▋    | 113/200 [3:31:00<2:44:21, 113.35s/it]Evaluating commonsenseqa :  94%|█████████▍| 189/200 [5:23:36<20:16, 110.57s/it]Evaluating commonsenseqa :   9%|▉         | 18/200 [22:32<3:47:31, 75.01s/it]Evaluating commonsenseqa :  36%|███▋      | 73/200 [1:40:30<2:54:14, 82.32s/it]Evaluating commonsenseqa :  57%|█████▋    | 114/200 [3:32:55<2:43:18, 113.94s/it]Evaluating commonsenseqa :  10%|▉         | 19/200 [23:48<3:46:55, 75.23s/it]Evaluating commonsenseqa :  34%|███▍      | 68/200 [2:33:07<4:57:30, 135.23s/it]Evaluating commonsenseqa :  95%|█████████▌| 190/200 [5:25:34<18:47, 112.76s/it]Evaluating commonsenseqa :  37%|███▋      | 74/200 [1:41:48<2:50:18, 81.10s/it]Evaluating commonsenseqa :  10%|█         | 20/200 [25:03<3:45:37, 75.21s/it]Evaluating commonsenseqa :  57%|█████▊    | 115/200 [3:34:48<2:41:06, 113.72s/it]Evaluating commonsenseqa :  38%|███▊      | 75/200 [1:43:17<2:54:05, 83.56s/it]Evaluating commonsenseqa :  96%|█████████▌| 191/200 [5:27:31<17:08, 114.25s/it]Evaluating commonsenseqa :  10%|█         | 21/200 [26:18<3:43:50, 75.03s/it]Evaluating commonsenseqa :  34%|███▍      | 69/200 [2:35:28<4:58:51, 136.88s/it]Evaluating commonsenseqa :  38%|███▊      | 76/200 [1:44:40<2:52:24, 83.43s/it]Evaluating commonsenseqa :  58%|█████▊    | 116/200 [3:36:40<2:38:29, 113.21s/it]Evaluating commonsenseqa :  11%|█         | 22/200 [27:32<3:42:25, 74.98s/it]Evaluating commonsenseqa :  96%|█████████▌| 192/200 [5:29:29<15:22, 115.32s/it]Evaluating commonsenseqa :  35%|███▌      | 70/200 [2:37:49<4:59:22, 138.17s/it]Evaluating commonsenseqa :  38%|███▊      | 77/200 [1:46:11<2:55:31, 85.62s/it]Evaluating commonsenseqa :  12%|█▏        | 23/200 [28:47<3:40:50, 74.86s/it]Evaluating commonsenseqa :  58%|█████▊    | 117/200 [3:38:33<2:36:23, 113.05s/it]Evaluating commonsenseqa :  12%|█▏        | 24/200 [30:02<3:39:43, 74.91s/it]Evaluating commonsenseqa :  96%|█████████▋| 193/200 [5:31:29<13:36, 116.58s/it]Evaluating commonsenseqa :  39%|███▉      | 78/200 [1:47:40<2:55:54, 86.51s/it]Evaluating commonsenseqa :  36%|███▌      | 71/200 [2:39:32<4:34:41, 127.76s/it]Evaluating commonsenseqa :  40%|███▉      | 79/200 [1:48:07<2:18:30, 68.69s/it]Evaluating commonsenseqa :  59%|█████▉    | 118/200 [3:40:25<2:33:55, 112.63s/it]Evaluating commonsenseqa :  12%|█▎        | 25/200 [31:18<3:39:16, 75.18s/it]Evaluating commonsenseqa :  97%|█████████▋| 194/200 [5:33:27<11:43, 117.19s/it]Evaluating commonsenseqa :  40%|████      | 80/200 [1:49:34<2:28:36, 74.30s/it]Evaluating commonsenseqa :  13%|█▎        | 26/200 [32:33<3:38:09, 75.23s/it]Evaluating commonsenseqa :  36%|███▌      | 72/200 [2:41:54<4:41:39, 132.03s/it]Evaluating commonsenseqa :  60%|█████▉    | 119/200 [3:42:18<2:32:16, 112.80s/it]Evaluating commonsenseqa :  40%|████      | 81/200 [1:51:03<2:35:47, 78.55s/it]Evaluating commonsenseqa :  14%|█▎        | 27/200 [33:47<3:36:03, 74.93s/it]Evaluating commonsenseqa :  98%|█████████▊| 195/200 [5:35:22<09:41, 116.32s/it]Evaluating commonsenseqa :  60%|██████    | 120/200 [3:44:12<2:30:46, 113.09s/it]Evaluating commonsenseqa :  14%|█▍        | 28/200 [35:03<3:35:12, 75.07s/it]Evaluating commonsenseqa :  41%|████      | 82/200 [1:52:32<2:41:07, 81.93s/it]Evaluating commonsenseqa :  36%|███▋      | 73/200 [2:44:15<4:44:57, 134.63s/it]Evaluating commonsenseqa :  98%|█████████▊| 196/200 [5:37:19<07:46, 116.69s/it]Evaluating commonsenseqa :  14%|█▍        | 29/200 [36:17<3:33:34, 74.94s/it]Evaluating commonsenseqa :  42%|████▏     | 83/200 [1:54:03<2:44:40, 84.44s/it]Evaluating commonsenseqa :  60%|██████    | 121/200 [3:46:07<2:29:38, 113.65s/it]Evaluating commonsenseqa :  98%|█████████▊| 197/200 [5:38:43<05:20, 106.71s/it]Evaluating commonsenseqa :  37%|███▋      | 74/200 [2:46:36<4:46:26, 136.40s/it]Evaluating commonsenseqa :  15%|█▌        | 30/200 [37:33<3:32:38, 75.05s/it]Evaluating commonsenseqa :  42%|████▏     | 84/200 [1:55:32<2:46:01, 85.88s/it]Evaluating commonsenseqa :  61%|██████    | 122/200 [3:48:00<2:27:49, 113.71s/it]Evaluating commonsenseqa :  16%|█▌        | 31/200 [38:49<3:32:30, 75.44s/it]Evaluating commonsenseqa :  99%|█████████▉| 198/200 [5:40:41<03:40, 110.11s/it]Evaluating commonsenseqa :  38%|███▊      | 75/200 [2:48:28<4:28:51, 129.05s/it]Evaluating commonsenseqa :  42%|████▎     | 85/200 [1:57:00<2:46:07, 86.67s/it]Evaluating commonsenseqa :  16%|█▌        | 32/200 [40:04<3:30:42, 75.25s/it]Evaluating commonsenseqa :  43%|████▎     | 86/200 [1:57:44<2:20:14, 73.81s/it]Evaluating commonsenseqa :  62%|██████▏   | 123/200 [3:49:53<2:25:30, 113.38s/it]Evaluating commonsenseqa : 100%|█████████▉| 199/200 [5:42:36<01:51, 111.71s/it]Evaluating commonsenseqa :  16%|█▋        | 33/200 [41:19<3:29:02, 75.11s/it]Evaluating commonsenseqa :  44%|████▎     | 87/200 [1:59:00<2:20:18, 74.50s/it]Evaluating commonsenseqa :  38%|███▊      | 76/200 [2:50:50<4:35:09, 133.14s/it]Evaluating commonsenseqa :  62%|██████▏   | 124/200 [3:51:48<2:24:06, 113.77s/it]Evaluating commonsenseqa :  17%|█▋        | 34/200 [42:34<3:28:11, 75.25s/it]Evaluating commonsenseqa :  44%|████▍     | 88/200 [2:00:28<2:26:36, 78.54s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [5:44:36<00:00, 114.29s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [5:44:36<00:00, 103.38s/it]
name: commonsenseqa | avg. gen lenth: 242.832 | time: 20679.24956226349s
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10139 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o11-tmathqa-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 11 9 11 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2023-09-20 05:19:08,057] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o11-tmathqa-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 11
  out_domain_data_name ......... mathqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o11-tmathqa-s20-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 438696.85it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.29s/it]
 > number of parameters: 6738415616
[2023-09-20 05:19:24,549] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.3, git-hash=unknown, git-branch=unknown
[2023-09-20 05:19:24,549] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-09-20 05:19:25,023] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-20 05:19:25,026] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2023-09-20 05:19:25,026] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-20 05:19:25,026] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-20 05:19:25,026] [INFO] [config.py:971:print]   amp_enabled .................. False
[2023-09-20 05:19:25,026] [INFO] [config.py:971:print]   amp_params ................... False
[2023-09-20 05:19:25,027] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-20 05:19:25,027] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2023-09-20 05:19:25,027] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2023-09-20 05:19:25,027] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2023-09-20 05:19:25,027] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2023-09-20 05:19:25,027] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fa7905d6d70>
[2023-09-20 05:19:25,027] [INFO] [config.py:971:print]   communication_data_type ...... None
[2023-09-20 05:19:25,027] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-20 05:19:25,027] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2023-09-20 05:19:25,027] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2023-09-20 05:19:25,027] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-20 05:19:25,027] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2023-09-20 05:19:25,027] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2023-09-20 05:19:25,027] [INFO] [config.py:971:print]   disable_allgather ............ False
[2023-09-20 05:19:25,027] [INFO] [config.py:971:print]   dump_state ................... False
[2023-09-20 05:19:25,027] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-20 05:19:25,027] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2023-09-20 05:19:25,027] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-20 05:19:25,027] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-20 05:19:25,027] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2023-09-20 05:19:25,027] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2023-09-20 05:19:25,027] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2023-09-20 05:19:25,027] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2023-09-20 05:19:25,028] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2023-09-20 05:19:25,028] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2023-09-20 05:19:25,028] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-20 05:19:25,028] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2023-09-20 05:19:25,028] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2023-09-20 05:19:25,028] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2023-09-20 05:19:25,028] [INFO] [config.py:971:print]   global_rank .................. 0
[2023-09-20 05:19:25,028] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2023-09-20 05:19:25,028] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2023-09-20 05:19:25,028] [INFO] [config.py:971:print]   gradient_clipping ............ 0.0
[2023-09-20 05:19:25,028] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2023-09-20 05:19:25,028] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-20 05:19:25,028] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 2048
[2023-09-20 05:19:25,028] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2023-09-20 05:19:25,028] [INFO] [config.py:971:print]   loss_scale ................... 0
[2023-09-20 05:19:25,028] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2023-09-20 05:19:25,028] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2023-09-20 05:19:25,028] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2023-09-20 05:19:25,028] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-20 05:19:25,028] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-20 05:19:25,028] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2023-09-20 05:19:25,028] [INFO] [config.py:971:print]   optimizer_name ............... None
[2023-09-20 05:19:25,028] [INFO] [config.py:971:print]   optimizer_params ............. None
[2023-09-20 05:19:25,028] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-20 05:19:25,028] [INFO] [config.py:971:print]   pld_enabled .................. False
[2023-09-20 05:19:25,028] [INFO] [config.py:971:print]   pld_params ................... False
[2023-09-20 05:19:25,029] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2023-09-20 05:19:25,029] [INFO] [config.py:971:print]   scheduler_name ............... None
[2023-09-20 05:19:25,029] [INFO] [config.py:971:print]   scheduler_params ............. None
[2023-09-20 05:19:25,029] [INFO] [config.py:971:print]   sparse_attention ............. None
[2023-09-20 05:19:25,029] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2023-09-20 05:19:25,029] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2023-09-20 05:19:25,029] [INFO] [config.py:971:print]   train_batch_size ............. 1
[2023-09-20 05:19:25,029] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  1
[2023-09-20 05:19:25,029] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2023-09-20 05:19:25,029] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2023-09-20 05:19:25,029] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2023-09-20 05:19:25,029] [INFO] [config.py:971:print]   world_size ................... 1
[2023-09-20 05:19:25,029] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  True
[2023-09-20 05:19:25,029] [INFO] [config.py:971:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2023-09-20 05:19:25,029] [INFO] [config.py:971:print]   zero_enabled ................. False
[2023-09-20 05:19:25,029] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-20 05:19:25,029] [INFO] [config.py:971:print]   zero_optimization_stage ...... 0
[2023-09-20 05:19:25,029] [INFO] [config.py:957:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/200 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: a man cycling along the road noticed that every 18 minutes a bus overtakes him and every 6 minutes he meets an oncoming bus. if all buses and the cyclist move at a constant speed, what is the time interval between consecutive buses? a ) 5 minutes, b ) 6 minutes, c ) 8 minutes, d ) 9 minutes, e ) 10 minutes
Output: d

Input: an athlete runs 200 metres race in 24 seconds. what is his speed? a ) 20 km / hr, b ) 30 km / hr, c ) 25 km / hr, d ) 35 km / hr, e ) 40 km / hr
Output: b

Input: two numbers are in the ratio 3 : 4. if the sum of numbers is 63, find the numbers. a ) 27 and 36., b ) 25 and 30., c ) 23 and 44., d ) 63 and 12., e ) 12 and 36.
Output: a

Input: a company wants to spend equal amounts of money for the purchase of two types of computer printers costing $ 375 and $ 150 per unit, respectively. what is the fewest number of computer printers that the company can purchase? a ) 3, b ) 4, c ) 5, d ) 6, e ) 7
Output: e

Input: a certain music store stocks 800 cellos and 600 violas. of these instruments, there are 80 cello - viola pairs, such that a cello and a viola were both made with wood from the same tree ( each tree can make at most one viola and one cello, so there are no pairs other than these 90 ). if one viola and one cello are chosen at random, what is the probability that the two instruments are made with wood from the same tree? a ) 3 / 16,000, b ) 1 / 8,100, c ) 1 / 600, d ) 1 / 90, e ) 2 / 45
Output: c

Input: what is the difference between local value & face value of 7 in the numeral 65793? a ) 693, b ) 656, c ) 691, d ) 9890, e ) 10000
Output: a

Input: in an office in singapore there are 60 % female employees. 50 % of all the male employees are computer literate. if there are total 62 % employees computer literate out of total 1100 employees, then the no. of female employees who are computer literate? a ) 462, b ) 674, c ) 672, d ) 960, e ) none
Output: a

Input: the cost price of 16 articles is the same as the selling price of 12 articles. find the loss / profit percentages. a ) 30 %, b ) 32.50 %, c ) 33 1 / 3 %, d ) 40 %, e ) 50 %
Output: c

Input: mike drives his new corvette from san francisco to las vegas, a journey of 640 miles. he drives the first half of the trip at an average rate of 80 miles per hour, but has to slow down for the second half of his journey. if the second half of the trip takes him 200 percent longer than the first half, what is his average rate q in miles per hour for the entire trip? a ) q = 26.7, b ) q = 30.0, c ) q = 40.0, d ) q = 53.3, e ) q = 60.0
Output: c

Input: lisa and robert have taken the same number of photos on their school trip. lisa has taken 3 times as many photos as claire and robert has taken 20 more photos than claire. how many photos has claire taken? a ) 6, b ) 8, c ) 10, d ) 12, e ) 14
Output: c

Input: meena wrote all the numbers from 1 to 69,999 inclusive. how many digits did she write in total? a ) 278,889, b ) 308,889, c ) 338,889, d ) 368,889, e ) 398,889
Output: c

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o11-tmathqa-s20-rFalse-m4096
Evaluating commonsenseqa :  18%|█▊        | 35/200 [43:50<3:27:21, 75.41s/it]Evaluating commonsenseqa :  38%|███▊      | 77/200 [2:53:10<4:37:03, 135.15s/it]Evaluating commonsenseqa :  62%|██████▎   | 125/200 [3:53:41<2:22:07, 113.70s/it]Evaluating commonsenseqa :   0%|          | 1/200 [00:48<2:41:19, 48.64s/it]Evaluating commonsenseqa :  44%|████▍     | 89/200 [2:01:58<2:31:14, 81.75s/it]Evaluating commonsenseqa :  18%|█▊        | 36/200 [45:04<3:25:02, 75.02s/it]Evaluating commonsenseqa :  45%|████▌     | 90/200 [2:02:53<2:15:27, 73.88s/it]Evaluating commonsenseqa :  46%|████▌     | 91/200 [2:03:25<1:51:36, 61.43s/it]Evaluating commonsenseqa :  63%|██████▎   | 126/200 [3:55:35<2:20:07, 113.62s/it]Evaluating commonsenseqa :   1%|          | 2/200 [02:40<4:43:38, 85.95s/it]Evaluating commonsenseqa :  18%|█▊        | 37/200 [46:20<3:24:32, 75.29s/it]Evaluating commonsenseqa :  39%|███▉      | 78/200 [2:55:31<4:38:07, 136.78s/it]Evaluating commonsenseqa :  46%|████▌     | 92/200 [2:04:34<1:54:29, 63.60s/it]Evaluating commonsenseqa :  19%|█▉        | 38/200 [47:36<3:23:31, 75.38s/it]Evaluating commonsenseqa :   2%|▏         | 3/200 [04:33<5:21:59, 98.07s/it]Evaluating commonsenseqa :  64%|██████▎   | 127/200 [3:57:29<2:18:21, 113.72s/it]Evaluating commonsenseqa :  46%|████▋     | 93/200 [2:06:03<2:06:40, 71.04s/it]Evaluating commonsenseqa :  40%|███▉      | 79/200 [2:57:50<4:37:19, 137.52s/it]Evaluating commonsenseqa :  20%|█▉        | 39/200 [48:51<3:22:02, 75.30s/it]Evaluating commonsenseqa :   2%|▏         | 4/200 [06:23<5:36:21, 102.97s/it]Evaluating commonsenseqa :  47%|████▋     | 94/200 [2:07:32<2:15:13, 76.55s/it]Evaluating commonsenseqa :  64%|██████▍   | 128/200 [3:59:22<2:16:25, 113.69s/it]Evaluating commonsenseqa :  20%|██        | 40/200 [50:05<3:20:18, 75.11s/it]Evaluating commonsenseqa :  40%|████      | 80/200 [3:00:11<4:37:09, 138.58s/it]Evaluating commonsenseqa :  20%|██        | 41/200 [51:21<3:19:05, 75.13s/it]Evaluating commonsenseqa :  48%|████▊     | 95/200 [2:09:00<2:19:46, 79.87s/it]Evaluating commonsenseqa :   2%|▎         | 5/200 [08:14<5:43:17, 105.63s/it]Evaluating commonsenseqa :  64%|██████▍   | 129/200 [4:01:15<2:14:10, 113.38s/it]Evaluating commonsenseqa :  21%|██        | 42/200 [52:37<3:19:01, 75.58s/it]Evaluating commonsenseqa :  65%|██████▌   | 130/200 [4:02:13<1:52:49, 96.71s/it] Evaluating commonsenseqa :  48%|████▊     | 96/200 [2:10:28<2:22:54, 82.44s/it]Evaluating commonsenseqa :  40%|████      | 81/200 [3:02:30<4:35:22, 138.85s/it]Evaluating commonsenseqa :   3%|▎         | 6/200 [10:05<5:47:37, 107.51s/it]Evaluating commonsenseqa :  22%|██▏       | 43/200 [53:52<3:16:57, 75.27s/it]Evaluating commonsenseqa :  48%|████▊     | 97/200 [2:11:44<2:17:58, 80.37s/it]Evaluating commonsenseqa :  66%|██████▌   | 131/200 [4:04:04<1:56:12, 101.05s/it]Evaluating commonsenseqa :  22%|██▏       | 44/200 [55:07<3:15:20, 75.13s/it]Evaluating commonsenseqa :   4%|▎         | 7/200 [11:41<5:33:45, 103.76s/it]Evaluating commonsenseqa :  49%|████▉     | 98/200 [2:13:11<2:20:21, 82.56s/it]Evaluating commonsenseqa :  41%|████      | 82/200 [3:04:51<4:33:54, 139.28s/it]Evaluating commonsenseqa :  22%|██▎       | 45/200 [56:22<3:14:22, 75.24s/it]Evaluating commonsenseqa :  66%|██████▌   | 132/200 [4:05:56<1:58:11, 104.29s/it]Evaluating commonsenseqa :  50%|████▉     | 99/200 [2:14:40<2:21:57, 84.33s/it]Evaluating commonsenseqa :   4%|▍         | 8/200 [13:35<5:43:09, 107.24s/it]Evaluating commonsenseqa :  23%|██▎       | 46/200 [57:38<3:13:36, 75.43s/it]Evaluating commonsenseqa :  42%|████▏     | 83/200 [3:07:13<4:33:12, 140.10s/it]Evaluating commonsenseqa :  66%|██████▋   | 133/200 [4:07:49<1:59:18, 106.84s/it]Evaluating commonsenseqa :  50%|█████     | 100/200 [2:16:09<2:23:03, 85.84s/it]Evaluating commonsenseqa :  24%|██▎       | 47/200 [58:53<3:11:56, 75.27s/it]Evaluating commonsenseqa :   4%|▍         | 9/200 [15:28<5:46:17, 108.78s/it]Evaluating commonsenseqa :  50%|█████     | 101/200 [2:17:10<2:09:05, 78.24s/it]Evaluating commonsenseqa :  24%|██▍       | 48/200 [1:00:07<3:10:04, 75.03s/it]Evaluating commonsenseqa :  42%|████▏     | 84/200 [3:09:30<4:29:26, 139.36s/it]Evaluating commonsenseqa :  67%|██████▋   | 134/200 [4:09:41<1:59:24, 108.55s/it]Evaluating commonsenseqa :   5%|▌         | 10/200 [16:54<5:22:16, 101.77s/it]Evaluating commonsenseqa :  51%|█████     | 102/200 [2:18:39<2:13:14, 81.57s/it]Evaluating commonsenseqa :  24%|██▍       | 49/200 [1:01:22<3:08:15, 74.80s/it]Evaluating commonsenseqa :  68%|██████▊   | 135/200 [4:11:32<1:58:27, 109.34s/it]Evaluating commonsenseqa :   6%|▌         | 11/200 [18:44<5:28:34, 104.31s/it]Evaluating commonsenseqa :  25%|██▌       | 50/200 [1:02:36<3:07:05, 74.83s/it]Evaluating commonsenseqa :  52%|█████▏    | 103/200 [2:20:07<2:15:05, 83.56s/it]Evaluating commonsenseqa :  42%|████▎     | 85/200 [3:11:48<4:26:21, 138.97s/it]Evaluating commonsenseqa :   6%|▌         | 12/200 [20:13<5:12:20, 99.68s/it] Evaluating commonsenseqa :  26%|██▌       | 51/200 [1:03:51<3:05:51, 74.84s/it]Evaluating commonsenseqa :  68%|██████▊   | 136/200 [4:13:23<1:57:04, 109.76s/it]Evaluating commonsenseqa :  52%|█████▏    | 104/200 [2:21:35<2:15:52, 84.92s/it]Evaluating commonsenseqa :  43%|████▎     | 86/200 [3:13:18<3:55:47, 124.10s/it]Evaluating commonsenseqa :  26%|██▌       | 52/200 [1:05:07<3:04:52, 74.95s/it]Evaluating commonsenseqa :  52%|█████▎    | 105/200 [2:23:03<2:15:53, 85.83s/it]Evaluating commonsenseqa :   6%|▋         | 13/200 [22:04<5:21:04, 103.02s/it]Evaluating commonsenseqa :  68%|██████▊   | 137/200 [4:15:17<1:56:26, 110.90s/it]Evaluating commonsenseqa :  53%|█████▎    | 106/200 [2:23:43<1:52:54, 72.07s/it]Evaluating commonsenseqa :  26%|██▋       | 53/200 [1:06:22<3:04:10, 75.17s/it]Evaluating commonsenseqa :  44%|████▎     | 87/200 [3:15:39<4:03:05, 129.08s/it]Evaluating commonsenseqa :   7%|▋         | 14/200 [23:56<5:28:36, 106.00s/it]Evaluating commonsenseqa :  27%|██▋       | 54/200 [1:07:37<3:02:38, 75.06s/it]Evaluating commonsenseqa :  54%|█████▎    | 107/200 [2:25:12<1:59:35, 77.15s/it]Evaluating commonsenseqa :  69%|██████▉   | 138/200 [4:17:08<1:54:40, 110.98s/it]Evaluating commonsenseqa :   8%|▊         | 15/200 [25:00<4:47:34, 93.27s/it] Evaluating commonsenseqa :  44%|████▍     | 88/200 [3:17:59<4:07:07, 132.39s/it]Evaluating commonsenseqa :   8%|▊         | 16/200 [25:16<3:34:53, 70.07s/it]Evaluating commonsenseqa :  28%|██▊       | 55/200 [1:08:55<3:03:16, 75.84s/it]Evaluating commonsenseqa :  54%|█████▍    | 108/200 [2:26:42<2:04:00, 80.87s/it]Evaluating commonsenseqa :  70%|██████▉   | 139/200 [4:19:03<1:54:08, 112.28s/it]Evaluating commonsenseqa :  55%|█████▍    | 109/200 [2:27:38<1:51:25, 73.47s/it]Evaluating commonsenseqa :  28%|██▊       | 56/200 [1:10:10<3:01:27, 75.61s/it]Evaluating commonsenseqa :   8%|▊         | 17/200 [27:10<4:13:42, 83.18s/it]Evaluating commonsenseqa :  44%|████▍     | 89/200 [3:20:20<4:09:55, 135.10s/it]Evaluating commonsenseqa :  28%|██▊       | 57/200 [1:11:25<3:00:13, 75.62s/it]Evaluating commonsenseqa :  70%|███████   | 140/200 [4:20:55<1:52:06, 112.12s/it]Evaluating commonsenseqa :  55%|█████▌    | 110/200 [2:29:07<1:57:21, 78.24s/it]Evaluating commonsenseqa :  29%|██▉       | 58/200 [1:12:41<2:58:39, 75.49s/it]Evaluating commonsenseqa :   9%|▉         | 18/200 [29:04<4:40:32, 92.49s/it]Evaluating commonsenseqa :  56%|█████▌    | 111/200 [2:30:36<2:00:50, 81.46s/it]Evaluating commonsenseqa :  70%|███████   | 141/200 [4:22:50<1:51:15, 113.15s/it]Evaluating commonsenseqa :  45%|████▌     | 90/200 [3:22:42<4:11:34, 137.22s/it]Evaluating commonsenseqa :  30%|██▉       | 59/200 [1:13:55<2:56:45, 75.22s/it]Evaluating commonsenseqa :  10%|▉         | 19/200 [30:58<4:57:52, 98.74s/it]Evaluating commonsenseqa :  56%|█████▌    | 112/200 [2:32:05<2:02:31, 83.54s/it]Evaluating commonsenseqa :  46%|████▌     | 91/200 [3:24:00<3:36:36, 119.23s/it]Evaluating commonsenseqa :  30%|███       | 60/200 [1:15:10<2:55:14, 75.11s/it]Evaluating commonsenseqa :  71%|███████   | 142/200 [4:24:41<1:48:43, 112.47s/it]Evaluating commonsenseqa :  46%|████▌     | 92/200 [3:25:02<3:03:56, 102.19s/it]Evaluating commonsenseqa :  56%|█████▋    | 113/200 [2:33:29<2:01:41, 83.92s/it]Evaluating commonsenseqa :  30%|███       | 61/200 [1:16:25<2:54:05, 75.15s/it]Evaluating commonsenseqa :  10%|█         | 20/200 [32:50<5:09:02, 103.01s/it]Evaluating commonsenseqa :  72%|███████▏  | 143/200 [4:26:34<1:46:55, 112.55s/it]Evaluating commonsenseqa :  57%|█████▋    | 114/200 [2:34:58<2:02:09, 85.23s/it]Evaluating commonsenseqa :  31%|███       | 62/200 [1:17:41<2:52:58, 75.21s/it]Evaluating commonsenseqa :  46%|████▋     | 93/200 [3:27:19<3:20:39, 112.52s/it]Evaluating commonsenseqa :  10%|█         | 21/200 [34:43<5:15:24, 105.72s/it]Evaluating commonsenseqa :  32%|███▏      | 63/200 [1:18:57<2:52:35, 75.59s/it]Evaluating commonsenseqa :  57%|█████▊    | 115/200 [2:36:26<2:02:09, 86.23s/it]Evaluating commonsenseqa :  72%|███████▏  | 144/200 [4:28:27<1:45:06, 112.61s/it]Evaluating commonsenseqa :  11%|█         | 22/200 [36:35<5:19:43, 107.77s/it]Evaluating commonsenseqa :  32%|███▏      | 64/200 [1:20:13<2:51:17, 75.57s/it]Evaluating commonsenseqa :  58%|█████▊    | 116/200 [2:37:56<2:01:59, 87.13s/it]Evaluating commonsenseqa :  47%|████▋     | 94/200 [3:29:40<3:34:05, 121.18s/it]Evaluating commonsenseqa :  58%|█████▊    | 117/200 [2:38:32<1:39:33, 71.97s/it]Evaluating commonsenseqa :  72%|███████▎  | 145/200 [4:30:23<1:44:08, 113.60s/it]Evaluating commonsenseqa :  32%|███▎      | 65/200 [1:21:28<2:49:56, 75.53s/it]Evaluating commonsenseqa :  12%|█▏        | 23/200 [38:25<5:20:10, 108.53s/it]Evaluating commonsenseqa :  59%|█████▉    | 118/200 [2:39:38<1:35:48, 70.11s/it]Evaluating commonsenseqa :  33%|███▎      | 66/200 [1:22:43<2:48:21, 75.39s/it]Evaluating commonsenseqa :  48%|████▊     | 95/200 [3:32:02<3:43:13, 127.55s/it]Evaluating commonsenseqa :  73%|███████▎  | 146/200 [4:32:14<1:41:31, 112.81s/it]Evaluating commonsenseqa :  60%|█████▉    | 119/200 [2:41:05<1:41:41, 75.33s/it]Evaluating commonsenseqa :  12%|█▏        | 24/200 [40:17<5:20:59, 109.43s/it]Evaluating commonsenseqa :  34%|███▎      | 67/200 [1:23:58<2:46:50, 75.27s/it]Evaluating commonsenseqa :  74%|███████▎  | 147/200 [4:34:07<1:39:50, 113.03s/it]Evaluating commonsenseqa :  60%|██████    | 120/200 [2:42:29<1:43:54, 77.93s/it]Evaluating commonsenseqa :  34%|███▍      | 68/200 [1:25:14<2:46:10, 75.53s/it]Evaluating commonsenseqa :  48%|████▊     | 96/200 [3:34:24<3:48:12, 131.66s/it]Evaluating commonsenseqa :  12%|█▎        | 25/200 [41:49<5:03:35, 104.09s/it]Evaluating commonsenseqa :  34%|███▍      | 69/200 [1:26:29<2:44:24, 75.30s/it]Evaluating commonsenseqa :  60%|██████    | 121/200 [2:43:58<1:46:48, 81.12s/it]Evaluating commonsenseqa :  74%|███████▍  | 148/200 [4:36:01<1:38:03, 113.14s/it]Evaluating commonsenseqa :  13%|█▎        | 26/200 [43:41<5:08:58, 106.54s/it]Evaluating commonsenseqa :  48%|████▊     | 97/200 [3:36:41<3:49:09, 133.49s/it]Evaluating commonsenseqa :  35%|███▌      | 70/200 [1:27:44<2:42:50, 75.16s/it]Evaluating commonsenseqa :  61%|██████    | 122/200 [2:45:25<1:47:41, 82.84s/it]Evaluating commonsenseqa :  74%|███████▍  | 149/200 [4:37:51<1:35:28, 112.31s/it]Evaluating commonsenseqa :  36%|███▌      | 71/200 [1:29:00<2:42:09, 75.42s/it]Evaluating commonsenseqa :  14%|█▎        | 27/200 [45:35<5:13:29, 108.72s/it]Evaluating commonsenseqa :  62%|██████▏   | 123/200 [2:46:54<1:48:37, 84.64s/it]Evaluating commonsenseqa :  49%|████▉     | 98/200 [3:39:03<3:51:00, 135.89s/it]Evaluating commonsenseqa :  36%|███▌      | 72/200 [1:30:15<2:40:57, 75.45s/it]Evaluating commonsenseqa :  75%|███████▌  | 150/200 [4:39:44<1:33:40, 112.40s/it]Evaluating commonsenseqa :  62%|██████▏   | 124/200 [2:48:22<1:48:33, 85.71s/it]Evaluating commonsenseqa :  14%|█▍        | 28/200 [47:24<5:12:11, 108.90s/it]Evaluating commonsenseqa :  36%|███▋      | 73/200 [1:31:30<2:39:20, 75.28s/it]Evaluating commonsenseqa :  50%|████▉     | 99/200 [3:41:22<3:50:20, 136.84s/it]Evaluating commonsenseqa :  76%|███████▌  | 151/200 [4:41:36<1:31:42, 112.30s/it]Evaluating commonsenseqa :  62%|██████▎   | 125/200 [2:49:50<1:48:05, 86.47s/it]Evaluating commonsenseqa :  37%|███▋      | 74/200 [1:32:45<2:37:55, 75.21s/it]Evaluating commonsenseqa :  14%|█▍        | 29/200 [49:13<5:10:22, 108.90s/it]Evaluating commonsenseqa :  63%|██████▎   | 126/200 [2:51:03<1:41:28, 82.27s/it]Evaluating commonsenseqa :  38%|███▊      | 75/200 [1:34:00<2:36:07, 74.94s/it]Evaluating commonsenseqa :  76%|███████▌  | 152/200 [4:43:31<1:30:32, 113.17s/it]Evaluating commonsenseqa :  50%|█████     | 100/200 [3:43:43<3:50:22, 138.22s/it]Evaluating commonsenseqa :  15%|█▌        | 30/200 [51:05<5:11:32, 109.96s/it]Evaluating commonsenseqa :  64%|██████▎   | 127/200 [2:52:32<1:42:46, 84.48s/it]Evaluating commonsenseqa :  38%|███▊      | 76/200 [1:35:15<2:35:01, 75.01s/it]Evaluating commonsenseqa :  76%|███████▋  | 153/200 [4:45:24<1:28:33, 113.06s/it]Evaluating commonsenseqa :  38%|███▊      | 77/200 [1:36:30<2:33:53, 75.07s/it]Evaluating commonsenseqa :  64%|██████▍   | 128/200 [2:54:00<1:42:35, 85.49s/it]Evaluating commonsenseqa :  16%|█▌        | 31/200 [52:57<5:11:01, 110.42s/it]Evaluating commonsenseqa :  50%|█████     | 101/200 [3:46:06<3:50:17, 139.57s/it]Evaluating commonsenseqa :  39%|███▉      | 78/200 [1:37:45<2:32:49, 75.16s/it]Evaluating commonsenseqa :  64%|██████▍   | 129/200 [2:55:27<1:41:34, 85.84s/it]Evaluating commonsenseqa :  77%|███████▋  | 154/200 [4:47:18<1:26:56, 113.41s/it]Evaluating commonsenseqa :  16%|█▌        | 32/200 [54:48<5:09:59, 110.71s/it]Evaluating commonsenseqa :  40%|███▉      | 79/200 [1:39:00<2:31:04, 74.91s/it]Evaluating commonsenseqa :  65%|██████▌   | 130/200 [2:56:49<1:38:46, 84.67s/it]Evaluating commonsenseqa :  51%|█████     | 102/200 [3:48:28<3:48:59, 140.20s/it]Evaluating commonsenseqa :  78%|███████▊  | 155/200 [4:49:12<1:25:13, 113.62s/it]Evaluating commonsenseqa :  40%|████      | 80/200 [1:40:15<2:30:14, 75.12s/it]Evaluating commonsenseqa :  16%|█▋        | 33/200 [56:41<5:10:01, 111.38s/it]Evaluating commonsenseqa :  66%|██████▌   | 131/200 [2:58:17<1:38:47, 85.90s/it]Evaluating commonsenseqa :  40%|████      | 81/200 [1:41:30<2:28:39, 74.96s/it]Evaluating commonsenseqa :  52%|█████▏    | 103/200 [3:50:49<3:47:15, 140.57s/it]Evaluating commonsenseqa :  78%|███████▊  | 156/200 [4:51:03<1:22:46, 112.87s/it]Evaluating commonsenseqa :  17%|█▋        | 34/200 [58:33<5:08:19, 111.44s/it]Evaluating commonsenseqa :  66%|██████▌   | 132/200 [2:59:45<1:38:00, 86.47s/it]Evaluating commonsenseqa :  41%|████      | 82/200 [1:42:46<2:27:54, 75.21s/it]Evaluating commonsenseqa :  78%|███████▊  | 157/200 [4:52:58<1:21:15, 113.39s/it]Evaluating commonsenseqa :  66%|██████▋   | 133/200 [3:01:13<1:37:02, 86.91s/it]Evaluating commonsenseqa :  42%|████▏     | 83/200 [1:44:01<2:26:25, 75.09s/it]Evaluating commonsenseqa :  18%|█▊        | 35/200 [1:00:25<5:07:14, 111.72s/it]Evaluating commonsenseqa :  52%|█████▏    | 104/200 [3:53:12<3:46:08, 141.34s/it]Evaluating commonsenseqa :  67%|██████▋   | 134/200 [3:02:43<1:36:31, 87.76s/it]Evaluating commonsenseqa :  42%|████▏     | 84/200 [1:45:17<2:25:44, 75.38s/it]Evaluating commonsenseqa :  79%|███████▉  | 158/200 [4:54:51<1:19:17, 113.26s/it]Evaluating commonsenseqa :  18%|█▊        | 36/200 [1:02:13<5:02:39, 110.73s/it]Evaluating commonsenseqa :  52%|█████▎    | 105/200 [3:55:29<3:41:23, 139.83s/it]Evaluating commonsenseqa :  42%|████▎     | 85/200 [1:46:31<2:24:08, 75.21s/it]Evaluating commonsenseqa :  68%|██████▊   | 135/200 [3:04:13<1:35:41, 88.32s/it]Evaluating commonsenseqa :  80%|███████▉  | 159/200 [4:56:42<1:17:00, 112.70s/it]Evaluating commonsenseqa :  18%|█▊        | 37/200 [1:04:07<5:02:44, 111.44s/it]Evaluating commonsenseqa :  43%|████▎     | 86/200 [1:47:46<2:22:31, 75.02s/it]Evaluating commonsenseqa :  68%|██████▊   | 136/200 [3:05:35<1:32:12, 86.44s/it]Evaluating commonsenseqa :  53%|█████▎    | 106/200 [3:57:52<3:40:32, 140.77s/it]Evaluating commonsenseqa :  19%|█▉        | 38/200 [1:05:22<4:31:24, 100.52s/it]Evaluating commonsenseqa :  44%|████▎     | 87/200 [1:49:01<2:21:18, 75.03s/it]Evaluating commonsenseqa :  80%|████████  | 160/200 [4:58:36<1:15:26, 113.17s/it]Evaluating commonsenseqa :  68%|██████▊   | 137/200 [3:07:05<1:31:54, 87.54s/it]Evaluating commonsenseqa :  44%|████▍     | 88/200 [1:50:17<2:20:24, 75.22s/it]Evaluating commonsenseqa :  20%|█▉        | 39/200 [1:06:56<4:24:41, 98.64s/it] Evaluating commonsenseqa :  54%|█████▎    | 107/200 [4:00:13<3:38:24, 140.91s/it]Evaluating commonsenseqa :  69%|██████▉   | 138/200 [3:08:34<1:31:03, 88.12s/it]Evaluating commonsenseqa :  80%|████████  | 161/200 [5:00:32<1:13:59, 113.83s/it]Evaluating commonsenseqa :  44%|████▍     | 89/200 [1:51:32<2:19:20, 75.32s/it]Evaluating commonsenseqa :  20%|██        | 40/200 [1:08:48<4:33:32, 102.58s/it]Evaluating commonsenseqa :  70%|██████▉   | 139/200 [3:10:04<1:30:03, 88.58s/it]Evaluating commonsenseqa :  45%|████▌     | 90/200 [1:52:44<2:16:19, 74.36s/it]Evaluating commonsenseqa :  81%|████████  | 162/200 [5:02:25<1:11:58, 113.64s/it]Evaluating commonsenseqa :  54%|█████▍    | 108/200 [4:02:32<3:35:13, 140.36s/it]Evaluating commonsenseqa :  46%|████▌     | 91/200 [1:54:00<2:15:55, 74.82s/it]Evaluating commonsenseqa :  70%|███████   | 140/200 [3:11:33<1:28:51, 88.86s/it]Evaluating commonsenseqa :  20%|██        | 41/200 [1:10:39<4:38:36, 105.13s/it]Evaluating commonsenseqa :  82%|████████▏ | 163/200 [5:04:18<1:09:57, 113.45s/it]Evaluating commonsenseqa :  46%|████▌     | 92/200 [1:55:16<2:15:18, 75.17s/it]Evaluating commonsenseqa :  70%|███████   | 141/200 [3:13:00<1:26:49, 88.30s/it]Evaluating commonsenseqa :  55%|█████▍    | 109/200 [4:04:51<3:32:29, 140.10s/it]Evaluating commonsenseqa :  21%|██        | 42/200 [1:12:32<4:42:59, 107.46s/it]Evaluating commonsenseqa :  46%|████▋     | 93/200 [1:56:31<2:13:42, 74.98s/it]Evaluating commonsenseqa :  82%|████████▏ | 164/200 [5:06:10<1:07:50, 113.07s/it]Evaluating commonsenseqa :  71%|███████   | 142/200 [3:14:27<1:24:53, 87.82s/it]Evaluating commonsenseqa :  22%|██▏       | 43/200 [1:14:03<4:28:48, 102.73s/it]Evaluating commonsenseqa :  47%|████▋     | 94/200 [1:57:46<2:12:26, 74.97s/it]Evaluating commonsenseqa :  55%|█████▌    | 110/200 [4:07:11<3:29:49, 139.88s/it]Evaluating commonsenseqa :  72%|███████▏  | 143/200 [3:15:56<1:23:50, 88.26s/it]Evaluating commonsenseqa :  82%|████████▎ | 165/200 [5:08:03<1:06:00, 113.17s/it]Evaluating commonsenseqa :  48%|████▊     | 95/200 [1:59:01<2:11:27, 75.12s/it]Evaluating commonsenseqa :  22%|██▏       | 44/200 [1:15:56<4:34:44, 105.67s/it]Evaluating commonsenseqa :  72%|███████▏  | 144/200 [3:17:26<1:22:42, 88.61s/it]Evaluating commonsenseqa :  48%|████▊     | 96/200 [2:00:16<2:10:11, 75.11s/it]Evaluating commonsenseqa :  56%|█████▌    | 111/200 [4:09:32<3:27:54, 140.16s/it]Evaluating commonsenseqa :  83%|████████▎ | 166/200 [5:09:57<1:04:12, 113.30s/it]Evaluating commonsenseqa :  22%|██▎       | 45/200 [1:17:50<4:39:21, 108.14s/it]Evaluating commonsenseqa :  72%|███████▎  | 145/200 [3:18:56<1:21:47, 89.23s/it]Evaluating commonsenseqa :  48%|████▊     | 97/200 [2:01:31<2:08:53, 75.09s/it]Evaluating commonsenseqa :  49%|████▉     | 98/200 [2:02:10<1:49:11, 64.23s/it]Evaluating commonsenseqa :  84%|████████▎ | 167/200 [5:11:48<1:01:59, 112.71s/it]Evaluating commonsenseqa :  73%|███████▎  | 146/200 [3:20:11<1:16:28, 84.98s/it]Evaluating commonsenseqa :  56%|█████▌    | 112/200 [4:11:51<3:25:24, 140.05s/it]Evaluating commonsenseqa :  23%|██▎       | 46/200 [1:19:41<4:39:45, 108.99s/it]Evaluating commonsenseqa :  50%|████▉     | 99/200 [2:03:25<1:53:40, 67.53s/it]Evaluating commonsenseqa :  74%|███████▎  | 147/200 [3:21:39<1:15:42, 85.71s/it]Evaluating commonsenseqa :  84%|████████▍ | 168/200 [5:13:41<1:00:04, 112.63s/it]Evaluating commonsenseqa :  74%|███████▍  | 148/200 [3:22:01<57:46, 66.66s/it]  Evaluating commonsenseqa :  50%|█████     | 100/200 [2:04:40<1:56:12, 69.73s/it]Evaluating commonsenseqa :  56%|█████▋    | 113/200 [4:13:58<3:17:15, 136.04s/it]Evaluating commonsenseqa :  24%|██▎       | 47/200 [1:21:32<4:39:33, 109.63s/it]Evaluating commonsenseqa :  50%|█████     | 101/200 [2:05:55<1:57:32, 71.24s/it]Evaluating commonsenseqa :  74%|███████▍  | 149/200 [3:23:30<1:02:21, 73.36s/it]Evaluating commonsenseqa :  84%|████████▍ | 169/200 [5:15:32<58:00, 112.28s/it]  Evaluating commonsenseqa :  75%|███████▌  | 150/200 [3:24:07<52:00, 62.40s/it]  Evaluating commonsenseqa :  24%|██▍       | 48/200 [1:23:23<4:38:31, 109.95s/it]Evaluating commonsenseqa :  51%|█████     | 102/200 [2:07:09<1:57:49, 72.13s/it]Evaluating commonsenseqa :  57%|█████▋    | 114/200 [4:16:21<3:17:45, 137.97s/it]Evaluating commonsenseqa :  85%|████████▌ | 170/200 [5:17:24<56:06, 112.23s/it]Evaluating commonsenseqa :  76%|███████▌  | 151/200 [3:25:37<57:41, 70.64s/it]Evaluating commonsenseqa :  52%|█████▏    | 103/200 [2:08:24<1:57:54, 72.94s/it]Evaluating commonsenseqa :  24%|██▍       | 49/200 [1:25:12<4:36:31, 109.87s/it]Evaluating commonsenseqa :  57%|█████▊    | 115/200 [4:18:42<3:16:57, 139.03s/it]Evaluating commonsenseqa :  76%|███████▌  | 152/200 [3:27:05<1:00:39, 75.81s/it]Evaluating commonsenseqa :  52%|█████▏    | 104/200 [2:09:39<1:57:49, 73.64s/it]Evaluating commonsenseqa :  86%|████████▌ | 171/200 [5:19:19<54:32, 112.84s/it]Evaluating commonsenseqa :  25%|██▌       | 50/200 [1:26:46<4:22:36, 105.04s/it]Evaluating commonsenseqa :  76%|███████▋  | 153/200 [3:28:18<58:54, 75.20s/it]  Evaluating commonsenseqa :  52%|█████▎    | 105/200 [2:10:54<1:57:16, 74.07s/it]Evaluating commonsenseqa :  86%|████████▌ | 172/200 [5:21:12<52:45, 113.05s/it]Evaluating commonsenseqa :  58%|█████▊    | 116/200 [4:21:03<3:15:32, 139.67s/it]Evaluating commonsenseqa :  53%|█████▎    | 106/200 [2:12:10<1:56:55, 74.63s/it]Evaluating commonsenseqa :  26%|██▌       | 51/200 [1:28:38<4:26:00, 107.12s/it]Evaluating commonsenseqa :  77%|███████▋  | 154/200 [3:29:47<1:00:48, 79.32s/it]Evaluating commonsenseqa :  54%|█████▎    | 107/200 [2:13:26<1:55:54, 74.78s/it]Evaluating commonsenseqa :  86%|████████▋ | 173/200 [5:23:03<50:34, 112.38s/it]Evaluating commonsenseqa :  78%|███████▊  | 155/200 [3:31:17<1:01:53, 82.51s/it]Evaluating commonsenseqa :  58%|█████▊    | 117/200 [4:23:04<3:05:20, 133.98s/it]Evaluating commonsenseqa :  26%|██▌       | 52/200 [1:30:28<4:26:15, 107.94s/it]Evaluating commonsenseqa :  59%|█████▉    | 118/200 [4:23:43<2:24:15, 105.56s/it]Evaluating commonsenseqa :  54%|█████▍    | 108/200 [2:14:40<1:54:37, 74.76s/it]Evaluating commonsenseqa :  78%|███████▊  | 156/200 [3:32:45<1:01:35, 83.98s/it]Evaluating commonsenseqa :  87%|████████▋ | 174/200 [5:24:56<48:48, 112.64s/it]Evaluating commonsenseqa :  55%|█████▍    | 109/200 [2:15:56<1:53:45, 75.01s/it]Evaluating commonsenseqa :  26%|██▋       | 53/200 [1:32:21<4:28:06, 109.43s/it]Evaluating commonsenseqa :  78%|███████▊  | 157/200 [3:34:12<1:00:54, 84.98s/it]Evaluating commonsenseqa :  60%|█████▉    | 119/200 [4:26:04<2:36:46, 116.13s/it]Evaluating commonsenseqa :  55%|█████▌    | 110/200 [2:17:11<1:52:48, 75.21s/it]Evaluating commonsenseqa :  88%|████████▊ | 175/200 [5:26:48<46:46, 112.27s/it]Evaluating commonsenseqa :  79%|███████▉  | 158/200 [3:35:15<54:56, 78.48s/it]  Evaluating commonsenseqa :  27%|██▋       | 54/200 [1:34:13<4:28:43, 110.44s/it]Evaluating commonsenseqa :  80%|███████▉  | 159/200 [3:35:51<44:52, 65.68s/it]Evaluating commonsenseqa :  56%|█████▌    | 111/200 [2:18:26<1:51:28, 75.15s/it]Evaluating commonsenseqa :  60%|██████    | 120/200 [4:28:23<2:44:07, 123.09s/it]Evaluating commonsenseqa :  88%|████████▊ | 176/200 [5:28:43<45:17, 113.21s/it]Evaluating commonsenseqa :  28%|██▊       | 55/200 [1:35:56<4:21:22, 108.15s/it]Evaluating commonsenseqa :  56%|█████▌    | 112/200 [2:19:41<1:50:05, 75.06s/it]Evaluating commonsenseqa :  80%|████████  | 160/200 [3:37:20<48:20, 72.52s/it]Evaluating commonsenseqa :  56%|█████▋    | 113/200 [2:20:56<1:48:33, 74.87s/it]Evaluating commonsenseqa :  88%|████████▊ | 177/200 [5:30:34<43:09, 112.57s/it]Evaluating commonsenseqa :  80%|████████  | 161/200 [3:38:48<50:14, 77.29s/it]Evaluating commonsenseqa :  28%|██▊       | 56/200 [1:37:46<4:20:25, 108.51s/it]Evaluating commonsenseqa :  60%|██████    | 121/200 [4:30:44<2:48:52, 128.26s/it]Evaluating commonsenseqa :  57%|█████▋    | 114/200 [2:22:11<1:47:23, 74.93s/it]Evaluating commonsenseqa :  81%|████████  | 162/200 [3:40:12<50:12, 79.27s/it]Evaluating commonsenseqa :  89%|████████▉ | 178/200 [5:32:26<41:08, 112.20s/it]Evaluating commonsenseqa :  28%|██▊       | 57/200 [1:39:39<4:22:10, 110.00s/it]Evaluating commonsenseqa :  57%|█████▊    | 115/200 [2:23:25<1:46:01, 74.84s/it]Evaluating commonsenseqa :  61%|██████    | 122/200 [4:33:04<2:51:17, 131.76s/it]Evaluating commonsenseqa :  82%|████████▏ | 163/200 [3:41:42<50:54, 82.56s/it]Evaluating commonsenseqa :  58%|█████▊    | 116/200 [2:24:41<1:44:56, 74.96s/it]Evaluating commonsenseqa :  90%|████████▉ | 179/200 [5:34:18<39:18, 112.30s/it]Evaluating commonsenseqa :  29%|██▉       | 58/200 [1:41:30<4:21:07, 110.34s/it]Evaluating commonsenseqa :  82%|████████▏ | 164/200 [3:43:03<49:16, 82.12s/it]Evaluating commonsenseqa :  58%|█████▊    | 117/200 [2:25:56<1:43:38, 74.93s/it]Evaluating commonsenseqa :  62%|██████▏   | 123/200 [4:35:25<2:52:51, 134.69s/it]Evaluating commonsenseqa :  90%|█████████ | 180/200 [5:36:11<37:29, 112.48s/it]Evaluating commonsenseqa :  30%|██▉       | 59/200 [1:43:20<4:18:55, 110.18s/it]Evaluating commonsenseqa :  82%|████████▎ | 165/200 [3:44:33<49:11, 84.33s/it]Evaluating commonsenseqa :  59%|█████▉    | 118/200 [2:27:10<1:42:09, 74.75s/it]Evaluating commonsenseqa :  62%|██████▏   | 124/200 [4:37:08<2:38:33, 125.17s/it]Evaluating commonsenseqa :  60%|█████▉    | 119/200 [2:28:25<1:41:04, 74.87s/it]Evaluating commonsenseqa :  83%|████████▎ | 166/200 [3:46:02<48:32, 85.67s/it]Evaluating commonsenseqa :  90%|█████████ | 181/200 [5:38:05<35:45, 112.92s/it]Evaluating commonsenseqa :  30%|███       | 60/200 [1:45:11<4:17:51, 110.51s/it]Evaluating commonsenseqa :  60%|██████    | 120/200 [2:29:41<1:40:06, 75.08s/it]Evaluating commonsenseqa :  84%|████████▎ | 167/200 [3:47:21<46:05, 83.79s/it]Evaluating commonsenseqa :  62%|██████▎   | 125/200 [4:39:27<2:41:39, 129.32s/it]Evaluating commonsenseqa :  30%|███       | 61/200 [1:47:01<4:15:16, 110.19s/it]Evaluating commonsenseqa :  91%|█████████ | 182/200 [5:39:57<33:48, 112.70s/it]Evaluating commonsenseqa :  60%|██████    | 121/200 [2:30:55<1:38:43, 74.98s/it]Evaluating commonsenseqa :  84%|████████▍ | 168/200 [3:48:49<45:22, 85.08s/it]Evaluating commonsenseqa :  63%|██████▎   | 126/200 [4:40:52<2:22:56, 115.89s/it]Evaluating commonsenseqa :  61%|██████    | 122/200 [2:32:11<1:37:48, 75.23s/it]Evaluating commonsenseqa :  31%|███       | 62/200 [1:48:50<4:12:24, 109.74s/it]Evaluating commonsenseqa :  92%|█████████▏| 183/200 [5:41:48<31:45, 112.10s/it]Evaluating commonsenseqa :  84%|████████▍ | 169/200 [3:50:20<44:54, 86.92s/it]Evaluating commonsenseqa :  32%|███▏      | 63/200 [1:49:22<3:17:33, 86.53s/it] Evaluating commonsenseqa :  64%|██████▎   | 127/200 [4:42:12<2:08:02, 105.24s/it]Evaluating commonsenseqa :  62%|██████▏   | 123/200 [2:33:27<1:36:38, 75.31s/it]Evaluating commonsenseqa :  85%|████████▌ | 170/200 [3:51:46<43:21, 86.71s/it]Evaluating commonsenseqa :  92%|█████████▏| 184/200 [5:43:39<29:50, 111.93s/it]Evaluating commonsenseqa :  62%|██████▏   | 124/200 [2:34:42<1:35:18, 75.24s/it]Evaluating commonsenseqa :  64%|██████▍   | 128/200 [4:43:57<2:06:15, 105.21s/it]Evaluating commonsenseqa :  32%|███▏      | 64/200 [1:51:15<3:34:26, 94.60s/it]Evaluating commonsenseqa :  86%|████████▌ | 171/200 [3:52:30<35:41, 73.85s/it]Evaluating commonsenseqa :  86%|████████▌ | 172/200 [3:52:53<27:20, 58.61s/it]Evaluating commonsenseqa :  62%|██████▎   | 125/200 [2:35:57<1:33:54, 75.12s/it]Evaluating commonsenseqa :  64%|██████▍   | 129/200 [4:45:12<1:53:36, 96.01s/it] Evaluating commonsenseqa :  92%|█████████▎| 185/200 [5:45:31<27:57, 111.86s/it]Evaluating commonsenseqa :  86%|████████▋ | 173/200 [3:53:55<26:49, 59.62s/it]Evaluating commonsenseqa :  32%|███▎      | 65/200 [1:53:04<3:42:25, 98.86s/it]Evaluating commonsenseqa :  63%|██████▎   | 126/200 [2:37:11<1:32:33, 75.05s/it]Evaluating commonsenseqa :  87%|████████▋ | 174/200 [3:55:25<29:40, 68.50s/it]Evaluating commonsenseqa :  93%|█████████▎| 186/200 [5:47:27<26:22, 113.04s/it]Evaluating commonsenseqa :  65%|██████▌   | 130/200 [4:47:32<2:07:30, 109.29s/it]Evaluating commonsenseqa :  64%|██████▎   | 127/200 [2:38:27<1:31:29, 75.20s/it]Evaluating commonsenseqa :  33%|███▎      | 66/200 [1:54:56<3:49:33, 102.79s/it]Evaluating commonsenseqa :  66%|██████▌   | 131/200 [4:48:26<1:46:35, 92.69s/it] Evaluating commonsenseqa :  88%|████████▊ | 175/200 [3:56:52<30:57, 74.31s/it]Evaluating commonsenseqa :  64%|██████▍   | 128/200 [2:39:41<1:29:55, 74.94s/it]Evaluating commonsenseqa :  94%|█████████▎| 187/200 [5:49:20<24:30, 113.11s/it]Evaluating commonsenseqa :  34%|███▎      | 67/200 [1:56:48<3:53:45, 105.46s/it]Evaluating commonsenseqa :  66%|██████▌   | 132/200 [4:49:39<1:38:25, 86.85s/it]Evaluating commonsenseqa :  88%|████████▊ | 176/200 [3:58:19<31:14, 78.10s/it]Evaluating commonsenseqa :  64%|██████▍   | 129/200 [2:40:56<1:28:38, 74.91s/it]Evaluating commonsenseqa :  66%|██████▋   | 133/200 [4:50:21<1:21:45, 73.22s/it]Evaluating commonsenseqa :  34%|███▍      | 68/200 [1:58:13<3:38:38, 99.39s/it] Evaluating commonsenseqa :  94%|█████████▍| 188/200 [5:51:14<22:39, 113.32s/it]Evaluating commonsenseqa :  65%|██████▌   | 130/200 [2:42:12<1:27:36, 75.10s/it]Evaluating commonsenseqa :  88%|████████▊ | 177/200 [3:59:48<31:09, 81.28s/it]Evaluating commonsenseqa :  34%|███▍      | 69/200 [1:59:36<3:25:58, 94.34s/it]Evaluating commonsenseqa :  89%|████████▉ | 178/200 [4:00:53<27:59, 76.33s/it]Evaluating commonsenseqa :  66%|██████▌   | 131/200 [2:43:28<1:26:38, 75.34s/it]Evaluating commonsenseqa :  67%|██████▋   | 134/200 [4:52:40<1:42:31, 93.21s/it]Evaluating commonsenseqa :  35%|███▌      | 70/200 [2:00:09<2:44:50, 76.08s/it]Evaluating commonsenseqa :  94%|█████████▍| 189/200 [5:53:07<20:46, 113.33s/it]Evaluating commonsenseqa :  66%|██████▌   | 132/200 [2:44:43<1:25:24, 75.36s/it]Evaluating commonsenseqa :  90%|████████▉ | 179/200 [4:02:21<28:00, 80.02s/it]Evaluating commonsenseqa :  36%|███▌      | 71/200 [2:01:58<3:05:04, 86.08s/it]Evaluating commonsenseqa :  95%|█████████▌| 190/200 [5:55:02<18:58, 113.83s/it]Evaluating commonsenseqa :  68%|██████▊   | 135/200 [4:55:02<1:56:42, 107.73s/it]Evaluating commonsenseqa :  66%|██████▋   | 133/200 [2:45:59<1:24:15, 75.45s/it]Evaluating commonsenseqa :  90%|█████████ | 180/200 [4:03:47<27:12, 81.63s/it]Evaluating commonsenseqa :  67%|██████▋   | 134/200 [2:47:14<1:23:03, 75.50s/it]Evaluating commonsenseqa :  36%|███▌      | 72/200 [2:03:51<3:20:26, 93.96s/it]Evaluating commonsenseqa :  96%|█████████▌| 191/200 [5:56:55<17:01, 113.45s/it]Evaluating commonsenseqa :  90%|█████████ | 181/200 [4:05:16<26:34, 83.91s/it]Evaluating commonsenseqa :  68%|██████▊   | 136/200 [4:57:27<2:06:55, 118.99s/it]Evaluating commonsenseqa :  68%|██████▊   | 135/200 [2:48:29<1:21:39, 75.38s/it]Evaluating commonsenseqa :  91%|█████████ | 182/200 [4:06:45<25:37, 85.41s/it]Evaluating commonsenseqa :  36%|███▋      | 73/200 [2:05:43<3:30:33, 99.48s/it]Evaluating commonsenseqa :  96%|█████████▌| 192/200 [5:58:48<15:06, 113.33s/it]Evaluating commonsenseqa :  68%|██████▊   | 136/200 [2:49:44<1:20:13, 75.21s/it]Evaluating commonsenseqa :  92%|█████████▏| 183/200 [4:07:38<21:27, 75.76s/it]Evaluating commonsenseqa :  68%|██████▊   | 137/200 [4:59:46<2:11:12, 124.96s/it]Evaluating commonsenseqa :  92%|█████████▏| 184/200 [4:08:25<17:54, 67.13s/it]Evaluating commonsenseqa :  68%|██████▊   | 137/200 [2:51:00<1:19:04, 75.31s/it]Evaluating commonsenseqa :  37%|███▋      | 74/200 [2:07:33<3:35:22, 102.56s/it]Evaluating commonsenseqa :  96%|█████████▋| 193/200 [6:00:38<13:06, 112.33s/it]Evaluating commonsenseqa :  69%|██████▉   | 138/200 [2:52:15<1:17:50, 75.33s/it]Evaluating commonsenseqa :  92%|█████████▎| 185/200 [4:09:52<18:14, 72.97s/it]Evaluating commonsenseqa :  97%|█████████▋| 194/200 [6:01:44<09:50, 98.46s/it] Evaluating commonsenseqa :  38%|███▊      | 75/200 [2:09:04<3:26:49, 99.27s/it] Evaluating commonsenseqa :  69%|██████▉   | 138/200 [5:02:09<2:14:42, 130.37s/it]Evaluating commonsenseqa :  70%|██████▉   | 139/200 [2:53:30<1:16:35, 75.33s/it]Evaluating commonsenseqa :  93%|█████████▎| 186/200 [4:11:22<18:15, 78.24s/it]Evaluating commonsenseqa :  98%|█████████▊| 195/200 [6:03:38<08:36, 103.25s/it]Evaluating commonsenseqa :  38%|███▊      | 76/200 [2:10:56<3:33:02, 103.09s/it]Evaluating commonsenseqa :  70%|██████▉   | 139/200 [5:03:51<2:03:52, 121.85s/it]Evaluating commonsenseqa :  70%|███████   | 140/200 [2:54:46<1:15:15, 75.26s/it]Evaluating commonsenseqa :  94%|█████████▎| 187/200 [4:12:52<17:42, 81.70s/it]Evaluating commonsenseqa :  70%|███████   | 140/200 [5:04:59<1:45:36, 105.60s/it]Evaluating commonsenseqa :  70%|███████   | 141/200 [2:56:01<1:14:01, 75.29s/it]Evaluating commonsenseqa :  98%|█████████▊| 196/200 [6:05:28<07:01, 105.31s/it]Evaluating commonsenseqa :  38%|███▊      | 77/200 [2:12:48<3:36:45, 105.74s/it]Evaluating commonsenseqa :  94%|█████████▍| 188/200 [4:14:21<16:46, 83.90s/it]Evaluating commonsenseqa :  70%|███████   | 141/200 [5:06:15<1:35:07, 96.73s/it] Evaluating commonsenseqa :  71%|███████   | 142/200 [2:57:17<1:12:54, 75.43s/it]Evaluating commonsenseqa :  98%|█████████▊| 197/200 [6:07:23<05:24, 108.11s/it]Evaluating commonsenseqa :  39%|███▉      | 78/200 [2:14:38<3:37:21, 106.90s/it]Evaluating commonsenseqa :  94%|█████████▍| 189/200 [4:15:50<15:40, 85.47s/it]Evaluating commonsenseqa :  72%|███████▏  | 143/200 [2:58:31<1:11:23, 75.16s/it]Evaluating commonsenseqa :  71%|███████   | 142/200 [5:08:34<1:45:50, 109.49s/it]Evaluating commonsenseqa :  95%|█████████▌| 190/200 [4:16:56<13:15, 79.54s/it]Evaluating commonsenseqa :  72%|███████▏  | 144/200 [2:59:46<1:10:08, 75.16s/it]Evaluating commonsenseqa :  99%|█████████▉| 198/200 [6:09:16<03:38, 109.40s/it]Evaluating commonsenseqa :  40%|███▉      | 79/200 [2:16:28<3:37:38, 107.92s/it]Evaluating commonsenseqa :  96%|█████████▌| 191/200 [4:18:25<12:21, 82.36s/it]Evaluating commonsenseqa :  72%|███████▎  | 145/200 [3:01:01<1:08:50, 75.10s/it]Evaluating commonsenseqa :  72%|███████▏  | 143/200 [5:10:54<1:52:34, 118.51s/it]Evaluating commonsenseqa : 100%|█████████▉| 199/200 [6:11:09<01:50, 110.48s/it]Evaluating commonsenseqa :  40%|████      | 80/200 [2:18:20<3:38:01, 109.01s/it]Evaluating commonsenseqa :  73%|███████▎  | 146/200 [3:02:16<1:07:26, 74.93s/it]Evaluating commonsenseqa :  96%|█████████▌| 192/200 [4:19:54<11:15, 84.38s/it]Evaluating commonsenseqa :  74%|███████▎  | 147/200 [3:03:31<1:06:22, 75.14s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [6:13:01<00:00, 110.95s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [6:13:01<00:00, 111.91s/it]
name: commonsenseqa | avg. gen lenth: 326.012 | time: 22383.788709640503s
Evaluating commonsenseqa :  40%|████      | 81/200 [2:20:12<3:38:01, 109.93s/it]python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10138 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o7-tmathqa-s20-rTrue --seed 20 --max-prompt-length 4096 --rationales --num-out-domain 7 5 7 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2023-09-20 07:39:42,464] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Evaluating commonsenseqa :  96%|█████████▋| 193/200 [4:21:24<10:01, 85.93s/it]using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o7-tmathqa-s20-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 7
  out_domain_data_name ......... mathqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o7-tmathqa-s20-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 368460.25it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Evaluating commonsenseqa :  72%|███████▏  | 144/200 [5:13:14<1:56:38, 124.97s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.43s/it]
 > number of parameters: 6738415616
[2023-09-20 07:39:59,301] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.3, git-hash=unknown, git-branch=unknown
[2023-09-20 07:39:59,301] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-09-20 07:39:59,721] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-20 07:39:59,723] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2023-09-20 07:39:59,723] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-20 07:39:59,723] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-20 07:39:59,723] [INFO] [config.py:971:print]   amp_enabled .................. False
[2023-09-20 07:39:59,723] [INFO] [config.py:971:print]   amp_params ................... False
[2023-09-20 07:39:59,724] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-20 07:39:59,724] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2023-09-20 07:39:59,724] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2023-09-20 07:39:59,724] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2023-09-20 07:39:59,724] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2023-09-20 07:39:59,724] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fe7bc822d10>
[2023-09-20 07:39:59,724] [INFO] [config.py:971:print]   communication_data_type ...... None
[2023-09-20 07:39:59,724] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-20 07:39:59,724] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2023-09-20 07:39:59,724] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2023-09-20 07:39:59,724] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-20 07:39:59,724] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2023-09-20 07:39:59,724] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2023-09-20 07:39:59,724] [INFO] [config.py:971:print]   disable_allgather ............ False
[2023-09-20 07:39:59,724] [INFO] [config.py:971:print]   dump_state ................... False
[2023-09-20 07:39:59,724] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-20 07:39:59,724] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2023-09-20 07:39:59,724] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-20 07:39:59,724] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-20 07:39:59,724] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2023-09-20 07:39:59,724] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2023-09-20 07:39:59,724] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2023-09-20 07:39:59,724] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2023-09-20 07:39:59,724] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2023-09-20 07:39:59,724] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2023-09-20 07:39:59,724] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-20 07:39:59,724] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   global_rank .................. 0
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   gradient_clipping ............ 0.0
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 2048
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   loss_scale ................... 0
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   optimizer_name ............... None
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   optimizer_params ............. None
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   pld_enabled .................. False
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   pld_params ................... False
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   scheduler_name ............... None
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   scheduler_params ............. None
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   sparse_attention ............. None
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   train_batch_size ............. 1
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  1
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   world_size ................... 1
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  True
[2023-09-20 07:39:59,725] [INFO] [config.py:971:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2023-09-20 07:39:59,726] [INFO] [config.py:971:print]   zero_enabled ................. False
[2023-09-20 07:39:59,726] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-20 07:39:59,726] [INFO] [config.py:971:print]   zero_optimization_stage ...... 0
[2023-09-20 07:39:59,726] [INFO] [config.py:957:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/200 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: a man cycling along the road noticed that every 18 minutes a bus overtakes him and every 6 minutes he meets an oncoming bus. if all buses and the cyclist move at a constant speed, what is the time interval between consecutive buses? a ) 5 minutes, b ) 6 minutes, c ) 8 minutes, d ) 9 minutes, e ) 10 minutes
Output: let's say the distance between the buses is d. we want to determine interval = \ frac { d } { b }, where b is the speed of bus. let the speed of cyclist be c. every 18 minutes a bus overtakes cyclist : \ frac { d } { b - c } = 18, d = 18 b - 18 c ; every 6 minutes cyclist meets an oncoming bus : \ frac { d } { b + c } = 6, d = 6 b + 6 c ; d = 18 b - 18 c = 6 b + 6 c, - - > b = 2 c, - - > d = 18 b - 9 b = 9 b. interval = \ frac { d } { b } = \ frac { 9 b } { b } = 9 answer : d ( 9 minutes ).
So the final answer is d

Input: an athlete runs 200 metres race in 24 seconds. what is his speed? a ) 20 km / hr, b ) 30 km / hr, c ) 25 km / hr, d ) 35 km / hr, e ) 40 km / hr
Output: speed = dist / time = 200 / 24 200 / 24 * 18 / 5 = 40 * 3 / 4 = 30 km / hr answer b
So the final answer is b

Input: two numbers are in the ratio 3 : 4. if the sum of numbers is 63, find the numbers. a ) 27 and 36., b ) 25 and 30., c ) 23 and 44., d ) 63 and 12., e ) 12 and 36.
Output: "sum of the terms of the ratio = 3 + 4 = 7 sum of numbers = 63 therefore, first number = 3 / 7 × 63 = 27 second number = 4 / 7 × 63 = 36 therefore, the two numbers are 27 and 36. answer is a"
So the final answer is a

Input: a company wants to spend equal amounts of money for the purchase of two types of computer printers costing $ 375 and $ 150 per unit, respectively. what is the fewest number of computer printers that the company can purchase? a ) 3, b ) 4, c ) 5, d ) 6, e ) 7
Output: the smallest amount that the company can spend is the lcm of 375 and 150, which is 750 for each, which is total 1500. the number of 1 st type of computers which costing $ 375 = 750 / 375 = 2. the number of 2 nd type of computers which costing $ 150 = 750 / 150 = 5. total = 2 + 5 = 7 answer is e.
So the final answer is e

Input: a certain music store stocks 800 cellos and 600 violas. of these instruments, there are 80 cello - viola pairs, such that a cello and a viola were both made with wood from the same tree ( each tree can make at most one viola and one cello, so there are no pairs other than these 90 ). if one viola and one cello are chosen at random, what is the probability that the two instruments are made with wood from the same tree? a ) 3 / 16,000, b ) 1 / 8,100, c ) 1 / 600, d ) 1 / 90, e ) 2 / 45
Output: "solution provided by stanford 2012 is correct : 80 / 800 choosing one of the cellos which has a pair viola, 1 / 600 choosing the viola which is the pair of chosen cello - - > p = 80 / 800 * 1 / 600 = 1 / 6,000. answer : c."
So the final answer is c

Input: what is the difference between local value & face value of 7 in the numeral 65793? a ) 693, b ) 656, c ) 691, d ) 9890, e ) 10000
Output: ( local value of 7 ) - ( face value of 7 ) = ( 700 - 7 ) = 693 a
So the final answer is a

Input: in an office in singapore there are 60 % female employees. 50 % of all the male employees are computer literate. if there are total 62 % employees computer literate out of total 1100 employees, then the no. of female employees who are computer literate? a ) 462, b ) 674, c ) 672, d ) 960, e ) none
Output: "solution : total employees, = 1100 female employees, 60 % of 1100. = ( 60 * 1100 ) / 100 = 660. then male employees, = 440 50 % of male are computer literate, = 220 male computer literate. 62 % of total employees are computer literate, = ( 62 * 1100 ) / 100 = 682 computer literate. thus, female computer literate = 682 - 220 = 462. answer : option a"
So the final answer is a

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o7-tmathqa-s20-rTrue-m4096
Evaluating commonsenseqa :  74%|███████▍  | 148/200 [3:04:47<1:05:17, 75.33s/it]Evaluating commonsenseqa :  97%|█████████▋| 194/200 [4:22:27<07:54, 79.09s/it]Evaluating commonsenseqa :   0%|          | 1/200 [01:28<4:54:27, 88.78s/it]Evaluating commonsenseqa :  41%|████      | 82/200 [2:22:05<3:38:10, 110.93s/it]Evaluating commonsenseqa :  74%|███████▍  | 149/200 [3:06:02<1:04:00, 75.30s/it]Evaluating commonsenseqa :  72%|███████▎  | 145/200 [5:15:33<1:58:37, 129.41s/it]Evaluating commonsenseqa :  98%|█████████▊| 195/200 [4:23:55<06:49, 81.99s/it]Evaluating commonsenseqa :  98%|█████████▊| 196/200 [4:24:46<04:50, 72.58s/it]Evaluating commonsenseqa :  75%|███████▌  | 150/200 [3:07:18<1:02:50, 75.41s/it]Evaluating commonsenseqa :  42%|████▏     | 83/200 [2:23:44<3:29:22, 107.37s/it]Evaluating commonsenseqa :   1%|          | 2/200 [03:12<5:22:43, 97.80s/it]Evaluating commonsenseqa :  76%|███████▌  | 151/200 [3:08:33<1:01:26, 75.24s/it]Evaluating commonsenseqa :  98%|█████████▊| 197/200 [4:26:03<03:41, 73.98s/it]Evaluating commonsenseqa :  73%|███████▎  | 146/200 [5:17:52<1:58:56, 132.16s/it]Evaluating commonsenseqa :   2%|▏         | 3/200 [04:52<5:24:01, 98.69s/it]Evaluating commonsenseqa :  42%|████▏     | 84/200 [2:25:37<3:30:36, 108.93s/it]Evaluating commonsenseqa :  99%|█████████▉| 198/200 [4:27:09<02:22, 71.35s/it]Evaluating commonsenseqa :  76%|███████▌  | 152/200 [3:09:48<1:00:02, 75.06s/it]Evaluating commonsenseqa :   2%|▏         | 4/200 [06:32<5:24:12, 99.25s/it]Evaluating commonsenseqa :  42%|████▎     | 85/200 [2:27:19<3:24:58, 106.94s/it]Evaluating commonsenseqa :  74%|███████▎  | 147/200 [5:20:10<1:58:15, 133.88s/it]Evaluating commonsenseqa :  76%|███████▋  | 153/200 [3:11:04<59:03, 75.40s/it]  Evaluating commonsenseqa : 100%|█████████▉| 199/200 [4:28:38<01:16, 76.89s/it]Evaluating commonsenseqa :  77%|███████▋  | 154/200 [3:12:19<57:45, 75.33s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [4:29:49<00:00, 74.87s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [4:29:49<00:00, 80.95s/it]
name: commonsenseqa | avg. gen lenth: 241.15 | time: 16190.565212488174s
Evaluating commonsenseqa :   2%|▎         | 5/200 [08:13<5:23:46, 99.62s/it]python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10136 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o17-tmathqa-s10-rTrue --seed 10 --max-prompt-length 4096 --rationales --num-out-domain 17 17 19 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2023-09-20 07:48:18,650] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o17-tmathqa-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 17
  out_domain_data_name ......... mathqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o17-tmathqa-s10-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 245295.81it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.07s/it]
 > number of parameters: 6738415616
[2023-09-20 07:48:31,742] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.3, git-hash=unknown, git-branch=unknown
[2023-09-20 07:48:31,742] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-09-20 07:48:32,083] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-20 07:48:32,084] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   amp_enabled .................. False
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   amp_params ................... False
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fb2e2a2ada0>
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   communication_data_type ...... None
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   disable_allgather ............ False
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   dump_state ................... False
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   global_rank .................. 0
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   gradient_clipping ............ 0.0
[2023-09-20 07:48:32,085] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 2048
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   loss_scale ................... 0
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   optimizer_name ............... None
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   optimizer_params ............. None
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   pld_enabled .................. False
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   pld_params ................... False
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   scheduler_name ............... None
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   scheduler_params ............. None
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   sparse_attention ............. None
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   train_batch_size ............. 1
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  1
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   world_size ................... 1
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  True
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   zero_enabled ................. False
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-20 07:48:32,086] [INFO] [config.py:971:print]   zero_optimization_stage ...... 0
[2023-09-20 07:48:32,086] [INFO] [config.py:957:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/200 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: in a recent head - to - head run - off election, 12000 absentee ballets were cast. 1 / 6 of the absentee ballets were thrown out and 3 / 5 of the remaining absentee ballets were cast for candidate a. how many absentee votes did candidate b receive? a ) 2,000, b ) 3,000, c ) 4,000, d ) 8,000, e ) 9,000
Output: 5 / 6 * 2 / 5 ( total absentee votes ) = 1 / 3 ( total votes ) = 1 / 3 * 12000 = 4000 answer is c
So the final answer is c

Input: the total age of a and b is 11 years more than the total age of b and c. c is how many years younger than a.? a ) 16, b ) 12, c ) 11, d ) 20, e ) 10
Output: "( a + b ) - ( b - c ) = 11 a - c = 11 answer is c"
So the final answer is c

Input: the scoring system in a certain football competition goes as follows : 3 points for victory, 1 point for a draw, and 0 points for defeat. each team plays 20 matches. if a team scored 14 points after 5 games, what is the least number of the remaining matches it has to win to reach the 40 - point mark by the end of the tournament? a ) 6, b ) 7, c ) 8, d ) 9, e ) 10
Output: "to get 40 points as end of season we need another 26 points or more from remaining 15 matches : option a = 6 * 3 + 9 * 1 = 27 hence option a - 6"
So the final answer is a

Input: how much water should be added to 10 liters of a 20 % - solution of alcohol to reduce the concentration of alcohol in the solution by 75 %? a ) 25 liters, b ) 27 liters, c ) 30 liters, d ) 32 liters, e ) 35 liters
Output: "let x ltr water to be added 2 ltr alcohol to be represented as ( 20 ( 1 - 3 / 4 ( new soln. = 10 + x ) ) ) 2 = 5 % * ( 10 + x ) - - - - - - - - > x = 30 answer : c"
So the final answer is c

Input: a goods train runs at the speed of 72 kmph and crosses a 250 m long platform in 36 seconds. what is the length of the goods train? a ) 470 m, b ) 240 m, c ) 260 m, d ) 270 m, e ) none of these
Output: "explanation : speed = [ 72 x ( 5 / 18 ) ] m / sec = 20 m / sec. time = 36 sec. let the length of the train be x metres. then, [ ( x + 250 ) / 36 ] = 20 = > x + 250 = 720 = > x = 470. answer : a"
So the final answer is a

Input: the volume of a cube is 1728 cc. find its surface. a ) 864, b ) 556, c ) 255, d ) 287, e ) 267
Output: "a 3 = 1728 = > a = 12 6 a 2 = 6 * 12 * 12 = 864 answer : a"
So the final answer is a

Input: a certain drink of type a is prepared by mixing 4 parts milk with 3 parts fruit juice. another drink of type b is prepared by mixing 4 parts of fruit juice and 3 parts of milk. how many liters of fruit juice must be added to 63 liters of drink a to convert it to drink b? a ) 7, b ) 14, c ) 21, d ) 28, e ) 35
Output: "in 63 liters of drink a, there are 36 liters of milk and 27 liters of juice. with 36 liters of milk, we need a total of 48 liters of juice to make drink b. we need to add 21 liters of juice. the answer is c."
So the final answer is c

Input: last week john spent 10 percent of his wages on recreation. this week, his wages are 10 percent less than last week ʼ s wages and he spent 40 percent of his wages on recreation. the amount he spends on recreation this week is what percent of the amount he spent on recreation last week a ) 180 %, b ) 360 %, c ) 200 %, d ) 220 %, e ) 250 %
Output: "say john's wages last week were $ 100, so he spent 0.10 * 100 = $ 10 on recreation ; this week's wages is 0.90 * 100 = $ 90, so he spends 0.4 * 90 = $ 36 on recreation ; 36 / 10 = 3.60, hence the amount he spends on recreation this week is 360 % of the amount he spent on recreation last week : 10 * 3.6 = 36 answer : b"
So the final answer is b

Input: the salary of a person was reduced by 15 %. by what percent should his reduced salary be raised so as to bring it at par with his original salary? a ) 10 %, b ) 17.6 %, c ) 13.7 %, d ) 15.1 %, e ) 12.3 %
Output: "let the original salary be $ 100 new salary = $ 85 increase on 85 = 15 increase on 100 = 15 / 85 * 100 = 17.6 % answer is b"
So the final answer is b

Input: if 20 men can build a water fountain 56 metres long in 7 days, what length of a similar water fountain can be built by 35 men in 3 days? a ) 40 m, b ) 42 m, c ) 47 m, d ) 49 m, e ) 50 m
Output: "explanation : let the required length be x metres more men, more length built ( direct proportion ) less days, less length built ( direct proportion ) men 20 : 35 days 7 : 3 : : 56 : x therefore ( 20 x 7 x x ) = ( 35 x 3 x 56 ) x = ( 35 x 3 x 56 ) / 140 = 42 hence, the required length is 42 m. answer : b"
So the final answer is b

Input: 12 men complete a work in 9 days. after they have worked for 6 days, 6 more men join them. how many days will they take to complete the remaining work? a ) 2 days, b ) 7 days, c ) 8 days, d ) 9 days, e ) 45 days
Output: 1 man's 1 day work = 1 / 108 12 men's 6 day's work = 1 / 9 * 6 = 2 / 3 remaining work = 1 - 2 / 3 = 1 / 3 18 men's 1 day work = 1 / 108 * 18 = 1 / 6 1 / 6 work is done by them in 1 day. 1 / 3 work is done by them in 6 * 1 / 3 = 2 days. answer : a
So the final answer is a

Input: a cheese factory sells its cheese in rectangular blocks. a normal block has a volume of 5 cubic feet. if a large block has twice the width, twice the depth, and the same length of a normal block, what is the volume of cheese in a large block in cubic feet? a ) 15, b ) 30, c ) 20, d ) 18, e ) 25
Output: "volume of cube = lbh = 5 new cube l, b, h are increases of l, 2 b, 2 h new volume of cube = l * 2 b * 2 h = 4 * lbh = 4 * 5 = 20 answer : c"
So the final answer is c

Input: two trains, one from howrah to patna and the other from patna to howrah, start simultaneously. after they meet, the trains reach their destinations after 64 hours and 25 hours respectively. the ratio of their speeds is? a ) 4 : 9, b ) 4 : 3, c ) 4 : 5, d ) 5 : 8, e ) 4 : 2
Output: "let us name the trains a and b. then, ( a's speed ) : ( b's speed ) = √ b : √ a = √ 25 : √ 64 = 5 : 8 answer : d"
So the final answer is d

Input: john had a stock of 1400 books in his bookshop. he sold 62 on monday, 62 on tuesday, 60 on wednesday, 48 on thursday and 40 on friday. what percentage of the books were not sold? a ) 81.57 %, b ) 36.5 %, c ) 80.67 %, d ) 56.5 %, e ) 80.57 %
Output: "let n be the total number of books sold. hence n = 62 + 62 + 60 + 48 + 40 = 272 let m be the books not sold m = 1400 - n = 1400 - 272 = 1128 percentage books not sold / total number of books = 1128 / 1200 = 0.81 = 80.57 % correct answer e"
So the final answer is e

Input: a and b can do a piece of work in 18 days ; band c can do it in 24 days a and c can do it in 36 days. in how many days will a, band c finish it together? a ) 15 days, b ) 12 days, c ) 8 days, d ) 16 days, e ) 9 days
Output: sol. ( a + b )'s 1 day's work = ( 1 / 18 ) ( b + c )'s 1 day's work = ( 1 / 24 ) and ( a + c )'s 1 day's work = ( 1 / 36 ) adding, we get : 2 ( a + b + c )'s 1 day's work = ¬ ( 1 / 18 + 1 / 24 + 1 / 36 ) = 9 / 72 = 1 / 8 ( a + b + c )'s 1 day's work = 1 / 16 thus, a, band c together can finish the work in 16 days. ans : d
So the final answer is d

Input: p, q and r have $ 9000 among themselves. r has two - thirds of the total amount with p and q. find the amount with r? a ) 2400, b ) 3600, c ) 3998, d ) 2539, e ) 1930
Output: "b 3600 let the amount with r be $ r r = 2 / 3 ( total amount with p and q ) r = 2 / 3 ( 9000 - r ) = > 3 r = 18000 - 2 r = > 5 r = 18000 = > r = 3600."
So the final answer is b

Input: the cost of the paint is rs. 40 per kg. if 1 kg of paint covers 20 sq. ft, how much will it cost to paint outside of a cube having 30 feet each side a ) rs. 962, b ) rs. 672, c ) rs. 546, d ) rs. 10800, e ) none of these
Output: "explanation : surface area of a cube = 6 x 30 ^ 2 = 5400 sq. ft quantity of paint required = ( 5400 / 20 ) = 270 kg cost of painting = 40 x 270 = rs. 10800 answer : d"
So the final answer is d

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o17-tmathqa-s10-rTrue-m4096
Evaluating commonsenseqa :  43%|████▎     | 86/200 [2:29:11<3:25:56, 108.39s/it]Evaluating commonsenseqa :  74%|███████▍  | 148/200 [5:22:28<1:57:04, 135.09s/it]Evaluating commonsenseqa :  78%|███████▊  | 155/200 [3:13:35<56:34, 75.44s/it]Evaluating commonsenseqa :   0%|          | 1/200 [01:07<3:43:53, 67.51s/it]Evaluating commonsenseqa :   3%|▎         | 6/200 [09:55<5:24:54, 100.49s/it]Evaluating commonsenseqa :  44%|████▎     | 87/200 [2:31:02<3:25:27, 109.09s/it]Evaluating commonsenseqa :  78%|███████▊  | 156/200 [3:14:50<55:20, 75.48s/it]Evaluating commonsenseqa :   1%|          | 2/200 [02:13<3:40:08, 66.71s/it]Evaluating commonsenseqa :  74%|███████▍  | 149/200 [5:24:48<1:56:03, 136.55s/it]Evaluating commonsenseqa :   4%|▎         | 7/200 [11:36<5:24:29, 100.88s/it]Evaluating commonsenseqa :   2%|▏         | 3/200 [03:19<3:37:57, 66.39s/it]Evaluating commonsenseqa :  78%|███████▊  | 157/200 [3:16:06<54:12, 75.64s/it]Evaluating commonsenseqa :  44%|████▍     | 88/200 [2:32:53<3:25:10, 109.91s/it]Evaluating commonsenseqa :   2%|▏         | 4/200 [04:25<3:36:23, 66.24s/it]Evaluating commonsenseqa :  79%|███████▉  | 158/200 [3:17:22<52:53, 75.56s/it]Evaluating commonsenseqa :   4%|▍         | 8/200 [13:20<5:25:16, 101.65s/it]Evaluating commonsenseqa :  75%|███████▌  | 150/200 [5:27:08<1:54:46, 137.73s/it]Evaluating commonsenseqa :   2%|▎         | 5/200 [05:31<3:34:42, 66.07s/it]Evaluating commonsenseqa :  44%|████▍     | 89/200 [2:34:46<3:24:38, 110.62s/it]Evaluating commonsenseqa :  80%|███████▉  | 159/200 [3:18:37<51:40, 75.63s/it]Evaluating commonsenseqa :   4%|▍         | 9/200 [15:03<5:25:11, 102.15s/it]Evaluating commonsenseqa :   3%|▎         | 6/200 [06:37<3:34:08, 66.23s/it]Evaluating commonsenseqa :  76%|███████▌  | 151/200 [5:28:56<1:45:03, 128.63s/it]Evaluating commonsenseqa :  80%|████████  | 160/200 [3:19:53<50:28, 75.71s/it]Evaluating commonsenseqa :  45%|████▌     | 90/200 [2:36:39<3:24:18, 111.44s/it]Evaluating commonsenseqa :   4%|▎         | 7/200 [07:43<3:32:24, 66.03s/it]Evaluating commonsenseqa :   5%|▌         | 10/200 [16:43<5:21:09, 101.42s/it]Evaluating commonsenseqa :  80%|████████  | 161/200 [3:21:09<49:11, 75.67s/it]Evaluating commonsenseqa :   4%|▍         | 8/200 [08:49<3:31:24, 66.07s/it]Evaluating commonsenseqa :  76%|███████▌  | 152/200 [5:31:07<1:43:34, 129.47s/it]Evaluating commonsenseqa :  46%|████▌     | 91/200 [2:38:32<3:22:59, 111.74s/it]Evaluating commonsenseqa :  81%|████████  | 162/200 [3:22:24<47:54, 75.64s/it]Evaluating commonsenseqa :   6%|▌         | 11/200 [18:24<5:19:25, 101.41s/it]Evaluating commonsenseqa :   4%|▍         | 9/200 [09:55<3:29:54, 65.94s/it]Evaluating commonsenseqa :  82%|████████▏ | 163/200 [3:23:40<46:36, 75.58s/it]Evaluating commonsenseqa :   5%|▌         | 10/200 [11:01<3:28:34, 65.87s/it]Evaluating commonsenseqa :  46%|████▌     | 92/200 [2:40:23<3:21:02, 111.69s/it]Evaluating commonsenseqa :   6%|▌         | 12/200 [20:07<5:19:12, 101.88s/it]Evaluating commonsenseqa :  76%|███████▋  | 153/200 [5:33:28<1:44:09, 132.97s/it]Evaluating commonsenseqa :   6%|▌         | 11/200 [12:07<3:27:43, 65.94s/it]Evaluating commonsenseqa :  82%|████████▏ | 164/200 [3:24:55<45:16, 75.45s/it]Evaluating commonsenseqa :  46%|████▋     | 93/200 [2:42:14<3:18:45, 111.46s/it]Evaluating commonsenseqa :   6%|▌         | 12/200 [13:13<3:26:44, 65.98s/it]Evaluating commonsenseqa :   6%|▋         | 13/200 [21:49<5:17:15, 101.79s/it]Evaluating commonsenseqa :  82%|████████▎ | 165/200 [3:26:11<44:02, 75.50s/it]Evaluating commonsenseqa :  77%|███████▋  | 154/200 [5:35:47<1:43:10, 134.58s/it]Evaluating commonsenseqa :   6%|▋         | 13/200 [14:19<3:25:23, 65.90s/it]Evaluating commonsenseqa :  83%|████████▎ | 166/200 [3:27:27<42:50, 75.60s/it]Evaluating commonsenseqa :  47%|████▋     | 94/200 [2:44:04<3:16:15, 111.09s/it]Evaluating commonsenseqa :   7%|▋         | 14/200 [23:31<5:15:57, 101.92s/it]Evaluating commonsenseqa :   7%|▋         | 14/200 [15:24<3:24:11, 65.87s/it]Evaluating commonsenseqa :  84%|████████▎ | 167/200 [3:28:42<41:30, 75.45s/it]Evaluating commonsenseqa :  78%|███████▊  | 155/200 [5:37:54<1:39:16, 132.37s/it]Evaluating commonsenseqa :   8%|▊         | 15/200 [16:31<3:23:41, 66.06s/it]Evaluating commonsenseqa :   8%|▊         | 15/200 [25:13<5:14:22, 101.96s/it]Evaluating commonsenseqa :  48%|████▊     | 95/200 [2:45:55<3:14:00, 110.86s/it]Evaluating commonsenseqa :  84%|████████▍ | 168/200 [3:29:58<40:27, 75.86s/it]Evaluating commonsenseqa :   8%|▊         | 16/200 [17:37<3:22:19, 65.98s/it]Evaluating commonsenseqa :  78%|███████▊  | 156/200 [5:39:55<1:34:35, 128.98s/it]Evaluating commonsenseqa :   8%|▊         | 16/200 [26:53<5:11:11, 101.47s/it]Evaluating commonsenseqa :  84%|████████▍ | 169/200 [3:31:15<39:18, 76.07s/it]Evaluating commonsenseqa :  48%|████▊     | 96/200 [2:47:45<3:12:04, 110.82s/it]Evaluating commonsenseqa :   8%|▊         | 17/200 [18:42<3:20:55, 65.88s/it]Evaluating commonsenseqa :  48%|████▊     | 97/200 [2:48:53<2:48:04, 97.91s/it] Evaluating commonsenseqa :  85%|████████▌ | 170/200 [3:32:31<37:57, 75.91s/it]Evaluating commonsenseqa :   9%|▉         | 18/200 [19:48<3:19:29, 65.76s/it]Evaluating commonsenseqa :   8%|▊         | 17/200 [28:36<5:10:39, 101.86s/it]Evaluating commonsenseqa :  78%|███████▊  | 157/200 [5:42:15<1:34:46, 132.25s/it]Evaluating commonsenseqa :  10%|▉         | 19/200 [20:53<3:18:18, 65.74s/it]Evaluating commonsenseqa :  86%|████████▌ | 171/200 [3:33:46<36:39, 75.83s/it]Evaluating commonsenseqa :  49%|████▉     | 98/200 [2:50:45<2:53:28, 102.04s/it]Evaluating commonsenseqa :   9%|▉         | 18/200 [30:20<5:10:50, 102.48s/it]Evaluating commonsenseqa :  10%|█         | 20/200 [22:00<3:17:44, 65.92s/it]Evaluating commonsenseqa :  86%|████████▌ | 172/200 [3:35:02<35:19, 75.69s/it]Evaluating commonsenseqa :  79%|███████▉  | 158/200 [5:44:32<1:33:41, 133.84s/it]Evaluating commonsenseqa :  10%|█         | 21/200 [23:05<3:16:26, 65.85s/it]Evaluating commonsenseqa :  50%|████▉     | 99/200 [2:52:36<2:56:34, 104.90s/it]Evaluating commonsenseqa :  10%|▉         | 19/200 [32:02<5:09:00, 102.43s/it]Evaluating commonsenseqa :  86%|████████▋ | 173/200 [3:36:17<34:04, 75.73s/it]Evaluating commonsenseqa :  11%|█         | 22/200 [24:11<3:14:57, 65.72s/it]Evaluating commonsenseqa :  87%|████████▋ | 174/200 [3:37:33<32:47, 75.68s/it]Evaluating commonsenseqa :  80%|███████▉  | 159/200 [5:46:51<1:32:21, 135.15s/it]Evaluating commonsenseqa :  10%|█         | 20/200 [33:47<5:09:17, 103.10s/it]Evaluating commonsenseqa :  12%|█▏        | 23/200 [25:16<3:13:33, 65.61s/it]Evaluating commonsenseqa :  50%|█████     | 100/200 [2:54:28<2:58:07, 106.88s/it]Evaluating commonsenseqa :  88%|████████▊ | 175/200 [3:38:49<31:38, 75.92s/it]Evaluating commonsenseqa :  80%|████████  | 160/200 [5:47:58<1:16:34, 114.85s/it]Evaluating commonsenseqa :  12%|█▏        | 24/200 [26:22<3:12:29, 65.62s/it]Evaluating commonsenseqa :  10%|█         | 21/200 [35:29<5:06:25, 102.71s/it]Evaluating commonsenseqa :  50%|█████     | 101/200 [2:56:19<2:58:24, 108.13s/it]Evaluating commonsenseqa :  88%|████████▊ | 176/200 [3:40:06<30:28, 76.20s/it]Evaluating commonsenseqa :  12%|█▎        | 25/200 [27:27<3:11:19, 65.60s/it]Evaluating commonsenseqa :  80%|████████  | 161/200 [5:50:18<1:19:28, 122.27s/it]Evaluating commonsenseqa :  13%|█▎        | 26/200 [28:34<3:10:54, 65.83s/it]Evaluating commonsenseqa :  11%|█         | 22/200 [37:10<5:03:09, 102.19s/it]Evaluating commonsenseqa :  88%|████████▊ | 177/200 [3:41:22<29:12, 76.18s/it]Evaluating commonsenseqa :  51%|█████     | 102/200 [2:58:08<2:57:02, 108.40s/it]Evaluating commonsenseqa :  14%|█▎        | 27/200 [29:40<3:09:44, 65.81s/it]Evaluating commonsenseqa :  89%|████████▉ | 178/200 [3:42:38<27:49, 75.91s/it]Evaluating commonsenseqa :  52%|█████▏    | 103/200 [2:59:10<2:32:33, 94.36s/it] Evaluating commonsenseqa :  81%|████████  | 162/200 [5:51:57<1:13:11, 115.55s/it]Evaluating commonsenseqa :  12%|█▏        | 23/200 [38:51<5:00:15, 101.78s/it]Evaluating commonsenseqa :  14%|█▍        | 28/200 [30:46<3:08:59, 65.93s/it]Evaluating commonsenseqa :  90%|████████▉ | 179/200 [3:43:53<26:31, 75.81s/it]Evaluating commonsenseqa :  52%|█████▏    | 104/200 [3:00:40<2:29:01, 93.15s/it]Evaluating commonsenseqa :  14%|█▍        | 29/200 [31:52<3:08:19, 66.08s/it]Evaluating commonsenseqa :  12%|█▏        | 24/200 [40:31<4:57:14, 101.33s/it]Evaluating commonsenseqa :  90%|█████████ | 180/200 [3:45:09<25:14, 75.74s/it]Evaluating commonsenseqa :  82%|████████▏ | 163/200 [5:54:17<1:15:45, 122.86s/it]Evaluating commonsenseqa :  15%|█▌        | 30/200 [32:58<3:06:37, 65.87s/it]Evaluating commonsenseqa :  52%|█████▎    | 105/200 [3:02:31<2:35:59, 98.52s/it]Evaluating commonsenseqa :  90%|█████████ | 181/200 [3:46:25<24:00, 75.79s/it]Evaluating commonsenseqa :  12%|█▎        | 25/200 [42:15<4:57:55, 102.15s/it]Evaluating commonsenseqa :  16%|█▌        | 31/200 [34:03<3:05:14, 65.77s/it]Evaluating commonsenseqa :  82%|████████▏ | 164/200 [5:56:41<1:17:24, 129.00s/it]Evaluating commonsenseqa :  91%|█████████ | 182/200 [3:47:40<22:42, 75.69s/it]Evaluating commonsenseqa :  16%|█▌        | 32/200 [35:09<3:04:20, 65.84s/it]Evaluating commonsenseqa :  53%|█████▎    | 106/200 [3:04:24<2:41:17, 102.96s/it]Evaluating commonsenseqa :  13%|█▎        | 26/200 [43:57<4:56:15, 102.16s/it]Evaluating commonsenseqa :  92%|█████████▏| 183/200 [3:48:55<21:23, 75.47s/it]Evaluating commonsenseqa :  16%|█▋        | 33/200 [36:15<3:03:08, 65.80s/it]Evaluating commonsenseqa :  14%|█▎        | 27/200 [45:39<4:54:26, 102.12s/it]Evaluating commonsenseqa :  54%|█████▎    | 107/200 [3:06:16<2:43:35, 105.55s/it]Evaluating commonsenseqa :  82%|████████▎ | 165/200 [5:59:03<1:17:30, 132.87s/it]Evaluating commonsenseqa :  17%|█▋        | 34/200 [37:21<3:02:28, 65.96s/it]Evaluating commonsenseqa :  92%|█████████▏| 184/200 [3:50:12<20:12, 75.81s/it]Evaluating commonsenseqa :  18%|█▊        | 35/200 [38:27<3:01:16, 65.92s/it]Evaluating commonsenseqa :  92%|█████████▎| 185/200 [3:51:27<18:56, 75.78s/it]Evaluating commonsenseqa :  14%|█▍        | 28/200 [47:22<4:53:48, 102.49s/it]Evaluating commonsenseqa :  54%|█████▍    | 108/200 [3:08:08<2:44:50, 107.51s/it]Evaluating commonsenseqa :  83%|████████▎ | 166/200 [6:01:23<1:16:34, 135.12s/it]Evaluating commonsenseqa :  18%|█▊        | 36/200 [39:32<2:59:46, 65.77s/it]Evaluating commonsenseqa :  93%|█████████▎| 186/200 [3:52:43<17:40, 75.78s/it]Evaluating commonsenseqa :  14%|█▍        | 29/200 [49:08<4:54:53, 103.47s/it]Evaluating commonsenseqa :  18%|█▊        | 37/200 [40:39<2:58:58, 65.88s/it]Evaluating commonsenseqa :  55%|█████▍    | 109/200 [3:10:00<2:45:05, 108.86s/it]Evaluating commonsenseqa :  94%|█████████▎| 187/200 [3:53:58<16:22, 75.56s/it]Evaluating commonsenseqa :  19%|█▉        | 38/200 [41:44<2:57:49, 65.86s/it]Evaluating commonsenseqa :  84%|████████▎ | 167/200 [6:03:46<1:15:33, 137.39s/it]Evaluating commonsenseqa :  15%|█▌        | 30/200 [50:50<4:51:32, 102.89s/it]Evaluating commonsenseqa :  94%|█████████▍| 188/200 [3:55:14<15:07, 75.61s/it]Evaluating commonsenseqa :  55%|█████▌    | 110/200 [3:11:50<2:43:49, 109.21s/it]Evaluating commonsenseqa :  20%|█▉        | 39/200 [42:50<2:56:37, 65.82s/it]Evaluating commonsenseqa :  94%|█████████▍| 189/200 [3:56:29<13:50, 75.50s/it]Evaluating commonsenseqa :  84%|████████▍ | 168/200 [6:05:40<1:09:39, 130.60s/it]Evaluating commonsenseqa :  20%|██        | 40/200 [43:56<2:55:36, 65.85s/it]Evaluating commonsenseqa :  16%|█▌        | 31/200 [52:33<4:49:54, 102.92s/it]Evaluating commonsenseqa :  56%|█████▌    | 111/200 [3:13:41<2:42:58, 109.87s/it]Evaluating commonsenseqa :  95%|█████████▌| 190/200 [3:57:44<12:33, 75.36s/it]Evaluating commonsenseqa :  20%|██        | 41/200 [45:03<2:55:03, 66.06s/it]Evaluating commonsenseqa :  84%|████████▍ | 169/200 [6:07:07<1:00:35, 117.27s/it]Evaluating commonsenseqa :  16%|█▌        | 32/200 [54:16<4:48:43, 103.12s/it]Evaluating commonsenseqa :  21%|██        | 42/200 [46:09<2:54:23, 66.22s/it]Evaluating commonsenseqa :  96%|█████████▌| 191/200 [3:59:01<11:21, 75.70s/it]Evaluating commonsenseqa :  56%|█████▌    | 112/200 [3:15:30<2:40:45, 109.61s/it]Evaluating commonsenseqa :  22%|██▏       | 43/200 [47:16<2:53:38, 66.36s/it]Evaluating commonsenseqa :  16%|█▋        | 33/200 [55:59<4:47:01, 103.12s/it]Evaluating commonsenseqa :  96%|█████████▌| 192/200 [4:00:17<10:05, 75.71s/it]Evaluating commonsenseqa :  85%|████████▌ | 170/200 [6:09:28<1:02:11, 124.37s/it]Evaluating commonsenseqa :  56%|█████▋    | 113/200 [3:17:23<2:40:12, 110.48s/it]Evaluating commonsenseqa :  22%|██▏       | 44/200 [48:22<2:52:40, 66.41s/it]Evaluating commonsenseqa :  96%|█████████▋| 193/200 [4:01:32<08:49, 75.60s/it]Evaluating commonsenseqa :  17%|█▋        | 34/200 [57:42<4:44:54, 102.98s/it]Evaluating commonsenseqa :  22%|██▎       | 45/200 [49:28<2:51:09, 66.25s/it]Evaluating commonsenseqa :  57%|█████▋    | 114/200 [3:18:35<2:22:05, 99.14s/it] Evaluating commonsenseqa :  86%|████████▌ | 171/200 [6:11:48<1:02:24, 129.11s/it]Evaluating commonsenseqa :  97%|█████████▋| 194/200 [4:02:49<07:35, 75.99s/it]Evaluating commonsenseqa :  23%|██▎       | 46/200 [50:34<2:49:51, 66.18s/it]Evaluating commonsenseqa :  18%|█▊        | 35/200 [59:26<4:43:46, 103.19s/it]Evaluating commonsenseqa :  98%|█████████▊| 195/200 [4:04:05<06:20, 76.06s/it]Evaluating commonsenseqa :  57%|█████▊    | 115/200 [3:20:30<2:26:53, 103.69s/it]Evaluating commonsenseqa :  24%|██▎       | 47/200 [51:40<2:48:11, 65.96s/it]Evaluating commonsenseqa :  86%|████████▌ | 172/200 [6:14:10<1:02:06, 133.07s/it]Evaluating commonsenseqa :  18%|█▊        | 36/200 [1:01:09<4:42:03, 103.19s/it]Evaluating commonsenseqa :  98%|█████████▊| 196/200 [4:05:21<05:03, 75.94s/it]Evaluating commonsenseqa :  24%|██▍       | 48/200 [52:45<2:46:37, 65.78s/it]Evaluating commonsenseqa :  58%|█████▊    | 116/200 [3:22:23<2:29:11, 106.57s/it]Evaluating commonsenseqa :  24%|██▍       | 49/200 [53:51<2:45:25, 65.73s/it]Evaluating commonsenseqa :  98%|█████████▊| 197/200 [4:06:36<03:47, 75.81s/it]Evaluating commonsenseqa :  18%|█▊        | 37/200 [1:02:52<4:39:57, 103.05s/it]Evaluating commonsenseqa :  58%|█████▊    | 117/200 [3:23:43<2:16:28, 98.66s/it] Evaluating commonsenseqa :  86%|████████▋ | 173/200 [6:16:31<1:00:54, 135.35s/it]Evaluating commonsenseqa :  25%|██▌       | 50/200 [54:57<2:44:29, 65.80s/it]Evaluating commonsenseqa :  99%|█████████▉| 198/200 [4:07:52<02:31, 75.76s/it]Evaluating commonsenseqa :  87%|████████▋ | 174/200 [6:17:45<50:43, 117.05s/it]  Evaluating commonsenseqa :  26%|██▌       | 51/200 [56:02<2:43:07, 65.69s/it]Evaluating commonsenseqa :  19%|█▉        | 38/200 [1:04:35<4:38:23, 103.11s/it]Evaluating commonsenseqa : 100%|█████████▉| 199/200 [4:09:08<01:15, 75.75s/it]Evaluating commonsenseqa :  59%|█████▉    | 118/200 [3:25:34<2:19:39, 102.19s/it]Evaluating commonsenseqa :  88%|████████▊ | 175/200 [6:18:42<41:18, 99.13s/it] Evaluating commonsenseqa :  26%|██▌       | 52/200 [57:08<2:42:08, 65.73s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [4:10:23<00:00, 75.70s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [4:10:23<00:00, 75.12s/it]
name: commonsenseqa | avg. gen lenth: 380.98 | time: 15027.850011110306s
Evaluating commonsenseqa :  20%|█▉        | 39/200 [1:06:16<4:35:22, 102.63s/it]python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10140 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o13-tmathqa-s30-rFalse --seed 30 --max-prompt-length 4096 --num-out-domain 13 13 15 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2023-09-20 08:46:22,481] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o13-tmathqa-s30-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 13
  out_domain_data_name ......... mathqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o13-tmathqa-s30-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 443064.13it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.37s/it]
 > number of parameters: 6738415616
[2023-09-20 08:46:39,243] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.3, git-hash=unknown, git-branch=unknown
[2023-09-20 08:46:39,243] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-09-20 08:46:39,673] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-20 08:46:39,676] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2023-09-20 08:46:39,676] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-20 08:46:39,676] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-20 08:46:39,676] [INFO] [config.py:971:print]   amp_enabled .................. False
[2023-09-20 08:46:39,676] [INFO] [config.py:971:print]   amp_params ................... False
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f46dc622da0>
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   communication_data_type ...... None
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   disable_allgather ............ False
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   dump_state ................... False
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   global_rank .................. 0
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   gradient_clipping ............ 0.0
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2023-09-20 08:46:39,677] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 2048
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   loss_scale ................... 0
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   optimizer_name ............... None
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   optimizer_params ............. None
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   pld_enabled .................. False
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   pld_params ................... False
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   scheduler_name ............... None
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   scheduler_params ............. None
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   sparse_attention ............. None
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   train_batch_size ............. 1
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  1
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   world_size ................... 1
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  True
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   zero_enabled ................. False
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-20 08:46:39,678] [INFO] [config.py:971:print]   zero_optimization_stage ...... 0
[2023-09-20 08:46:39,678] [INFO] [config.py:957:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/200 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: the mean of 30 values was 140. it was detected on rechecking that one value 145 was wrongly copied as 135 for the computation of the mean. find the correct mean. a ) 151, b ) 140.33, c ) 152, d ) 148, e ) none of the above
Output: b

Input: the measurement of a rectangular box with lid is 25 cmx 24 cmx 18 cm. find the volume of the largest sphere that can be inscribed in the box ( in terms of π cm 3 ). ( hint : the lowest measure of rectangular box represents the diameter of the largest sphere ) a ) 288, b ) 2302, c ) 2304, d ) 8640, e ) 964
Output: c

Input: a certain fraction has the same ratio to 1 / 33, as 3 / 4 does to 7 / 11. what is this certain fraction? a ) 1 / 14, b ) 1 / 18, c ) 1 / 21, d ) 1 / 25, e ) 1 / 28
Output: e

Input: what is the sum of all remainders obtained when the first 110 natural numbers are divided by 9? a ) 397, b ) 401, c ) 403, d ) 405, e ) 399
Output: c

Input: a ’ s speed is 20 / 15 times that of b. if a and b run a race, what part of the length of the race should a give b as a head start, so that the race ends in a dead heat? a ) 1 / 17, b ) 3 / 17, c ) 1 / 10, d ) 5 / 20, e ) 3 / 10
Output: d

Input: find the average of all the numbers between 6 and 34 which are divisible by 7. a ) 18, b ) 20, c ) 17.5, d ) 30, e ) 32
Output: c

Input: instead of multiplying a number by 5, the number is divided by 10. what is the percentage of error obtained? a ) 96 %, b ) 98 %, c ) 95 %, d ) 97 %, e ) 96 %
Output: b

Input: by selling an article at rs. 150, a profit of 25 % is made. find its cost price? a ) s. 486, b ) s. 455, c ) s. 487, d ) s. 120, e ) s. 489
Output: d

Input: if 1 = 6, 2 = 12, 3 = 18, 4 = 24, 5 = 30, then 6 =? a ) 5, b ) 3, c ) 1, d ) 7, e ) 9
Output: c

Input: 62 small identical cubes are used to form a large cube. how many more cubes are needed to add one top layer of small cube all over the surface of the large cube? a ) 64, b ) 128, c ) 152, d ) 154, e ) 256
Output: d

Input: a boat running upstream takes 640 min to cover a certain distance, while it takes 280 min to cover the same distance running down stream. what is the ratio between the speed of the boat and speed of water current respectively? a ) 23 : 7, b ) 22 : 9, c ) 23 : 8, d ) 23 : 9, e ) 23 : 11
Output: d

Input: there are 2 positive integers x and y. what is the probability that x + y is odd? a ) 1 / 4, b ) 1 / 2, c ) 1 / 3, d ) 1 / 5, e ) 1 / 9
Output: b

Input: two numbers have a h. c. f of 9 and a product of two numbers is 1800. find the l. c. m of the two numbers? a ) 200, b ) 150, c ) 160, d ) 170, e ) 180
Output: a

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o13-tmathqa-s30-rFalse-m4096
Evaluating commonsenseqa :  26%|██▋       | 53/200 [58:14<2:41:11, 65.79s/it]Evaluating commonsenseqa :  60%|█████▉    | 119/200 [3:27:24<2:21:25, 104.76s/it]Evaluating commonsenseqa :  88%|████████▊ | 176/200 [6:21:01<44:27, 111.13s/it]Evaluating commonsenseqa :   0%|          | 1/200 [01:07<3:44:21, 67.64s/it]Evaluating commonsenseqa :  27%|██▋       | 54/200 [59:20<2:40:05, 65.79s/it]Evaluating commonsenseqa :  20%|██        | 40/200 [1:07:59<4:33:32, 102.58s/it]Evaluating commonsenseqa :  88%|████████▊ | 177/200 [6:21:56<36:05, 94.14s/it] Evaluating commonsenseqa :  60%|██████    | 120/200 [3:29:17<2:22:52, 107.16s/it]Evaluating commonsenseqa :  28%|██▊       | 55/200 [1:00:25<2:38:42, 65.67s/it]Evaluating commonsenseqa :   1%|          | 2/200 [02:26<4:04:01, 73.95s/it]Evaluating commonsenseqa :  89%|████████▉ | 178/200 [6:22:58<30:58, 84.46s/it]Evaluating commonsenseqa :  20%|██        | 41/200 [1:09:42<4:32:08, 102.69s/it]Evaluating commonsenseqa :  60%|██████    | 121/200 [3:30:27<2:06:25, 96.02s/it] Evaluating commonsenseqa :  28%|██▊       | 56/200 [1:01:31<2:37:30, 65.63s/it]Evaluating commonsenseqa :   2%|▏         | 3/200 [04:12<4:51:38, 88.83s/it]Evaluating commonsenseqa :  28%|██▊       | 57/200 [1:02:35<2:35:52, 65.40s/it]Evaluating commonsenseqa :  21%|██        | 42/200 [1:11:26<4:31:19, 103.03s/it]Evaluating commonsenseqa :  61%|██████    | 122/200 [3:32:19<2:11:03, 100.82s/it]Evaluating commonsenseqa :  90%|████████▉ | 179/200 [6:25:16<35:13, 100.66s/it]Evaluating commonsenseqa :  29%|██▉       | 58/200 [1:03:41<2:35:12, 65.58s/it]Evaluating commonsenseqa :  62%|██████▏   | 123/200 [3:32:57<1:45:15, 82.02s/it] Evaluating commonsenseqa :  22%|██▏       | 43/200 [1:12:30<3:59:22, 91.48s/it] Evaluating commonsenseqa :   2%|▏         | 4/200 [06:01<5:16:41, 96.95s/it]Evaluating commonsenseqa :  30%|██▉       | 59/200 [1:04:47<2:34:04, 65.56s/it]Evaluating commonsenseqa :  22%|██▏       | 44/200 [1:14:13<4:06:28, 94.80s/it]Evaluating commonsenseqa :  90%|█████████ | 180/200 [6:27:35<37:22, 112.10s/it]Evaluating commonsenseqa :  62%|██████▏   | 124/200 [3:34:51<1:55:59, 91.58s/it]Evaluating commonsenseqa :  30%|███       | 60/200 [1:05:52<2:32:49, 65.50s/it]Evaluating commonsenseqa :   2%|▎         | 5/200 [07:52<5:30:49, 101.79s/it]Evaluating commonsenseqa :  30%|███       | 61/200 [1:06:58<2:31:37, 65.45s/it]Evaluating commonsenseqa :  22%|██▎       | 45/200 [1:15:53<4:09:09, 96.45s/it]Evaluating commonsenseqa :  62%|██████▎   | 125/200 [3:36:45<2:02:48, 98.25s/it]Evaluating commonsenseqa :   3%|▎         | 6/200 [09:44<5:40:35, 105.34s/it]Evaluating commonsenseqa :  31%|███       | 62/200 [1:08:03<2:30:20, 65.36s/it]Evaluating commonsenseqa :  90%|█████████ | 181/200 [6:30:00<38:34, 121.80s/it]Evaluating commonsenseqa :  23%|██▎       | 46/200 [1:17:35<4:11:28, 97.98s/it]Evaluating commonsenseqa :  32%|███▏      | 63/200 [1:09:08<2:29:19, 65.40s/it]Evaluating commonsenseqa :  63%|██████▎   | 126/200 [3:38:37<2:06:14, 102.36s/it]Evaluating commonsenseqa :   4%|▎         | 7/200 [11:36<5:45:54, 107.54s/it]Evaluating commonsenseqa :  32%|███▏      | 64/200 [1:10:14<2:28:10, 65.37s/it]Evaluating commonsenseqa :  91%|█████████ | 182/200 [6:32:23<38:27, 128.18s/it]Evaluating commonsenseqa :  24%|██▎       | 47/200 [1:19:16<4:12:16, 98.93s/it]Evaluating commonsenseqa :  32%|███▎      | 65/200 [1:11:19<2:27:18, 65.47s/it]Evaluating commonsenseqa :  64%|██████▎   | 127/200 [3:40:30<2:08:26, 105.57s/it]Evaluating commonsenseqa :   4%|▍         | 8/200 [13:32<5:52:27, 110.15s/it]Evaluating commonsenseqa :  24%|██▍       | 48/200 [1:20:56<4:11:43, 99.36s/it]Evaluating commonsenseqa :  33%|███▎      | 66/200 [1:12:24<2:25:58, 65.36s/it]Evaluating commonsenseqa :  92%|█████████▏| 183/200 [6:34:43<37:22, 131.90s/it]Evaluating commonsenseqa :  64%|██████▍   | 128/200 [3:42:20<2:08:04, 106.73s/it]Evaluating commonsenseqa :  34%|███▎      | 67/200 [1:13:30<2:24:49, 65.33s/it]Evaluating commonsenseqa :   4%|▍         | 9/200 [15:23<5:51:33, 110.44s/it]Evaluating commonsenseqa :  24%|██▍       | 49/200 [1:22:39<4:12:43, 100.42s/it]Evaluating commonsenseqa :  34%|███▍      | 68/200 [1:14:35<2:23:36, 65.28s/it]Evaluating commonsenseqa :  64%|██████▍   | 129/200 [3:44:12<2:08:16, 108.41s/it]Evaluating commonsenseqa :  92%|█████████▏| 184/200 [6:37:05<35:57, 134.84s/it]Evaluating commonsenseqa :   5%|▌         | 10/200 [17:15<5:50:56, 110.82s/it]Evaluating commonsenseqa :  34%|███▍      | 69/200 [1:15:40<2:22:34, 65.30s/it]Evaluating commonsenseqa :  25%|██▌       | 50/200 [1:24:21<4:12:11, 100.87s/it]Evaluating commonsenseqa :  35%|███▌      | 70/200 [1:16:45<2:21:20, 65.23s/it]Evaluating commonsenseqa :  65%|██████▌   | 130/200 [3:46:07<2:08:57, 110.54s/it]Evaluating commonsenseqa :   6%|▌         | 11/200 [19:08<5:51:08, 111.47s/it]Evaluating commonsenseqa :  26%|██▌       | 51/200 [1:26:04<4:12:01, 101.49s/it]Evaluating commonsenseqa :  92%|█████████▎| 185/200 [6:39:25<34:05, 136.36s/it]Evaluating commonsenseqa :  36%|███▌      | 71/200 [1:17:51<2:20:26, 65.32s/it]Evaluating commonsenseqa :  36%|███▌      | 72/200 [1:18:53<2:17:28, 64.44s/it]Evaluating commonsenseqa :  66%|██████▌   | 131/200 [3:48:01<2:08:01, 111.33s/it]Evaluating commonsenseqa :   6%|▌         | 12/200 [21:00<5:49:58, 111.69s/it]Evaluating commonsenseqa :  26%|██▌       | 52/200 [1:27:46<4:10:41, 101.63s/it]Evaluating commonsenseqa :  93%|█████████▎| 186/200 [6:41:49<32:22, 138.72s/it]Evaluating commonsenseqa :  36%|███▋      | 73/200 [1:19:58<2:16:51, 64.66s/it]Evaluating commonsenseqa :  66%|██████▌   | 132/200 [3:49:10<1:51:56, 98.77s/it] Evaluating commonsenseqa :  26%|██▋       | 53/200 [1:29:31<4:11:17, 102.57s/it]Evaluating commonsenseqa :   6%|▋         | 13/200 [22:52<5:48:57, 111.96s/it]Evaluating commonsenseqa :  37%|███▋      | 74/200 [1:21:03<2:16:03, 64.79s/it]Evaluating commonsenseqa :  66%|██████▋   | 133/200 [3:51:05<1:55:50, 103.73s/it]Evaluating commonsenseqa :  38%|███▊      | 75/200 [1:22:10<2:15:56, 65.25s/it]Evaluating commonsenseqa :  94%|█████████▎| 187/200 [6:44:10<30:12, 139.42s/it]Evaluating commonsenseqa :   7%|▋         | 14/200 [24:22<5:25:55, 105.14s/it]Evaluating commonsenseqa :  27%|██▋       | 54/200 [1:31:12<4:08:57, 102.31s/it]Evaluating commonsenseqa :  38%|███▊      | 76/200 [1:23:15<2:15:11, 65.41s/it]Evaluating commonsenseqa :  67%|██████▋   | 134/200 [3:52:26<1:46:21, 96.69s/it] Evaluating commonsenseqa :  38%|███▊      | 77/200 [1:24:22<2:14:28, 65.60s/it]Evaluating commonsenseqa :  28%|██▊       | 55/200 [1:32:54<4:07:00, 102.21s/it]Evaluating commonsenseqa :   8%|▊         | 15/200 [26:15<5:31:27, 107.50s/it]Evaluating commonsenseqa :  94%|█████████▍| 188/200 [6:46:19<27:14, 136.25s/it]Evaluating commonsenseqa :  68%|██████▊   | 135/200 [3:53:53<1:41:37, 93.81s/it]Evaluating commonsenseqa :  39%|███▉      | 78/200 [1:25:28<2:13:47, 65.80s/it]Evaluating commonsenseqa :  68%|██████▊   | 136/200 [3:54:41<1:25:26, 80.11s/it]Evaluating commonsenseqa :   8%|▊         | 16/200 [27:30<4:59:59, 97.82s/it] Evaluating commonsenseqa :  28%|██▊       | 56/200 [1:34:36<4:04:46, 101.99s/it]Evaluating commonsenseqa :  40%|███▉      | 79/200 [1:26:34<2:13:06, 66.01s/it]Evaluating commonsenseqa :  94%|█████████▍| 189/200 [6:48:30<24:43, 134.84s/it]Evaluating commonsenseqa :  68%|██████▊   | 137/200 [3:56:36<1:35:14, 90.70s/it]Evaluating commonsenseqa :   8%|▊         | 17/200 [29:23<5:12:39, 102.51s/it]Evaluating commonsenseqa :  40%|████      | 80/200 [1:27:40<2:11:48, 65.90s/it]Evaluating commonsenseqa :  28%|██▊       | 57/200 [1:36:16<4:02:09, 101.61s/it]Evaluating commonsenseqa :  40%|████      | 81/200 [1:28:46<2:10:31, 65.81s/it]Evaluating commonsenseqa :  95%|█████████▌| 190/200 [6:50:51<22:45, 136.54s/it]Evaluating commonsenseqa :  69%|██████▉   | 138/200 [3:58:29<1:40:39, 97.42s/it]Evaluating commonsenseqa :   9%|▉         | 18/200 [31:15<5:19:32, 105.35s/it]Evaluating commonsenseqa :  29%|██▉       | 58/200 [1:37:59<4:00:50, 101.76s/it]Evaluating commonsenseqa :  41%|████      | 82/200 [1:29:51<2:09:17, 65.74s/it]Evaluating commonsenseqa :  42%|████▏     | 83/200 [1:30:57<2:08:06, 65.70s/it]Evaluating commonsenseqa :  30%|██▉       | 59/200 [1:39:42<4:00:01, 102.14s/it]Evaluating commonsenseqa :  70%|██████▉   | 139/200 [4:00:22<1:43:35, 101.89s/it]Evaluating commonsenseqa :  10%|▉         | 19/200 [33:10<5:26:02, 108.08s/it]Evaluating commonsenseqa :  96%|█████████▌| 191/200 [6:53:13<20:43, 138.17s/it]Evaluating commonsenseqa :  42%|████▏     | 84/200 [1:32:02<2:06:36, 65.49s/it]Evaluating commonsenseqa :  70%|███████   | 140/200 [4:01:30<1:31:56, 91.95s/it] Evaluating commonsenseqa :  10%|█         | 20/200 [34:37<5:05:17, 101.76s/it]Evaluating commonsenseqa :  30%|███       | 60/200 [1:41:26<3:59:50, 102.79s/it]Evaluating commonsenseqa :  42%|████▎     | 85/200 [1:33:08<2:05:49, 65.65s/it]Evaluating commonsenseqa :  70%|███████   | 141/200 [4:02:17<1:16:59, 78.30s/it]Evaluating commonsenseqa :  96%|█████████▌| 192/200 [6:55:33<18:30, 138.86s/it]Evaluating commonsenseqa :  43%|████▎     | 86/200 [1:34:14<2:04:57, 65.77s/it]Evaluating commonsenseqa :  71%|███████   | 142/200 [4:03:23<1:12:03, 74.54s/it]Evaluating commonsenseqa :  30%|███       | 61/200 [1:43:10<3:58:55, 103.13s/it]Evaluating commonsenseqa :  10%|█         | 21/200 [36:30<5:13:57, 105.24s/it]Evaluating commonsenseqa :  96%|█████████▋| 193/200 [6:57:06<14:33, 124.82s/it]Evaluating commonsenseqa :  44%|████▎     | 87/200 [1:35:20<2:03:58, 65.83s/it]Evaluating commonsenseqa :  72%|███████▏  | 143/200 [4:05:14<1:21:19, 85.61s/it]Evaluating commonsenseqa :  31%|███       | 62/200 [1:44:52<3:56:23, 102.78s/it]Evaluating commonsenseqa :  44%|████▍     | 88/200 [1:36:26<2:03:06, 65.95s/it]Evaluating commonsenseqa :  11%|█         | 22/200 [38:24<5:19:58, 107.86s/it]Evaluating commonsenseqa :  44%|████▍     | 89/200 [1:37:33<2:02:20, 66.13s/it]Evaluating commonsenseqa :  97%|█████████▋| 194/200 [6:59:30<13:03, 130.61s/it]Evaluating commonsenseqa :  72%|███████▏  | 144/200 [4:07:06<1:27:14, 93.46s/it]Evaluating commonsenseqa :  32%|███▏      | 63/200 [1:46:35<3:54:46, 102.82s/it]Evaluating commonsenseqa :  45%|████▌     | 90/200 [1:38:20<1:51:01, 60.56s/it]Evaluating commonsenseqa :  12%|█▏        | 23/200 [40:15<5:20:48, 108.75s/it]Evaluating commonsenseqa :  46%|████▌     | 91/200 [1:39:26<1:52:48, 62.09s/it]Evaluating commonsenseqa :  32%|███▏      | 64/200 [1:48:17<3:52:33, 102.60s/it]Evaluating commonsenseqa :  72%|███████▎  | 145/200 [4:09:00<1:31:21, 99.67s/it]Evaluating commonsenseqa :  98%|█████████▊| 195/200 [7:01:50<11:07, 133.59s/it]Evaluating commonsenseqa :  12%|█▏        | 24/200 [42:11<5:25:18, 110.90s/it]Evaluating commonsenseqa :  46%|████▌     | 92/200 [1:40:31<1:53:38, 63.14s/it]Evaluating commonsenseqa :  12%|█▎        | 25/200 [42:50<4:20:54, 89.45s/it] Evaluating commonsenseqa :  32%|███▎      | 65/200 [1:50:01<3:52:06, 103.16s/it]Evaluating commonsenseqa :  46%|████▋     | 93/200 [1:41:36<1:53:40, 63.74s/it]Evaluating commonsenseqa :  73%|███████▎  | 146/200 [4:10:51<1:32:48, 103.12s/it]Evaluating commonsenseqa :  98%|█████████▊| 196/200 [7:04:07<08:58, 134.57s/it]Evaluating commonsenseqa :  47%|████▋     | 94/200 [1:42:42<1:53:40, 64.35s/it]Evaluating commonsenseqa :  13%|█▎        | 26/200 [44:43<4:39:14, 96.29s/it]Evaluating commonsenseqa :  33%|███▎      | 66/200 [1:51:43<3:49:25, 102.73s/it]Evaluating commonsenseqa :  74%|███████▎  | 147/200 [4:12:43<1:33:21, 105.69s/it]Evaluating commonsenseqa :  48%|████▊     | 95/200 [1:43:48<1:53:25, 64.81s/it]Evaluating commonsenseqa :  98%|█████████▊| 197/200 [7:06:27<06:48, 136.25s/it]Evaluating commonsenseqa :  14%|█▎        | 27/200 [46:33<4:49:32, 100.42s/it]Evaluating commonsenseqa :  34%|███▎      | 67/200 [1:53:25<3:47:28, 102.62s/it]Evaluating commonsenseqa :  48%|████▊     | 96/200 [1:44:54<1:52:54, 65.14s/it]Evaluating commonsenseqa :  74%|███████▍  | 148/200 [4:14:35<1:33:19, 107.69s/it]Evaluating commonsenseqa :  48%|████▊     | 97/200 [1:45:59<1:51:55, 65.19s/it]Evaluating commonsenseqa :  14%|█▍        | 28/200 [48:24<4:57:20, 103.73s/it]Evaluating commonsenseqa :  34%|███▍      | 68/200 [1:55:10<3:46:54, 103.14s/it]Evaluating commonsenseqa :  99%|█████████▉| 198/200 [7:08:44<04:33, 136.51s/it]Evaluating commonsenseqa :  49%|████▉     | 98/200 [1:47:05<1:50:58, 65.28s/it]Evaluating commonsenseqa :  74%|███████▍  | 149/200 [4:16:28<1:32:55, 109.33s/it]Evaluating commonsenseqa :  14%|█▍        | 29/200 [49:36<4:28:17, 94.14s/it] Evaluating commonsenseqa :  50%|████▉     | 99/200 [1:48:10<1:49:56, 65.31s/it]Evaluating commonsenseqa :  34%|███▍      | 69/200 [1:56:52<3:44:40, 102.91s/it]Evaluating commonsenseqa : 100%|█████████▉| 199/200 [7:10:19<02:03, 123.98s/it]Evaluating commonsenseqa :  15%|█▌        | 30/200 [50:43<4:03:46, 86.04s/it]Evaluating commonsenseqa :  75%|███████▌  | 150/200 [4:18:21<1:31:55, 110.32s/it]Evaluating commonsenseqa :  50%|█████     | 100/200 [1:49:16<1:49:00, 65.41s/it]Evaluating commonsenseqa :  35%|███▌      | 70/200 [1:58:34<3:42:10, 102.54s/it]Evaluating commonsenseqa :  16%|█▌        | 31/200 [51:57<3:52:29, 82.54s/it]Evaluating commonsenseqa :  50%|█████     | 101/200 [1:50:22<1:48:01, 65.47s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [7:12:40<00:00, 129.00s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [7:12:40<00:00, 129.80s/it]
name: commonsenseqa | avg. gen lenth: 244.601 | time: 25962.1040289402s
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10137 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tmathqa-s20-rTrue --seed 20 --max-prompt-length 4096 --rationales --num-out-domain 1 1 3 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2023-09-20 09:39:31,649] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Evaluating commonsenseqa :  76%|███████▌  | 151/200 [4:20:09<1:29:30, 109.59s/it]using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tmathqa-s20-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 1
  out_domain_data_name ......... mathqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o1-tmathqa-s20-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 754802.70it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.38s/it]
 > number of parameters: 6738415616
[2023-09-20 09:39:48,247] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.3, git-hash=unknown, git-branch=unknown
[2023-09-20 09:39:48,248] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-09-20 09:39:48,647] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-20 09:39:48,649] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2023-09-20 09:39:48,650] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-20 09:39:48,650] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-20 09:39:48,650] [INFO] [config.py:971:print]   amp_enabled .................. False
[2023-09-20 09:39:48,650] [INFO] [config.py:971:print]   amp_params ................... False
[2023-09-20 09:39:48,650] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-20 09:39:48,650] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2023-09-20 09:39:48,650] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2023-09-20 09:39:48,650] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2023-09-20 09:39:48,650] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2023-09-20 09:39:48,650] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fb1c5422da0>
[2023-09-20 09:39:48,650] [INFO] [config.py:971:print]   communication_data_type ...... None
[2023-09-20 09:39:48,650] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-20 09:39:48,650] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2023-09-20 09:39:48,650] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2023-09-20 09:39:48,650] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   disable_allgather ............ False
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   dump_state ................... False
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   global_rank .................. 0
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   gradient_clipping ............ 0.0
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 2048
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   loss_scale ................... 0
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-20 09:39:48,651] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-20 09:39:48,652] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2023-09-20 09:39:48,652] [INFO] [config.py:971:print]   optimizer_name ............... None
[2023-09-20 09:39:48,652] [INFO] [config.py:971:print]   optimizer_params ............. None
[2023-09-20 09:39:48,652] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-20 09:39:48,652] [INFO] [config.py:971:print]   pld_enabled .................. False
[2023-09-20 09:39:48,652] [INFO] [config.py:971:print]   pld_params ................... False
[2023-09-20 09:39:48,652] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2023-09-20 09:39:48,652] [INFO] [config.py:971:print]   scheduler_name ............... None
[2023-09-20 09:39:48,652] [INFO] [config.py:971:print]   scheduler_params ............. None
[2023-09-20 09:39:48,652] [INFO] [config.py:971:print]   sparse_attention ............. None
[2023-09-20 09:39:48,652] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2023-09-20 09:39:48,652] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2023-09-20 09:39:48,652] [INFO] [config.py:971:print]   train_batch_size ............. 1
[2023-09-20 09:39:48,652] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  1
[2023-09-20 09:39:48,652] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2023-09-20 09:39:48,652] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2023-09-20 09:39:48,652] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2023-09-20 09:39:48,652] [INFO] [config.py:971:print]   world_size ................... 1
[2023-09-20 09:39:48,652] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  True
[2023-09-20 09:39:48,652] [INFO] [config.py:971:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2023-09-20 09:39:48,652] [INFO] [config.py:971:print]   zero_enabled ................. False
[2023-09-20 09:39:48,652] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-20 09:39:48,652] [INFO] [config.py:971:print]   zero_optimization_stage ...... 0
[2023-09-20 09:39:48,652] [INFO] [config.py:957:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/200 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: a man cycling along the road noticed that every 18 minutes a bus overtakes him and every 6 minutes he meets an oncoming bus. if all buses and the cyclist move at a constant speed, what is the time interval between consecutive buses? a ) 5 minutes, b ) 6 minutes, c ) 8 minutes, d ) 9 minutes, e ) 10 minutes
Output: let's say the distance between the buses is d. we want to determine interval = \ frac { d } { b }, where b is the speed of bus. let the speed of cyclist be c. every 18 minutes a bus overtakes cyclist : \ frac { d } { b - c } = 18, d = 18 b - 18 c ; every 6 minutes cyclist meets an oncoming bus : \ frac { d } { b + c } = 6, d = 6 b + 6 c ; d = 18 b - 18 c = 6 b + 6 c, - - > b = 2 c, - - > d = 18 b - 9 b = 9 b. interval = \ frac { d } { b } = \ frac { 9 b } { b } = 9 answer : d ( 9 minutes ).
So the final answer is d

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o1-tmathqa-s20-rTrue-m4096
Evaluating commonsenseqa :  51%|█████     | 102/200 [1:51:27<1:47:11, 65.62s/it]Evaluating commonsenseqa :  16%|█▌        | 32/200 [53:35<4:03:43, 87.04s/it]Evaluating commonsenseqa :  36%|███▌      | 71/200 [2:00:18<3:41:25, 102.99s/it]Evaluating commonsenseqa :  52%|█████▏    | 103/200 [1:52:33<1:45:48, 65.45s/it]Evaluating commonsenseqa :  76%|███████▌  | 152/200 [4:22:00<1:28:06, 110.14s/it]Evaluating commonsenseqa :  36%|███▌      | 72/200 [2:02:02<3:40:35, 103.40s/it]Evaluating commonsenseqa :   0%|          | 1/200 [02:18<7:38:30, 138.25s/it]Evaluating commonsenseqa :  16%|█▋        | 33/200 [55:27<4:23:21, 94.62s/it]Evaluating commonsenseqa :  52%|█████▏    | 104/200 [1:53:38<1:44:47, 65.49s/it]Evaluating commonsenseqa :   1%|          | 2/200 [03:23<5:13:51, 95.11s/it] Evaluating commonsenseqa :  52%|█████▎    | 105/200 [1:54:44<1:43:51, 65.60s/it]Evaluating commonsenseqa :  76%|███████▋  | 153/200 [4:23:52<1:26:31, 110.46s/it]Evaluating commonsenseqa :  36%|███▋      | 73/200 [2:03:44<3:37:59, 102.98s/it]Evaluating commonsenseqa :  17%|█▋        | 34/200 [57:19<4:36:09, 99.81s/it]Evaluating commonsenseqa :  53%|█████▎    | 106/200 [1:55:50<1:42:56, 65.71s/it]Evaluating commonsenseqa :  77%|███████▋  | 154/200 [4:25:44<1:25:16, 111.22s/it]Evaluating commonsenseqa :  18%|█▊        | 35/200 [58:47<4:24:34, 96.21s/it]Evaluating commonsenseqa :  37%|███▋      | 74/200 [2:05:27<3:36:27, 103.08s/it]Evaluating commonsenseqa :  54%|█████▎    | 107/200 [1:56:55<1:41:41, 65.60s/it]Evaluating commonsenseqa :   2%|▏         | 3/200 [05:39<6:13:56, 113.89s/it]Evaluating commonsenseqa :  54%|█████▍    | 108/200 [1:58:00<1:40:21, 65.45s/it]Evaluating commonsenseqa :  78%|███████▊  | 155/200 [4:27:35<1:23:17, 111.05s/it]Evaluating commonsenseqa :  38%|███▊      | 75/200 [2:07:08<3:33:27, 102.46s/it]Evaluating commonsenseqa :  18%|█▊        | 36/200 [1:00:38<4:35:32, 100.81s/it]Evaluating commonsenseqa :  55%|█████▍    | 109/200 [1:59:05<1:39:01, 65.29s/it]Evaluating commonsenseqa :   2%|▏         | 4/200 [07:58<6:45:10, 124.03s/it]Evaluating commonsenseqa :  55%|█████▌    | 110/200 [2:00:11<1:38:14, 65.50s/it]Evaluating commonsenseqa :  38%|███▊      | 76/200 [2:08:50<3:31:17, 102.24s/it]Evaluating commonsenseqa :  78%|███████▊  | 156/200 [4:29:26<1:21:18, 110.88s/it]Evaluating commonsenseqa :  18%|█▊        | 37/200 [1:02:33<4:44:57, 104.89s/it]Evaluating commonsenseqa :  56%|█████▌    | 111/200 [2:01:16<1:36:58, 65.37s/it]Evaluating commonsenseqa :   2%|▎         | 5/200 [10:17<7:00:02, 129.24s/it]Evaluating commonsenseqa :  38%|███▊      | 77/200 [2:10:31<3:28:39, 101.78s/it]Evaluating commonsenseqa :  78%|███████▊  | 157/200 [4:31:19<1:19:56, 111.56s/it]Evaluating commonsenseqa :  19%|█▉        | 38/200 [1:04:14<4:40:08, 103.76s/it]Evaluating commonsenseqa :  56%|█████▌    | 112/200 [2:02:22<1:36:05, 65.51s/it]Evaluating commonsenseqa :  56%|█████▋    | 113/200 [2:03:28<1:34:58, 65.50s/it]Evaluating commonsenseqa :  79%|███████▉  | 158/200 [4:32:47<1:13:07, 104.46s/it]Evaluating commonsenseqa :  39%|███▉      | 78/200 [2:12:12<3:26:38, 101.63s/it]Evaluating commonsenseqa :   3%|▎         | 6/200 [12:33<7:05:52, 131.71s/it]Evaluating commonsenseqa :  20%|█▉        | 39/200 [1:06:05<4:44:07, 105.89s/it]Evaluating commonsenseqa :  57%|█████▋    | 114/200 [2:04:33<1:33:56, 65.54s/it]Evaluating commonsenseqa :  80%|███████▉  | 159/200 [4:34:25<1:10:11, 102.72s/it]Evaluating commonsenseqa :  40%|███▉      | 79/200 [2:13:53<3:24:44, 101.53s/it]Evaluating commonsenseqa :  57%|█████▊    | 115/200 [2:05:39<1:32:48, 65.51s/it]Evaluating commonsenseqa :  20%|██        | 40/200 [1:07:57<4:47:29, 107.81s/it]Evaluating commonsenseqa :   4%|▎         | 7/200 [14:52<7:10:48, 133.93s/it]Evaluating commonsenseqa :  80%|████████  | 160/200 [4:35:46<1:04:02, 96.07s/it] Evaluating commonsenseqa :  58%|█████▊    | 116/200 [2:06:44<1:31:48, 65.58s/it]Evaluating commonsenseqa :  40%|████      | 80/200 [2:15:37<3:24:27, 102.23s/it]Evaluating commonsenseqa :   4%|▍         | 8/200 [16:13<6:14:37, 117.07s/it]Evaluating commonsenseqa :  58%|█████▊    | 117/200 [2:07:50<1:30:44, 65.60s/it]Evaluating commonsenseqa :  20%|██        | 41/200 [1:09:50<4:49:17, 109.17s/it]Evaluating commonsenseqa :  80%|████████  | 161/200 [4:37:38<1:05:33, 100.85s/it]Evaluating commonsenseqa :  40%|████      | 81/200 [2:17:18<3:21:57, 101.82s/it]Evaluating commonsenseqa :  59%|█████▉    | 118/200 [2:08:56<1:29:33, 65.53s/it]Evaluating commonsenseqa :   4%|▍         | 9/200 [18:31<6:33:38, 123.66s/it]Evaluating commonsenseqa :  21%|██        | 42/200 [1:11:42<4:50:16, 110.23s/it]Evaluating commonsenseqa :  81%|████████  | 162/200 [4:38:59<1:00:02, 94.80s/it] Evaluating commonsenseqa :  60%|█████▉    | 119/200 [2:10:01<1:28:24, 65.49s/it]Evaluating commonsenseqa :  41%|████      | 82/200 [2:18:59<3:19:51, 101.62s/it]Evaluating commonsenseqa :  60%|██████    | 120/200 [2:11:07<1:27:36, 65.71s/it]Evaluating commonsenseqa :  82%|████████▏ | 163/200 [4:40:23<56:35, 91.76s/it]  Evaluating commonsenseqa :  22%|██▏       | 43/200 [1:13:34<4:49:20, 110.57s/it]Evaluating commonsenseqa :   5%|▌         | 10/200 [20:50<6:46:54, 128.50s/it]Evaluating commonsenseqa :  42%|████▏     | 83/200 [2:20:41<3:18:12, 101.64s/it]Evaluating commonsenseqa :  60%|██████    | 121/200 [2:12:12<1:26:18, 65.55s/it]Evaluating commonsenseqa :  82%|████████▏ | 164/200 [4:42:14<58:32, 97.56s/it]Evaluating commonsenseqa :  61%|██████    | 122/200 [2:13:18<1:25:22, 65.67s/it]Evaluating commonsenseqa :  22%|██▏       | 44/200 [1:15:27<4:49:36, 111.39s/it]Evaluating commonsenseqa :  42%|████▏     | 84/200 [2:22:27<3:18:45, 102.80s/it]Evaluating commonsenseqa :  62%|██████▏   | 123/200 [2:14:00<1:15:06, 58.53s/it]Evaluating commonsenseqa :  82%|████████▎ | 165/200 [4:43:13<50:04, 85.83s/it]Evaluating commonsenseqa :   6%|▌         | 11/200 [23:09<6:54:30, 131.59s/it]Evaluating commonsenseqa :  62%|██████▏   | 124/200 [2:15:06<1:16:54, 60.72s/it]Evaluating commonsenseqa :  22%|██▎       | 45/200 [1:17:20<4:48:43, 111.77s/it]Evaluating commonsenseqa :  42%|████▎     | 85/200 [2:24:09<3:16:46, 102.67s/it]Evaluating commonsenseqa :  83%|████████▎ | 166/200 [4:44:53<51:00, 90.00s/it]Evaluating commonsenseqa :  62%|██████▎   | 125/200 [2:16:11<1:17:36, 62.09s/it]Evaluating commonsenseqa :   6%|▌         | 12/200 [25:28<6:59:33, 133.90s/it]Evaluating commonsenseqa :  63%|██████▎   | 126/200 [2:17:17<1:17:50, 63.12s/it]Evaluating commonsenseqa :  43%|████▎     | 86/200 [2:25:50<3:14:11, 102.21s/it]Evaluating commonsenseqa :  23%|██▎       | 46/200 [1:19:12<4:47:32, 112.03s/it]Evaluating commonsenseqa :  84%|████████▎ | 167/200 [4:46:46<53:27, 97.19s/it]Evaluating commonsenseqa :  64%|██████▎   | 127/200 [2:18:23<1:18:06, 64.20s/it]Evaluating commonsenseqa :  44%|████▎     | 87/200 [2:27:33<3:12:52, 102.41s/it]Evaluating commonsenseqa :   6%|▋         | 13/200 [27:47<7:01:49, 135.35s/it]Evaluating commonsenseqa :  24%|██▎       | 47/200 [1:21:05<4:46:19, 112.29s/it]Evaluating commonsenseqa :  64%|██████▍   | 128/200 [2:19:29<1:17:24, 64.50s/it]Evaluating commonsenseqa :  84%|████████▍ | 168/200 [4:48:38<54:04, 101.38s/it]Evaluating commonsenseqa :  64%|██████▍   | 129/200 [2:20:35<1:16:54, 64.99s/it]Evaluating commonsenseqa :  44%|████▍     | 88/200 [2:29:16<3:11:43, 102.71s/it]Evaluating commonsenseqa :  24%|██▍       | 48/200 [1:22:58<4:44:47, 112.42s/it]Evaluating commonsenseqa :  84%|████████▍ | 169/200 [4:50:28<53:45, 104.06s/it]Evaluating commonsenseqa :   7%|▋         | 14/200 [30:06<7:02:53, 136.41s/it]Evaluating commonsenseqa :  65%|██████▌   | 130/200 [2:21:40<1:15:54, 65.06s/it]Evaluating commonsenseqa :  44%|████▍     | 89/200 [2:30:57<3:08:56, 102.13s/it]Evaluating commonsenseqa :  66%|██████▌   | 131/200 [2:22:46<1:15:12, 65.39s/it]Evaluating commonsenseqa :  85%|████████▌ | 170/200 [4:52:03<50:38, 101.28s/it]Evaluating commonsenseqa :  24%|██▍       | 49/200 [1:24:51<4:43:18, 112.57s/it]Evaluating commonsenseqa :  86%|████████▌ | 171/200 [4:52:27<37:46, 78.14s/it] Evaluating commonsenseqa :   8%|▊         | 15/200 [32:25<7:03:16, 137.28s/it]Evaluating commonsenseqa :  66%|██████▌   | 132/200 [2:23:52<1:14:05, 65.37s/it]Evaluating commonsenseqa :  45%|████▌     | 90/200 [2:32:41<3:08:08, 102.62s/it]Evaluating commonsenseqa :  25%|██▌       | 50/200 [1:26:43<4:41:30, 112.60s/it]Evaluating commonsenseqa :  66%|██████▋   | 133/200 [2:24:57<1:13:05, 65.46s/it]Evaluating commonsenseqa :  86%|████████▌ | 172/200 [4:54:18<41:04, 88.03s/it]Evaluating commonsenseqa :  46%|████▌     | 91/200 [2:34:24<3:06:38, 102.74s/it]Evaluating commonsenseqa :  26%|██▌       | 51/200 [1:27:48<4:03:49, 98.19s/it] Evaluating commonsenseqa :   8%|▊         | 16/200 [34:40<6:58:33, 136.49s/it]Evaluating commonsenseqa :  67%|██████▋   | 134/200 [2:26:03<1:12:13, 65.65s/it]Evaluating commonsenseqa :  86%|████████▋ | 173/200 [4:55:21<36:13, 80.49s/it]Evaluating commonsenseqa :  26%|██▌       | 52/200 [1:28:54<3:38:33, 88.61s/it]Evaluating commonsenseqa :  68%|██████▊   | 135/200 [2:27:09<1:11:15, 65.78s/it]Evaluating commonsenseqa :  46%|████▌     | 92/200 [2:36:07<3:04:53, 102.72s/it]Evaluating commonsenseqa :  87%|████████▋ | 174/200 [4:56:43<35:07, 81.06s/it]Evaluating commonsenseqa :  26%|██▋       | 53/200 [1:29:52<3:14:18, 79.31s/it]Evaluating commonsenseqa :  88%|████████▊ | 175/200 [4:57:11<27:05, 65.01s/it]Evaluating commonsenseqa :   8%|▊         | 17/200 [36:57<6:57:21, 136.84s/it]Evaluating commonsenseqa :  68%|██████▊   | 136/200 [2:28:15<1:09:59, 65.61s/it]Evaluating commonsenseqa :  27%|██▋       | 54/200 [1:30:51<2:58:05, 73.19s/it]Evaluating commonsenseqa :  46%|████▋     | 93/200 [2:37:50<3:03:32, 102.92s/it]Evaluating commonsenseqa :  68%|██████▊   | 137/200 [2:29:20<1:08:56, 65.65s/it]Evaluating commonsenseqa :  88%|████████▊ | 176/200 [4:58:40<28:50, 72.12s/it]Evaluating commonsenseqa :  69%|██████▉   | 138/200 [2:30:26<1:07:55, 65.73s/it]Evaluating commonsenseqa :   9%|▉         | 18/200 [39:15<6:55:30, 136.98s/it]Evaluating commonsenseqa :  28%|██▊       | 55/200 [1:32:44<3:26:10, 85.31s/it]Evaluating commonsenseqa :  47%|████▋     | 94/200 [2:39:34<3:02:38, 103.39s/it]Evaluating commonsenseqa :  88%|████████▊ | 177/200 [5:00:31<32:11, 83.96s/it]Evaluating commonsenseqa :  70%|██████▉   | 139/200 [2:31:31<1:06:37, 65.54s/it]Evaluating commonsenseqa :  10%|▉         | 19/200 [40:43<6:09:32, 122.50s/it]Evaluating commonsenseqa :  70%|███████   | 140/200 [2:32:37<1:05:28, 65.47s/it]Evaluating commonsenseqa :  28%|██▊       | 56/200 [1:34:38<3:44:54, 93.71s/it]Evaluating commonsenseqa :  48%|████▊     | 95/200 [2:41:18<3:01:03, 103.46s/it]Evaluating commonsenseqa :  89%|████████▉ | 178/200 [5:02:20<33:32, 91.47s/it]Evaluating commonsenseqa :  70%|███████   | 141/200 [2:33:42<1:04:21, 65.46s/it]Evaluating commonsenseqa :  28%|██▊       | 57/200 [1:35:35<3:17:02, 82.68s/it]Evaluating commonsenseqa :  10%|█         | 20/200 [43:02<6:22:02, 127.35s/it]Evaluating commonsenseqa :  48%|████▊     | 96/200 [2:43:01<2:59:07, 103.34s/it]Evaluating commonsenseqa :  71%|███████   | 142/200 [2:34:47<1:03:11, 65.36s/it]Evaluating commonsenseqa :  90%|████████▉ | 179/200 [5:04:00<32:51, 93.88s/it]Evaluating commonsenseqa :  29%|██▉       | 58/200 [1:37:25<3:35:25, 91.02s/it]Evaluating commonsenseqa :  72%|███████▏  | 143/200 [2:35:53<1:02:09, 65.44s/it]Evaluating commonsenseqa :  48%|████▊     | 97/200 [2:44:43<2:56:47, 102.98s/it]Evaluating commonsenseqa :  10%|█         | 21/200 [45:18<6:27:49, 130.00s/it]Evaluating commonsenseqa :  90%|█████████ | 180/200 [5:05:52<33:10, 99.51s/it]Evaluating commonsenseqa :  72%|███████▏  | 144/200 [2:36:58<1:01:06, 65.47s/it]Evaluating commonsenseqa :  30%|██▉       | 59/200 [1:39:20<3:50:26, 98.06s/it]Evaluating commonsenseqa :  49%|████▉     | 98/200 [2:46:27<2:55:24, 103.18s/it]Evaluating commonsenseqa :  72%|███████▎  | 145/200 [2:38:04<1:00:06, 65.58s/it]Evaluating commonsenseqa :  90%|█████████ | 181/200 [5:07:45<32:45, 103.46s/it]Evaluating commonsenseqa :  11%|█         | 22/200 [47:36<6:32:45, 132.39s/it]Evaluating commonsenseqa :  73%|███████▎  | 146/200 [2:39:10<59:10, 65.75s/it]  Evaluating commonsenseqa :  30%|███       | 60/200 [1:41:05<3:53:41, 100.15s/it]Evaluating commonsenseqa :  50%|████▉     | 99/200 [2:48:11<2:53:59, 103.36s/it]Evaluating commonsenseqa :  74%|███████▎  | 147/200 [2:40:16<58:02, 65.70s/it]Evaluating commonsenseqa :  30%|███       | 61/200 [1:42:18<3:33:43, 92.25s/it] Evaluating commonsenseqa :  91%|█████████ | 182/200 [5:09:37<31:49, 106.07s/it]Evaluating commonsenseqa :  12%|█▏        | 23/200 [49:52<6:33:45, 133.48s/it]Evaluating commonsenseqa :  31%|███       | 62/200 [1:43:03<2:59:39, 78.11s/it]Evaluating commonsenseqa :  50%|█████     | 100/200 [2:49:51<2:50:55, 102.56s/it]Evaluating commonsenseqa :  74%|███████▍  | 148/200 [2:41:21<56:53, 65.64s/it]Evaluating commonsenseqa :  92%|█████████▏| 183/200 [5:11:29<30:32, 107.79s/it]Evaluating commonsenseqa :  74%|███████▍  | 149/200 [2:42:26<55:38, 65.46s/it]Evaluating commonsenseqa :  50%|█████     | 101/200 [2:51:33<2:48:39, 102.22s/it]Evaluating commonsenseqa :  32%|███▏      | 63/200 [1:44:59<3:23:41, 89.21s/it]Evaluating commonsenseqa :  12%|█▏        | 24/200 [52:12<6:37:21, 135.46s/it]Evaluating commonsenseqa :  75%|███████▌  | 150/200 [2:43:32<54:29, 65.39s/it]Evaluating commonsenseqa :  92%|█████████▏| 184/200 [5:13:23<29:15, 109.70s/it]Evaluating commonsenseqa :  76%|███████▌  | 151/200 [2:44:37<53:22, 65.35s/it]Evaluating commonsenseqa :  51%|█████     | 102/200 [2:53:16<2:47:17, 102.42s/it]Evaluating commonsenseqa :  32%|███▏      | 64/200 [1:46:53<3:39:13, 96.71s/it]Evaluating commonsenseqa :  76%|███████▌  | 152/200 [2:45:43<52:24, 65.52s/it]Evaluating commonsenseqa :  12%|█▎        | 25/200 [54:31<6:38:07, 136.50s/it]Evaluating commonsenseqa :  92%|█████████▎| 185/200 [5:15:15<27:33, 110.25s/it]Evaluating commonsenseqa :  52%|█████▏    | 103/200 [2:54:59<2:45:51, 102.59s/it]Evaluating commonsenseqa :  76%|███████▋  | 153/200 [2:46:48<51:18, 65.50s/it]Evaluating commonsenseqa :  32%|███▎      | 65/200 [1:48:45<3:48:03, 101.36s/it]Evaluating commonsenseqa :  77%|███████▋  | 154/200 [2:47:54<50:08, 65.41s/it]Evaluating commonsenseqa :  93%|█████████▎| 186/200 [5:17:07<25:51, 110.86s/it]Evaluating commonsenseqa :  13%|█▎        | 26/200 [56:49<6:37:11, 136.96s/it]Evaluating commonsenseqa :  52%|█████▏    | 104/200 [2:56:40<2:43:36, 102.25s/it]Evaluating commonsenseqa :  33%|███▎      | 66/200 [1:50:38<3:53:57, 104.76s/it]Evaluating commonsenseqa :  78%|███████▊  | 155/200 [2:48:59<49:10, 65.57s/it]Evaluating commonsenseqa :  52%|█████▎    | 105/200 [2:58:23<2:42:08, 102.40s/it]Evaluating commonsenseqa :  94%|█████████▎| 187/200 [5:19:01<24:12, 111.76s/it]Evaluating commonsenseqa :  78%|███████▊  | 156/200 [2:50:05<48:09, 65.67s/it]Evaluating commonsenseqa :  14%|█▎        | 27/200 [59:07<6:35:48, 137.28s/it]Evaluating commonsenseqa :  34%|███▎      | 67/200 [1:52:29<3:56:45, 106.81s/it]Evaluating commonsenseqa :  78%|███████▊  | 157/200 [2:51:11<46:57, 65.52s/it]Evaluating commonsenseqa :  53%|█████▎    | 106/200 [3:00:04<2:39:57, 102.10s/it]Evaluating commonsenseqa :  94%|█████████▍| 188/200 [5:20:53<22:21, 111.83s/it]Evaluating commonsenseqa :  79%|███████▉  | 158/200 [2:52:03<43:02, 61.48s/it]Evaluating commonsenseqa :  34%|███▍      | 68/200 [1:54:24<3:59:58, 109.08s/it]Evaluating commonsenseqa :  94%|█████████▍| 189/200 [5:21:46<17:16, 94.24s/it] Evaluating commonsenseqa :  14%|█▍        | 28/200 [1:01:29<6:37:19, 138.60s/it]Evaluating commonsenseqa :  80%|███████▉  | 159/200 [2:53:08<42:45, 62.57s/it]Evaluating commonsenseqa :  54%|█████▎    | 107/200 [3:01:46<2:38:07, 102.02s/it]Evaluating commonsenseqa :  34%|███▍      | 69/200 [1:55:59<3:49:16, 105.01s/it]Evaluating commonsenseqa :  80%|████████  | 160/200 [2:54:13<42:20, 63.51s/it]Evaluating commonsenseqa :  95%|█████████▌| 190/200 [5:23:38<16:37, 99.73s/it]Evaluating commonsenseqa :  54%|█████▍    | 108/200 [3:03:26<2:35:36, 101.48s/it]Evaluating commonsenseqa :  14%|█▍        | 29/200 [1:03:49<6:35:54, 138.92s/it]Evaluating commonsenseqa :  80%|████████  | 161/200 [2:55:18<41:33, 63.93s/it]Evaluating commonsenseqa :  35%|███▌      | 70/200 [1:57:30<3:38:03, 100.64s/it]Evaluating commonsenseqa :  81%|████████  | 162/200 [2:56:25<40:55, 64.62s/it]Evaluating commonsenseqa :  96%|█████████▌| 191/200 [5:25:32<15:35, 103.99s/it]Evaluating commonsenseqa :  55%|█████▍    | 109/200 [3:05:10<2:34:54, 102.13s/it]Evaluating commonsenseqa :  15%|█▌        | 30/200 [1:06:08<6:33:50, 139.00s/it]Evaluating commonsenseqa :  36%|███▌      | 71/200 [1:59:22<3:43:38, 104.02s/it]Evaluating commonsenseqa :  82%|████████▏ | 163/200 [2:57:30<39:58, 64.82s/it]Evaluating commonsenseqa :  96%|█████████▌| 192/200 [5:27:24<14:09, 106.19s/it]Evaluating commonsenseqa :  55%|█████▌    | 110/200 [3:06:53<2:33:46, 102.51s/it]Evaluating commonsenseqa :  82%|████████▏ | 164/200 [2:58:36<39:11, 65.31s/it]Evaluating commonsenseqa :  36%|███▌      | 72/200 [2:01:17<3:49:12, 107.44s/it]Evaluating commonsenseqa :  82%|████████▎ | 165/200 [2:59:42<38:05, 65.30s/it]Evaluating commonsenseqa :  16%|█▌        | 31/200 [1:08:27<6:31:37, 139.04s/it]Evaluating commonsenseqa :  56%|█████▌    | 111/200 [3:08:38<2:32:47, 103.01s/it]Evaluating commonsenseqa :  96%|█████████▋| 193/200 [5:29:17<12:37, 108.26s/it]Evaluating commonsenseqa :  83%|████████▎ | 166/200 [3:00:47<37:03, 65.40s/it]Evaluating commonsenseqa :  36%|███▋      | 73/200 [2:03:07<3:49:12, 108.28s/it]Evaluating commonsenseqa :  97%|█████████▋| 194/200 [5:30:49<10:19, 103.29s/it]Evaluating commonsenseqa :  56%|█████▌    | 112/200 [3:10:18<2:29:58, 102.25s/it]Evaluating commonsenseqa :  84%|████████▎ | 167/200 [3:01:53<36:06, 65.64s/it]Evaluating commonsenseqa :  16%|█▌        | 32/200 [1:10:43<6:26:33, 138.05s/it]Evaluating commonsenseqa :  84%|████████▍ | 168/200 [3:03:00<35:06, 65.84s/it]Evaluating commonsenseqa :  37%|███▋      | 74/200 [2:05:04<3:52:39, 110.79s/it]Evaluating commonsenseqa :  56%|█████▋    | 113/200 [3:12:00<2:28:16, 102.26s/it]Evaluating commonsenseqa :  98%|█████████▊| 195/200 [5:32:43<08:53, 106.65s/it]Evaluating commonsenseqa :  84%|████████▍ | 169/200 [3:04:05<33:53, 65.60s/it]Evaluating commonsenseqa :  16%|█▋        | 33/200 [1:13:02<6:25:10, 138.39s/it]Evaluating commonsenseqa :  38%|███▊      | 75/200 [2:06:58<3:52:40, 111.69s/it]Evaluating commonsenseqa :  85%|████████▌ | 170/200 [3:05:10<32:42, 65.42s/it]Evaluating commonsenseqa :  57%|█████▋    | 114/200 [3:13:43<2:26:47, 102.41s/it]Evaluating commonsenseqa :  98%|█████████▊| 196/200 [5:34:27<07:03, 105.96s/it]Evaluating commonsenseqa :  86%|████████▌ | 171/200 [3:06:16<31:43, 65.65s/it]Evaluating commonsenseqa :  17%|█▋        | 34/200 [1:15:24<6:25:51, 139.47s/it]Evaluating commonsenseqa :  57%|█████▊    | 115/200 [3:15:24<2:24:39, 102.11s/it]Evaluating commonsenseqa :  38%|███▊      | 76/200 [2:08:51<3:52:03, 112.29s/it]Evaluating commonsenseqa :  98%|█████████▊| 197/200 [5:36:21<05:24, 108.11s/it]Evaluating commonsenseqa :  86%|████████▌ | 172/200 [3:07:21<30:36, 65.59s/it]Evaluating commonsenseqa :  86%|████████▋ | 173/200 [3:08:27<29:32, 65.64s/it]Evaluating commonsenseqa :  58%|█████▊    | 116/200 [3:17:08<2:23:33, 102.54s/it]Evaluating commonsenseqa :  38%|███▊      | 77/200 [2:10:46<3:51:55, 113.13s/it]Evaluating commonsenseqa :  18%|█▊        | 35/200 [1:17:46<6:25:56, 140.34s/it]Evaluating commonsenseqa :  99%|█████████▉| 198/200 [5:38:13<03:38, 109.44s/it]Evaluating commonsenseqa :  87%|████████▋ | 174/200 [3:09:33<28:31, 65.83s/it]Evaluating commonsenseqa :  58%|█████▊    | 117/200 [3:18:51<2:21:58, 102.64s/it]Evaluating commonsenseqa :  88%|████████▊ | 175/200 [3:10:39<27:26, 65.84s/it]Evaluating commonsenseqa :  39%|███▉      | 78/200 [2:12:42<3:51:39, 113.93s/it]Evaluating commonsenseqa : 100%|█████████▉| 199/200 [5:40:05<01:50, 110.16s/it]Evaluating commonsenseqa :  18%|█▊        | 36/200 [1:20:07<6:23:43, 140.39s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [5:40:41<00:00, 88.09s/it] Evaluating commonsenseqa : 100%|██████████| 200/200 [5:40:41<00:00, 102.21s/it]
name: commonsenseqa | avg. gen lenth: 243.606 | time: 20444.380330085754s
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10139 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o9-tmathqa-s30-rTrue --seed 30 --max-prompt-length 4096 --rationales --num-out-domain 9 9 11 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2023-09-20 11:00:15,176] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Evaluating commonsenseqa :  88%|████████▊ | 176/200 [3:11:45<26:17, 65.72s/it]using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o9-tmathqa-s30-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 9
  out_domain_data_name ......... mathqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o9-tmathqa-s30-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 340941.42it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.31s/it]
 > number of parameters: 6738415616
[2023-09-20 11:00:31,795] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.3, git-hash=unknown, git-branch=unknown
[2023-09-20 11:00:31,795] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-09-20 11:00:32,234] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-20 11:00:32,236] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2023-09-20 11:00:32,237] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-20 11:00:32,237] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-20 11:00:32,237] [INFO] [config.py:971:print]   amp_enabled .................. False
[2023-09-20 11:00:32,237] [INFO] [config.py:971:print]   amp_params ................... False
[2023-09-20 11:00:32,237] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-20 11:00:32,237] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2023-09-20 11:00:32,237] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2023-09-20 11:00:32,237] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2023-09-20 11:00:32,237] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2023-09-20 11:00:32,237] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fa78650ed70>
[2023-09-20 11:00:32,237] [INFO] [config.py:971:print]   communication_data_type ...... None
[2023-09-20 11:00:32,237] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-20 11:00:32,237] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2023-09-20 11:00:32,237] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2023-09-20 11:00:32,237] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-20 11:00:32,237] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2023-09-20 11:00:32,237] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2023-09-20 11:00:32,237] [INFO] [config.py:971:print]   disable_allgather ............ False
[2023-09-20 11:00:32,237] [INFO] [config.py:971:print]   dump_state ................... False
[2023-09-20 11:00:32,237] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   global_rank .................. 0
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   gradient_clipping ............ 0.0
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 2048
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   loss_scale ................... 0
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   optimizer_name ............... None
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   optimizer_params ............. None
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   pld_enabled .................. False
[2023-09-20 11:00:32,238] [INFO] [config.py:971:print]   pld_params ................... False
[2023-09-20 11:00:32,239] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2023-09-20 11:00:32,239] [INFO] [config.py:971:print]   scheduler_name ............... None
[2023-09-20 11:00:32,239] [INFO] [config.py:971:print]   scheduler_params ............. None
[2023-09-20 11:00:32,239] [INFO] [config.py:971:print]   sparse_attention ............. None
[2023-09-20 11:00:32,239] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2023-09-20 11:00:32,239] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2023-09-20 11:00:32,239] [INFO] [config.py:971:print]   train_batch_size ............. 1
[2023-09-20 11:00:32,239] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  1
[2023-09-20 11:00:32,239] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2023-09-20 11:00:32,239] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2023-09-20 11:00:32,239] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2023-09-20 11:00:32,239] [INFO] [config.py:971:print]   world_size ................... 1
[2023-09-20 11:00:32,239] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  True
[2023-09-20 11:00:32,239] [INFO] [config.py:971:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2023-09-20 11:00:32,239] [INFO] [config.py:971:print]   zero_enabled ................. False
[2023-09-20 11:00:32,239] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-20 11:00:32,239] [INFO] [config.py:971:print]   zero_optimization_stage ...... 0
[2023-09-20 11:00:32,239] [INFO] [config.py:957:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/200 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: the mean of 30 values was 140. it was detected on rechecking that one value 145 was wrongly copied as 135 for the computation of the mean. find the correct mean. a ) 151, b ) 140.33, c ) 152, d ) 148, e ) none of the above
Output: "corrected mean = 140 × 30 − 135 + 145 / 30 = 4200 − 135 + 145 / 30 = 4210 / 30 = 140.33 answer b"
So the final answer is b

Input: the measurement of a rectangular box with lid is 25 cmx 24 cmx 18 cm. find the volume of the largest sphere that can be inscribed in the box ( in terms of π cm 3 ). ( hint : the lowest measure of rectangular box represents the diameter of the largest sphere ) a ) 288, b ) 2302, c ) 2304, d ) 8640, e ) 964
Output: "d = 24, r = 12 ; volume of the largest sphere = 4 / 3 π r 3 = 4 / 3 * π * 12 * 12 * 12 = 2304 π cm 3 answer : c"
So the final answer is c

Input: a certain fraction has the same ratio to 1 / 33, as 3 / 4 does to 7 / 11. what is this certain fraction? a ) 1 / 14, b ) 1 / 18, c ) 1 / 21, d ) 1 / 25, e ) 1 / 28
Output: "x / ( 1 / 33 ) = ( 3 / 4 ) / ( 7 / 11 ) x = 3 * 11 * 1 / 33 * 4 * 7 = 1 / 28 the answer is e."
So the final answer is e

Input: what is the sum of all remainders obtained when the first 110 natural numbers are divided by 9? a ) 397, b ) 401, c ) 403, d ) 405, e ) 399
Output: "a positive integer can give only the following 9 remainders when divided by 9 : 1, 2, 3, 4, 5, 6, 7, 8, and 0. 1 divided by 9 gives the remainder of 1 ; 2 divided by 9 gives the remainder of 2 ;... 8 divided by 9 gives the remainder of 8 ; 9 divided by 9 gives the remainder of 0. we'll have 11 such blocks, since 99 / 9 = 11. the last will be : 91 divided by 9 gives the remainder of 1 ; 92 divided by 9 gives the remainder of 2 ;... 98 divided by 9 gives the remainder of 8 ; 99 divided by 9 gives the remainder of 0. the last number, 100, gives the remainder of 1 when divided by 9, thus the sum of all remainders will be : 11 ( 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 0 ) + 1 = 403. answer : c."
So the final answer is c

Input: a ’ s speed is 20 / 15 times that of b. if a and b run a race, what part of the length of the race should a give b as a head start, so that the race ends in a dead heat? a ) 1 / 17, b ) 3 / 17, c ) 1 / 10, d ) 5 / 20, e ) 3 / 10
Output: "we have the ratio of a ’ s speed and b ’ s speed. this means, we know how much distance a covers compared with b in the same time. this is what the beginning of the race will look like : ( start ) a _________ b ______________________________ if a covers 20 meters, b covers 15 meters in that time. so if the race is 20 meters long, when a reaches the finish line, b would be 5 meters behind him. if we want the race to end in a dead heat, we want b to be at the finish line too at the same time. this means b should get a head start of 5 meters so that he doesn ’ t need to cover that. in that case, the time required by a ( to cover 20 meters ) would be the same as the time required by b ( to cover 15 meters ) to reach the finish line. so b should get a head start of 5 / 20 th of the race. answer ( d )"
So the final answer is d

Input: find the average of all the numbers between 6 and 34 which are divisible by 7. a ) 18, b ) 20, c ) 17.5, d ) 30, e ) 32
Output: "solution average = ( 7 + 14 + 21 + 28 ) / 4 ) = 70 / 4 = 17.5. answer c"
So the final answer is c

Input: instead of multiplying a number by 5, the number is divided by 10. what is the percentage of error obtained? a ) 96 %, b ) 98 %, c ) 95 %, d ) 97 %, e ) 96 %
Output: "let the number be x the right number is 5 x the wrong number is x / 10 error is ( 5 x - x / 10 ) = 49 x / 10 percentage of error is ( ( 49 x / 10 ) / 5 x ) * 100 = 98 % answer : b"
So the final answer is b

Input: by selling an article at rs. 150, a profit of 25 % is made. find its cost price? a ) s. 486, b ) s. 455, c ) s. 487, d ) s. 120, e ) s. 489
Output: "sp = 150 cp = ( sp ) * [ 100 / ( 100 + p ) ] = 150 * [ 100 / ( 100 + 25 ) ] = 150 * [ 100 / 125 ] = rs. 120 answer : d"
So the final answer is d

Input: if 1 = 6, 2 = 12, 3 = 18, 4 = 24, 5 = 30, then 6 =? a ) 5, b ) 3, c ) 1, d ) 7, e ) 9
Output: solution : 1 as stated 1 = 6 = > 6 = 1 answer c
So the final answer is c

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o9-tmathqa-s30-rTrue-m4096
Evaluating commonsenseqa :  59%|█████▉    | 118/200 [3:20:33<2:19:56, 102.39s/it]Evaluating commonsenseqa :  40%|███▉      | 79/200 [2:14:37<3:50:10, 114.14s/it]Evaluating commonsenseqa :  88%|████████▊ | 177/200 [3:12:51<25:13, 65.82s/it]Evaluating commonsenseqa :   0%|          | 1/200 [01:35<5:16:30, 95.43s/it]Evaluating commonsenseqa :  60%|█████▉    | 119/200 [3:22:15<2:18:00, 102.23s/it]Evaluating commonsenseqa :  18%|█▊        | 37/200 [1:22:27<6:21:23, 140.39s/it]Evaluating commonsenseqa :  89%|████████▉ | 178/200 [3:13:56<24:07, 65.77s/it]Evaluating commonsenseqa :  40%|████      | 80/200 [2:16:32<3:48:43, 114.37s/it]Evaluating commonsenseqa :  90%|████████▉ | 179/200 [3:15:03<23:04, 65.92s/it]Evaluating commonsenseqa :   1%|          | 2/200 [03:10<5:14:19, 95.25s/it]Evaluating commonsenseqa :  60%|██████    | 120/200 [3:23:57<2:16:21, 102.27s/it]Evaluating commonsenseqa :  19%|█▉        | 38/200 [1:24:48<6:19:13, 140.45s/it]Evaluating commonsenseqa :  90%|█████████ | 180/200 [3:16:09<21:58, 65.91s/it]Evaluating commonsenseqa :  40%|████      | 81/200 [2:18:12<3:38:16, 110.05s/it]Evaluating commonsenseqa :   2%|▏         | 3/200 [04:44<5:10:51, 94.68s/it]Evaluating commonsenseqa :  60%|██████    | 121/200 [3:25:39<2:14:26, 102.11s/it]Evaluating commonsenseqa :  90%|█████████ | 181/200 [3:17:14<20:51, 65.89s/it]Evaluating commonsenseqa :  41%|████      | 82/200 [2:19:57<3:33:33, 108.59s/it]Evaluating commonsenseqa :   2%|▏         | 4/200 [06:18<5:08:29, 94.43s/it]Evaluating commonsenseqa :  91%|█████████ | 182/200 [3:18:20<19:45, 65.86s/it]Evaluating commonsenseqa :  20%|█▉        | 39/200 [1:27:06<6:15:01, 139.76s/it]Evaluating commonsenseqa :  61%|██████    | 122/200 [3:27:21<2:12:58, 102.29s/it]Evaluating commonsenseqa :  42%|████▏     | 83/200 [2:21:15<3:13:47, 99.38s/it] Evaluating commonsenseqa :  92%|█████████▏| 183/200 [3:19:26<18:38, 65.80s/it]Evaluating commonsenseqa :   2%|▎         | 5/200 [07:52<5:06:37, 94.34s/it]Evaluating commonsenseqa :  62%|██████▏   | 123/200 [3:29:05<2:11:45, 102.67s/it]Evaluating commonsenseqa :  92%|█████████▏| 184/200 [3:20:33<17:37, 66.10s/it]Evaluating commonsenseqa :  20%|██        | 40/200 [1:29:25<6:12:24, 139.66s/it]Evaluating commonsenseqa :  42%|████▏     | 84/200 [2:23:07<3:19:44, 103.32s/it]Evaluating commonsenseqa :   3%|▎         | 6/200 [09:28<5:06:51, 94.91s/it]Evaluating commonsenseqa :  92%|█████████▎| 185/200 [3:21:40<16:36, 66.44s/it]Evaluating commonsenseqa :  42%|████▎     | 85/200 [2:23:57<2:47:03, 87.16s/it] Evaluating commonsenseqa :  62%|██████▏   | 124/200 [3:30:48<2:10:04, 102.69s/it]Evaluating commonsenseqa :  93%|█████████▎| 186/200 [3:22:46<15:27, 66.24s/it]Evaluating commonsenseqa :  20%|██        | 41/200 [1:31:45<6:10:15, 139.72s/it]Evaluating commonsenseqa :   4%|▎         | 7/200 [11:03<5:05:19, 94.92s/it]Evaluating commonsenseqa :  94%|█████████▎| 187/200 [3:23:49<14:07, 65.21s/it]Evaluating commonsenseqa :  62%|██████▎   | 125/200 [3:32:29<2:07:55, 102.34s/it]Evaluating commonsenseqa :  43%|████▎     | 86/200 [2:25:49<3:00:05, 94.79s/it]Evaluating commonsenseqa :   4%|▍         | 8/200 [12:40<5:05:25, 95.45s/it]Evaluating commonsenseqa :  94%|█████████▍| 188/200 [3:24:54<13:04, 65.34s/it]Evaluating commonsenseqa :  21%|██        | 42/200 [1:34:07<6:09:34, 140.34s/it]Evaluating commonsenseqa :  63%|██████▎   | 126/200 [3:34:10<2:05:44, 101.95s/it]Evaluating commonsenseqa :  44%|████▎     | 87/200 [2:27:45<3:10:17, 101.04s/it]Evaluating commonsenseqa :  94%|█████████▍| 189/200 [3:25:59<11:58, 65.32s/it]Evaluating commonsenseqa :   4%|▍         | 9/200 [14:16<5:04:27, 95.64s/it]Evaluating commonsenseqa :  95%|█████████▌| 190/200 [3:27:05<10:53, 65.35s/it]Evaluating commonsenseqa :  64%|██████▎   | 127/200 [3:35:53<2:04:11, 102.08s/it]Evaluating commonsenseqa :  44%|████▍     | 88/200 [2:29:24<3:07:20, 100.36s/it]Evaluating commonsenseqa :  22%|██▏       | 43/200 [1:36:27<6:07:03, 140.28s/it]Evaluating commonsenseqa :   5%|▌         | 10/200 [15:51<5:02:21, 95.48s/it]Evaluating commonsenseqa :  96%|█████████▌| 191/200 [3:28:10<09:47, 65.27s/it]Evaluating commonsenseqa :  64%|██████▍   | 128/200 [3:37:34<2:02:16, 101.89s/it]Evaluating commonsenseqa :  96%|█████████▌| 192/200 [3:29:16<08:44, 65.62s/it]Evaluating commonsenseqa :  44%|████▍     | 89/200 [2:31:16<3:12:12, 103.89s/it]Evaluating commonsenseqa :   6%|▌         | 11/200 [17:27<5:01:22, 95.68s/it]Evaluating commonsenseqa :  22%|██▏       | 44/200 [1:38:45<6:03:01, 139.63s/it]Evaluating commonsenseqa :  96%|█████████▋| 193/200 [3:30:23<07:41, 65.90s/it]Evaluating commonsenseqa :  64%|██████▍   | 129/200 [3:39:16<2:00:35, 101.91s/it]Evaluating commonsenseqa :   6%|▌         | 12/200 [19:02<4:58:51, 95.38s/it]Evaluating commonsenseqa :  45%|████▌     | 90/200 [2:33:08<3:15:07, 106.43s/it]Evaluating commonsenseqa :  97%|█████████▋| 194/200 [3:31:28<06:34, 65.70s/it]Evaluating commonsenseqa :  22%|██▎       | 45/200 [1:41:03<5:59:02, 138.98s/it]Evaluating commonsenseqa :  65%|██████▌   | 130/200 [3:40:59<1:59:15, 102.22s/it]Evaluating commonsenseqa :  98%|█████████▊| 195/200 [3:32:34<05:28, 65.65s/it]Evaluating commonsenseqa :   6%|▋         | 13/200 [20:38<4:57:36, 95.49s/it]Evaluating commonsenseqa :  46%|████▌     | 91/200 [2:34:48<3:09:43, 104.43s/it]Evaluating commonsenseqa :  98%|█████████▊| 196/200 [3:33:39<04:22, 65.65s/it]Evaluating commonsenseqa :   7%|▋         | 14/200 [22:11<4:54:05, 94.87s/it]Evaluating commonsenseqa :  66%|██████▌   | 131/200 [3:42:44<1:58:31, 103.07s/it]Evaluating commonsenseqa :  23%|██▎       | 46/200 [1:43:24<5:58:14, 139.57s/it]Evaluating commonsenseqa :  98%|█████████▊| 197/200 [3:34:45<03:16, 65.54s/it]Evaluating commonsenseqa :  46%|████▌     | 92/200 [2:36:43<3:13:31, 107.51s/it]Evaluating commonsenseqa :   8%|▊         | 15/200 [23:47<4:53:39, 95.24s/it]Evaluating commonsenseqa :  99%|█████████▉| 198/200 [3:35:51<02:11, 65.93s/it]Evaluating commonsenseqa :  66%|██████▌   | 132/200 [3:44:28<1:57:07, 103.35s/it]Evaluating commonsenseqa :  46%|████▋     | 93/200 [2:38:36<3:14:43, 109.19s/it]Evaluating commonsenseqa :  24%|██▎       | 47/200 [1:45:40<5:53:18, 138.55s/it]Evaluating commonsenseqa : 100%|█████████▉| 199/200 [3:36:58<01:05, 65.99s/it]Evaluating commonsenseqa :   8%|▊         | 16/200 [25:23<4:52:22, 95.34s/it]Evaluating commonsenseqa :  66%|██████▋   | 133/200 [3:46:12<1:55:38, 103.56s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [3:38:03<00:00, 65.87s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [3:38:03<00:00, 65.42s/it]
name: commonsenseqa | avg. gen lenth: 371.451 | time: 13086.170297384262s
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10136 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o19-tmathqa-s10-rTrue --seed 10 --max-prompt-length 4096 --rationales --num-out-domain 19 17 19 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2023-09-20 11:26:43,087] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o19-tmathqa-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 19
  out_domain_data_name ......... mathqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o19-tmathqa-s10-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 224206.57it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.00s/it]
 > number of parameters: 6738415616
[2023-09-20 11:26:56,115] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.3, git-hash=unknown, git-branch=unknown
[2023-09-20 11:26:56,115] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-09-20 11:26:56,425] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-20 11:26:56,427] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2023-09-20 11:26:56,427] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-20 11:26:56,427] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-20 11:26:56,427] [INFO] [config.py:971:print]   amp_enabled .................. False
[2023-09-20 11:26:56,427] [INFO] [config.py:971:print]   amp_params ................... False
[2023-09-20 11:26:56,427] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-20 11:26:56,427] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2023-09-20 11:26:56,427] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2023-09-20 11:26:56,427] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2023-09-20 11:26:56,427] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2023-09-20 11:26:56,427] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fb3eda22d70>
[2023-09-20 11:26:56,427] [INFO] [config.py:971:print]   communication_data_type ...... None
[2023-09-20 11:26:56,427] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-20 11:26:56,427] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2023-09-20 11:26:56,427] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2023-09-20 11:26:56,427] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-20 11:26:56,427] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2023-09-20 11:26:56,427] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2023-09-20 11:26:56,427] [INFO] [config.py:971:print]   disable_allgather ............ False
[2023-09-20 11:26:56,427] [INFO] [config.py:971:print]   dump_state ................... False
[2023-09-20 11:26:56,427] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-20 11:26:56,427] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2023-09-20 11:26:56,427] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-20 11:26:56,427] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-20 11:26:56,427] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   global_rank .................. 0
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   gradient_clipping ............ 0.0
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 2048
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   loss_scale ................... 0
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   optimizer_name ............... None
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   optimizer_params ............. None
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   pld_enabled .................. False
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   pld_params ................... False
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   scheduler_name ............... None
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   scheduler_params ............. None
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   sparse_attention ............. None
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   train_batch_size ............. 1
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  1
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   world_size ................... 1
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  True
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   zero_enabled ................. False
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-20 11:26:56,428] [INFO] [config.py:971:print]   zero_optimization_stage ...... 0
[2023-09-20 11:26:56,428] [INFO] [config.py:957:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/200 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: in a recent head - to - head run - off election, 12000 absentee ballets were cast. 1 / 6 of the absentee ballets were thrown out and 3 / 5 of the remaining absentee ballets were cast for candidate a. how many absentee votes did candidate b receive? a ) 2,000, b ) 3,000, c ) 4,000, d ) 8,000, e ) 9,000
Output: 5 / 6 * 2 / 5 ( total absentee votes ) = 1 / 3 ( total votes ) = 1 / 3 * 12000 = 4000 answer is c
So the final answer is c

Input: the total age of a and b is 11 years more than the total age of b and c. c is how many years younger than a.? a ) 16, b ) 12, c ) 11, d ) 20, e ) 10
Output: "( a + b ) - ( b - c ) = 11 a - c = 11 answer is c"
So the final answer is c

Input: the scoring system in a certain football competition goes as follows : 3 points for victory, 1 point for a draw, and 0 points for defeat. each team plays 20 matches. if a team scored 14 points after 5 games, what is the least number of the remaining matches it has to win to reach the 40 - point mark by the end of the tournament? a ) 6, b ) 7, c ) 8, d ) 9, e ) 10
Output: "to get 40 points as end of season we need another 26 points or more from remaining 15 matches : option a = 6 * 3 + 9 * 1 = 27 hence option a - 6"
So the final answer is a

Input: how much water should be added to 10 liters of a 20 % - solution of alcohol to reduce the concentration of alcohol in the solution by 75 %? a ) 25 liters, b ) 27 liters, c ) 30 liters, d ) 32 liters, e ) 35 liters
Output: "let x ltr water to be added 2 ltr alcohol to be represented as ( 20 ( 1 - 3 / 4 ( new soln. = 10 + x ) ) ) 2 = 5 % * ( 10 + x ) - - - - - - - - > x = 30 answer : c"
So the final answer is c

Input: a goods train runs at the speed of 72 kmph and crosses a 250 m long platform in 36 seconds. what is the length of the goods train? a ) 470 m, b ) 240 m, c ) 260 m, d ) 270 m, e ) none of these
Output: "explanation : speed = [ 72 x ( 5 / 18 ) ] m / sec = 20 m / sec. time = 36 sec. let the length of the train be x metres. then, [ ( x + 250 ) / 36 ] = 20 = > x + 250 = 720 = > x = 470. answer : a"
So the final answer is a

Input: the volume of a cube is 1728 cc. find its surface. a ) 864, b ) 556, c ) 255, d ) 287, e ) 267
Output: "a 3 = 1728 = > a = 12 6 a 2 = 6 * 12 * 12 = 864 answer : a"
So the final answer is a

Input: a certain drink of type a is prepared by mixing 4 parts milk with 3 parts fruit juice. another drink of type b is prepared by mixing 4 parts of fruit juice and 3 parts of milk. how many liters of fruit juice must be added to 63 liters of drink a to convert it to drink b? a ) 7, b ) 14, c ) 21, d ) 28, e ) 35
Output: "in 63 liters of drink a, there are 36 liters of milk and 27 liters of juice. with 36 liters of milk, we need a total of 48 liters of juice to make drink b. we need to add 21 liters of juice. the answer is c."
So the final answer is c

Input: last week john spent 10 percent of his wages on recreation. this week, his wages are 10 percent less than last week ʼ s wages and he spent 40 percent of his wages on recreation. the amount he spends on recreation this week is what percent of the amount he spent on recreation last week a ) 180 %, b ) 360 %, c ) 200 %, d ) 220 %, e ) 250 %
Output: "say john's wages last week were $ 100, so he spent 0.10 * 100 = $ 10 on recreation ; this week's wages is 0.90 * 100 = $ 90, so he spends 0.4 * 90 = $ 36 on recreation ; 36 / 10 = 3.60, hence the amount he spends on recreation this week is 360 % of the amount he spent on recreation last week : 10 * 3.6 = 36 answer : b"
So the final answer is b

Input: the salary of a person was reduced by 15 %. by what percent should his reduced salary be raised so as to bring it at par with his original salary? a ) 10 %, b ) 17.6 %, c ) 13.7 %, d ) 15.1 %, e ) 12.3 %
Output: "let the original salary be $ 100 new salary = $ 85 increase on 85 = 15 increase on 100 = 15 / 85 * 100 = 17.6 % answer is b"
So the final answer is b

Input: if 20 men can build a water fountain 56 metres long in 7 days, what length of a similar water fountain can be built by 35 men in 3 days? a ) 40 m, b ) 42 m, c ) 47 m, d ) 49 m, e ) 50 m
Output: "explanation : let the required length be x metres more men, more length built ( direct proportion ) less days, less length built ( direct proportion ) men 20 : 35 days 7 : 3 : : 56 : x therefore ( 20 x 7 x x ) = ( 35 x 3 x 56 ) x = ( 35 x 3 x 56 ) / 140 = 42 hence, the required length is 42 m. answer : b"
So the final answer is b

Input: 12 men complete a work in 9 days. after they have worked for 6 days, 6 more men join them. how many days will they take to complete the remaining work? a ) 2 days, b ) 7 days, c ) 8 days, d ) 9 days, e ) 45 days
Output: 1 man's 1 day work = 1 / 108 12 men's 6 day's work = 1 / 9 * 6 = 2 / 3 remaining work = 1 - 2 / 3 = 1 / 3 18 men's 1 day work = 1 / 108 * 18 = 1 / 6 1 / 6 work is done by them in 1 day. 1 / 3 work is done by them in 6 * 1 / 3 = 2 days. answer : a
So the final answer is a

Input: a cheese factory sells its cheese in rectangular blocks. a normal block has a volume of 5 cubic feet. if a large block has twice the width, twice the depth, and the same length of a normal block, what is the volume of cheese in a large block in cubic feet? a ) 15, b ) 30, c ) 20, d ) 18, e ) 25
Output: "volume of cube = lbh = 5 new cube l, b, h are increases of l, 2 b, 2 h new volume of cube = l * 2 b * 2 h = 4 * lbh = 4 * 5 = 20 answer : c"
So the final answer is c

Input: two trains, one from howrah to patna and the other from patna to howrah, start simultaneously. after they meet, the trains reach their destinations after 64 hours and 25 hours respectively. the ratio of their speeds is? a ) 4 : 9, b ) 4 : 3, c ) 4 : 5, d ) 5 : 8, e ) 4 : 2
Output: "let us name the trains a and b. then, ( a's speed ) : ( b's speed ) = √ b : √ a = √ 25 : √ 64 = 5 : 8 answer : d"
So the final answer is d

Input: john had a stock of 1400 books in his bookshop. he sold 62 on monday, 62 on tuesday, 60 on wednesday, 48 on thursday and 40 on friday. what percentage of the books were not sold? a ) 81.57 %, b ) 36.5 %, c ) 80.67 %, d ) 56.5 %, e ) 80.57 %
Output: "let n be the total number of books sold. hence n = 62 + 62 + 60 + 48 + 40 = 272 let m be the books not sold m = 1400 - n = 1400 - 272 = 1128 percentage books not sold / total number of books = 1128 / 1200 = 0.81 = 80.57 % correct answer e"
So the final answer is e

Input: a and b can do a piece of work in 18 days ; band c can do it in 24 days a and c can do it in 36 days. in how many days will a, band c finish it together? a ) 15 days, b ) 12 days, c ) 8 days, d ) 16 days, e ) 9 days
Output: sol. ( a + b )'s 1 day's work = ( 1 / 18 ) ( b + c )'s 1 day's work = ( 1 / 24 ) and ( a + c )'s 1 day's work = ( 1 / 36 ) adding, we get : 2 ( a + b + c )'s 1 day's work = ¬ ( 1 / 18 + 1 / 24 + 1 / 36 ) = 9 / 72 = 1 / 8 ( a + b + c )'s 1 day's work = 1 / 16 thus, a, band c together can finish the work in 16 days. ans : d
So the final answer is d

Input: p, q and r have $ 9000 among themselves. r has two - thirds of the total amount with p and q. find the amount with r? a ) 2400, b ) 3600, c ) 3998, d ) 2539, e ) 1930
Output: "b 3600 let the amount with r be $ r r = 2 / 3 ( total amount with p and q ) r = 2 / 3 ( 9000 - r ) = > 3 r = 18000 - 2 r = > 5 r = 18000 = > r = 3600."
So the final answer is b

Input: the cost of the paint is rs. 40 per kg. if 1 kg of paint covers 20 sq. ft, how much will it cost to paint outside of a cube having 30 feet each side a ) rs. 962, b ) rs. 672, c ) rs. 546, d ) rs. 10800, e ) none of these
Output: "explanation : surface area of a cube = 6 x 30 ^ 2 = 5400 sq. ft quantity of paint required = ( 5400 / 20 ) = 270 kg cost of painting = 40 x 270 = rs. 10800 answer : d"
So the final answer is d

Input: a salesman's income consists of a commission and a base salary of $ 370 per week. over the past 5 weeks, his weekly income totals have been $ 406, $ 413, $ 420, $ 436 and $ 395. what must his average ( arithmetic mean ) commission be per week over the next two weeks so that his average weekly income is $ 500 over the 7 - week period? a ) $ 150, b ) $ 345, c ) $ 365, d ) $ 715, e ) $ 730
Output: "total weekly income over 5 weeks = $ 406 + $ 413 + $ 420 + $ 436 + $ 395 = $ 2070 for avg weekly income to be $ 500 over 7 weeks, we need total weekly income over 7 weeks = $ 3500 now, $ 3500 - $ 2070 = $ 1430 from this, we subtract base salary for 2 weeks i. e $ 370 * 2 = $ 740 therefore, commission = $ 1430 - $ 740 = $ 690 for 2 weeks avg weekly commission = $ 345 answer b"
So the final answer is b

Input: a 230 m long train running at the speed of 120 km / hr crosses another train running in opposite direction at the speed of 80 km / hr in 9 sec. what is the length of the other train? a ) 230, b ) 270, c ) 260, d ) 256, e ) 298
Output: "relative speed = 120 + 80 = 200 km / hr. = 200 * 5 / 18 = 500 / 9 m / sec. let the length of the other train be x m. then, ( x + 2340 ) / 9 = 500 / 9 = > x = 270. answer : b"
So the final answer is b

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o19-tmathqa-s10-rTrue-m4096
Evaluating commonsenseqa :   0%|          | 0/200 [00:07<?, ?it/s]
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 97, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 94, in main
    inference_main(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 90, in inference_main
    query_ids, response_ids, answers, indices = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 65, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 2154471) of binary: /home/ylu130/.conda/envs/ood/bin/python
Traceback (most recent call last):
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py", line 196, in <module>
    main()
  File "/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py", line 192, in main
    launch(args)
  File "/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py", line 177, in launch
    run(args)
  File "/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/ylu130/workspace/in-context-generalization/inference.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-09-20_11:27:06
  host      : ia1.wse.jhu.edu
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 2154471)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10136 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o17-tmathqa-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 17 17 19 True False 4096 5
Evaluating commonsenseqa :  47%|████▋     | 94/200 [2:40:27<3:14:01, 109.83s/it]/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2023-09-20 11:27:09,572] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o17-tmathqa-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 17
  out_domain_data_name ......... mathqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o17-tmathqa-s10-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 280995.29it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.02s/it]
 > number of parameters: 6738415616
[2023-09-20 11:27:22,464] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.3, git-hash=unknown, git-branch=unknown
[2023-09-20 11:27:22,464] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-09-20 11:27:22,787] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-20 11:27:22,788] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2023-09-20 11:27:22,788] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-20 11:27:22,788] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-20 11:27:22,788] [INFO] [config.py:971:print]   amp_enabled .................. False
[2023-09-20 11:27:22,788] [INFO] [config.py:971:print]   amp_params ................... False
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fa396222ef0>
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   communication_data_type ...... None
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   disable_allgather ............ False
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   dump_state ................... False
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   global_rank .................. 0
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   gradient_clipping ............ 0.0
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 2048
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   loss_scale ................... 0
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2023-09-20 11:27:22,789] [INFO] [config.py:971:print]   optimizer_name ............... None
[2023-09-20 11:27:22,790] [INFO] [config.py:971:print]   optimizer_params ............. None
[2023-09-20 11:27:22,790] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-20 11:27:22,790] [INFO] [config.py:971:print]   pld_enabled .................. False
[2023-09-20 11:27:22,790] [INFO] [config.py:971:print]   pld_params ................... False
[2023-09-20 11:27:22,790] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2023-09-20 11:27:22,790] [INFO] [config.py:971:print]   scheduler_name ............... None
[2023-09-20 11:27:22,790] [INFO] [config.py:971:print]   scheduler_params ............. None
[2023-09-20 11:27:22,790] [INFO] [config.py:971:print]   sparse_attention ............. None
[2023-09-20 11:27:22,790] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2023-09-20 11:27:22,790] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2023-09-20 11:27:22,790] [INFO] [config.py:971:print]   train_batch_size ............. 1
[2023-09-20 11:27:22,790] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  1
[2023-09-20 11:27:22,790] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2023-09-20 11:27:22,790] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2023-09-20 11:27:22,790] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2023-09-20 11:27:22,790] [INFO] [config.py:971:print]   world_size ................... 1
[2023-09-20 11:27:22,790] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  True
[2023-09-20 11:27:22,790] [INFO] [config.py:971:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2023-09-20 11:27:22,790] [INFO] [config.py:971:print]   zero_enabled ................. False
[2023-09-20 11:27:22,790] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-20 11:27:22,790] [INFO] [config.py:971:print]   zero_optimization_stage ...... 0
[2023-09-20 11:27:22,790] [INFO] [config.py:957:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/200 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: in a recent head - to - head run - off election, 12000 absentee ballets were cast. 1 / 6 of the absentee ballets were thrown out and 3 / 5 of the remaining absentee ballets were cast for candidate a. how many absentee votes did candidate b receive? a ) 2,000, b ) 3,000, c ) 4,000, d ) 8,000, e ) 9,000
Output: c

Input: the total age of a and b is 11 years more than the total age of b and c. c is how many years younger than a.? a ) 16, b ) 12, c ) 11, d ) 20, e ) 10
Output: c

Input: the scoring system in a certain football competition goes as follows : 3 points for victory, 1 point for a draw, and 0 points for defeat. each team plays 20 matches. if a team scored 14 points after 5 games, what is the least number of the remaining matches it has to win to reach the 40 - point mark by the end of the tournament? a ) 6, b ) 7, c ) 8, d ) 9, e ) 10
Output: a

Input: how much water should be added to 10 liters of a 20 % - solution of alcohol to reduce the concentration of alcohol in the solution by 75 %? a ) 25 liters, b ) 27 liters, c ) 30 liters, d ) 32 liters, e ) 35 liters
Output: c

Input: a goods train runs at the speed of 72 kmph and crosses a 250 m long platform in 36 seconds. what is the length of the goods train? a ) 470 m, b ) 240 m, c ) 260 m, d ) 270 m, e ) none of these
Output: a

Input: the volume of a cube is 1728 cc. find its surface. a ) 864, b ) 556, c ) 255, d ) 287, e ) 267
Output: a

Input: a certain drink of type a is prepared by mixing 4 parts milk with 3 parts fruit juice. another drink of type b is prepared by mixing 4 parts of fruit juice and 3 parts of milk. how many liters of fruit juice must be added to 63 liters of drink a to convert it to drink b? a ) 7, b ) 14, c ) 21, d ) 28, e ) 35
Output: c

Input: last week john spent 10 percent of his wages on recreation. this week, his wages are 10 percent less than last week ʼ s wages and he spent 40 percent of his wages on recreation. the amount he spends on recreation this week is what percent of the amount he spent on recreation last week a ) 180 %, b ) 360 %, c ) 200 %, d ) 220 %, e ) 250 %
Output: b

Input: the salary of a person was reduced by 15 %. by what percent should his reduced salary be raised so as to bring it at par with his original salary? a ) 10 %, b ) 17.6 %, c ) 13.7 %, d ) 15.1 %, e ) 12.3 %
Output: b

Input: if 20 men can build a water fountain 56 metres long in 7 days, what length of a similar water fountain can be built by 35 men in 3 days? a ) 40 m, b ) 42 m, c ) 47 m, d ) 49 m, e ) 50 m
Output: b

Input: 12 men complete a work in 9 days. after they have worked for 6 days, 6 more men join them. how many days will they take to complete the remaining work? a ) 2 days, b ) 7 days, c ) 8 days, d ) 9 days, e ) 45 days
Output: a

Input: a cheese factory sells its cheese in rectangular blocks. a normal block has a volume of 5 cubic feet. if a large block has twice the width, twice the depth, and the same length of a normal block, what is the volume of cheese in a large block in cubic feet? a ) 15, b ) 30, c ) 20, d ) 18, e ) 25
Output: c

Input: two trains, one from howrah to patna and the other from patna to howrah, start simultaneously. after they meet, the trains reach their destinations after 64 hours and 25 hours respectively. the ratio of their speeds is? a ) 4 : 9, b ) 4 : 3, c ) 4 : 5, d ) 5 : 8, e ) 4 : 2
Output: d

Input: john had a stock of 1400 books in his bookshop. he sold 62 on monday, 62 on tuesday, 60 on wednesday, 48 on thursday and 40 on friday. what percentage of the books were not sold? a ) 81.57 %, b ) 36.5 %, c ) 80.67 %, d ) 56.5 %, e ) 80.57 %
Output: e

Input: a and b can do a piece of work in 18 days ; band c can do it in 24 days a and c can do it in 36 days. in how many days will a, band c finish it together? a ) 15 days, b ) 12 days, c ) 8 days, d ) 16 days, e ) 9 days
Output: d

Input: p, q and r have $ 9000 among themselves. r has two - thirds of the total amount with p and q. find the amount with r? a ) 2400, b ) 3600, c ) 3998, d ) 2539, e ) 1930
Output: b

Input: the cost of the paint is rs. 40 per kg. if 1 kg of paint covers 20 sq. ft, how much will it cost to paint outside of a cube having 30 feet each side a ) rs. 962, b ) rs. 672, c ) rs. 546, d ) rs. 10800, e ) none of these
Output: d

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o17-tmathqa-s10-rFalse-m4096
Evaluating commonsenseqa :   8%|▊         | 17/200 [26:58<4:50:25, 95.22s/it]Evaluating commonsenseqa :  24%|██▍       | 48/200 [1:47:59<5:51:49, 138.88s/it]Evaluating commonsenseqa :  67%|██████▋   | 134/200 [3:47:53<1:53:01, 102.75s/it]Evaluating commonsenseqa :   0%|          | 1/200 [01:32<5:06:22, 92.37s/it]Evaluating commonsenseqa :  48%|████▊     | 95/200 [2:42:19<3:13:08, 110.37s/it]Evaluating commonsenseqa :   9%|▉         | 18/200 [28:32<4:47:45, 94.86s/it]Evaluating commonsenseqa :  68%|██████▊   | 135/200 [3:49:35<1:51:03, 102.52s/it]Evaluating commonsenseqa :  10%|▉         | 19/200 [29:19<4:02:51, 80.51s/it]Evaluating commonsenseqa :  24%|██▍       | 49/200 [1:50:16<5:48:04, 138.31s/it]Evaluating commonsenseqa :   1%|          | 2/200 [03:04<5:04:13, 92.19s/it]Evaluating commonsenseqa :  48%|████▊     | 96/200 [2:44:11<3:12:08, 110.85s/it]Evaluating commonsenseqa :  68%|██████▊   | 136/200 [3:51:18<1:49:31, 102.67s/it]Evaluating commonsenseqa :  10%|█         | 20/200 [30:54<4:15:05, 85.03s/it]Evaluating commonsenseqa :  48%|████▊     | 97/200 [2:45:09<2:43:03, 94.98s/it] Evaluating commonsenseqa :   2%|▏         | 3/200 [04:35<5:00:50, 91.63s/it]Evaluating commonsenseqa :  25%|██▌       | 50/200 [1:52:33<5:44:23, 137.76s/it]Evaluating commonsenseqa :  68%|██████▊   | 137/200 [3:53:01<1:47:50, 102.71s/it]Evaluating commonsenseqa :  10%|█         | 21/200 [32:29<4:22:47, 88.09s/it]Evaluating commonsenseqa :   2%|▏         | 4/200 [06:06<4:58:56, 91.51s/it]Evaluating commonsenseqa :  49%|████▉     | 98/200 [2:47:01<2:50:31, 100.31s/it]Evaluating commonsenseqa :  50%|████▉     | 99/200 [2:47:42<2:18:43, 82.41s/it] Evaluating commonsenseqa :  11%|█         | 22/200 [34:00<4:23:34, 88.84s/it]Evaluating commonsenseqa :  69%|██████▉   | 138/200 [3:54:43<1:45:56, 102.53s/it]Evaluating commonsenseqa :  26%|██▌       | 51/200 [1:54:54<5:44:57, 138.91s/it]Evaluating commonsenseqa :   2%|▎         | 5/200 [07:37<4:56:55, 91.36s/it]Evaluating commonsenseqa :  50%|█████     | 100/200 [2:48:50<2:10:17, 78.18s/it]Evaluating commonsenseqa :  12%|█▏        | 23/200 [35:35<4:27:07, 90.55s/it]Evaluating commonsenseqa :  70%|██████▉   | 139/200 [3:56:22<1:43:14, 101.55s/it]Evaluating commonsenseqa :   3%|▎         | 6/200 [09:09<4:55:44, 91.46s/it]Evaluating commonsenseqa :  26%|██▌       | 52/200 [1:57:12<5:41:20, 138.38s/it]Evaluating commonsenseqa :  50%|█████     | 101/200 [2:50:43<2:26:14, 88.63s/it]Evaluating commonsenseqa :   4%|▎         | 7/200 [10:07<4:19:01, 80.52s/it]Evaluating commonsenseqa :  12%|█▏        | 24/200 [37:10<4:30:01, 92.05s/it]Evaluating commonsenseqa :  51%|█████     | 102/200 [2:51:06<1:52:37, 68.95s/it]Evaluating commonsenseqa :  70%|███████   | 140/200 [3:58:06<1:42:19, 102.32s/it]Evaluating commonsenseqa :   4%|▍         | 8/200 [10:55<3:44:45, 70.24s/it]Evaluating commonsenseqa :  26%|██▋       | 53/200 [1:59:29<5:38:08, 138.02s/it]Evaluating commonsenseqa :  12%|█▎        | 25/200 [38:46<4:32:10, 93.31s/it]Evaluating commonsenseqa :  52%|█████▏    | 103/200 [2:52:56<2:11:19, 81.23s/it]Evaluating commonsenseqa :   4%|▍         | 9/200 [12:26<4:03:44, 76.57s/it]Evaluating commonsenseqa :  70%|███████   | 141/200 [3:59:49<1:40:51, 102.57s/it]Evaluating commonsenseqa :  13%|█▎        | 26/200 [40:21<4:31:50, 93.74s/it]Evaluating commonsenseqa :   5%|▌         | 10/200 [13:56<4:15:55, 80.82s/it]Evaluating commonsenseqa :  52%|█████▏    | 104/200 [2:54:45<2:23:08, 89.46s/it]Evaluating commonsenseqa :  71%|███████   | 142/200 [4:01:32<1:39:17, 102.71s/it]Evaluating commonsenseqa :  27%|██▋       | 54/200 [2:01:46<5:35:21, 137.82s/it]Evaluating commonsenseqa :  14%|█▎        | 27/200 [41:56<4:31:04, 94.02s/it]Evaluating commonsenseqa :   6%|▌         | 11/200 [15:26<4:23:45, 83.73s/it]Evaluating commonsenseqa :  72%|███████▏  | 143/200 [4:03:08<1:35:41, 100.72s/it]Evaluating commonsenseqa :  52%|█████▎    | 105/200 [2:56:34<2:31:03, 95.40s/it]Evaluating commonsenseqa :   6%|▌         | 12/200 [16:20<3:53:37, 74.56s/it]Evaluating commonsenseqa :  28%|██▊       | 55/200 [2:04:03<5:32:15, 137.48s/it]Evaluating commonsenseqa :  14%|█▍        | 28/200 [43:30<4:29:33, 94.03s/it]Evaluating commonsenseqa :   6%|▋         | 13/200 [16:48<3:08:52, 60.60s/it]Evaluating commonsenseqa :   7%|▋         | 14/200 [17:28<2:48:03, 54.21s/it]Evaluating commonsenseqa :  72%|███████▏  | 144/200 [4:04:51<1:34:33, 101.31s/it]Evaluating commonsenseqa :  53%|█████▎    | 106/200 [2:58:27<2:37:34, 100.58s/it]Evaluating commonsenseqa :  14%|█▍        | 29/200 [45:04<4:27:55, 94.01s/it]Evaluating commonsenseqa :  28%|██▊       | 56/200 [2:06:17<5:27:54, 136.63s/it]Evaluating commonsenseqa :   8%|▊         | 15/200 [18:59<3:21:26, 65.33s/it]Evaluating commonsenseqa :  72%|███████▎  | 145/200 [4:06:32<1:32:46, 101.20s/it]Evaluating commonsenseqa :  54%|█████▎    | 107/200 [3:00:19<2:41:13, 104.02s/it]Evaluating commonsenseqa :  15%|█▌        | 30/200 [46:40<4:28:07, 94.63s/it]Evaluating commonsenseqa :   8%|▊         | 16/200 [20:23<3:37:42, 70.99s/it]Evaluating commonsenseqa :  28%|██▊       | 57/200 [2:08:24<5:18:15, 133.54s/it]Evaluating commonsenseqa :  73%|███████▎  | 146/200 [4:08:14<1:31:17, 101.44s/it]Evaluating commonsenseqa :  16%|█▌        | 31/200 [48:13<4:25:28, 94.25s/it]Evaluating commonsenseqa :  54%|█████▍    | 108/200 [3:02:11<2:43:20, 106.53s/it]Evaluating commonsenseqa :   8%|▊         | 17/200 [21:41<3:42:44, 73.03s/it]Evaluating commonsenseqa :  55%|█████▍    | 109/200 [3:03:14<2:21:39, 93.40s/it] Evaluating commonsenseqa :  74%|███████▎  | 147/200 [4:09:55<1:29:27, 101.28s/it]Evaluating commonsenseqa :  16%|█▌        | 32/200 [49:47<4:23:18, 94.04s/it]Evaluating commonsenseqa :  29%|██▉       | 58/200 [2:10:41<5:18:38, 134.63s/it]Evaluating commonsenseqa :   9%|▉         | 18/200 [23:12<3:57:57, 78.45s/it]Evaluating commonsenseqa :  74%|███████▍  | 148/200 [4:11:35<1:27:26, 100.90s/it]Evaluating commonsenseqa :  55%|█████▌    | 110/200 [3:05:04<2:27:36, 98.41s/it]Evaluating commonsenseqa :  16%|█▋        | 33/200 [51:23<4:23:10, 94.56s/it]Evaluating commonsenseqa :  10%|▉         | 19/200 [24:41<4:06:26, 81.69s/it]Evaluating commonsenseqa :  56%|█████▌    | 111/200 [3:05:45<2:00:28, 81.22s/it]Evaluating commonsenseqa :  30%|██▉       | 59/200 [2:13:01<5:19:51, 136.11s/it]Evaluating commonsenseqa :  74%|███████▍  | 149/200 [4:12:55<1:20:29, 94.69s/it] Evaluating commonsenseqa :  17%|█▋        | 34/200 [52:57<4:21:04, 94.37s/it]Evaluating commonsenseqa :  10%|█         | 20/200 [26:12<4:12:50, 84.28s/it]Evaluating commonsenseqa :  56%|█████▌    | 112/200 [3:07:37<2:12:35, 90.40s/it]Evaluating commonsenseqa :  75%|███████▌  | 150/200 [4:14:39<1:21:09, 97.39s/it]Evaluating commonsenseqa :  10%|█         | 21/200 [27:41<4:15:47, 85.74s/it]Evaluating commonsenseqa :  18%|█▊        | 35/200 [54:32<4:20:31, 94.74s/it]Evaluating commonsenseqa :  30%|███       | 60/200 [2:15:16<5:17:19, 136.00s/it]Evaluating commonsenseqa :  56%|█████▋    | 113/200 [3:09:28<2:19:58, 96.54s/it]Evaluating commonsenseqa :  76%|███████▌  | 151/200 [4:16:21<1:20:44, 98.87s/it]Evaluating commonsenseqa :  11%|█         | 22/200 [29:13<4:20:09, 87.69s/it]Evaluating commonsenseqa :  18%|█▊        | 36/200 [56:08<4:19:28, 94.93s/it]Evaluating commonsenseqa :  30%|███       | 61/200 [2:17:35<5:17:03, 136.86s/it]Evaluating commonsenseqa :  57%|█████▋    | 114/200 [3:11:19<2:24:37, 100.90s/it]Evaluating commonsenseqa :  76%|███████▌  | 152/200 [4:18:03<1:19:44, 99.67s/it]Evaluating commonsenseqa :  12%|█▏        | 23/200 [30:43<4:20:52, 88.43s/it]Evaluating commonsenseqa :  18%|█▊        | 37/200 [57:41<4:16:31, 94.43s/it]Evaluating commonsenseqa :  31%|███       | 62/200 [2:18:28<4:16:44, 111.63s/it]Evaluating commonsenseqa :  57%|█████▊    | 115/200 [3:12:13<2:02:46, 86.66s/it] Evaluating commonsenseqa :  76%|███████▋  | 153/200 [4:19:32<1:15:31, 96.41s/it]Evaluating commonsenseqa :  12%|█▏        | 24/200 [32:14<4:21:32, 89.16s/it]Evaluating commonsenseqa :  19%|█▉        | 38/200 [59:16<4:15:14, 94.53s/it]Evaluating commonsenseqa :  32%|███▏      | 63/200 [2:20:45<4:32:17, 119.25s/it]Evaluating commonsenseqa :  58%|█████▊    | 116/200 [3:14:07<2:13:07, 95.09s/it]Evaluating commonsenseqa :  12%|█▎        | 25/200 [33:44<4:21:17, 89.59s/it]Evaluating commonsenseqa :  77%|███████▋  | 154/200 [4:21:16<1:15:40, 98.70s/it]Evaluating commonsenseqa :  20%|█▉        | 39/200 [1:00:49<4:12:29, 94.10s/it]Evaluating commonsenseqa :  13%|█▎        | 26/200 [35:18<4:22:47, 90.62s/it]Evaluating commonsenseqa :  58%|█████▊    | 117/200 [3:16:02<2:19:36, 100.92s/it]Evaluating commonsenseqa :  32%|███▏      | 64/200 [2:23:01<4:41:46, 124.31s/it]Evaluating commonsenseqa :  20%|██        | 40/200 [1:02:24<4:12:03, 94.52s/it]Evaluating commonsenseqa :  78%|███████▊  | 155/200 [4:22:59<1:15:08, 100.18s/it]Evaluating commonsenseqa :  14%|█▎        | 27/200 [36:49<4:22:11, 90.93s/it]Evaluating commonsenseqa :  59%|█████▉    | 118/200 [3:17:52<2:21:40, 103.67s/it]Evaluating commonsenseqa :  20%|██        | 41/200 [1:03:59<4:11:07, 94.76s/it]Evaluating commonsenseqa :  78%|███████▊  | 156/200 [4:24:40<1:13:30, 100.24s/it]Evaluating commonsenseqa :  32%|███▎      | 65/200 [2:25:19<4:48:37, 128.28s/it]Evaluating commonsenseqa :  14%|█▍        | 28/200 [38:11<4:13:12, 88.33s/it]Evaluating commonsenseqa :  21%|██        | 42/200 [1:05:15<3:54:37, 89.10s/it]Evaluating commonsenseqa :  78%|███████▊  | 157/200 [4:26:22<1:12:21, 100.96s/it]Evaluating commonsenseqa :  60%|█████▉    | 119/200 [3:19:45<2:23:44, 106.48s/it]Evaluating commonsenseqa :  14%|█▍        | 29/200 [39:06<3:42:29, 78.07s/it]Evaluating commonsenseqa :  22%|██▏       | 43/200 [1:06:22<3:35:18, 82.28s/it]Evaluating commonsenseqa :  33%|███▎      | 66/200 [2:27:34<4:51:29, 130.52s/it]Evaluating commonsenseqa :  15%|█▌        | 30/200 [40:16<3:34:34, 75.73s/it]Evaluating commonsenseqa :  79%|███████▉  | 158/200 [4:28:07<1:11:21, 101.95s/it]Evaluating commonsenseqa :  60%|██████    | 120/200 [3:21:35<2:23:13, 107.42s/it]Evaluating commonsenseqa :  22%|██▏       | 44/200 [1:07:56<3:43:08, 85.82s/it]Evaluating commonsenseqa :  22%|██▎       | 45/200 [1:08:15<2:49:59, 65.80s/it]Evaluating commonsenseqa :  16%|█▌        | 31/200 [41:25<3:27:24, 73.63s/it]Evaluating commonsenseqa :  60%|██████    | 121/200 [3:22:42<2:05:35, 95.39s/it] Evaluating commonsenseqa :  34%|███▎      | 67/200 [2:29:50<4:52:32, 131.97s/it]Evaluating commonsenseqa :  80%|███████▉  | 159/200 [4:29:49<1:09:50, 102.21s/it]Evaluating commonsenseqa :  16%|█▌        | 32/200 [42:55<3:40:14, 78.66s/it]Evaluating commonsenseqa :  23%|██▎       | 46/200 [1:09:52<3:12:42, 75.08s/it]Evaluating commonsenseqa :  61%|██████    | 122/200 [3:24:32<2:09:43, 99.79s/it]Evaluating commonsenseqa :  80%|████████  | 160/200 [4:31:32<1:08:10, 102.26s/it]Evaluating commonsenseqa :  16%|█▋        | 33/200 [44:25<3:48:28, 82.09s/it]Evaluating commonsenseqa :  34%|███▍      | 68/200 [2:32:06<4:53:18, 133.32s/it]Evaluating commonsenseqa :  24%|██▎       | 47/200 [1:11:25<3:25:37, 80.64s/it]Evaluating commonsenseqa :  62%|██████▏   | 123/200 [3:26:23<2:12:34, 103.31s/it]Evaluating commonsenseqa :  80%|████████  | 161/200 [4:33:12<1:06:05, 101.68s/it]Evaluating commonsenseqa :  17%|█▋        | 34/200 [45:55<3:54:02, 84.59s/it]Evaluating commonsenseqa :  24%|██▍       | 48/200 [1:13:01<3:35:55, 85.23s/it]Evaluating commonsenseqa :  34%|███▍      | 69/200 [2:34:25<4:54:38, 134.95s/it]Evaluating commonsenseqa :  18%|█▊        | 35/200 [47:28<3:59:12, 86.98s/it]Evaluating commonsenseqa :  62%|██████▏   | 124/200 [3:28:16<2:14:13, 105.97s/it]Evaluating commonsenseqa :  81%|████████  | 162/200 [4:34:56<1:04:52, 102.43s/it]Evaluating commonsenseqa :  24%|██▍       | 49/200 [1:14:37<3:42:38, 88.46s/it]Evaluating commonsenseqa :  35%|███▌      | 70/200 [2:35:55<4:23:00, 121.38s/it]Evaluating commonsenseqa :  18%|█▊        | 36/200 [48:57<3:59:41, 87.69s/it]Evaluating commonsenseqa :  82%|████████▏ | 163/200 [4:36:39<1:03:15, 102.58s/it]Evaluating commonsenseqa :  25%|██▌       | 50/200 [1:16:09<3:43:32, 89.42s/it]Evaluating commonsenseqa :  62%|██████▎   | 125/200 [3:30:07<2:14:29, 107.59s/it]Evaluating commonsenseqa :  18%|█▊        | 37/200 [50:30<4:01:52, 89.03s/it]Evaluating commonsenseqa :  36%|███▌      | 71/200 [2:38:11<4:30:55, 126.01s/it]Evaluating commonsenseqa :  26%|██▌       | 51/200 [1:17:44<3:46:24, 91.17s/it]Evaluating commonsenseqa :  82%|████████▏ | 164/200 [4:38:21<1:01:28, 102.45s/it]Evaluating commonsenseqa :  63%|██████▎   | 126/200 [3:31:50<2:10:58, 106.20s/it]Evaluating commonsenseqa :  19%|█▉        | 38/200 [52:01<4:02:22, 89.77s/it]Evaluating commonsenseqa :  26%|██▌       | 52/200 [1:19:19<3:47:51, 92.37s/it]Evaluating commonsenseqa :  82%|████████▎ | 165/200 [4:40:05<59:55, 102.73s/it]  Evaluating commonsenseqa :  36%|███▌      | 72/200 [2:40:29<4:36:16, 129.50s/it]Evaluating commonsenseqa :  64%|██████▎   | 127/200 [3:33:43<2:11:54, 108.41s/it]Evaluating commonsenseqa :  20%|█▉        | 39/200 [53:32<4:01:34, 90.03s/it]Evaluating commonsenseqa :  26%|██▋       | 53/200 [1:20:56<3:49:38, 93.73s/it]Evaluating commonsenseqa :  83%|████████▎ | 166/200 [4:41:47<58:09, 102.62s/it]Evaluating commonsenseqa :  64%|██████▍   | 128/200 [3:35:12<2:02:59, 102.50s/it]Evaluating commonsenseqa :  20%|██        | 40/200 [55:04<4:01:38, 90.62s/it]Evaluating commonsenseqa :  36%|███▋      | 73/200 [2:42:49<4:40:44, 132.63s/it]Evaluating commonsenseqa :  27%|██▋       | 54/200 [1:22:32<3:49:35, 94.35s/it]Evaluating commonsenseqa :  64%|██████▍   | 129/200 [3:36:42<1:56:51, 98.75s/it] Evaluating commonsenseqa :  84%|████████▎ | 167/200 [4:43:31<56:43, 103.13s/it]Evaluating commonsenseqa :  20%|██        | 41/200 [56:28<3:55:31, 88.88s/it]Evaluating commonsenseqa :  28%|██▊       | 55/200 [1:23:57<3:40:57, 91.43s/it]Evaluating commonsenseqa :  37%|███▋      | 74/200 [2:45:09<4:42:55, 134.73s/it]Evaluating commonsenseqa :  84%|████████▍ | 168/200 [4:45:15<55:05, 103.30s/it]Evaluating commonsenseqa :  65%|██████▌   | 130/200 [3:38:36<2:00:20, 103.15s/it]Evaluating commonsenseqa :  21%|██        | 42/200 [58:00<3:56:29, 89.81s/it]Evaluating commonsenseqa :  66%|██████▌   | 131/200 [3:39:27<1:40:43, 87.58s/it] Evaluating commonsenseqa :  28%|██▊       | 56/200 [1:25:35<3:44:14, 93.43s/it]Evaluating commonsenseqa :  84%|████████▍ | 169/200 [4:47:01<53:43, 103.98s/it]Evaluating commonsenseqa :  22%|██▏       | 43/200 [59:39<4:02:11, 92.56s/it]Evaluating commonsenseqa :  38%|███▊      | 75/200 [2:47:29<4:44:09, 136.40s/it]Evaluating commonsenseqa :  66%|██████▌   | 132/200 [3:40:55<1:39:29, 87.79s/it]Evaluating commonsenseqa :  28%|██▊       | 57/200 [1:27:09<3:43:11, 93.65s/it]Evaluating commonsenseqa :  22%|██▏       | 44/200 [1:01:11<3:59:31, 92.13s/it]Evaluating commonsenseqa :  29%|██▉       | 58/200 [1:28:09<3:17:44, 83.55s/it]Evaluating commonsenseqa :  85%|████████▌ | 170/200 [4:48:43<51:47, 103.58s/it]Evaluating commonsenseqa :  66%|██████▋   | 133/200 [3:42:47<1:46:09, 95.07s/it]Evaluating commonsenseqa :  38%|███▊      | 76/200 [2:49:48<4:43:14, 137.05s/it]Evaluating commonsenseqa :  22%|██▎       | 45/200 [1:02:41<3:56:40, 91.62s/it]Evaluating commonsenseqa :  30%|██▉       | 59/200 [1:29:43<3:23:41, 86.68s/it]Evaluating commonsenseqa :  86%|████████▌ | 171/200 [4:50:25<49:45, 102.96s/it]Evaluating commonsenseqa :  67%|██████▋   | 134/200 [3:44:39<1:50:03, 100.06s/it]Evaluating commonsenseqa :  23%|██▎       | 46/200 [1:04:12<3:54:40, 91.43s/it]Evaluating commonsenseqa :  30%|███       | 60/200 [1:31:19<3:29:01, 89.58s/it]Evaluating commonsenseqa :  38%|███▊      | 77/200 [2:52:10<4:44:06, 138.59s/it]Evaluating commonsenseqa :  86%|████████▌ | 172/200 [4:52:08<48:01, 102.90s/it]Evaluating commonsenseqa :  24%|██▎       | 47/200 [1:05:41<3:51:28, 90.77s/it]Evaluating commonsenseqa :  68%|██████▊   | 135/200 [3:46:31<1:52:19, 103.68s/it]Evaluating commonsenseqa :  30%|███       | 61/200 [1:32:53<3:30:27, 90.85s/it]Evaluating commonsenseqa :  86%|████████▋ | 173/200 [4:53:50<46:16, 102.82s/it]Evaluating commonsenseqa :  39%|███▉      | 78/200 [2:54:32<4:44:16, 139.81s/it]Evaluating commonsenseqa :  24%|██▍       | 48/200 [1:07:13<3:50:46, 91.10s/it]Evaluating commonsenseqa :  31%|███       | 62/200 [1:34:26<3:30:18, 91.44s/it]Evaluating commonsenseqa :  68%|██████▊   | 136/200 [3:48:21<1:52:30, 105.48s/it]Evaluating commonsenseqa :  87%|████████▋ | 174/200 [4:55:32<44:27, 102.61s/it]Evaluating commonsenseqa :  24%|██▍       | 49/200 [1:08:43<3:48:42, 90.88s/it]Evaluating commonsenseqa :  32%|███▏      | 63/200 [1:35:40<3:16:49, 86.20s/it]Evaluating commonsenseqa :  40%|███▉      | 79/200 [2:56:52<4:41:52, 139.77s/it]Evaluating commonsenseqa :  68%|██████▊   | 137/200 [3:50:13<1:53:00, 107.62s/it]Evaluating commonsenseqa :  25%|██▌       | 50/200 [1:09:49<3:28:11, 83.28s/it]Evaluating commonsenseqa :  88%|████████▊ | 175/200 [4:57:17<43:01, 103.26s/it]Evaluating commonsenseqa :  32%|███▏      | 64/200 [1:37:14<3:20:54, 88.64s/it]Evaluating commonsenseqa :  69%|██████▉   | 138/200 [3:51:44<1:45:56, 102.52s/it]Evaluating commonsenseqa :  26%|██▌       | 51/200 [1:11:20<3:32:16, 85.48s/it]Evaluating commonsenseqa :  40%|████      | 80/200 [2:59:10<4:38:32, 139.27s/it]Evaluating commonsenseqa :  88%|████████▊ | 176/200 [4:58:59<41:11, 102.96s/it]Evaluating commonsenseqa :  26%|██▌       | 52/200 [1:11:50<2:49:49, 68.85s/it]Evaluating commonsenseqa :  32%|███▎      | 65/200 [1:38:49<3:23:27, 90.43s/it]Evaluating commonsenseqa :  70%|██████▉   | 139/200 [3:52:50<1:32:58, 91.45s/it] Evaluating commonsenseqa :  26%|██▋       | 53/200 [1:12:24<2:23:09, 58.43s/it]Evaluating commonsenseqa :  88%|████████▊ | 177/200 [5:00:41<39:16, 102.47s/it]Evaluating commonsenseqa :  33%|███▎      | 66/200 [1:40:23<3:24:17, 91.48s/it]Evaluating commonsenseqa :  40%|████      | 81/200 [3:01:25<4:33:35, 137.94s/it]Evaluating commonsenseqa :  27%|██▋       | 54/200 [1:13:54<2:45:14, 67.90s/it]Evaluating commonsenseqa :  70%|███████   | 140/200 [3:54:41<1:37:33, 97.55s/it]Evaluating commonsenseqa :  89%|████████▉ | 178/200 [5:02:21<37:20, 101.86s/it]Evaluating commonsenseqa :  34%|███▎      | 67/200 [1:41:58<3:25:10, 92.56s/it]Evaluating commonsenseqa :  28%|██▊       | 55/200 [1:15:26<3:01:47, 75.22s/it]Evaluating commonsenseqa :  70%|███████   | 141/200 [3:56:18<1:35:36, 97.22s/it]Evaluating commonsenseqa :  41%|████      | 82/200 [3:03:46<4:32:52, 138.75s/it]Evaluating commonsenseqa :  34%|███▍      | 68/200 [1:43:32<3:24:35, 93.00s/it]Evaluating commonsenseqa :  90%|████████▉ | 179/200 [5:04:05<35:53, 102.56s/it]Evaluating commonsenseqa :  28%|██▊       | 56/200 [1:16:58<3:12:15, 80.11s/it]Evaluating commonsenseqa :  71%|███████   | 142/200 [3:58:10<1:38:16, 101.66s/it]Evaluating commonsenseqa :  34%|███▍      | 69/200 [1:45:08<3:25:07, 93.95s/it]Evaluating commonsenseqa :  90%|█████████ | 180/200 [5:05:48<34:09, 102.46s/it]Evaluating commonsenseqa :  28%|██▊       | 57/200 [1:18:28<3:18:31, 83.29s/it]Evaluating commonsenseqa :  42%|████▏     | 83/200 [3:06:05<4:31:06, 139.03s/it]Evaluating commonsenseqa :  72%|███████▏  | 143/200 [4:00:04<1:40:10, 105.45s/it]Evaluating commonsenseqa :  35%|███▌      | 70/200 [1:46:41<3:23:04, 93.72s/it]Evaluating commonsenseqa :  29%|██▉       | 58/200 [1:20:01<3:23:38, 86.05s/it]Evaluating commonsenseqa :  90%|█████████ | 181/200 [5:07:31<32:34, 102.86s/it]Evaluating commonsenseqa :  42%|████▏     | 84/200 [3:08:25<4:28:57, 139.12s/it]Evaluating commonsenseqa :  72%|███████▏  | 144/200 [4:01:55<1:39:58, 107.12s/it]Evaluating commonsenseqa :  36%|███▌      | 71/200 [1:48:15<3:21:39, 93.79s/it]Evaluating commonsenseqa :  30%|██▉       | 59/200 [1:21:30<3:24:21, 86.96s/it]Evaluating commonsenseqa :  91%|█████████ | 182/200 [5:09:14<30:51, 102.84s/it]Evaluating commonsenseqa :  30%|███       | 60/200 [1:22:58<3:23:32, 87.23s/it]Evaluating commonsenseqa :  36%|███▌      | 72/200 [1:49:49<3:20:05, 93.79s/it]Evaluating commonsenseqa :  72%|███████▎  | 145/200 [4:03:46<1:39:18, 108.34s/it]Evaluating commonsenseqa :  42%|████▎     | 85/200 [3:10:41<4:24:46, 138.15s/it]Evaluating commonsenseqa :  92%|█████████▏| 183/200 [5:10:59<29:16, 103.35s/it]Evaluating commonsenseqa :  30%|███       | 61/200 [1:23:53<2:59:41, 77.57s/it]Evaluating commonsenseqa :  36%|███▋      | 73/200 [1:51:25<3:19:47, 94.39s/it]Evaluating commonsenseqa :  73%|███████▎  | 146/200 [4:05:39<1:38:38, 109.59s/it]Evaluating commonsenseqa :  31%|███       | 62/200 [1:24:57<2:49:01, 73.49s/it]Evaluating commonsenseqa :  92%|█████████▏| 184/200 [5:12:42<27:33, 103.36s/it]Evaluating commonsenseqa :  43%|████▎     | 86/200 [3:12:58<4:22:13, 138.01s/it]Evaluating commonsenseqa :  74%|███████▎  | 147/200 [4:06:48<1:26:12, 97.60s/it] Evaluating commonsenseqa :  37%|███▋      | 74/200 [1:52:59<3:18:20, 94.45s/it]Evaluating commonsenseqa :  32%|███▏      | 63/200 [1:26:28<3:00:00, 78.84s/it]Evaluating commonsenseqa :  44%|████▎     | 87/200 [3:14:12<3:43:28, 118.66s/it]Evaluating commonsenseqa :  92%|█████████▎| 185/200 [5:14:23<25:39, 102.62s/it]Evaluating commonsenseqa :  38%|███▊      | 75/200 [1:54:33<3:16:33, 94.35s/it]Evaluating commonsenseqa :  32%|███▏      | 64/200 [1:27:58<3:06:32, 82.30s/it]Evaluating commonsenseqa :  74%|███████▍  | 148/200 [4:08:42<1:28:42, 102.35s/it]Evaluating commonsenseqa :  93%|█████████▎| 186/200 [5:16:05<23:55, 102.54s/it]Evaluating commonsenseqa :  44%|████▍     | 88/200 [3:16:33<3:54:07, 125.42s/it]Evaluating commonsenseqa :  38%|███▊      | 76/200 [1:56:07<3:14:36, 94.16s/it]Evaluating commonsenseqa :  32%|███▎      | 65/200 [1:29:31<3:12:06, 85.38s/it]Evaluating commonsenseqa :  74%|███████▍  | 149/200 [4:10:34<1:29:22, 105.15s/it]Evaluating commonsenseqa :  94%|█████████▎| 187/200 [5:17:48<22:13, 102.55s/it]Evaluating commonsenseqa :  33%|███▎      | 66/200 [1:30:38<2:58:19, 79.84s/it]Evaluating commonsenseqa :  38%|███▊      | 77/200 [1:57:44<3:14:30, 94.88s/it]Evaluating commonsenseqa :  44%|████▍     | 89/200 [3:18:53<4:00:17, 129.89s/it]Evaluating commonsenseqa :  75%|███████▌  | 150/200 [4:12:25<1:29:18, 107.18s/it]Evaluating commonsenseqa :  34%|███▎      | 67/200 [1:32:07<3:03:01, 82.57s/it]Evaluating commonsenseqa :  94%|█████████▍| 188/200 [5:19:31<20:31, 102.63s/it]Evaluating commonsenseqa :  39%|███▉      | 78/200 [1:59:19<3:13:12, 95.02s/it]Evaluating commonsenseqa :  45%|████▌     | 90/200 [3:21:12<4:02:44, 132.40s/it]Evaluating commonsenseqa :  76%|███████▌  | 151/200 [4:14:22<1:29:45, 109.91s/it]Evaluating commonsenseqa :  34%|███▍      | 68/200 [1:33:39<3:08:13, 85.56s/it]Evaluating commonsenseqa :  40%|███▉      | 79/200 [2:00:40<3:03:06, 90.80s/it]Evaluating commonsenseqa :  94%|█████████▍| 189/200 [5:21:15<18:54, 103.17s/it]Evaluating commonsenseqa :  34%|███▍      | 69/200 [1:35:10<3:09:54, 86.98s/it]Evaluating commonsenseqa :  40%|████      | 80/200 [2:02:14<3:03:39, 91.83s/it]Evaluating commonsenseqa :  76%|███████▌  | 152/200 [4:16:14<1:28:25, 110.52s/it]Evaluating commonsenseqa :  95%|█████████▌| 190/200 [5:22:59<17:12, 103.28s/it]Evaluating commonsenseqa :  46%|████▌     | 91/200 [3:23:33<4:05:28, 135.12s/it]Evaluating commonsenseqa :  35%|███▌      | 70/200 [1:36:40<3:10:39, 88.00s/it]Evaluating commonsenseqa :  40%|████      | 81/200 [2:03:32<2:53:33, 87.51s/it]Evaluating commonsenseqa :  96%|█████████▌| 191/200 [5:24:39<15:21, 102.34s/it]Evaluating commonsenseqa :  76%|███████▋  | 153/200 [4:18:09<1:27:43, 111.98s/it]Evaluating commonsenseqa :  36%|███▌      | 71/200 [1:38:12<3:11:43, 89.18s/it]Evaluating commonsenseqa :  46%|████▌     | 92/200 [3:25:51<4:05:00, 136.12s/it]Evaluating commonsenseqa :  41%|████      | 82/200 [2:05:09<2:58:10, 90.60s/it]Evaluating commonsenseqa :  96%|█████████▌| 192/200 [5:26:22<13:40, 102.59s/it]Evaluating commonsenseqa :  77%|███████▋  | 154/200 [4:19:59<1:25:28, 111.49s/it]Evaluating commonsenseqa :  36%|███▌      | 72/200 [1:39:34<3:05:43, 87.06s/it]Evaluating commonsenseqa :  42%|████▏     | 83/200 [2:06:47<3:00:44, 92.69s/it]Evaluating commonsenseqa :  46%|████▋     | 93/200 [3:28:12<4:05:19, 137.57s/it]Evaluating commonsenseqa :  96%|█████████▋| 193/200 [5:28:04<11:56, 102.36s/it]Evaluating commonsenseqa :  36%|███▋      | 73/200 [1:41:05<3:06:52, 88.29s/it]Evaluating commonsenseqa :  78%|███████▊  | 155/200 [4:21:51<1:23:43, 111.64s/it]Evaluating commonsenseqa :  42%|████▏     | 84/200 [2:08:22<3:00:43, 93.48s/it]Evaluating commonsenseqa :  97%|█████████▋| 194/200 [5:29:28<09:41, 96.92s/it] Evaluating commonsenseqa :  37%|███▋      | 74/200 [1:42:37<3:07:42, 89.38s/it]Evaluating commonsenseqa :  42%|████▎     | 85/200 [2:09:45<2:53:06, 90.32s/it]Evaluating commonsenseqa :  47%|████▋     | 94/200 [3:30:32<4:04:15, 138.26s/it]Evaluating commonsenseqa :  78%|███████▊  | 156/200 [4:23:43<1:21:54, 111.70s/it]Evaluating commonsenseqa :  98%|█████████▊| 195/200 [5:31:08<08:09, 97.92s/it]Evaluating commonsenseqa :  38%|███▊      | 75/200 [1:44:09<3:07:28, 89.99s/it]Evaluating commonsenseqa :  43%|████▎     | 86/200 [2:11:20<2:54:14, 91.70s/it]Evaluating commonsenseqa :  78%|███████▊  | 157/200 [4:25:17<1:16:16, 106.44s/it]Evaluating commonsenseqa :  48%|████▊     | 95/200 [3:32:49<4:01:23, 137.94s/it]Evaluating commonsenseqa :  98%|█████████▊| 196/200 [5:32:51<06:36, 99.21s/it]Evaluating commonsenseqa :  38%|███▊      | 76/200 [1:45:40<3:06:49, 90.40s/it]Evaluating commonsenseqa :  44%|████▎     | 87/200 [2:12:56<2:55:05, 92.97s/it]Evaluating commonsenseqa :  79%|███████▉  | 158/200 [4:27:13<1:16:29, 109.27s/it]Evaluating commonsenseqa :  98%|█████████▊| 197/200 [5:34:34<05:01, 100.60s/it]Evaluating commonsenseqa :  38%|███▊      | 77/200 [1:47:12<3:06:18, 90.88s/it]Evaluating commonsenseqa :  44%|████▍     | 88/200 [2:14:13<2:44:30, 88.13s/it]Evaluating commonsenseqa :  48%|████▊     | 96/200 [3:35:09<4:00:04, 138.51s/it]Evaluating commonsenseqa :  80%|███████▉  | 159/200 [4:29:05<1:15:08, 109.97s/it]Evaluating commonsenseqa :  39%|███▉      | 78/200 [1:48:38<3:01:37, 89.32s/it]Evaluating commonsenseqa :  99%|█████████▉| 198/200 [5:36:18<03:22, 101.47s/it]Evaluating commonsenseqa :  44%|████▍     | 89/200 [2:15:50<2:48:07, 90.87s/it]Evaluating commonsenseqa :  48%|████▊     | 97/200 [3:37:26<3:56:57, 138.03s/it]Evaluating commonsenseqa :  40%|███▉      | 79/200 [1:50:11<3:02:40, 90.58s/it]Evaluating commonsenseqa :  80%|████████  | 160/200 [4:31:00<1:14:17, 111.44s/it]Evaluating commonsenseqa : 100%|█████████▉| 199/200 [5:37:58<01:41, 101.09s/it]Evaluating commonsenseqa :  45%|████▌     | 90/200 [2:17:26<2:49:16, 92.33s/it]Evaluating commonsenseqa :  40%|████      | 80/200 [1:51:28<2:53:12, 86.61s/it]Evaluating commonsenseqa :  80%|████████  | 161/200 [4:32:29<1:08:07, 104.80s/it]Evaluating commonsenseqa :  46%|████▌     | 91/200 [2:19:02<2:49:44, 93.44s/it]Evaluating commonsenseqa :  49%|████▉     | 98/200 [3:39:46<3:55:43, 138.66s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [5:39:43<00:00, 102.10s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [5:39:43<00:00, 101.92s/it]
name: commonsenseqa | avg. gen lenth: 340.834 | time: 20386.018656730652s
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10138 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o5-tmathqa-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 5 5 7 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2023-09-20 13:19:54,452] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o5-tmathqa-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 5
  out_domain_data_name ......... mathqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o5-tmathqa-s20-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 651362.54it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.46s/it]
 > number of parameters: 6738415616
[2023-09-20 13:20:11,181] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.3, git-hash=unknown, git-branch=unknown
[2023-09-20 13:20:11,181] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-09-20 13:20:11,602] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-20 13:20:11,604] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2023-09-20 13:20:11,604] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-20 13:20:11,604] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-20 13:20:11,604] [INFO] [config.py:971:print]   amp_enabled .................. False
[2023-09-20 13:20:11,604] [INFO] [config.py:971:print]   amp_params ................... False
[2023-09-20 13:20:11,605] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-20 13:20:11,605] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2023-09-20 13:20:11,605] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2023-09-20 13:20:11,605] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2023-09-20 13:20:11,605] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2023-09-20 13:20:11,605] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fd2c162ad70>
[2023-09-20 13:20:11,605] [INFO] [config.py:971:print]   communication_data_type ...... None
[2023-09-20 13:20:11,605] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-20 13:20:11,605] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2023-09-20 13:20:11,605] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2023-09-20 13:20:11,605] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-20 13:20:11,605] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2023-09-20 13:20:11,605] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2023-09-20 13:20:11,605] [INFO] [config.py:971:print]   disable_allgather ............ False
[2023-09-20 13:20:11,605] [INFO] [config.py:971:print]   dump_state ................... False
[2023-09-20 13:20:11,605] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-20 13:20:11,605] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2023-09-20 13:20:11,605] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-20 13:20:11,605] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-20 13:20:11,605] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2023-09-20 13:20:11,605] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2023-09-20 13:20:11,605] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2023-09-20 13:20:11,605] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2023-09-20 13:20:11,605] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2023-09-20 13:20:11,605] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2023-09-20 13:20:11,605] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-20 13:20:11,605] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   global_rank .................. 0
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   gradient_clipping ............ 0.0
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 2048
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   loss_scale ................... 0
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   optimizer_name ............... None
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   optimizer_params ............. None
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   pld_enabled .................. False
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   pld_params ................... False
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   scheduler_name ............... None
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   scheduler_params ............. None
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   sparse_attention ............. None
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   train_batch_size ............. 1
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  1
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   world_size ................... 1
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  True
[2023-09-20 13:20:11,606] [INFO] [config.py:971:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2023-09-20 13:20:11,607] [INFO] [config.py:971:print]   zero_enabled ................. False
[2023-09-20 13:20:11,607] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-20 13:20:11,607] [INFO] [config.py:971:print]   zero_optimization_stage ...... 0
[2023-09-20 13:20:11,607] [INFO] [config.py:957:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/200 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: a man cycling along the road noticed that every 18 minutes a bus overtakes him and every 6 minutes he meets an oncoming bus. if all buses and the cyclist move at a constant speed, what is the time interval between consecutive buses? a ) 5 minutes, b ) 6 minutes, c ) 8 minutes, d ) 9 minutes, e ) 10 minutes
Output: d

Input: an athlete runs 200 metres race in 24 seconds. what is his speed? a ) 20 km / hr, b ) 30 km / hr, c ) 25 km / hr, d ) 35 km / hr, e ) 40 km / hr
Output: b

Input: two numbers are in the ratio 3 : 4. if the sum of numbers is 63, find the numbers. a ) 27 and 36., b ) 25 and 30., c ) 23 and 44., d ) 63 and 12., e ) 12 and 36.
Output: a

Input: a company wants to spend equal amounts of money for the purchase of two types of computer printers costing $ 375 and $ 150 per unit, respectively. what is the fewest number of computer printers that the company can purchase? a ) 3, b ) 4, c ) 5, d ) 6, e ) 7
Output: e

Input: a certain music store stocks 800 cellos and 600 violas. of these instruments, there are 80 cello - viola pairs, such that a cello and a viola were both made with wood from the same tree ( each tree can make at most one viola and one cello, so there are no pairs other than these 90 ). if one viola and one cello are chosen at random, what is the probability that the two instruments are made with wood from the same tree? a ) 3 / 16,000, b ) 1 / 8,100, c ) 1 / 600, d ) 1 / 90, e ) 2 / 45
Output: c

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o5-tmathqa-s20-rFalse-m4096
Evaluating commonsenseqa :  40%|████      | 81/200 [1:53:00<2:54:45, 88.12s/it]Evaluating commonsenseqa :  81%|████████  | 162/200 [4:34:23<1:08:07, 107.55s/it]Evaluating commonsenseqa :  46%|████▌     | 92/200 [2:20:40<2:50:54, 94.95s/it]Evaluating commonsenseqa :  50%|████▉     | 99/200 [3:42:05<3:53:38, 138.80s/it]Evaluating commonsenseqa :  41%|████      | 82/200 [1:54:31<2:55:10, 89.07s/it]Evaluating commonsenseqa :   0%|          | 1/200 [02:14<7:25:36, 134.35s/it]Evaluating commonsenseqa :  82%|████████▏ | 163/200 [4:35:50<1:02:30, 101.36s/it]Evaluating commonsenseqa :  46%|████▋     | 93/200 [2:22:16<2:49:41, 95.15s/it]Evaluating commonsenseqa :  42%|████▏     | 83/200 [1:55:42<2:42:41, 83.43s/it]Evaluating commonsenseqa :  50%|█████     | 100/200 [3:44:24<3:51:13, 138.73s/it]Evaluating commonsenseqa :  82%|████████▏ | 164/200 [4:37:42<1:02:43, 104.55s/it]Evaluating commonsenseqa :  47%|████▋     | 94/200 [2:23:52<2:48:39, 95.46s/it]Evaluating commonsenseqa :  42%|████▏     | 84/200 [1:57:11<2:44:34, 85.12s/it]Evaluating commonsenseqa :   1%|          | 2/200 [04:29<7:24:01, 134.55s/it]Evaluating commonsenseqa :  48%|████▊     | 95/200 [2:25:27<2:46:26, 95.11s/it]Evaluating commonsenseqa :  42%|████▎     | 85/200 [1:58:42<2:46:49, 87.04s/it]Evaluating commonsenseqa :  82%|████████▎ | 165/200 [4:39:32<1:01:57, 106.21s/it]Evaluating commonsenseqa :  50%|█████     | 101/200 [3:46:41<3:47:48, 138.06s/it]Evaluating commonsenseqa :   2%|▏         | 3/200 [06:39<7:15:47, 132.73s/it]Evaluating commonsenseqa :  48%|████▊     | 96/200 [2:27:01<2:44:27, 94.88s/it]Evaluating commonsenseqa :  43%|████▎     | 86/200 [2:00:12<2:46:52, 87.83s/it]Evaluating commonsenseqa :  83%|████████▎ | 166/200 [4:41:24<1:01:14, 108.06s/it]Evaluating commonsenseqa :   2%|▏         | 4/200 [08:08<6:16:36, 115.29s/it]Evaluating commonsenseqa :  44%|████▎     | 87/200 [2:01:26<2:37:45, 83.76s/it]Evaluating commonsenseqa :  51%|█████     | 102/200 [3:49:01<3:46:33, 138.71s/it]Evaluating commonsenseqa :  48%|████▊     | 97/200 [2:28:38<2:43:48, 95.42s/it]Evaluating commonsenseqa :  84%|████████▎ | 167/200 [4:43:20<1:00:40, 110.32s/it]Evaluating commonsenseqa :  44%|████▍     | 88/200 [2:02:57<2:40:08, 85.79s/it]Evaluating commonsenseqa :   2%|▎         | 5/200 [10:21<6:35:34, 121.72s/it]Evaluating commonsenseqa :  49%|████▉     | 98/200 [2:30:11<2:41:05, 94.76s/it]Evaluating commonsenseqa :  52%|█████▏    | 103/200 [3:51:19<3:43:49, 138.45s/it]Evaluating commonsenseqa :  44%|████▍     | 89/200 [2:04:02<2:27:22, 79.66s/it]Evaluating commonsenseqa :  84%|████████▍ | 168/200 [4:45:14<59:21, 111.31s/it]  Evaluating commonsenseqa :  45%|████▌     | 90/200 [2:04:43<2:04:35, 67.96s/it]Evaluating commonsenseqa :  50%|████▉     | 99/200 [2:31:44<2:38:43, 94.29s/it]Evaluating commonsenseqa :   3%|▎         | 6/200 [12:33<6:45:18, 125.35s/it]Evaluating commonsenseqa :  84%|████████▍ | 169/200 [4:46:38<53:24, 103.37s/it]Evaluating commonsenseqa :  52%|█████▏    | 104/200 [3:53:39<3:42:24, 139.01s/it]Evaluating commonsenseqa :  46%|████▌     | 91/200 [2:06:14<2:15:57, 74.84s/it]Evaluating commonsenseqa :   4%|▎         | 7/200 [13:35<5:36:34, 104.63s/it]Evaluating commonsenseqa :  50%|█████     | 100/200 [2:33:19<2:37:16, 94.36s/it]Evaluating commonsenseqa :  46%|████▌     | 92/200 [2:07:16<2:07:55, 71.07s/it]Evaluating commonsenseqa :  85%|████████▌ | 170/200 [4:48:27<52:27, 104.92s/it]Evaluating commonsenseqa :   4%|▍         | 8/200 [14:56<5:11:00, 97.19s/it] Evaluating commonsenseqa :  50%|█████     | 101/200 [2:34:57<2:37:34, 95.50s/it]Evaluating commonsenseqa :  52%|█████▎    | 105/200 [3:55:59<3:40:44, 139.41s/it]Evaluating commonsenseqa :  46%|████▋     | 93/200 [2:08:47<2:17:28, 77.08s/it]Evaluating commonsenseqa :  86%|████████▌ | 171/200 [4:50:19<51:42, 106.99s/it]Evaluating commonsenseqa :  51%|█████     | 102/200 [2:36:32<2:35:40, 95.32s/it]Evaluating commonsenseqa :   4%|▍         | 9/200 [17:08<5:44:01, 108.07s/it]Evaluating commonsenseqa :  47%|████▋     | 94/200 [2:10:18<2:23:41, 81.34s/it]Evaluating commonsenseqa :  52%|█████▏    | 103/200 [2:37:26<2:14:17, 83.07s/it]Evaluating commonsenseqa :  53%|█████▎    | 106/200 [3:58:22<3:39:52, 140.34s/it]Evaluating commonsenseqa :  86%|████████▌ | 172/200 [4:52:14<51:05, 109.47s/it]Evaluating commonsenseqa :  48%|████▊     | 95/200 [2:11:49<2:27:21, 84.20s/it]Evaluating commonsenseqa :   5%|▌         | 10/200 [19:21<6:06:31, 115.74s/it]Evaluating commonsenseqa :  52%|█████▏    | 104/200 [2:39:02<2:19:08, 86.97s/it]Evaluating commonsenseqa :  54%|█████▎    | 107/200 [4:00:42<3:37:30, 140.33s/it]Evaluating commonsenseqa :  48%|████▊     | 96/200 [2:13:19<2:28:40, 85.77s/it]Evaluating commonsenseqa :  86%|████████▋ | 173/200 [4:54:07<49:43, 110.52s/it]Evaluating commonsenseqa :  52%|█████▎    | 105/200 [2:40:37<2:21:25, 89.32s/it]Evaluating commonsenseqa :   6%|▌         | 11/200 [21:30<6:16:43, 119.60s/it]Evaluating commonsenseqa :  48%|████▊     | 97/200 [2:14:24<2:16:48, 79.69s/it]Evaluating commonsenseqa :  87%|████████▋ | 174/200 [4:56:01<48:18, 111.48s/it]Evaluating commonsenseqa :  53%|█████▎    | 106/200 [2:42:14<2:23:27, 91.57s/it]Evaluating commonsenseqa :  54%|█████▍    | 108/200 [4:03:04<3:35:47, 140.73s/it]Evaluating commonsenseqa :  49%|████▉     | 98/200 [2:15:54<2:20:38, 82.73s/it]Evaluating commonsenseqa :   6%|▌         | 12/200 [23:41<6:25:46, 123.12s/it]Evaluating commonsenseqa :  50%|████▉     | 99/200 [2:16:48<2:04:49, 74.15s/it]Evaluating commonsenseqa :  54%|█████▎    | 107/200 [2:43:47<2:22:48, 92.14s/it]Evaluating commonsenseqa :  88%|████████▊ | 175/200 [4:57:57<47:02, 112.89s/it]Evaluating commonsenseqa :   6%|▋         | 13/200 [24:47<5:30:06, 105.92s/it]Evaluating commonsenseqa :  55%|█████▍    | 109/200 [4:05:22<3:32:06, 139.85s/it]Evaluating commonsenseqa :  50%|█████     | 100/200 [2:18:17<2:11:02, 78.62s/it]Evaluating commonsenseqa :  54%|█████▍    | 108/200 [2:45:24<2:23:25, 93.54s/it]Evaluating commonsenseqa :  50%|█████     | 101/200 [2:18:57<1:50:26, 66.93s/it]Evaluating commonsenseqa :  88%|████████▊ | 176/200 [4:59:50<45:08, 112.83s/it]Evaluating commonsenseqa :   7%|▋         | 14/200 [26:57<5:50:49, 113.17s/it]Evaluating commonsenseqa :  55%|█████▌    | 110/200 [4:07:38<3:28:14, 138.83s/it]Evaluating commonsenseqa :  55%|█████▍    | 109/200 [2:46:58<2:22:14, 93.79s/it]Evaluating commonsenseqa :  51%|█████     | 102/200 [2:20:26<2:00:19, 73.66s/it]Evaluating commonsenseqa :  88%|████████▊ | 177/200 [5:01:41<43:04, 112.36s/it]Evaluating commonsenseqa :  55%|█████▌    | 110/200 [2:48:33<2:20:56, 93.96s/it]Evaluating commonsenseqa :  52%|█████▏    | 103/200 [2:21:55<2:06:20, 78.15s/it]Evaluating commonsenseqa :   8%|▊         | 15/200 [29:12<6:09:05, 119.70s/it]Evaluating commonsenseqa :  56%|█████▌    | 111/200 [4:09:59<3:26:43, 139.37s/it]Evaluating commonsenseqa :  89%|████████▉ | 178/200 [5:03:32<41:05, 112.09s/it]Evaluating commonsenseqa :  56%|█████▌    | 111/200 [2:50:10<2:20:44, 94.89s/it]Evaluating commonsenseqa :  52%|█████▏    | 104/200 [2:23:27<2:12:01, 82.52s/it]Evaluating commonsenseqa :  52%|█████▎    | 105/200 [2:24:08<1:50:42, 69.92s/it]Evaluating commonsenseqa :   8%|▊         | 16/200 [31:27<6:21:03, 124.26s/it]Evaluating commonsenseqa :  90%|████████▉ | 179/200 [5:05:26<39:21, 112.45s/it]Evaluating commonsenseqa :  56%|█████▌    | 112/200 [4:12:18<3:24:25, 139.39s/it]Evaluating commonsenseqa :  56%|█████▌    | 112/200 [2:51:45<2:19:16, 94.96s/it]Evaluating commonsenseqa :  53%|█████▎    | 106/200 [2:25:38<1:59:11, 76.08s/it]Evaluating commonsenseqa :   8%|▊         | 17/200 [32:58<5:49:04, 114.45s/it]Evaluating commonsenseqa :  56%|█████▋    | 113/200 [2:53:22<2:18:42, 95.66s/it]Evaluating commonsenseqa :  90%|█████████ | 180/200 [5:07:18<37:31, 112.55s/it]Evaluating commonsenseqa :  56%|█████▋    | 113/200 [4:14:42<3:23:53, 140.61s/it]Evaluating commonsenseqa :  54%|█████▎    | 107/200 [2:27:12<2:05:53, 81.22s/it]Evaluating commonsenseqa :   9%|▉         | 18/200 [35:12<6:04:10, 120.06s/it]Evaluating commonsenseqa :  57%|█████▋    | 114/200 [2:54:56<2:16:30, 95.23s/it]Evaluating commonsenseqa :  90%|█████████ | 181/200 [5:09:12<35:44, 112.88s/it]Evaluating commonsenseqa :  54%|█████▍    | 108/200 [2:28:43<2:09:16, 84.31s/it]Evaluating commonsenseqa :  10%|▉         | 19/200 [36:05<5:01:52, 100.07s/it]Evaluating commonsenseqa :  57%|█████▋    | 114/200 [4:17:03<3:21:45, 140.77s/it]Evaluating commonsenseqa :  57%|█████▊    | 115/200 [2:56:34<2:15:41, 95.78s/it]Evaluating commonsenseqa :  91%|█████████ | 182/200 [5:10:27<30:26, 101.50s/it]Evaluating commonsenseqa :  55%|█████▍    | 109/200 [2:30:14<2:10:55, 86.33s/it]Evaluating commonsenseqa :  10%|█         | 20/200 [38:18<5:29:31, 109.84s/it]Evaluating commonsenseqa :  58%|█████▊    | 116/200 [2:58:08<2:13:29, 95.36s/it]Evaluating commonsenseqa :  57%|█████▊    | 115/200 [4:19:02<3:10:29, 134.47s/it]Evaluating commonsenseqa :  92%|█████████▏| 183/200 [5:12:24<30:03, 106.10s/it]Evaluating commonsenseqa :  55%|█████▌    | 110/200 [2:31:47<2:12:25, 88.28s/it]Evaluating commonsenseqa :  10%|█         | 21/200 [39:30<4:53:42, 98.45s/it] Evaluating commonsenseqa :  58%|█████▊    | 117/200 [2:59:44<2:12:09, 95.54s/it]Evaluating commonsenseqa :  56%|█████▌    | 111/200 [2:33:19<2:12:33, 89.37s/it]Evaluating commonsenseqa :  92%|█████████▏| 184/200 [5:14:18<28:55, 108.49s/it]Evaluating commonsenseqa :  56%|█████▌    | 112/200 [2:33:49<1:44:57, 71.56s/it]Evaluating commonsenseqa :  58%|█████▊    | 116/200 [4:21:24<3:11:10, 136.55s/it]Evaluating commonsenseqa :  59%|█████▉    | 118/200 [3:01:21<2:11:15, 96.04s/it]Evaluating commonsenseqa :  11%|█         | 22/200 [41:43<5:23:18, 108.98s/it]Evaluating commonsenseqa :  56%|█████▋    | 113/200 [2:35:00<1:43:27, 71.35s/it]Evaluating commonsenseqa :  92%|█████████▎| 185/200 [5:16:11<27:26, 109.76s/it]Evaluating commonsenseqa :  60%|█████▉    | 119/200 [3:02:58<2:09:59, 96.29s/it]Evaluating commonsenseqa :  58%|█████▊    | 117/200 [4:23:47<3:11:36, 138.52s/it]Evaluating commonsenseqa :  57%|█████▋    | 114/200 [2:36:29<1:50:06, 76.82s/it]Evaluating commonsenseqa :  12%|█▏        | 23/200 [43:54<5:40:45, 115.51s/it]Evaluating commonsenseqa :  93%|█████████▎| 186/200 [5:18:06<25:59, 111.42s/it]Evaluating commonsenseqa :  60%|██████    | 120/200 [3:04:33<2:07:53, 95.92s/it]Evaluating commonsenseqa :  57%|█████▊    | 115/200 [2:38:00<1:54:27, 80.80s/it]Evaluating commonsenseqa :  59%|█████▉    | 118/200 [4:26:06<3:09:40, 138.79s/it]Evaluating commonsenseqa :  12%|█▏        | 24/200 [46:10<5:56:57, 121.69s/it]Evaluating commonsenseqa :  60%|██████    | 121/200 [3:06:07<2:05:22, 95.22s/it]Evaluating commonsenseqa :  94%|█████████▎| 187/200 [5:20:01<24:20, 112.37s/it]Evaluating commonsenseqa :  58%|█████▊    | 116/200 [2:39:32<1:58:00, 84.30s/it]Evaluating commonsenseqa :  94%|█████████▍| 188/200 [5:21:01<19:19, 96.66s/it] Evaluating commonsenseqa :  61%|██████    | 122/200 [3:07:40<2:03:11, 94.76s/it]Evaluating commonsenseqa :  60%|█████▉    | 119/200 [4:28:27<3:07:55, 139.21s/it]Evaluating commonsenseqa :  58%|█████▊    | 117/200 [2:41:01<1:58:41, 85.80s/it]Evaluating commonsenseqa :  12%|█▎        | 25/200 [48:25<6:06:31, 125.67s/it]Evaluating commonsenseqa :  60%|██████    | 120/200 [4:28:49<2:19:05, 104.32s/it]Evaluating commonsenseqa :  94%|█████████▍| 189/200 [5:22:55<18:41, 101.98s/it]Evaluating commonsenseqa :  62%|██████▏   | 123/200 [3:09:14<2:01:09, 94.41s/it]Evaluating commonsenseqa :  59%|█████▉    | 118/200 [2:42:32<1:59:22, 87.35s/it]Evaluating commonsenseqa :  13%|█▎        | 26/200 [50:38<6:10:39, 127.81s/it]Evaluating commonsenseqa :  60%|██████    | 121/200 [4:31:09<2:31:24, 115.00s/it]Evaluating commonsenseqa :  62%|██████▏   | 124/200 [3:10:48<1:59:20, 94.21s/it]Evaluating commonsenseqa :  60%|█████▉    | 119/200 [2:44:02<1:59:01, 88.17s/it]Evaluating commonsenseqa :  95%|█████████▌| 190/200 [5:24:48<17:34, 105.42s/it]Evaluating commonsenseqa :  14%|█▎        | 27/200 [52:32<5:56:40, 123.70s/it]Evaluating commonsenseqa :  60%|██████    | 120/200 [2:45:33<1:58:43, 89.04s/it]Evaluating commonsenseqa :  62%|██████▎   | 125/200 [3:12:24<1:58:39, 94.92s/it]Evaluating commonsenseqa :  61%|██████    | 122/200 [4:33:30<2:39:28, 122.67s/it]Evaluating commonsenseqa :  96%|█████████▌| 191/200 [5:26:40<16:04, 107.14s/it]Evaluating commonsenseqa :  14%|█▍        | 28/200 [53:44<5:10:25, 108.29s/it]Evaluating commonsenseqa :  60%|██████    | 121/200 [2:47:02<1:56:54, 88.79s/it]Evaluating commonsenseqa :  63%|██████▎   | 126/200 [3:13:59<1:56:52, 94.77s/it]Evaluating commonsenseqa :  96%|█████████▌| 192/200 [5:28:32<14:29, 108.73s/it]Evaluating commonsenseqa :  62%|██████▏   | 123/200 [4:35:49<2:43:42, 127.57s/it]Evaluating commonsenseqa :  61%|██████    | 122/200 [2:48:34<1:56:57, 89.97s/it]Evaluating commonsenseqa :  64%|██████▎   | 127/200 [3:15:35<1:55:56, 95.29s/it]Evaluating commonsenseqa :  14%|█▍        | 29/200 [55:57<5:29:38, 115.66s/it]Evaluating commonsenseqa :  96%|█████████▋| 193/200 [5:30:23<12:45, 109.39s/it]Evaluating commonsenseqa :  62%|██████▏   | 123/200 [2:50:04<1:55:31, 90.02s/it]Evaluating commonsenseqa :  15%|█▌        | 30/200 [57:25<5:04:02, 107.31s/it]Evaluating commonsenseqa :  64%|██████▍   | 128/200 [3:17:10<1:54:15, 95.21s/it]Evaluating commonsenseqa :  62%|██████▏   | 124/200 [4:38:08<2:45:58, 131.03s/it]Evaluating commonsenseqa :  62%|██████▏   | 124/200 [2:51:09<1:44:30, 82.50s/it]Evaluating commonsenseqa :  97%|█████████▋| 194/200 [5:32:16<11:02, 110.46s/it]Evaluating commonsenseqa :  64%|██████▍   | 129/200 [3:18:47<1:53:23, 95.82s/it]Evaluating commonsenseqa :  16%|█▌        | 31/200 [59:36<5:22:20, 114.44s/it]Evaluating commonsenseqa :  62%|██████▎   | 125/200 [2:52:40<1:46:18, 85.05s/it]Evaluating commonsenseqa :  62%|██████▎   | 125/200 [4:40:26<2:46:17, 133.04s/it]Evaluating commonsenseqa :  98%|█████████▊| 195/200 [5:33:53<08:51, 106.39s/it]Evaluating commonsenseqa :  65%|██████▌   | 130/200 [3:20:24<1:52:08, 96.12s/it]Evaluating commonsenseqa :  63%|██████▎   | 126/200 [2:53:48<1:38:14, 79.66s/it]Evaluating commonsenseqa :  98%|█████████▊| 196/200 [5:35:00<06:18, 94.70s/it] Evaluating commonsenseqa :  64%|██████▎   | 127/200 [2:54:28<1:22:32, 67.84s/it]Evaluating commonsenseqa :  16%|█▌        | 32/200 [1:01:52<5:38:25, 120.86s/it]Evaluating commonsenseqa :  64%|██████▍   | 128/200 [2:55:03<1:09:31, 57.94s/it]Evaluating commonsenseqa :  66%|██████▌   | 131/200 [3:22:00<1:50:26, 96.04s/it]Evaluating commonsenseqa :  63%|██████▎   | 126/200 [4:42:49<2:48:01, 136.24s/it]Evaluating commonsenseqa :  98%|█████████▊| 197/200 [5:36:53<05:00, 100.27s/it]Evaluating commonsenseqa :  64%|██████▍   | 129/200 [2:56:22<1:16:10, 64.38s/it]Evaluating commonsenseqa :  66%|██████▌   | 132/200 [3:23:35<1:48:24, 95.66s/it]Evaluating commonsenseqa :  16%|█▋        | 33/200 [1:04:07<5:48:30, 125.21s/it]Evaluating commonsenseqa :  64%|██████▎   | 127/200 [4:45:11<2:47:43, 137.86s/it]Evaluating commonsenseqa :  65%|██████▌   | 130/200 [2:57:52<1:24:10, 72.15s/it]Evaluating commonsenseqa :  99%|█████████▉| 198/200 [5:38:45<03:27, 103.59s/it]Evaluating commonsenseqa :  66%|██████▋   | 133/200 [3:25:10<1:46:45, 95.61s/it]Evaluating commonsenseqa :  66%|██████▌   | 131/200 [2:59:01<1:21:46, 71.11s/it]Evaluating commonsenseqa :  17%|█▋        | 34/200 [1:06:20<5:53:03, 127.61s/it]Evaluating commonsenseqa :  66%|██████▌   | 132/200 [2:59:44<1:10:54, 62.56s/it]Evaluating commonsenseqa : 100%|█████████▉| 199/200 [5:40:36<01:45, 105.90s/it]Evaluating commonsenseqa :  67%|██████▋   | 134/200 [3:26:45<1:44:49, 95.29s/it]Evaluating commonsenseqa :  64%|██████▍   | 128/200 [4:47:32<2:46:24, 138.67s/it]Evaluating commonsenseqa :  66%|██████▋   | 133/200 [3:01:14<1:19:09, 70.88s/it]Evaluating commonsenseqa :  18%|█▊        | 35/200 [1:08:35<5:57:07, 129.86s/it]Evaluating commonsenseqa :  68%|██████▊   | 135/200 [3:28:21<1:43:40, 95.70s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [5:42:27<00:00, 107.55s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [5:42:27<00:00, 102.74s/it]
name: commonsenseqa | avg. gen lenth: 238.499 | time: 20550.330538988113s
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10140 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o15-tmathqa-s30-rFalse --seed 30 --max-prompt-length 4096 --num-out-domain 15 13 15 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2023-09-20 14:29:20,054] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o15-tmathqa-s30-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 15
  out_domain_data_name ......... mathqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o15-tmathqa-s30-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 404357.79it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.13s/it]
 > number of parameters: 6738415616
[2023-09-20 14:29:36,243] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.3, git-hash=unknown, git-branch=unknown
[2023-09-20 14:29:36,244] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-09-20 14:29:36,662] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-20 14:29:36,664] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2023-09-20 14:29:36,665] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-20 14:29:36,665] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-20 14:29:36,665] [INFO] [config.py:971:print]   amp_enabled .................. False
[2023-09-20 14:29:36,665] [INFO] [config.py:971:print]   amp_params ................... False
[2023-09-20 14:29:36,666] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-20 14:29:36,666] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2023-09-20 14:29:36,666] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2023-09-20 14:29:36,666] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2023-09-20 14:29:36,666] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2023-09-20 14:29:36,666] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f4c3880ed70>
[2023-09-20 14:29:36,666] [INFO] [config.py:971:print]   communication_data_type ...... None
[2023-09-20 14:29:36,666] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-20 14:29:36,666] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2023-09-20 14:29:36,666] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2023-09-20 14:29:36,666] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-20 14:29:36,666] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2023-09-20 14:29:36,666] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2023-09-20 14:29:36,666] [INFO] [config.py:971:print]   disable_allgather ............ False
[2023-09-20 14:29:36,666] [INFO] [config.py:971:print]   dump_state ................... False
[2023-09-20 14:29:36,666] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-20 14:29:36,666] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2023-09-20 14:29:36,666] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-20 14:29:36,666] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-20 14:29:36,666] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2023-09-20 14:29:36,666] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2023-09-20 14:29:36,666] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2023-09-20 14:29:36,666] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2023-09-20 14:29:36,666] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2023-09-20 14:29:36,666] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2023-09-20 14:29:36,666] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-20 14:29:36,666] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2023-09-20 14:29:36,666] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   global_rank .................. 0
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   gradient_clipping ............ 0.0
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 2048
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   loss_scale ................... 0
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   optimizer_name ............... None
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   optimizer_params ............. None
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   pld_enabled .................. False
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   pld_params ................... False
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   scheduler_name ............... None
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   scheduler_params ............. None
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   sparse_attention ............. None
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   train_batch_size ............. 1
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  1
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2023-09-20 14:29:36,667] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2023-09-20 14:29:36,668] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2023-09-20 14:29:36,668] [INFO] [config.py:971:print]   world_size ................... 1
[2023-09-20 14:29:36,668] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  True
[2023-09-20 14:29:36,668] [INFO] [config.py:971:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2023-09-20 14:29:36,668] [INFO] [config.py:971:print]   zero_enabled ................. False
[2023-09-20 14:29:36,668] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-20 14:29:36,668] [INFO] [config.py:971:print]   zero_optimization_stage ...... 0
[2023-09-20 14:29:36,668] [INFO] [config.py:957:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/200 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: the mean of 30 values was 140. it was detected on rechecking that one value 145 was wrongly copied as 135 for the computation of the mean. find the correct mean. a ) 151, b ) 140.33, c ) 152, d ) 148, e ) none of the above
Output: b

Input: the measurement of a rectangular box with lid is 25 cmx 24 cmx 18 cm. find the volume of the largest sphere that can be inscribed in the box ( in terms of π cm 3 ). ( hint : the lowest measure of rectangular box represents the diameter of the largest sphere ) a ) 288, b ) 2302, c ) 2304, d ) 8640, e ) 964
Output: c

Input: a certain fraction has the same ratio to 1 / 33, as 3 / 4 does to 7 / 11. what is this certain fraction? a ) 1 / 14, b ) 1 / 18, c ) 1 / 21, d ) 1 / 25, e ) 1 / 28
Output: e

Input: what is the sum of all remainders obtained when the first 110 natural numbers are divided by 9? a ) 397, b ) 401, c ) 403, d ) 405, e ) 399
Output: c

Input: a ’ s speed is 20 / 15 times that of b. if a and b run a race, what part of the length of the race should a give b as a head start, so that the race ends in a dead heat? a ) 1 / 17, b ) 3 / 17, c ) 1 / 10, d ) 5 / 20, e ) 3 / 10
Output: d

Input: find the average of all the numbers between 6 and 34 which are divisible by 7. a ) 18, b ) 20, c ) 17.5, d ) 30, e ) 32
Output: c

Input: instead of multiplying a number by 5, the number is divided by 10. what is the percentage of error obtained? a ) 96 %, b ) 98 %, c ) 95 %, d ) 97 %, e ) 96 %
Output: b

Input: by selling an article at rs. 150, a profit of 25 % is made. find its cost price? a ) s. 486, b ) s. 455, c ) s. 487, d ) s. 120, e ) s. 489
Output: d

Input: if 1 = 6, 2 = 12, 3 = 18, 4 = 24, 5 = 30, then 6 =? a ) 5, b ) 3, c ) 1, d ) 7, e ) 9
Output: c

Input: 62 small identical cubes are used to form a large cube. how many more cubes are needed to add one top layer of small cube all over the surface of the large cube? a ) 64, b ) 128, c ) 152, d ) 154, e ) 256
Output: d

Input: a boat running upstream takes 640 min to cover a certain distance, while it takes 280 min to cover the same distance running down stream. what is the ratio between the speed of the boat and speed of water current respectively? a ) 23 : 7, b ) 22 : 9, c ) 23 : 8, d ) 23 : 9, e ) 23 : 11
Output: d

Input: there are 2 positive integers x and y. what is the probability that x + y is odd? a ) 1 / 4, b ) 1 / 2, c ) 1 / 3, d ) 1 / 5, e ) 1 / 9
Output: b

Input: two numbers have a h. c. f of 9 and a product of two numbers is 1800. find the l. c. m of the two numbers? a ) 200, b ) 150, c ) 160, d ) 170, e ) 180
Output: a

Input: a metallic sheet is of rectangular shape with dimensions 48 m x 36 m. from each of its corners, a square is cut off so as to make an open box. if the length of the square is 8 m, the volume of the box ( in m 3 ) is a ) 3220, b ) 4830, c ) 5120, d ) 6420, e ) none
Output: c

Input: amar takes as much time in running 24 meters as a car takes in covering 60 meters. what will be the distance covered by amar during the time the car covers 2.2 km? a ) 700 m, b ) 500 m, c ) 870 m, d ) 880 m, e ) 840 m
Output: d

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o15-tmathqa-s30-rFalse-m4096
Evaluating commonsenseqa :  64%|██████▍   | 129/200 [4:49:52<2:44:43, 139.21s/it]Evaluating commonsenseqa :  67%|██████▋   | 134/200 [3:02:43<1:24:08, 76.48s/it]Evaluating commonsenseqa :  68%|██████▊   | 136/200 [3:29:58<1:42:12, 95.82s/it]Evaluating commonsenseqa :   0%|          | 1/200 [01:09<3:51:27, 69.79s/it]Evaluating commonsenseqa :  68%|██████▊   | 135/200 [3:03:34<1:14:35, 68.86s/it]Evaluating commonsenseqa :  18%|█▊        | 36/200 [1:10:50<5:58:40, 131.22s/it]Evaluating commonsenseqa :  65%|██████▌   | 130/200 [4:52:12<2:42:30, 139.29s/it]Evaluating commonsenseqa :  68%|██████▊   | 137/200 [3:31:32<1:40:09, 95.39s/it]Evaluating commonsenseqa :  68%|██████▊   | 136/200 [3:05:08<1:21:13, 76.15s/it]Evaluating commonsenseqa :   1%|          | 2/200 [02:56<5:02:12, 91.58s/it]Evaluating commonsenseqa :  18%|█▊        | 37/200 [1:13:02<5:57:10, 131.48s/it]Evaluating commonsenseqa :  69%|██████▉   | 138/200 [3:33:08<1:38:49, 95.64s/it]Evaluating commonsenseqa :  68%|██████▊   | 137/200 [3:06:45<1:26:36, 82.49s/it]Evaluating commonsenseqa :  66%|██████▌   | 131/200 [4:54:32<2:40:32, 139.60s/it]Evaluating commonsenseqa :   2%|▏         | 3/200 [04:44<5:25:09, 99.03s/it]Evaluating commonsenseqa :  70%|██████▉   | 139/200 [3:34:44<1:37:14, 95.65s/it]Evaluating commonsenseqa :  19%|█▉        | 38/200 [1:15:17<5:57:39, 132.47s/it]Evaluating commonsenseqa :   2%|▏         | 4/200 [05:59<4:52:26, 89.52s/it]Evaluating commonsenseqa :  69%|██████▉   | 138/200 [3:08:22<1:29:37, 86.74s/it]Evaluating commonsenseqa :  66%|██████▌   | 132/200 [4:56:54<2:38:54, 140.22s/it]Evaluating commonsenseqa :  70%|███████   | 140/200 [3:36:23<1:36:35, 96.59s/it]Evaluating commonsenseqa :  20%|█▉        | 39/200 [1:17:08<5:38:15, 126.06s/it]Evaluating commonsenseqa :  70%|██████▉   | 139/200 [3:09:58<1:31:04, 89.58s/it]Evaluating commonsenseqa :   2%|▎         | 5/200 [07:46<5:11:15, 95.77s/it]Evaluating commonsenseqa :  70%|███████   | 140/200 [3:10:30<1:12:28, 72.47s/it]Evaluating commonsenseqa :  70%|███████   | 141/200 [3:37:33<1:27:19, 88.81s/it]Evaluating commonsenseqa :  70%|███████   | 141/200 [3:11:18<1:04:01, 65.12s/it]Evaluating commonsenseqa :  66%|██████▋   | 133/200 [4:59:16<2:37:21, 140.92s/it]Evaluating commonsenseqa :   3%|▎         | 6/200 [09:32<5:20:33, 99.14s/it]Evaluating commonsenseqa :  71%|███████   | 142/200 [3:12:07<58:04, 60.08s/it]  Evaluating commonsenseqa :  20%|██        | 40/200 [1:19:24<5:43:57, 128.98s/it]Evaluating commonsenseqa :  71%|███████   | 142/200 [3:39:09<1:27:52, 90.91s/it]Evaluating commonsenseqa :  20%|██        | 41/200 [1:20:16<4:41:00, 106.04s/it]Evaluating commonsenseqa :   4%|▎         | 7/200 [11:18<5:26:47, 101.59s/it]Evaluating commonsenseqa :  72%|███████▏  | 143/200 [3:13:44<1:07:44, 71.30s/it]Evaluating commonsenseqa :  72%|███████▏  | 143/200 [3:40:45<1:27:43, 92.35s/it]Evaluating commonsenseqa :  67%|██████▋   | 134/200 [5:01:36<2:34:40, 140.61s/it]Evaluating commonsenseqa :   4%|▍         | 8/200 [11:57<4:21:12, 81.63s/it] Evaluating commonsenseqa :   4%|▍         | 9/200 [12:29<3:30:04, 65.99s/it]Evaluating commonsenseqa :  72%|███████▏  | 144/200 [3:41:44<1:16:52, 82.37s/it]Evaluating commonsenseqa :  21%|██        | 42/200 [1:22:19<4:52:32, 111.09s/it]Evaluating commonsenseqa :  72%|███████▏  | 144/200 [3:15:22<1:13:58, 79.26s/it]Evaluating commonsenseqa :  68%|██████▊   | 135/200 [5:03:15<2:18:42, 128.04s/it]Evaluating commonsenseqa :   5%|▌         | 10/200 [14:16<4:09:13, 78.70s/it]Evaluating commonsenseqa :  72%|███████▎  | 145/200 [3:43:21<1:19:40, 86.91s/it]Evaluating commonsenseqa :  72%|███████▎  | 145/200 [3:16:58<1:17:17, 84.32s/it]Evaluating commonsenseqa :   6%|▌         | 11/200 [14:59<3:34:04, 67.96s/it]Evaluating commonsenseqa :  22%|██▏       | 43/200 [1:24:34<5:09:15, 118.19s/it]Evaluating commonsenseqa :  68%|██████▊   | 136/200 [5:05:37<2:21:04, 132.26s/it]Evaluating commonsenseqa :  73%|███████▎  | 146/200 [3:45:00<1:21:16, 90.31s/it]Evaluating commonsenseqa :  73%|███████▎  | 146/200 [3:18:20<1:15:15, 83.62s/it]Evaluating commonsenseqa :   6%|▌         | 12/200 [16:48<4:11:25, 80.24s/it]Evaluating commonsenseqa :  74%|███████▎  | 147/200 [3:19:34<1:11:10, 80.58s/it]Evaluating commonsenseqa :  22%|██▏       | 44/200 [1:26:47<5:18:48, 122.62s/it]Evaluating commonsenseqa :  74%|███████▎  | 147/200 [3:46:35<1:21:07, 91.84s/it]Evaluating commonsenseqa :  68%|██████▊   | 137/200 [5:07:56<2:21:06, 134.38s/it]Evaluating commonsenseqa :   6%|▋         | 13/200 [18:35<4:35:36, 88.43s/it]Evaluating commonsenseqa :  74%|███████▍  | 148/200 [3:21:13<1:14:41, 86.18s/it]Evaluating commonsenseqa :  74%|███████▍  | 148/200 [3:48:12<1:20:49, 93.25s/it]Evaluating commonsenseqa :  22%|██▎       | 45/200 [1:29:01<5:25:43, 126.09s/it]Evaluating commonsenseqa :   7%|▋         | 14/200 [20:21<4:50:45, 93.79s/it]Evaluating commonsenseqa :  69%|██████▉   | 138/200 [5:10:15<2:20:22, 135.85s/it]Evaluating commonsenseqa :  74%|███████▍  | 149/200 [3:22:55<1:17:14, 90.86s/it]Evaluating commonsenseqa :  74%|███████▍  | 149/200 [3:49:48<1:20:04, 94.20s/it]Evaluating commonsenseqa :  23%|██▎       | 46/200 [1:31:13<5:28:05, 127.83s/it]Evaluating commonsenseqa :   8%|▊         | 15/200 [21:50<4:44:07, 92.15s/it]Evaluating commonsenseqa :  75%|███████▌  | 150/200 [3:51:24<1:18:52, 94.65s/it]Evaluating commonsenseqa :  75%|███████▌  | 150/200 [3:24:34<1:17:55, 93.52s/it]Evaluating commonsenseqa :  70%|██████▉   | 139/200 [5:12:34<2:18:59, 136.71s/it]Evaluating commonsenseqa :   8%|▊         | 16/200 [23:36<4:56:09, 96.58s/it]Evaluating commonsenseqa :  76%|███████▌  | 151/200 [3:53:00<1:17:45, 95.21s/it]Evaluating commonsenseqa :  76%|███████▌  | 151/200 [3:26:14<1:17:47, 95.26s/it]Evaluating commonsenseqa :  24%|██▎       | 47/200 [1:33:26<5:29:55, 129.39s/it]Evaluating commonsenseqa :  70%|███████   | 140/200 [5:14:54<2:17:44, 137.74s/it]Evaluating commonsenseqa :  76%|███████▌  | 152/200 [3:27:22<1:09:49, 87.28s/it]Evaluating commonsenseqa :   8%|▊         | 17/200 [25:22<5:03:10, 99.40s/it]Evaluating commonsenseqa :  76%|███████▌  | 152/200 [3:54:34<1:15:45, 94.71s/it]Evaluating commonsenseqa :  24%|██▍       | 48/200 [1:35:38<5:30:17, 130.38s/it]Evaluating commonsenseqa :   9%|▉         | 18/200 [26:47<4:48:16, 95.04s/it]Evaluating commonsenseqa :  76%|███████▋  | 153/200 [3:29:04<1:11:47, 91.64s/it]Evaluating commonsenseqa :  76%|███████▋  | 153/200 [3:56:11<1:14:39, 95.31s/it]Evaluating commonsenseqa :  70%|███████   | 141/200 [5:17:11<2:15:15, 137.54s/it]Evaluating commonsenseqa :  24%|██▍       | 49/200 [1:37:52<5:30:11, 131.20s/it]Evaluating commonsenseqa :  77%|███████▋  | 154/200 [3:30:44<1:12:06, 94.05s/it]Evaluating commonsenseqa :  10%|▉         | 19/200 [28:34<4:57:11, 98.52s/it]Evaluating commonsenseqa :  77%|███████▋  | 154/200 [3:57:46<1:13:08, 95.40s/it]Evaluating commonsenseqa :  10%|█         | 20/200 [29:37<4:23:41, 87.90s/it]Evaluating commonsenseqa :  71%|███████   | 142/200 [5:19:32<2:13:58, 138.59s/it]Evaluating commonsenseqa :  78%|███████▊  | 155/200 [3:32:22<1:11:33, 95.42s/it]Evaluating commonsenseqa :  78%|███████▊  | 155/200 [3:59:21<1:11:31, 95.36s/it]Evaluating commonsenseqa :  25%|██▌       | 50/200 [1:40:06<5:30:04, 132.03s/it]Evaluating commonsenseqa :  10%|█         | 21/200 [31:24<4:39:41, 93.75s/it]Evaluating commonsenseqa :  78%|███████▊  | 156/200 [3:34:05<1:11:35, 97.63s/it]Evaluating commonsenseqa :  78%|███████▊  | 156/200 [4:00:56<1:09:44, 95.11s/it]Evaluating commonsenseqa :  72%|███████▏  | 143/200 [5:21:56<2:13:01, 140.03s/it]Evaluating commonsenseqa :  26%|██▌       | 51/200 [1:42:22<5:30:58, 133.28s/it]Evaluating commonsenseqa :  11%|█         | 22/200 [33:10<4:49:01, 97.42s/it]Evaluating commonsenseqa :  78%|███████▊  | 157/200 [4:02:31<1:08:04, 95.00s/it]Evaluating commonsenseqa :  78%|███████▊  | 157/200 [3:35:43<1:10:06, 97.82s/it]Evaluating commonsenseqa :  26%|██▌       | 52/200 [1:43:09<4:25:09, 107.50s/it]Evaluating commonsenseqa :  72%|███████▏  | 144/200 [5:24:15<2:10:21, 139.68s/it]Evaluating commonsenseqa :  12%|█▏        | 23/200 [34:58<4:56:16, 100.43s/it]Evaluating commonsenseqa :  79%|███████▉  | 158/200 [4:04:06<1:06:30, 95.01s/it]Evaluating commonsenseqa :  79%|███████▉  | 158/200 [3:37:23<1:08:54, 98.45s/it]Evaluating commonsenseqa :  26%|██▋       | 53/200 [1:45:25<4:44:09, 115.98s/it]Evaluating commonsenseqa :  72%|███████▎  | 145/200 [5:26:12<2:01:54, 132.98s/it]Evaluating commonsenseqa :  80%|███████▉  | 159/200 [4:05:42<1:05:10, 95.39s/it]Evaluating commonsenseqa :  80%|███████▉  | 159/200 [3:38:58<1:06:33, 97.41s/it]Evaluating commonsenseqa :  12%|█▏        | 24/200 [36:45<5:00:19, 102.38s/it]Evaluating commonsenseqa :  80%|████████  | 160/200 [4:07:17<1:03:28, 95.22s/it]Evaluating commonsenseqa :  27%|██▋       | 54/200 [1:47:39<4:55:37, 121.49s/it]Evaluating commonsenseqa :  80%|████████  | 160/200 [3:40:30<1:03:50, 95.76s/it]Evaluating commonsenseqa :  12%|█▎        | 25/200 [38:30<5:00:52, 103.16s/it]Evaluating commonsenseqa :  73%|███████▎  | 146/200 [5:28:34<2:01:59, 135.55s/it]Evaluating commonsenseqa :  80%|████████  | 161/200 [3:41:35<56:08, 86.37s/it]  Evaluating commonsenseqa :  13%|█▎        | 26/200 [39:46<4:35:33, 95.02s/it] Evaluating commonsenseqa :  80%|████████  | 161/200 [4:08:54<1:02:20, 95.90s/it]Evaluating commonsenseqa :  28%|██▊       | 55/200 [1:49:52<5:01:56, 124.94s/it]Evaluating commonsenseqa :  81%|████████  | 162/200 [3:43:07<55:45, 88.03s/it]Evaluating commonsenseqa :  74%|███████▎  | 147/200 [5:30:54<2:00:53, 136.86s/it]Evaluating commonsenseqa :  14%|█▎        | 27/200 [41:23<4:35:58, 95.72s/it]Evaluating commonsenseqa :  81%|████████  | 162/200 [4:10:29<1:00:28, 95.48s/it]Evaluating commonsenseqa :  82%|████████▏ | 163/200 [3:43:59<47:43, 77.38s/it]Evaluating commonsenseqa :  28%|██▊       | 56/200 [1:52:06<5:05:55, 127.47s/it]Evaluating commonsenseqa :  82%|████████▏ | 163/200 [4:12:05<59:04, 95.80s/it]  Evaluating commonsenseqa :  14%|█▍        | 28/200 [43:09<4:43:28, 98.89s/it]Evaluating commonsenseqa :  82%|████████▏ | 164/200 [3:45:30<48:45, 81.27s/it]Evaluating commonsenseqa :  74%|███████▍  | 148/200 [5:33:13<1:59:18, 137.67s/it]Evaluating commonsenseqa :  14%|█▍        | 29/200 [43:57<3:57:46, 83.43s/it]Evaluating commonsenseqa :  28%|██▊       | 57/200 [1:53:24<4:28:55, 112.84s/it]Evaluating commonsenseqa :  82%|████████▏ | 164/200 [4:13:43<57:45, 96.26s/it]Evaluating commonsenseqa :  82%|████████▎ | 165/200 [3:47:02<49:20, 84.57s/it]Evaluating commonsenseqa :  15%|█▌        | 30/200 [45:45<4:17:29, 90.88s/it]Evaluating commonsenseqa :  74%|███████▍  | 149/200 [5:35:34<1:57:57, 138.78s/it]Evaluating commonsenseqa :  82%|████████▎ | 165/200 [4:15:14<55:16, 94.76s/it]Evaluating commonsenseqa :  29%|██▉       | 58/200 [1:55:39<4:42:23, 119.32s/it]Evaluating commonsenseqa :  83%|████████▎ | 166/200 [3:48:35<49:26, 87.24s/it]Evaluating commonsenseqa :  16%|█▌        | 31/200 [47:30<4:28:01, 95.16s/it]Evaluating commonsenseqa :  83%|████████▎ | 166/200 [4:16:47<53:28, 94.37s/it]Evaluating commonsenseqa :  84%|████████▎ | 167/200 [3:50:07<48:39, 88.47s/it]Evaluating commonsenseqa :  75%|███████▌  | 150/200 [5:37:54<1:55:50, 139.02s/it]Evaluating commonsenseqa :  30%|██▉       | 59/200 [1:57:50<4:49:01, 122.99s/it]Evaluating commonsenseqa :  16%|█▌        | 32/200 [49:18<4:37:27, 99.09s/it]Evaluating commonsenseqa :  84%|████████▎ | 167/200 [4:18:24<52:19, 95.14s/it]Evaluating commonsenseqa :  84%|████████▍ | 168/200 [3:51:36<47:23, 88.85s/it]Evaluating commonsenseqa :  84%|████████▍ | 168/200 [4:18:44<38:44, 72.64s/it]Evaluating commonsenseqa :  76%|███████▌  | 151/200 [5:40:13<1:53:38, 139.15s/it]Evaluating commonsenseqa :  30%|███       | 60/200 [2:00:06<4:56:07, 126.91s/it]Evaluating commonsenseqa :  84%|████████▍ | 169/200 [3:53:07<46:12, 89.44s/it]Evaluating commonsenseqa :  16%|█▋        | 33/200 [51:03<4:39:58, 100.59s/it]Evaluating commonsenseqa :  84%|████████▍ | 169/200 [4:20:21<41:13, 79.79s/it]Evaluating commonsenseqa :  85%|████████▌ | 170/200 [3:54:12<41:01, 82.06s/it]Evaluating commonsenseqa :  76%|███████▌  | 152/200 [5:42:35<1:51:54, 139.88s/it]Evaluating commonsenseqa :  17%|█▋        | 34/200 [52:49<4:43:00, 102.29s/it]Evaluating commonsenseqa :  85%|████████▌ | 170/200 [4:21:55<41:58, 83.93s/it]Evaluating commonsenseqa :  30%|███       | 61/200 [2:02:18<4:57:24, 128.38s/it]Evaluating commonsenseqa :  86%|████████▌ | 171/200 [3:55:44<41:04, 84.97s/it]Evaluating commonsenseqa :  86%|████████▌ | 171/200 [4:23:31<42:25, 87.76s/it]Evaluating commonsenseqa :  18%|█▊        | 35/200 [54:35<4:44:13, 103.35s/it]Evaluating commonsenseqa :  86%|████████▌ | 172/200 [3:57:15<40:30, 86.82s/it]Evaluating commonsenseqa :  76%|███████▋  | 153/200 [5:44:55<1:49:33, 139.86s/it]Evaluating commonsenseqa :  31%|███       | 62/200 [2:04:33<4:59:50, 130.36s/it]Evaluating commonsenseqa :  86%|████████▌ | 172/200 [4:25:08<42:12, 90.44s/it]Evaluating commonsenseqa :  18%|█▊        | 36/200 [56:17<4:41:22, 102.94s/it]Evaluating commonsenseqa :  86%|████████▋ | 173/200 [3:58:45<39:33, 87.89s/it]Evaluating commonsenseqa :  32%|███▏      | 63/200 [2:06:47<5:00:25, 131.57s/it]Evaluating commonsenseqa :  77%|███████▋  | 154/200 [5:47:15<1:47:15, 139.91s/it]Evaluating commonsenseqa :  86%|████████▋ | 173/200 [4:26:43<41:17, 91.77s/it]Evaluating commonsenseqa :  87%|████████▋ | 174/200 [3:59:55<35:42, 82.40s/it]Evaluating commonsenseqa :  18%|█▊        | 37/200 [58:02<4:42:04, 103.83s/it]Evaluating commonsenseqa :  19%|█▉        | 38/200 [58:48<3:52:42, 86.19s/it] Evaluating commonsenseqa :  88%|████████▊ | 175/200 [4:01:24<35:13, 84.54s/it]Evaluating commonsenseqa :  87%|████████▋ | 174/200 [4:28:18<40:11, 92.74s/it]Evaluating commonsenseqa :  32%|███▏      | 64/200 [2:09:02<4:59:54, 132.31s/it]Evaluating commonsenseqa :  78%|███████▊  | 155/200 [5:49:33<1:44:26, 139.25s/it]Evaluating commonsenseqa :  88%|████████▊ | 176/200 [4:02:17<29:59, 74.96s/it]Evaluating commonsenseqa :  20%|█▉        | 39/200 [1:00:34<4:07:29, 92.23s/it]Evaluating commonsenseqa :  88%|████████▊ | 175/200 [4:29:54<39:06, 93.87s/it]Evaluating commonsenseqa :  88%|████████▊ | 177/200 [4:03:46<30:17, 79.03s/it]Evaluating commonsenseqa :  20%|██        | 40/200 [1:01:35<3:40:58, 82.87s/it]Evaluating commonsenseqa :  32%|███▎      | 65/200 [2:11:16<4:59:06, 132.94s/it]Evaluating commonsenseqa :  78%|███████▊  | 156/200 [5:51:54<1:42:40, 140.00s/it]Evaluating commonsenseqa :  88%|████████▊ | 176/200 [4:31:30<37:48, 94.54s/it]Evaluating commonsenseqa :  89%|████████▉ | 178/200 [4:04:46<26:58, 73.59s/it]Evaluating commonsenseqa :  20%|██        | 41/200 [1:03:20<3:57:07, 89.48s/it]Evaluating commonsenseqa :  88%|████████▊ | 177/200 [4:33:04<36:08, 94.28s/it]Evaluating commonsenseqa :  90%|████████▉ | 179/200 [4:06:18<27:36, 78.90s/it]Evaluating commonsenseqa :  33%|███▎      | 66/200 [2:13:29<4:57:17, 133.11s/it]Evaluating commonsenseqa :  78%|███████▊  | 157/200 [5:54:16<1:40:37, 140.40s/it]Evaluating commonsenseqa :  21%|██        | 42/200 [1:05:08<4:10:05, 94.97s/it]Evaluating commonsenseqa :  90%|█████████ | 180/200 [4:07:48<27:27, 82.39s/it]Evaluating commonsenseqa :  89%|████████▉ | 178/200 [4:34:41<34:54, 95.18s/it]Evaluating commonsenseqa :  34%|███▎      | 67/200 [2:15:44<4:55:52, 133.48s/it]Evaluating commonsenseqa :  79%|███████▉  | 158/200 [5:56:38<1:38:45, 141.08s/it]Evaluating commonsenseqa :  22%|██▏       | 43/200 [1:06:56<4:19:17, 99.09s/it]Evaluating commonsenseqa :  90%|█████████ | 181/200 [4:09:19<26:51, 84.81s/it]Evaluating commonsenseqa :  90%|████████▉ | 179/200 [4:36:17<33:21, 95.31s/it]Evaluating commonsenseqa :  91%|█████████ | 182/200 [4:10:06<22:03, 73.54s/it]Evaluating commonsenseqa :  34%|███▍      | 68/200 [2:17:57<4:53:46, 133.53s/it]Evaluating commonsenseqa :  22%|██▏       | 44/200 [1:08:45<4:25:07, 101.97s/it]Evaluating commonsenseqa :  90%|█████████ | 180/200 [4:37:52<31:46, 95.32s/it]Evaluating commonsenseqa :  80%|███████▉  | 159/200 [5:58:57<1:35:48, 140.20s/it]Evaluating commonsenseqa :  92%|█████████▏| 183/200 [4:11:36<22:14, 78.48s/it]Evaluating commonsenseqa :  34%|███▍      | 69/200 [2:19:27<4:22:40, 120.31s/it]Evaluating commonsenseqa :  22%|██▎       | 45/200 [1:10:20<4:18:15, 99.97s/it] Evaluating commonsenseqa :  90%|█████████ | 181/200 [4:39:29<30:16, 95.62s/it]Evaluating commonsenseqa :  92%|█████████▏| 184/200 [4:13:04<21:43, 81.45s/it]Evaluating commonsenseqa :  80%|████████  | 160/200 [6:01:15<1:33:11, 139.78s/it]Evaluating commonsenseqa :  91%|█████████ | 182/200 [4:41:05<28:45, 95.88s/it]Evaluating commonsenseqa :  23%|██▎       | 46/200 [1:12:04<4:19:30, 101.10s/it]Evaluating commonsenseqa :  35%|███▌      | 70/200 [2:21:37<4:26:49, 123.15s/it]Evaluating commonsenseqa :  92%|█████████▎| 185/200 [4:14:35<21:02, 84.15s/it]Evaluating commonsenseqa :  92%|█████████▏| 183/200 [4:42:41<27:10, 95.88s/it]Evaluating commonsenseqa :  80%|████████  | 161/200 [6:03:32<1:30:11, 138.76s/it]Evaluating commonsenseqa :  24%|██▎       | 47/200 [1:13:51<4:21:56, 102.73s/it]Evaluating commonsenseqa :  93%|█████████▎| 186/200 [4:16:05<20:03, 85.95s/it]Evaluating commonsenseqa :  36%|███▌      | 71/200 [2:23:54<4:33:36, 127.26s/it]Evaluating commonsenseqa :  24%|██▍       | 48/200 [1:14:37<3:37:12, 85.74s/it] Evaluating commonsenseqa :  92%|█████████▏| 184/200 [4:44:17<25:32, 95.80s/it]Evaluating commonsenseqa :  94%|█████████▎| 187/200 [4:17:36<18:56, 87.39s/it]Evaluating commonsenseqa :  81%|████████  | 162/200 [6:05:52<1:28:11, 139.24s/it]Evaluating commonsenseqa :  24%|██▍       | 49/200 [1:16:25<3:52:32, 92.40s/it]Evaluating commonsenseqa :  36%|███▌      | 72/200 [2:26:07<4:35:33, 129.17s/it]Evaluating commonsenseqa :  92%|█████████▎| 185/200 [4:45:52<23:56, 95.77s/it]Evaluating commonsenseqa :  94%|█████████▍| 188/200 [4:19:07<17:42, 88.51s/it]Evaluating commonsenseqa :  25%|██▌       | 50/200 [1:17:54<3:49:01, 91.61s/it]Evaluating commonsenseqa :  82%|████████▏ | 163/200 [6:08:11<1:25:53, 139.28s/it]Evaluating commonsenseqa :  93%|█████████▎| 186/200 [4:47:28<22:19, 95.71s/it]Evaluating commonsenseqa :  94%|█████████▍| 189/200 [4:20:39<16:25, 89.57s/it]Evaluating commonsenseqa :  36%|███▋      | 73/200 [2:28:23<4:37:46, 131.24s/it]Evaluating commonsenseqa :  26%|██▌       | 51/200 [1:19:33<3:53:01, 93.84s/it]Evaluating commonsenseqa :  95%|█████████▌| 190/200 [4:22:10<14:59, 89.96s/it]Evaluating commonsenseqa :  94%|█████████▎| 187/200 [4:49:04<20:45, 95.83s/it]Evaluating commonsenseqa :  82%|████████▏ | 164/200 [6:10:30<1:23:28, 139.13s/it]Evaluating commonsenseqa :  37%|███▋      | 74/200 [2:30:37<4:37:23, 132.09s/it]Evaluating commonsenseqa :  26%|██▌       | 52/200 [1:21:21<4:01:23, 97.86s/it]Evaluating commonsenseqa :  96%|█████████▌| 191/200 [4:23:41<13:32, 90.26s/it]Evaluating commonsenseqa :  94%|█████████▍| 188/200 [4:50:40<19:09, 95.75s/it]Evaluating commonsenseqa :  96%|█████████▌| 192/200 [4:24:33<10:32, 79.01s/it]Evaluating commonsenseqa :  26%|██▋       | 53/200 [1:23:02<4:02:36, 99.02s/it]Evaluating commonsenseqa :  82%|████████▎ | 165/200 [6:12:54<1:21:53, 140.39s/it]Evaluating commonsenseqa :  94%|█████████▍| 189/200 [4:52:16<17:34, 95.91s/it]Evaluating commonsenseqa :  38%|███▊      | 75/200 [2:32:50<4:35:31, 132.25s/it]Evaluating commonsenseqa :  96%|█████████▋| 193/200 [4:26:04<09:38, 82.60s/it]Evaluating commonsenseqa :  95%|█████████▌| 190/200 [4:53:51<15:58, 95.83s/it]Evaluating commonsenseqa :  27%|██▋       | 54/200 [1:24:47<4:05:21, 100.83s/it]Evaluating commonsenseqa :  97%|█████████▋| 194/200 [4:27:36<08:32, 85.43s/it]Evaluating commonsenseqa :  83%|████████▎ | 166/200 [6:15:13<1:19:25, 140.18s/it]Evaluating commonsenseqa :  28%|██▊       | 55/200 [1:25:29<3:21:02, 83.19s/it] Evaluating commonsenseqa :  38%|███▊      | 76/200 [2:35:04<4:34:33, 132.85s/it]Evaluating commonsenseqa :  98%|█████████▊| 195/200 [4:28:15<05:56, 71.27s/it]Evaluating commonsenseqa :  96%|█████████▌| 191/200 [4:55:27<14:20, 95.66s/it]Evaluating commonsenseqa :  28%|██▊       | 56/200 [1:26:25<3:00:06, 75.05s/it]Evaluating commonsenseqa :  84%|████████▎ | 167/200 [6:16:35<1:07:28, 122.70s/it]Evaluating commonsenseqa :  28%|██▊       | 57/200 [1:27:00<2:29:40, 62.80s/it]Evaluating commonsenseqa :  98%|█████████▊| 196/200 [4:29:46<05:08, 77.20s/it]Evaluating commonsenseqa :  38%|███▊      | 77/200 [2:37:17<4:32:05, 132.73s/it]Evaluating commonsenseqa :  96%|█████████▌| 192/200 [4:57:01<12:43, 95.39s/it]Evaluating commonsenseqa :  29%|██▉       | 58/200 [1:28:27<2:46:03, 70.16s/it]Evaluating commonsenseqa :  96%|█████████▋| 193/200 [4:57:44<09:16, 79.56s/it]Evaluating commonsenseqa :  98%|█████████▊| 197/200 [4:31:15<04:02, 80.86s/it]Evaluating commonsenseqa :  84%|████████▍ | 168/200 [6:18:57<1:08:29, 128.43s/it]Evaluating commonsenseqa :  39%|███▉      | 78/200 [2:39:02<4:13:10, 124.51s/it]Evaluating commonsenseqa :  30%|██▉       | 59/200 [1:30:11<3:08:54, 80.38s/it]Evaluating commonsenseqa :  97%|█████████▋| 194/200 [4:59:21<08:28, 84.77s/it]Evaluating commonsenseqa :  99%|█████████▉| 198/200 [4:32:46<02:47, 83.89s/it]Evaluating commonsenseqa :  30%|███       | 60/200 [1:30:48<2:36:42, 67.16s/it]Evaluating commonsenseqa :  30%|███       | 61/200 [1:31:27<2:16:30, 58.92s/it]Evaluating commonsenseqa :  84%|████████▍ | 169/200 [6:21:17<1:08:05, 131.78s/it]Evaluating commonsenseqa :  40%|███▉      | 79/200 [2:41:16<4:16:34, 127.23s/it]Evaluating commonsenseqa :  98%|█████████▊| 195/200 [5:00:56<07:18, 87.78s/it]Evaluating commonsenseqa : 100%|█████████▉| 199/200 [4:34:16<01:25, 85.69s/it]Evaluating commonsenseqa :  31%|███       | 62/200 [1:33:14<2:48:29, 73.25s/it]Evaluating commonsenseqa :  98%|█████████▊| 196/200 [5:02:31<05:59, 89.89s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [4:35:48<00:00, 87.66s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [4:35:48<00:00, 82.74s/it]
name: commonsenseqa | avg. gen lenth: 227.054 | time: 16550.240037441254s
python -m torch.distributed.launch --use-env --nproc_per_node 1 --nnodes 1 --master_addr ia1 --master_port 10136 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name mathqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o19-tmathqa-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 19 17 19 True False 4096 5
/home/ylu130/.local/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2023-09-20 16:03:22,229] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o19-tmathqa-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 19
  out_domain_data_name ......... mathqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o19-tmathqa-s10-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 481477.25it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Evaluating commonsenseqa :  85%|████████▌ | 170/200 [6:23:37<1:07:08, 134.28s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.90s/it]
 > number of parameters: 6738415616
[2023-09-20 16:03:34,870] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.3, git-hash=unknown, git-branch=unknown
[2023-09-20 16:03:34,871] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-09-20 16:03:35,196] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-20 16:03:35,197] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   amp_enabled .................. False
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   amp_params ................... False
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fd5c8e0aad0>
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   communication_data_type ...... None
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   disable_allgather ............ False
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   dump_state ................... False
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2023-09-20 16:03:35,198] [INFO] [config.py:971:print]   global_rank .................. 0
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   gradient_clipping ............ 0.0
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 2048
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   loss_scale ................... 0
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   optimizer_name ............... None
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   optimizer_params ............. None
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   pld_enabled .................. False
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   pld_params ................... False
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   scheduler_name ............... None
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   scheduler_params ............. None
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   sparse_attention ............. None
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   train_batch_size ............. 1
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  1
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   world_size ................... 1
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  True
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   zero_enabled ................. False
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-20 16:03:35,199] [INFO] [config.py:971:print]   zero_optimization_stage ...... 0
[2023-09-20 16:03:35,199] [INFO] [config.py:957:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/200 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: in a recent head - to - head run - off election, 12000 absentee ballets were cast. 1 / 6 of the absentee ballets were thrown out and 3 / 5 of the remaining absentee ballets were cast for candidate a. how many absentee votes did candidate b receive? a ) 2,000, b ) 3,000, c ) 4,000, d ) 8,000, e ) 9,000
Output: c

Input: the total age of a and b is 11 years more than the total age of b and c. c is how many years younger than a.? a ) 16, b ) 12, c ) 11, d ) 20, e ) 10
Output: c

Input: the scoring system in a certain football competition goes as follows : 3 points for victory, 1 point for a draw, and 0 points for defeat. each team plays 20 matches. if a team scored 14 points after 5 games, what is the least number of the remaining matches it has to win to reach the 40 - point mark by the end of the tournament? a ) 6, b ) 7, c ) 8, d ) 9, e ) 10
Output: a

Input: how much water should be added to 10 liters of a 20 % - solution of alcohol to reduce the concentration of alcohol in the solution by 75 %? a ) 25 liters, b ) 27 liters, c ) 30 liters, d ) 32 liters, e ) 35 liters
Output: c

Input: a goods train runs at the speed of 72 kmph and crosses a 250 m long platform in 36 seconds. what is the length of the goods train? a ) 470 m, b ) 240 m, c ) 260 m, d ) 270 m, e ) none of these
Output: a

Input: the volume of a cube is 1728 cc. find its surface. a ) 864, b ) 556, c ) 255, d ) 287, e ) 267
Output: a

Input: a certain drink of type a is prepared by mixing 4 parts milk with 3 parts fruit juice. another drink of type b is prepared by mixing 4 parts of fruit juice and 3 parts of milk. how many liters of fruit juice must be added to 63 liters of drink a to convert it to drink b? a ) 7, b ) 14, c ) 21, d ) 28, e ) 35
Output: c

Input: last week john spent 10 percent of his wages on recreation. this week, his wages are 10 percent less than last week ʼ s wages and he spent 40 percent of his wages on recreation. the amount he spends on recreation this week is what percent of the amount he spent on recreation last week a ) 180 %, b ) 360 %, c ) 200 %, d ) 220 %, e ) 250 %
Output: b

Input: the salary of a person was reduced by 15 %. by what percent should his reduced salary be raised so as to bring it at par with his original salary? a ) 10 %, b ) 17.6 %, c ) 13.7 %, d ) 15.1 %, e ) 12.3 %
Output: b

Input: if 20 men can build a water fountain 56 metres long in 7 days, what length of a similar water fountain can be built by 35 men in 3 days? a ) 40 m, b ) 42 m, c ) 47 m, d ) 49 m, e ) 50 m
Output: b

Input: 12 men complete a work in 9 days. after they have worked for 6 days, 6 more men join them. how many days will they take to complete the remaining work? a ) 2 days, b ) 7 days, c ) 8 days, d ) 9 days, e ) 45 days
Output: a

Input: a cheese factory sells its cheese in rectangular blocks. a normal block has a volume of 5 cubic feet. if a large block has twice the width, twice the depth, and the same length of a normal block, what is the volume of cheese in a large block in cubic feet? a ) 15, b ) 30, c ) 20, d ) 18, e ) 25
Output: c

Input: two trains, one from howrah to patna and the other from patna to howrah, start simultaneously. after they meet, the trains reach their destinations after 64 hours and 25 hours respectively. the ratio of their speeds is? a ) 4 : 9, b ) 4 : 3, c ) 4 : 5, d ) 5 : 8, e ) 4 : 2
Output: d

Input: john had a stock of 1400 books in his bookshop. he sold 62 on monday, 62 on tuesday, 60 on wednesday, 48 on thursday and 40 on friday. what percentage of the books were not sold? a ) 81.57 %, b ) 36.5 %, c ) 80.67 %, d ) 56.5 %, e ) 80.57 %
Output: e

Input: a and b can do a piece of work in 18 days ; band c can do it in 24 days a and c can do it in 36 days. in how many days will a, band c finish it together? a ) 15 days, b ) 12 days, c ) 8 days, d ) 16 days, e ) 9 days
Output: d

Input: p, q and r have $ 9000 among themselves. r has two - thirds of the total amount with p and q. find the amount with r? a ) 2400, b ) 3600, c ) 3998, d ) 2539, e ) 1930
Output: b

Input: the cost of the paint is rs. 40 per kg. if 1 kg of paint covers 20 sq. ft, how much will it cost to paint outside of a cube having 30 feet each side a ) rs. 962, b ) rs. 672, c ) rs. 546, d ) rs. 10800, e ) none of these
Output: d

Input: a salesman's income consists of a commission and a base salary of $ 370 per week. over the past 5 weeks, his weekly income totals have been $ 406, $ 413, $ 420, $ 436 and $ 395. what must his average ( arithmetic mean ) commission be per week over the next two weeks so that his average weekly income is $ 500 over the 7 - week period? a ) $ 150, b ) $ 345, c ) $ 365, d ) $ 715, e ) $ 730
Output: b

Input: a 230 m long train running at the speed of 120 km / hr crosses another train running in opposite direction at the speed of 80 km / hr in 9 sec. what is the length of the other train? a ) 230, b ) 270, c ) 260, d ) 256, e ) 298
Output: b

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/mathqa/o19-tmathqa-s10-rFalse-m4096
Evaluating commonsenseqa :  40%|████      | 80/200 [2:43:32<4:20:01, 130.02s/it]Evaluating commonsenseqa :  32%|███▏      | 63/200 [1:35:00<3:09:37, 83.05s/it]Evaluating commonsenseqa :  98%|█████████▊| 197/200 [5:04:07<04:35, 91.71s/it]Evaluating commonsenseqa :   0%|          | 1/200 [01:26<4:47:31, 86.69s/it]Evaluating commonsenseqa :  86%|████████▌ | 171/200 [6:25:56<1:05:37, 135.78s/it]Evaluating commonsenseqa :  40%|████      | 81/200 [2:45:45<4:19:42, 130.95s/it]Evaluating commonsenseqa :  99%|█████████▉| 198/200 [5:05:40<03:04, 92.34s/it]Evaluating commonsenseqa :  32%|███▏      | 64/200 [1:36:45<3:23:25, 89.75s/it]Evaluating commonsenseqa :   1%|          | 2/200 [02:53<4:46:07, 86.70s/it]Evaluating commonsenseqa :  32%|███▎      | 65/200 [1:37:27<2:49:15, 75.23s/it]Evaluating commonsenseqa : 100%|█████████▉| 199/200 [5:07:17<01:33, 93.47s/it]Evaluating commonsenseqa :   2%|▏         | 3/200 [04:19<4:43:25, 86.32s/it]Evaluating commonsenseqa :  86%|████████▌ | 172/200 [6:28:17<1:04:08, 137.44s/it]Evaluating commonsenseqa :  41%|████      | 82/200 [2:48:00<4:19:47, 132.10s/it]Evaluating commonsenseqa :  33%|███▎      | 66/200 [1:39:15<3:10:03, 85.10s/it]Evaluating commonsenseqa :   2%|▏         | 4/200 [05:45<4:42:06, 86.36s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [5:08:52<00:00, 94.06s/it]Evaluating commonsenseqa : 100%|██████████| 200/200 [5:08:52<00:00, 92.66s/it]
