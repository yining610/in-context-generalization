WORLD_SIZE=1
MASTER_ADDR=icgpu04
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 17479 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o11-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 11 11 12 13 14 15 True 4096 10
[2023-09-09 14:55:01,795] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 17479 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o12-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 12 11 12 13 14 15 True 4096 10
[2023-09-09 14:55:08,293] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 17479 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o13-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 13 11 12 13 14 15 True 4096 10
[2023-09-09 14:55:15,186] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 17479 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o14-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 14 11 12 13 14 15 True 4096 10
[2023-09-09 14:55:22,030] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu04 --master_port 17479 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 10 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o15-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 15 11 12 13 14 15 True 4096 10
