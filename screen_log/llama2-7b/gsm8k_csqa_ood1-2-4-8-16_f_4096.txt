torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 12355 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o1-tcommonsenseqa-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 00:31:18,100] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 00:31:18,100] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 2
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o1-tcommonsenseqa-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 1
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o1-tcommonsenseqa-s1-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading data:   0%|                                                           | 0/7473 [00:00<?, ?it/s]Loading data: 100%|███████████████████████████████████████████| 7473/7473 [00:00<00:00, 1147502.61it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                                 | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                 | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|████████████████████▌                    | 1/2 [00:06<00:06,  6.60s/it]Loading checkpoint shards:  50%|████████████████████▌                    | 1/2 [00:07<00:07,  7.08s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  4.04s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  4.42s/it]
[2023-08-30 00:31:28,083] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:09<00:00,  4.27s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:09<00:00,  4.70s/it]
 > number of parameters: 6738415616
[2023-08-30 00:31:28,692] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 00:31:29,113] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-30 00:31:29,115] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-30 00:31:29,115] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-30 00:31:29,115] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-30 00:31:29,115] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-30 00:31:29,115] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f1ee07c9300>
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-30 00:31:29,116] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-30 00:31:29,117] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-30 00:31:29,117] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-30 00:31:29,117] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-30 00:31:29,117] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-30 00:31:29,117] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-30 00:31:29,117] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-30 00:31:29,117] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-30 00:31:29,117] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-30 00:31:29,117] [INFO] [config.py:964:print]   train_batch_size ............. 2
[2023-08-30 00:31:29,117] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-30 00:31:29,117] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-30 00:31:29,117] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-30 00:31:29,117] [INFO] [config.py:964:print]   world_size ................... 2
[2023-08-30 00:31:29,117] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-30 00:31:29,117] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-30 00:31:29,117] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-30 00:31:29,117] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-30 00:31:29,117] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-30 00:31:29,117] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating gsm8k :   0%|                                                       | 0/100 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following grade math question.

Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Output: A: oil refineries

Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o1-tcommonsenseqa-s1-rFalse-m4096
Evaluating gsm8k :   1%|▍                                           | 1/100 [02:22<3:55:47, 142.90s/it]Evaluating gsm8k :   2%|▉                                           | 2/100 [04:41<3:49:40, 140.62s/it]Evaluating gsm8k :   3%|█▎                                          | 3/100 [06:55<3:42:29, 137.62s/it]Evaluating gsm8k :   4%|█▊                                          | 4/100 [09:16<3:42:10, 138.86s/it]Evaluating gsm8k :   5%|██▏                                         | 5/100 [11:35<3:39:41, 138.75s/it]Evaluating gsm8k :   6%|██▋                                         | 6/100 [13:57<3:39:20, 140.01s/it]Evaluating gsm8k :   7%|███                                         | 7/100 [16:19<3:37:46, 140.50s/it]Evaluating gsm8k :   8%|███▌                                        | 8/100 [18:39<3:35:10, 140.33s/it]Evaluating gsm8k :   9%|███▉                                        | 9/100 [20:57<3:31:55, 139.73s/it]Evaluating gsm8k :  10%|████▎                                      | 10/100 [23:19<3:30:31, 140.35s/it]Evaluating gsm8k :  11%|████▋                                      | 11/100 [24:42<3:02:00, 122.70s/it]Evaluating gsm8k :  12%|█████▏                                     | 12/100 [26:58<3:06:07, 126.90s/it]Evaluating gsm8k :  13%|█████▌                                     | 13/100 [28:17<2:42:59, 112.40s/it]Evaluating gsm8k :  14%|██████                                     | 14/100 [30:35<2:52:16, 120.19s/it]Evaluating gsm8k :  15%|██████▍                                    | 15/100 [32:34<2:49:29, 119.64s/it]Evaluating gsm8k :  16%|██████▉                                    | 16/100 [34:52<2:55:33, 125.40s/it]Evaluating gsm8k :  17%|███████▎                                   | 17/100 [37:11<2:58:47, 129.25s/it]Evaluating gsm8k :  18%|███████▋                                   | 18/100 [39:33<3:01:49, 133.05s/it]Evaluating gsm8k :  19%|████████▏                                  | 19/100 [41:41<2:57:55, 131.80s/it]Evaluating gsm8k :  20%|████████▌                                  | 20/100 [44:02<2:59:20, 134.51s/it]Evaluating gsm8k :  21%|█████████                                  | 21/100 [46:25<3:00:19, 136.96s/it]Evaluating gsm8k :  22%|█████████▍                                 | 22/100 [48:42<2:58:02, 136.96s/it]Evaluating gsm8k :  23%|█████████▉                                 | 23/100 [51:05<2:58:02, 138.74s/it]Evaluating gsm8k :  24%|██████████▎                                | 24/100 [52:00<2:23:59, 113.68s/it]Evaluating gsm8k :  25%|██████████▊                                | 25/100 [53:37<2:15:47, 108.64s/it]Evaluating gsm8k :  26%|███████████▏                               | 26/100 [55:59<2:26:12, 118.54s/it]Evaluating gsm8k :  27%|███████████▌                               | 27/100 [58:20<2:32:28, 125.32s/it]Evaluating gsm8k :  28%|████████████                               | 28/100 [59:01<2:00:19, 100.28s/it]Evaluating gsm8k :  29%|███████████▉                             | 29/100 [1:01:21<2:12:35, 112.05s/it]Evaluating gsm8k :  30%|████████████▎                            | 30/100 [1:03:11<2:10:01, 111.44s/it]Evaluating gsm8k :  31%|████████████▋                            | 31/100 [1:05:34<2:18:51, 120.75s/it]Evaluating gsm8k :  32%|█████████████                            | 32/100 [1:07:54<2:23:25, 126.56s/it]Evaluating gsm8k :  33%|█████████████▌                           | 33/100 [1:10:16<2:26:31, 131.21s/it]Evaluating gsm8k :  34%|█████████████▉                           | 34/100 [1:12:35<2:26:59, 133.63s/it]Evaluating gsm8k :  35%|██████████████▎                          | 35/100 [1:14:57<2:27:33, 136.21s/it]Evaluating gsm8k :  36%|██████████████▊                          | 36/100 [1:17:08<2:23:26, 134.48s/it]Evaluating gsm8k :  37%|███████████████▏                         | 37/100 [1:19:30<2:23:48, 136.96s/it]Evaluating gsm8k :  38%|███████████████▌                         | 38/100 [1:21:50<2:22:28, 137.88s/it]Evaluating gsm8k :  39%|███████████████▉                         | 39/100 [1:24:13<2:21:28, 139.16s/it]Evaluating gsm8k :  40%|████████████████▍                        | 40/100 [1:26:31<2:18:56, 138.94s/it]Evaluating gsm8k :  41%|████████████████▊                        | 41/100 [1:27:10<1:47:04, 108.89s/it]Evaluating gsm8k :  42%|█████████████████▏                       | 42/100 [1:29:31<1:54:47, 118.74s/it]Evaluating gsm8k :  43%|█████████████████▋                       | 43/100 [1:31:52<1:59:06, 125.37s/it]Evaluating gsm8k :  44%|██████████████████                       | 44/100 [1:34:11<2:00:52, 129.51s/it]Evaluating gsm8k :  45%|██████████████████▍                      | 45/100 [1:35:40<1:47:33, 117.33s/it]Evaluating gsm8k :  46%|██████████████████▊                      | 46/100 [1:37:58<1:51:09, 123.51s/it]Evaluating gsm8k :  47%|███████████████████▎                     | 47/100 [1:40:21<1:54:07, 129.20s/it]Evaluating gsm8k :  48%|███████████████████▋                     | 48/100 [1:42:30<1:51:57, 129.19s/it]Evaluating gsm8k :  49%|████████████████████                     | 49/100 [1:44:52<1:53:11, 133.17s/it]Evaluating gsm8k :  50%|████████████████████▌                    | 50/100 [1:47:13<1:52:42, 135.26s/it]Evaluating gsm8k :  51%|████████████████████▉                    | 51/100 [1:49:18<1:47:57, 132.19s/it]Evaluating gsm8k :  52%|█████████████████████▎                   | 52/100 [1:50:09<1:26:21, 107.95s/it]Evaluating gsm8k :  53%|█████████████████████▋                   | 53/100 [1:52:27<1:31:37, 116.96s/it]Evaluating gsm8k :  54%|██████████████████████▏                  | 54/100 [1:54:45<1:34:33, 123.35s/it]Evaluating gsm8k :  55%|██████████████████████▌                  | 55/100 [1:57:09<1:37:01, 129.36s/it]Evaluating gsm8k :  56%|██████████████████████▉                  | 56/100 [1:58:48<1:28:14, 120.32s/it]Evaluating gsm8k :  57%|███████████████████████▎                 | 57/100 [2:01:08<1:30:28, 126.25s/it]Evaluating gsm8k :  58%|███████████████████████▊                 | 58/100 [2:03:29<1:31:35, 130.84s/it]Evaluating gsm8k :  59%|████████████████████████▏                | 59/100 [2:05:49<1:31:09, 133.39s/it]Evaluating gsm8k :  60%|████████████████████████▌                | 60/100 [2:08:09<1:30:19, 135.48s/it]Evaluating gsm8k :  61%|█████████████████████████                | 61/100 [2:10:29<1:29:00, 136.92s/it]Evaluating gsm8k :  62%|█████████████████████████▍               | 62/100 [2:11:56<1:17:09, 121.82s/it]Evaluating gsm8k :  63%|█████████████████████████▊               | 63/100 [2:13:54<1:14:21, 120.59s/it]Evaluating gsm8k :  64%|██████████████████████████▏              | 64/100 [2:16:16<1:16:14, 127.08s/it]Evaluating gsm8k :  65%|██████████████████████████▋              | 65/100 [2:17:34<1:05:29, 112.28s/it]Evaluating gsm8k :  66%|███████████████████████████              | 66/100 [2:19:58<1:09:04, 121.90s/it]Evaluating gsm8k :  67%|███████████████████████████▍             | 67/100 [2:22:22<1:10:38, 128.43s/it]Evaluating gsm8k :  68%|███████████████████████████▉             | 68/100 [2:24:21<1:07:03, 125.74s/it]Evaluating gsm8k :  69%|████████████████████████████▎            | 69/100 [2:26:48<1:08:17, 132.18s/it]Evaluating gsm8k :  70%|████████████████████████████▋            | 70/100 [2:28:51<1:04:39, 129.33s/it]Evaluating gsm8k :  71%|█████████████████████████████            | 71/100 [2:31:13<1:04:22, 133.18s/it]Evaluating gsm8k :  72%|█████████████████████████████▌           | 72/100 [2:33:34<1:03:09, 135.34s/it]Evaluating gsm8k :  73%|███████████████████████████████▍           | 73/100 [2:35:20<56:55, 126.50s/it]Evaluating gsm8k :  74%|███████████████████████████████▊           | 74/100 [2:37:38<56:24, 130.15s/it]Evaluating gsm8k :  75%|████████████████████████████████▎          | 75/100 [2:39:58<55:28, 133.14s/it]Evaluating gsm8k :  76%|████████████████████████████████▋          | 76/100 [2:41:12<46:09, 115.38s/it]Evaluating gsm8k :  77%|█████████████████████████████████          | 77/100 [2:43:33<47:06, 122.89s/it]Evaluating gsm8k :  78%|█████████████████████████████████▌         | 78/100 [2:45:51<46:43, 127.41s/it]Evaluating gsm8k :  79%|█████████████████████████████████▉         | 79/100 [2:48:15<46:20, 132.39s/it]Evaluating gsm8k :  80%|██████████████████████████████████▍        | 80/100 [2:49:16<37:04, 111.21s/it]Evaluating gsm8k :  81%|██████████████████████████████████▊        | 81/100 [2:51:40<38:15, 120.80s/it]Evaluating gsm8k :  82%|███████████████████████████████████▎       | 82/100 [2:54:01<38:06, 127.05s/it]Evaluating gsm8k :  83%|███████████████████████████████████▋       | 83/100 [2:56:24<37:19, 131.71s/it]Evaluating gsm8k :  84%|████████████████████████████████████       | 84/100 [2:58:46<35:59, 134.97s/it]Evaluating gsm8k :  85%|████████████████████████████████████▌      | 85/100 [3:01:04<33:54, 135.65s/it]Evaluating gsm8k :  86%|████████████████████████████████████▉      | 86/100 [3:03:26<32:07, 137.70s/it]Evaluating gsm8k :  87%|█████████████████████████████████████▍     | 87/100 [3:05:42<29:44, 137.24s/it]Evaluating gsm8k :  88%|█████████████████████████████████████▊     | 88/100 [3:08:04<27:42, 138.58s/it]Evaluating gsm8k :  89%|██████████████████████████████████████▎    | 89/100 [3:09:59<24:06, 131.46s/it]Evaluating gsm8k :  90%|██████████████████████████████████████▋    | 90/100 [3:12:19<22:20, 134.05s/it]Evaluating gsm8k :  91%|███████████████████████████████████████▏   | 91/100 [3:14:39<20:23, 135.99s/it]Evaluating gsm8k :  92%|███████████████████████████████████████▌   | 92/100 [3:16:55<18:07, 135.99s/it]Evaluating gsm8k :  93%|███████████████████████████████████████▉   | 93/100 [3:18:44<14:54, 127.84s/it]Evaluating gsm8k :  94%|████████████████████████████████████████▍  | 94/100 [3:21:06<13:11, 131.95s/it]Evaluating gsm8k :  95%|████████████████████████████████████████▊  | 95/100 [3:22:35<09:55, 119.15s/it]Evaluating gsm8k :  96%|█████████████████████████████████████████▎ | 96/100 [3:24:58<08:25, 126.25s/it]Evaluating gsm8k :  97%|█████████████████████████████████████████▋ | 97/100 [3:26:45<06:01, 120.42s/it]Evaluating gsm8k :  98%|██████████████████████████████████████████▏| 98/100 [3:29:08<04:14, 127.23s/it]Evaluating gsm8k :  99%|██████████████████████████████████████████▌| 99/100 [3:31:29<02:11, 131.35s/it]Evaluating gsm8k : 100%|██████████████████████████████████████████| 100/100 [3:33:48<00:00, 133.73s/it]Evaluating gsm8k : 100%|██████████████████████████████████████████| 100/100 [3:33:48<00:00, 128.29s/it]
name: gsm8k | avg. gen lenth: 231.682 | time: 12829.034383296967s
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 12355 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o2-tcommonsenseqa-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 2
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 04:05:23,539] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 04:05:23,552] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 2
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o2-tcommonsenseqa-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 2
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o2-tcommonsenseqa-s1-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading data:   0%|                                                           | 0/7473 [00:00<?, ?it/s]Loading data: 100%|███████████████████████████████████████████| 7473/7473 [00:00<00:00, 1064313.54it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                                 | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                 | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|████████████████████▌                    | 1/2 [00:06<00:06,  6.26s/it]Loading checkpoint shards:  50%|████████████████████▌                    | 1/2 [00:06<00:06,  6.79s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  3.73s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  4.11s/it]
 > number of parameters: 6738415616
[2023-08-30 04:05:32,964] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:09<00:00,  4.35s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:09<00:00,  4.72s/it]
[2023-08-30 04:05:34,141] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 04:05:34,632] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-30 04:05:34,634] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-30 04:05:34,634] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-30 04:05:34,634] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-30 04:05:34,634] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-30 04:05:34,634] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-30 04:05:34,634] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-30 04:05:34,634] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-30 04:05:34,634] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-30 04:05:34,634] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-30 04:05:34,634] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-30 04:05:34,634] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f68bd5bd2d0>
[2023-08-30 04:05:34,634] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-30 04:05:34,634] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-30 04:05:34,634] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-30 04:05:34,634] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-30 04:05:34,634] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-30 04:05:34,634] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-30 04:05:34,634] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   train_batch_size ............. 2
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   world_size ................... 2
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-30 04:05:34,635] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-30 04:05:34,636] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating gsm8k :   0%|                                                       | 0/100 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following grade math question.

Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Output: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Output: D: accomplishing

Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o2-tcommonsenseqa-s1-rFalse-m4096
Evaluating gsm8k :   1%|▍                                           | 1/100 [02:04<3:24:37, 124.02s/it]Evaluating gsm8k :   2%|▉                                           | 2/100 [03:36<2:51:48, 105.19s/it]Evaluating gsm8k :   3%|█▎                                          | 3/100 [05:52<3:12:48, 119.27s/it]Evaluating gsm8k :   4%|█▊                                          | 4/100 [08:07<3:21:08, 125.71s/it]Evaluating gsm8k :   5%|██▏                                         | 5/100 [10:27<3:27:03, 130.77s/it]Evaluating gsm8k :   6%|██▋                                         | 6/100 [12:23<3:17:08, 125.84s/it]Evaluating gsm8k :   7%|███                                         | 7/100 [14:41<3:21:20, 129.90s/it]Evaluating gsm8k :   8%|███▌                                        | 8/100 [16:37<3:12:18, 125.42s/it]Evaluating gsm8k :   9%|███▉                                        | 9/100 [18:56<3:16:27, 129.53s/it]Evaluating gsm8k :  10%|████▎                                      | 10/100 [21:18<3:20:00, 133.34s/it]Evaluating gsm8k :  11%|████▋                                      | 11/100 [23:34<3:19:19, 134.37s/it]Evaluating gsm8k :  12%|█████▏                                     | 12/100 [25:50<3:17:49, 134.88s/it]Evaluating gsm8k :  13%|█████▌                                     | 13/100 [27:06<2:49:36, 116.97s/it]Evaluating gsm8k :  14%|██████                                     | 14/100 [29:20<2:54:57, 122.07s/it]Evaluating gsm8k :  15%|██████▍                                    | 15/100 [31:38<2:59:39, 126.82s/it]Evaluating gsm8k :  16%|██████▉                                    | 16/100 [33:55<3:01:52, 129.90s/it]Evaluating gsm8k :  17%|███████▎                                   | 17/100 [36:13<3:03:04, 132.34s/it]Evaluating gsm8k :  18%|███████▋                                   | 18/100 [38:31<3:03:01, 133.92s/it]Evaluating gsm8k :  19%|████████▏                                  | 19/100 [40:46<3:01:29, 134.43s/it]Evaluating gsm8k :  20%|████████▌                                  | 20/100 [42:09<2:38:40, 119.01s/it]Evaluating gsm8k :  21%|█████████                                  | 21/100 [44:27<2:44:01, 124.57s/it]Evaluating gsm8k :  22%|█████████▍                                 | 22/100 [46:43<2:46:24, 128.00s/it]Evaluating gsm8k :  23%|█████████▉                                 | 23/100 [49:02<2:48:28, 131.28s/it]Evaluating gsm8k :  24%|██████████▎                                | 24/100 [51:17<2:47:44, 132.43s/it]Evaluating gsm8k :  25%|██████████▊                                | 25/100 [53:34<2:47:15, 133.81s/it]Evaluating gsm8k :  26%|███████████▏                               | 26/100 [55:50<2:46:03, 134.64s/it]Evaluating gsm8k :  27%|███████████▌                               | 27/100 [58:08<2:44:45, 135.42s/it]Evaluating gsm8k :  28%|███████████▍                             | 28/100 [1:00:27<2:43:53, 136.58s/it]Evaluating gsm8k :  29%|███████████▉                             | 29/100 [1:02:46<2:42:30, 137.33s/it]Evaluating gsm8k :  30%|████████████▎                            | 30/100 [1:04:25<2:26:53, 125.91s/it]Evaluating gsm8k :  31%|████████████▋                            | 31/100 [1:06:42<2:28:21, 129.01s/it]Evaluating gsm8k :  32%|█████████████                            | 32/100 [1:08:09<2:12:09, 116.61s/it]Evaluating gsm8k :  33%|█████████████▌                           | 33/100 [1:10:27<2:17:27, 123.10s/it]Evaluating gsm8k :  34%|█████████████▉                           | 34/100 [1:12:44<2:19:45, 127.05s/it]Evaluating gsm8k :  35%|██████████████▎                          | 35/100 [1:14:59<2:20:16, 129.49s/it]Evaluating gsm8k :  36%|██████████████▊                          | 36/100 [1:17:16<2:20:29, 131.71s/it]Evaluating gsm8k :  37%|███████████████▏                         | 37/100 [1:19:32<2:19:48, 133.16s/it]Evaluating gsm8k :  38%|███████████████▌                         | 38/100 [1:21:49<2:18:42, 134.23s/it]Evaluating gsm8k :  39%|███████████████▉                         | 39/100 [1:24:09<2:18:17, 136.03s/it]Evaluating gsm8k :  40%|████████████████▍                        | 40/100 [1:26:27<2:16:25, 136.42s/it]Evaluating gsm8k :  41%|████████████████▊                        | 41/100 [1:28:42<2:13:47, 136.05s/it]Evaluating gsm8k :  42%|█████████████████▏                       | 42/100 [1:31:00<2:12:07, 136.68s/it]Evaluating gsm8k :  43%|█████████████████▋                       | 43/100 [1:33:18<2:10:14, 137.10s/it]Evaluating gsm8k :  44%|██████████████████                       | 44/100 [1:34:56<1:57:08, 125.50s/it]Evaluating gsm8k :  45%|██████████████████▍                      | 45/100 [1:37:16<1:59:01, 129.85s/it]Evaluating gsm8k :  46%|██████████████████▊                      | 46/100 [1:39:06<1:51:30, 123.89s/it]Evaluating gsm8k :  47%|███████████████████▎                     | 47/100 [1:41:22<1:52:32, 127.41s/it]Evaluating gsm8k :  48%|███████████████████▋                     | 48/100 [1:43:04<1:43:41, 119.64s/it]Evaluating gsm8k :  49%|████████████████████                     | 49/100 [1:45:21<1:46:07, 124.85s/it]Evaluating gsm8k :  50%|████████████████████▌                    | 50/100 [1:47:19<1:42:32, 123.05s/it]Evaluating gsm8k :  51%|████████████████████▉                    | 51/100 [1:49:38<1:44:24, 127.84s/it]Evaluating gsm8k :  52%|█████████████████████▎                   | 52/100 [1:51:57<1:44:54, 131.13s/it]Evaluating gsm8k :  53%|█████████████████████▋                   | 53/100 [1:53:07<1:28:24, 112.86s/it]Evaluating gsm8k :  54%|██████████████████████▏                  | 54/100 [1:55:23<1:31:44, 119.67s/it]Evaluating gsm8k :  55%|██████████████████████▌                  | 55/100 [1:57:38<1:33:09, 124.21s/it]Evaluating gsm8k :  56%|██████████████████████▉                  | 56/100 [1:59:36<1:29:39, 122.27s/it]Evaluating gsm8k :  57%|███████████████████████▎                 | 57/100 [2:01:51<1:30:32, 126.34s/it]Evaluating gsm8k :  58%|███████████████████████▊                 | 58/100 [2:04:09<1:30:53, 129.84s/it]Evaluating gsm8k :  59%|████████████████████████▏                | 59/100 [2:06:28<1:30:29, 132.44s/it]Evaluating gsm8k :  60%|████████████████████████▌                | 60/100 [2:08:28<1:25:52, 128.81s/it]Evaluating gsm8k :  61%|█████████████████████████                | 61/100 [2:10:32<1:22:42, 127.25s/it]Evaluating gsm8k :  62%|█████████████████████████▍               | 62/100 [2:11:50<1:11:15, 112.51s/it]Evaluating gsm8k :  63%|█████████████████████████▊               | 63/100 [2:14:05<1:13:33, 119.27s/it]Evaluating gsm8k :  64%|██████████████████████████▏              | 64/100 [2:16:23<1:14:54, 124.86s/it]Evaluating gsm8k :  65%|██████████████████████████▋              | 65/100 [2:18:16<1:10:48, 121.39s/it]Evaluating gsm8k :  66%|███████████████████████████              | 66/100 [2:20:35<1:11:39, 126.46s/it]Evaluating gsm8k :  67%|███████████████████████████▍             | 67/100 [2:22:16<1:05:22, 118.85s/it]Evaluating gsm8k :  68%|███████████████████████████▉             | 68/100 [2:24:29<1:05:38, 123.07s/it]Evaluating gsm8k :  69%|████████████████████████████▎            | 69/100 [2:26:25<1:02:34, 121.11s/it]Evaluating gsm8k :  70%|████████████████████████████▋            | 70/100 [2:28:46<1:03:33, 127.13s/it]Evaluating gsm8k :  71%|█████████████████████████████            | 71/100 [2:31:05<1:03:08, 130.64s/it]Evaluating gsm8k :  72%|██████████████████████████████▉            | 72/100 [2:32:40<56:00, 120.01s/it]Evaluating gsm8k :  73%|███████████████████████████████▍           | 73/100 [2:34:56<56:10, 124.83s/it]Evaluating gsm8k :  74%|███████████████████████████████▊           | 74/100 [2:36:05<46:48, 108.02s/it]Evaluating gsm8k :  75%|████████████████████████████████▎          | 75/100 [2:38:21<48:29, 116.40s/it]Evaluating gsm8k :  76%|████████████████████████████████▋          | 76/100 [2:40:38<49:02, 122.60s/it]Evaluating gsm8k :  77%|█████████████████████████████████          | 77/100 [2:42:55<48:38, 126.90s/it]Evaluating gsm8k :  78%|█████████████████████████████████▌         | 78/100 [2:45:10<47:25, 129.33s/it]Evaluating gsm8k :  79%|█████████████████████████████████▉         | 79/100 [2:46:34<40:27, 115.61s/it]Evaluating gsm8k :  80%|██████████████████████████████████▍        | 80/100 [2:48:47<40:19, 120.99s/it]Evaluating gsm8k :  81%|██████████████████████████████████▊        | 81/100 [2:50:59<39:18, 124.11s/it]Evaluating gsm8k :  82%|███████████████████████████████████▎       | 82/100 [2:53:16<38:25, 128.08s/it]Evaluating gsm8k :  83%|███████████████████████████████████▋       | 83/100 [2:55:34<37:05, 130.92s/it]Evaluating gsm8k :  84%|████████████████████████████████████       | 84/100 [2:57:51<35:25, 132.83s/it]Evaluating gsm8k :  85%|████████████████████████████████████▌      | 85/100 [3:00:11<33:43, 134.92s/it]Evaluating gsm8k :  86%|████████████████████████████████████▉      | 86/100 [3:02:28<31:38, 135.59s/it]Evaluating gsm8k :  87%|█████████████████████████████████████▍     | 87/100 [3:04:45<29:28, 136.07s/it]Evaluating gsm8k :  88%|█████████████████████████████████████▊     | 88/100 [3:06:55<26:50, 134.19s/it]Evaluating gsm8k :  89%|██████████████████████████████████████▎    | 89/100 [3:09:07<24:28, 133.52s/it]Evaluating gsm8k :  90%|██████████████████████████████████████▋    | 90/100 [3:11:08<21:38, 129.87s/it]Evaluating gsm8k :  91%|███████████████████████████████████████▏   | 91/100 [3:13:24<19:45, 131.68s/it]Evaluating gsm8k :  92%|███████████████████████████████████████▌   | 92/100 [3:15:41<17:46, 133.31s/it]Evaluating gsm8k :  93%|███████████████████████████████████████▉   | 93/100 [3:17:57<15:37, 133.95s/it]Evaluating gsm8k :  94%|████████████████████████████████████████▍  | 94/100 [3:20:15<13:32, 135.38s/it]Evaluating gsm8k :  95%|████████████████████████████████████████▊  | 95/100 [3:22:31<11:17, 135.52s/it]Evaluating gsm8k :  96%|█████████████████████████████████████████▎ | 96/100 [3:24:48<09:04, 136.05s/it]Evaluating gsm8k :  97%|█████████████████████████████████████████▋ | 97/100 [3:26:47<06:32, 130.69s/it]Evaluating gsm8k :  98%|██████████████████████████████████████████▏| 98/100 [3:29:04<04:25, 132.76s/it]Evaluating gsm8k :  99%|██████████████████████████████████████████▌| 99/100 [3:30:46<02:03, 123.62s/it]Evaluating gsm8k : 100%|██████████████████████████████████████████| 100/100 [3:33:02<00:00, 127.27s/it]Evaluating gsm8k : 100%|██████████████████████████████████████████| 100/100 [3:33:02<00:00, 127.83s/it]
name: gsm8k | avg. gen lenth: 257.428 | time: 12783.228007555008s
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 12355 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o4-tcommonsenseqa-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 4
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 07:38:44,040] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 07:38:44,113] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 2
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o4-tcommonsenseqa-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 4
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o4-tcommonsenseqa-s1-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading data:   0%|                                                           | 0/7473 [00:00<?, ?it/s]Loading data: 100%|████████████████████████████████████████████| 7473/7473 [00:00<00:00, 981310.35it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                                 | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                 | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|████████████████████▌                    | 1/2 [00:06<00:06,  6.76s/it]Loading checkpoint shards:  50%|████████████████████▌                    | 1/2 [00:06<00:06,  6.86s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  4.01s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  4.42s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:09<00:00,  4.09s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:09<00:00,  4.51s/it]
 > number of parameters: 6738415616
[2023-08-30 07:38:54,132] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 07:38:54,244] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 07:38:54,685] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-30 07:38:54,687] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-30 07:38:54,687] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-30 07:38:54,687] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-30 07:38:54,687] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-30 07:38:54,687] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-30 07:38:54,687] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-30 07:38:54,687] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-30 07:38:54,687] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-30 07:38:54,687] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-30 07:38:54,687] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-30 07:38:54,687] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f47f44d12d0>
[2023-08-30 07:38:54,687] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-30 07:38:54,687] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-30 07:38:54,687] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-30 07:38:54,687] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-30 07:38:54,687] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-30 07:38:54,687] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-30 07:38:54,687] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-30 07:38:54,687] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-30 07:38:54,687] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-30 07:38:54,687] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-30 07:38:54,687] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-30 07:38:54,687] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   train_batch_size ............. 2
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   world_size ................... 2
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-30 07:38:54,688] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-30 07:38:54,688] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating gsm8k :   0%|                                                       | 0/100 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following grade math question.

Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Output: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Output: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Output: A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Output: B: response

Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o4-tcommonsenseqa-s1-rFalse-m4096
Evaluating gsm8k :   1%|▍                                           | 1/100 [02:17<3:46:22, 137.20s/it]Evaluating gsm8k :   2%|▉                                           | 2/100 [04:31<3:41:44, 135.76s/it]Evaluating gsm8k :   3%|█▎                                          | 3/100 [06:46<3:38:49, 135.35s/it]Evaluating gsm8k :   4%|█▊                                          | 4/100 [09:03<3:37:12, 135.76s/it]Evaluating gsm8k :   5%|██▏                                         | 5/100 [11:19<3:35:03, 135.83s/it]Evaluating gsm8k :   6%|██▋                                         | 6/100 [13:19<3:24:17, 130.40s/it]Evaluating gsm8k :   7%|███                                         | 7/100 [15:34<3:24:52, 132.17s/it]Evaluating gsm8k :   8%|███▌                                        | 8/100 [17:47<3:22:49, 132.28s/it]Evaluating gsm8k :   9%|███▉                                        | 9/100 [18:30<2:38:27, 104.48s/it]Evaluating gsm8k :  10%|████▎                                      | 10/100 [20:26<2:42:08, 108.10s/it]Evaluating gsm8k :  11%|████▋                                      | 11/100 [22:44<2:53:54, 117.24s/it]Evaluating gsm8k :  12%|█████▏                                     | 12/100 [25:00<3:00:08, 122.82s/it]Evaluating gsm8k :  13%|█████▌                                     | 13/100 [27:16<3:03:53, 126.83s/it]Evaluating gsm8k :  14%|██████                                     | 14/100 [28:23<2:35:51, 108.74s/it]Evaluating gsm8k :  15%|██████▍                                    | 15/100 [30:35<2:43:52, 115.68s/it]Evaluating gsm8k :  16%|██████▉                                    | 16/100 [32:50<2:50:01, 121.44s/it]Evaluating gsm8k :  17%|███████▎                                   | 17/100 [35:04<2:53:19, 125.29s/it]Evaluating gsm8k :  18%|███████▋                                   | 18/100 [37:19<2:55:19, 128.29s/it]Evaluating gsm8k :  19%|████████▏                                  | 19/100 [38:44<2:35:29, 115.17s/it]Evaluating gsm8k :  20%|████████▌                                  | 20/100 [40:59<2:41:30, 121.13s/it]Evaluating gsm8k :  21%|█████████                                  | 21/100 [43:14<2:45:14, 125.50s/it]Evaluating gsm8k :  22%|█████████▍                                 | 22/100 [45:26<2:45:25, 127.25s/it]Evaluating gsm8k :  23%|█████████▉                                 | 23/100 [47:40<2:46:05, 129.42s/it]Evaluating gsm8k :  24%|██████████▎                                | 24/100 [49:53<2:45:24, 130.58s/it]Evaluating gsm8k :  25%|██████████▊                                | 25/100 [52:08<2:44:41, 131.75s/it]Evaluating gsm8k :  26%|███████████▏                               | 26/100 [53:14<2:18:18, 112.14s/it]Evaluating gsm8k :  27%|███████████▌                               | 27/100 [55:30<2:24:52, 119.07s/it]Evaluating gsm8k :  28%|████████████                               | 28/100 [57:45<2:28:55, 124.10s/it]Evaluating gsm8k :  29%|███████████▉                             | 29/100 [1:00:02<2:31:21, 127.91s/it]Evaluating gsm8k :  30%|████████████▎                            | 30/100 [1:02:09<2:28:54, 127.64s/it]Evaluating gsm8k :  31%|████████████▋                            | 31/100 [1:04:26<2:29:45, 130.23s/it]Evaluating gsm8k :  32%|█████████████                            | 32/100 [1:06:41<2:29:30, 131.92s/it]Evaluating gsm8k :  33%|█████████████▌                           | 33/100 [1:07:55<2:07:41, 114.35s/it]Evaluating gsm8k :  34%|█████████████▉                           | 34/100 [1:10:10<2:12:38, 120.58s/it]Evaluating gsm8k :  35%|██████████████▎                          | 35/100 [1:12:26<2:15:50, 125.39s/it]Evaluating gsm8k :  36%|██████████████▊                          | 36/100 [1:14:40<2:16:24, 127.89s/it]Evaluating gsm8k :  37%|███████████████▏                         | 37/100 [1:16:42<2:12:23, 126.09s/it]Evaluating gsm8k :  38%|███████████████▌                         | 38/100 [1:18:18<2:01:01, 117.13s/it]Evaluating gsm8k :  39%|███████████████▉                         | 39/100 [1:20:32<2:04:10, 122.15s/it]Evaluating gsm8k :  40%|████████████████▍                        | 40/100 [1:22:50<2:06:44, 126.74s/it]Evaluating gsm8k :  41%|████████████████▊                        | 41/100 [1:25:01<2:06:08, 128.28s/it]Evaluating gsm8k :  42%|█████████████████▏                       | 42/100 [1:26:09<1:46:18, 109.97s/it]Evaluating gsm8k :  43%|█████████████████▋                       | 43/100 [1:28:25<1:51:54, 117.79s/it]Evaluating gsm8k :  44%|██████████████████                       | 44/100 [1:30:11<1:46:41, 114.31s/it]Evaluating gsm8k :  45%|██████████████████▍                      | 45/100 [1:32:27<1:50:47, 120.86s/it]Evaluating gsm8k :  46%|██████████████████▊                      | 46/100 [1:34:43<1:52:45, 125.28s/it]Evaluating gsm8k :  47%|███████████████████▎                     | 47/100 [1:36:58<1:53:25, 128.41s/it]Evaluating gsm8k :  48%|███████████████████▋                     | 48/100 [1:38:29<1:41:20, 116.93s/it]Evaluating gsm8k :  49%|████████████████████                     | 49/100 [1:40:45<1:44:23, 122.81s/it]Evaluating gsm8k :  50%|████████████████████▌                    | 50/100 [1:43:00<1:45:19, 126.39s/it]Evaluating gsm8k :  51%|████████████████████▉                    | 51/100 [1:45:15<1:45:17, 128.93s/it]Evaluating gsm8k :  52%|█████████████████████▎                   | 52/100 [1:47:26<1:43:48, 129.76s/it]Evaluating gsm8k :  53%|█████████████████████▋                   | 53/100 [1:49:42<1:43:04, 131.58s/it]Evaluating gsm8k :  54%|██████████████████████▏                  | 54/100 [1:51:54<1:40:58, 131.70s/it]Evaluating gsm8k :  55%|██████████████████████▌                  | 55/100 [1:53:39<1:32:45, 123.69s/it]Evaluating gsm8k :  56%|██████████████████████▉                  | 56/100 [1:54:56<1:20:19, 109.54s/it]Evaluating gsm8k :  57%|███████████████████████▎                 | 57/100 [1:57:10<1:23:48, 116.94s/it]Evaluating gsm8k :  58%|███████████████████████▊                 | 58/100 [1:59:27<1:26:05, 122.98s/it]Evaluating gsm8k :  59%|████████████████████████▏                | 59/100 [2:01:20<1:21:58, 119.96s/it]Evaluating gsm8k :  60%|████████████████████████▌                | 60/100 [2:03:04<1:16:45, 115.14s/it]Evaluating gsm8k :  61%|█████████████████████████                | 61/100 [2:05:17<1:18:26, 120.68s/it]Evaluating gsm8k :  62%|█████████████████████████▍               | 62/100 [2:07:02<1:13:27, 115.98s/it]Evaluating gsm8k :  63%|███████████████████████████▋                | 63/100 [2:07:28<54:44, 88.77s/it]Evaluating gsm8k :  64%|██████████████████████████▏              | 64/100 [2:09:44<1:01:45, 102.93s/it]Evaluating gsm8k :  65%|██████████████████████████▋              | 65/100 [2:11:58<1:05:30, 112.30s/it]Evaluating gsm8k :  66%|███████████████████████████              | 66/100 [2:14:12<1:07:23, 118.94s/it]Evaluating gsm8k :  67%|███████████████████████████▍             | 67/100 [2:16:20<1:06:47, 121.44s/it]Evaluating gsm8k :  68%|███████████████████████████▉             | 68/100 [2:18:34<1:06:54, 125.45s/it]Evaluating gsm8k :  69%|████████████████████████████▎            | 69/100 [2:20:47<1:05:57, 127.67s/it]Evaluating gsm8k :  70%|██████████████████████████████             | 70/100 [2:22:28<59:44, 119.50s/it]Evaluating gsm8k :  71%|██████████████████████████████▌            | 71/100 [2:24:41<59:45, 123.65s/it]Evaluating gsm8k :  72%|██████████████████████████████▉            | 72/100 [2:26:59<59:43, 127.97s/it]Evaluating gsm8k :  73%|███████████████████████████████▍           | 73/100 [2:28:23<51:41, 114.86s/it]Evaluating gsm8k :  74%|███████████████████████████████▊           | 74/100 [2:29:30<43:33, 100.53s/it]Evaluating gsm8k :  75%|████████████████████████████████▎          | 75/100 [2:31:27<43:53, 105.33s/it]Evaluating gsm8k :  76%|████████████████████████████████▋          | 76/100 [2:33:41<45:33, 113.90s/it]Evaluating gsm8k :  77%|█████████████████████████████████          | 77/100 [2:35:56<46:08, 120.35s/it]Evaluating gsm8k :  78%|█████████████████████████████████▌         | 78/100 [2:38:14<46:02, 125.56s/it]Evaluating gsm8k :  79%|█████████████████████████████████▉         | 79/100 [2:40:28<44:50, 128.12s/it]Evaluating gsm8k :  80%|██████████████████████████████████▍        | 80/100 [2:42:43<43:24, 130.22s/it]Evaluating gsm8k :  81%|██████████████████████████████████▊        | 81/100 [2:43:48<35:03, 110.70s/it]Evaluating gsm8k :  82%|███████████████████████████████████▎       | 82/100 [2:46:03<35:22, 117.94s/it]Evaluating gsm8k :  83%|███████████████████████████████████▋       | 83/100 [2:48:04<33:38, 118.72s/it]Evaluating gsm8k :  84%|████████████████████████████████████       | 84/100 [2:50:20<33:03, 123.95s/it]Evaluating gsm8k :  85%|████████████████████████████████████▌      | 85/100 [2:52:31<31:31, 126.07s/it]Evaluating gsm8k :  86%|████████████████████████████████████▉      | 86/100 [2:53:31<24:50, 106.45s/it]Evaluating gsm8k :  87%|█████████████████████████████████████▍     | 87/100 [2:55:47<24:55, 115.01s/it]Evaluating gsm8k :  88%|█████████████████████████████████████▊     | 88/100 [2:57:30<22:20, 111.69s/it]Evaluating gsm8k :  89%|███████████████████████████████████████▏    | 89/100 [2:58:32<17:44, 96.80s/it]Evaluating gsm8k :  90%|██████████████████████████████████████▋    | 90/100 [3:00:44<17:51, 107.10s/it]Evaluating gsm8k :  91%|███████████████████████████████████████▏   | 91/100 [3:02:33<16:10, 107.84s/it]Evaluating gsm8k :  92%|███████████████████████████████████████▌   | 92/100 [3:04:52<15:36, 117.04s/it]Evaluating gsm8k :  93%|███████████████████████████████████████▉   | 93/100 [3:07:09<14:21, 123.04s/it]Evaluating gsm8k :  94%|████████████████████████████████████████▍  | 94/100 [3:09:26<12:43, 127.30s/it]Evaluating gsm8k :  95%|████████████████████████████████████████▊  | 95/100 [3:11:35<10:39, 127.83s/it]Evaluating gsm8k :  96%|█████████████████████████████████████████▎ | 96/100 [3:13:49<08:38, 129.55s/it]Evaluating gsm8k :  97%|█████████████████████████████████████████▋ | 97/100 [3:15:02<05:37, 112.58s/it]Evaluating gsm8k :  98%|██████████████████████████████████████████▏| 98/100 [3:17:15<03:57, 118.76s/it]Evaluating gsm8k :  99%|██████████████████████████████████████████▌| 99/100 [3:19:28<02:03, 123.22s/it]Evaluating gsm8k : 100%|██████████████████████████████████████████| 100/100 [3:20:28<00:00, 104.08s/it]Evaluating gsm8k : 100%|██████████████████████████████████████████| 100/100 [3:20:28<00:00, 120.28s/it]
name: gsm8k | avg. gen lenth: 228.254 | time: 12028.83826494217s
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 12355 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o8-tcommonsenseqa-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 8
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 11:08:09,340] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 11:08:09,396] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 2
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o8-tcommonsenseqa-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 8
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o8-tcommonsenseqa-s1-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading data:   0%|                                                           | 0/7473 [00:00<?, ?it/s]Loading data: 100%|███████████████████████████████████████████| 7473/7473 [00:00<00:00, 1197891.68it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                                 | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                 | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|████████████████████▌                    | 1/2 [00:06<00:06,  6.30s/it]Loading checkpoint shards:  50%|████████████████████▌                    | 1/2 [00:06<00:06,  6.75s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  3.86s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  4.22s/it]
 > number of parameters: 6738415616
[2023-08-30 11:08:18,964] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  4.03s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  4.44s/it]
[2023-08-30 11:08:19,509] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 11:08:20,052] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-30 11:08:20,054] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-30 11:08:20,055] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-30 11:08:20,055] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-30 11:08:20,055] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-30 11:08:20,055] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-30 11:08:20,055] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f01bb1bd2d0>
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-30 11:08:20,056] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   train_batch_size ............. 2
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   world_size ................... 2
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-30 11:08:20,057] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-30 11:08:20,058] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating gsm8k :   0%|                                                       | 0/100 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following grade math question.

Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Output: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Output: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Output: A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Output: B: response

Input: The lizard frightened the hiker, it's movements made what rustle? Choices:  A: garden B: trees C: books D: rocks E: bushes
Output: E: bushes

Input: The man spent big money and time maintaining his lawn, it was part of keeping up with the Joneses where? Choices:  A: front yard B: suburbia C: neighborhood D: back yard E: golf course
Output: B: suburbia

Input: What would a human do if they want to get to a store that he or she can see? Choices:  A: cross road B: see around C: drink coffee D: dream dreams E: think critically
Output: A: cross road

Input: Where would you grab an object contained by a doorway? Choices:  A: television B: control panel C: opening doors D: doorknob E: doorway
Output: E: doorway

Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o8-tcommonsenseqa-s1-rFalse-m4096
Evaluating gsm8k :   1%|▍                                           | 1/100 [02:07<3:31:08, 127.96s/it]Evaluating gsm8k :   2%|▉                                           | 2/100 [04:13<3:26:50, 126.63s/it]Evaluating gsm8k :   3%|█▎                                          | 3/100 [06:18<3:23:41, 125.99s/it]Evaluating gsm8k :   4%|█▊                                          | 4/100 [08:04<3:08:40, 117.92s/it]Evaluating gsm8k :   5%|██▏                                         | 5/100 [09:32<2:49:52, 107.29s/it]Evaluating gsm8k :   6%|██▋                                         | 6/100 [11:27<2:51:45, 109.63s/it]Evaluating gsm8k :   7%|███                                         | 7/100 [13:04<2:43:36, 105.56s/it]Evaluating gsm8k :   8%|███▌                                        | 8/100 [15:09<2:51:29, 111.84s/it]Evaluating gsm8k :   9%|███▉                                        | 9/100 [17:15<2:56:09, 116.15s/it]Evaluating gsm8k :  10%|████▎                                      | 10/100 [19:21<2:58:48, 119.21s/it]Evaluating gsm8k :  11%|████▋                                      | 11/100 [20:49<2:42:45, 109.73s/it]Evaluating gsm8k :  12%|█████▏                                     | 12/100 [22:51<2:46:34, 113.57s/it]Evaluating gsm8k :  13%|█████▋                                      | 13/100 [23:56<2:23:23, 98.89s/it]Evaluating gsm8k :  14%|██████                                     | 14/100 [26:03<2:33:39, 107.20s/it]Evaluating gsm8k :  15%|██████▍                                    | 15/100 [27:51<2:32:29, 107.64s/it]Evaluating gsm8k :  16%|██████▉                                    | 16/100 [29:58<2:38:35, 113.28s/it]Evaluating gsm8k :  17%|███████▎                                   | 17/100 [32:02<2:41:23, 116.67s/it]Evaluating gsm8k :  18%|███████▋                                   | 18/100 [34:07<2:42:44, 119.07s/it]Evaluating gsm8k :  19%|████████▏                                  | 19/100 [36:14<2:43:57, 121.46s/it]Evaluating gsm8k :  20%|████████▌                                  | 20/100 [38:04<2:37:28, 118.11s/it]Evaluating gsm8k :  21%|█████████                                  | 21/100 [40:09<2:38:05, 120.07s/it]Evaluating gsm8k :  22%|█████████▍                                 | 22/100 [42:15<2:38:33, 121.97s/it]Evaluating gsm8k :  23%|█████████▉                                 | 23/100 [43:52<2:26:53, 114.47s/it]Evaluating gsm8k :  24%|██████████▎                                | 24/100 [45:57<2:28:57, 117.59s/it]Evaluating gsm8k :  25%|██████████▊                                | 25/100 [47:59<2:28:36, 118.89s/it]Evaluating gsm8k :  26%|███████████▏                               | 26/100 [50:07<2:29:45, 121.43s/it]Evaluating gsm8k :  27%|███████████▌                               | 27/100 [52:12<2:29:17, 122.70s/it]Evaluating gsm8k :  28%|████████████                               | 28/100 [54:14<2:26:54, 122.43s/it]Evaluating gsm8k :  29%|████████████▍                              | 29/100 [56:17<2:25:08, 122.65s/it]Evaluating gsm8k :  30%|████████████▉                              | 30/100 [58:23<2:24:15, 123.65s/it]Evaluating gsm8k :  31%|████████████▋                            | 31/100 [1:00:28<2:22:31, 123.93s/it]Evaluating gsm8k :  32%|█████████████                            | 32/100 [1:02:25<2:18:19, 122.05s/it]Evaluating gsm8k :  33%|█████████████▌                           | 33/100 [1:03:48<2:03:09, 110.30s/it]Evaluating gsm8k :  34%|█████████████▉                           | 34/100 [1:05:55<2:06:41, 115.17s/it]Evaluating gsm8k :  35%|██████████████▋                           | 35/100 [1:06:38<1:41:17, 93.51s/it]Evaluating gsm8k :  36%|██████████████▊                          | 36/100 [1:08:44<1:50:06, 103.23s/it]Evaluating gsm8k :  37%|███████████████▏                         | 37/100 [1:10:52<1:56:10, 110.65s/it]Evaluating gsm8k :  38%|███████████████▌                         | 38/100 [1:12:59<1:59:38, 115.78s/it]Evaluating gsm8k :  39%|███████████████▉                         | 39/100 [1:15:03<2:00:07, 118.15s/it]Evaluating gsm8k :  40%|████████████████▍                        | 40/100 [1:16:51<1:55:05, 115.10s/it]Evaluating gsm8k :  41%|████████████████▊                        | 41/100 [1:18:37<1:50:33, 112.44s/it]Evaluating gsm8k :  42%|█████████████████▏                       | 42/100 [1:20:16<1:44:47, 108.40s/it]Evaluating gsm8k :  43%|█████████████████▋                       | 43/100 [1:22:22<1:48:01, 113.70s/it]Evaluating gsm8k :  44%|██████████████████                       | 44/100 [1:24:26<1:49:00, 116.80s/it]Evaluating gsm8k :  45%|██████████████████▍                      | 45/100 [1:26:31<1:49:10, 119.10s/it]Evaluating gsm8k :  46%|██████████████████▊                      | 46/100 [1:28:37<1:49:04, 121.19s/it]Evaluating gsm8k :  47%|███████████████████▎                     | 47/100 [1:30:41<1:47:51, 122.11s/it]Evaluating gsm8k :  48%|███████████████████▋                     | 48/100 [1:32:48<1:47:08, 123.62s/it]Evaluating gsm8k :  49%|████████████████████                     | 49/100 [1:34:53<1:45:14, 123.81s/it]Evaluating gsm8k :  50%|████████████████████▌                    | 50/100 [1:36:58<1:43:33, 124.28s/it]Evaluating gsm8k :  51%|████████████████████▉                    | 51/100 [1:37:53<1:24:32, 103.52s/it]Evaluating gsm8k :  52%|█████████████████████▎                   | 52/100 [1:39:59<1:28:07, 110.16s/it]Evaluating gsm8k :  53%|█████████████████████▋                   | 53/100 [1:42:07<1:30:27, 115.47s/it]Evaluating gsm8k :  54%|██████████████████████▏                  | 54/100 [1:44:11<1:30:32, 118.09s/it]Evaluating gsm8k :  55%|██████████████████████▌                  | 55/100 [1:46:17<1:30:24, 120.54s/it]Evaluating gsm8k :  56%|██████████████████████▉                  | 56/100 [1:47:53<1:23:05, 113.31s/it]Evaluating gsm8k :  57%|███████████████████████▎                 | 57/100 [1:50:00<1:24:05, 117.33s/it]Evaluating gsm8k :  58%|███████████████████████▊                 | 58/100 [1:52:04<1:23:31, 119.33s/it]Evaluating gsm8k :  59%|████████████████████████▊                 | 59/100 [1:52:51<1:06:38, 97.54s/it]Evaluating gsm8k :  60%|████████████████████████▌                | 60/100 [1:54:56<1:10:31, 105.79s/it]Evaluating gsm8k :  61%|█████████████████████████                | 61/100 [1:57:02<1:12:49, 112.03s/it]Evaluating gsm8k :  62%|█████████████████████████▍               | 62/100 [1:59:06<1:13:12, 115.58s/it]Evaluating gsm8k :  63%|█████████████████████████▊               | 63/100 [2:01:14<1:13:27, 119.13s/it]Evaluating gsm8k :  64%|██████████████████████████▏              | 64/100 [2:03:18<1:12:26, 120.74s/it]Evaluating gsm8k :  65%|██████████████████████████▋              | 65/100 [2:05:24<1:11:16, 122.18s/it]Evaluating gsm8k :  66%|███████████████████████████              | 66/100 [2:07:30<1:09:55, 123.39s/it]Evaluating gsm8k :  67%|███████████████████████████▍             | 67/100 [2:09:39<1:08:52, 125.21s/it]Evaluating gsm8k :  68%|███████████████████████████▉             | 68/100 [2:11:45<1:06:45, 125.16s/it]Evaluating gsm8k :  69%|████████████████████████████▎            | 69/100 [2:13:50<1:04:42, 125.24s/it]Evaluating gsm8k :  70%|████████████████████████████▋            | 70/100 [2:15:58<1:03:01, 126.06s/it]Evaluating gsm8k :  71%|███████████████████████████████▏            | 71/100 [2:16:33<47:45, 98.83s/it]Evaluating gsm8k :  72%|███████████████████████████████▋            | 72/100 [2:17:56<43:51, 93.97s/it]Evaluating gsm8k :  73%|████████████████████████████████            | 73/100 [2:19:15<40:21, 89.68s/it]Evaluating gsm8k :  74%|███████████████████████████████▊           | 74/100 [2:21:24<43:56, 101.40s/it]Evaluating gsm8k :  75%|████████████████████████████████▎          | 75/100 [2:23:34<45:48, 109.95s/it]Evaluating gsm8k :  76%|█████████████████████████████████▍          | 76/100 [2:24:08<34:52, 87.19s/it]Evaluating gsm8k :  77%|█████████████████████████████████▉          | 77/100 [2:26:11<37:33, 97.99s/it]Evaluating gsm8k :  78%|██████████████████████████████████▎         | 78/100 [2:27:34<34:13, 93.33s/it]Evaluating gsm8k :  79%|█████████████████████████████████▉         | 79/100 [2:29:40<36:03, 103.04s/it]Evaluating gsm8k :  80%|██████████████████████████████████▍        | 80/100 [2:31:43<36:20, 109.02s/it]Evaluating gsm8k :  81%|██████████████████████████████████▊        | 81/100 [2:33:48<36:06, 114.03s/it]Evaluating gsm8k :  82%|███████████████████████████████████▎       | 82/100 [2:35:54<35:13, 117.41s/it]Evaluating gsm8k :  83%|███████████████████████████████████▋       | 83/100 [2:38:02<34:12, 120.75s/it]Evaluating gsm8k :  84%|████████████████████████████████████       | 84/100 [2:40:10<32:48, 123.01s/it]Evaluating gsm8k :  85%|████████████████████████████████████▌      | 85/100 [2:41:37<28:03, 112.20s/it]Evaluating gsm8k :  86%|████████████████████████████████████▉      | 86/100 [2:43:07<24:34, 105.31s/it]Evaluating gsm8k :  87%|█████████████████████████████████████▍     | 87/100 [2:45:16<24:23, 112.58s/it]Evaluating gsm8k :  88%|█████████████████████████████████████▊     | 88/100 [2:47:23<23:20, 116.75s/it]Evaluating gsm8k :  89%|██████████████████████████████████████▎    | 89/100 [2:49:32<22:05, 120.50s/it]Evaluating gsm8k :  90%|██████████████████████████████████████▋    | 90/100 [2:51:37<20:18, 121.86s/it]Evaluating gsm8k :  91%|███████████████████████████████████████▏   | 91/100 [2:53:41<18:22, 122.51s/it]Evaluating gsm8k :  92%|███████████████████████████████████████▌   | 92/100 [2:55:18<15:18, 114.86s/it]Evaluating gsm8k :  93%|███████████████████████████████████████▉   | 93/100 [2:57:23<13:45, 117.93s/it]Evaluating gsm8k :  94%|████████████████████████████████████████▍  | 94/100 [2:59:30<12:03, 120.60s/it]Evaluating gsm8k :  95%|████████████████████████████████████████▊  | 95/100 [3:01:32<10:05, 121.16s/it]Evaluating gsm8k :  96%|█████████████████████████████████████████▎ | 96/100 [3:03:39<08:10, 122.73s/it]Evaluating gsm8k :  97%|█████████████████████████████████████████▋ | 97/100 [3:05:45<06:11, 123.90s/it]Evaluating gsm8k :  98%|██████████████████████████████████████████▏| 98/100 [3:07:54<04:10, 125.40s/it]Evaluating gsm8k :  99%|██████████████████████████████████████████▌| 99/100 [3:09:58<02:04, 124.82s/it]Evaluating gsm8k : 100%|██████████████████████████████████████████| 100/100 [3:12:02<00:00, 124.60s/it]Evaluating gsm8k : 100%|██████████████████████████████████████████| 100/100 [3:12:02<00:00, 115.22s/it]
name: gsm8k | avg. gen lenth: 239.4 | time: 11522.839025497437s
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 12355 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o16-tcommonsenseqa-s1-rFalse --seed 1 --max-prompt-length 4096 --num-out-domain 16
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 14:20:27,909] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 2
[2023-08-30 14:20:28,418] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o16-tcommonsenseqa-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 16
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o16-tcommonsenseqa-s1-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
WARNING: /scratch/ylu130/processed_data/gsm8k/out-domain/o16-tcommonsenseqa-s1-rFalse/gsm8k.jsonl does not exist
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 97, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 87, in main
    dataset = prepare_dataset_main(args, tokenizer)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 21, in prepare_dataset_main
    return PromptDataset(args, tokenizer, args.data_dir, args.num_eval)
  File "/home/ylu130/workspace/in-context-generalization/data_utils/prompt_datasets.py", line 19, in __init__
    self.data = self.load_data_json(data_path)
  File "/home/ylu130/workspace/in-context-generalization/data_utils/prompt_datasets.py", line 36, in load_data_json
    with open(data_path) as f:
FileNotFoundError: [Errno 2] No such file or directory: '/scratch/ylu130/processed_data/gsm8k/out-domain/o16-tcommonsenseqa-s1-rFalse'
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 97, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 87, in main
    dataset = prepare_dataset_main(args, tokenizer)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 21, in prepare_dataset_main
    return PromptDataset(args, tokenizer, args.data_dir, args.num_eval)
  File "/home/ylu130/workspace/in-context-generalization/data_utils/prompt_datasets.py", line 19, in __init__
    self.data = self.load_data_json(data_path)
  File "/home/ylu130/workspace/in-context-generalization/data_utils/prompt_datasets.py", line 36, in load_data_json
    with open(data_path) as f:
FileNotFoundError: [Errno 2] No such file or directory: '/scratch/ylu130/processed_data/gsm8k/out-domain/o16-tcommonsenseqa-s1-rFalse'
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 884913) of binary: /home/ylu130/.conda/envs/ood/bin/python
Traceback (most recent call last):
  File "/home/ylu130/.conda/envs/ood/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/run.py", line 794, in main
    run(args)
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/ylu130/workspace/in-context-generalization/inference.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-08-30_14:20:31
  host      : ia1.wse.jhu.edu
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 884914)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-08-30_14:20:31
  host      : ia1.wse.jhu.edu
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 884913)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 12355 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o1-tcommonsenseqa-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 14:20:34,837] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 2
[2023-08-30 14:20:35,398] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o1-tcommonsenseqa-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 1
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o1-tcommonsenseqa-s10-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading data:   0%|                                                           | 0/7473 [00:00<?, ?it/s]Loading data: 100%|███████████████████████████████████████████| 7473/7473 [00:00<00:00, 1187723.90it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                                 | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                 | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|████████████████████▌                    | 1/2 [00:06<00:06,  6.89s/it]Loading checkpoint shards:  50%|████████████████████▌                    | 1/2 [00:06<00:06,  6.80s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  3.99s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  4.43s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  3.98s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  4.40s/it]
 > number of parameters: 6738415616
[2023-08-30 14:20:45,367] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 14:20:45,482] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 14:20:45,926] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-30 14:20:45,927] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-30 14:20:45,927] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-30 14:20:45,927] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-30 14:20:45,927] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-30 14:20:45,927] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-30 14:20:45,927] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-30 14:20:45,927] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-30 14:20:45,927] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-30 14:20:45,927] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-30 14:20:45,927] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-30 14:20:45,927] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f7095bc52a0>
[2023-08-30 14:20:45,927] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-30 14:20:45,927] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-30 14:20:45,927] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-30 14:20:45,927] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   train_batch_size ............. 2
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   world_size ................... 2
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-30 14:20:45,928] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-30 14:20:45,929] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-30 14:20:45,929] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-30 14:20:45,929] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-30 14:20:45,929] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating gsm8k :   0%|                                                       | 0/100 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following grade math question.

Input: Fabric is cut to order at what type of seller? Choices:  A: curtains B: tailor shop C: clothing store D: sewing room E: hardware store
Output: B: tailor shop

Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o1-tcommonsenseqa-s10-rFalse-m4096
Evaluating gsm8k :   1%|▍                                           | 1/100 [02:23<3:57:29, 143.93s/it]Evaluating gsm8k :   2%|▉                                           | 2/100 [03:38<2:48:24, 103.11s/it]Evaluating gsm8k :   3%|█▎                                           | 3/100 [05:03<2:33:29, 94.94s/it]Evaluating gsm8k :   4%|█▊                                          | 4/100 [07:25<3:01:49, 113.64s/it]Evaluating gsm8k :   5%|██▏                                         | 5/100 [09:46<3:15:29, 123.47s/it]Evaluating gsm8k :   6%|██▋                                         | 6/100 [12:07<3:22:44, 129.41s/it]Evaluating gsm8k :   7%|███                                         | 7/100 [14:26<3:25:06, 132.33s/it]Evaluating gsm8k :   8%|███▌                                        | 8/100 [16:47<3:27:10, 135.11s/it]Evaluating gsm8k :   9%|███▉                                        | 9/100 [19:09<3:28:32, 137.49s/it]Evaluating gsm8k :  10%|████▎                                      | 10/100 [21:33<3:29:04, 139.39s/it]Evaluating gsm8k :  11%|████▋                                      | 11/100 [23:51<3:26:02, 138.90s/it]Evaluating gsm8k :  12%|█████▏                                     | 12/100 [25:15<2:59:07, 122.13s/it]Evaluating gsm8k :  13%|█████▌                                     | 13/100 [26:51<2:45:42, 114.28s/it]Evaluating gsm8k :  14%|██████                                     | 14/100 [29:15<2:56:34, 123.19s/it]Evaluating gsm8k :  15%|██████▍                                    | 15/100 [31:34<3:01:24, 128.06s/it]Evaluating gsm8k :  16%|██████▉                                    | 16/100 [33:55<3:04:44, 131.95s/it]Evaluating gsm8k :  17%|███████▎                                   | 17/100 [35:32<2:47:48, 121.31s/it]Evaluating gsm8k :  18%|███████▋                                   | 18/100 [37:53<2:54:04, 127.37s/it]Evaluating gsm8k :  19%|████████▏                                  | 19/100 [40:16<2:58:15, 132.05s/it]Evaluating gsm8k :  20%|████████▌                                  | 20/100 [42:38<3:00:07, 135.09s/it]Evaluating gsm8k :  21%|█████████                                  | 21/100 [44:27<2:47:35, 127.29s/it]Evaluating gsm8k :  22%|█████████▍                                 | 22/100 [45:29<2:19:53, 107.61s/it]Evaluating gsm8k :  23%|█████████▉                                 | 23/100 [47:48<2:30:12, 117.04s/it]Evaluating gsm8k :  24%|██████████▎                                | 24/100 [50:09<2:37:26, 124.29s/it]Evaluating gsm8k :  25%|██████████▊                                | 25/100 [52:30<2:41:32, 129.23s/it]Evaluating gsm8k :  26%|███████████▏                               | 26/100 [54:50<2:43:21, 132.45s/it]Evaluating gsm8k :  27%|███████████▌                               | 27/100 [56:16<2:24:19, 118.63s/it]Evaluating gsm8k :  28%|████████████                               | 28/100 [58:35<2:29:27, 124.55s/it]Evaluating gsm8k :  29%|███████████▉                             | 29/100 [1:00:54<2:32:46, 129.10s/it]Evaluating gsm8k :  30%|████████████▎                            | 30/100 [1:03:12<2:33:36, 131.67s/it]Evaluating gsm8k :  31%|████████████▋                            | 31/100 [1:05:33<2:34:35, 134.43s/it]Evaluating gsm8k :  32%|█████████████                            | 32/100 [1:07:53<2:34:12, 136.07s/it]Evaluating gsm8k :  33%|█████████████▌                           | 33/100 [1:10:15<2:34:06, 138.01s/it]Evaluating gsm8k :  34%|█████████████▉                           | 34/100 [1:12:37<2:32:54, 139.01s/it]Evaluating gsm8k :  35%|██████████████▎                          | 35/100 [1:14:59<2:31:34, 139.92s/it]Evaluating gsm8k :  36%|██████████████▊                          | 36/100 [1:17:17<2:28:33, 139.28s/it]Evaluating gsm8k :  37%|███████████████▏                         | 37/100 [1:19:38<2:26:47, 139.80s/it]Evaluating gsm8k :  38%|███████████████▌                         | 38/100 [1:21:58<2:24:40, 140.00s/it]Evaluating gsm8k :  39%|███████████████▉                         | 39/100 [1:24:01<2:17:14, 134.99s/it]Evaluating gsm8k :  40%|████████████████▍                        | 40/100 [1:25:42<2:04:36, 124.61s/it]Evaluating gsm8k :  41%|█████████████████▏                        | 41/100 [1:26:23<1:37:50, 99.50s/it]Evaluating gsm8k :  42%|█████████████████▏                       | 42/100 [1:28:44<1:48:21, 112.10s/it]Evaluating gsm8k :  43%|█████████████████▋                       | 43/100 [1:31:04<1:54:20, 120.36s/it]Evaluating gsm8k :  44%|██████████████████                       | 44/100 [1:33:25<1:58:17, 126.75s/it]Evaluating gsm8k :  45%|██████████████████▍                      | 45/100 [1:35:44<1:59:34, 130.44s/it]Evaluating gsm8k :  46%|██████████████████▊                      | 46/100 [1:37:39<1:53:10, 125.76s/it]Evaluating gsm8k :  47%|███████████████████▎                     | 47/100 [1:39:59<1:54:50, 130.00s/it]Evaluating gsm8k :  48%|███████████████████▋                     | 48/100 [1:42:19<1:55:11, 132.91s/it]Evaluating gsm8k :  49%|████████████████████                     | 49/100 [1:44:28<1:52:01, 131.79s/it]Evaluating gsm8k :  50%|████████████████████▌                    | 50/100 [1:46:49<1:52:03, 134.47s/it]Evaluating gsm8k :  51%|████████████████████▉                    | 51/100 [1:49:09<1:51:09, 136.12s/it]Evaluating gsm8k :  52%|█████████████████████▎                   | 52/100 [1:51:28<1:49:39, 137.08s/it]Evaluating gsm8k :  53%|█████████████████████▋                   | 53/100 [1:51:51<1:20:37, 102.93s/it]Evaluating gsm8k :  54%|██████████████████████▏                  | 54/100 [1:54:13<1:27:52, 114.61s/it]Evaluating gsm8k :  55%|██████████████████████▌                  | 55/100 [1:56:25<1:29:47, 119.73s/it]Evaluating gsm8k :  56%|██████████████████████▉                  | 56/100 [1:58:46<1:32:34, 126.23s/it]Evaluating gsm8k :  57%|███████████████████████▎                 | 57/100 [2:00:32<1:26:07, 120.18s/it]Evaluating gsm8k :  58%|███████████████████████▊                 | 58/100 [2:02:49<1:27:33, 125.07s/it]Evaluating gsm8k :  59%|████████████████████████▏                | 59/100 [2:05:06<1:27:58, 128.74s/it]Evaluating gsm8k :  60%|████████████████████████▌                | 60/100 [2:07:28<1:28:32, 132.80s/it]Evaluating gsm8k :  61%|█████████████████████████                | 61/100 [2:08:44<1:15:08, 115.61s/it]Evaluating gsm8k :  62%|█████████████████████████▍               | 62/100 [2:11:03<1:17:43, 122.72s/it]Evaluating gsm8k :  63%|█████████████████████████▊               | 63/100 [2:13:26<1:19:23, 128.75s/it]Evaluating gsm8k :  64%|██████████████████████████▏              | 64/100 [2:15:45<1:19:01, 131.70s/it]Evaluating gsm8k :  65%|██████████████████████████▋              | 65/100 [2:18:04<1:18:06, 133.91s/it]Evaluating gsm8k :  66%|███████████████████████████              | 66/100 [2:20:24<1:16:55, 135.76s/it]Evaluating gsm8k :  67%|███████████████████████████▍             | 67/100 [2:22:28<1:12:44, 132.25s/it]Evaluating gsm8k :  68%|███████████████████████████▉             | 68/100 [2:24:48<1:11:45, 134.53s/it]Evaluating gsm8k :  69%|████████████████████████████▎            | 69/100 [2:27:10<1:10:41, 136.84s/it]Evaluating gsm8k :  70%|████████████████████████████▋            | 70/100 [2:29:32<1:09:14, 138.49s/it]Evaluating gsm8k :  71%|█████████████████████████████            | 71/100 [2:31:21<1:02:36, 129.54s/it]Evaluating gsm8k :  72%|█████████████████████████████▌           | 72/100 [2:33:41<1:01:58, 132.82s/it]Evaluating gsm8k :  73%|███████████████████████████████▍           | 73/100 [2:34:32<48:43, 108.27s/it]Evaluating gsm8k :  74%|███████████████████████████████▊           | 74/100 [2:36:55<51:25, 118.68s/it]Evaluating gsm8k :  75%|████████████████████████████████▎          | 75/100 [2:39:18<52:26, 125.87s/it]Evaluating gsm8k :  76%|████████████████████████████████▋          | 76/100 [2:41:39<52:11, 130.48s/it]Evaluating gsm8k :  77%|█████████████████████████████████          | 77/100 [2:44:01<51:20, 133.93s/it]Evaluating gsm8k :  78%|█████████████████████████████████▌         | 78/100 [2:46:21<49:45, 135.72s/it]Evaluating gsm8k :  79%|█████████████████████████████████▉         | 79/100 [2:47:14<38:50, 110.97s/it]Evaluating gsm8k :  80%|██████████████████████████████████▍        | 80/100 [2:49:18<38:18, 114.90s/it]Evaluating gsm8k :  81%|██████████████████████████████████▊        | 81/100 [2:51:38<38:42, 122.21s/it]Evaluating gsm8k :  82%|███████████████████████████████████▎       | 82/100 [2:53:57<38:11, 127.31s/it]Evaluating gsm8k :  83%|███████████████████████████████████▋       | 83/100 [2:56:15<37:01, 130.68s/it]Evaluating gsm8k :  84%|████████████████████████████████████       | 84/100 [2:57:43<31:23, 117.73s/it]Evaluating gsm8k :  85%|████████████████████████████████████▌      | 85/100 [3:00:01<30:56, 123.76s/it]Evaluating gsm8k :  86%|████████████████████████████████████▉      | 86/100 [3:02:22<30:04, 128.88s/it]Evaluating gsm8k :  87%|█████████████████████████████████████▍     | 87/100 [3:04:42<28:41, 132.45s/it]Evaluating gsm8k :  88%|█████████████████████████████████████▊     | 88/100 [3:07:01<26:51, 134.28s/it]Evaluating gsm8k :  89%|██████████████████████████████████████▎    | 89/100 [3:09:23<25:03, 136.68s/it]Evaluating gsm8k :  90%|██████████████████████████████████████▋    | 90/100 [3:11:44<22:59, 137.93s/it]Evaluating gsm8k :  91%|███████████████████████████████████████▏   | 91/100 [3:13:33<19:22, 129.21s/it]Evaluating gsm8k :  92%|███████████████████████████████████████▌   | 92/100 [3:15:54<17:42, 132.76s/it]Evaluating gsm8k :  93%|███████████████████████████████████████▉   | 93/100 [3:18:14<15:45, 135.03s/it]Evaluating gsm8k :  94%|████████████████████████████████████████▍  | 94/100 [3:20:30<13:31, 135.22s/it]Evaluating gsm8k :  95%|████████████████████████████████████████▊  | 95/100 [3:22:52<11:25, 137.14s/it]Evaluating gsm8k :  96%|█████████████████████████████████████████▎ | 96/100 [3:25:14<09:14, 138.74s/it]Evaluating gsm8k :  97%|█████████████████████████████████████████▋ | 97/100 [3:27:38<07:00, 140.19s/it]Evaluating gsm8k :  98%|██████████████████████████████████████████▏| 98/100 [3:30:01<04:42, 141.04s/it]Evaluating gsm8k :  99%|██████████████████████████████████████████▌| 99/100 [3:31:53<02:12, 132.52s/it]Evaluating gsm8k : 100%|██████████████████████████████████████████| 100/100 [3:34:01<00:00, 131.08s/it]Evaluating gsm8k : 100%|██████████████████████████████████████████| 100/100 [3:34:01<00:00, 128.41s/it]
name: gsm8k | avg. gen lenth: 243.364 | time: 12841.9228682518s
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 12355 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o2-tcommonsenseqa-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 2
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 17:54:55,897] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-30 17:54:55,920] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 2
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o2-tcommonsenseqa-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 2
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o2-tcommonsenseqa-s10-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading data:   0%|                                                           | 0/7473 [00:00<?, ?it/s]Loading data: 100%|███████████████████████████████████████████| 7473/7473 [00:00<00:00, 1115128.57it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                                 | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                 | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|████████████████████▌                    | 1/2 [00:06<00:06,  6.77s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  3.90s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  4.33s/it]
[2023-08-30 17:55:05,787] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards:  50%|████████████████████▌                    | 1/2 [00:11<00:11, 11.53s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:13<00:00,  5.99s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:13<00:00,  6.82s/it]
 > number of parameters: 6738415616
[2023-08-30 17:55:10,741] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 17:55:11,186] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-30 17:55:11,187] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-30 17:55:11,188] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-30 17:55:11,188] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-30 17:55:11,188] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-30 17:55:11,188] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-30 17:55:11,188] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-30 17:55:11,188] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-30 17:55:11,188] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-30 17:55:11,188] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-30 17:55:11,188] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-30 17:55:11,188] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f094c4c92d0>
[2023-08-30 17:55:11,188] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-30 17:55:11,188] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-30 17:55:11,188] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-30 17:55:11,188] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-30 17:55:11,188] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-30 17:55:11,188] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-30 17:55:11,188] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-30 17:55:11,188] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-30 17:55:11,188] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-30 17:55:11,188] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-30 17:55:11,188] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-30 17:55:11,188] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-30 17:55:11,188] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-30 17:55:11,188] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-30 17:55:11,188] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-30 17:55:11,188] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-30 17:55:11,188] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-30 17:55:11,188] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   train_batch_size ............. 2
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   world_size ................... 2
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-30 17:55:11,189] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-30 17:55:11,189] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating gsm8k :   0%|                                                       | 0/100 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following grade math question.

Input: Fabric is cut to order at what type of seller? Choices:  A: curtains B: tailor shop C: clothing store D: sewing room E: hardware store
Output: B: tailor shop

Input: Where are you if your reading magazines while waiting for a vehicle on rails? Choices:  A: vegetables B: market C: doctor D: train station E: bookstore
Output: D: train station

Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o2-tcommonsenseqa-s10-rFalse-m4096
Evaluating gsm8k :   1%|▍                                           | 1/100 [02:22<3:54:50, 142.33s/it]Evaluating gsm8k :   2%|▉                                           | 2/100 [04:00<3:10:19, 116.53s/it]Evaluating gsm8k :   3%|█▎                                          | 3/100 [06:21<3:26:20, 127.64s/it]Evaluating gsm8k :   4%|█▊                                          | 4/100 [08:42<3:32:31, 132.83s/it]Evaluating gsm8k :   5%|██▏                                         | 5/100 [11:01<3:33:54, 135.10s/it]Evaluating gsm8k :   6%|██▋                                         | 6/100 [12:28<3:06:12, 118.86s/it]Evaluating gsm8k :   7%|███                                         | 7/100 [14:48<3:14:46, 125.66s/it]Evaluating gsm8k :   8%|███▌                                         | 8/100 [15:26<2:30:00, 97.83s/it]Evaluating gsm8k :   9%|███▉                                        | 9/100 [17:48<2:49:12, 111.56s/it]Evaluating gsm8k :  10%|████▍                                       | 10/100 [18:56<2:26:57, 97.97s/it]Evaluating gsm8k :  11%|████▊                                       | 11/100 [20:03<2:11:13, 88.46s/it]Evaluating gsm8k :  12%|█████▎                                      | 12/100 [21:48<2:17:32, 93.77s/it]Evaluating gsm8k :  13%|█████▌                                     | 13/100 [24:09<2:36:41, 108.06s/it]Evaluating gsm8k :  14%|██████                                     | 14/100 [25:53<2:33:10, 106.87s/it]Evaluating gsm8k :  15%|██████▍                                    | 15/100 [27:38<2:30:25, 106.18s/it]Evaluating gsm8k :  16%|██████▉                                    | 16/100 [29:56<2:42:09, 115.82s/it]Evaluating gsm8k :  17%|███████▎                                   | 17/100 [31:14<2:24:30, 104.46s/it]Evaluating gsm8k :  18%|███████▋                                   | 18/100 [33:33<2:36:59, 114.87s/it]Evaluating gsm8k :  19%|████████▏                                  | 19/100 [35:37<2:38:45, 117.59s/it]Evaluating gsm8k :  20%|████████▌                                  | 20/100 [37:55<2:44:44, 123.55s/it]Evaluating gsm8k :  21%|█████████                                  | 21/100 [40:12<2:48:07, 127.69s/it]Evaluating gsm8k :  22%|█████████▍                                 | 22/100 [42:29<2:49:38, 130.50s/it]Evaluating gsm8k :  23%|█████████▉                                 | 23/100 [44:48<2:50:32, 132.89s/it]Evaluating gsm8k :  24%|██████████▎                                | 24/100 [47:08<2:50:59, 134.99s/it]Evaluating gsm8k :  25%|██████████▊                                | 25/100 [49:26<2:49:59, 135.99s/it]Evaluating gsm8k :  26%|███████████▏                               | 26/100 [51:37<2:45:55, 134.54s/it]Evaluating gsm8k :  27%|███████████▌                               | 27/100 [53:54<2:44:43, 135.39s/it]Evaluating gsm8k :  28%|████████████                               | 28/100 [55:35<2:29:53, 124.90s/it]Evaluating gsm8k :  29%|████████████▍                              | 29/100 [57:39<2:27:32, 124.69s/it]Evaluating gsm8k :  30%|████████████▉                              | 30/100 [58:29<1:59:12, 102.18s/it]Evaluating gsm8k :  31%|████████████▋                            | 31/100 [1:00:22<2:01:30, 105.67s/it]Evaluating gsm8k :  32%|█████████████                            | 32/100 [1:02:40<2:10:42, 115.33s/it]Evaluating gsm8k :  33%|█████████████▌                           | 33/100 [1:04:55<2:15:19, 121.19s/it]Evaluating gsm8k :  34%|█████████████▉                           | 34/100 [1:07:11<2:17:58, 125.43s/it]Evaluating gsm8k :  35%|██████████████▎                          | 35/100 [1:09:29<2:20:12, 129.42s/it]Evaluating gsm8k :  36%|██████████████▊                          | 36/100 [1:11:44<2:19:49, 131.08s/it]Evaluating gsm8k :  37%|███████████████▏                         | 37/100 [1:14:00<2:19:04, 132.46s/it]Evaluating gsm8k :  38%|███████████████▌                         | 38/100 [1:16:21<2:19:28, 134.98s/it]Evaluating gsm8k :  39%|███████████████▉                         | 39/100 [1:17:42<2:00:49, 118.85s/it]Evaluating gsm8k :  40%|████████████████▍                        | 40/100 [1:19:59<2:04:24, 124.40s/it]Evaluating gsm8k :  41%|████████████████▊                        | 41/100 [1:22:16<2:06:00, 128.14s/it]Evaluating gsm8k :  42%|█████████████████▏                       | 42/100 [1:24:34<2:06:37, 130.99s/it]Evaluating gsm8k :  43%|█████████████████▋                       | 43/100 [1:26:51<2:06:20, 132.99s/it]Evaluating gsm8k :  44%|██████████████████                       | 44/100 [1:28:12<1:49:20, 117.16s/it]Evaluating gsm8k :  45%|██████████████████▍                      | 45/100 [1:30:29<1:52:56, 123.21s/it]Evaluating gsm8k :  46%|██████████████████▊                      | 46/100 [1:32:48<1:55:08, 127.94s/it]Evaluating gsm8k :  47%|███████████████████▎                     | 47/100 [1:33:56<1:37:14, 110.09s/it]Evaluating gsm8k :  48%|███████████████████▋                     | 48/100 [1:36:14<1:42:33, 118.34s/it]Evaluating gsm8k :  49%|████████████████████                     | 49/100 [1:38:35<1:46:21, 125.12s/it]Evaluating gsm8k :  50%|████████████████████▌                    | 50/100 [1:40:53<1:47:26, 128.93s/it]Evaluating gsm8k :  51%|████████████████████▉                    | 51/100 [1:42:53<1:43:11, 126.36s/it]Evaluating gsm8k :  52%|█████████████████████▎                   | 52/100 [1:45:10<1:43:39, 129.58s/it]Evaluating gsm8k :  53%|█████████████████████▋                   | 53/100 [1:46:58<1:36:20, 122.99s/it]Evaluating gsm8k :  54%|██████████████████████▏                  | 54/100 [1:49:15<1:37:32, 127.23s/it]Evaluating gsm8k :  55%|██████████████████████▌                  | 55/100 [1:51:34<1:38:02, 130.71s/it]Evaluating gsm8k :  56%|██████████████████████▉                  | 56/100 [1:53:56<1:38:22, 134.15s/it]Evaluating gsm8k :  57%|███████████████████████▎                 | 57/100 [1:56:12<1:36:29, 134.63s/it]Evaluating gsm8k :  58%|███████████████████████▊                 | 58/100 [1:58:29<1:34:43, 135.31s/it]Evaluating gsm8k :  59%|████████████████████████▏                | 59/100 [1:59:57<1:22:51, 121.25s/it]Evaluating gsm8k :  60%|████████████████████████▌                | 60/100 [2:02:15<1:24:07, 126.18s/it]Evaluating gsm8k :  61%|█████████████████████████                | 61/100 [2:03:43<1:14:33, 114.71s/it]Evaluating gsm8k :  62%|█████████████████████████▍               | 62/100 [2:06:02<1:17:17, 122.03s/it]Evaluating gsm8k :  63%|███████████████████████████▋                | 63/100 [2:06:38<59:19, 96.20s/it]Evaluating gsm8k :  64%|██████████████████████████▏              | 64/100 [2:08:55<1:05:02, 108.40s/it]Evaluating gsm8k :  65%|██████████████████████████▋              | 65/100 [2:11:14<1:08:39, 117.70s/it]Evaluating gsm8k :  66%|███████████████████████████              | 66/100 [2:13:34<1:10:27, 124.34s/it]Evaluating gsm8k :  67%|███████████████████████████▍             | 67/100 [2:15:27<1:06:35, 121.06s/it]Evaluating gsm8k :  68%|███████████████████████████▉             | 68/100 [2:17:44<1:07:05, 125.79s/it]Evaluating gsm8k :  69%|████████████████████████████▎            | 69/100 [2:20:01<1:06:46, 129.24s/it]Evaluating gsm8k :  70%|████████████████████████████▋            | 70/100 [2:22:15<1:05:13, 130.46s/it]Evaluating gsm8k :  71%|█████████████████████████████            | 71/100 [2:24:35<1:04:28, 133.39s/it]Evaluating gsm8k :  72%|█████████████████████████████▌           | 72/100 [2:26:54<1:03:01, 135.05s/it]Evaluating gsm8k :  73%|███████████████████████████████▍           | 73/100 [2:28:56<59:04, 131.27s/it]Evaluating gsm8k :  74%|███████████████████████████████▊           | 74/100 [2:31:15<57:52, 133.57s/it]Evaluating gsm8k :  75%|████████████████████████████████▎          | 75/100 [2:33:00<52:04, 125.00s/it]Evaluating gsm8k :  76%|████████████████████████████████▋          | 76/100 [2:35:19<51:40, 129.20s/it]Evaluating gsm8k :  77%|█████████████████████████████████          | 77/100 [2:37:38<50:36, 132.04s/it]Evaluating gsm8k :  78%|█████████████████████████████████▌         | 78/100 [2:39:54<48:51, 133.23s/it]Evaluating gsm8k :  79%|█████████████████████████████████▉         | 79/100 [2:42:11<47:04, 134.48s/it]Evaluating gsm8k :  80%|██████████████████████████████████▍        | 80/100 [2:44:31<45:22, 136.13s/it]Evaluating gsm8k :  81%|██████████████████████████████████▊        | 81/100 [2:44:59<32:48, 103.63s/it]Evaluating gsm8k :  82%|███████████████████████████████████▎       | 82/100 [2:47:15<33:57, 113.21s/it]Evaluating gsm8k :  83%|███████████████████████████████████▋       | 83/100 [2:49:32<34:07, 120.45s/it]Evaluating gsm8k :  84%|████████████████████████████████████       | 84/100 [2:51:53<33:45, 126.59s/it]Evaluating gsm8k :  85%|████████████████████████████████████▌      | 85/100 [2:54:10<32:26, 129.77s/it]Evaluating gsm8k :  86%|████████████████████████████████████▉      | 86/100 [2:56:28<30:51, 132.26s/it]Evaluating gsm8k :  87%|█████████████████████████████████████▍     | 87/100 [2:58:49<29:11, 134.76s/it]Evaluating gsm8k :  88%|█████████████████████████████████████▊     | 88/100 [2:59:31<21:23, 106.97s/it]Evaluating gsm8k :  89%|██████████████████████████████████████▎    | 89/100 [3:01:31<20:20, 110.92s/it]Evaluating gsm8k :  90%|██████████████████████████████████████▋    | 90/100 [3:03:46<19:42, 118.20s/it]Evaluating gsm8k :  91%|███████████████████████████████████████▏   | 91/100 [3:06:06<18:42, 124.70s/it]Evaluating gsm8k :  92%|███████████████████████████████████████▌   | 92/100 [3:08:24<17:09, 128.69s/it]Evaluating gsm8k :  93%|███████████████████████████████████████▉   | 93/100 [3:10:43<15:21, 131.62s/it]Evaluating gsm8k :  94%|████████████████████████████████████████▍  | 94/100 [3:12:00<11:32, 115.36s/it]Evaluating gsm8k :  95%|████████████████████████████████████████▊  | 95/100 [3:14:17<10:09, 121.92s/it]Evaluating gsm8k :  96%|█████████████████████████████████████████▎ | 96/100 [3:16:38<08:30, 127.72s/it]Evaluating gsm8k :  97%|█████████████████████████████████████████▋ | 97/100 [3:18:58<06:33, 131.15s/it]Evaluating gsm8k :  98%|██████████████████████████████████████████▏| 98/100 [3:20:20<03:53, 116.57s/it]Evaluating gsm8k :  99%|██████████████████████████████████████████▌| 99/100 [3:22:37<02:02, 122.57s/it]Evaluating gsm8k : 100%|██████████████████████████████████████████| 100/100 [3:24:55<00:00, 127.17s/it]Evaluating gsm8k : 100%|██████████████████████████████████████████| 100/100 [3:24:55<00:00, 122.95s/it]
name: gsm8k | avg. gen lenth: 222.75 | time: 12295.547491073608s
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 12355 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o4-tcommonsenseqa-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 4
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-30 21:22:30,699] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 2
[2023-08-30 21:22:31,201] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o4-tcommonsenseqa-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 4
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o4-tcommonsenseqa-s10-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading data:   0%|                                                           | 0/7473 [00:00<?, ?it/s]Loading data: 100%|████████████████████████████████████████████| 7473/7473 [00:00<00:00, 978034.00it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                                 | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                 | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|████████████████████▌                    | 1/2 [00:06<00:06,  6.74s/it]Loading checkpoint shards:  50%|████████████████████▌                    | 1/2 [00:06<00:06,  6.82s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  3.98s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  4.39s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  3.99s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  4.41s/it]
 > number of parameters: 6738415616
[2023-08-30 21:22:41,068] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 21:22:41,089] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-30 21:22:41,534] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-30 21:22:41,536] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-30 21:22:41,536] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-30 21:22:41,536] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-30 21:22:41,536] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-30 21:22:41,536] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-30 21:22:41,536] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-30 21:22:41,536] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-30 21:22:41,536] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-30 21:22:41,536] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-30 21:22:41,536] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-30 21:22:41,536] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f4cbd8bd2d0>
[2023-08-30 21:22:41,536] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-30 21:22:41,536] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-30 21:22:41,536] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-30 21:22:41,536] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-30 21:22:41,536] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-30 21:22:41,536] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-30 21:22:41,536] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-30 21:22:41,536] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-30 21:22:41,536] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-30 21:22:41,536] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-30 21:22:41,536] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-30 21:22:41,536] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-30 21:22:41,536] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-30 21:22:41,536] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-30 21:22:41,536] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-30 21:22:41,536] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   train_batch_size ............. 2
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   world_size ................... 2
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-30 21:22:41,537] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-30 21:22:41,537] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating gsm8k :   0%|                                                       | 0/100 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following grade math question.

Input: Fabric is cut to order at what type of seller? Choices:  A: curtains B: tailor shop C: clothing store D: sewing room E: hardware store
Output: B: tailor shop

Input: Where are you if your reading magazines while waiting for a vehicle on rails? Choices:  A: vegetables B: market C: doctor D: train station E: bookstore
Output: D: train station

Input: What would need oil to be used? Choices:  A: ground B: human  body C: repair shop D: combustion engines E: service station
Output: D: combustion engines

Input: What is person probably feeling that plans on stopping being married to their spouse? Choices:  A: detachment B: bankruptcy C: sad D: fights E: wrong
Output: A: detachment

Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o4-tcommonsenseqa-s10-rFalse-m4096
Evaluating gsm8k :   1%|▍                                           | 1/100 [02:15<3:43:19, 135.34s/it]Evaluating gsm8k :   2%|▉                                            | 2/100 [02:51<2:05:59, 77.14s/it]Evaluating gsm8k :   3%|█▎                                          | 3/100 [05:06<2:47:27, 103.58s/it]Evaluating gsm8k :   4%|█▊                                          | 4/100 [07:19<3:04:16, 115.17s/it]Evaluating gsm8k :   5%|██▏                                         | 5/100 [09:08<2:58:26, 112.70s/it]Evaluating gsm8k :   6%|██▋                                         | 6/100 [11:21<3:07:33, 119.72s/it]Evaluating gsm8k :   7%|███                                         | 7/100 [13:37<3:13:56, 125.12s/it]Evaluating gsm8k :   8%|███▌                                        | 8/100 [15:51<3:15:57, 127.80s/it]Evaluating gsm8k :   9%|███▉                                        | 9/100 [18:05<3:16:50, 129.78s/it]Evaluating gsm8k :  10%|████▎                                      | 10/100 [20:19<3:16:47, 131.20s/it]Evaluating gsm8k :  11%|████▋                                      | 11/100 [22:37<3:17:25, 133.09s/it]Evaluating gsm8k :  12%|█████▏                                     | 12/100 [23:48<2:47:47, 114.41s/it]Evaluating gsm8k :  13%|█████▌                                     | 13/100 [25:21<2:36:23, 107.86s/it]Evaluating gsm8k :  14%|██████                                     | 14/100 [27:36<2:46:25, 116.10s/it]Evaluating gsm8k :  15%|██████▍                                    | 15/100 [29:52<2:52:55, 122.06s/it]Evaluating gsm8k :  16%|██████▉                                    | 16/100 [32:07<2:56:21, 125.98s/it]Evaluating gsm8k :  17%|███████▎                                   | 17/100 [33:39<2:40:10, 115.79s/it]Evaluating gsm8k :  18%|███████▋                                   | 18/100 [35:55<2:46:20, 121.72s/it]Evaluating gsm8k :  19%|████████▏                                  | 19/100 [36:49<2:17:06, 101.56s/it]Evaluating gsm8k :  20%|████████▌                                  | 20/100 [38:34<2:16:32, 102.40s/it]Evaluating gsm8k :  21%|█████████▏                                  | 21/100 [39:26<1:55:11, 87.49s/it]Evaluating gsm8k :  22%|█████████▍                                 | 22/100 [41:41<2:11:56, 101.49s/it]Evaluating gsm8k :  23%|█████████▉                                 | 23/100 [43:58<2:24:04, 112.27s/it]Evaluating gsm8k :  24%|██████████▎                                | 24/100 [46:12<2:30:28, 118.79s/it]Evaluating gsm8k :  25%|██████████▊                                | 25/100 [47:45<2:18:52, 111.10s/it]Evaluating gsm8k :  26%|███████████▏                               | 26/100 [49:23<2:11:58, 107.01s/it]Evaluating gsm8k :  27%|███████████▉                                | 27/100 [50:27<1:54:42, 94.29s/it]Evaluating gsm8k :  28%|████████████                               | 28/100 [52:42<2:07:47, 106.49s/it]Evaluating gsm8k :  29%|████████████▍                              | 29/100 [54:57<2:16:11, 115.10s/it]Evaluating gsm8k :  30%|████████████▉                              | 30/100 [57:12<2:21:08, 120.97s/it]Evaluating gsm8k :  31%|█████████████▎                             | 31/100 [58:04<1:55:27, 100.39s/it]Evaluating gsm8k :  32%|█████████████                            | 32/100 [1:00:21<2:06:08, 111.30s/it]Evaluating gsm8k :  33%|█████████████▌                           | 33/100 [1:02:33<2:11:01, 117.33s/it]Evaluating gsm8k :  34%|█████████████▉                           | 34/100 [1:04:50<2:15:37, 123.30s/it]Evaluating gsm8k :  35%|██████████████▎                          | 35/100 [1:07:06<2:17:52, 127.27s/it]Evaluating gsm8k :  36%|██████████████▊                          | 36/100 [1:08:42<2:05:33, 117.72s/it]Evaluating gsm8k :  37%|███████████████▏                         | 37/100 [1:10:57<2:09:11, 123.04s/it]Evaluating gsm8k :  38%|███████████████▌                         | 38/100 [1:13:11<2:10:25, 126.22s/it]Evaluating gsm8k :  39%|███████████████▉                         | 39/100 [1:15:23<2:10:13, 128.09s/it]Evaluating gsm8k :  40%|████████████████▍                        | 40/100 [1:17:38<2:10:09, 130.15s/it]Evaluating gsm8k :  41%|████████████████▊                        | 41/100 [1:19:49<2:08:10, 130.35s/it]Evaluating gsm8k :  42%|█████████████████▏                       | 42/100 [1:22:01<2:06:36, 130.97s/it]Evaluating gsm8k :  43%|█████████████████▋                       | 43/100 [1:24:16<2:05:26, 132.05s/it]Evaluating gsm8k :  44%|██████████████████                       | 44/100 [1:26:31<2:04:06, 132.98s/it]Evaluating gsm8k :  45%|██████████████████▍                      | 45/100 [1:28:43<2:01:39, 132.72s/it]Evaluating gsm8k :  46%|██████████████████▊                      | 46/100 [1:30:44<1:56:05, 129.00s/it]Evaluating gsm8k :  47%|███████████████████▎                     | 47/100 [1:32:59<1:55:33, 130.83s/it]Evaluating gsm8k :  48%|███████████████████▋                     | 48/100 [1:35:12<1:54:03, 131.61s/it]Evaluating gsm8k :  49%|████████████████████                     | 49/100 [1:37:26<1:52:32, 132.40s/it]Evaluating gsm8k :  50%|████████████████████▌                    | 50/100 [1:39:38<1:50:02, 132.05s/it]Evaluating gsm8k :  51%|████████████████████▉                    | 51/100 [1:41:55<1:49:10, 133.69s/it]Evaluating gsm8k :  52%|█████████████████████▎                   | 52/100 [1:44:09<1:47:03, 133.83s/it]Evaluating gsm8k :  53%|█████████████████████▋                   | 53/100 [1:45:35<1:33:28, 119.32s/it]Evaluating gsm8k :  54%|██████████████████████▏                  | 54/100 [1:47:51<1:35:16, 124.26s/it]Evaluating gsm8k :  55%|██████████████████████▌                  | 55/100 [1:49:32<1:28:00, 117.35s/it]Evaluating gsm8k :  56%|██████████████████████▉                  | 56/100 [1:50:43<1:15:55, 103.53s/it]Evaluating gsm8k :  57%|███████████████████████▎                 | 57/100 [1:52:58<1:20:59, 113.01s/it]Evaluating gsm8k :  58%|█████████████████████████▌                  | 58/100 [1:53:11<57:59, 82.85s/it]Evaluating gsm8k :  59%|████████████████████████▊                 | 59/100 [1:55:26<1:07:17, 98.49s/it]Evaluating gsm8k :  60%|██████████████████████████▍                 | 60/100 [1:56:33<59:24, 89.12s/it]Evaluating gsm8k :  61%|█████████████████████████                | 61/100 [1:58:49<1:07:08, 103.29s/it]Evaluating gsm8k :  62%|██████████████████████████                | 62/100 [2:00:10<1:01:05, 96.45s/it]Evaluating gsm8k :  63%|█████████████████████████▊               | 63/100 [2:02:26<1:06:54, 108.51s/it]Evaluating gsm8k :  64%|██████████████████████████▏              | 64/100 [2:04:42<1:09:59, 116.66s/it]Evaluating gsm8k :  65%|███████████████████████████▉               | 65/100 [2:05:48<59:13, 101.54s/it]Evaluating gsm8k :  66%|████████████████████████████▍              | 66/100 [2:07:44<59:57, 105.80s/it]Evaluating gsm8k :  67%|███████████████████████████▍             | 67/100 [2:09:45<1:00:37, 110.24s/it]Evaluating gsm8k :  68%|███████████████████████████▉             | 68/100 [2:11:59<1:02:43, 117.60s/it]Evaluating gsm8k :  69%|█████████████████████████████▋             | 69/100 [2:13:51<59:47, 115.72s/it]Evaluating gsm8k :  70%|████████████████████████████▋            | 70/100 [2:16:04<1:00:31, 121.06s/it]Evaluating gsm8k :  71%|██████████████████████████████▌            | 71/100 [2:17:13<50:53, 105.29s/it]Evaluating gsm8k :  72%|██████████████████████████████▉            | 72/100 [2:18:53<48:29, 103.91s/it]Evaluating gsm8k :  73%|███████████████████████████████▍           | 73/100 [2:21:10<51:11, 113.76s/it]Evaluating gsm8k :  74%|███████████████████████████████▊           | 74/100 [2:23:22<51:42, 119.31s/it]Evaluating gsm8k :  75%|████████████████████████████████▎          | 75/100 [2:25:38<51:42, 124.09s/it]Evaluating gsm8k :  76%|████████████████████████████████▋          | 76/100 [2:27:50<50:35, 126.49s/it]Evaluating gsm8k :  77%|█████████████████████████████████          | 77/100 [2:28:30<38:34, 100.62s/it]Evaluating gsm8k :  78%|██████████████████████████████████▎         | 78/100 [2:29:33<32:47, 89.42s/it]Evaluating gsm8k :  79%|██████████████████████████████████▊         | 79/100 [2:30:34<28:14, 80.69s/it]Evaluating gsm8k :  80%|███████████████████████████████████▏        | 80/100 [2:32:49<32:18, 96.93s/it]Evaluating gsm8k :  81%|██████████████████████████████████▊        | 81/100 [2:35:02<34:07, 107.79s/it]Evaluating gsm8k :  82%|███████████████████████████████████▎       | 82/100 [2:36:51<32:26, 108.14s/it]Evaluating gsm8k :  83%|███████████████████████████████████▋       | 83/100 [2:39:06<32:57, 116.34s/it]Evaluating gsm8k :  84%|████████████████████████████████████       | 84/100 [2:41:22<32:34, 122.18s/it]Evaluating gsm8k :  85%|████████████████████████████████████▌      | 85/100 [2:43:30<30:58, 123.92s/it]Evaluating gsm8k :  86%|████████████████████████████████████▉      | 86/100 [2:45:45<29:40, 127.19s/it]Evaluating gsm8k :  87%|█████████████████████████████████████▍     | 87/100 [2:47:27<25:55, 119.68s/it]Evaluating gsm8k :  88%|█████████████████████████████████████▊     | 88/100 [2:49:41<24:48, 124.08s/it]Evaluating gsm8k :  89%|██████████████████████████████████████▎    | 89/100 [2:50:40<19:09, 104.53s/it]Evaluating gsm8k :  90%|██████████████████████████████████████▋    | 90/100 [2:52:57<19:03, 114.31s/it]Evaluating gsm8k :  91%|███████████████████████████████████████▏   | 91/100 [2:55:11<18:02, 120.24s/it]Evaluating gsm8k :  92%|████████████████████████████████████████▍   | 92/100 [2:56:03<13:18, 99.76s/it]Evaluating gsm8k :  93%|███████████████████████████████████████▉   | 93/100 [2:58:16<12:48, 109.78s/it]Evaluating gsm8k :  94%|████████████████████████████████████████▍  | 94/100 [3:00:32<11:45, 117.59s/it]Evaluating gsm8k :  95%|████████████████████████████████████████▊  | 95/100 [3:02:49<10:16, 123.29s/it]Evaluating gsm8k :  96%|█████████████████████████████████████████▎ | 96/100 [3:05:03<08:26, 126.56s/it]Evaluating gsm8k :  97%|█████████████████████████████████████████▋ | 97/100 [3:07:18<06:27, 129.03s/it]Evaluating gsm8k :  98%|██████████████████████████████████████████▏| 98/100 [3:09:36<04:23, 131.64s/it]Evaluating gsm8k :  99%|██████████████████████████████████████████▌| 99/100 [3:11:50<02:12, 132.40s/it]Evaluating gsm8k : 100%|██████████████████████████████████████████| 100/100 [3:12:49<00:00, 110.59s/it]Evaluating gsm8k : 100%|██████████████████████████████████████████| 100/100 [3:12:49<00:00, 115.70s/it]
name: gsm8k | avg. gen lenth: 204.42 | time: 11570.340865135193s
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 12355 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o8-tcommonsenseqa-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 8
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-31 00:35:40,602] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 00:35:40,617] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 2
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o8-tcommonsenseqa-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 8
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o8-tcommonsenseqa-s10-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading data:   0%|                                                           | 0/7473 [00:00<?, ?it/s]Loading data: 100%|████████████████████████████████████████████| 7473/7473 [00:00<00:00, 820739.30it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                                 | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                 | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|████████████████████▌                    | 1/2 [00:06<00:06,  6.65s/it]Loading checkpoint shards:  50%|████████████████████▌                    | 1/2 [00:06<00:06,  6.81s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  3.95s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  4.35s/it]
[2023-08-31 00:35:50,520] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  4.01s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  4.43s/it]
 > number of parameters: 6738415616
[2023-08-31 00:35:50,731] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 00:35:51,279] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-31 00:35:51,281] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-31 00:35:51,281] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-31 00:35:51,281] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-31 00:35:51,281] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-31 00:35:51,281] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-31 00:35:51,281] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fe3dc1c5300>
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-31 00:35:51,282] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-31 00:35:51,283] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-31 00:35:51,283] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-31 00:35:51,283] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-31 00:35:51,283] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-31 00:35:51,283] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-31 00:35:51,283] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-31 00:35:51,283] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-31 00:35:51,283] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-31 00:35:51,283] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-31 00:35:51,283] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-31 00:35:51,283] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-31 00:35:51,283] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-31 00:35:51,283] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-31 00:35:51,283] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-31 00:35:51,283] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-31 00:35:51,283] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-31 00:35:51,283] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-31 00:35:51,283] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-31 00:35:51,283] [INFO] [config.py:964:print]   train_batch_size ............. 2
[2023-08-31 00:35:51,283] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-31 00:35:51,283] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-31 00:35:51,283] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-31 00:35:51,283] [INFO] [config.py:964:print]   world_size ................... 2
[2023-08-31 00:35:51,283] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-31 00:35:51,283] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-31 00:35:51,283] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-31 00:35:51,283] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-31 00:35:51,283] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-31 00:35:51,283] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating gsm8k :   0%|                                                       | 0/100 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following grade math question.

Input: Fabric is cut to order at what type of seller? Choices:  A: curtains B: tailor shop C: clothing store D: sewing room E: hardware store
Output: B: tailor shop

Input: Where are you if your reading magazines while waiting for a vehicle on rails? Choices:  A: vegetables B: market C: doctor D: train station E: bookstore
Output: D: train station

Input: What would need oil to be used? Choices:  A: ground B: human  body C: repair shop D: combustion engines E: service station
Output: D: combustion engines

Input: What is person probably feeling that plans on stopping being married to their spouse? Choices:  A: detachment B: bankruptcy C: sad D: fights E: wrong
Output: A: detachment

Input: What could you use to store a clock? Choices:  A: shelf B: own bedroom C: desk D: wall E: car
Output: A: shelf

Input: The person put on lotion, what did they want? Choices:  A: fresh smell B: good credit C: smooth skin D: fresh produce E: headache
Output: C: smooth skin

Input: They burned the record, they were trying to do what to history? Choices:  A: compact disc B: tape C: rewrite D: play music E: erase
Output: E: erase

Input: She sure didn't have a green thumb, every time she thought she was making grow something it would what? Choices:  A: growth B: flowering C: ground D: die E: plants
Output: D: die

Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o8-tcommonsenseqa-s10-rFalse-m4096
Evaluating gsm8k :   1%|▍                                           | 1/100 [02:07<3:31:00, 127.89s/it]Evaluating gsm8k :   2%|▉                                           | 2/100 [04:18<3:31:09, 129.28s/it]Evaluating gsm8k :   3%|█▎                                           | 3/100 [05:11<2:32:52, 94.56s/it]Evaluating gsm8k :   4%|█▊                                          | 4/100 [07:19<2:52:34, 107.86s/it]Evaluating gsm8k :   5%|██▎                                          | 5/100 [08:38<2:33:58, 97.24s/it]Evaluating gsm8k :   6%|██▋                                         | 6/100 [10:43<2:47:30, 106.92s/it]Evaluating gsm8k :   7%|███▏                                         | 7/100 [11:19<2:09:33, 83.59s/it]Evaluating gsm8k :   8%|███▌                                         | 8/100 [13:28<2:30:22, 98.07s/it]Evaluating gsm8k :   9%|████                                         | 9/100 [14:14<2:03:59, 81.75s/it]Evaluating gsm8k :  10%|████▍                                       | 10/100 [15:44<2:06:29, 84.33s/it]Evaluating gsm8k :  11%|████▊                                       | 11/100 [17:07<2:04:42, 84.07s/it]Evaluating gsm8k :  12%|█████▎                                      | 12/100 [19:15<2:22:44, 97.33s/it]Evaluating gsm8k :  13%|█████▋                                      | 13/100 [20:11<2:02:49, 84.71s/it]Evaluating gsm8k :  14%|██████▏                                     | 14/100 [22:18<2:19:54, 97.61s/it]Evaluating gsm8k :  15%|██████▍                                    | 15/100 [24:26<2:31:03, 106.63s/it]Evaluating gsm8k :  16%|██████▉                                    | 16/100 [26:35<2:38:41, 113.35s/it]Evaluating gsm8k :  17%|███████▎                                   | 17/100 [28:38<2:41:02, 116.41s/it]Evaluating gsm8k :  18%|███████▋                                   | 18/100 [29:45<2:18:47, 101.55s/it]Evaluating gsm8k :  19%|████████▏                                  | 19/100 [31:51<2:27:07, 108.98s/it]Evaluating gsm8k :  20%|████████▊                                   | 20/100 [33:09<2:12:49, 99.61s/it]Evaluating gsm8k :  21%|█████████                                  | 21/100 [35:18<2:22:32, 108.26s/it]Evaluating gsm8k :  22%|█████████▍                                 | 22/100 [37:24<2:27:44, 113.64s/it]Evaluating gsm8k :  23%|█████████▉                                 | 23/100 [39:33<2:32:00, 118.45s/it]Evaluating gsm8k :  24%|██████████▎                                | 24/100 [41:40<2:33:16, 121.00s/it]Evaluating gsm8k :  25%|██████████▊                                | 25/100 [43:51<2:34:45, 123.81s/it]Evaluating gsm8k :  26%|███████████▏                               | 26/100 [45:58<2:33:59, 124.86s/it]Evaluating gsm8k :  27%|███████████▌                               | 27/100 [46:41<2:02:04, 100.33s/it]Evaluating gsm8k :  28%|████████████                               | 28/100 [48:48<2:09:53, 108.24s/it]Evaluating gsm8k :  29%|████████████▍                              | 29/100 [50:53<2:14:15, 113.46s/it]Evaluating gsm8k :  30%|████████████▉                              | 30/100 [53:00<2:17:02, 117.47s/it]Evaluating gsm8k :  31%|█████████████▎                             | 31/100 [55:07<2:18:23, 120.34s/it]Evaluating gsm8k :  32%|█████████████▊                             | 32/100 [57:15<2:18:59, 122.64s/it]Evaluating gsm8k :  33%|██████████████▏                            | 33/100 [58:51<2:08:00, 114.64s/it]Evaluating gsm8k :  34%|██████████████▉                             | 34/100 [59:53<1:48:47, 98.90s/it]Evaluating gsm8k :  35%|██████████████▎                          | 35/100 [1:01:57<1:55:08, 106.29s/it]Evaluating gsm8k :  36%|██████████████▊                          | 36/100 [1:03:38<1:51:35, 104.62s/it]Evaluating gsm8k :  37%|███████████████▏                         | 37/100 [1:05:48<1:57:57, 112.33s/it]Evaluating gsm8k :  38%|███████████████▌                         | 38/100 [1:07:54<2:00:16, 116.40s/it]Evaluating gsm8k :  39%|███████████████▉                         | 39/100 [1:09:10<1:45:53, 104.16s/it]Evaluating gsm8k :  40%|████████████████▍                        | 40/100 [1:11:13<1:49:51, 109.86s/it]Evaluating gsm8k :  41%|█████████████████▏                        | 41/100 [1:12:06<1:31:22, 92.92s/it]Evaluating gsm8k :  42%|█████████████████▋                        | 42/100 [1:13:11<1:21:36, 84.42s/it]Evaluating gsm8k :  43%|██████████████████                        | 43/100 [1:15:13<1:31:02, 95.83s/it]Evaluating gsm8k :  44%|██████████████████                       | 44/100 [1:17:10<1:35:23, 102.21s/it]Evaluating gsm8k :  45%|██████████████████▍                      | 45/100 [1:19:17<1:40:26, 109.58s/it]Evaluating gsm8k :  46%|██████████████████▊                      | 46/100 [1:21:22<1:42:42, 114.13s/it]Evaluating gsm8k :  47%|███████████████████▎                     | 47/100 [1:23:19<1:41:38, 115.06s/it]Evaluating gsm8k :  48%|███████████████████▋                     | 48/100 [1:25:11<1:39:01, 114.26s/it]Evaluating gsm8k :  49%|████████████████████                     | 49/100 [1:27:16<1:39:45, 117.36s/it]Evaluating gsm8k :  50%|████████████████████▌                    | 50/100 [1:29:24<1:40:33, 120.67s/it]Evaluating gsm8k :  51%|████████████████████▉                    | 51/100 [1:31:32<1:40:11, 122.68s/it]Evaluating gsm8k :  52%|█████████████████████▎                   | 52/100 [1:33:39<1:39:16, 124.09s/it]Evaluating gsm8k :  53%|█████████████████████▋                   | 53/100 [1:35:17<1:31:09, 116.36s/it]Evaluating gsm8k :  54%|██████████████████████▏                  | 54/100 [1:37:26<1:32:02, 120.05s/it]Evaluating gsm8k :  55%|██████████████████████▌                  | 55/100 [1:38:32<1:17:47, 103.73s/it]Evaluating gsm8k :  56%|██████████████████████▉                  | 56/100 [1:40:38<1:21:01, 110.50s/it]Evaluating gsm8k :  57%|███████████████████████▉                  | 57/100 [1:41:24<1:05:23, 91.25s/it]Evaluating gsm8k :  58%|███████████████████████▊                 | 58/100 [1:43:34<1:12:00, 102.88s/it]Evaluating gsm8k :  59%|████████████████████████▊                 | 59/100 [1:44:47<1:04:05, 93.80s/it]Evaluating gsm8k :  60%|████████████████████████▌                | 60/100 [1:46:55<1:09:25, 104.14s/it]Evaluating gsm8k :  61%|█████████████████████████                | 61/100 [1:49:04<1:12:24, 111.40s/it]Evaluating gsm8k :  62%|█████████████████████████▍               | 62/100 [1:51:13<1:13:55, 116.72s/it]Evaluating gsm8k :  63%|█████████████████████████▊               | 63/100 [1:53:23<1:14:33, 120.92s/it]Evaluating gsm8k :  64%|██████████████████████████▏              | 64/100 [1:55:27<1:12:56, 121.56s/it]Evaluating gsm8k :  65%|██████████████████████████▋              | 65/100 [1:57:31<1:11:20, 122.30s/it]Evaluating gsm8k :  66%|███████████████████████████              | 66/100 [1:59:28<1:08:32, 120.96s/it]Evaluating gsm8k :  67%|███████████████████████████▍             | 67/100 [2:01:36<1:07:39, 123.00s/it]Evaluating gsm8k :  68%|█████████████████████████████▏             | 68/100 [2:02:34<55:09, 103.44s/it]Evaluating gsm8k :  69%|█████████████████████████████▋             | 69/100 [2:04:40<56:54, 110.14s/it]Evaluating gsm8k :  70%|██████████████████████████████             | 70/100 [2:06:13<52:35, 105.18s/it]Evaluating gsm8k :  71%|███████████████████████████████▏            | 71/100 [2:06:48<40:33, 83.91s/it]Evaluating gsm8k :  72%|███████████████████████████████▋            | 72/100 [2:08:53<44:59, 96.41s/it]Evaluating gsm8k :  73%|███████████████████████████████▍           | 73/100 [2:11:01<47:36, 105.78s/it]Evaluating gsm8k :  74%|███████████████████████████████▊           | 74/100 [2:13:10<48:49, 112.67s/it]Evaluating gsm8k :  75%|████████████████████████████████▎          | 75/100 [2:15:19<49:04, 117.79s/it]Evaluating gsm8k :  76%|█████████████████████████████████▍          | 76/100 [2:15:51<36:50, 92.10s/it]Evaluating gsm8k :  77%|█████████████████████████████████▉          | 77/100 [2:16:53<31:49, 83.01s/it]Evaluating gsm8k :  78%|██████████████████████████████████▎         | 78/100 [2:19:01<35:23, 96.50s/it]Evaluating gsm8k :  79%|█████████████████████████████████▉         | 79/100 [2:20:50<35:00, 100.04s/it]Evaluating gsm8k :  80%|██████████████████████████████████▍        | 80/100 [2:22:57<36:04, 108.23s/it]Evaluating gsm8k :  81%|██████████████████████████████████▊        | 81/100 [2:25:06<36:13, 114.38s/it]Evaluating gsm8k :  82%|███████████████████████████████████▎       | 82/100 [2:27:10<35:15, 117.50s/it]Evaluating gsm8k :  83%|███████████████████████████████████▋       | 83/100 [2:29:18<34:07, 120.43s/it]Evaluating gsm8k :  84%|████████████████████████████████████       | 84/100 [2:31:26<32:44, 122.81s/it]Evaluating gsm8k :  85%|████████████████████████████████████▌      | 85/100 [2:33:31<30:50, 123.37s/it]Evaluating gsm8k :  86%|████████████████████████████████████▉      | 86/100 [2:35:12<27:13, 116.71s/it]Evaluating gsm8k :  87%|█████████████████████████████████████▍     | 87/100 [2:36:17<21:57, 101.33s/it]Evaluating gsm8k :  88%|█████████████████████████████████████▊     | 88/100 [2:38:25<21:52, 109.37s/it]Evaluating gsm8k :  89%|███████████████████████████████████████▏    | 89/100 [2:39:22<17:08, 93.48s/it]Evaluating gsm8k :  90%|███████████████████████████████████████▌    | 90/100 [2:40:58<15:42, 94.27s/it]Evaluating gsm8k :  91%|███████████████████████████████████████▏   | 91/100 [2:43:02<15:28, 103.11s/it]Evaluating gsm8k :  92%|███████████████████████████████████████▌   | 92/100 [2:44:53<14:05, 105.70s/it]Evaluating gsm8k :  93%|███████████████████████████████████████▉   | 93/100 [2:47:00<13:03, 111.95s/it]Evaluating gsm8k :  94%|████████████████████████████████████████▍  | 94/100 [2:49:05<11:34, 115.78s/it]Evaluating gsm8k :  95%|████████████████████████████████████████▊  | 95/100 [2:51:14<09:59, 119.83s/it]Evaluating gsm8k :  96%|█████████████████████████████████████████▎ | 96/100 [2:53:13<07:57, 119.49s/it]Evaluating gsm8k :  97%|██████████████████████████████████████████▋ | 97/100 [2:53:41<04:35, 92.00s/it]Evaluating gsm8k :  98%|███████████████████████████████████████████ | 98/100 [2:55:02<02:57, 88.77s/it]Evaluating gsm8k :  99%|███████████████████████████████████████████▌| 99/100 [2:56:14<01:23, 83.66s/it]Evaluating gsm8k : 100%|███████████████████████████████████████████| 100/100 [2:58:19<00:00, 96.32s/it]Evaluating gsm8k : 100%|██████████████████████████████████████████| 100/100 [2:58:19<00:00, 107.00s/it]
name: gsm8k | avg. gen lenth: 198.988 | time: 10700.36801457405s
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 12355 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o16-tcommonsenseqa-s10-rFalse --seed 10 --max-prompt-length 4096 --num-out-domain 16
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-31 03:47:29,747] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 03:47:29,766] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 2
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o16-tcommonsenseqa-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 16
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o16-tcommonsenseqa-s10-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 97, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 87, in main
    dataset = prepare_dataset_main(args, tokenizer)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 21, in prepare_dataset_main
    return PromptDataset(args, tokenizer, args.data_dir, args.num_eval)
  File "/home/ylu130/workspace/in-context-generalization/data_utils/prompt_datasets.py", line 19, in __init__
    self.data = self.load_data_json(data_path)
  File "/home/ylu130/workspace/in-context-generalization/data_utils/prompt_datasets.py", line 36, in load_data_json
    with open(data_path) as f:
FileNotFoundError: [Errno 2] No such file or directory: '/scratch/ylu130/processed_data/gsm8k/out-domain/o16-tcommonsenseqa-s10-rFalse'
WARNING: /scratch/ylu130/processed_data/gsm8k/out-domain/o16-tcommonsenseqa-s10-rFalse/gsm8k.jsonl does not exist
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 97, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 87, in main
    dataset = prepare_dataset_main(args, tokenizer)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 21, in prepare_dataset_main
    return PromptDataset(args, tokenizer, args.data_dir, args.num_eval)
  File "/home/ylu130/workspace/in-context-generalization/data_utils/prompt_datasets.py", line 19, in __init__
    self.data = self.load_data_json(data_path)
  File "/home/ylu130/workspace/in-context-generalization/data_utils/prompt_datasets.py", line 36, in load_data_json
    with open(data_path) as f:
FileNotFoundError: [Errno 2] No such file or directory: '/scratch/ylu130/processed_data/gsm8k/out-domain/o16-tcommonsenseqa-s10-rFalse'
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 1100947) of binary: /home/ylu130/.conda/envs/ood/bin/python
Traceback (most recent call last):
  File "/home/ylu130/.conda/envs/ood/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/run.py", line 794, in main
    run(args)
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/ylu130/workspace/in-context-generalization/inference.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-08-31_03:47:32
  host      : ia1.wse.jhu.edu
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 1100948)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-08-31_03:47:32
  host      : ia1.wse.jhu.edu
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 1100947)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 12355 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o1-tcommonsenseqa-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-31 03:47:36,165] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 03:47:36,678] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 2
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o1-tcommonsenseqa-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 1
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o1-tcommonsenseqa-s20-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading data:   0%|                                                           | 0/7473 [00:00<?, ?it/s]Loading data: 100%|███████████████████████████████████████████| 7473/7473 [00:00<00:00, 1189165.86it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                                 | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                 | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|████████████████████▌                    | 1/2 [00:06<00:06,  6.77s/it]Loading checkpoint shards:  50%|████████████████████▌                    | 1/2 [00:08<00:08,  8.15s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  3.93s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  4.36s/it]
 > number of parameters: 6738415616
[2023-08-31 03:47:46,958] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:10<00:00,  4.51s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:10<00:00,  5.06s/it]
[2023-08-31 03:47:47,973] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 03:47:48,495] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-31 03:47:48,497] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-31 03:47:48,497] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-31 03:47:48,497] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-31 03:47:48,497] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-31 03:47:48,497] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-31 03:47:48,497] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-31 03:47:48,497] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-31 03:47:48,497] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-31 03:47:48,497] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-31 03:47:48,497] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-31 03:47:48,497] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7facf1ad12a0>
[2023-08-31 03:47:48,497] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-31 03:47:48,497] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-31 03:47:48,498] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-31 03:47:48,499] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-31 03:47:48,499] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-31 03:47:48,499] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-31 03:47:48,499] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-31 03:47:48,499] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-31 03:47:48,499] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-31 03:47:48,499] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-31 03:47:48,499] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-31 03:47:48,499] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-31 03:47:48,499] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-31 03:47:48,499] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-31 03:47:48,499] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-31 03:47:48,499] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-31 03:47:48,499] [INFO] [config.py:964:print]   train_batch_size ............. 2
[2023-08-31 03:47:48,499] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-31 03:47:48,499] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-31 03:47:48,499] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-31 03:47:48,499] [INFO] [config.py:964:print]   world_size ................... 2
[2023-08-31 03:47:48,499] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-31 03:47:48,499] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-31 03:47:48,499] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-31 03:47:48,499] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-31 03:47:48,499] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-31 03:47:48,499] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating gsm8k :   0%|                                                       | 0/100 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following grade math question.

Input: The machine was very intricate, it was quite an what? Choices:  A: box B: apparatus C: appliance D: wash dishes E: implement
Output: B: apparatus

Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o1-tcommonsenseqa-s20-rFalse-m4096
Evaluating gsm8k :   1%|▍                                           | 1/100 [02:23<3:56:09, 143.12s/it]Evaluating gsm8k :   2%|▉                                           | 2/100 [04:45<3:52:50, 142.56s/it]Evaluating gsm8k :   3%|█▎                                          | 3/100 [07:06<3:49:08, 141.74s/it]Evaluating gsm8k :   4%|█▊                                          | 4/100 [09:28<3:46:57, 141.85s/it]Evaluating gsm8k :   5%|██▏                                         | 5/100 [11:50<3:44:53, 142.03s/it]Evaluating gsm8k :   6%|██▋                                         | 6/100 [13:57<3:34:36, 136.99s/it]Evaluating gsm8k :   7%|███                                         | 7/100 [16:16<3:33:14, 137.58s/it]Evaluating gsm8k :   8%|███▌                                        | 8/100 [18:33<3:30:36, 137.35s/it]Evaluating gsm8k :   9%|███▉                                        | 9/100 [20:02<3:05:21, 122.22s/it]Evaluating gsm8k :  10%|████▎                                      | 10/100 [22:26<3:13:39, 129.11s/it]Evaluating gsm8k :  11%|████▋                                      | 11/100 [24:30<3:08:57, 127.39s/it]Evaluating gsm8k :  12%|█████▏                                     | 12/100 [25:53<2:46:59, 113.85s/it]Evaluating gsm8k :  13%|█████▌                                     | 13/100 [28:13<2:56:49, 121.95s/it]Evaluating gsm8k :  14%|██████                                     | 14/100 [30:33<3:02:34, 127.38s/it]Evaluating gsm8k :  15%|██████▍                                    | 15/100 [32:52<3:05:13, 130.75s/it]Evaluating gsm8k :  16%|██████▉                                    | 16/100 [35:12<3:06:56, 133.53s/it]Evaluating gsm8k :  17%|███████▎                                   | 17/100 [37:03<2:55:26, 126.83s/it]Evaluating gsm8k :  18%|███████▋                                   | 18/100 [39:27<3:00:17, 131.92s/it]Evaluating gsm8k :  19%|████████▏                                  | 19/100 [41:47<3:01:38, 134.55s/it]Evaluating gsm8k :  20%|████████▌                                  | 20/100 [44:08<3:01:59, 136.49s/it]Evaluating gsm8k :  21%|█████████                                  | 21/100 [46:30<3:01:40, 137.98s/it]Evaluating gsm8k :  22%|█████████▍                                 | 22/100 [48:52<3:00:57, 139.20s/it]Evaluating gsm8k :  23%|█████████▉                                 | 23/100 [51:14<2:59:56, 140.22s/it]Evaluating gsm8k :  24%|██████████▎                                | 24/100 [53:30<2:55:40, 138.69s/it]Evaluating gsm8k :  25%|██████████▊                                | 25/100 [55:51<2:54:25, 139.54s/it]Evaluating gsm8k :  26%|███████████▏                               | 26/100 [58:16<2:54:06, 141.17s/it]Evaluating gsm8k :  27%|███████████                              | 27/100 [1:00:36<2:51:22, 140.86s/it]Evaluating gsm8k :  28%|███████████▍                             | 28/100 [1:01:56<2:26:52, 122.40s/it]Evaluating gsm8k :  29%|███████████▉                             | 29/100 [1:04:14<2:30:26, 127.14s/it]Evaluating gsm8k :  30%|████████████▎                            | 30/100 [1:06:39<2:34:36, 132.52s/it]Evaluating gsm8k :  31%|████████████▋                            | 31/100 [1:09:01<2:35:39, 135.36s/it]Evaluating gsm8k :  32%|█████████████                            | 32/100 [1:11:21<2:35:03, 136.81s/it]Evaluating gsm8k :  33%|█████████████▌                           | 33/100 [1:13:27<2:29:04, 133.49s/it]Evaluating gsm8k :  34%|█████████████▉                           | 34/100 [1:15:48<2:29:14, 135.67s/it]Evaluating gsm8k :  35%|██████████████▎                          | 35/100 [1:18:09<2:28:53, 137.45s/it]Evaluating gsm8k :  36%|██████████████▊                          | 36/100 [1:20:03<2:19:06, 130.41s/it]Evaluating gsm8k :  37%|███████████████▏                         | 37/100 [1:21:54<2:10:38, 124.42s/it]Evaluating gsm8k :  38%|███████████████▌                         | 38/100 [1:24:16<2:14:11, 129.86s/it]Evaluating gsm8k :  39%|███████████████▉                         | 39/100 [1:26:37<2:15:17, 133.07s/it]Evaluating gsm8k :  40%|████████████████▍                        | 40/100 [1:28:57<2:15:22, 135.37s/it]Evaluating gsm8k :  41%|████████████████▊                        | 41/100 [1:31:20<2:15:16, 137.57s/it]Evaluating gsm8k :  42%|█████████████████▏                       | 42/100 [1:33:39<2:13:23, 137.99s/it]Evaluating gsm8k :  43%|█████████████████▋                       | 43/100 [1:36:00<2:11:52, 138.82s/it]Evaluating gsm8k :  44%|██████████████████                       | 44/100 [1:37:33<1:56:54, 125.26s/it]Evaluating gsm8k :  45%|██████████████████▍                      | 45/100 [1:39:44<1:56:17, 126.87s/it]Evaluating gsm8k :  46%|██████████████████▊                      | 46/100 [1:42:04<1:57:47, 130.88s/it]Evaluating gsm8k :  47%|███████████████████▎                     | 47/100 [1:44:21<1:57:02, 132.51s/it]Evaluating gsm8k :  48%|███████████████████▋                     | 48/100 [1:46:42<1:57:08, 135.17s/it]Evaluating gsm8k :  49%|████████████████████                     | 49/100 [1:47:37<1:34:20, 110.98s/it]Evaluating gsm8k :  50%|████████████████████▌                    | 50/100 [1:49:56<1:39:40, 119.62s/it]Evaluating gsm8k :  51%|████████████████████▉                    | 51/100 [1:52:18<1:43:08, 126.30s/it]Evaluating gsm8k :  52%|█████████████████████▎                   | 52/100 [1:54:38<1:44:21, 130.46s/it]Evaluating gsm8k :  53%|█████████████████████▋                   | 53/100 [1:56:58<1:44:18, 133.15s/it]Evaluating gsm8k :  54%|██████████████████████▏                  | 54/100 [1:59:18<1:43:35, 135.11s/it]Evaluating gsm8k :  55%|██████████████████████▌                  | 55/100 [2:01:38<1:42:39, 136.87s/it]Evaluating gsm8k :  56%|██████████████████████▉                  | 56/100 [2:04:01<1:41:30, 138.42s/it]Evaluating gsm8k :  57%|███████████████████████▎                 | 57/100 [2:05:04<1:23:10, 116.07s/it]Evaluating gsm8k :  58%|███████████████████████▊                 | 58/100 [2:07:23<1:26:01, 122.89s/it]Evaluating gsm8k :  59%|████████████████████████▏                | 59/100 [2:09:43<1:27:24, 127.92s/it]Evaluating gsm8k :  60%|████████████████████████▌                | 60/100 [2:12:03<1:27:41, 131.55s/it]Evaluating gsm8k :  61%|█████████████████████████                | 61/100 [2:14:25<1:27:36, 134.77s/it]Evaluating gsm8k :  62%|█████████████████████████▍               | 62/100 [2:16:46<1:26:26, 136.49s/it]Evaluating gsm8k :  63%|█████████████████████████▊               | 63/100 [2:19:06<1:24:53, 137.66s/it]Evaluating gsm8k :  64%|██████████████████████████▏              | 64/100 [2:21:25<1:22:53, 138.15s/it]Evaluating gsm8k :  65%|██████████████████████████▋              | 65/100 [2:23:48<1:21:21, 139.47s/it]Evaluating gsm8k :  66%|███████████████████████████              | 66/100 [2:26:08<1:19:08, 139.66s/it]Evaluating gsm8k :  67%|███████████████████████████▍             | 67/100 [2:27:07<1:03:32, 115.53s/it]Evaluating gsm8k :  68%|███████████████████████████▉             | 68/100 [2:29:03<1:01:35, 115.49s/it]Evaluating gsm8k :  69%|█████████████████████████████▋             | 69/100 [2:30:45<57:41, 111.65s/it]Evaluating gsm8k :  70%|██████████████████████████████             | 70/100 [2:33:02<59:37, 119.25s/it]Evaluating gsm8k :  71%|█████████████████████████████            | 71/100 [2:35:23<1:00:45, 125.72s/it]Evaluating gsm8k :  72%|█████████████████████████████▌           | 72/100 [2:37:45<1:00:54, 130.53s/it]Evaluating gsm8k :  73%|█████████████████████████████▉           | 73/100 [2:40:05<1:00:03, 133.48s/it]Evaluating gsm8k :  74%|███████████████████████████████▊           | 74/100 [2:42:24<58:28, 134.96s/it]Evaluating gsm8k :  75%|████████████████████████████████▎          | 75/100 [2:42:57<43:33, 104.55s/it]Evaluating gsm8k :  76%|████████████████████████████████▋          | 76/100 [2:45:17<46:02, 115.10s/it]Evaluating gsm8k :  77%|█████████████████████████████████          | 77/100 [2:47:39<47:12, 123.17s/it]Evaluating gsm8k :  78%|█████████████████████████████████▌         | 78/100 [2:49:59<47:01, 128.24s/it]Evaluating gsm8k :  79%|█████████████████████████████████▉         | 79/100 [2:52:18<46:02, 131.55s/it]Evaluating gsm8k :  80%|██████████████████████████████████▍        | 80/100 [2:54:28<43:39, 130.97s/it]Evaluating gsm8k :  81%|██████████████████████████████████▊        | 81/100 [2:56:48<42:17, 133.57s/it]Evaluating gsm8k :  82%|███████████████████████████████████▎       | 82/100 [2:59:03<40:13, 134.08s/it]Evaluating gsm8k :  83%|███████████████████████████████████▋       | 83/100 [3:01:26<38:44, 136.75s/it]Evaluating gsm8k :  84%|████████████████████████████████████       | 84/100 [3:03:15<34:15, 128.48s/it]Evaluating gsm8k :  85%|████████████████████████████████████▌      | 85/100 [3:05:08<30:58, 123.91s/it]Evaluating gsm8k :  86%|████████████████████████████████████▉      | 86/100 [3:07:28<30:00, 128.62s/it]Evaluating gsm8k :  87%|█████████████████████████████████████▍     | 87/100 [3:09:48<28:37, 132.13s/it]Evaluating gsm8k :  88%|█████████████████████████████████████▊     | 88/100 [3:12:07<26:48, 134.06s/it]Evaluating gsm8k :  89%|██████████████████████████████████████▎    | 89/100 [3:14:28<24:57, 136.15s/it]Evaluating gsm8k :  90%|██████████████████████████████████████▋    | 90/100 [3:16:49<22:57, 137.72s/it]Evaluating gsm8k :  91%|███████████████████████████████████████▏   | 91/100 [3:19:12<20:52, 139.22s/it]Evaluating gsm8k :  92%|███████████████████████████████████████▌   | 92/100 [3:21:33<18:38, 139.86s/it]Evaluating gsm8k :  93%|███████████████████████████████████████▉   | 93/100 [3:23:54<16:19, 139.99s/it]Evaluating gsm8k :  94%|████████████████████████████████████████▍  | 94/100 [3:26:11<13:54, 139.12s/it]Evaluating gsm8k :  95%|████████████████████████████████████████▊  | 95/100 [3:28:32<11:38, 139.71s/it]Evaluating gsm8k :  96%|█████████████████████████████████████████▎ | 96/100 [3:30:54<09:22, 140.51s/it]Evaluating gsm8k :  97%|█████████████████████████████████████████▋ | 97/100 [3:33:12<06:59, 139.71s/it]Evaluating gsm8k :  98%|██████████████████████████████████████████▏| 98/100 [3:35:34<04:40, 140.43s/it]Evaluating gsm8k :  99%|██████████████████████████████████████████▌| 99/100 [3:37:55<02:20, 140.57s/it]Evaluating gsm8k : 100%|██████████████████████████████████████████| 100/100 [3:40:18<00:00, 141.27s/it]Evaluating gsm8k : 100%|██████████████████████████████████████████| 100/100 [3:40:18<00:00, 132.18s/it]
name: gsm8k | avg. gen lenth: 253.056 | time: 13218.766284227371s
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 12355 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o2-tcommonsenseqa-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 2
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-31 07:28:12,555] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 07:28:12,579] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 2
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o2-tcommonsenseqa-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 2
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o2-tcommonsenseqa-s20-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading data:   0%|                                                           | 0/7473 [00:00<?, ?it/s]Loading data: 100%|███████████████████████████████████████████| 7473/7473 [00:00<00:00, 1081649.31it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                                 | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                 | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|████████████████████▌                    | 1/2 [00:06<00:06,  6.61s/it]Loading checkpoint shards:  50%|████████████████████▌                    | 1/2 [00:06<00:06,  6.81s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  3.89s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  4.30s/it]
[2023-08-31 07:28:22,352] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  4.05s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  4.46s/it]
 > number of parameters: 6738415616
[2023-08-31 07:28:22,759] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 07:28:23,193] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-31 07:28:23,195] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-31 07:28:23,195] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-31 07:28:23,195] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-31 07:28:23,195] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-31 07:28:23,195] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-31 07:28:23,195] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-31 07:28:23,195] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-31 07:28:23,195] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-31 07:28:23,195] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-31 07:28:23,195] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-31 07:28:23,195] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f348abcd2d0>
[2023-08-31 07:28:23,195] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-31 07:28:23,195] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-31 07:28:23,195] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-31 07:28:23,195] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-31 07:28:23,195] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-31 07:28:23,195] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-31 07:28:23,195] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-31 07:28:23,195] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-31 07:28:23,195] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-31 07:28:23,195] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-31 07:28:23,195] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   train_batch_size ............. 2
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   world_size ................... 2
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-31 07:28:23,196] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-31 07:28:23,197] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating gsm8k :   0%|                                                       | 0/100 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following grade math question.

Input: The machine was very intricate, it was quite an what? Choices:  A: box B: apparatus C: appliance D: wash dishes E: implement
Output: B: apparatus

Input: Where do you get petrol? Choices:  A: burn hot B: fuel tank C: burn hot D: car E: gas station
Output: E: gas station

Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o2-tcommonsenseqa-s20-rFalse-m4096
Evaluating gsm8k :   1%|▍                                           | 1/100 [02:22<3:54:22, 142.05s/it]Evaluating gsm8k :   2%|▉                                           | 2/100 [04:42<3:50:00, 140.82s/it]Evaluating gsm8k :   3%|█▎                                          | 3/100 [07:00<3:46:13, 139.93s/it]Evaluating gsm8k :   4%|█▊                                          | 4/100 [09:19<3:43:17, 139.56s/it]Evaluating gsm8k :   5%|██▏                                         | 5/100 [11:40<3:41:41, 140.02s/it]Evaluating gsm8k :   6%|██▋                                         | 6/100 [13:39<3:28:08, 132.85s/it]Evaluating gsm8k :   7%|███                                         | 7/100 [14:58<2:58:35, 115.22s/it]Evaluating gsm8k :   8%|███▌                                        | 8/100 [17:17<3:08:06, 122.68s/it]Evaluating gsm8k :   9%|███▉                                        | 9/100 [19:13<3:03:01, 120.68s/it]Evaluating gsm8k :  10%|████▎                                      | 10/100 [20:31<2:41:26, 107.63s/it]Evaluating gsm8k :  11%|████▋                                      | 11/100 [22:27<2:43:20, 110.12s/it]Evaluating gsm8k :  12%|█████▏                                     | 12/100 [24:46<2:54:20, 118.87s/it]Evaluating gsm8k :  13%|█████▌                                     | 13/100 [27:04<3:00:50, 124.72s/it]Evaluating gsm8k :  14%|██████                                     | 14/100 [28:50<2:50:42, 119.09s/it]Evaluating gsm8k :  15%|██████▍                                    | 15/100 [30:21<2:36:44, 110.65s/it]Evaluating gsm8k :  16%|██████▉                                    | 16/100 [32:43<2:47:54, 119.93s/it]Evaluating gsm8k :  17%|███████▎                                   | 17/100 [34:59<2:52:45, 124.89s/it]Evaluating gsm8k :  18%|███████▋                                   | 18/100 [37:17<2:56:06, 128.86s/it]Evaluating gsm8k :  19%|████████▏                                  | 19/100 [38:18<2:26:12, 108.30s/it]Evaluating gsm8k :  20%|████████▌                                  | 20/100 [40:34<2:35:35, 116.70s/it]Evaluating gsm8k :  21%|█████████                                  | 21/100 [42:55<2:43:23, 124.10s/it]Evaluating gsm8k :  22%|█████████▍                                 | 22/100 [45:17<2:48:09, 129.35s/it]Evaluating gsm8k :  23%|█████████▉                                 | 23/100 [47:37<2:50:14, 132.66s/it]Evaluating gsm8k :  24%|██████████▎                                | 24/100 [49:14<2:34:18, 121.83s/it]Evaluating gsm8k :  25%|██████████▊                                | 25/100 [51:36<2:39:49, 127.86s/it]Evaluating gsm8k :  26%|███████████▏                               | 26/100 [53:56<2:42:08, 131.47s/it]Evaluating gsm8k :  27%|███████████▌                               | 27/100 [56:17<2:43:37, 134.48s/it]Evaluating gsm8k :  28%|████████████                               | 28/100 [58:36<2:42:50, 135.71s/it]Evaluating gsm8k :  29%|███████████▉                             | 29/100 [1:00:53<2:41:06, 136.15s/it]Evaluating gsm8k :  30%|████████████▎                            | 30/100 [1:03:10<2:39:08, 136.41s/it]Evaluating gsm8k :  31%|████████████▋                            | 31/100 [1:04:26<2:15:50, 118.13s/it]Evaluating gsm8k :  32%|█████████████                            | 32/100 [1:06:44<2:20:40, 124.13s/it]Evaluating gsm8k :  33%|█████████████▌                           | 33/100 [1:07:39<1:55:24, 103.35s/it]Evaluating gsm8k :  34%|█████████████▉                           | 34/100 [1:09:56<2:05:06, 113.73s/it]Evaluating gsm8k :  35%|██████████████▎                          | 35/100 [1:11:28<1:56:01, 107.10s/it]Evaluating gsm8k :  36%|██████████████▊                          | 36/100 [1:12:58<1:48:42, 101.91s/it]Evaluating gsm8k :  37%|███████████████▏                         | 37/100 [1:15:20<1:59:31, 113.83s/it]Evaluating gsm8k :  38%|███████████████▌                         | 38/100 [1:17:36<2:04:46, 120.76s/it]Evaluating gsm8k :  39%|███████████████▉                         | 39/100 [1:19:52<2:07:24, 125.32s/it]Evaluating gsm8k :  40%|████████████████▍                        | 40/100 [1:21:43<2:00:59, 120.99s/it]Evaluating gsm8k :  41%|████████████████▊                        | 41/100 [1:22:49<1:42:39, 104.40s/it]Evaluating gsm8k :  42%|█████████████████▏                       | 42/100 [1:24:44<1:43:54, 107.49s/it]Evaluating gsm8k :  43%|█████████████████▋                       | 43/100 [1:27:01<1:50:44, 116.57s/it]Evaluating gsm8k :  44%|██████████████████                       | 44/100 [1:29:21<1:55:06, 123.33s/it]Evaluating gsm8k :  45%|██████████████████▍                      | 45/100 [1:31:40<1:57:26, 128.11s/it]Evaluating gsm8k :  46%|██████████████████▊                      | 46/100 [1:33:45<1:54:34, 127.31s/it]Evaluating gsm8k :  47%|███████████████████▎                     | 47/100 [1:35:43<1:49:49, 124.33s/it]Evaluating gsm8k :  48%|███████████████████▋                     | 48/100 [1:38:01<1:51:18, 128.43s/it]Evaluating gsm8k :  49%|████████████████████                     | 49/100 [1:40:19<1:51:36, 131.30s/it]Evaluating gsm8k :  50%|████████████████████▌                    | 50/100 [1:42:38<1:51:31, 133.82s/it]Evaluating gsm8k :  51%|████████████████████▉                    | 51/100 [1:44:30<1:43:44, 127.04s/it]Evaluating gsm8k :  52%|█████████████████████▎                   | 52/100 [1:46:50<1:44:57, 131.20s/it]Evaluating gsm8k :  53%|█████████████████████▋                   | 53/100 [1:49:07<1:43:56, 132.69s/it]Evaluating gsm8k :  54%|██████████████████████▏                  | 54/100 [1:51:23<1:42:39, 133.90s/it]Evaluating gsm8k :  55%|██████████████████████▌                  | 55/100 [1:52:53<1:30:27, 120.61s/it]Evaluating gsm8k :  56%|██████████████████████▉                  | 56/100 [1:55:12<1:32:34, 126.23s/it]Evaluating gsm8k :  57%|███████████████████████▎                 | 57/100 [1:57:11<1:28:51, 123.99s/it]Evaluating gsm8k :  58%|███████████████████████▊                 | 58/100 [1:59:30<1:29:59, 128.55s/it]Evaluating gsm8k :  59%|████████████████████████▏                | 59/100 [2:01:52<1:30:32, 132.49s/it]Evaluating gsm8k :  60%|████████████████████████▌                | 60/100 [2:04:10<1:29:26, 134.16s/it]Evaluating gsm8k :  61%|█████████████████████████                | 61/100 [2:06:25<1:27:27, 134.55s/it]Evaluating gsm8k :  62%|█████████████████████████▍               | 62/100 [2:08:48<1:26:38, 136.80s/it]Evaluating gsm8k :  63%|█████████████████████████▊               | 63/100 [2:09:42<1:09:13, 112.25s/it]Evaluating gsm8k :  64%|██████████████████████████▏              | 64/100 [2:12:01<1:12:02, 120.07s/it]Evaluating gsm8k :  65%|██████████████████████████▋              | 65/100 [2:13:32<1:05:03, 111.54s/it]Evaluating gsm8k :  66%|███████████████████████████              | 66/100 [2:15:51<1:07:46, 119.61s/it]Evaluating gsm8k :  67%|███████████████████████████▍             | 67/100 [2:18:13<1:09:26, 126.27s/it]Evaluating gsm8k :  68%|███████████████████████████▉             | 68/100 [2:20:29<1:09:00, 129.39s/it]Evaluating gsm8k :  69%|█████████████████████████████▋             | 69/100 [2:21:50<59:13, 114.62s/it]Evaluating gsm8k :  70%|████████████████████████████▋            | 70/100 [2:24:11<1:01:18, 122.60s/it]Evaluating gsm8k :  71%|█████████████████████████████            | 71/100 [2:26:30<1:01:40, 127.60s/it]Evaluating gsm8k :  72%|█████████████████████████████▌           | 72/100 [2:28:48<1:01:03, 130.85s/it]Evaluating gsm8k :  73%|███████████████████████████████▍           | 73/100 [2:31:06<59:49, 132.93s/it]Evaluating gsm8k :  74%|███████████████████████████████▊           | 74/100 [2:33:23<58:09, 134.21s/it]Evaluating gsm8k :  75%|████████████████████████████████▎          | 75/100 [2:35:12<52:45, 126.64s/it]Evaluating gsm8k :  76%|████████████████████████████████▋          | 76/100 [2:37:29<51:48, 129.54s/it]Evaluating gsm8k :  77%|█████████████████████████████████          | 77/100 [2:39:32<48:58, 127.74s/it]Evaluating gsm8k :  78%|█████████████████████████████████▌         | 78/100 [2:41:24<45:04, 122.94s/it]Evaluating gsm8k :  79%|█████████████████████████████████▉         | 79/100 [2:43:17<42:01, 120.05s/it]Evaluating gsm8k :  80%|██████████████████████████████████▍        | 80/100 [2:45:37<41:57, 125.90s/it]Evaluating gsm8k :  81%|██████████████████████████████████▊        | 81/100 [2:47:54<40:56, 129.29s/it]Evaluating gsm8k :  82%|███████████████████████████████████▎       | 82/100 [2:50:12<39:33, 131.87s/it]Evaluating gsm8k :  83%|███████████████████████████████████▋       | 83/100 [2:52:29<37:49, 133.52s/it]Evaluating gsm8k :  84%|████████████████████████████████████       | 84/100 [2:54:47<35:58, 134.93s/it]Evaluating gsm8k :  85%|████████████████████████████████████▌      | 85/100 [2:57:06<33:58, 135.88s/it]Evaluating gsm8k :  86%|████████████████████████████████████▉      | 86/100 [2:57:52<25:27, 109.13s/it]Evaluating gsm8k :  87%|█████████████████████████████████████▍     | 87/100 [3:00:05<25:12, 116.33s/it]Evaluating gsm8k :  88%|█████████████████████████████████████▊     | 88/100 [3:02:23<24:31, 122.65s/it]Evaluating gsm8k :  89%|███████████████████████████████████████▏    | 89/100 [3:03:04<18:01, 98.27s/it]Evaluating gsm8k :  90%|██████████████████████████████████████▋    | 90/100 [3:04:50<16:45, 100.52s/it]Evaluating gsm8k :  91%|███████████████████████████████████████▏   | 91/100 [3:07:07<16:44, 111.56s/it]Evaluating gsm8k :  92%|███████████████████████████████████████▌   | 92/100 [3:09:26<15:57, 119.72s/it]Evaluating gsm8k :  93%|███████████████████████████████████████▉   | 93/100 [3:11:32<14:11, 121.59s/it]Evaluating gsm8k :  94%|████████████████████████████████████████▍  | 94/100 [3:13:52<12:41, 126.99s/it]Evaluating gsm8k :  95%|████████████████████████████████████████▊  | 95/100 [3:16:12<10:54, 130.93s/it]Evaluating gsm8k :  96%|█████████████████████████████████████████▎ | 96/100 [3:18:32<08:55, 133.81s/it]Evaluating gsm8k :  97%|█████████████████████████████████████████▋ | 97/100 [3:20:52<06:46, 135.52s/it]Evaluating gsm8k :  98%|██████████████████████████████████████████▏| 98/100 [3:23:13<04:34, 137.34s/it]Evaluating gsm8k :  99%|██████████████████████████████████████████▌| 99/100 [3:25:12<02:11, 131.79s/it]Evaluating gsm8k : 100%|██████████████████████████████████████████| 100/100 [3:26:36<00:00, 117.27s/it]Evaluating gsm8k : 100%|██████████████████████████████████████████| 100/100 [3:26:36<00:00, 123.96s/it]
name: gsm8k | avg. gen lenth: 229.746 | time: 12396.53644657135s
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 12355 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o4-tcommonsenseqa-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 4
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-31 10:55:07,517] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 10:55:07,524] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 2
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o4-tcommonsenseqa-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 4
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o4-tcommonsenseqa-s20-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading data:   0%|                                                           | 0/7473 [00:00<?, ?it/s]Loading data: 100%|███████████████████████████████████████████| 7473/7473 [00:00<00:00, 1014107.47it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                                 | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                 | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|████████████████████▌                    | 1/2 [00:06<00:06,  6.82s/it]Loading checkpoint shards:  50%|████████████████████▌                    | 1/2 [00:06<00:06,  6.86s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  3.96s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  4.39s/it]
 > number of parameters: 6738415616
[2023-08-31 10:55:17,597] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:09<00:00,  4.10s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:09<00:00,  4.52s/it]
[2023-08-31 10:55:17,897] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 10:55:18,470] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-31 10:55:18,471] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-31 10:55:18,471] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-31 10:55:18,471] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-31 10:55:18,471] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-31 10:55:18,471] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fc8aefd1300>
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-31 10:55:18,472] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-31 10:55:18,473] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-31 10:55:18,473] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-31 10:55:18,473] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-31 10:55:18,473] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-31 10:55:18,473] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-31 10:55:18,473] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-31 10:55:18,473] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-31 10:55:18,473] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-31 10:55:18,473] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-31 10:55:18,473] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-31 10:55:18,473] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-31 10:55:18,473] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-31 10:55:18,473] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-31 10:55:18,473] [INFO] [config.py:964:print]   train_batch_size ............. 2
[2023-08-31 10:55:18,473] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-31 10:55:18,473] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-31 10:55:18,473] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-31 10:55:18,473] [INFO] [config.py:964:print]   world_size ................... 2
[2023-08-31 10:55:18,473] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-31 10:55:18,473] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-31 10:55:18,473] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-31 10:55:18,473] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-31 10:55:18,473] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-31 10:55:18,473] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating gsm8k :   0%|                                                       | 0/100 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following grade math question.

Input: The machine was very intricate, it was quite an what? Choices:  A: box B: apparatus C: appliance D: wash dishes E: implement
Output: B: apparatus

Input: Where do you get petrol? Choices:  A: burn hot B: fuel tank C: burn hot D: car E: gas station
Output: E: gas station

Input: Where might a television used at night be? Choices:  A: cabinet B: house C: apartment D: bedroom E: woods
Output: D: bedroom

Input: The knowledge was expensive to get, where was it being gained? Choices:  A: university B: book C: field D: meeting E: class
Output: A: university

Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o4-tcommonsenseqa-s20-rFalse-m4096
Evaluating gsm8k :   1%|▍                                           | 1/100 [02:00<3:18:15, 120.16s/it]Evaluating gsm8k :   2%|▉                                           | 2/100 [03:34<2:51:21, 104.91s/it]Evaluating gsm8k :   3%|█▎                                          | 3/100 [05:51<3:13:36, 119.76s/it]Evaluating gsm8k :   4%|█▊                                          | 4/100 [08:06<3:20:56, 125.59s/it]Evaluating gsm8k :   5%|██▏                                         | 5/100 [10:24<3:25:59, 130.10s/it]Evaluating gsm8k :   6%|██▋                                         | 6/100 [12:43<3:28:49, 133.29s/it]Evaluating gsm8k :   7%|███                                         | 7/100 [14:18<3:07:03, 120.68s/it]Evaluating gsm8k :   8%|███▌                                        | 8/100 [16:33<3:11:54, 125.16s/it]Evaluating gsm8k :   9%|███▉                                        | 9/100 [18:49<3:15:09, 128.67s/it]Evaluating gsm8k :  10%|████▍                                       | 10/100 [19:20<2:27:51, 98.57s/it]Evaluating gsm8k :  11%|████▋                                      | 11/100 [21:34<2:41:51, 109.12s/it]Evaluating gsm8k :  12%|█████▏                                     | 12/100 [23:48<2:51:27, 116.90s/it]Evaluating gsm8k :  13%|█████▌                                     | 13/100 [26:04<2:57:50, 122.64s/it]Evaluating gsm8k :  14%|██████                                     | 14/100 [28:17<3:00:10, 125.71s/it]Evaluating gsm8k :  15%|██████▍                                    | 15/100 [29:22<2:32:11, 107.43s/it]Evaluating gsm8k :  16%|██████▉                                    | 16/100 [31:39<2:42:57, 116.40s/it]Evaluating gsm8k :  17%|███████▍                                    | 17/100 [31:58<2:00:32, 87.14s/it]Evaluating gsm8k :  18%|███████▋                                   | 18/100 [34:14<2:18:56, 101.67s/it]Evaluating gsm8k :  19%|████████▏                                  | 19/100 [36:28<2:30:23, 111.41s/it]Evaluating gsm8k :  20%|████████▌                                  | 20/100 [38:22<2:29:37, 112.22s/it]Evaluating gsm8k :  21%|█████████                                  | 21/100 [40:37<2:36:47, 119.08s/it]Evaluating gsm8k :  22%|█████████▍                                 | 22/100 [42:52<2:41:11, 124.00s/it]Evaluating gsm8k :  23%|█████████▉                                 | 23/100 [45:10<2:44:26, 128.13s/it]Evaluating gsm8k :  24%|██████████▎                                | 24/100 [47:22<2:43:46, 129.29s/it]Evaluating gsm8k :  25%|██████████▊                                | 25/100 [49:36<2:43:08, 130.51s/it]Evaluating gsm8k :  26%|███████████▏                               | 26/100 [51:52<2:43:16, 132.38s/it]Evaluating gsm8k :  27%|███████████▌                               | 27/100 [53:23<2:25:45, 119.80s/it]Evaluating gsm8k :  28%|████████████                               | 28/100 [54:54<2:13:36, 111.35s/it]Evaluating gsm8k :  29%|████████████▍                              | 29/100 [56:47<2:12:09, 111.68s/it]Evaluating gsm8k :  30%|████████████▉                              | 30/100 [58:23<2:04:55, 107.08s/it]Evaluating gsm8k :  31%|████████████▋                            | 31/100 [1:00:38<2:12:44, 115.43s/it]Evaluating gsm8k :  32%|█████████████                            | 32/100 [1:02:22<2:07:01, 112.08s/it]Evaluating gsm8k :  33%|█████████████▌                           | 33/100 [1:03:53<1:58:06, 105.78s/it]Evaluating gsm8k :  34%|█████████████▉                           | 34/100 [1:06:08<2:05:45, 114.33s/it]Evaluating gsm8k :  35%|██████████████▎                          | 35/100 [1:08:11<2:06:54, 117.15s/it]Evaluating gsm8k :  36%|██████████████▊                          | 36/100 [1:10:04<2:03:31, 115.80s/it]Evaluating gsm8k :  37%|███████████████▌                          | 37/100 [1:10:51<1:39:51, 95.10s/it]Evaluating gsm8k :  38%|███████████████▌                         | 38/100 [1:13:06<1:50:40, 107.10s/it]Evaluating gsm8k :  39%|███████████████▉                         | 39/100 [1:15:09<1:53:44, 111.88s/it]Evaluating gsm8k :  40%|████████████████▍                        | 40/100 [1:17:23<1:58:27, 118.46s/it]Evaluating gsm8k :  41%|████████████████▊                        | 41/100 [1:18:46<1:46:04, 107.87s/it]Evaluating gsm8k :  42%|█████████████████▏                       | 42/100 [1:21:03<1:52:50, 116.74s/it]Evaluating gsm8k :  43%|█████████████████▋                       | 43/100 [1:22:41<1:45:30, 111.06s/it]Evaluating gsm8k :  44%|██████████████████                       | 44/100 [1:24:56<1:50:22, 118.25s/it]Evaluating gsm8k :  45%|██████████████████▍                      | 45/100 [1:26:34<1:42:46, 112.11s/it]Evaluating gsm8k :  46%|██████████████████▊                      | 46/100 [1:28:49<1:47:09, 119.07s/it]Evaluating gsm8k :  47%|███████████████████▎                     | 47/100 [1:31:05<1:49:39, 124.14s/it]Evaluating gsm8k :  48%|███████████████████▋                     | 48/100 [1:33:22<1:50:48, 127.86s/it]Evaluating gsm8k :  49%|████████████████████                     | 49/100 [1:35:38<1:50:48, 130.37s/it]Evaluating gsm8k :  50%|████████████████████▌                    | 50/100 [1:36:53<1:34:39, 113.58s/it]Evaluating gsm8k :  51%|████████████████████▉                    | 51/100 [1:39:08<1:38:00, 120.02s/it]Evaluating gsm8k :  52%|█████████████████████▊                    | 52/100 [1:39:37<1:14:11, 92.74s/it]Evaluating gsm8k :  53%|██████████████████████▎                   | 53/100 [1:40:48<1:07:36, 86.31s/it]Evaluating gsm8k :  54%|██████████████████████▋                   | 54/100 [1:42:25<1:08:40, 89.58s/it]Evaluating gsm8k :  55%|██████████████████████▌                  | 55/100 [1:44:30<1:15:00, 100.00s/it]Evaluating gsm8k :  56%|██████████████████████▉                  | 56/100 [1:46:46<1:21:18, 110.88s/it]Evaluating gsm8k :  57%|███████████████████████▎                 | 57/100 [1:49:02<1:24:55, 118.49s/it]Evaluating gsm8k :  58%|███████████████████████▊                 | 58/100 [1:50:03<1:10:54, 101.29s/it]Evaluating gsm8k :  59%|████████████████████████▊                 | 59/100 [1:51:29<1:06:01, 96.63s/it]Evaluating gsm8k :  60%|████████████████████████▌                | 60/100 [1:53:42<1:11:43, 107.58s/it]Evaluating gsm8k :  61%|█████████████████████████                | 61/100 [1:55:56<1:15:03, 115.48s/it]Evaluating gsm8k :  62%|█████████████████████████▍               | 62/100 [1:58:10<1:16:44, 121.18s/it]Evaluating gsm8k :  63%|█████████████████████████▊               | 63/100 [2:00:28<1:17:45, 126.11s/it]Evaluating gsm8k :  64%|██████████████████████████▏              | 64/100 [2:02:44<1:17:24, 129.02s/it]Evaluating gsm8k :  65%|██████████████████████████▋              | 65/100 [2:03:51<1:04:20, 110.31s/it]Evaluating gsm8k :  66%|███████████████████████████              | 66/100 [2:05:58<1:05:26, 115.48s/it]Evaluating gsm8k :  67%|███████████████████████████▍             | 67/100 [2:08:14<1:06:53, 121.63s/it]Evaluating gsm8k :  68%|███████████████████████████▉             | 68/100 [2:10:29<1:07:00, 125.63s/it]Evaluating gsm8k :  69%|██████████████████████████████▎             | 69/100 [2:11:06<51:11, 99.08s/it]Evaluating gsm8k :  70%|██████████████████████████████             | 70/100 [2:13:25<55:30, 111.02s/it]Evaluating gsm8k :  71%|██████████████████████████████▌            | 71/100 [2:14:57<50:53, 105.29s/it]Evaluating gsm8k :  72%|██████████████████████████████▉            | 72/100 [2:17:18<54:04, 115.89s/it]Evaluating gsm8k :  73%|███████████████████████████████▍           | 73/100 [2:19:05<51:02, 113.43s/it]Evaluating gsm8k :  74%|███████████████████████████████▊           | 74/100 [2:21:23<52:22, 120.86s/it]Evaluating gsm8k :  75%|████████████████████████████████▎          | 75/100 [2:23:40<52:19, 125.56s/it]Evaluating gsm8k :  76%|████████████████████████████████▋          | 76/100 [2:25:01<44:52, 112.18s/it]Evaluating gsm8k :  77%|█████████████████████████████████          | 77/100 [2:26:24<39:37, 103.39s/it]Evaluating gsm8k :  78%|█████████████████████████████████▌         | 78/100 [2:28:37<41:08, 112.21s/it]Evaluating gsm8k :  79%|█████████████████████████████████▉         | 79/100 [2:30:50<41:32, 118.70s/it]Evaluating gsm8k :  80%|██████████████████████████████████▍        | 80/100 [2:32:05<35:07, 105.39s/it]Evaluating gsm8k :  81%|██████████████████████████████████▊        | 81/100 [2:34:20<36:12, 114.35s/it]Evaluating gsm8k :  82%|████████████████████████████████████        | 82/100 [2:34:38<25:39, 85.51s/it]Evaluating gsm8k :  83%|███████████████████████████████████▋       | 83/100 [2:36:56<28:40, 101.21s/it]Evaluating gsm8k :  84%|████████████████████████████████████       | 84/100 [2:39:10<29:34, 110.90s/it]Evaluating gsm8k :  85%|████████████████████████████████████▌      | 85/100 [2:41:23<29:24, 117.62s/it]Evaluating gsm8k :  86%|████████████████████████████████████▉      | 86/100 [2:42:57<25:46, 110.45s/it]Evaluating gsm8k :  87%|██████████████████████████████████████▎     | 87/100 [2:43:50<20:14, 93.40s/it]Evaluating gsm8k :  88%|█████████████████████████████████████▊     | 88/100 [2:46:09<21:24, 107.01s/it]Evaluating gsm8k :  89%|███████████████████████████████████████▏    | 89/100 [2:46:44<15:40, 85.49s/it]Evaluating gsm8k :  90%|███████████████████████████████████████▌    | 90/100 [2:48:52<16:20, 98.00s/it]Evaluating gsm8k :  91%|███████████████████████████████████████▏   | 91/100 [2:51:04<16:14, 108.27s/it]Evaluating gsm8k :  92%|███████████████████████████████████████▌   | 92/100 [2:53:04<14:54, 111.77s/it]Evaluating gsm8k :  93%|███████████████████████████████████████▉   | 93/100 [2:55:20<13:54, 119.27s/it]Evaluating gsm8k :  94%|████████████████████████████████████████▍  | 94/100 [2:57:40<12:31, 125.23s/it]Evaluating gsm8k :  95%|████████████████████████████████████████▊  | 95/100 [2:58:59<09:16, 111.38s/it]Evaluating gsm8k :  96%|█████████████████████████████████████████▎ | 96/100 [3:01:15<07:55, 118.82s/it]Evaluating gsm8k :  97%|█████████████████████████████████████████▋ | 97/100 [3:02:39<05:25, 108.50s/it]Evaluating gsm8k :  98%|██████████████████████████████████████████▏| 98/100 [3:04:56<03:53, 116.96s/it]Evaluating gsm8k :  99%|██████████████████████████████████████████▌| 99/100 [3:07:11<02:02, 122.29s/it]Evaluating gsm8k : 100%|██████████████████████████████████████████| 100/100 [3:09:28<00:00, 126.90s/it]Evaluating gsm8k : 100%|██████████████████████████████████████████| 100/100 [3:09:28<00:00, 113.69s/it]
name: gsm8k | avg. gen lenth: 193.696 | time: 11369.287531137466s
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 12355 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o8-tcommonsenseqa-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 8
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-31 14:06:56,427] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 14:06:56,449] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 2
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o8-tcommonsenseqa-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 8
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o8-tcommonsenseqa-s20-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading data:   0%|                                                           | 0/7473 [00:00<?, ?it/s]Loading data: 100%|████████████████████████████████████████████| 7473/7473 [00:00<00:00, 821298.44it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                                 | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                 | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|████████████████████▌                    | 1/2 [00:06<00:06,  6.71s/it]Loading checkpoint shards:  50%|████████████████████▌                    | 1/2 [00:06<00:06,  6.70s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  3.95s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  4.36s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  3.95s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  4.36s/it]
 > number of parameters: 6738415616
[2023-08-31 14:07:06,392] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 14:07:06,420] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 14:07:06,855] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-31 14:07:06,856] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-31 14:07:06,856] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-31 14:07:06,856] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-31 14:07:06,856] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-31 14:07:06,856] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-31 14:07:06,856] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f29e07bd2d0>
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-31 14:07:06,857] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-31 14:07:06,858] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-31 14:07:06,858] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-31 14:07:06,858] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-31 14:07:06,858] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-31 14:07:06,858] [INFO] [config.py:964:print]   train_batch_size ............. 2
[2023-08-31 14:07:06,858] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-31 14:07:06,858] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-31 14:07:06,858] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-31 14:07:06,858] [INFO] [config.py:964:print]   world_size ................... 2
[2023-08-31 14:07:06,858] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-31 14:07:06,858] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-31 14:07:06,858] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-31 14:07:06,858] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-31 14:07:06,858] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-31 14:07:06,858] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating gsm8k :   0%|                                                       | 0/100 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following grade math question.

Input: The machine was very intricate, it was quite an what? Choices:  A: box B: apparatus C: appliance D: wash dishes E: implement
Output: B: apparatus

Input: Where do you get petrol? Choices:  A: burn hot B: fuel tank C: burn hot D: car E: gas station
Output: E: gas station

Input: Where might a television used at night be? Choices:  A: cabinet B: house C: apartment D: bedroom E: woods
Output: D: bedroom

Input: The knowledge was expensive to get, where was it being gained? Choices:  A: university B: book C: field D: meeting E: class
Output: A: university

Input: Where are small grapes likely to be found? Choices:  A: lunch box B: food store C: wine country D: kitchen E: raisins
Output: C: wine country

Input: The painter explained how he never achieved a flawless portrait, he said this was because all people are what? Choices:  A: imperfect B: disfigured C: damaged D: flawed E: defective
Output: A: imperfect

Input: If you're betting with a shark, where are you likely playing? Choices:  A: aquarium B: mediterranean sea C: south pacific D: pool hall E: pacific ocean
Output: D: pool hall

Input: Marmot's can be found in high places.  They have hands that they can use to get to the top of what? Choices:  A: outside B: hill C: jungle D: rocky hillside E: tree
Output: E: tree

Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o8-tcommonsenseqa-s20-rFalse-m4096
Evaluating gsm8k :   1%|▍                                           | 1/100 [01:45<2:54:28, 105.74s/it]Evaluating gsm8k :   2%|▉                                           | 2/100 [03:56<3:16:42, 120.43s/it]Evaluating gsm8k :   3%|█▎                                          | 3/100 [06:04<3:20:21, 123.93s/it]Evaluating gsm8k :   4%|█▊                                           | 4/100 [06:46<2:26:16, 91.42s/it]Evaluating gsm8k :   5%|██▏                                         | 5/100 [08:53<2:45:17, 104.40s/it]Evaluating gsm8k :   6%|██▋                                         | 6/100 [10:59<2:54:59, 111.70s/it]Evaluating gsm8k :   7%|███                                         | 7/100 [12:34<2:44:50, 106.35s/it]Evaluating gsm8k :   8%|███▌                                        | 8/100 [14:44<2:54:21, 113.71s/it]Evaluating gsm8k :   9%|███▉                                        | 9/100 [16:52<2:59:33, 118.38s/it]Evaluating gsm8k :  10%|████▎                                      | 10/100 [19:01<3:02:28, 121.65s/it]Evaluating gsm8k :  11%|████▋                                      | 11/100 [21:10<3:03:42, 123.85s/it]Evaluating gsm8k :  12%|█████▏                                     | 12/100 [23:19<3:03:48, 125.32s/it]Evaluating gsm8k :  13%|█████▌                                     | 13/100 [25:02<2:51:44, 118.45s/it]Evaluating gsm8k :  14%|██████                                     | 14/100 [27:12<2:55:00, 122.10s/it]Evaluating gsm8k :  15%|██████▍                                    | 15/100 [28:43<2:39:33, 112.63s/it]Evaluating gsm8k :  16%|██████▉                                    | 16/100 [30:33<2:36:46, 111.98s/it]Evaluating gsm8k :  17%|███████▎                                   | 17/100 [32:11<2:29:10, 107.84s/it]Evaluating gsm8k :  18%|███████▉                                    | 18/100 [33:31<2:15:53, 99.43s/it]Evaluating gsm8k :  19%|████████▏                                  | 19/100 [35:40<2:26:01, 108.17s/it]Evaluating gsm8k :  20%|████████▌                                  | 20/100 [37:50<2:33:07, 114.85s/it]Evaluating gsm8k :  21%|█████████                                  | 21/100 [39:59<2:36:35, 118.93s/it]Evaluating gsm8k :  22%|█████████▍                                 | 22/100 [42:05<2:37:39, 121.28s/it]Evaluating gsm8k :  23%|█████████▉                                 | 23/100 [44:09<2:36:31, 121.97s/it]Evaluating gsm8k :  24%|██████████▎                                | 24/100 [46:17<2:36:54, 123.88s/it]Evaluating gsm8k :  25%|██████████▊                                | 25/100 [48:24<2:36:05, 124.87s/it]Evaluating gsm8k :  26%|███████████▏                               | 26/100 [50:20<2:30:34, 122.09s/it]Evaluating gsm8k :  27%|███████████▌                               | 27/100 [52:30<2:31:18, 124.36s/it]Evaluating gsm8k :  28%|████████████                               | 28/100 [54:38<2:30:38, 125.53s/it]Evaluating gsm8k :  29%|████████████▍                              | 29/100 [56:48<2:30:10, 126.91s/it]Evaluating gsm8k :  30%|████████████▉                              | 30/100 [58:45<2:24:40, 124.00s/it]Evaluating gsm8k :  31%|████████████▋                            | 31/100 [1:00:52<2:23:28, 124.76s/it]Evaluating gsm8k :  32%|█████████████                            | 32/100 [1:02:58<2:21:49, 125.14s/it]Evaluating gsm8k :  33%|█████████████▌                           | 33/100 [1:05:04<2:20:00, 125.38s/it]Evaluating gsm8k :  34%|█████████████▉                           | 34/100 [1:07:09<2:17:43, 125.20s/it]Evaluating gsm8k :  35%|██████████████▎                          | 35/100 [1:08:15<1:56:22, 107.42s/it]Evaluating gsm8k :  36%|██████████████▊                          | 36/100 [1:10:21<2:00:46, 113.22s/it]Evaluating gsm8k :  37%|███████████████▌                          | 37/100 [1:11:19<1:41:14, 96.42s/it]Evaluating gsm8k :  38%|███████████████▌                         | 38/100 [1:13:26<1:49:23, 105.86s/it]Evaluating gsm8k :  39%|███████████████▉                         | 39/100 [1:15:34<1:54:08, 112.28s/it]Evaluating gsm8k :  40%|████████████████▍                        | 40/100 [1:17:42<1:56:56, 116.95s/it]Evaluating gsm8k :  41%|████████████████▊                        | 41/100 [1:18:50<1:40:46, 102.47s/it]Evaluating gsm8k :  42%|█████████████████▏                       | 42/100 [1:20:59<1:46:35, 110.26s/it]Evaluating gsm8k :  43%|█████████████████▋                       | 43/100 [1:23:06<1:49:34, 115.34s/it]Evaluating gsm8k :  44%|██████████████████                       | 44/100 [1:24:14<1:34:27, 101.21s/it]Evaluating gsm8k :  45%|██████████████████▍                      | 45/100 [1:26:01<1:34:24, 103.00s/it]Evaluating gsm8k :  46%|██████████████████▊                      | 46/100 [1:28:08<1:39:10, 110.19s/it]Evaluating gsm8k :  47%|███████████████████▎                     | 47/100 [1:30:16<1:42:01, 115.50s/it]Evaluating gsm8k :  48%|███████████████████▋                     | 48/100 [1:32:21<1:42:38, 118.44s/it]Evaluating gsm8k :  49%|████████████████████                     | 49/100 [1:34:27<1:42:28, 120.57s/it]Evaluating gsm8k :  50%|████████████████████▌                    | 50/100 [1:36:32<1:41:38, 121.97s/it]Evaluating gsm8k :  51%|████████████████████▉                    | 51/100 [1:38:40<1:41:06, 123.80s/it]Evaluating gsm8k :  52%|█████████████████████▎                   | 52/100 [1:40:49<1:40:07, 125.15s/it]Evaluating gsm8k :  53%|█████████████████████▋                   | 53/100 [1:42:54<1:37:59, 125.10s/it]Evaluating gsm8k :  54%|██████████████████████▏                  | 54/100 [1:45:01<1:36:30, 125.87s/it]Evaluating gsm8k :  55%|██████████████████████▌                  | 55/100 [1:46:50<1:30:39, 120.87s/it]Evaluating gsm8k :  56%|███████████████████████▌                  | 56/100 [1:47:32<1:11:13, 97.11s/it]Evaluating gsm8k :  57%|███████████████████████▎                 | 57/100 [1:49:40<1:16:14, 106.37s/it]Evaluating gsm8k :  58%|███████████████████████▊                 | 58/100 [1:51:48<1:18:58, 112.83s/it]Evaluating gsm8k :  59%|████████████████████████▏                | 59/100 [1:53:52<1:19:27, 116.27s/it]Evaluating gsm8k :  60%|████████████████████████▌                | 60/100 [1:56:02<1:20:14, 120.35s/it]Evaluating gsm8k :  61%|█████████████████████████▌                | 61/100 [1:56:38<1:01:50, 95.13s/it]Evaluating gsm8k :  62%|███████████████████████████▎                | 62/100 [1:57:30<51:58, 82.07s/it]Evaluating gsm8k :  63%|███████████████████████████▋                | 63/100 [1:59:02<52:30, 85.16s/it]Evaluating gsm8k :  64%|████████████████████████████▏               | 64/100 [2:00:09<47:40, 79.46s/it]Evaluating gsm8k :  65%|████████████████████████████▌               | 65/100 [2:02:14<54:29, 93.40s/it]Evaluating gsm8k :  66%|█████████████████████████████               | 66/100 [2:03:57<54:30, 96.19s/it]Evaluating gsm8k :  67%|████████████████████████████▊              | 67/100 [2:06:06<58:20, 106.09s/it]Evaluating gsm8k :  68%|███████████████████████████▉             | 68/100 [2:08:15<1:00:12, 112.89s/it]Evaluating gsm8k :  69%|█████████████████████████████▋             | 69/100 [2:09:40<54:01, 104.58s/it]Evaluating gsm8k :  70%|██████████████████████████████▊             | 70/100 [2:10:57<48:02, 96.07s/it]Evaluating gsm8k :  71%|██████████████████████████████▌            | 71/100 [2:13:07<51:28, 106.50s/it]Evaluating gsm8k :  72%|██████████████████████████████▉            | 72/100 [2:15:18<53:03, 113.69s/it]Evaluating gsm8k :  73%|████████████████████████████████            | 73/100 [2:15:41<38:55, 86.50s/it]Evaluating gsm8k :  74%|████████████████████████████████▌           | 74/100 [2:17:50<43:00, 99.24s/it]Evaluating gsm8k :  75%|████████████████████████████████▎          | 75/100 [2:19:56<44:43, 107.36s/it]Evaluating gsm8k :  76%|████████████████████████████████▋          | 76/100 [2:22:04<45:20, 113.36s/it]Evaluating gsm8k :  77%|█████████████████████████████████          | 77/100 [2:24:13<45:17, 118.15s/it]Evaluating gsm8k :  78%|█████████████████████████████████▌         | 78/100 [2:26:21<44:25, 121.17s/it]Evaluating gsm8k :  79%|█████████████████████████████████▉         | 79/100 [2:28:09<41:02, 117.26s/it]Evaluating gsm8k :  80%|██████████████████████████████████▍        | 80/100 [2:30:13<39:42, 119.10s/it]Evaluating gsm8k :  81%|██████████████████████████████████▊        | 81/100 [2:32:21<38:35, 121.85s/it]Evaluating gsm8k :  82%|███████████████████████████████████▎       | 82/100 [2:33:23<31:13, 104.07s/it]Evaluating gsm8k :  83%|███████████████████████████████████▋       | 83/100 [2:35:31<31:28, 111.08s/it]Evaluating gsm8k :  84%|████████████████████████████████████       | 84/100 [2:37:38<30:53, 115.84s/it]Evaluating gsm8k :  85%|████████████████████████████████████▌      | 85/100 [2:39:45<29:48, 119.23s/it]Evaluating gsm8k :  86%|████████████████████████████████████▉      | 86/100 [2:41:53<28:26, 121.86s/it]Evaluating gsm8k :  87%|█████████████████████████████████████▍     | 87/100 [2:43:54<26:22, 121.72s/it]Evaluating gsm8k :  88%|█████████████████████████████████████▊     | 88/100 [2:46:03<24:44, 123.69s/it]Evaluating gsm8k :  89%|██████████████████████████████████████▎    | 89/100 [2:48:10<22:53, 124.83s/it]Evaluating gsm8k :  90%|██████████████████████████████████████▋    | 90/100 [2:50:20<21:03, 126.34s/it]Evaluating gsm8k :  91%|███████████████████████████████████████▏   | 91/100 [2:52:29<19:04, 127.18s/it]Evaluating gsm8k :  92%|███████████████████████████████████████▌   | 92/100 [2:53:39<14:40, 110.03s/it]Evaluating gsm8k :  93%|███████████████████████████████████████▉   | 93/100 [2:55:48<13:28, 115.54s/it]Evaluating gsm8k :  94%|████████████████████████████████████████▍  | 94/100 [2:57:57<11:58, 119.76s/it]Evaluating gsm8k :  95%|████████████████████████████████████████▊  | 95/100 [2:59:38<09:29, 113.96s/it]Evaluating gsm8k :  96%|█████████████████████████████████████████▎ | 96/100 [3:01:45<07:52, 118.12s/it]Evaluating gsm8k :  97%|█████████████████████████████████████████▋ | 97/100 [3:03:54<06:03, 121.30s/it]Evaluating gsm8k :  98%|██████████████████████████████████████████▏| 98/100 [3:05:50<03:59, 119.54s/it]Evaluating gsm8k :  99%|██████████████████████████████████████████▌| 99/100 [3:07:58<02:02, 122.26s/it]Evaluating gsm8k : 100%|██████████████████████████████████████████| 100/100 [3:10:06<00:00, 123.79s/it]Evaluating gsm8k : 100%|██████████████████████████████████████████| 100/100 [3:10:06<00:00, 114.06s/it]
name: gsm8k | avg. gen lenth: 202.056 | time: 11406.503389835358s
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 12355 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o16-tcommonsenseqa-s20-rFalse --seed 20 --max-prompt-length 4096 --num-out-domain 16
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-31 17:17:20,240] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 17:17:20,302] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 2
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o16-tcommonsenseqa-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 16
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o16-tcommonsenseqa-s20-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 97, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 87, in main
    dataset = prepare_dataset_main(args, tokenizer)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 21, in prepare_dataset_main
    return PromptDataset(args, tokenizer, args.data_dir, args.num_eval)
  File "/home/ylu130/workspace/in-context-generalization/data_utils/prompt_datasets.py", line 19, in __init__
    self.data = self.load_data_json(data_path)
  File "/home/ylu130/workspace/in-context-generalization/data_utils/prompt_datasets.py", line 36, in load_data_json
    with open(data_path) as f:
FileNotFoundError: [Errno 2] No such file or directory: '/scratch/ylu130/processed_data/gsm8k/out-domain/o16-tcommonsenseqa-s20-rFalse'
WARNING: /scratch/ylu130/processed_data/gsm8k/out-domain/o16-tcommonsenseqa-s20-rFalse/gsm8k.jsonl does not exist
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 97, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 87, in main
    dataset = prepare_dataset_main(args, tokenizer)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 21, in prepare_dataset_main
    return PromptDataset(args, tokenizer, args.data_dir, args.num_eval)
  File "/home/ylu130/workspace/in-context-generalization/data_utils/prompt_datasets.py", line 19, in __init__
    self.data = self.load_data_json(data_path)
  File "/home/ylu130/workspace/in-context-generalization/data_utils/prompt_datasets.py", line 36, in load_data_json
    with open(data_path) as f:
FileNotFoundError: [Errno 2] No such file or directory: '/scratch/ylu130/processed_data/gsm8k/out-domain/o16-tcommonsenseqa-s20-rFalse'
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 1334990) of binary: /home/ylu130/.conda/envs/ood/bin/python
Traceback (most recent call last):
  File "/home/ylu130/.conda/envs/ood/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/run.py", line 794, in main
    run(args)
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/ylu130/workspace/in-context-generalization/inference.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-08-31_17:17:23
  host      : ia1.wse.jhu.edu
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 1334991)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-08-31_17:17:23
  host      : ia1.wse.jhu.edu
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 1334990)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 12355 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o1-tcommonsenseqa-s30-rFalse --seed 30 --max-prompt-length 4096 --num-out-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-31 17:17:26,707] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 17:17:26,707] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 2
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o1-tcommonsenseqa-s30-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 1
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o1-tcommonsenseqa-s30-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading data:   0%|                                                           | 0/7473 [00:00<?, ?it/s]Loading data: 100%|███████████████████████████████████████████| 7473/7473 [00:00<00:00, 1155540.42it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                                 | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                 | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|████████████████████▌                    | 1/2 [00:06<00:06,  6.66s/it]Loading checkpoint shards:  50%|████████████████████▌                    | 1/2 [00:06<00:06,  6.70s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  3.96s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  4.37s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  3.95s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  4.37s/it]
 > number of parameters: 6738415616
[2023-08-31 17:17:36,527] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 17:17:36,554] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 17:17:37,038] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-31 17:17:37,039] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f1a5bfc52a0>
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-31 17:17:37,040] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   train_batch_size ............. 2
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   world_size ................... 2
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-31 17:17:37,041] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-31 17:17:37,041] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating gsm8k :   0%|                                                       | 0/100 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following grade math question.

Input: The lab results had been compiled, the scientist began analysing the data because he wanted what? Choices:  A: learn more about B: headache C: do math D: enlightened E: better understanding
Output: E: better understanding

Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o1-tcommonsenseqa-s30-rFalse-m4096
Evaluating gsm8k :   1%|▍                                           | 1/100 [02:24<3:58:03, 144.27s/it]Evaluating gsm8k :   2%|▉                                           | 2/100 [04:43<3:50:54, 141.37s/it]Evaluating gsm8k :   3%|█▎                                          | 3/100 [07:06<3:49:32, 141.98s/it]Evaluating gsm8k :   4%|█▊                                          | 4/100 [08:51<3:23:39, 127.28s/it]Evaluating gsm8k :   5%|██▏                                         | 5/100 [10:08<2:53:11, 109.38s/it]Evaluating gsm8k :   6%|██▋                                         | 6/100 [12:31<3:08:59, 120.64s/it]Evaluating gsm8k :   7%|███                                         | 7/100 [14:51<3:16:48, 126.97s/it]Evaluating gsm8k :   8%|███▌                                        | 8/100 [17:12<3:21:53, 131.67s/it]Evaluating gsm8k :   9%|███▉                                        | 9/100 [18:25<2:51:36, 113.15s/it]Evaluating gsm8k :  10%|████▎                                      | 10/100 [20:44<3:01:40, 121.12s/it]Evaluating gsm8k :  11%|████▋                                      | 11/100 [23:06<3:09:01, 127.43s/it]Evaluating gsm8k :  12%|█████▏                                     | 12/100 [25:27<3:12:59, 131.58s/it]Evaluating gsm8k :  13%|█████▌                                     | 13/100 [27:45<3:13:48, 133.66s/it]Evaluating gsm8k :  14%|██████                                     | 14/100 [30:04<3:13:51, 135.24s/it]Evaluating gsm8k :  15%|██████▍                                    | 15/100 [32:23<3:13:15, 136.42s/it]Evaluating gsm8k :  16%|██████▉                                    | 16/100 [34:46<3:13:52, 138.48s/it]Evaluating gsm8k :  17%|███████▎                                   | 17/100 [37:03<3:10:38, 137.81s/it]Evaluating gsm8k :  18%|███████▋                                   | 18/100 [39:24<3:09:41, 138.80s/it]Evaluating gsm8k :  19%|████████▏                                  | 19/100 [41:42<3:07:07, 138.61s/it]Evaluating gsm8k :  20%|████████▌                                  | 20/100 [44:01<3:05:06, 138.83s/it]Evaluating gsm8k :  21%|█████████                                  | 21/100 [45:35<2:44:59, 125.31s/it]Evaluating gsm8k :  22%|█████████▍                                 | 22/100 [47:59<2:50:00, 130.77s/it]Evaluating gsm8k :  23%|█████████▉                                 | 23/100 [50:19<2:51:21, 133.52s/it]Evaluating gsm8k :  24%|██████████▎                                | 24/100 [52:38<2:51:15, 135.20s/it]Evaluating gsm8k :  25%|██████████▊                                | 25/100 [54:56<2:50:14, 136.20s/it]Evaluating gsm8k :  26%|███████████▏                               | 26/100 [56:04<2:22:40, 115.69s/it]Evaluating gsm8k :  27%|███████████▌                               | 27/100 [58:25<2:30:01, 123.31s/it]Evaluating gsm8k :  28%|███████████▍                             | 28/100 [1:00:46<2:34:15, 128.54s/it]Evaluating gsm8k :  29%|███████████▉                             | 29/100 [1:03:05<2:36:02, 131.87s/it]Evaluating gsm8k :  30%|████████████▎                            | 30/100 [1:05:26<2:36:45, 134.36s/it]Evaluating gsm8k :  31%|████████████▋                            | 31/100 [1:07:03<2:21:50, 123.34s/it]Evaluating gsm8k :  32%|█████████████                            | 32/100 [1:09:24<2:25:33, 128.43s/it]Evaluating gsm8k :  33%|█████████████▌                           | 33/100 [1:11:44<2:27:29, 132.09s/it]Evaluating gsm8k :  34%|█████████████▉                           | 34/100 [1:14:03<2:27:34, 134.15s/it]Evaluating gsm8k :  35%|██████████████▎                          | 35/100 [1:16:24<2:27:36, 136.25s/it]Evaluating gsm8k :  36%|██████████████▊                          | 36/100 [1:18:46<2:26:57, 137.77s/it]Evaluating gsm8k :  37%|███████████████▏                         | 37/100 [1:21:04<2:24:52, 137.98s/it]Evaluating gsm8k :  38%|███████████████▌                         | 38/100 [1:23:23<2:22:45, 138.15s/it]Evaluating gsm8k :  39%|███████████████▉                         | 39/100 [1:25:40<2:20:04, 137.78s/it]Evaluating gsm8k :  40%|████████████████▍                        | 40/100 [1:27:42<2:13:04, 133.08s/it]Evaluating gsm8k :  41%|████████████████▊                        | 41/100 [1:29:25<2:01:56, 124.01s/it]Evaluating gsm8k :  42%|█████████████████▏                       | 42/100 [1:31:45<2:04:33, 128.85s/it]Evaluating gsm8k :  43%|█████████████████▋                       | 43/100 [1:34:03<2:05:10, 131.77s/it]Evaluating gsm8k :  44%|██████████████████                       | 44/100 [1:36:21<2:04:42, 133.62s/it]Evaluating gsm8k :  45%|██████████████████▍                      | 45/100 [1:38:41<2:04:05, 135.38s/it]Evaluating gsm8k :  46%|██████████████████▊                      | 46/100 [1:41:01<2:03:17, 136.99s/it]Evaluating gsm8k :  47%|███████████████████▎                     | 47/100 [1:43:23<2:02:09, 138.30s/it]Evaluating gsm8k :  48%|███████████████████▋                     | 48/100 [1:45:45<2:00:47, 139.37s/it]Evaluating gsm8k :  49%|████████████████████                     | 49/100 [1:47:27<1:49:07, 128.39s/it]Evaluating gsm8k :  50%|████████████████████▌                    | 50/100 [1:49:44<1:48:59, 130.79s/it]Evaluating gsm8k :  51%|████████████████████▉                    | 51/100 [1:52:02<1:48:33, 132.94s/it]Evaluating gsm8k :  52%|█████████████████████▎                   | 52/100 [1:54:24<1:48:29, 135.62s/it]Evaluating gsm8k :  53%|█████████████████████▋                   | 53/100 [1:56:16<1:40:45, 128.62s/it]Evaluating gsm8k :  54%|██████████████████████▏                  | 54/100 [1:58:26<1:38:56, 129.05s/it]Evaluating gsm8k :  55%|██████████████████████▌                  | 55/100 [2:00:48<1:39:40, 132.90s/it]Evaluating gsm8k :  56%|██████████████████████▉                  | 56/100 [2:02:07<1:25:42, 116.87s/it]Evaluating gsm8k :  57%|███████████████████████▎                 | 57/100 [2:04:25<1:28:16, 123.18s/it]Evaluating gsm8k :  58%|███████████████████████▊                 | 58/100 [2:06:45<1:29:43, 128.17s/it]Evaluating gsm8k :  59%|████████████████████████▏                | 59/100 [2:08:41<1:25:02, 124.45s/it]Evaluating gsm8k :  60%|████████████████████████▌                | 60/100 [2:11:02<1:26:19, 129.48s/it]Evaluating gsm8k :  61%|█████████████████████████                | 61/100 [2:13:25<1:26:53, 133.67s/it]Evaluating gsm8k :  62%|█████████████████████████▍               | 62/100 [2:15:44<1:25:33, 135.08s/it]Evaluating gsm8k :  63%|█████████████████████████▊               | 63/100 [2:18:04<1:24:19, 136.73s/it]Evaluating gsm8k :  64%|██████████████████████████▏              | 64/100 [2:20:22<1:22:14, 137.08s/it]Evaluating gsm8k :  65%|██████████████████████████▋              | 65/100 [2:22:26<1:17:35, 133.01s/it]Evaluating gsm8k :  66%|███████████████████████████              | 66/100 [2:24:46<1:16:32, 135.07s/it]Evaluating gsm8k :  67%|███████████████████████████▍             | 67/100 [2:27:03<1:14:43, 135.87s/it]Evaluating gsm8k :  68%|███████████████████████████▉             | 68/100 [2:29:20<1:12:38, 136.20s/it]Evaluating gsm8k :  69%|████████████████████████████▎            | 69/100 [2:31:40<1:10:50, 137.11s/it]Evaluating gsm8k :  70%|████████████████████████████▋            | 70/100 [2:33:55<1:08:18, 136.63s/it]Evaluating gsm8k :  71%|█████████████████████████████            | 71/100 [2:36:16<1:06:35, 137.77s/it]Evaluating gsm8k :  72%|██████████████████████████████▉            | 72/100 [2:37:02<51:30, 110.37s/it]Evaluating gsm8k :  73%|███████████████████████████████▍           | 73/100 [2:39:20<53:25, 118.73s/it]Evaluating gsm8k :  74%|███████████████████████████████▊           | 74/100 [2:41:25<52:11, 120.45s/it]Evaluating gsm8k :  75%|█████████████████████████████████           | 75/100 [2:42:12<41:06, 98.64s/it]Evaluating gsm8k :  76%|████████████████████████████████▋          | 76/100 [2:44:34<44:32, 111.37s/it]Evaluating gsm8k :  77%|█████████████████████████████████          | 77/100 [2:46:55<46:10, 120.45s/it]Evaluating gsm8k :  78%|█████████████████████████████████▌         | 78/100 [2:49:13<46:06, 125.75s/it]Evaluating gsm8k :  79%|█████████████████████████████████▉         | 79/100 [2:50:41<40:00, 114.31s/it]Evaluating gsm8k :  80%|██████████████████████████████████▍        | 80/100 [2:53:02<40:45, 122.29s/it]Evaluating gsm8k :  81%|██████████████████████████████████▊        | 81/100 [2:55:21<40:18, 127.30s/it]Evaluating gsm8k :  82%|███████████████████████████████████▎       | 82/100 [2:57:39<39:11, 130.63s/it]Evaluating gsm8k :  83%|███████████████████████████████████▋       | 83/100 [3:00:02<38:00, 134.16s/it]Evaluating gsm8k :  84%|████████████████████████████████████       | 84/100 [3:02:22<36:18, 136.14s/it]Evaluating gsm8k :  85%|████████████████████████████████████▌      | 85/100 [3:04:40<34:09, 136.63s/it]Evaluating gsm8k :  86%|████████████████████████████████████▉      | 86/100 [3:06:59<32:01, 137.28s/it]Evaluating gsm8k :  87%|█████████████████████████████████████▍     | 87/100 [3:09:18<29:50, 137.69s/it]Evaluating gsm8k :  88%|█████████████████████████████████████▊     | 88/100 [3:11:37<27:38, 138.22s/it]Evaluating gsm8k :  89%|██████████████████████████████████████▎    | 89/100 [3:13:56<25:24, 138.57s/it]Evaluating gsm8k :  90%|██████████████████████████████████████▋    | 90/100 [3:16:14<23:02, 138.28s/it]Evaluating gsm8k :  91%|███████████████████████████████████████▏   | 91/100 [3:17:19<17:27, 116.39s/it]Evaluating gsm8k :  92%|███████████████████████████████████████▌   | 92/100 [3:19:39<16:26, 123.35s/it]Evaluating gsm8k :  93%|███████████████████████████████████████▉   | 93/100 [3:21:59<14:57, 128.28s/it]Evaluating gsm8k :  94%|████████████████████████████████████████▍  | 94/100 [3:24:19<13:12, 132.00s/it]Evaluating gsm8k :  95%|████████████████████████████████████████▊  | 95/100 [3:26:36<11:07, 133.51s/it]Evaluating gsm8k :  96%|█████████████████████████████████████████▎ | 96/100 [3:28:57<09:02, 135.65s/it]Evaluating gsm8k :  97%|█████████████████████████████████████████▋ | 97/100 [3:31:17<06:50, 136.93s/it]Evaluating gsm8k :  98%|██████████████████████████████████████████▏| 98/100 [3:33:36<04:35, 137.66s/it]Evaluating gsm8k :  99%|██████████████████████████████████████████▌| 99/100 [3:35:55<02:18, 138.05s/it]Evaluating gsm8k : 100%|██████████████████████████████████████████| 100/100 [3:37:53<00:00, 132.07s/it]Evaluating gsm8k : 100%|██████████████████████████████████████████| 100/100 [3:37:53<00:00, 130.74s/it]
name: gsm8k | avg. gen lenth: 256.552 | time: 13074.388234615326s
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 12355 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 5 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o2-tcommonsenseqa-s30-rFalse --seed 30 --max-prompt-length 4096 --num-out-domain 2
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-31 20:55:37,564] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-31 20:55:37,637] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 2
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... False
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o2-tcommonsenseqa-s30-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 2
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o2-tcommonsenseqa-s30-rFalse-m4096
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 5
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading data:   0%|                                                           | 0/7473 [00:00<?, ?it/s]Loading data: 100%|███████████████████████████████████████████| 7473/7473 [00:00<00:00, 1081388.09it/s]
Num instances: 1000
Loading checkpoint shards:   0%|                                                 | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                 | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|████████████████████▌                    | 1/2 [00:06<00:06,  6.52s/it]Loading checkpoint shards:  50%|████████████████████▌                    | 1/2 [00:06<00:06,  6.87s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  3.85s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  4.25s/it]
 > number of parameters: 6738415616
[2023-08-31 20:55:47,378] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  4.01s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████| 2/2 [00:08<00:00,  4.44s/it]
[2023-08-31 20:55:47,775] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-08-31 20:55:48,226] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-31 20:55:48,227] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   amp_params ................... False
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f4abb3c5300>
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   dump_state ................... False
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-08-31 20:55:48,228] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   pld_params ................... False
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   train_batch_size ............. 2
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   world_size ................... 2
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-08-31 20:55:48,229] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-08-31 20:55:48,229] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating gsm8k :   0%|                                                       | 0/100 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following grade math question.

Input: The lab results had been compiled, the scientist began analysing the data because he wanted what? Choices:  A: learn more about B: headache C: do math D: enlightened E: better understanding
Output: E: better understanding

Input: I needed to find out how to contact a person with a certain name, where should I look? Choices:  A: directory B: michigan C: roster D: phone book E: certificate
Output: D: phone book

Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o2-tcommonsenseqa-s30-rFalse-m4096
Evaluating gsm8k :   1%|▍                                           | 1/100 [01:42<2:49:36, 102.79s/it]Evaluating gsm8k :   2%|▉                                           | 2/100 [03:58<3:19:58, 122.43s/it]Evaluating gsm8k :   3%|█▎                                          | 3/100 [06:13<3:26:58, 128.03s/it]Evaluating gsm8k :   4%|█▊                                          | 4/100 [08:31<3:30:54, 131.82s/it]Evaluating gsm8k :   5%|██▏                                         | 5/100 [09:58<3:03:06, 115.65s/it]Evaluating gsm8k :   6%|██▋                                         | 6/100 [12:14<3:12:07, 122.63s/it]Evaluating gsm8k :   7%|███                                         | 7/100 [13:19<2:40:48, 103.75s/it]Evaluating gsm8k :   8%|███▌                                        | 8/100 [15:34<2:54:15, 113.65s/it]Evaluating gsm8k :   9%|███▉                                        | 9/100 [17:52<3:04:16, 121.50s/it]Evaluating gsm8k :  10%|████▍                                       | 10/100 [18:39<2:27:29, 98.33s/it]Evaluating gsm8k :  11%|████▊                                       | 11/100 [19:16<1:57:51, 79.45s/it]Evaluating gsm8k :  12%|█████▎                                      | 12/100 [21:36<2:23:37, 97.92s/it]Evaluating gsm8k :  13%|█████▌                                     | 13/100 [23:54<2:39:49, 110.22s/it]Evaluating gsm8k :  14%|██████                                     | 14/100 [26:11<2:49:25, 118.21s/it]Evaluating gsm8k :  15%|██████▍                                    | 15/100 [28:26<2:54:43, 123.34s/it]Evaluating gsm8k :  16%|██████▉                                    | 16/100 [30:45<2:59:20, 128.10s/it]Evaluating gsm8k :  17%|███████▎                                   | 17/100 [33:02<3:00:51, 130.74s/it]Evaluating gsm8k :  18%|███████▋                                   | 18/100 [35:22<3:02:28, 133.52s/it]Evaluating gsm8k :  19%|████████▏                                  | 19/100 [37:40<3:02:01, 134.83s/it]Evaluating gsm8k :  20%|████████▌                                  | 20/100 [39:36<2:52:07, 129.09s/it]Evaluating gsm8k :  21%|█████████                                  | 21/100 [41:56<2:54:34, 132.58s/it]Evaluating gsm8k :  22%|█████████▍                                 | 22/100 [44:14<2:54:06, 133.93s/it]Evaluating gsm8k :  23%|█████████▉                                 | 23/100 [46:30<2:52:46, 134.62s/it]Evaluating gsm8k :  24%|██████████▎                                | 24/100 [48:43<2:50:07, 134.31s/it]Evaluating gsm8k :  25%|██████████▊                                | 25/100 [50:59<2:48:28, 134.78s/it]Evaluating gsm8k :  26%|███████████▏                               | 26/100 [53:14<2:46:22, 134.90s/it]Evaluating gsm8k :  27%|███████████▌                               | 27/100 [54:45<2:27:56, 121.59s/it]Evaluating gsm8k :  28%|████████████                               | 28/100 [57:04<2:32:07, 126.77s/it]Evaluating gsm8k :  29%|████████████▍                              | 29/100 [57:42<1:58:39, 100.27s/it]Evaluating gsm8k :  30%|████████████▎                            | 30/100 [1:00:02<2:10:50, 112.14s/it]Evaluating gsm8k :  31%|████████████▋                            | 31/100 [1:02:19<2:17:33, 119.62s/it]Evaluating gsm8k :  32%|█████████████                            | 32/100 [1:04:37<2:21:47, 125.10s/it]Evaluating gsm8k :  33%|█████████████▌                           | 33/100 [1:06:55<2:23:50, 128.81s/it]Evaluating gsm8k :  34%|█████████████▉                           | 34/100 [1:09:09<2:23:32, 130.49s/it]Evaluating gsm8k :  35%|██████████████▎                          | 35/100 [1:11:27<2:23:44, 132.68s/it]Evaluating gsm8k :  36%|██████████████▊                          | 36/100 [1:13:45<2:23:12, 134.25s/it]Evaluating gsm8k :  37%|███████████████▏                         | 37/100 [1:16:02<2:22:01, 135.25s/it]Evaluating gsm8k :  38%|███████████████▌                         | 38/100 [1:18:18<2:19:48, 135.30s/it]Evaluating gsm8k :  39%|███████████████▉                         | 39/100 [1:20:34<2:17:51, 135.60s/it]Evaluating gsm8k :  40%|████████████████▍                        | 40/100 [1:22:50<2:15:36, 135.61s/it]Evaluating gsm8k :  41%|████████████████▊                        | 41/100 [1:25:08<2:14:05, 136.37s/it]Evaluating gsm8k :  42%|█████████████████▏                       | 42/100 [1:27:27<2:12:47, 137.38s/it]Evaluating gsm8k :  43%|█████████████████▋                       | 43/100 [1:29:43<2:09:51, 136.69s/it]Evaluating gsm8k :  44%|██████████████████                       | 44/100 [1:31:56<2:06:33, 135.60s/it]^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B[?2004h(base) [01;32mylu130@ia1[00m:[01;34m~/workspace/in-context-generalization[00m$ vim tree.pyls[Kcd /home/ylu130/.conda/envs/got/lib/python3.9/site-packages/treelib/[A(base) [01;32mylu130@ia1[00m:[01;34m~/workspace/in-context-generalization[00m$ python[K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[1Pcd ..[3Plscd ..pythoncd /home/ylu130/.conda/envs/got/lib/python3.9/site-packages/treelib/[A(base) [01;32mylu130@ia1[00m:[01;34m~/workspace/in-context-generalization[00m$ ls[K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cvim tree.py[Kscreen -ls
[?2004lThere are screens on:
	639400.pts-0.ia1	(08/30/2023 12:31:13 AM)	(Attached)
	624355.pts-0.ia1	(08/30/2023 12:26:53 AM)	(Detached)
	604043.pts-4.ia1	(08/30/2023 12:13:48 AM)	(Detached)
3 Sockets in /run/screen/S-ylu130.
[?2004h(base) [01;32mylu130@ia1[00m:[01;34m~/workspace/in-context-generalization[00m$ screen -r 639400
[?2004lThere is a screen on:
	639400.pts-0.ia1	(08/30/2023 12:31:13 AM)	(Attached)
There is no screen to be resumed matching 639400.
[?2004h(base) [01;32mylu130@ia1[00m:[01;34m~/workspace/in-context-generalization[00m$ screen -r 639400-639400d639400 639400
[?2004lAttaching from inside of screen?
[?2004h(base) [01;32mylu130@ia1[00m:[01;34m~/workspace/in-context-generalization[00m$ screen -r -d 639400[3P639400ls[Kvim tree.py[1Pscreen -ls
[?2004lThere are screens on:
	639400.pts-0.ia1	(08/30/2023 12:31:13 AM)	(Attached)
	624355.pts-0.ia1	(08/30/2023 12:26:53 AM)	(Detached)
	604043.pts-4.ia1	(08/30/2023 12:13:48 AM)	(Detached)
3 Sockets in /run/screen/S-ylu130.
[?2004h(base) [01;32mylu130@ia1[00m:[01;34m~/workspace/in-context-generalization[00m$ screen -lsr -d 639400[1P 639400[1P 639400[1P639400D 639400
[?2004lAttaching from inside of screen?
[?2004h(base) [01;32mylu130@ia1[00m:[01;34m~/workspace/in-context-generalization[00m$ screen -rD 639400[C[1P 639400d 639400
[?2004lAttaching from inside of screen?
[?2004h(base) [01;32mylu130@ia1[00m:[01;34m~/workspace/in-context-generalization[00m$ screen -rd 639400[C[1P 639400[1P 639400x 639400
[?2004lAttaching from inside of screen?
[?2004h(base) [01;32mylu130@ia1[00m:[01;34m~/workspace/in-context-generalization[00m$ screen -x 639400[1@rd[C[C[C[C[C[C[CD[C[C[C[C[C[C[Cls[Kr -d 639400ls[K
[?2004lThere are screens on:
	639400.pts-0.ia1	(08/30/2023 12:31:13 AM)	(Attached)
	624355.pts-0.ia1	(08/30/2023 12:26:53 AM)	(Detached)
	604043.pts-4.ia1	(08/30/2023 12:13:48 AM)	(Detached)
3 Sockets in /run/screen/S-ylu130.
[?2004h(base) [01;32mylu130@ia1[00m:[01;34m~/workspace/in-context-generalization[00m$ screen -lsx 639400[1@rd[C[C[C[C[C[C[CD[C[C[C[C[C[C[Cd[C[C[C[C[C[C[C[1Px[C[C[C[C[C[C[Cls[K[Kscreen -lsx 639400ls[K[Knvidiat[K s[K[K-smi
[?2004lThu Aug 31 22:29:59 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA RTX A6000               Off | 00000000:14:00.0 Off |                  Off |
| 30%   57C    P2             163W / 300W |  46298MiB / 49140MiB |     41%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA RTX A6000               Off | 00000000:24:00.0 Off |                  Off |
| 30%   49C    P2             144W / 300W |  46298MiB / 49140MiB |     34%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   2  NVIDIA RTX A6000               Off | 00000000:27:00.0 Off |                  Off |
| 30%   57C    P2             164W / 300W |  46268MiB / 49140MiB |     29%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   3  NVIDIA RTX A6000               Off | 00000000:2A:00.0 Off |                  Off |
| 30%   59C    P2             146W / 300W |  46292MiB / 49140MiB |     13%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   4  NVIDIA RTX A6000               Off | 00000000:2B:00.0 Off |                  Off |
| 30%   59C    P2             152W / 300W |  46266MiB / 49140MiB |     23%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   5  NVIDIA RTX A6000               Off | 00000000:88:00.0 Off |                  Off |
| 30%   53C    P2             156W / 300W |  46242MiB / 49140MiB |     15%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   6  NVIDIA RTX A6000               Off | 00000000:98:00.0 Off |                  Off |
| 34%   63C    P2             202W / 300W |  46174MiB / 49140MiB |     40%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   7  NVIDIA RTX A6000               Off | 00000000:9B:00.0 Off |                  Off |
| 39%   68C    P2             204W / 300W |  46182MiB / 49140MiB |     39%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   8  NVIDIA RTX A6000               Off | 00000000:9E:00.0 Off |                  Off |
| 30%   58C    P2             196W / 300W |  46184MiB / 49140MiB |     40%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   9  NVIDIA RTX A6000               Off | 00000000:9F:00.0 Off |                  Off |
| 38%   68C    P2             212W / 300W |  46146MiB / 49140MiB |     57%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A   1393519      C   ...e/ylu130/.conda/envs/ood/bin/python    46290MiB |
|    1   N/A  N/A   1393520      C   ...e/ylu130/.conda/envs/ood/bin/python    46290MiB |
|    2   N/A  N/A   1399462      C   ...e/ylu130/.conda/envs/ood/bin/python    46260MiB |
|    3   N/A  N/A   1399463      C   ...e/ylu130/.conda/envs/ood/bin/python    46284MiB |
|    4   N/A  N/A   1399464      C   ...e/ylu130/.conda/envs/ood/bin/python    46258MiB |
|    5   N/A  N/A   1399465      C   ...e/ylu130/.conda/envs/ood/bin/python    46234MiB |
|    6   N/A  N/A   1418749      C   ...e/ylu130/.conda/envs/ood/bin/python    46166MiB |
|    7   N/A  N/A   1418750      C   ...e/ylu130/.conda/envs/ood/bin/python    46174MiB |
|    8   N/A  N/A   1418751      C   ...e/ylu130/.conda/envs/ood/bin/python    46176MiB |
|    9   N/A  N/A   1418752      C   ...e/ylu130/.conda/envs/ood/bin/python    46138MiB |
+---------------------------------------------------------------------------------------+
Evaluating gsm8k :  45%|██████████████████▍                      | 45/100 [1:34:11<2:04:22, 135.68s/it]^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A[?2004h(base) [01;32mylu130@ia1[00m:[01;34m~/workspace/in-context-generalization[00m$ nvidia-smiscreen -lsx 639400[1@rd[C[C[C[C[C[C[CD[C[C[C[C[C[C[Cls[Kr -d 639400[3P639400ls[Kvim tree.pyls[Kcd /home/ylu130/.conda/envs/got/lib/python3.9/site-packages/treelib/[A(base) [01;32mylu130@ia1[00m:[01;34m~/workspace/in-context-generalization[00m$ python[K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[1Pcd ..[3Plscd lib/ls[Kcd ..[3Plscd bin[4Plscd ..[3Plscd lib[4Plscd /home/ylu130/.conda/envs/got[13Pecho $CONDA_PREFIXls[K[Kcd ~[2Plscd lib[4Plscd /usr/ls[Kconda activate gotpython visualize.py [2Pconda activate gotpython -m pip install treelib[10P[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[1Pconda activate gotls /scratch/ylu130/data/entailment_trees_emnlp2021_data_v3/dataset/task_1/[C[C[C[C[C[C[C[C[C[Kdataset/task_1/[A(base) [01;32mylu130@ia1[00m:[01;34m~/workspace/in-context-generalization[00m$ [32Pconda activate got
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpip install treelib[10@ython -m p[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[11Pconda activate gotpython visualize.py [2Pconda activate gotls[Kcd /usr/ls[Kcd lib[4Plscd ~l[Ksecho $CONDA_PREFIXcd /home/ylu130/.conda/envs/gotls[Kcd lib[4Plscd ..[3Plscd lib[4Plscd /home/ylu130/.conda/envs/got[13Pecho $CONDA_PREFIXls[K[Kcd ~[2Plscd lib[4Plscd /usr/ls[Kconda activate gotpython visualize.py [2Pconda activate gotpython -m pip install treelib[10P[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[1Pconda activate gotls /scratch/ylu130/data/entailment_trees_emnlp2021_data_v3/dataset/task_1/[C[C[C[C[C[C[C[C[C[K[A(base) [01;32mylu130@ia1[00m:[01;34m~/workspace/in-context-generalization[00m$ [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cmodel-hf/[Kconda activate gotpwd[KPWDconda activate got[10Pgit pushcommit -m "update"add .[K.ls[Kcd GraphReasoning/[9Pgit add .,[4Pcd ..git commit -m "Revert to 9d7fa437f09eb7dc74623c81c057ef79bb306af1"[A(base) [01;32mylu130@ia1[00m:[01;34m~/workspace/in-context-generalization[00m$ [C[C[C[C[23Preset --soft "HEAD@{1}"
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Khard 9d7fa437f09eb7dc74623c81c057ef79bb306af1[A(base) [01;32mylu130@ia1[00m:[01;34m~/workspace/in-context-generalization[00m$ [32Pconda activate got
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[10Pgit pullconda activate ood[8Pscreen -lsconda activate gotls[K /scratch/ylu130/data/entailment_trees_emnlp2021_data_v3/[A(base) [01;32mylu130@ia1[00m:[01;34m~/workspace/in-context-generalization[00m$ [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[6Pconda activate got[4Penv list[4Pscreen -ls[2Pgit pullscreen -lsnvidia-smiscreen -L -Logfile ./screen_log/llama2-7b/gsm8k_csqa_ood1-2-4-8-16_f_4096.txt bash ./scripts/model/llama2-7b/out-domain/commonsenseqa/inference_gsm8k.sh [Anvidia-smi[K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cividia-smiscreen -L -Logfile ./screen_log/llama2-7b/csqa_id0-9_tf_4096.txt bash ./scripts/model/llama2-7b/in-domain/inference_commonsenseqa.sh [A[7Pconda activate /home/ylu130/.conda/envs/ood
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cood[Kvim /home/ylu130/.bashrcconda activate /home/ylu130/.conda/envs/oodpowershell[Kactivate ood[8Pinitactivate /home/ylu130/.conda/envs/oodood[K[4Penv listinit bashactivate ood[2Pscreen -r 620936conda activate ood[3Pinit bash[1Penv listactivate ood/home/ylu130/.conda/envs/oodinit[Kactivate ood[2Ppowershellactivate /home/ylu130/.conda/envs/ood[19Pvim /home/ylu130/.bashrc[6Pconda activate ood/home/ylu130/.conda/envs/oodscreen -L -Logfile ./screen_log/llama2-7b/csqa_id0-9_tf_4096.txt bash ./scripts/model/llama2-7b/in-domain/inference_commonsenseqa.sh [Anividia-smi[K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[1Pvidia-smiscreen -L -Logfile ./screen_log/llama2-7b/gsm8k_csqa_ood1-2-4-8-16_f_4096.txt bash ./scripts/model/llama2-7b/out-domain/commonsenseqa/inference_gsm8k.sh [Anvidia-smi[K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cscreen -ls[2Pgit pullscreen -lsconda env listactivate gotls /scratch/ylu130/data/entailment_trees_emnlp2021_data_v3/[A(base) [01;32mylu130@ia1[00m:[01;34m~/workspace/in-context-generalization[00m$ [C[C[K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cconda activate got[8Pscreen -lsconda activate ood[10Pgit pullconda activate gotgit reset --hard 9d7fa437f09eb7dc74623c81c057ef79bb306af1[A(base) [01;32mylu130@ia1[00m:[01;34m~/workspace/in-context-generalization[00m$ [C[C[C[C[C[C[C[C[C[C[C[C[24Psoft "HEAD@{1}
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C"commit -m "Revert to 9d7fa437f09eb7dc74623c81c057ef79bb306af1"[A(base) [01;32mylu130@ia1[00m:[01;34m~/workspace/in-context-generalization[00m$ cd ..[K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cgit add ,.cd GraphReasoning/ls[Kgit add ..[Kcommit -m "update"push[Kconda activate gotPWD[Kpwdconda activate gotls[K /scratch/ylu130/model-hf/[4Pdata/entailment_trees_emnlp2021_data_v3/dataset/task_1/[A(base) [01;32mylu130@ia1[00m:[01;34m~/workspace/in-context-generalization[00m$ [32Pconda activate got
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpip install treelib[10@ython -m p[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[11Pconda activate gotpython visualize.py [2Pconda activate gotls[Kcd /usr/ls[Kcd lib[4Plscd ~l[Ksecho $CONDA_PREFIXcd /home/ylu130/.conda/envs/gotls[Kcd lib[4Plscd ..[3Plscd bin[4Plscd ..[3Plscd lib/ls[Kcd ..pythoncd /home/ylu130/.conda/envs/got/lib/python3.9/site-packages/treelib/[A(base) [01;32mylu130@ia1[00m:[01;34m~/workspace/in-context-generalization[00m$ ls[K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cvim tree.py[1Pscreen -lsr 639400-d 639400ls[KrD 639400d[C[C[C[C[C[C[C[1Px[C[C[C[C[C[C[Cls[Knvidia-smi[Knvidia-smiscreen -ls
[?2004lThere are screens on:
	639400.pts-0.ia1	(08/30/2023 12:31:14 AM)	(Attached)
	624355.pts-0.ia1	(08/30/2023 12:26:54 AM)	(Detached)
	604043.pts-4.ia1	(08/30/2023 12:13:49 AM)	(Detached)
3 Sockets in /run/screen/S-ylu130.
[?2004h(base) [01;32mylu130@ia1[00m:[01;34m~/workspace/in-context-generalization[00m$ screen -X -S SCREENID kill[1P kill[1P kill[1P kill[1P kill[1P kill[1P kill[1P kill[1P kill639400 kill[C
[?2004l^CTraceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 97, in <module>
Evaluating gsm8k :  45%|██████████████████▍                      | 45/100 [1:35:25<1:56:38, 127.24s/it]
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 94, in main
    inference_main(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 90, in inference_main
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 97, in <module>
    query_ids, response_ids, answers, indices = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 65, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 94, in main
    inference_main(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 90, in inference_main
    query_ids, response_ids, answers, indices = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 65, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
WARNING:torch.distributed.elastic.agent.server.api:Received 2 death signal, shutting down workers
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2509, in sample
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2509, in sample
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1393519 closing signal SIGINT
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/logits_process.py", line 92, in __call__
    next_token_scores = logits_processor(input_ids, next_token_logits)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/logits_process.py", line 92, in __call__
    scores = processor(input_ids, scores)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/logits_process.py", line 487, in __call__
    scores = processor(input_ids, scores)
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1393520 closing signal SIGINT
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/logits_process.py", line 487, in __call__
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/logits_process.py", line 460, in _calc_banned_ngram_tokens
    banned_batch_tokens = _calc_banned_ngram_tokens(self.ngram_size, input_ids, num_batch_hypotheses, cur_len)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/logits_process.py", line 460, in _calc_banned_ngram_tokens
        generated_ngrams = _get_ngrams(ngram_size, prev_input_ids, num_hypos)generated_ngrams = _get_ngrams(ngram_size, prev_input_ids, num_hypos)

  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/logits_process.py", line 441, in _get_ngrams
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/logits_process.py", line 441, in _get_ngrams
        generated_ngram[prev_ngram_tuple] = generated_ngram.get(prev_ngram_tuple, []) + [ngram[-1]]generated_ngram[prev_ngram_tuple] = generated_ngram.get(prev_ngram_tuple, []) + [ngram[-1]]

KeyboardInterrupt
KeyboardInterrupt
^CWARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1393520 closing signal SIGTERM
^CTraceback (most recent call last):
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 723, in run
    result = self._invoke_run(role)
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 864, in _invoke_run
    time.sleep(monitor_interval)
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 62, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 1393443 got signal: 2

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 730, in run
    self._shutdown(e.sigval)
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py", line 289, in _shutdown
    self._pcontext.close(death_sig)
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 331, in close
    self._close(death_sig=death_sig, timeout=timeout)
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 708, in _close
    handler.proc.wait(time_to_wait)
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/subprocess.py", line 1209, in wait
    return self._wait(timeout=timeout)
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/subprocess.py", line 1953, in _wait
    time.sleep(delay)
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 62, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 1393443 got signal: 2

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ylu130/.conda/envs/ood/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/run.py", line 794, in main
    run(args)
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 241, in launch_agent
    result = agent.run()
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 735, in run
    self._shutdown()
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py", line 289, in _shutdown
    self._pcontext.close(death_sig)
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 331, in close
    self._close(death_sig=death_sig, timeout=timeout)
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 708, in _close
    handler.proc.wait(time_to_wait)
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/subprocess.py", line 1209, in wait
    return self._wait(timeout=timeout)
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/subprocess.py", line 1953, in _wait
    time.sleep(delay)
  File "/home/ylu130/.conda/envs/ood/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 62, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 1393443 got signal: 2
^C