WORLD_SIZE=1
MASTER_ADDR=gpu04
torchrun --nproc_per_node 1 --nnodes 1 --master_addr gpu04 --master_port 12094 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 6 6 7 8 9 10 True 4096 4
[2023-09-02 20:44:31,941] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 6
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o6-tgsm8k-s1-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 569027.11it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:12<00:12, 12.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  7.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.67s/it]
 > number of parameters: 6738415616
[2023-09-02 20:44:51,343] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-02 20:44:51,567] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-02 20:44:51,569] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-02 20:44:51,569] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-02 20:44:51,569] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-02 20:44:51,569] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-02 20:44:51,569] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f41460>
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-02 20:44:51,570] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-02 20:44:51,571] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-02 20:44:51,571] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/250 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: Mary added a total of 7 stickers/page * 6 pages= <<7*6=42>>42 stickers to the 6 other pages.
In total, Mary added 3 large stickers + 42 stickers = <<3+42=45>>45 stickers to her journal.
Since she started with 89 stickers, she now has 89 - 45 = <<89-45=44>>44 stickers left.
So the final answer is 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: If he babysits for 2 hours at $7 per hour, he will earn 2*7 = $<<2*7=14>>14
This week he will earn $5 allowance, $10 mowing the lawn and $14 from babysitting for a total of 5+10+14 = $<<5+10+14=29>>29
If we add the $29 he will earn to his $65 savings, he will have a total of 29 + 65 = $<<29+65=94>>94
The bike costs $100 and he will have $94 leaving $100-$94 = $<<100-94=6>>6 more that he will need to earn
So the final answer is 6

Input: Mark has kangaroos and goats.  Kangaroos have two legs and goats have four legs.  If he has 23 kangaroos and three times as many goats as kangaroos what is the total number of legs of all his animals?
Output: His kangaroos have a total of 23*2=<<23*2=46>>46 legs
He has 23*3=<<23*3=69>>69 goats
The goats have 69*4=<<69*4=276>>276 legs
So in total his animals have 276+46=<<276+46=322>>322 legs
So the final answer is 322

Input: Josh’s mom gives him $20 to go shopping at the mall. He buys a hat for $10 and a pencil for $2. Then he buys four cookies. If each cookie costs $1.25, how much money does Josh have left?
Output: After buying a hat, Josh has $20 - $10 = $<<20-10=10>>10
After buying a pencil, Josh has $10 - $2 = $<<10-2=8>>8
The total cost of cookies is 4 * $1.25 = $<<4*1.25=5>>5
After buying the cookies, Josh has $8 - $5 = $<<8-5=3>>3
So the final answer is 3

Input: George's bowling team is one round away from breaking the league record for most points scored in a season. The old record is an average score per player of 287 per round. Each team has 4 players and there are 10 rounds in the season. Through the first 9 rounds, his team has scored a total of 10,440. How many points less than the current league record per game average is the minimum average they need to score, per player, in the final round to tie the league record?
Output: The old team per round record is 1,148 because 287 x 4 = <<1148=1148>>1,148
The team season record is 11,480 because 10 x 1,248 = 11,480
They need 1,040 points in the final round to tie the record because 11,480 - 10,440 = <<11480-10440=1040>>1,040
They need to average 260 points each because 1,040 / 4 = <<1040/4=260>>260
This is 27 points less than the current record average because 287 - 260 = <<27=27>>27
So the final answer is 27

Input: Max was doing homework in three different subjects. It took him 20 minutes to finish tasks from biology and two times more time to finish history. Geography took him the most time, three times more than history. How much time did Max spend on doing his homework?
Output: Max finished history in 20 * 2 = <<20*2=40>>40 minutes.
Finishing geography took the most time, which is 40 * 3 = <<40*3=120>>120 minutes.
In total, for all three subjects, Max needed 20 + 40 + 120 = <<20+40+120=180>>180 minutes.
So the final answer is 180

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o6-tgsm8k-s1-rTrue-m4096
                                                                                               Evaluating commonsenseqa :   0%|          | 1/250 [01:02<4:20:09, 62.69s/it]                                                                                               Evaluating commonsenseqa :   1%|          | 2/250 [02:04<4:16:07, 61.97s/it]Evaluating commonsenseqa :   1%|          | 3/250 [03:06<4:15:47, 62.14s/it]Evaluating commonsenseqa :   2%|▏         | 4/250 [04:07<4:12:36, 61.61s/it]                Evaluating commonsenseqa :   2%|▏         | 5/250 [04:28<3:12:29, 47.14s/it]Evaluating commonsenseqa :   2%|▏         | 6/250 [05:31<3:32:56, 52.36s/it]Evaluating commonsenseqa :   3%|▎         | 7/250 [06:32<3:43:18, 55.14s/it]                Evaluating commonsenseqa :   3%|▎         | 8/250 [07:35<3:52:36, 57.67s/it]                                                                                                               Evaluating commonsenseqa :   4%|▎         | 9/250 [08:37<3:57:16, 59.07s/it]Evaluating commonsenseqa :   4%|▍         | 10/250 [09:02<3:13:52, 48.47s/it]               Evaluating commonsenseqa :   4%|▍         | 11/250 [10:05<3:31:05, 52.99s/it]Evaluating commonsenseqa :   5%|▍         | 12/250 [11:07<3:41:41, 55.89s/it]               Evaluating commonsenseqa :   5%|▌         | 13/250 [12:11<3:49:49, 58.19s/it]               Evaluating commonsenseqa :   6%|▌         | 14/250 [13:13<3:53:32, 59.37s/it]               Evaluating commonsenseqa :   6%|▌         | 15/250 [14:15<3:55:19, 60.08s/it]               Evaluating commonsenseqa :   6%|▋         | 16/250 [15:16<3:55:47, 60.46s/it]Evaluating commonsenseqa :   7%|▋         | 17/250 [16:18<3:56:48, 60.98s/it]               Evaluating commonsenseqa :   7%|▋         | 18/250 [17:20<3:57:10, 61.34s/it]                                                                                                                  Evaluating commonsenseqa :   8%|▊         | 19/250 [18:23<3:57:08, 61.59s/it]Evaluating commonsenseqa :   8%|▊         | 20/250 [19:26<3:57:55, 62.07s/it]                 Evaluating commonsenseqa :   8%|▊         | 21/250 [20:29<3:58:07, 62.39s/it]                 Evaluating commonsenseqa :   9%|▉         | 22/250 [21:30<3:55:54, 62.08s/it]                 Evaluating commonsenseqa :   9%|▉         | 23/250 [22:32<3:54:40, 62.03s/it]Evaluating commonsenseqa :  10%|▉         | 24/250 [23:11<3:27:41, 55.14s/it]Evaluating commonsenseqa :  10%|█         | 25/250 [24:14<3:35:13, 57.39s/it]                 Evaluating commonsenseqa :  10%|█         | 26/250 [24:46<3:06:31, 49.96s/it]Evaluating commonsenseqa :  11%|█         | 27/250 [25:48<3:18:55, 53.52s/it]                 Evaluating commonsenseqa :  11%|█         | 28/250 [26:51<3:28:44, 56.42s/it]                 Evaluating commonsenseqa :  12%|█▏        | 29/250 [27:42<3:20:54, 54.55s/it]Evaluating commonsenseqa :  12%|█▏        | 30/250 [28:44<3:28:18, 56.81s/it]Evaluating commonsenseqa :  12%|█▏        | 31/250 [29:46<3:33:22, 58.46s/it]               Evaluating commonsenseqa :  13%|█▎        | 32/250 [30:37<3:24:12, 56.21s/it]               Evaluating commonsenseqa :  13%|█▎        | 33/250 [31:39<3:29:45, 58.00s/it]               Evaluating commonsenseqa :  14%|█▎        | 34/250 [32:43<3:35:07, 59.76s/it]Evaluating commonsenseqa :  14%|█▍        | 35/250 [33:45<3:36:26, 60.40s/it]               Evaluating commonsenseqa :  14%|█▍        | 36/250 [34:48<3:37:55, 61.10s/it]               Evaluating commonsenseqa :  15%|█▍        | 37/250 [35:50<3:38:20, 61.51s/it]               Evaluating commonsenseqa :  15%|█▌        | 38/250 [36:49<3:34:10, 60.61s/it]               Evaluating commonsenseqa :  16%|█▌        | 39/250 [37:51<3:34:30, 61.00s/it]Evaluating commonsenseqa :  16%|█▌        | 40/250 [38:53<3:35:26, 61.55s/it]                                                                                                                Evaluating commonsenseqa :  16%|█▋        | 41/250 [39:56<3:35:26, 61.85s/it]Evaluating commonsenseqa :  17%|█▋        | 42/250 [40:59<3:35:09, 62.07s/it]               Evaluating commonsenseqa :  17%|█▋        | 43/250 [42:00<3:33:39, 61.93s/it]               Evaluating commonsenseqa :  18%|█▊        | 44/250 [43:01<3:31:37, 61.64s/it]Evaluating commonsenseqa :  18%|█▊        | 45/250 [44:04<3:31:25, 61.88s/it]               Evaluating commonsenseqa :  18%|█▊        | 46/250 [45:06<3:30:59, 62.06s/it]               Evaluating commonsenseqa :  19%|█▉        | 47/250 [46:09<3:30:34, 62.24s/it]               Evaluating commonsenseqa :  19%|█▉        | 48/250 [47:10<3:28:12, 61.84s/it]Evaluating commonsenseqa :  20%|█▉        | 49/250 [48:00<3:15:28, 58.35s/it]               Evaluating commonsenseqa :  20%|██        | 50/250 [49:01<3:17:19, 59.20s/it]                 Evaluating commonsenseqa :  20%|██        | 51/250 [50:03<3:19:11, 60.06s/it]                                                                                                                Evaluating commonsenseqa :  21%|██        | 52/250 [51:05<3:20:15, 60.68s/it]Evaluating commonsenseqa :  21%|██        | 53/250 [52:08<3:21:10, 61.27s/it]Evaluating commonsenseqa :  22%|██▏       | 54/250 [53:09<3:20:15, 61.30s/it]                                                                                                 Evaluating commonsenseqa :  22%|██▏       | 55/250 [54:11<3:19:57, 61.53s/it]Evaluating commonsenseqa :  22%|██▏       | 56/250 [55:14<3:19:55, 61.83s/it]             Evaluating commonsenseqa :  23%|██▎       | 57/250 [56:16<3:18:59, 61.86s/it]             Evaluating commonsenseqa :  23%|██▎       | 58/250 [56:48<2:49:05, 52.84s/it]Evaluating commonsenseqa :  24%|██▎       | 59/250 [57:49<2:56:25, 55.42s/it]             Evaluating commonsenseqa :  24%|██▍       | 60/250 [58:51<3:01:23, 57.28s/it]             Evaluating commonsenseqa :  24%|██▍       | 61/250 [59:53<3:05:28, 58.88s/it]Evaluating commonsenseqa :  25%|██▍       | 62/250 [1:00:56<3:07:59, 60.00s/it]                                                                                                            Evaluating commonsenseqa :  25%|██▌       | 63/250 [1:01:59<3:10:00, 60.96s/it]Evaluating commonsenseqa :  26%|██▌       | 64/250 [1:03:01<3:09:50, 61.24s/it]                                                                                                            Evaluating commonsenseqa :  26%|██▌       | 65/250 [1:03:47<2:54:43, 56.67s/it]                                                                                                 Evaluating commonsenseqa :  26%|██▋       | 66/250 [1:04:50<2:59:21, 58.48s/it]Evaluating commonsenseqa :  27%|██▋       | 67/250 [1:05:52<3:01:33, 59.53s/it]           Evaluating commonsenseqa :  27%|██▋       | 68/250 [1:06:54<3:02:49, 60.27s/it]           Evaluating commonsenseqa :  28%|██▊       | 69/250 [1:07:56<3:03:32, 60.84s/it]Evaluating commonsenseqa :  28%|██▊       | 70/250 [1:09:00<3:05:25, 61.81s/it]           Evaluating commonsenseqa :  28%|██▊       | 71/250 [1:10:03<3:05:33, 62.20s/it]           Evaluating commonsenseqa :  29%|██▉       | 72/250 [1:11:00<2:59:46, 60.60s/it]           Evaluating commonsenseqa :  29%|██▉       | 73/250 [1:12:02<2:59:49, 60.96s/it]           Evaluating commonsenseqa :  30%|██▉       | 74/250 [1:13:04<2:59:47, 61.29s/it]Evaluating commonsenseqa :  30%|███       | 75/250 [1:14:06<2:59:15, 61.46s/it]           Evaluating commonsenseqa :  30%|███       | 76/250 [1:14:45<2:38:42, 54.73s/it]           Evaluating commonsenseqa :  31%|███       | 77/250 [1:15:46<2:43:26, 56.69s/it]           Evaluating commonsenseqa :  31%|███       | 78/250 [1:16:49<2:48:01, 58.61s/it]Evaluating commonsenseqa :  32%|███▏      | 79/250 [1:17:50<2:49:34, 59.50s/it]Evaluating commonsenseqa :  32%|███▏      | 80/250 [1:18:53<2:50:53, 60.32s/it]         Evaluating commonsenseqa :  32%|███▏      | 81/250 [1:19:46<2:43:44, 58.13s/it]           Evaluating commonsenseqa :  33%|███▎      | 82/250 [1:20:48<2:45:58, 59.28s/it]           Evaluating commonsenseqa :  33%|███▎      | 83/250 [1:21:50<2:47:42, 60.25s/it]           Evaluating commonsenseqa :  34%|███▎      | 84/250 [1:22:52<2:48:03, 60.74s/it]           Evaluating commonsenseqa :  34%|███▍      | 85/250 [1:23:52<2:46:38, 60.59s/it]Evaluating commonsenseqa :  34%|███▍      | 86/250 [1:24:52<2:44:56, 60.34s/it]           Evaluating commonsenseqa :  35%|███▍      | 87/250 [1:25:53<2:44:36, 60.59s/it]           Evaluating commonsenseqa :  35%|███▌      | 88/250 [1:26:55<2:44:06, 60.78s/it]                                                                                                              Evaluating commonsenseqa :  36%|███▌      | 89/250 [1:27:58<2:45:04, 61.52s/it]Evaluating commonsenseqa :  36%|███▌      | 90/250 [1:29:00<2:44:28, 61.68s/it]           Evaluating commonsenseqa :  36%|███▋      | 91/250 [1:30:02<2:43:29, 61.69s/it]           Evaluating commonsenseqa :  37%|███▋      | 92/250 [1:31:04<2:43:25, 62.06s/it]           Evaluating commonsenseqa :  37%|███▋      | 93/250 [1:32:06<2:41:45, 61.82s/it]Evaluating commonsenseqa :  38%|███▊      | 94/250 [1:33:09<2:41:32, 62.13s/it]           Evaluating commonsenseqa :  38%|███▊      | 95/250 [1:34:10<2:40:09, 62.00s/it]           Evaluating commonsenseqa :  38%|███▊      | 96/250 [1:35:12<2:38:45, 61.86s/it]           Evaluating commonsenseqa :  39%|███▉      | 97/250 [1:36:13<2:37:34, 61.79s/it]           Evaluating commonsenseqa :  39%|███▉      | 98/250 [1:37:15<2:36:10, 61.65s/it]                                                                                                   Evaluating commonsenseqa :  40%|███▉      | 99/250 [1:38:18<2:36:33, 62.21s/it]Evaluating commonsenseqa :  40%|████      | 100/250 [1:39:20<2:35:24, 62.16s/it]Evaluating commonsenseqa :  40%|████      | 101/250 [1:40:21<2:33:31, 61.83s/it]          Evaluating commonsenseqa :  41%|████      | 102/250 [1:41:25<2:33:32, 62.24s/it]          Evaluating commonsenseqa :  41%|████      | 103/250 [1:42:28<2:33:14, 62.54s/it]                                                                                                             Evaluating commonsenseqa :  42%|████▏     | 104/250 [1:43:31<2:32:22, 62.62s/it]Evaluating commonsenseqa :  42%|████▏     | 105/250 [1:44:32<2:30:30, 62.28s/it]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Evaluating commonsenseqa :  42%|████▏     | 106/250 [1:45:35<2:29:51, 62.44s/it]erator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o3-tgsm8k-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 3
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o3-tgsm8k-s1-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 922523.38it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:14<00:14, 14.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:19<00:00,  8.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:19<00:00,  9.71s/it]
 > number of parameters: 6738415616
[2023-09-02 22:29:47,787] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-02 22:29:48,025] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-02 22:29:48,027] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-02 22:29:48,028] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-02 22:29:48,028] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-02 22:29:48,028] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-02 22:29:48,028] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-02 22:29:48,028] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-02 22:29:48,028] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-02 22:29:48,028] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-02 22:29:48,028] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-02 22:29:48,028] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-02 22:29:48,028] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f3d490>
[2023-09-02 22:29:48,028] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-02 22:29:48,028] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-02 22:29:48,028] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-02 22:29:48,028] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-02 22:29:48,028] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-02 22:29:48,028] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-02 22:29:48,028] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-02 22:29:48,028] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-02 22:29:48,028] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-02 22:29:48,028] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-02 22:29:48,028] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-02 22:29:48,028] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-02 22:29:48,028] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-02 22:29:48,028] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-02 22:29:48,029] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-02 22:29:48,030] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-02 22:29:48,030] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-02 22:29:48,030] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-02 22:29:48,030] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-02 22:29:48,030] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/250 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: Mary added a total of 7 stickers/page * 6 pages= <<7*6=42>>42 stickers to the 6 other pages.
In total, Mary added 3 large stickers + 42 stickers = <<3+42=45>>45 stickers to her journal.
Since she started with 89 stickers, she now has 89 - 45 = <<89-45=44>>44 stickers left.
So the final answer is 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: If he babysits for 2 hours at $7 per hour, he will earn 2*7 = $<<2*7=14>>14
This week he will earn $5 allowance, $10 mowing the lawn and $14 from babysitting for a total of 5+10+14 = $<<5+10+14=29>>29
If we add the $29 he will earn to his $65 savings, he will have a total of 29 + 65 = $<<29+65=94>>94
The bike costs $100 and he will have $94 leaving $100-$94 = $<<100-94=6>>6 more that he will need to earn
So the final answer is 6

Input: Mark has kangaroos and goats.  Kangaroos have two legs and goats have four legs.  If he has 23 kangaroos and three times as many goats as kangaroos what is the total number of legs of all his animals?
Output: His kangaroos have a total of 23*2=<<23*2=46>>46 legs
He has 23*3=<<23*3=69>>69 goats
The goats have 69*4=<<69*4=276>>276 legs
So in total his animals have 276+46=<<276+46=322>>322 legs
So the final answer is 322

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o3-tgsm8k-s1-rTrue-m4096
Evaluating commonsenseqa :   0%|          | 1/250 [01:15<5:12:04, 75.20s/it]: 1000}, 'diffEvaluating commonsenseqa :   1%|          | 2/250 [02:31<5:12:51, 75.69s/it]method': 'l1',Evaluating commonsenseqa :   1%|          | 3/250 [03:45<5:09:14, 75.12s/it]parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'chaEvaluating commonsenseqa :   2%|▏         | 4/250 [05:00<5:08:17, 75.19s/it]le_offset': Evaluating commonsenseqa :   2%|▏         | 5/250 [06:15<5:06:24, 75.04s/it]-02 17:26:23Evaluating commonsenseqa :   2%|▏         | 6/250 [07:30<5:05:07, 75.03s/it]Evaluating commonsenseqa :   3%|▎         | 7/250 [08:15<4:24:14, 65.24s/it]... False
[2023-09-02 17Evaluating commonsenseqa :   3%|▎         | 8/250 [09:30<4:35:32, 68.32s/it]bled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_woEvaluating commonsenseqa :   4%|▎         | 9/250 [10:47<4:44:31, 70.83s/it]Evaluating commonsenseqa :   4%|▍         | 10/250 [11:50<4:34:42, 68.68s/it]Evaluating commonsenseqa :   4%|▍         | 11/250 [12:49<4:21:11, 65.57s/it]iency_enabled ...... False
[2023-0Evaluating commonsenseqa :   5%|▍         | 12/250 [14:03<4:30:01, 68.07s/it] False
[2023-09-02 17:26:23,474] [INFO] [config.py:964:print]   disable_allgather ............ False
[Evaluating commonsenseqa :   5%|▌         | 13/250 [15:18<4:37:27, 70.24s/it]...... FalsEvaluating commonsenseqa :   6%|▌         | 14/250 [16:32<4:40:55, 71.42s/it]gs ...... {Evaluating commonsenseqa :   6%|▌         | 15/250 [17:48<4:44:24, 72.61s/it]resis': FalEvaluating commonsenseqa :   6%|▋         | 16/250 [19:02<4:45:16, 73.15s/it]envalue_enaEvaluating commonsenseqa :   7%|▋         | 17/250 [20:17<4:46:33, 73.79s/it]eigenvalue_Evaluating commonsenseqa :   7%|▋         | 18/250 [21:33<4:47:05, 74.25s/it] 63.01s/it]Evaluating commonsenseqa :  51%|█████     | 127/250 [2:07:26<2:08:14, 62.56s/it]Evaluating commonsenseqa :  51%|█████     | 128/250 [2:08:28<2:06:33, 62.24s/it]Evaluating commonsenseqa :  52%|█████▏    | 129/250 [2:09:30<2:05:22, 62.17s/it]Evaluating commonsenseqa :  52%|█████▏    | 130/250 [2:10:31<2:03:41, 61.84s/it]                                                                   Evaluating commonsenseqa :  52%|█████▏    | 131/250 [2:11:33<2:03:04, 62.06s/it]Evaluating commonsenseqa :  53%|█████▎    | 132/250 [2:12:35<2:02:05, 62.08s/it]Evaluating commonsenseqa :  53%|█████▎    | 133/250 [2:13:37<2:01:02, 62.07s/it]Evaluating commonsenseqa :  54%|█████▎    | 134/250 [2:14:40<2:00:19, 62.24s/it]Evaluating commonsenseqa :  54%|█████▍    | 135/250 [2:15:42<1:59:14, 62.21s/it]                                                      Evaluating commonsenseqa :  54%|█████▍    | 136/250 [2:16:44<1:57:52, 62.04s/it]Evaluating commonsenseqa :  55%|█████▍    | 137/250 [2:17:46<1:57:11, 62.23s/it]Evaluating commonsenseqa :  55%|█████▌    | 138/250 [2:18:49<1:56:19, 62.32s/it]Evaluating commonsenseqa :  56%|█████▌    | 139/250 [2:19:51<1:55:05, 62.21s/it]Evaluating commonsenseqa :  56%|█████▌    | 140/250 [2:20:35<1:44:11, 56.83s/it]Evaluating commonsenseqa :  56%|█████▋    | 141/250 [2:21:38<1:46:22, 58.55s/it]Evaluating commonsenseqa :  57%|█████▋    | 142/250 [2:22:41<1:47:39, 59.81s/it]Evaluating commonsenseqa :  57%|█████▋    | 143/250 [2:23:43<1:48:02, 60.58s/it]Evaluating commonsenseqa :  58%|█████▊    | 144/250 [2:24:46<1:48:15, 61.28s/it]Evaluating commonsenseqa :  58%|█████▊    | 145/250 [2:25:48<1:47:48, 61.61s/it]Evaluating commonsenseqa :  58%|█████▊    | 146/250 [2:26:49<1:46:29, 61.44s/it]Evaluating commonsenseqa :  59%|█████▉    | 147/250 [2:27:51<1:45:31, 61.47s/it]Evaluating commonsenseqa :  59%|█████▉    | 148/250 [2:28:52<1:44:26, 61.44s/it]Evaluating commonsenseqa :  60%|█████▉    | 149/250 [2:29:54<1:43:35, 61.54s/it]                                                                                  Evaluating commonsenseqa :  60%|██████    | 150/250 [2:30:56<1:42:55, 61.75s/it]Evaluating commonsenseqa :  60%|██████    | 151/250 [2:31:27<1:26:27, 52.40s/it]Evaluating commonsenseqa :  61%|██████    | 152/250 [2:32:28<1:30:08, 55.19s/it]                                                                                  Evaluating commonsenseqa :  61%|██████    | 153/250 [2:33:31<1:32:39, 57.32s/it]Evaluating commonsenseqa :  62%|██████▏   | 154/250 [2:34:33<1:34:01, 58.76s/it]Evaluating commonsenseqa :  62%|██████▏   | 155/250 [2:35:36<1:35:00, 60.01s/it]Evaluating commonsenseqa :  62%|██████▏   | 156/250 [2:36:29<1:30:35, 57.82s/it]Evaluating commonsenseqa :  63%|██████▎   | 157/250 [2:37:32<1:32:08, 59.44s/it]Evaluating commonsenseqa :  63%|██████▎   | 158/250 [2:38:33<1:32:10, 60.12s/it]Evaluating commonsenseqa :  64%|██████▎   | 159/250 [2:39:35<1:32:00, 60.67s/it]Evaluating commonsenseqa :  64%|██████▍   | 160/250 [2:40:39<1:32:28, 61.65s/it]Evaluating commonsenseqa :  64%|██████▍   | 161/250 [2:41:42<1:31:57, 61.99s/it]Evaluating commonsenseqa :  65%|██████▍   | 162/250 [2:42:45<1:31:31, 62.41s/it]Evaluating commonsenseqa :  65%|██████▌   | 163/250 [2:43:47<1:30:13, 62.22s/it]Evaluating commonsenseqa :  66%|██████▌   | 164/250 [2:44:50<1:29:18, 62.31s/it]Evaluating commonsenseqa :  66%|██████▌   | 165/250 [2:45:52<1:28:03, 62.16s/it]Evaluating commonsenseqa :  66%|██████▋   | 166/250 [2:46:54<1:27:00, 62.15s/it]Evaluating commonsenseqa :  67%|██████▋   | 167/250 [2:47:56<1:26:00, 62.17s/it]Evaluating commonsenseqa :  67%|██████▋   | 168/250 [2:48:59<1:25:17, 62.41s/it]                                                                             Evaluating commonsenseqa :  68%|██████▊   | 169/250 [2:50:02<1:24:23, 62.52s/it]Evaluating commonsenseqa :  68%|██████▊   | 170/250 [2:50:56<1:20:04, 60.06s/it]Evaluating commonsenseqa :  68%|██████▊   | 171/250 [2:51:58<1:19:52, 60.67s/it]Evaluating commonsenseqa :  69%|██████▉   | 172/250 [2:53:01<1:19:34, 61.21s/it]Evaluating commonsenseqa :  69%|██████▉   | 173/250 [2:54:04<1:19:18, 61.80s/it]Evaluating commonsenseqa :  70%|██████▉   | 174/250 [2:54:32<1:05:39, 51.84s/it]Evaluating commonsenseqa :  70%|███████   | 175/250 [2:55:34<1:08:32, 54.83s/it]Evaluating commonsenseqa :  70%|███████   | 176/250 [2:56:37<1:10:35, 57.24s/it]Evaluating commonsenseqa :  71%|███████   | 177/250 [2:57:39<1:11:23, 58.68s/it]Evaluating commonsenseqa :  71%|███████   | 178/250 [2:58:41<1:11:31, 59.61s/it]Evaluating commonsenseqa :  72%|███████▏  | 179/250 [2:59:42<1:11:05, 60.08s/it]Evaluating commonsenseqa :  72%|███████▏  | 180/250 [3:00:29<1:05:22, 56.04s/it]Evaluating commonsenseqa :  72%|███████▏  | 181/250 [3:01:31<1:06:35, 57.90s/it]Evaluating commonsenseqa :  73%|███████▎  | 182/250 [3:02:20<1:02:31, 55.17s/it]Evaluating commonsenseqa :  73%|███████▎  | 183/250 [3:03:22<1:03:57, 57.27s/it]Evaluating commonsenseqa :  74%|███████▎  | 184/250 [3:04:25<1:04:56, 59.04s/it]Evaluating commonsenseqa :  74%|███████▍  | 185/250 [3:05:27<1:04:51, 59.86s/it]Evaluating commonsenseqa :  74%|███████▍  | 186/250 [3:06:30<1:04:55, 60.87s/it]Evaluating commonsenseqa :  75%|███████▍  | 187/250 [3:07:34<1:04:44, 61.66s/it]Evaluating commonsenseqa :  75%|███████▌  | 188/250 [3:08:35<1:03:34, 61.52s/it]                                                                           Evaluating commonsenseqa :  76%|███████▌  | 189/250 [3:09:36<1:02:28, 61.44s/it]Evaluating commonsenseqa :  76%|███████▌  | 190/250 [3:10:38<1:01:39, 61.65s/it]                                                                           Evaluating commonsenseqa :  76%|███████▋  | 191/250 [3:11:41<1:01:06, 62.14s/it]Evaluating commonsenseqa :  77%|███████▋  | 192/250 [3:12:44<1:00:12, 62.28s/it]Evaluating commonsenseqa :  77%|███████▋  | 193/250 [3:13:46<59:02, 62.15s/it]  Evaluating commonsenseqa :  78%|███████▊  | 194/250 [3:14:49<58:15, 62.41s/it]Evaluating commonsenseqa :  78%|███████▊  | 195/250 [3:15:26<50:09, 54.73s/it]Evaluating commonsenseqa :  78%|███████▊  | 196/250 [3:16:29<51:37, 57.36s/it]                                                                                        Evaluating commonsenseqa :  79%|███████▉  | 197/250 [3:17:32<52:02, 58.92s/it]Evaluating commonsenseqa :  79%|███████▉  | 198/250 [3:18:27<49:59, 57.68s/it]Evaluating commonsenseqa :  80%|███████▉  | 199/250 [3:19:28<49:54, 58.72s/it]Evaluating commonsenseqa :  80%|████████  | 200/250 [3:20:31<50:01, 60.03s/it]Evaluating commonsenseqa :  80%|████████  | 201/250 [3:21:33<49:35, 60.73s/it]                                                                                 Evaluating commonsenseqa :  81%|████████  | 202/250 [3:22:35<48:54, 61.14s/it]Evaluating commonsenseqa :  81%|████████  | 203/250 [3:23:25<45:12, 57.70s/it]Evaluating commonsenseqa :  82%|████████▏ | 204/250 [3:24:29<45:39, 59.56s/it]Evaluating commonsenseqa :  82%|████████▏ | 205/250 [3:25:32<45:24, 60.54s/it]Evaluating commonsenseqa :  82%|████████▏ | 206/250 [3:26:07<38:57, 53.12s/it]Evaluating commonsenseqa :  83%|████████▎ | 207/250 [3:26:40<33:38, 46.94s/it]Evaluating commonsenseqa :  83%|████████▎ | 208/250 [3:27:42<36:01, 51.46s/it]                                                                                        Evaluating commonsenseqa :  84%|████████▎ | 209/250 [3:28:45<37:30, 54.89s/it]Evaluating commonsenseqa :  84%|████████▍ | 210/250 [3:29:48<38:19, 57.50s/it]Evaluating commonsenseqa :  84%|████████▍ | 211/250 [3:30:50<38:11, 58.76s/it]Evaluating commonsenseqa :  85%|████████▍ | 212/250 [3:31:52<37:51, 59.78s/it]Evaluating commonsenseqa :  85%|████████▌ | 213/250 [3:32:46<35:39, 57.82s/it]Evaluating commonsenseqa :  86%|████████▌ | 214/250 [3:33:49<35:39, 59.42s/it]Evaluating commonsenseqa :  86%|████████▌ | 215/250 [3:34:50<35:03, 60.10s/it]Evaluating commonsenseqa :  86%|████████▋ | 216/250 [3:35:53<34:30, 60.91s/it]Evaluating commonsenseqa :  87%|████████▋ | 217/250 [3:36:55<33:42, 61.29s/it]Evaluating commonsenseqa :  87%|████████▋ | 218/250 [3:37:59<33:00, 61.89s/it]Evaluating commonsenseqa :  88%|████████▊ | 219/250 [3:39:01<32:06, 62.16s/it]                                                                               Evaluating commonsenseqa :  88%|████████▊ | 220/250 [3:40:03<31:03, 62.11s/it]Evaluating commonsenseqa :  88%|████████▊ | 221/250 [3:41:06<30:06, 62.29s/it]Evaluating commonsenseqa :  89%|████████▉ | 222/250 [3:42:09<29:08, 62.44s/it]Evaluating commonsenseqa :  89%|████████▉ | 223/250 [3:43:12<28:14, 62.77s/it]Evaluating commonsenseqa :  90%|████████▉ | 224/250 [3:44:14<27:05, 62.51s/it]Evaluating commonsenseqa :  90%|█████████ | 225/250 [3:45:17<26:02, 62.51s/it]Evaluating commonsenseqa :  90%|█████████ | 226/250 [3:46:19<24:57, 62.41s/it]Evaluating commonsenseqa :  91%|█████████ | 227/250 [3:47:22<23:56, 62.46s/it]Evaluating commonsenseqa :  91%|█████████ | 228/250 [3:48:24<22:51, 62.32s/it]Evaluating commonsenseqa :  92%|█████████▏| 229/250 [3:49:25<21:45, 62.14s/it]Evaluating commonsenseqa :  92%|█████████▏| 230/250 [3:50:28<20:44, 62.24s/it]Evaluating commonsenseqa :  92%|█████████▏| 231/250 [3:51:30<19:40, 62.15s/it]Evaluating commonsenseqa :  93%|█████████▎| 232/250 [3:52:31<18:35, 61.96s/it]                                                                                           Evaluating commonsenseqa :  93%|█████████▎| 233/250 [3:53:33<17:33, 61.94s/it]Evaluating commonsenseqa :  94%|█████████▎| 234/250 [3:54:34<16:26, 61.66s/it]Evaluating commonsenseqa :  94%|█████████▍| 235/250 [3:55:36<15:25, 61.72s/it]Evaluating commonsenseqa :  94%|█████████▍| 236/250 [3:56:38<14:26, 61.86s/it]Evaluating commonsenseqa :  95%|█████████▍| 237/250 [3:57:41<13:26, 62.01s/it]Evaluating commonsenseqa :  95%|█████████▌| 238/250 [3:58:42<12:21, 61.76s/it]Evaluating commonsenseqa :  96%|█████████▌| 239/250 [3:59:43<11:18, 61.71s/it]Evaluating commonsenseqa :  96%|█████████▌| 240/250 [4:00:46<10:19, 61.93s/it]Evaluating commonsenseqa :  96%|█████████▋| 241/250 [4:01:48<09:18, 62.00s/it]Evaluating commonsenseqa :  97%|█████████▋| 242/250 [4:02:51<08:18, 62.27s/it]Evaluating commonsenseqa :  97%|█████████▋| 243/250 [4:03:49<07:07, 61.08s/it]Evaluating commonsenseqa :  98%|█████████▊| 244/250 [4:04:50<06:06, 61.10s/it]Evaluating commonsenseqa :  98%|█████████▊| 245/250 [4:05:53<05:08, 61.66s/it]Evaluating commonsenseqa :  98%|█████████▊| 246/250 [4:06:27<03:32, 53.21s/it]                                                                                           Evaluating commonsenseqa :  99%|█████████▉| 247/250 [4:07:30<02:48, 56.30s/it]Evaluating commonsenseqa :  99%|█████████▉| 248/250 [4:08:33<01:56, 58.37s/it]Evaluating commonsenseqa : 100%|█████████▉| 249/250 [4:09:21<00:55, 55.22s/it]Evaluating commonsenseqa : 100%|██████████| 250/250 [4:10:11<00:00, 53.43s/it]Evaluating commonsenseqa : 100%|██████████| 250/250 [4:10:11<00:00, 60.04s/it]
name: commonsenseqa | avg. gen lenth: 319.198 | time: 15012.795899868011s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr gpu04 --master_port 12094 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o7-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 7 6 7 8 9 10 True 4096 4
[2023-09-03 00:55:08,776] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o7-tgsm8k-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 7
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o7-tgsm8k-s1-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 526775.60it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:12<00:12, 12.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  6.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  7.72s/it]
 > number of parameters: 6738415616
[2023-09-03 00:55:25,761] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-03 00:55:25,981] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-03 00:55:25,983] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-03 00:55:25,984] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-03 00:55:25,984] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-03 00:55:25,984] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-03 00:55:25,984] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-03 00:55:25,984] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-03 00:55:25,984] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-03 00:55:25,984] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-03 00:55:25,984] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-03 00:55:25,984] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-03 00:55:25,984] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f3d460>
[2023-09-03 00:55:25,984] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-03 00:55:25,984] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-03 00:55:25,984] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-03 00:55:25,984] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-03 00:55:25,985] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-03 00:55:25,986] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-03 00:55:25,986] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-03 00:55:25,986] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-03 00:55:25,986] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-03 00:55:25,986] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-03 00:55:25,986] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-03 00:55:25,986] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-03 00:55:25,986] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-03 00:55:25,986] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-03 00:55:25,986] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-03 00:55:25,986] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-03 00:55:25,986] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-03 00:55:25,986] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-03 00:55:25,986] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-03 00:55:25,986] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-03 00:55:25,986] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-03 00:55:25,986] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-03 00:55:25,986] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/250 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: Mary added a total of 7 stickers/page * 6 pages= <<7*6=42>>42 stickers to the 6 other pages.
In total, Mary added 3 large stickers + 42 stickers = <<3+42=45>>45 stickers to her journal.
Since she started with 89 stickers, she now has 89 - 45 = <<89-45=44>>44 stickers left.
So the final answer is 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: If he babysits for 2 hours at $7 per hour, he will earn 2*7 = $<<2*7=14>>14
This week he will earn $5 allowance, $10 mowing the lawn and $14 from babysitting for a total of 5+10+14 = $<<5+10+14=29>>29
If we add the $29 he will earn to his $65 savings, he will have a total of 29 + 65 = $<<29+65=94>>94
The bike costs $100 and he will have $94 leaving $100-$94 = $<<100-94=6>>6 more that he will need to earn
So the final answer is 6

Input: Mark has kangaroos and goats.  Kangaroos have two legs and goats have four legs.  If he has 23 kangaroos and three times as many goats as kangaroos what is the total number of legs of all his animals?
Output: His kangaroos have a total of 23*2=<<23*2=46>>46 legs
He has 23*3=<<23*3=69>>69 goats
The goats have 69*4=<<69*4=276>>276 legs
So in total his animals have 276+46=<<276+46=322>>322 legs
So the final answer is 322

Input: Josh’s mom gives him $20 to go shopping at the mall. He buys a hat for $10 and a pencil for $2. Then he buys four cookies. If each cookie costs $1.25, how much money does Josh have left?
Output: After buying a hat, Josh has $20 - $10 = $<<20-10=10>>10
After buying a pencil, Josh has $10 - $2 = $<<10-2=8>>8
The total cost of cookies is 4 * $1.25 = $<<4*1.25=5>>5
After buying the cookies, Josh has $8 - $5 = $<<8-5=3>>3
So the final answer is 3

Input: George's bowling team is one round away from breaking the league record for most points scored in a season. The old record is an average score per player of 287 per round. Each team has 4 players and there are 10 rounds in the season. Through the first 9 rounds, his team has scored a total of 10,440. How many points less than the current league record per game average is the minimum average they need to score, per player, in the final round to tie the league record?
Output: The old team per round record is 1,148 because 287 x 4 = <<1148=1148>>1,148
The team season record is 11,480 because 10 x 1,248 = 11,480
They need 1,040 points in the final round to tie the record because 11,480 - 10,440 = <<11480-10440=1040>>1,040
They need to average 260 points each because 1,040 / 4 = <<1040/4=260>>260
This is 27 points less than the current record average because 287 - 260 = <<27=27>>27
So the final answer is 27

Input: Max was doing homework in three different subjects. It took him 20 minutes to finish tasks from biology and two times more time to finish history. Geography took him the most time, three times more than history. How much time did Max spend on doing his homework?
Output: Max finished history in 20 * 2 = <<20*2=40>>40 minutes.
Finishing geography took the most time, which is 40 * 3 = <<40*3=120>>120 minutes.
In total, for all three subjects, Max needed 20 + 40 + 120 = <<20+40+120=180>>180 minutes.
So the final answer is 180

Input: Sophia ate 1/6 of her pie and she put the rest on the fridge. If the pie left in the fridge weighs 1200 grams, how many grams did Sophia eat?
Output: If Sophia ate 1/6 of the pie, then 6/6 - 1/6 = 5/6 is left in the fridge.
Let x be the pie's original weight.
The current weight of the pie can be described by 5x/6=1200 grams
So, 5x=7200.
And, the original weight is x = <<1440=1440>>1440 grams.
So, Sophia ate 1440 grams original - 1200 grams after= <<1440-1200=240>>240 grams of pie.
So the final answer is 240

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o7-tgsm8k-s1-rTrue-m4096
Evaluating commonsenseqa :   0%|          | 1/250 [00:59<4:06:25, 59.38s/it]              Evaluating commonsenseqa :   1%|          | 2/250 [01:58<4:05:15, 59.34s/it]              Evaluating commonsenseqa :   1%|          | 3/250 [02:57<4:03:17, 59.10s/it]              Evaluating commonsenseqa :   2%|▏         | 4/250 [03:57<4:04:20, 59.60s/it]Evaluating commonsenseqa :   2%|▏         | 5/250 [04:56<4:01:47, 59.21s/it]                                                                                                         Evaluating commonsenseqa :   2%|▏         | 6/250 [05:54<3:59:25, 58.88s/it]Evaluating commonsenseqa :   3%|▎         | 7/250 [06:53<3:58:12, 58.82s/it]              Evaluating commonsenseqa :   3%|▎         | 8/250 [07:51<3:57:00, 58.76s/it]              Evaluating commonsenseqa :   4%|▎         | 9/250 [08:50<3:56:20, 58.84s/it]              Evaluating commonsenseqa :   4%|▍         | 10/250 [09:50<3:56:15, 59.06s/it]             Evaluating commonsenseqa :   4%|▍         | 11/250 [10:49<3:55:15, 59.06s/it]             Evaluating commonsenseqa :   5%|▍         | 12/250 [11:47<3:53:23, 58.84s/it]Evaluating commonsenseqa :   5%|▌         | 13/250 [12:46<3:52:41, 58.91s/it]             Evaluating commonsenseqa :   6%|▌         | 14/250 [13:45<3:50:44, 58.66s/it]             Evaluating commonsenseqa :   6%|▌         | 15/250 [14:43<3:49:38, 58.63s/it]             Evaluating commonsenseqa :   6%|▋         | 16/250 [15:42<3:49:23, 58.82s/it]Evaluating commonsenseqa :   7%|▋         | 17/250 [16:42<3:49:50, 59.19s/it]             Evaluating commonsenseqa :   7%|▋         | 18/250 [17:40<3:47:31, 58.84s/it]             Evaluating commonsenseqa :   8%|▊         | 19/250 [18:39<3:46:42, 58.89s/it]             Evaluating commonsenseqa :   8%|▊         | 20/250 [19:38<3:45:49, 58.91s/it]Evaluating commonsenseqa :   8%|▊         | 21/250 [20:38<3:45:03, 58.97s/it]                          Evaluating commonsenseqa :   9%|▉         | 22/250 [21:37<3:45:12, 59.26s/it]Evaluating commonsenseqa :   9%|▉         | 23/250 [22:36<3:42:58, 58.94s/it]             Evaluating commonsenseqa :  10%|▉         | 24/250 [23:36<3:43:38, 59.38s/it]             Evaluating commonsenseqa :  10%|█         | 25/250 [24:36<3:42:50, 59.42s/it]             Evaluating commonsenseqa :  10%|█         | 26/250 [25:36<3:42:31, 59.60s/it]Evaluating commonsenseqa :  11%|█         | 27/250 [26:34<3:40:42, 59.38s/it]             Evaluating commonsenseqa :  11%|█         | 28/250 [27:21<3:25:53, 55.65s/it]             Evaluating commonsenseqa :  12%|█▏        | 29/250 [28:05<3:11:50, 52.09s/it]Evaluating commonsenseqa :  12%|█▏        | 30/250 [29:04<3:18:06, 54.03s/it]                                                                                                        Evaluating commonsenseqa :  12%|█▏        | 31/250 [30:02<3:21:29, 55.20s/it]Evaluating commonsenseqa :  13%|█▎        | 32/250 [31:01<3:25:07, 56.46s/it]                                                                                                        Evaluating commonsenseqa :  13%|█▎        | 33/250 [32:00<3:26:27, 57.08s/it]Evaluating commonsenseqa :  14%|█▎        | 34/250 [32:58<3:27:16, 57.58s/it]           Evaluating commonsenseqa :  14%|█▍        | 35/250 [33:57<3:27:14, 57.84s/it]Evaluating commonsenseqa :  14%|█▍        | 36/250 [34:57<3:28:25, 58.43s/it]                        Evaluating commonsenseqa :  15%|█▍        | 37/250 [35:55<3:27:12, 58.37s/it]Evaluating commonsenseqa :  15%|█▌        | 38/250 [36:53<3:25:47, 58.24s/it]                                                                                                                                                                                                           Evaluating commonsenseqa :  16%|█▌        | 39/250 [37:31<3:03:45, 52.26s/it]Evaluating commonsenseqa :  16%|█▌        | 40/250 [38:31<3:10:50, 54.52s/it]             Evaluating commonsenseqa :  16%|█▋        | 41/250 [39:30<3:14:58, 55.97s/it]Evaluating commonsenseqa :  17%|█▋        | 42/250 [40:29<3:17:16, 56.91s/it]                          Evaluating commonsenseqa :  17%|█▋        | 43/250 [41:25<3:15:04, 56.54s/it]Evaluating commonsenseqa :  18%|█▊        | 44/250 [42:24<3:16:57, 57.37s/it]             Evaluating commonsenseqa :  18%|█▊        | 45/250 [43:25<3:19:17, 58.33s/it]             Evaluating commonsenseqa :  18%|█▊        | 46/250 [44:24<3:19:15, 58.60s/it]             Evaluating commonsenseqa :  19%|█▉        | 47/250 [45:23<3:18:28, 58.66s/it]Evaluating commonsenseqa :  19%|█▉        | 48/250 [46:21<3:16:58, 58.51s/it]             Evaluating commonsenseqa :  20%|█▉        | 49/250 [47:21<3:17:14, 58.88s/it]             Evaluating commonsenseqa :  20%|██        | 50/250 [48:20<3:16:38, 58.99s/it]             Evaluating commonsenseqa :  20%|██        | 51/250 [49:19<3:15:14, 58.86s/it]Evaluating commonsenseqa :  21%|██        | 52/250 [50:18<3:14:51, 59.05s/it]                          Evaluating commonsenseqa :  21%|██        | 53/250 [51:17<3:13:13, 58.85s/it]Evaluating commonsenseqa :  22%|██▏       | 54/250 [52:15<3:12:08, 58.82s/it]           Evaluating commonsenseqa :  22%|██▏       | 55/250 [53:16<3:12:49, 59.33s/it]           Evaluating commonsenseqa :  22%|██▏       | 56/250 [54:15<3:11:58, 59.37s/it]           Evaluating commonsenseqa :  23%|██▎       | 57/250 [55:15<3:11:15, 59.46s/it]           Evaluating commonsenseqa :  23%|██▎       | 58/250 [56:14<3:10:02, 59.39s/it]           Evaluating commonsenseqa :  24%|██▎       | 59/250 [57:13<3:08:37, 59.25s/it]Evaluating commonsenseqa :  24%|██▍       | 60/250 [58:12<3:07:20, 59.16s/it]           Evaluating commonsenseqa :  24%|██▍       | 61/250 [59:10<3:05:16, 58.82s/it]           Evaluating commonsenseqa :  25%|██▍       | 62/250 [1:00:08<3:03:33, 58.58s/it]         Evaluating commonsenseqa :  25%|██▌       | 63/250 [1:01:08<3:03:23, 58.84s/it]Evaluating commonsenseqa :  26%|██▌       | 64/250 [1:02:06<3:02:28, 58.86s/it]                                                                                                        Evaluating commonsenseqa :  26%|██▌       | 65/250 [1:03:06<3:01:40, 58.92s/it]Evaluating commonsenseqa :  26%|██▋       | 66/250 [1:04:04<3:00:13, 58.77s/it]                                                                                                            Evaluating commonsenseqa :  27%|██▋       | 67/250 [1:05:03<2:59:31, 58.86s/it]Evaluating commonsenseqa :  27%|██▋       | 68/250 [1:06:02<2:58:14, 58.76s/it]                      Evaluating commonsenseqa :  28%|██▊       | 69/250 [1:07:00<2:56:43, 58.58s/it]Evaluating commonsenseqa :  28%|██▊       | 70/250 [1:07:59<2:56:18, 58.77s/it]           Evaluating commonsenseqa :  28%|██▊       | 71/250 [1:08:57<2:54:56, 58.64s/it]           Evaluating commonsenseqa :  29%|██▉       | 72/250 [1:09:56<2:54:00, 58.65s/it]           Evaluating commonsenseqa :  29%|██▉       | 73/250 [1:10:54<2:52:28, 58.46s/it]Evaluating commonsenseqa :  30%|██▉       | 74/250 [1:11:54<2:52:58, 58.97s/it]                      Evaluating commonsenseqa :  30%|███       | 75/250 [1:12:53<2:52:00, 58.97s/it]Evaluating commonsenseqa :  30%|███       | 76/250 [1:13:52<2:51:17, 59.06s/it]           Evaluating commonsenseqa :  31%|███       | 77/250 [1:14:52<2:51:00, 59.31s/it]           Evaluating commonsenseqa :  31%|███       | 78/250 [1:15:51<2:49:40, 59.19s/it]           Evaluating commonsenseqa :  32%|███▏      | 79/250 [1:16:51<2:49:06, 59.34s/it]Evaluating commonsenseqa :  32%|███▏      | 80/250 [1:17:40<2:39:54, 56.44s/it]         Evaluating commonsenseqa :  32%|███▏      | 81/250 [1:18:40<2:41:48, 57.45s/it]         Evaluating commonsenseqa :  33%|███▎      | 82/250 [1:19:40<2:42:23, 57.99s/it]         Evaluating commonsenseqa :  33%|███▎      | 83/250 [1:20:39<2:42:17, 58.31s/it]Evaluating commonsenseqa :  34%|███▎      | 84/250 [1:21:36<2:40:57, 58.18s/it]2.49s/it]Evaluating commonsenseqa :  78%|███████▊  | 195/250 [3:47:41<1:07:17, 73.41s/it]Evaluating commonsenseqa :  78%|███████▊  | 196/250 [3:48:19<56:30, 62.78s/it]  Evaluating commonsenseqa :  79%|███████▉  | 197/250 [3:49:33<58:36, 66.35s/it]                                                                                        Evaluating commonsenseqa :  79%|███████▉  | 198/250 [3:50:48<59:37, 68.80s/it]Evaluating commonsenseqa :  80%|███████▉  | 199/250 [3:52:05<1:00:32, 71.22s/it]Evaluating commonsenseqa :  80%|████████  | 200/250 [3:53:20<1:00:18, 72.37s/it]                                                                                        Evaluating commonsenseqa :  80%|████████  | 201/250 [3:54:33<59:16, 72.59s/it]  Evaluating commonsenseqa :  81%|████████  | 202/250 [3:55:21<52:09, 65.20s/it]                                                                                        Evaluating commonsenseqa :  81%|████████  | 203/250 [3:56:36<53:19, 68.07s/it]Evaluating commonsenseqa :  82%|████████▏ | 204/250 [3:57:51<53:46, 70.15s/it]Evaluating commonsenseqa :  82%|████████▏ | 205/250 [3:58:23<44:01, 58.70s/it]Evaluating commonsenseqa :  82%|████████▏ | 206/250 [3:59:35<46:07, 62.89s/it]Evaluating commonsenseqa :  83%|████████▎ | 207/250 [4:00:50<47:30, 66.29s/it]Evaluating commonsenseqa :  83%|████████▎ | 208/250 [4:02:04<48:01, 68.62s/it]Evaluating commonsenseqa :  84%|████████▎ | 209/250 [4:02:48<41:59, 61.45s/it]                                                                                         Evaluating commonsenseqa :  84%|████████▍ | 210/250 [4:04:03<43:30, 65.26s/it]Evaluating commonsenseqa :  84%|████████▍ | 211/250 [4:05:17<44:11, 67.98s/it]Evaluating commonsenseqa :  85%|████████▍ | 212/250 [4:06:31<44:12, 69.79s/it]                                                                                           Evaluating commonsenseqa :  85%|████████▌ | 213/250 [4:07:45<43:46, 70.98s/it]Evaluating commonsenseqa :  86%|████████▌ | 214/250 [4:08:59<43:14, 72.06s/it]                                                                                           Evaluating commonsenseqa :  86%|████████▌ | 215/250 [4:10:12<42:14, 72.41s/it]Evaluating commonsenseqa :  86%|████████▋ | 216/250 [4:11:27<41:20, 72.95s/it]Evaluating commonsenseqa :  87%|████████▋ | 217/250 [4:12:42<40:30, 73.67s/it]                                                                                           Evaluating commonsenseqa :  87%|████████▋ | 218/250 [4:13:56<39:19, 73.73s/it]Evaluating commonsenseqa :  88%|████████▊ | 219/250 [4:14:38<33:13, 64.30s/it]                                                                                           Evaluating commonsenseqa :  88%|████████▊ | 220/250 [4:15:52<33:31, 67.03s/it]                                                                                     Evaluating commonsenseqa :  88%|████████▊ | 221/250 [4:17:07<33:35, 69.49s/it]Evaluating commonsenseqa :  89%|████████▉ | 222/250 [4:18:21<33:04, 70.87s/it]Evaluating commonsenseqa :  89%|████████▉ | 223/250 [4:19:35<32:16, 71.72s/it]                                                                                           Evaluating commonsenseqa :  90%|████████▉ | 224/250 [4:20:48<31:19, 72.28s/it]Evaluating commonsenseqa :  90%|█████████ | 225/250 [4:22:04<30:33, 73.35s/it]Evaluating commonsenseqa :  90%|█████████ | 226/250 [4:23:18<29:28, 73.67s/it]                                                                                           Evaluating commonsenseqa :  50%|████▉     | 124/250 [1:59:36<2:02:03, 58.12s/it]5s/it]Evaluating commonsenseqa :  91%|█████████ | 228/250 [4:25:46<27:00, 73.67s/it]Evaluating commonsenseqa :  92%|█████████▏| 229/250 [4:27:01<25:58, 74.23s/it]                                                                                           Evaluating commonsenseqa :  92%|█████████▏| 230/250 [4:28:14<24:38, 73.91s/it]Evaluating commonsenseqa :  92%|█████████▏| 231/250 [4:29:30<23:31, 74.30s/it]                                                                                             Evaluating commonsenseqa :  93%|█████████▎| 232/250 [4:30:43<22:10, 73.93s/it]Evaluating commonsenseqa :  93%|█████████▎| 233/250 [4:31:57<21:01, 74.20s/it]Evaluating commonsenseqa :  94%|█████████▎| 234/250 [4:33:13<19:53, 74.58s/it]                                                                                             Evaluating commonsenseqa :  94%|█████████▍| 235/250 [4:34:28<18:42, 74.84s/it]Evaluating commonsenseqa :  94%|█████████▍| 236/250 [4:35:43<17:28, 74.87s/it]Evaluating commonsenseqa :  95%|█████████▍| 237/250 [4:36:40<15:01, 69.38s/it]Evaluating commonsenseqa :  95%|█████████▌| 238/250 [4:37:55<14:14, 71.23s/it]                                                                                 Evaluating commonsenseqa :  96%|█████████▌| 239/250 [4:39:09<13:11, 71.96s/it]Evaluating commonsenseqa :  96%|█████████▌| 240/250 [4:40:26<12:13, 73.31s/it]Evaluating commonsenseqa :  96%|█████████▋| 241/250 [4:41:40<11:02, 73.67s/it]                                                                                             Evaluating commonsenseqa :  97%|█████████▋| 242/250 [4:42:55<09:51, 73.94s/it]Evaluating commonsenseqa :  97%|█████████▋| 243/250 [4:44:09<08:37, 73.99s/it]Evaluating commonsenseqa :  98%|█████████▊| 244/250 [4:45:13<07:07, 71.20s/it]                                                                                             Evaluating commonsenseqa :  98%|█████████▊| 245/250 [4:46:28<06:01, 72.23s/it]Evaluating commonsenseqa :  98%|█████████▊| 246/250 [4:47:43<04:51, 72.93s/it]Evaluating commonsenseqa :  99%|█████████▉| 247/250 [4:48:55<03:38, 72.90s/it]Evaluating commonsenseqa :  99%|█████████▉| 248/250 [4:50:08<02:25, 72.94s/it]Evaluating commonsenseqa : 100%|█████████▉| 249/250 [4:51:22<01:13, 73.17s/it]Evaluating commonsenseqa : 100%|██████████| 250/250 [4:52:21<00:00, 68.8Evaluating commonsenseqa :  61%|██████    | 153/250 [2:27:33<1:35:59, 59.38s/it], 70.17s/it]
name: commonsenseqa | avg. gen lenth: 291.494 | time: 17542.688746213913s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr gpu03 --master_port 17129 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o4-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 4 1 2 3 4 5 True 4096 4
[2023-09-03 03:22:16,419] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o4-tgsm8k-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 4
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o4-tgsm8k-s1-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 746391.33it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:14<00:14, 14.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:20<00:00,  9.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:20<00:00, 10.09s/it]
 > number of parameters: 6738415616
[2023-09-03 03:22:38,206] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-03 03:22:38,439] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-03 03:22:38,440] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f3f490>
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-03 03:22:38,441] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-03 03:22:38,442] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-03 03:22:38,442] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/250 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: Mary added a total of 7 stickers/page * 6 pages= <<7*6=42>>42 stickers to the 6 other pages.
In total, Mary added 3 large stickers + 42 stickers = <<3+42=45>>45 stickers to her journal.
Since she started with 89 stickers, she now has 89 - 45 = <<89-45=44>>44 stickers left.
So the final answer is 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: If he babysits for 2 hours at $7 per hour, he will earn 2*7 = $<<2*7=14>>14
This week he will earn $5 allowance, $10 mowing the lawn and $14 from babysitting for a total of 5+10+14 = $<<5+10+14=29>>29
If we add the $29 he will earn to his $65 savings, he will have a total of 29 + 65 = $<<29+65=94>>94
The bike costs $100 and he will have $94 leaving $100-$94 = $<<100-94=6>>6 more that he will need to earn
So the final answer is 6

Input: Mark has kangaroos and goats.  Kangaroos have two legs and goats have four legs.  If he has 23 kangaroos and three times as many goats as kangaroos what is the total number of legs of all his animals?
Output: His kangaroos have a total of 23*2=<<23*2=46>>46 legs
He has 23*3=<<23*3=69>>69 goats
The goats have 69*4=<<69*4=276>>276 legs
So in total his animals have 276+46=<<276+46=322>>322 legs
So the final answer is 322

Input: Josh’s mom gives him $20 to go shopping at the mall. He buys a hat for $10 and a pencil for $2. Then he buys four cookies. If each cookie costs $1.25, how much money does Josh have left?
Output: After buying a hat, Josh has $20 - $10 = $<<20-10=10>>10
After buying a pencil, Josh has $10 - $2 = $<<10-2=8>>8
The total cost of cookies is 4 * $1.25 = $<<4*1.25=5>>5
After buying the cookies, Josh has $8 - $5 = $<<8-5=3>>3
So the final answer is 3

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o4-tgsm8k-s1-rTrue-m4096
Evaluating commonsenseqa :   0%|          | 1/250 [01:12<5:01:06, 72.56s/it]                  Evaluating commonsenseqa :   1%|          | 2/250 [02:23<4:56:09, 71.65s/it]                                                                                                                 Evaluating commonsenseqa :   1%|          | 3/250 [03:35<4:55:22, 71.75s/it]                  Evaluating commonsenseqa :   2%|▏         | 4/250 [04:43<4:47:41, 70.17s/it]Evaluating commonsenseqa :   2%|▏         | 5/250 [05:44<4:33:52, 67.07s/it]Evaluating commonsenseqa :   2%|▏         | 6/250 [06:22<3:52:32, 57.18s/it]                                                Evaluating commonsenseqa :   3%|▎         | 7/250 [07:33<4:09:46, 61.67s/it]                Evaluating commonsenseqa :   3%|▎         | 8/250 [08:43<4:19:04, 64.23s/it]                Evaluating commonsenseqa :   4%|▎         | 9/250 [09:54<4:26:30, 66.35s/it]                                                                                                               Evaluating commonsenseqa :   4%|▍         | 10/250 [11:05<4:31:38, 67.91s/it]Evaluating commonsenseqa :   4%|▍         | 11/250 [12:15<4:32:07, 68.32s/it]                                                                                               Evaluating commonsenseqa :   5%|▍         | 12/250 [13:25<4:33:20, 68.91s/it]               Evaluating commonsenseqa :   5%|▌         | 13/250 [14:37<4:36:12, 69.93s/it]               Evaluating commonsenseqa :   6%|▌         | 14/250 [15:46<4:34:24, 69.77s/it]                                                                                                              Evaluating commonsenseqa :   6%|▌         | 15/250 [16:56<4:33:28, 69.82s/it]Evaluating commonsenseqa :   6%|▋         | 16/250 [18:07<4:33:31, 70.13s/it]Evaluating commonsenseqa :   7%|▋         | 17/250 [19:04<4:16:23, 66.02s/it]                                                                                                              Evaluating commonsenseqa :   7%|▋         | 18/250 [20:14<4:20:24, 67.35s/it]               Evaluating commonsenseqa :   8%|▊         | 19/250 [21:25<4:23:04, 68.33s/it]                                                                                                              Evaluating commonsenseqa :   8%|▊         | 20/250 [22:37<4:26:06, 69.42s/it]                                                                                                              Evaluating commonsenseqa :   8%|▊         | 21/250 [23:48<4:27:26, 70.07s/it]Evaluating commonsenseqa :   9%|▉         | 22/250 [24:36<4:00:41, 63.34s/it]Evaluating commonsenseqa :   9%|▉         | 23/250 [25:47<4:08:50, 65.77s/it]                 Evaluating commonsenseqa :  10%|▉         | 24/250 [26:42<3:55:17, 62.47s/it]Evaluating commonsenseqa :  10%|█         | 25/250 [27:36<3:44:27, 59.85s/it]                                                                                                                  Evaluating commonsenseqa :  10%|█         | 26/250 [28:47<3:55:51, 63.18s/it]Evaluating commonsenseqa :  11%|█         | 27/250 [29:20<3:21:14, 54.15s/it]                                  Evaluating commonsenseqa :  11%|█         | 28/250 [30:25<3:32:34, 57.45s/it]                 Evaluating commonsenseqa :  12%|█▏        | 29/250 [31:37<3:47:05, 61.65s/it]               Evaluating commonsenseqa :  12%|█▏        | 30/250 [32:48<3:56:50, 64.59s/it]                                                                                                                Evaluating commonsenseqa :  12%|█▏        | 31/250 [33:59<4:02:21, 66.40s/it]               Evaluating commonsenseqa :  13%|█▎        | 32/250 [35:11<4:07:30, 68.12s/it]             Evaluating commonsenseqa :  76%|███████▋  | 191/250 [3:03:47<57:15, 58.23s/it]ommonsenseqa :  14%|█▎        | 34/250 [36:46<3:19:27, 55.41s/it]Evaluating commonsenseqa :  77%|███████▋  | 192/250 [3:04:45<56:01, 57.95s/it]Evaluating commonsenseqa :  77%|███████▋  | 193/250 [3:05:44<55:25, 58.35s/it]Evaluating commonsenseqa :  78%|███████▊  | 194/250 [3:06:42<54:28, 58.36s/it]Evaluating commonsenseqa :  78%|███████▊  | 195/250 [3:07:41<53:29, 58.35s/it]Evaluating commonsenseqa :  78%|███████▊  | 196/250 [3:08:21<47:31, 52.81s/it]Evaluating commonsenseqa :  79%|███████▉  | 197/250 [3:09:20<48:26, 54.84s/it]Evaluating commonsenseqa :  79%|███████▉  | 198/250 [3:10:18<48:25, 55.88s/it]Evaluating commonsenseqa :  80%|███████▉  | 199/250 [3:10:57<42:59, 50.57s/it]Evaluating commonsenseqa :  80%|████████  | 200/250 [3:11:56<44:15, 53.11s/it]Evaluating commonsenseqa :  80%|████████  | 201/250 [3:12:54<44:43, 54.77s/it]Evaluating commonsenseqa :  81%|████████  | 202/250 [3:13:52<44:35, 55.75s/it]Evaluating commonsenseqa :  81%|████████  | 203/250 [3:14:51<44:22, 56.64s/it]Evaluating commonsenseqa :  82%|████████▏ | 204/250 [3:15:50<44:00, 57.39s/it]Evaluating commonsenseqa :  82%|████████▏ | 205/250 [3:16:48<43:14, 57.66s/it]Evaluating commonsenseqa :  82%|████████▏ | 206/250 [3:17:47<42:27, 57.89s/it]Evaluating commonsenseqa :  83%|████████▎ | 207/250 [3:18:45<41:36, 58.05s/it]Evaluating commonsenseqa :  83%|████████▎ | 208/250 [3:19:43<40:36, 58.02s/it]Evaluating commonsenseqa :  84%|████████▎ | 209/250 [3:20:31<37:33, 54.95s/it]Evaluating commonsenseqa :  84%|████████▍ | 210/250 [3:21:29<37:16, 55.92s/it]Evaluating commonsenseqa :  84%|████████▍ | 211/250 [3:22:27<36:40, 56.42s/it]Evaluating commonsenseqa :  85%|████████▍ | 212/250 [3:23:25<36:02, 56.91s/it]Evaluating commonsenseqa :  85%|████████▌ | 213/250 [3:24:23<35:15, 57.18s/it]Evaluating commonsenseqa :  86%|████████▌ | 214/250 [3:25:21<34:28, 57.45s/it]Evaluating commonsenseqa :  86%|████████▌ | 215/250 [3:26:19<33:42, 57.80s/it]Evaluating commonsenseqa :  86%|████████▋ | 216/250 [3:27:17<32:45, 57.81s/it]Evaluating commonsenseqa :  87%|████████▋ | 217/250 [3:28:17<32:06, 58.36s/it]Evaluating commonsenseqa :  87%|████████▋ | 218/250 [3:28:29<23:42, 44.44s/it]Evaluating commonsenseqa :  88%|████████▊ | 219/250 [3:29:27<25:05, 48.58s/it]Evaluating commonsenseqa :  88%|████████▊ | 220/250 [3:30:25<25:42, 51.42s/it]Evaluating commonsenseqa :  88%|████████▊ | 221/250 [3:31:24<25:54, 53.59s/it]Evaluating commonsenseqa :  89%|████████▉ | 222/250 [3:32:22<25:39, 54.99s/it]Evaluating commonsenseqa :  89%|████████▉ | 223/250 [3:33:20<25:12, 56.00s/it]Evaluating commonsenseqa :  90%|████████▉ | 224/250 [3:34:18<24:27, 56.45s/it]Evaluating commonsenseqa :  90%|█████████ | 225/250 [3:35:17<23:48, 57.14s/it]Evaluating commonsenseqa :  90%|█████████ | 226/250 [3:36:14<22:53, 57.23s/it]Evaluating commonsenseqa :  91%|█████████ | 227/250 [3:37:04<21:05, 55.02s/it]Evaluating commonsenseqa :  91%|█████████ | 228/250 [3:38:02<20:32, 56.04s/it]Evaluating commonsenseqa :  92%|█████████▏| 229/250 [3:39:00<19:48, 56.60s/it]Evaluating commonsenseqa :  92%|█████████▏| 230/250 [3:39:58<19:01, 57.05s/it]Evaluating commonsenseqa :  92%|█████████▏| 231/250 [3:40:48<17:24, 54.96s/it]Evaluating commonsenseqa :  93%|█████████▎| 232/250 [3:41:47<16:46, 55.91s/it]Evaluating commonsenseqa :  93%|█████████▎| 233/250 [3:42:45<16:04, 56.72s/it]Evaluating commonsenseqa :  94%|█████████▎| 234/250 [3:43:43<15:13, 57.07s/it]Evaluating commonsenseqa :  94%|█████████▍| 235/250 [3:44:40<14:17, 57.13s/it]Evaluating commonsenseqa :  94%|█████████▍| 236/250 [3:45:38<13:23, 57.42s/it]Evaluating commonsenseqa :  95%|█████████▍| 237/250 [3:46:38<12:33, 57.94s/it]Evaluating commonsenseqa :  95%|█████████▌| 238/250 [3:47:35<11:32, 57.70s/it]Evaluating commonsenseqa :  96%|█████████▌| 239/250 [3:48:33<10:36, 57.82s/it]                                                                         Evaluating commonsenseqa :  96%|█████████▌| 240/250 [3:49:31<09:40, 58.07s/it]Evaluating commonsenseqa :  96%|█████████▋| 241/250 [3:50:30<08:44, 58.31s/it]Evaluating commonsenseqa :  97%|█████████▋| 242/250 [3:51:29<07:46, 58.33s/it]Evaluating commonsenseqa :  97%|█████████▋| 243/250 [3:52:27<06:48, 58.42s/it]Evaluating commonsenseqa :  98%|█████████▊| 244/250 [3:53:26<05:51, 58.60s/it]Evaluating commonsenseqa :  98%|█████████▊| 245/250 [3:54:24<04:51, 58.39s/it]Evaluating commonsenseqa :  98%|█████████▊| 246/250 [3:55:22<03:52, 58.25s/it]Evaluating commonsenseqa :  99%|█████████▉| 247/250 [3:56:21<02:55, 58.54s/it]Evaluating commonsenseqa :  99%|█████████▉| 248/250 [3:57:19<01:56, 58.20s/it]Evaluating commonsenseqa : 100%|█████████▉| 249/250 [3:58:17<00:58, 58.05s/it]Evaluating commonsenseqa : 100%|██████████| 250/250 [3:59:15<00:00, 58.16s/it]Evaluating commonsenseqa : 100%|██████████| 250/250 [3:59:15<00:00, 57.42s/it]
name: commonsenseqa | avg. gen lenth: 334.139 | time: 14357.220797538757s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr gpu04 --master_port 12094 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 8 6 7 8 9 10 True 4096 4
[2023-09-03 04:54:50,095] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 8
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o8-tgsm8k-s1-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 491911.76it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:10<00:10, 10.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.98s/it]
 > number of parameters: 6738415616
[2023-09-03 04:55:05,608] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-03 04:55:05,828] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-03 04:55:05,829] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f3d490>
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-03 04:55:05,830] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-03 04:55:05,831] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-03 04:55:05,831] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/250 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: Mary added a total of 7 stickers/page * 6 pages= <<7*6=42>>42 stickers to the 6 other pages.
In total, Mary added 3 large stickers + 42 stickers = <<3+42=45>>45 stickers to her journal.
Since she started with 89 stickers, she now has 89 - 45 = <<89-45=44>>44 stickers left.
So the final answer is 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: If he babysits for 2 hours at $7 per hour, he will earn 2*7 = $<<2*7=14>>14
This week he will earn $5 allowance, $10 mowing the lawn and $14 from babysitting for a total of 5+10+14 = $<<5+10+14=29>>29
If we add the $29 he will earn to his $65 savings, he will have a total of 29 + 65 = $<<29+65=94>>94
The bike costs $100 and he will have $94 leaving $100-$94 = $<<100-94=6>>6 more that he will need to earn
So the final answer is 6

Input: Mark has kangaroos and goats.  Kangaroos have two legs and goats have four legs.  If he has 23 kangaroos and three times as many goats as kangaroos what is the total number of legs of all his animals?
Output: His kangaroos have a total of 23*2=<<23*2=46>>46 legs
He has 23*3=<<23*3=69>>69 goats
The goats have 69*4=<<69*4=276>>276 legs
So in total his animals have 276+46=<<276+46=322>>322 legs
So the final answer is 322

Input: Josh’s mom gives him $20 to go shopping at the mall. He buys a hat for $10 and a pencil for $2. Then he buys four cookies. If each cookie costs $1.25, how much money does Josh have left?
Output: After buying a hat, Josh has $20 - $10 = $<<20-10=10>>10
After buying a pencil, Josh has $10 - $2 = $<<10-2=8>>8
The total cost of cookies is 4 * $1.25 = $<<4*1.25=5>>5
After buying the cookies, Josh has $8 - $5 = $<<8-5=3>>3
So the final answer is 3

Input: George's bowling team is one round away from breaking the league record for most points scored in a season. The old record is an average score per player of 287 per round. Each team has 4 players and there are 10 rounds in the season. Through the first 9 rounds, his team has scored a total of 10,440. How many points less than the current league record per game average is the minimum average they need to score, per player, in the final round to tie the league record?
Output: The old team per round record is 1,148 because 287 x 4 = <<1148=1148>>1,148
The team season record is 11,480 because 10 x 1,248 = 11,480
They need 1,040 points in the final round to tie the record because 11,480 - 10,440 = <<11480-10440=1040>>1,040
They need to average 260 points each because 1,040 / 4 = <<1040/4=260>>260
This is 27 points less than the current record average because 287 - 260 = <<27=27>>27
So the final answer is 27

Input: Max was doing homework in three different subjects. It took him 20 minutes to finish tasks from biology and two times more time to finish history. Geography took him the most time, three times more than history. How much time did Max spend on doing his homework?
Output: Max finished history in 20 * 2 = <<20*2=40>>40 minutes.
Finishing geography took the most time, which is 40 * 3 = <<40*3=120>>120 minutes.
In total, for all three subjects, Max needed 20 + 40 + 120 = <<20+40+120=180>>180 minutes.
So the final answer is 180

Input: Sophia ate 1/6 of her pie and she put the rest on the fridge. If the pie left in the fridge weighs 1200 grams, how many grams did Sophia eat?
Output: If Sophia ate 1/6 of the pie, then 6/6 - 1/6 = 5/6 is left in the fridge.
Let x be the pie's original weight.
The current weight of the pie can be described by 5x/6=1200 grams
So, 5x=7200.
And, the original weight is x = <<1440=1440>>1440 grams.
So, Sophia ate 1440 grams original - 1200 grams after= <<1440-1200=240>>240 grams of pie.
So the final answer is 240

Input: Sarah, Mary, and Tuan decided to go to the restaurant for a meal. They decided to split the cost of the meal evenly. If the total price of the meal comes to $67 and they have a coupon for $4, how much does each person need to contribute to the bill?
Output: After using the coupon, the final price comes to 67 - 4 = <<67-4=63>>63 dollars.
With three people, they each need to pay 63 / 3 = <<63/3=21>>21 dollars each.
So the final answer is 21

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o8-tgsm8k-s1-rTrue-m4096
Evaluating commonsenseqa :   0%|          | 1/250 [00:56<3:56:25, 56.97s/it]           Evaluating commonsenseqa :   1%|          | 2/250 [01:53<3:54:59, 56.85s/it]Evaluating commonsenseqa :   1%|          | 3/250 [02:50<3:54:18, 56.92s/it]           Evaluating commonsenseqa :   2%|▏         | 4/250 [03:47<3:53:03, 56.84s/it]         Evaluating commonsenseqa :   2%|▏         | 5/250 [04:44<3:51:51, 56.78s/it]         Evaluating commonsenseqa :   2%|▏         | 6/250 [05:41<3:51:33, 56.94s/it]         Evaluating commonsenseqa :   3%|▎         | 7/250 [06:38<3:50:13, 56.85s/it]         Evaluating commonsenseqa :   3%|▎         | 8/250 [07:35<3:49:44, 56.96s/it]Evaluating commonsenseqa :   4%|▎         | 9/250 [08:32<3:49:41, 57.18s/it]         Evaluating commonsenseqa :   4%|▍         | 10/250 [09:30<3:49:46, 57.45s/it]        Evaluating commonsenseqa :   4%|▍         | 11/250 [10:28<3:49:25, 57.60s/it]        Evaluating commonsenseqa :   5%|▍         | 12/250 [11:26<3:48:32, 57.61s/it]Evaluating commonsenseqa :   5%|▌         | 13/250 [12:23<3:46:42, 57.40s/it]                                                                                                Evaluating commonsenseqa :   6%|▌         | 14/250 [13:20<3:44:51, 57.17s/it]Evaluating commonsenseqa :   6%|▌         | 15/250 [14:18<3:44:57, 57.44s/it]                                                                                                Evaluating commonsenseqa :   6%|▋         | 16/250 [15:16<3:44:59, 57.69s/it]Evaluating commonsenseqa :   7%|▋         | 17/250 [16:13<3:43:05, 57.45s/it]        Evaluating commonsenseqa :   7%|▋         | 18/250 [17:10<3:41:34, 57.30s/it]        Evaluating commonsenseqa :   8%|▊         | 19/250 [18:08<3:41:20, 57.49s/it]        Evaluating commonsenseqa :   8%|▊         | 20/250 [19:05<3:40:27, 57.51s/it]Evaluating commonsenseqa :   8%|▊         | 21/250 [20:03<3:39:24, 57.49s/it]        Evaluating commonsenseqa :   9%|▉         | 22/250 [21:01<3:39:19, 57.72s/it]         Evaluating commonsenseqa :   9%|▉         | 23/250 [21:59<3:38:18, 57.70s/it]         Evaluating commonsenseqa :  10%|▉         | 24/250 [22:56<3:37:29, 57.74s/it]         Evaluating commonsenseqa :  10%|█         | 25/250 [23:54<3:36:31, 57.74s/it]         Evaluating commonsenseqa :  10%|█         | 26/250 [24:52<3:36:10, 57.91s/it]Evaluating commonsenseqa :  11%|█         | 27/250 [25:51<3:35:34, 58.00s/it]           Evaluating commonsenseqa :  11%|█         | 28/250 [26:47<3:33:09, 57.61s/it]           Evaluating commonsenseqa :  12%|█▏        | 29/250 [27:44<3:31:14, 57.35s/it]                                                                                                    Evaluating commonsenseqa :  12%|█▏        | 30/250 [28:42<3:30:40, 57.46s/it]Evaluating commonsenseqa :  12%|█▏        | 31/250 [29:40<3:30:41, 57.72s/it]         Evaluating commonsenseqa :  13%|█▎        | 32/250 [30:39<3:30:30, 57.94s/it]         Evaluating commonsenseqa :  13%|█▎        | 33/250 [31:36<3:29:05, 57.81s/it]         Evaluating commonsenseqa :  14%|█▎        | 34/250 [32:34<3:28:14, 57.85s/it]Evaluating commonsenseqa :  14%|█▍        | 35/250 [33:33<3:28:36, 58.22s/it]         Evaluating commonsenseqa :  14%|█▍        | 36/250 [34:30<3:26:26, 57.88s/it]         Evaluating commonsenseqa :  15%|█▍        | 37/250 [35:27<3:24:32, 57.62s/it]         Evaluating commonsenseqa :  15%|█▌        | 38/250 [36:24<3:22:47, 57.39s/it]Evaluating commonsenseqa :  16%|█▌        | 39/250 [37:23<3:23:08, 57.77s/it]                  Evaluating commonsenseqa :  16%|█▌        | 40/250 [38:21<3:22:09, 57.76s/it]Evaluating commonsenseqa :  16%|█▋        | 41/250 [39:17<3:20:03, 57.43s/it]                                                                                                    Evaluating commonsenseqa :  17%|█▋        | 42/250 [40:14<3:18:26, 57.24s/it]Evaluating commonsenseqa :  17%|█▋        | 43/250 [41:12<3:17:48, 57.33s/it]         Evaluating commonsenseqa :  18%|█▊        | 44/250 [42:09<3:16:33, 57.25s/it]         Evaluating commonsenseqa :  18%|█▊        | 45/250 [43:06<3:15:58, 57.36s/it]         Evaluating commonsenseqa :  18%|█▊        | 46/250 [44:04<3:15:20, 57.45s/it]Evaluating commonsenseqa :  19%|█▉        | 47/250 [45:02<3:14:35, 57.52s/it]         Evaluating commonsenseqa :  19%|█▉        | 48/250 [46:00<3:14:58, 57.91s/it]         Evaluating commonsenseqa :  20%|█▉        | 49/250 [46:58<3:14:01, 57.92s/it]         Evaluating commonsenseqa :  20%|██        | 50/250 [47:57<3:13:21, 58.01s/it]         Evaluating commonsenseqa :  20%|██        | 51/250 [48:54<3:12:19, 57.99s/it]         Evaluating commonsenseqa :  21%|██        | 52/250 [49:51<3:10:22, 57.69s/it]Evaluating commonsenseqa :  21%|██        | 53/250 [50:49<3:08:58, 57.55s/it]                                                                                                    Evaluating commonsenseqa :  22%|██▏       | 54/250 [51:46<3:08:15, 57.63s/it]Evaluating commonsenseqa :  22%|██▏       | 55/250 [52:43<3:06:29, 57.38s/it]                                                                                                    Evaluating commonsenseqa :  22%|██▏       | 56/250 [53:41<3:06:14, 57.60s/it]Evaluating commonsenseqa :  23%|██▎       | 57/250 [54:39<3:04:53, 57.48s/it]         Evaluating commonsenseqa :  23%|██▎       | 58/250 [55:36<3:04:00, 57.50s/it]         Evaluating commonsenseqa :  24%|██▎       | 59/250 [56:32<3:01:36, 57.05s/it]         Evaluating commonsenseqa :  24%|██▍       | 60/250 [57:29<3:00:17, 56.93s/it]Evaluating commonsenseqa :  24%|██▍       | 61/250 [58:26<2:59:45, 57.07s/it]         Evaluating commonsenseqa :  25%|██▍       | 62/250 [59:24<2:59:05, 57.16s/it]         Evaluating commonsenseqa :  25%|██▌       | 63/250 [1:00:20<2:57:51, 57.07s/it]       Evaluating commonsenseqa :  26%|██▌       | 64/250 [1:01:00<2:40:32, 51.79s/it]Evaluating commonsenseqa :  26%|██▌       | 65/250 [1:01:57<2:44:42, 53.42s/it]       Evaluating commonsenseqa :  26%|██▋       | 66/250 [1:02:54<2:47:08, 54.50s/it]       Evaluating commonsenseqa :  27%|██▋       | 67/250 [1:03:53<2:50:09, 55.79s/it]       Evaluating commonsenseqa :  27%|██▋       | 68/250 [1:04:50<2:50:34, 56.23s/it]Evaluating commonsenseqa :  28%|██▊       | 69/250 [1:05:47<2:50:22, 56.48s/it]                                                                                                    Evaluating commonsenseqa :  28%|██▊       | 70/250 [1:06:45<2:50:26, 56.81s/it]Evaluating commonsenseqa :  28%|██▊       | 71/250 [1:07:43<2:50:50, 57.27s/it]       Evaluating commonsenseqa :  29%|██▉       | 72/250 [1:08:41<2:50:28, 57.46s/it]       Evaluating commonsenseqa :  29%|██▉       | 73/250 [1:09:40<2:50:24, 57.77s/it]       Evaluating commonsenseqa :  30%|██▉       | 74/250 [1:10:39<2:50:42, 58.19s/it]Evaluating commonsenseqa :  30%|███       | 75/250 [1:11:36<2:49:03, 57.96s/it]              Evaluating commonsenseqa :  30%|███       | 76/250 [1:12:34<2:47:57, 57.91s/it]Evaluating commonsenseqa :  31%|███       | 77/250 [1:13:32<2:47:27, 58.08s/it]       Evaluating commonsenseqa :  31%|███       | 78/250 [1:14:29<2:45:28, 57.73s/it]       Evaluating commonsenseqa :  32%|███▏      | 79/250 [1:15:27<2:44:49, 57.83s/it]     Evaluating commonsenseqa :  32%|███▏      | 80/250 [1:16:25<2:43:51, 57.83s/it]Evaluating commonsenseqa :  32%|███▏      | 81/250 [1:17:25<2:44:27, 58.39s/it]                                                                                                  Evaluating commonsenseqa :  33%|███▎      | 82/250 [1:18:23<2:43:10, 58.28s/it]     Evaluating commonsenseqa :  33%|███▎      | 83/250 [1:19:21<2:42:06, 58.24s/it]     Evaluating commonsenseqa :  34%|███▎      | 84/250 [1:20:19<2:40:41, 58.08s/it]Evaluating commonsenseqa :  34%|███▍      | 85/250 [1:21:17<2:39:48, 58.11s/it]                                                                                                    Evaluating commonsenseqa :  34%|███▍      | 86/250 [1:22:15<2:38:47, 58.10s/it]Evaluating commonsenseqa :  35%|███▍      | 87/250 [1:23:12<2:37:04, 57.82s/it]       Evaluating commonsenseqa :  35%|███▌      | 88/250 [1:24:10<2:36:25, 57.94s/it]       Evaluating commonsenseqa :  36%|███▌      | 89/250 [1:25:08<2:35:23, 57.91s/it]       Evaluating commonsenseqa :  36%|███▌      | 90/250 [1:26:06<2:34:28, 57.93s/it]       Evaluating commonsenseqa :  36%|███▋      | 91/250 [1:27:04<2:32:57, 57.72s/it]       Evaluating commonsenseqa :  37%|███▋      | 92/250 [1:28:01<2:32:01, 57.73s/it]       Evaluating commonsenseqa :  37%|███▋      | 93/250 [1:29:01<2:32:14, 58.18s/it]       Evaluating commonsenseqa :  38%|███▊      | 94/250 [1:29:57<2:30:19, 57.81s/it]Evaluating commonsenseqa :  38%|███▊      | 95/250 [1:30:55<2:29:21, 57.82s/it]                                                                                                      Evaluating commonsenseqa :  38%|███▊      | 96/250 [1:31:53<2:28:06, 57.70s/it]Evaluating commonsenseqa :  39%|███▉      | 97/250 [1:32:50<2:26:44, 57.54s/it]       Evaluating commonsenseqa :  39%|███▉      | 98/250 [1:33:48<2:26:03, 57.65s/it]       Evaluating commonsenseqa :  40%|███▉      | 99/250 [1:34:47<2:25:59, 58.01s/it]       Evaluating commonsenseqa :  40%|████      | 100/250 [1:35:30<2:14:16, 53.71s/it]Evaluating commonsenseqa :  40%|████      | 101/250 [1:36:28<2:16:23, 54.92s/it]      Evaluating commonsenseqa :  41%|████      | 102/250 [1:37:26<2:17:35, 55.78s/it]      Evaluating commonsenseqa :  41%|████      | 103/250 [1:38:24<2:18:17, 56.45s/it]      Evaluating commonsenseqa :  42%|████▏     | 104/250 [1:39:23<2:19:30, 57.33s/it]    Evaluating commonsenseqa :  42%|████▏     | 105/250 [1:40:20<2:18:22, 57.26s/it]    Evaluating commonsenseqa :  42%|████▏     | 106/250 [1:41:19<2:18:27, 57.69s/it]Evaluating commonsenseqa :  43%|████▎     | 107/250 [1:42:16<2:17:06, 57.52s/it]    Evaluating commonsenseqa :  43%|████▎     | 108/250 [1:43:14<2:16:01, 57.47s/it]    Evaluating commonsenseqa :  44%|████▎     | 109/250 [1:44:12<2:15:36, 57.70s/it]    Evaluating commonsenseqa :  44%|████▍     | 110/250 [1:45:09<2:14:30, 57.65s/it]    Evaluating commonsenseqa :  44%|████▍     | 111/250 [1:46:07<2:13:32, 57.64s/it]    Evaluating commonsenseqa :  45%|████▍     | 112/250 [1:47:04<2:12:11, 57.47s/it]Evaluating commonsenseqa :  45%|████▌     | 113/250 [1:47:51<2:04:01, 54.32s/it]    Evaluating commonsenseqa :  46%|████▌     | 114/250 [1:48:50<2:06:11, 55.67s/it]    Evaluating commonsenseqa :  46%|████▌     | 115/250 [1:49:48<2:07:15, 56.56s/it]      Evaluating commonsenseqa :  46%|████▋     | 116/250 [1:50:45<2:06:34, 56.67s/it]Evaluating commonsenseqa :  47%|████▋     | 117/250 [1:51:43<2:06:32, 57.08s/it]            Evaluating commonsenseqa :  47%|████▋     | 118/250 [1:52:40<2:05:26, 57.02s/it]      Evaluating commonsenseqa :  48%|████▊     | 119/250 [1:53:37<2:04:35, 57.06s/it]      Evaluating commonsenseqa :  48%|████▊     | 120/250 [1:54:37<2:05:07, 57.75s/it]Evaluating commonsenseqa :  48%|████▊     | 121/250 [1:55:35<2:04:09, 57.75s/it]      Evaluating commonsenseqa :  49%|████▉     | 122/250 [1:56:32<2:03:16, 57.78s/it]      Evaluating commonsenseqa :  49%|████▉     | 123/250 [1:57:30<2:02:29, 57.87s/it]      Evaluating commonsenseqa :  50%|████▉     | 124/250 [1:58:28<2:01:28, 57.85s/it]Evaluating commonsenseqa :  50%|█████     | 125/250 [1:59:26<2:00:16, 57.73s/it]                                                                                                       Evaluating commonsenseqa :  50%|█████     | 126/250 [2:00:24<1:59:26, 57.80s/it]Evaluating commonsenseqa :  51%|█████     | 127/250 [2:01:22<1:58:47, 57.95s/it]                                                                                                       Evaluating commonsenseqa :  51%|█████     | 128/250 [2:02:19<1:57:14, 57.66s/it]    Evaluating commonsenseqa :  52%|█████▏    | 129/250 [2:03:18<1:57:08, 58.09s/it]  Evaluating commonsenseqa :  52%|█████▏    | 130/250 [2:04:16<1:56:20, 58.17s/it]Evaluating commonsenseqa :  52%|█████▏    | 131/250 [2:05:13<1:54:37, 57.79s/it]    Evaluating commonsenseqa :  53%|█████▎    | 132/250 [2:06:11<1:53:34, 57.75s/it]    Evaluating commonsenseqa :  53%|█████▎    | 133/250 [2:07:09<1:53:01, 57.96s/it]    Evaluating commonsenseqa :  54%|█████▎    | 134/250 [2:08:07<1:51:43, 57.79s/it]    Evaluating commonsenseqa :  54%|█████▍    | 135/250 [2:09:04<1:50:33, 57.69s/it]    Evaluating commonsenseqa :  54%|█████▍    | 136/250 [2:10:02<1:49:50, 57.82s/it]Evaluating commonsenseqa :  55%|█████▍    | 137/250 [2:11:00<1:49:02, 57.89s/it]    Evaluating commonsenseqa :  55%|█████▌    | 138/250 [2:11:58<1:48:02, 57.88s/it]    Evaluating commonsenseqa :  56%|█████▌    | 139/250 [2:12:55<1:46:30, 57.57s/it]                                                                                                 Evaluating commonsenseqa :  56%|█████▌    | 140/250 [2:13:52<1:45:22, 57.47s/it]Evaluating commonsenseqa :  56%|█████▋    | 141/250 [2:14:51<1:44:59, 57.79s/it]Evaluating commonsenseqa :  57%|█████▋    | 142/250 [2:15:49<1:44:13, 57.91s/it]  Evaluating commonsenseqa :  57%|█████▋    | 143/250 [2:16:47<1:43:17, 57.92s/it]    Evaluating commonsenseqa :  58%|█████▊    | 144/250 [2:17:29<1:33:56, 53.18s/it]Evaluating commonsenseqa :  58%|█████▊    | 145/250 [2:18:27<1:35:22, 54.50s/it]Evaluating commonsenseqa :  58%|█████▊    | 146/250 [2:19:24<1:35:44, 55.24s/it]Evaluating commonsenseqa :  59%|█████▉    | 147/250 [2:20:21<1:36:06, 55.99s/it]    Evaluating commonsenseqa :  59%|█████▉    | 148/250 [2:21:18<1:35:40, 56.27s/it]Evaluating commonsenseqa :  60%|█████▉    | 149/250 [2:22:17<1:36:06, 57.09s/it]        Evaluating commonsenseqa :  60%|██████    | 150/250 [2:23:15<1:35:16, 57.17s/it]Evaluating commonsenseqa :  60%|██████    | 151/250 [2:24:12<1:34:17, 57.15s/it]    Evaluating commonsenseqa :  61%|██████    | 152/250 [2:25:09<1:33:23, 57.17s/it]    Evaluating commonsenseqa :  61%|██████    | 153/250 [2:26:06<1:32:15, 57.07s/it]    Evaluating commonsenseqa :  62%|██████▏   | 154/250 [2:27:04<1:31:35, 57.24s/it]Evaluating commonsenseqa :  62%|██████▏   | 155/250 [2:28:01<1:30:38, 57.25s/it]                                                                                                   Evaluating commonsenseqa :  62%|██████▏   | 156/250 [2:28:59<1:30:03, 57.49s/it]Evaluating commonsenseqa :  63%|██████▎   | 157/250 [2:29:57<1:29:23, 57.68s/it]  Evaluating commonsenseqa :  63%|██████▎   | 158/250 [2:30:55<1:28:28, 57.70s/it]  Evaluating commonsenseqa :  64%|██████▎   | 159/250 [2:31:52<1:27:06, 57.44s/it]  Evaluating commonsenseqa :  64%|██████▍   | 160/250 [2:32:50<1:26:26, 57.63s/it]Evaluating commonsenseqa :  64%|██████▍   | 161/250 [2:33:47<1:25:13, 57.46s/it]  Evaluating commonsenseqa :  65%|██████▍   | 162/250 [2:34:44<1:24:14, 57.43s/it]  Evaluating commonsenseqa :  65%|██████▌   | 163/250 [2:35:43<1:23:57, 57.90s/it]  Evaluating commonsenseqa :  66%|██████▌   | 164/250 [2:36:40<1:22:37, 57.65s/it]  Evaluating commonsenseqa :  66%|██████▌   | 165/250 [2:37:37<1:21:28, 57.51s/it]  Evaluating commonsenseqa :  66%|██████▋   | 166/250 [2:38:34<1:20:00, 57.15s/it]Evaluating commonsenseqa :  67%|██████▋   | 167/250 [2:39:30<1:18:42, 56.90s/it]  Evaluating commonsenseqa :  67%|██████▋   | 168/250 [2:40:26<1:17:19, 56.58s/it]  Evaluating commonsenseqa :  68%|██████▊   | 169/250 [2:41:21<1:16:02, 56.32s/it]  Evaluating commonsenseqa :  68%|██████▊   | 170/250 [2:42:19<1:15:33, 56.67s/it]Evaluating commonsenseqa :  68%|██████▊   | 171/250 [2:43:16<1:14:48, 56.82s/it]                                                                                                   Evaluating commonsenseqa :  69%|██████▉   | 172/250 [2:44:13<1:13:48, 56.77s/it]Evaluating commonsenseqa :  69%|██████▉   | 173/250 [2:45:09<1:12:30, 56.50s/it]  Evaluating commonsenseqa :  70%|██████▉   | 174/250 [2:46:04<1:11:02, 56.09s/it]    Evaluating commonsenseqa :  70%|███████   | 175/250 [2:46:59<1:09:50, 55.87s/it]    Evaluating commonsenseqa :  70%|███████   | 176/250 [2:47:54<1:08:40, 55.68s/it]Evaluating commonsenseqa :  71%|███████   | 177/250 [2:48:51<1:08:11, 56.04s/it]        Evaluating commonsenseqa :  71%|███████   | 178/250 [2:49:35<1:02:49, 52.35s/it]Evaluating commonsenseqa :  72%|███████▏  | 179/250 [2:50:33<1:03:51, 53.96s/it]  Evaluating commonsenseqa :  72%|███████▏  | 180/250 [2:51:29<1:03:42, 54.60s/it]  Evaluating commonsenseqa :  72%|███████▏  | 181/250 [2:52:26<1:03:32, 55.25s/it]  Evaluating commonsenseqa :  73%|███████▎  | 182/250 [2:53:21<1:02:42, 55.33s/it]Evaluating commonsenseqa :  73%|███████▎  | 183/250 [2:54:00<56:18, 50.42s/it]  Evaluating commonsenseqa :  74%|███████▎  | 184/250 [2:54:25<46:54, 42.64s/it]Evaluating commonsenseqa :  74%|███████▍  | 185/250 [2:55:21<50:34, 46.69s/it]    Evaluating commonsenseqa :  74%|███████▍  | 186/250 [2:56:18<53:04, 49.76s/it]    Evaluating commonsenseqa :  75%|███████▍  | 187/250 [2:57:13<53:59, 51.42s/it]    Evaluating commonsenseqa :  75%|███████▌  | 188/250 [2:58:09<54:33, 52.80s/it]Evaluating commonsenseqa :  76%|███████▌  | 189/250 [2:59:05<54:36, 53.71s/it]        Evaluating commonsenseqa :  76%|███████▌  | 190/250 [3:00:00<54:08, 54.15s/it]Evaluating commonsenseqa :  76%|███████▋  | 191/250 [3:00:56<53:54, 54.83s/it]    Evaluating commonsenseqa :  77%|███████▋  | 192/250 [3:01:52<53:17, 55.13s/it]    Evaluating commonsenseqa :  77%|███████▋  | 193/250 [3:02:48<52:31, 55.29s/it]    Evaluating commonsenseqa :  78%|███████▊  | 194/250 [3:03:44<51:47, 55.48s/it]Evaluating commonsenseqa :  78%|███████▊  | 195/250 [3:04:40<50:59, 55.63s/it]                                                                                                       Evaluating commonsenseqa :  78%|███████▊  | 196/250 [3:05:37<50:24, 56.02s/it]Evaluating commonsenseqa :  79%|███████▉  | 197/250 [3:06:33<49:34, 56.13s/it]    Evaluating commonsenseqa :  79%|███████▉  | 198/250 [3:07:30<48:49, 56.34s/it]    Evaluating commonsenseqa :  80%|███████▉  | 199/250 [3:08:28<48:27, 57.01s/it]    Evaluating commonsenseqa :  80%|████████  | 200/250 [3:09:24<47:13, 56.67s/it]Evaluating commonsenseqa :  80%|████████  | 201/250 [3:10:21<46:10, 56.54s/it]/it]Evaluating commonsenseqa : 100%|██████████| 250/250 [4:42:11<00:00, 67.72s/it]
name: commonsenseqa | avg. gen lenth: 304.731 | time: 16932.534699440002s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr gpu03 --master_port 17129 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o5-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 5 1 2 3 4 5 True 4096 4
[2023-09-03 08:05:00,491] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o5-tgsm8k-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 5
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o5-tgsm8k-s1-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 636456.92it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:14<00:14, 14.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:19<00:00,  8.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:19<00:00,  9.58s/it]
 > number of parameters: 6738415616
[2023-09-03 08:05:21,136] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-03 08:05:21,356] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-03 08:05:21,358] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-03 08:05:21,358] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-03 08:05:21,358] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-03 08:05:21,358] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-03 08:05:21,358] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f3d490>
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-03 08:05:21,359] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-03 08:05:21,360] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-03 08:05:21,360] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-03 08:05:21,360] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-03 08:05:21,360] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-03 08:05:21,360] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-03 08:05:21,360] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-03 08:05:21,360] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-03 08:05:21,360] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-03 08:05:21,360] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-03 08:05:21,360] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-03 08:05:21,360] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-03 08:05:21,360] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-03 08:05:21,360] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-03 08:05:21,360] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-03 08:05:21,360] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-03 08:05:21,360] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-03 08:05:21,360] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-03 08:05:21,360] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-03 08:05:21,360] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-03 08:05:21,360] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-03 08:05:21,360] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-03 08:05:21,360] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/250 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: Mary added a total of 7 stickers/page * 6 pages= <<7*6=42>>42 stickers to the 6 other pages.
In total, Mary added 3 large stickers + 42 stickers = <<3+42=45>>45 stickers to her journal.
Since she started with 89 stickers, she now has 89 - 45 = <<89-45=44>>44 stickers left.
So the final answer is 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: If he babysits for 2 hours at $7 per hour, he will earn 2*7 = $<<2*7=14>>14
This week he will earn $5 allowance, $10 mowing the lawn and $14 from babysitting for a total of 5+10+14 = $<<5+10+14=29>>29
If we add the $29 he will earn to his $65 savings, he will have a total of 29 + 65 = $<<29+65=94>>94
The bike costs $100 and he will have $94 leaving $100-$94 = $<<100-94=6>>6 more that he will need to earn
So the final answer is 6

Input: Mark has kangaroos and goats.  Kangaroos have two legs and goats have four legs.  If he has 23 kangaroos and three times as many goats as kangaroos what is the total number of legs of all his animals?
Output: His kangaroos have a total of 23*2=<<23*2=46>>46 legs
He has 23*3=<<23*3=69>>69 goats
The goats have 69*4=<<69*4=276>>276 legs
So in total his animals have 276+46=<<276+46=322>>322 legs
So the final answer is 322

Input: Josh’s mom gives him $20 to go shopping at the mall. He buys a hat for $10 and a pencil for $2. Then he buys four cookies. If each cookie costs $1.25, how much money does Josh have left?
Output: After buying a hat, Josh has $20 - $10 = $<<20-10=10>>10
After buying a pencil, Josh has $10 - $2 = $<<10-2=8>>8
The total cost of cookies is 4 * $1.25 = $<<4*1.25=5>>5
After buying the cookies, Josh has $8 - $5 = $<<8-5=3>>3
So the final answer is 3

Input: George's bowling team is one round away from breaking the league record for most points scored in a season. The old record is an average score per player of 287 per round. Each team has 4 players and there are 10 rounds in the season. Through the first 9 rounds, his team has scored a total of 10,440. How many points less than the current league record per game average is the minimum average they need to score, per player, in the final round to tie the league record?
Output: The old team per round record is 1,148 because 287 x 4 = <<1148=1148>>1,148
The team season record is 11,480 because 10 x 1,248 = 11,480
They need 1,040 points in the final round to tie the record because 11,480 - 10,440 = <<11480-10440=1040>>1,040
They need to average 260 points each because 1,040 / 4 = <<1040/4=260>>260
This is 27 points less than the current record average because 287 - 260 = <<27=27>>27
So the final answer is 27

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o5-tgsm8k-s1-rTrue-m4096
Evaluating commonsenseqa :   0%|          | 1/250 [01:06<4:34:57, 66.26s/it]                                                                                                                 Evaluating commonsenseqa :   1%|          | 2/250 [02:12<4:32:49, 66.01s/it]                    Evaluating commonsenseqa :   1%|          | 3/250 [03:18<4:32:12, 66.12s/it]Evaluating commonsenseqa :   2%|▏         | 4/250 [04:22<4:27:40, 65.29s/it]                                                                                                                                       Evaluating commonsenseqa :   2%|▏         | 5/250 [05:27<4:26:53, 65.36s/it]                  Evaluating commonsenseqa :   2%|▏         | 6/250 [06:32<4:25:28, 65.28s/it]Evaluating commonsenseqa :   3%|▎         | 7/250 [07:37<4:22:48, 64.89s/it]Evaluating commonsenseqa :   3%|▎Evaluating commonsenseqa :  84%|████████▍ | 211/250 [3:19:00<35:29, 54.59s/it]Evaluating commonsenseqa :  85%|████████▍ | 212/250 [3:19:57<35:00, 55.28s/it]Evaluating commonsenseqa :  85%|████████▌ | 213/250 [3:20:53<34:17, 55.61s/it]Evaluating commonsenseqa :  86%|████████▌ | 214/250 [3:21:50<33:28, 55.80s/it]                                                               Evaluating commonsenseqa :  86%|████████▌ | 215/250 [3:22:46<32:38, 55.97s/it]Evaluating commonsenseqa :  86%|████████▋ | 216/250 [3:23:42<31:46, 56.06s/it]Evaluating commonsenseqa :  87%|████████▋ | 217/250 [3:24:12<26:26, 48.08s/it]Evaluating commonsenseqa :  87%|████████▋ | 218/250 [3:25:05<26:33, 49.79s/it]Evaluating commonsenseqa :  88%|████████▊ | 219/250 [3:26:01<26:36, 51.49s/it]Evaluating commonsenseqa :  88%|████████▊ | 220/250 [3:26:58<26:37, 53.25s/it]Evaluating commonsenseqa :  88%|████████▊ | 221/250 [3:27:55<26:11, 54.19s/it]Evaluating commonsenseqa :  89%|████████▉ | 222/250 [3:28:50<25:29, 54.63s/it]Evaluating commonsenseqa :  89%|████████▉ | 223/250 [3:29:46<24:44, 54.99s/it]Evaluating commonsenseqa :  90%|████████▉ | 224/250 [3:30:42<23:54, 55.16s/it]Evaluating commonsenseqa :  90%|█████████ | 225/250 [3:31:31<22:12, 53.31s/it]Evaluating commonsenseqa :  90%|█████████ | 226/250 [3:32:04<18:58, 47.45s/it]Evaluating commonsenseqa :  91%|█████████ | 227/250 [3:33:01<19:13, 50.16s/it]Evaluating commonsenseqa :  91%|█████████ | 228/250 [3:33:57<19:05, 52.05s/it]Evaluating commonsenseqa :  92%|█████████▏| 229/250 [3:34:53<18:38, 53.25s/it]Evaluating commonsenseqa :  92%|█████████▏| 230/250 [3:35:50<18:07, 54.38s/it]Evaluating commonsenseqa :  92%|█████████▏| 231/250 [3:36:48<17:29, 55.25s/it]                                                             Evaluating commonsenseqa :  93%|█████████▎| 232/250 [3:37:45<16:43, 55.73s/it]Evaluating commonsenseqa :  93%|█████████▎| 233/250 [3:38:42<15:53, 56.12s/it]Evaluating commonsenseqa :  94%|█████████▎| 234/250 [3:39:38<14:57, 56.09s/it]Evaluating commonsenseqa :  94%|█████████▍| 235/250 [3:40:34<14:03, 56.20s/it]Evaluating commonsenseqa :  94%|█████████▍| 236/250 [3:41:31<13:08, 56.31s/it]Evaluating commonsenseqa :  95%|█████████▍| 237/250 [3:42:28<12:15, 56.57s/it]Evaluating commonsenseqa :  95%|█████████▌| 238/250 [3:43:24<11:17, 56.43s/it]Evaluating commonsenseqa :  96%|█████████▌| 239/250 [3:44:21<10:21, 56.50s/it]Evaluating commonsenseqa :  96%|█████████▌| 240/250 [3:45:16<09:22, 56.23s/it]Evaluating commonsenseqa :  96%|█████████▋| 241/250 [3:46:14<08:30, 56.67s/it]Evaluating commonsenseqa :  97%|█████████▋| 242/250 [3:47:10<07:32, 56.56s/it]Evaluating commonsenseqa :  97%|█████████▋| 243/250 [3:48:06<06:34, 56.42s/it]Evaluating commonsenseqa :  98%|█████████▊| 244/250 [3:49:02<05:36, 56.14s/it]Evaluating commonsenseqa :  98%|█████████▊| 245/250 [3:49:58<04:40, 56.08s/it]Evaluating commonsenseqa :  98%|█████████▊| 246/250 [3:50:54<03:44, 56.14s/it]Evaluating commonsenseqa :  99%|█████████▉| 247/250 [3:51:50<02:48, 56.21s/it]Evaluating commonsenseqa :  99%|█████████▉| 248/250 [3:52:47<01:52, 56.45s/it]Evaluating commonsenseqa : 100%|█████████▉| 249/250 [3:53:44<00:56, 56.38s/it]Evaluating commonsenseqa : 100%|██████████| 250/250 [3:54:40<00:00, 56.32s/it]Evaluating commonsenseqa : 100%|██████████| 250/250 [3:54:40<00:00, 56.32s/it]
name: commonsenseqa | avg. gen lenth: 361.525 | time: 14082.1408264637s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr gpu04 --master_port 12094 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o9-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 9 6 7 8 9 10 True 4096 4
[2023-09-03 08:49:56,216] [INFO] [real_accelerator.py:133:get_accelerator] SettingEvaluating commonsenseqa :  18%|█▊        | 44/250 [45:51<3:42:18, 64.75s/it]................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o9-tgsm8k-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 9
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o9-tgsm8k-s1-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 469768.61it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:10<00:10, 10.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:14<00:00,  6.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:14<00:00,  7.10s/it]
 > number of parameters: 6738415616
[2023-09-03 08:50:11,891] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-03 08:50:12,121] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-03 08:50:12,123] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-03 08:50:12,123] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-03 08:50:12,123] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f3f460>
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-03 08:50:12,124] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-03 08:50:12,125] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-03 08:50:12,125] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/250 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: Mary added a total of 7 stickers/page * 6 pages= <<7*6=42>>42 stickers to the 6 other pages.
In total, Mary added 3 large stickers + 42 stickers = <<3+42=45>>45 stickers to her journal.
Since she started with 89 stickers, she now has 89 - 45 = <<89-45=44>>44 stickers left.
So the final answer is 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: If he babysits for 2 hours at $7 per hour, he will earn 2*7 = $<<2*7=14>>14
This week he will earn $5 allowance, $10 mowing the lawn and $14 from babysitting for a total of 5+10+14 = $<<5+10+14=29>>29
If we add the $29 he will earn to his $65 savings, he will have a total of 29 + 65 = $<<29+65=94>>94
The bike costs $100 and he will have $94 leaving $100-$94 = $<<100-94=6>>6 more that he will need to earn
So the final answer is 6

Input: Mark has kangaroos and goats.  Kangaroos have two legs and goats have four legs.  If he has 23 kangaroos and three times as many goats as kangaroos what is the total number of legs of all his animals?
Output: His kangaroos have a total of 23*2=<<23*2=46>>46 legs
He has 23*3=<<23*3=69>>69 goats
The goats have 69*4=<<69*4=276>>276 legs
So in total his animals have 276+46=<<276+46=322>>322 legs
So the final answer is 322

Input: Josh’s mom gives him $20 to go shopping at the mall. He buys a hat for $10 and a pencil for $2. Then he buys four cookies. If each cookie costs $1.25, how much money does Josh have left?
Output: After buying a hat, Josh has $20 - $10 = $<<20-10=10>>10
After buying a pencil, Josh has $10 - $2 = $<<10-2=8>>8
The total cost of cookies is 4 * $1.25 = $<<4*1.25=5>>5
After buying the cookies, Josh has $8 - $5 = $<<8-5=3>>3
So the final answer is 3

Input: George's bowling team is one round away from breaking the league record for most points scored in a season. The old record is an average score per player of 287 per round. Each team has 4 players and there are 10 rounds in the season. Through the first 9 rounds, his team has scored a total of 10,440. How many points less than the current league record per game average is the minimum average they need to score, per player, in the final round to tie the league record?
Output: The old team per round record is 1,148 because 287 x 4 = <<1148=1148>>1,148
The team season record is 11,480 because 10 x 1,248 = 11,480
They need 1,040 points in the final round to tie the record because 11,480 - 10,440 = <<11480-10440=1040>>1,040
They need to average 260 points each because 1,040 / 4 = <<1040/4=260>>260
This is 27 points less than the current record average because 287 - 260 = <<27=27>>27
So the final answer is 27

Input: Max was doing homework in three different subjects. It took him 20 minutes to finish tasks from biology and two times more time to finish history. Geography took him the most time, three times more than history. How much time did Max spend on doing his homework?
Output: Max finished history in 20 * 2 = <<20*2=40>>40 minutes.
Finishing geography took the most time, which is 40 * 3 = <<40*3=120>>120 minutes.
In total, for all three subjects, Max needed 20 + 40 + 120 = <<20+40+120=180>>180 minutes.
So the final answer is 180

Input: Sophia ate 1/6 of her pie and she put the rest on the fridge. If the pie left in the fridge weighs 1200 grams, how many grams did Sophia eat?
Output: If Sophia ate 1/6 of the pie, then 6/6 - 1/6 = 5/6 is left in the fridge.
Let x be the pie's original weight.
The current weight of the pie can be described by 5x/6=1200 grams
So, 5x=7200.
And, the original weight is x = <<1440=1440>>1440 grams.
So, Sophia ate 1440 grams original - 1200 grams after= <<1440-1200=240>>240 grams of pie.
So the final answer is 240

Input: Sarah, Mary, and Tuan decided to go to the restaurant for a meal. They decided to split the cost of the meal evenly. If the total price of the meal comes to $67 and they have a coupon for $4, how much does each person need to contribute to the bill?
Output: After using the coupon, the final price comes to 67 - 4 = <<67-4=63>>63 dollars.
With three people, they each need to pay 63 / 3 = <<63/3=21>>21 dollars each.
So the final answer is 21

Input: Tom's brother is 4 times as old as Tom's dog. If in 6 years, Tom's brother will be 30 years, how old is Tom's dog going to be in six years?
Output: If in six years Tom's brother will be 30 years old, he is currently 30-6 = <<30-6=24>>24 years old.
Since Tom's brother is 4 times as old as Tom's dog, Tom's dog is 24/4 = <<24/4=6>>6 years old currently.
Tom's dog will be 6+6 = <<6+6=12>>12 years old in six years.
So the final answer is 12

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o9-tgsm8k-s1-rTrue-m4096
Evaluating commonsenseqa :   0%|          | 1/250 [00:55<3:50:11, 55.47s/it]Evaluating commonsenseqa :   1%|          | 2/250 [01:50<3:47:12, 54.97s/it]Evaluating commonsenseqa :   1%|          | 3/250 [02:44<3:45:04, 54.67s/it]     Evaluating commonsenseqa :   2%|▏         | 4/250 [03:37<3:42:04, 54.17s/it]   Evaluating commonsenseqa :   2%|▏         | 5/250 [04:31<3:39:58, 53.87s/it]   Evaluating commonsenseqa :   2%|▏         | 6/250 [05:25<3:39:48, 54.05s/it]   Evaluating commonsenseqa :   3%|▎         | 7/250 [06:18<3:37:51, 53.79s/it]   Evaluating commonsenseqa :   3%|▎         | 8/250 [07:11<3:36:09, 53.59s/it]Evaluating commonsenseqa :   4%|▎         | 9/250 [08:05<3:35:08, 53.56s/it]                                                                                     Evaluating commonsenseqa :   4%|▍         | 10/250 [09:00<3:36:33, 54.14s/it]Evaluating commonsenseqa :   4%|▍         | 11/250 [09:54<3:34:50, 53.94s/it]    Evaluating commonsenseqa :   5%|▍         | 12/250 [10:49<3:35:06, 54.23s/it]Evaluating commonsenseqa :   5%|▌         | 13/250 [11:43<3:33:48, 54.13s/it]                                                                                        Evaluating commonsenseqa :   6%|▌         | 14/250 [12:36<3:32:19, 53.98s/it]Evaluating commonsenseqa :   6%|▌         | 15/250 [13:31<3:32:28, 54.25s/it]    Evaluating commonsenseqa :   6%|▋         | 16/250 [14:26<3:32:13, 54.42s/it]    Evaluating commonsenseqa :   7%|▋         | 17/250 [15:20<3:30:20, 54.16s/it]    Evaluating commonsenseqa :   7%|▋         | 18/250 [16:03<3:16:57, 50.94s/it]      Evaluating commonsenseqa :   8%|▊         | 19/250 [16:59<3:21:52, 52.44s/it]      Evaluating commonsenseqa :   8%|▊         | 20/250 [17:52<3:22:18, 52.78s/it]Evaluating commonsenseqa :   8%|▊         | 21/250 [18:47<3:22:59, 53.19s/it]Evaluating commonsenseqa :   9%|▉         | 22/250 [19:41<3:23:45, 53.62s/it]Evaluating commonsenseqa :   9%|▉         | 23/250 [20:35<3:23:26, 53.77s/it]Evaluating commonsenseqa :  10%|▉         | 24/250 [21:29<3:22:17, 53.71s/it]Evaluating commonsenseqa :  10%|█         | 25/250 [22:23<3:21:28, 53.73s/it]            Evaluating commonsenseqa :  10%|█         | 26/250 [23:16<3:20:08, 53.61s/it]Evaluating commonsenseqa :  11%|█         | 27/250 [24:10<3:19:37, 53.71s/it]      Evaluating commonsenseqa :  11%|█         | 28/250 [25:04<3:18:54, 53.76s/it]      Evaluating commonsenseqa :  12%|█▏        | 29/250 [25:57<3:17:40, 53.67s/it]    Evaluating commonsenseqa :  12%|█▏        | 30/250 [26:51<3:16:42, 53.65s/it]Evaluating commonsenseqa :  12%|█▏        | 31/250 [27:45<3:16:07, 53.73s/it]                                                                                          Evaluating commonsenseqa :  13%|█▎        | 32/250 [28:39<3:15:53, 53.92s/it]Evaluating commonsenseqa :  13%|█▎        | 33/250 [29:33<3:15:07, 53.95s/it]    Evaluating commonsenseqa :  14%|█▎        | 34/250 [29:49<2:33:12, 42.56s/it]Evaluating commonsenseqa :  14%|█▍        | 35/250 [30:43<2:44:54, 46.02s/it]Evaluating commonsenseqa :  14%|█▍        | 36/250 [31:37<2:52:38, 48.40s/it]    Evaluating commonsenseqa :  15%|█▍        | 37/250 [32:32<2:58:42, 50.34s/it]    Evaluating commonsenseqa :  15%|█▌        | 38/250 [33:20<2:55:19, 49.62s/it]Evaluating commonsenseqa :  16%|█▌        | 39/250 [34:14<2:58:33, 50.78s/it]Evaluating commonsenseqa :  16%|█▌        | 40/250 [35:07<3:00:46, 51.65s/it]Evaluating commonsenseqa :  16%|█▋        | 41/250 [36:01<3:01:37, 52.14s/it]    Evaluating commonsenseqa :  17%|█▋        | 42/250 [36:55<3:03:13, 52.85s/it]    Evaluating commonsenseqa :  17%|█▋        | 43/250 [37:50<3:04:50, 53.58s/it]                                                                                              Evaluating commonsenseqa :  18%|█▊        | 44/250 [38:45<3:05:20, 53.98s/it]Evaluating commonsenseqa :  18%|█▊        | 45/250 [39:41<3:06:08, 54.48s/i.59s/it]Evaluating commonsenseqa :  33%|███▎      | 82/250 [1:24:51<2:33:39, 54.88s/it]                                                                                  Evaluating commonsenseqa :  33%|███▎      | 83/250 [1:25:57<2:42:14, 58.29s/it]Evaluating commonsenseqa :  34%|███▎      | 84/250 [1:27:03<2:47:34, 60.57s/it]Evaluating commonsenseqa :  34%|███▍      | 85/250 [1:28:08<2:50:06, 61.86s/it]                                                                                  Evaluating commonsenseqa :  34%|███▍      | 86/250 [1:29:15<2:53:24, 63.44s/it]Evaluating commonsenseqa :  35%|███▍      | 87/250 [1:30:19<2:52:32, 63.51s/it]                                                                                  Evaluating commonsenseqa :  35%|███▌      | 88/250 [1:31:24<2:53:21, 64.21s/it]Evaluating commonsenseqa :  36%|███▌      | 89/250 [1:32:29<2:52:44, 64.38s/it]Evaluating commonsenseqa :  36%|███▌      | 90/250 [1:33:34<2:51:37, 64.36s/it]Evaluating commonsenseqa :  36%|███▋      | 91/250 [1:34:37<2:50:10, 64.22s/it]Evaluating commonsenseqa :  37%|███▋      | 92/250 [1:35:41<2:48:31, 64.00s/it]Evaluating commonsenseqa :  37%|███▋      | 93/250 [1:36:45<2:47:40, 64.08s/it]Evaluating commonsenseqa :  38%|███▊      | 94/250 [1:37:50<2:47:07, 64.28s/it]Evaluating commonsenseqa :  38%|███▊      | 95/250 [1:38:54<2:46:01, 64.27s/it]Evaluating commonsenseqa :  38%|███▊      | 96/250 [1:39:58<2:44:48, 64.21s/it]Evaluating commonsenseqa :  39%|███▉      | 97/250 [1:41:02<2:43:28, 64.11s/it]Evaluating commonsenseqa :  39%|███▉      | 98/250 [1:41:47<2:27:28, 58.22s/it]Evaluating commonsenseqa :  40%|███▉      | 99/250 [1:42:51<2:31:11, 60.08s/it]Evaluating commonsenseqa :  40%|████      | 100/250 [1:43:55<2:32:50, 61.14s/it]                                                   Evaluating commonsenseqa :  40%|████      | 101/250 [1:44:59<2:33:57, 61.99s/it]                                                                                 Evaluating commonsenseqa :  41%|████      | 102/250 [1:46:02<2:34:10, 62.51s/it]Evaluating commonsenseqa :  41%|████      | 103/250 [1:47:06<2:34:08, 62.92s/it]Evaluating commonsenseqa :  42%|████▏     | 104/250 [1:48:11<2:34:43, 63.58s/it]Evaluating commonsenseqa :  42%|████▏     | 105/250 [1:49:15<2:33:55, 63.69s/it]Evaluating commonsenseqa :  42%|████▏     | 106/250 [1:50:10<2:26:32, 61.06s/it]Evaluating commonsenseqa :  43%|████▎     | 107/250 [1:51:13<2:26:37, 61.52s/it]Evaluating commonsenseqa :  43%|████▎     | 108/250 [1:52:16<2:26:42, 61.99s/it]                                                          Evaluating commonsenseqa :  44%|████▎     | 109/250 [1:53:20<2:27:20, 62.70s/it]Evaluating commonsenseqa :  44%|████▍     | 110/250 [1:54:25<2:27:38, 63.28s/it]                                                                                   Evaluating commonsenseqa :  44%|████▍     | 111/250 [1:55:29<2:27:05, 63.49s/it]Evaluating commonsenseqa :  45%|████▍     | 112/250 [1:56:33<2:26:39, 63.76s/it]Evaluating commonsenseqa :  45%|████▌     | 113/250 [1:57:36<2:25:08, 63.57s/it]                                                                                  Evaluating commonsenseqa :  46%|████▌     | 114/250 [1:58:41<2:25:10, 64.05s/it]Evaluating commonsenseqa :  46%|████▌     | 115/250 [1:59:43<2:22:07, 63.16s/it]Evaluating commonsenseqa :  46%|████▋     | 116/250 [2:00:47<2:21:54, 63.54s/it]Evaluating commonsenseqa :  47%|████▋     | 117/250 [2:01:51<2:20:58, 63.59s/it]Evaluating commonsenseqa :  47%|████▋     | 118/250 [2:02:55<2:20:23, 63.81s/it]                                                                         Evaluating commonsenseqa :  48%|████▊     | 119/250 [2:03:34<2:03:20, 56.49s/it]Evaluating commonsenseqa :  36%|███▋      | 91/250 [1:19:34<2:19:02, 52.47s/it]Evaluating commonsenseqa :  37%|███▋      | 92/250 [1:20:26<2:18:10, 52.47s/it]Evaluating commonsenseqa :  37%|███▋      | 93/250 [1:21:19<2:17:22, 52.50s/it]Evaluating commonsenseqa :  38%|███▊      | 94/250 [1:22:04<2:10:28, 50.18s/it]   Evaluating commonsenseqa :  38%|███▊      | 95/250 [1:22:57<2:12:16, 51.21s/it]Evaluating commonsenseqa :  38%|███▊      | 96/250 [1:23:50<2:12:41, 51.70s/it]                                                                                              Evaluating commonsenseqa :  39%|███▉      | 97/250 [1:24:44<2:13:30, 52.36s/it]Evaluating commonsenseqa :  39%|███▉      | 98/250 [1:25:38<2:13:57, 52.88s/it]Evaluating commonsenseqa :  40%|███▉      | 99/250 [1:26:31<2:12:47, 52.77s/it]Evaluating commonsenseqa :  40%|████      | 100/250 [1:27:24<2:12:37, 53.05s/it]Evaluating commonsenseqa :  40%|████      | 101/250 [1:28:17<2:11:24, 52.92s/it]Evaluating commonsenseqa :  41%|████      | 102/250 [1:29:10<2:10:58, 53.10s/it]      Evaluating commonsenseqa :  41%|████      | 103/250 [1:30:04<2:10:20, 53.20s/it]Evaluating commonsenseqa :  42%|████▏     | 104/250 [1:30:57<2:09:18, 53.14s/it]                                                                                               Evaluating commonsenseqa :  42%|████▏     | 105/250 [1:31:51<2:08:50, 53.32s/it]Evaluating commonsenseqa :  42%|████▏     | 106/250 [1:32:45<2:08:21, 53.48s/it]  Evaluating commonsenseqa :  43%|████▎     | 107/250 [1:33:37<2:07:03, 53.31s/it]  Evaluating commonsenseqa :  43%|████▎     | 108/250 [1:34:30<2:05:28, 53.02s/it]  Evaluating commonsenseqa :  44%|████▎     | 109/250 [1:35:23<2:04:51, 53.13s/it]Evaluating commonsenseqa :  44%|████▍     | 110/250 [1:36:16<2:03:55, 53.11s/it]  Evaluating commonsenseqa :  44%|████▍     | 111/250 [1:37:09<2:03:07, 53.15s/it]  Evaluating commonsenseqa :  45%|████▍     | 112/250 [1:38:02<2:02:02, 53.06s/it]  Evaluating commonsenseqa :  45%|████▌     | 113/250 [1:38:55<2:01:10, 53.07s/it]  Evaluating commonsenseqa :  46%|████▌     | 114/250 [1:39:49<2:00:34, 53.20s/it]  Evaluating commonsenseqa :  46%|████▌     | 115/250 [1:40:42<1:59:38, 53.17s/it]Evaluating commonsenseqa :  46%|████▋     | 116/250 [1:41:34<1:58:06, 52.88s/it]Evaluating commonsenseqa :  47%|████▋     | 117/250 [1:42:26<1:56:45, 52.67s/it]  Evaluating commonsenseqa :  47%|████▋     | 118/250 [1:43:19<1:55:35, 52.54s/it]  Evaluating commonsenseqa :  48%|████▊     | 119/250 [1:44:13<1:55:35, 52.94s/it]Evaluating commonsenseqa :  48%|████▊     | 120/250 [1:45:06<1:55:16, 53.21s/it]    Evaluating commonsenseqa :  48%|████▊     | 121/250 [1:46:00<1:54:39, 53.33s/it]Evaluating commonsenseqa :  49%|████▉     | 122/250 [1:46:54<1:54:06, 53.49s/it]  Evaluating commonsenseqa :  49%|████▉     | 123/250 [1:47:46<1:52:36, 53.20s/it]  Evaluating commonsenseqa :  50%|████▉     | 124/250 [1:48:39<1:51:11, 52.95s/it]                                                                                               Evaluating commonsenseqa :  50%|█████     | 125/250 [1:49:32<1:50:15, 52.93s/it]Evaluating commonsenseqa :  50%|█████     | 126/250 [1:50:24<1:49:02, 52.76s/it]  Evaluating commonsenseqa :  51%|█████     | 127/250 [1:51:17<1:48:23, 52.87s/it]  Evaluating commonsenseqa :  51%|█████     | 128/250 [1:52:11<1:48:11, 53.21s/it]  Evaluating commonsenseqa :  52%|█████▏    | 129/250 [1:53:07<1:48:38, 53.87s/it]Evaluating commonsenseqa :  52%|█████▏    | 130/250 [1:54:02<1:48:35, 54.29s/it]Evaluating commonsenseqa :  52%|█████▏    | 131/250 [1:54:58<1:48:42, 54.81s/it]Evaluating commonsenseqa :  53%|█████▎    | 132/250 [1:55:53<1:48:02, 54.94s/it]  Evaluating commonsenseqa :  53%|█████▎    | 133/250 [1:56:49<1:47:51, 55.32s/it]  Evaluating commonsenseqa :  54%|█████▎    | 134/250 [1:57:45<1:47:23, 55.54s/it]  Evaluating commonsenseqa :  54%|█████▍    | 135/250 [1:58:42<1:47:14, 55.96s/it]Evaluating commonsenseqa :  54%|█████▍    | 136/250 [1:59:38<1:46:09, 55.87s/it]                                                                                                 Evaluating commonsenseqa :  55%|█████▍    | 137/250 [2:00:34<1:45:08, 55.83s/it]Evaluating commonsenseqa :  55%|█████▌    | 138/250 [2:01:29<1:44:04, 55.75s/it]    Evaluating commonsenseqa :  56%|█████▌    | 139/250 [2:02:26<1:43:31, 55.96s/it]Evaluating commonsenseqa :  56%|█████▌    | 140/250 [2:03:22<1:42:34, 55.95s/it]  Evaluating commonsenseqa :  56%|█████▋    | 141/250 [2:04:18<1:41:48, 56.04s/it]  Evaluating commonsenseqa :  57%|█████▋    | 142/250 [2:05:14<1:40:50, 56.02s/it]  Evaluating commonsenseqa :  57%|█████▋    | 143/250 [2:06:10<1:39:59, 56.07s/it]  Evaluating commonsenseqa :  58%|█████▊    | 144/250 [2:07:06<1:39:14, 56.18s/it]  Evaluating commonsenseqa :  58%|█████▊    | 145/250 [2:08:02<1:38:13, 56.13s/it]Evaluating commonsenseqa :  58%|█████▊    | 146/250 [2:08:59<1:37:18, 56.14s/it]Evaluating commonsenseqa :  59%|█████▉    | 147/250 [2:09:55<1:36:38, 56.29s/it]Evaluating commonsenseqa :  59%|█████▉    | 148/250 [2:10:47<1:33:08, 54.79s/it]Evaluating commonsenseqa :  60%|█████▉    | 149/250 [2:11:43<1:33:04, 55.29s/it]  Evaluating commonsenseqa :  60%|██████    | 150/250 [2:12:40<1:32:56, 55.77s/it]  Evaluating commonsenseqa :  60%|██████    | 151/250 [2:13:36<1:32:17, 55.93s/it]  Evaluating commonsenseqa :  61%|██████    | 152/250 [2:14:33<1:31:38, 56.11s/it]  Evaluating commonsenseqa :  61%|██████    | 153/250 [2:15:29<1:30:51, 56.20s/it]Evaluating commonsenseqa :  62%|██████▏   | 154/250 [2:16:25<1:29:56, 56.21s/it]                                                                                               Evaluating commonsenseqa :  62%|██████▏   | 155/250 [2:17:22<1:29:02, 56.24s/it]Evaluating commonsenseqa :  62%|██████▏   | 156/250 [2:18:17<1:27:45, 56.01s/it]Evaluating commonsenseqa :  63%|██████▎   | 157/250 [2:19:14<1:27:01, 56.15s/it]Evaluating commonsenseqa :  63%|██████▎   | 158/250 [2:20:11<1:26:42, 56.54s/it]Evaluating commonsenseqa :  64%|██████▎   | 159/250 [2:21:08<1:25:58, 56.68s/it]Evaluating commonsenseqa :  64%|██████▍   | 160/250 [2:22:04<1:24:38, 56.43s/it]  Evaluating commonsenseqa :  64%|██████▍   | 161/250 [2:23:01<1:23:53, 56.55s/it]  Evaluating commonsenseqa :  65%|██████▍   | 162/250 [2:23:57<1:22:43, 56.40s/it]  Evaluating commonsenseqa :  65%|██████▌   | 163/250 [2:24:53<1:21:37, 56.29s/it]Evaluating commonsenseqa :  66%|██████▌   | 164/250 [2:25:49<1:20:38, 56.26s/it]    Evaluating commonsenseqa :  66%|██████▌   | 165/250 [2:26:46<1:19:56, 56.43s/it]  Evaluating commonsenseqa :  66%|██████▋   | 166/250 [2:27:41<1:18:34, 56.12s/it]  Evaluating commonsenseqa :  67%|██████▋   | 167/250 [2:28:38<1:17:42, 56.18s/it]  Evaluating commonsenseqa :  67%|██████▋   | 168/250 [2:29:34<1:16:59, 56.33s/it]  Evaluating commonsenseqa :  68%|██████▊   | 169/250 [2:30:29<1:15:14, 55.73s/it]Evaluating commonsenseqa :  68%|██████▊   | 170/250 [2:31:23<1:13:42, 55.28s/it]    Evaluating commonsenseqa :  68%|██████▊   | 171/250 [2:32:18<1:12:46, 55.28s/it]Evaluating commonsenseqa :  69%|██████▉   | 172/250 [2:33:14<1:11:56, 55.34s/it]Evaluating commonsenseqa :  69%|██████▉   | 173/250 [2:34:09<1:11:00, 55.33s/it]  Evaluating commonsenseqa :  70%|██████▉   | 174/250 [2:35:05<1:10:25, 55.59s/it]  Evaluating commonsenseqa :  70%|███████   | 175/250 [2:36:02<1:09:50, 55.88s/it]  Evaluating commonsenseqa :  70%|███████   | 176/250 [2:36:58<1:09:02, 55.98s/it]  Evaluating commonsenseqa :  71%|███████   | 177/250 [2:37:54<1:08:12, 56.06s/it]Evaluating commonsenseqa :  71%|███████   | 178/250 [2:38:50<1:07:04, 55.90s/it]  Evaluating commonsenseqa :  72%|███████▏  | 179/250 [2:39:46<1:06:16, 56.00s/it]Evaluating commonsenseqa :  72%|███████▏  | 180/250 [2:40:43<1:05:53, 56.48s/it]Evaluating commonsenseqa :  72%|███████▏  | 181/250 [2:41:40<1:04:49, 56.37s/it]Evaluating commonsenseqa :  73%|███████▎  | 182/250 [2:42:35<1:03:37, 56.13s/it]Evaluating commonsenseqa :  73%|███████▎  | 183/250 [2:43:31<1:02:39, 56.11s/it]Evaluating commonsenseqa :  74%|███████▎  | 184/250 [2:44:26<1:01:26, 55.85s/it]Evaluating commonsenseqa :  74%|███████▍  | 185/250 [2:45:23<1:00:41, 56.03s/it]Evaluating commonsenseqa :  74%|███████▍  | 186/250 [2:46:19<59:55, 56.19s/it]  Evaluating commonsenseqa :  75%|███████▍  | 187/250 [2:47:15<58:43, 55.92s/it]Evaluating commonsenseqa :  75%|███████▌  | 188/250 [2:48:11<57:55, 56.05s/it]  Evaluating commonsenseqa :  76%|███████▌  | 189/250 [2:49:07<56:55, 55.98s/it]Evaluating commonsenseqa :  76%|███████▌  | 190/250 [2:49:41<49:22, 49.38s/it]Evaluating commonsenseqa :  76%|███████▋  | 191/250 [2:50:37<50:35, 51.45s/it]  Evaluating commonsenseqa :  77%|███████▋  | 192/250 [2:51:33<50:52, 52.62s/it]  Evaluating commonsenseqa :  77%|███████▋  | 193/250 [2:52:28<50:46, 53.45s/it]  Evaluating commonsenseqa :  78%|███████▊  | 194/250 [2:53:25<50:55, 54.55s/it]Evaluating commonsenseqa :  78%|███████▊  | 195/250 [2:54:21<50:26, 55.02s/it]    Evaluating commonsenseqa :  78%|███████▊  | 196/250 [2:55:08<47:19, 52.58s/it]Evaluating commonsenseqa :  79%|███████▉  | 197/250 [2:56:04<47:12, 53.45s/it]Evaluating commonsenseqa :  79%|███████▉  | 198/250 [2:57:00<47:00, 54.25s/it]Evaluating commonsenseqa :  80%|███████▉  | 199/250 [2:57:56<46:43, 54.97s/it]Evaluating commonsenseqa :  80%|████████  | 200/250 [2:58:52<45:59, 55.20s/it]Evaluating commonsenseqa :  80%|████████  | 201/250 [2:59:29<40:40, 49.81s/it]Evaluating commonsenseqa :  81%|████████  | 202/250 [3:00:25<41:17, 51.62s/it]Evaluating commonsenseqa :  81%|████████  | 203/250 [3:01:21<41:22, 52.82s/it]                                                                                                   Evaluating commonsenseqa :  82%|████████▏ | 204/250 [3:02:17<41:20, 53.92s/it]Evaluating commonsenseqa :  82%|████████▏ | 205/250 [3:03:13<40:48, 54.42s/it]Evaluating commonsenseqa :  82%|████████▏ | 206/250 [3:03:48<35:34, 48.50s/it]Evaluating commonsenseqa :  83%|████████▎ | 207/250 [3:04:44<36:25, 50.82s/it]Evaluating commonsenseqa :  83%|████████▎ | 208/250 [3:05:40<36:38, 52.36s/it]Evaluating commonsenseqa :  84%|████████▎ | 209/250 [3:06:11<31:27, 46.04s/it]Evaluating commonsenseqa :  84%|████████▍ | 210/250 [3:07:08<32:48, 49.20s/it]Evaluating commonsenseqa :  84%|████████▍ | 211/250 [3:08:03<33:12, 51.10s/it]Evaluating commonsenseqa :  85%|████████▍ | 212/250 [3:08:59<33:20, 52.64s/it]Evaluating commonsenseqa :  85%|████████▌ | 213/250 [3:09:55<32:57, 53.46s/it]Evaluating commonsenseqa :  86%|████████▌ | 214/250 [3:10:52<32:41, 54.49s/it]Evaluating commonsenseqa :  86%|████████▌ | 215/250 [3:11:47<32:00, 54.86s/it]Evaluating commonsenseqa :  86%|████████▋ | 216/250 [3:12:44<31:24, 55.42s/it]Evaluating commonsenseqa :  87%|████████▋ | 217/250 [3:13:40<30:33, 55.57s/it]    Evaluating commonsenseqa :  87%|████████▋ | 218/250 [3:14:36<29:43, 55.75s/it]Evaluating commonsenseqa :  88%|████████▊ | 219/250 [3:15:33<28:53, 55.93s/it]Evaluating commonsenseqa :  88%|████████▊ | 220/250 [3:15:55<23:01, 46.04s/it]Evaluating commonsenseqa :  88%|████████▊ | 221/250 [3:16:52<23:45, 49.15s/it]                                                                                                     Evaluating commonsenseqa :  89%|████████▉ | 222/250 [3:17:50<24:08, 51.72s/it]Evaluating commonsenseqa :  89%|████████▉ | 223/250 [3:18:46<23:52, 53.04s/it]Evaluating commonsenseqa :  90%|████████▉ | 224/250 [3:19:41<23:18, 53.80s/it]Evaluating commonsenseqa :  90%|█████████ | 225/250 [3:20:38<22:45, 54.62s/it]  Evaluating commonsenseqa :  90%|█████████ | 226/250 [3:21:34<22:00, 55.03s/it]  Evaluating commonsenseqa :  91%|█████████ | 227/250 [3:22:31<21:18, 55.58s/it]  Evaluating commonsenseqa :  91%|█████████ | 228/250 [3:23:26<20:21, 55.50s/it]Evaluating commonsenseqa :  92%|█████████▏| 229/250 [3:24:23<19:34, 55.95s/it]  Evaluating commonsenseqa :  92%|█████████▏| 230/250 [3:25:15<18:15, 54.75s/it]Evaluating commonsenseqa :  92%|█████████▏| 231/250 [3:26:11<17:25, 55.02s/it]Evaluating commonsenseqa :  93%|█████████▎| 232/250 [3:27:06<16:32, 55.15s/it]Evaluating commonsenseqa :  93%|█████████▎| 233/250 [3:28:02<15:42, 55.41s/it]Evaluating commonsenseqa :  94%|█████████▎| 234/250 [3:28:58<14:48, 55.56s/it]Evaluating commonsenseqa :  94%|█████████▍| 235/250 [3:29:52<13:48, 55.20s/it]Evaluating commonsenseqa :  94%|█████████▍| 236/250 [3:30:48<12:53, 55.28s/it]Evaluating commonsenseqa :  95%|█████████▍| 237/250 [3:31:40<11:47, 54.39s/it]Evaluating commonsenseqa :  95%|█████████▌| 238/250 [3:32:36<10:58, 54.86s/it]Evaluating commonsenseqa :  96%|█████████▌| 239/250 [3:33:31<10:05, 55.01s/it]Evaluating commonsenseqa :  96%|█████████▌| 240/250 [3:34:28<09:13, 55.37s/it]Evaluating commonsenseqa :  96%|█████████▋| 241/250 [3:35:23<08:18, 55.39s/it]Evaluating commonsenseqa : 100%|██████████| 250/250 [4:19:39<00:00, 62.32s/it]
name: commonsenseqa | avg. gen lenth: 322.24 | time: 15581.442025661469s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr gpu03 --master_port 17129 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s10-rTrue --seed 10 --max-prompt-length 4096 --rationales --num-out-domain 1 1 2 3 4 5 True 4096 4
[2023-09-03 12:25:08,292] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 1
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o1-tgsm8k-s10-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 1397527.46it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:12<00:12, 12.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  9.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  9.49s/it]
 > number of parameters: 6738415616
[2023-09-03 12:25:28,635] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-03 12:25:28,863] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-03 12:25:28,865] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-03 12:25:28,865] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-03 12:25:28,865] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-03 12:25:28,865] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-03 12:25:28,865] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-03 12:25:28,865] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-03 12:25:28,865] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-03 12:25:28,865] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-03 12:25:28,865] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-03 12:25:28,865] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-03 12:25:28,865] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f41490>
[2023-09-03 12:25:28,865] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-03 12:25:28,865] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-03 12:25:28,865] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-03 12:25:28,866] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-03 12:25:28,867] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-03 12:25:28,867] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-03 12:25:28,867] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-03 12:25:28,867] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-03 12:25:28,867] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/250 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: For the nuts Adam paid 3 * $12 = $<<3*12=36>>36.
And for dried fruits Adam paid 2.5 * $8 = $<<2.5*8=20>>20.
So in total for his purchases Adam paid $36 + $20 = $<<36+20=56>>56.
So the final answer is 56

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o1-tgsm8k-s10-rTrue-m4096
                                                                                                   Evaluating commonsenseqa :   0%|          | 1/250 [01:27<6:01:41, 87.15s/it]Evaluating commonsenseqa :   1%|          | 2/250 [02:52<5:55:44, 86.07s/it]                                            Evaluating commonsenseqa :   1%|          | 3/250 [03:59<5:18:31, 77.37s/it]                      Evaluating commonsenseqa :   2%|▏         | 4/250 [05:22<5:26:46, 79.70s/it]                    Evaluating commonsenseqa :   2%|▏         | 5/250 [06:46<5:31:09, 81.10s/it]                                                                                                                       Evaluating commonsenseqa :   2%|▏         | 6/250 [08:10<5:34:38, 82.29s/it]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Evaluating commonsenseqa :   3%|▎         | 7/250 [09:35<5:36:12, 83.01s/it]ing ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o10-tgsm8k-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 10
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o10-tgsm8k-s1-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 445130.14it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.73s/it]
 > number of parameters: 6738415616
[2023-09-03 12:34:23,186] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-03 12:34:23,407] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-03 12:34:23,408] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-03 12:34:23,409] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-03 12:34:23,409] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-03 12:34:23,409] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-03 12:34:23,409] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-03 12:34:23,409] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-03 12:34:23,409] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-03 12:34:23,409] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-03 12:34:23,409] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-03 12:34:23,409] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-03 12:34:23,409] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f3f460>
[2023-09-03 12:34:23,409] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-03 12:34:23,409] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-03 12:34:23,409] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-03 12:34:23,409] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-03 12:34:23,409] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-03 12:34:23,409] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-03 12:34:23,409] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-03 12:34:23,409] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-03 12:34:23,409] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-03 12:34:23,409] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-03 12:34:23,409] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-03 12:34:23,409] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-03 12:34:23,409] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-03 12:34:23,409] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-03 12:34:23,409] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-03 12:34:23,409] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-03 12:34:23,409] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-03 12:34:23,409] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-03 12:34:23,409] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-03 12:34:23,410] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-03 12:34:23,410] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/250 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: Mary added a total of 7 stickers/page * 6 pages= <<7*6=42>>42 stickers to the 6 other pages.
In total, Mary added 3 large stickers + 42 stickers = <<3+42=45>>45 stickers to her journal.
Since she started with 89 stickers, she now has 89 - 45 = <<89-45=44>>44 stickers left.
So the final answer is 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: If he babysits for 2 hours at $7 per hour, he will earn 2*7 = $<<2*7=14>>14
This week he will earn $5 allowance, $10 mowing the lawn and $14 from babysitting for a total of 5+10+14 = $<<5+10+14=29>>29
If we add the $29 he will earn to his $65 savings, he will have a total of 29 + 65 = $<<29+65=94>>94
The bike costs $100 and he will have $94 leaving $100-$94 = $<<100-94=6>>6 more that he will need to earn
So the final answer is 6

Input: Mark has kangaroos and goats.  Kangaroos have two legs and goats have four legs.  If he has 23 kangaroos and three times as many goats as kangaroos what is the total number of legs of all his animals?
Output: His kangaroos have a total of 23*2=<<23*2=46>>46 legs
He has 23*3=<<23*3=69>>69 goats
The goats have 69*4=<<69*4=276>>276 legs
So in total his animals have 276+46=<<276+46=322>>322 legs
So the final answer is 322

Input: Josh’s mom gives him $20 to go shopping at the mall. He buys a hat for $10 and a pencil for $2. Then he buys four cookies. If each cookie costs $1.25, how much money does Josh have left?
Output: After buying a hat, Josh has $20 - $10 = $<<20-10=10>>10
After buying a pencil, Josh has $10 - $2 = $<<10-2=8>>8
The total cost of cookies is 4 * $1.25 = $<<4*1.25=5>>5
After buying the cookies, Josh has $8 - $5 = $<<8-5=3>>3
So the final answer is 3

Input: George's bowling team is one round away from breaking the league record for most points scored in a season. The old record is an average score per player of 287 per round. Each team has 4 players and there are 10 rounds in the season. Through the first 9 rounds, his team has scored a total of 10,440. How many points less than the current league record per game average is the minimum average they need to score, per player, in the final round to tie the league record?
Output: The old team per round record is 1,148 because 287 x 4 = <<1148=1148>>1,148
The team season record is 11,480 because 10 x 1,248 = 11,480
They need 1,040 points in the final round to tie the record because 11,480 - 10,440 = <<11480-10440=1040>>1,040
They need to average 260 points each because 1,040 / 4 = <<1040/4=260>>260
This is 27 points less than the current record average because 287 - 260 = <<27=27>>27
So the final answer is 27

Input: Max was doing homework in three different subjects. It took him 20 minutes to finish tasks from biology and two times more time to finish history. Geography took him the most time, three times more than history. How much time did Max spend on doing his homework?
Output: Max finished history in 20 * 2 = <<20*2=40>>40 minutes.
Finishing geography took the most time, which is 40 * 3 = <<40*3=120>>120 minutes.
In total, for all three subjects, Max needed 20 + 40 + 120 = <<20+40+120=180>>180 minutes.
So the final answer is 180

Input: Sophia ate 1/6 of her pie and she put the rest on the fridge. If the pie left in the fridge weighs 1200 grams, how many grams did Sophia eat?
Output: If Sophia ate 1/6 of the pie, then 6/6 - 1/6 = 5/6 is left in the fridge.
Let x be the pie's original weight.
The current weight of the pie can be described by 5x/6=1200 grams
So, 5x=7200.
And, the original weight is x = <<1440=1440>>1440 grams.
So, Sophia ate 1440 grams original - 1200 grams after= <<1440-1200=240>>240 grams of pie.
So the final answer is 240

Input: Sarah, Mary, and Tuan decided to go to the restaurant for a meal. They decided to split the cost of the meal evenly. If the total price of the meal comes to $67 and they have a coupon for $4, how much does each person need to contribute to the bill?
Output: After using the coupon, the final price comes to 67 - 4 = <<67-4=63>>63 dollars.
With three people, they each need to pay 63 / 3 = <<63/3=21>>21 dollars each.
So the final answer is 21

Input: Tom's brother is 4 times as old as Tom's dog. If in 6 years, Tom's brother will be 30 years, how old is Tom's dog going to be in six years?
Output: If in six years Tom's brother will be 30 years old, he is currently 30-6 = <<30-6=24>>24 years old.
Since Tom's brother is 4 times as old as Tom's dog, Tom's dog is 24/4 = <<24/4=6>>6 years old currently.
Tom's dog will be 6+6 = <<6+6=12>>12 years old in six years.
So the final answer is 12

Input: There are 50 children at the party. Three-fifths of them are boys. How many of the children are girls?
Output: 50 x 3/5 = <<50*3/5=30>>30 children are boys.
So, there are 50 - 30 = <<50-30=20>>20 children that are girls.
So the final answer is 20

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o10-tgsm8k-s1-rTrue-m4096
Evaluating commonsenseqa :   0%|          | 1/250 [00:56<3:53:20, 56.23s/it]Evaluating commonsenseqa :   1%|          | 2/250 [01:50<3:48:14, 55.22s/it]Evaluating commonsenseqa :   1%|          | 3/250 [02:45<3:46:08, 54.93s/it]Evaluating commonsenseqa :   2%|▏         | 4/250 [03:40<3:44:48, 54.83s/it]Evaluating commonsenseqa :   2%|▏         | 5/250 [04:34<3:43:21, 54.70s/it]Evaluating commonsenseqa :   2%|▏         | 6/250 [05:29<3:42:15, 54.65s/it]Evaluating commonsenseqa :   3%|▎         | 7/250 [06:23<3:40:59, 54.57s/it]Evaluating commonsenseqa :   3%|▎         | 8/250 [07:18<3:40:10, 54.59s/it]Evaluating commonsenseqa :   5%|▌         | 13/250 [17:52<5:19:59, 81.01s/it]                                                                               Evaluating commonsenseqa :   6%|▌         | 14/250 [19:19<5:25:39, 82.79s/it]Evaluating commonsenseqa :   6%|▌         | 15/250 [20:47<5:30:28, 84.38s/it]                                                                                Evaluating commonsenseqa :   6%|▋         | 16/250 [21:15<4:22:56, 67.42s/it]Evaluating commonsenseqa :   7%|▋         | 17/250 [22:41<4:43:12, 72.93s/it]Evaluating commonsenseqa :   7%|▋         | 18/250 [24:08<4:57:50, 77.03s/it]Evaluating commonsenseqa :   8%|▊         | 19/250 [25:10<4:39:06, 72.49s/it]                                                                                Evaluating commonsenseqa :   8%|▊         | 20/250 [26:36<4:53:34, 76.59s/it]Evaluating commonsenseqa :   8%|▊         | 21/250 [28:02<5:02:54, 79.36s/it]                                                                                Evaluating commonsenseqa :   9%|▉         | 22/250 [29:28<5:10:04, 81.60s/it]Evaluating commonsenseqa :   9%|▉         | 23/250 [30:20<4:34:44, 72.62s/it]                                                                                Evaluating commonsenseqa :  10%|▉         | 24/250 [31:44<4:46:17, 76.00s/it]Evaluating commonsenseqa :  10%|█         | 25/250 [33:11<4:57:01, 79.20s/it]Evaluating commonsenseqa :  10%|█         | 26/250 [34:36<5:02:55, 81.14s/it]                                                                                Evaluating commonsenseqa :  11%|█         | 27/250 [36:02<5:06:31, 82.47s/it]                                                                                    Evaluating commonsenseqa :  11%|█         | 28/250 [37:28<5:08:58, 83.51s/it]                                                                                    Evaluating commonsenseqa :  12%|█▏        | 29/250 [38:53<5:09:36, 84.06s/it]Evaluating commonsenseqa :  12%|█▏        | 30/250 [40:20<5:11:33, 84.97s/it]                                                                                  Evaluating commonsenseqa :  12%|█▏        | 31/250 [41:00<4:21:04, 71.53s/it]Evaluating commonsenseqa :  13%|█▎        | 32/250 [42:26<4:35:23, 75.80s/it]Evaluating commonsenseqa :  13%|█▎        | 33/250 [43:52<4:44:59, 78.80s/it]                                                                                  Evaluating commonsenseqa :  14%|█▎        | 34/250 [45:17<4:50:51, 80.80s/it]Evaluating commonsenseqa :  14%|█▍        | 35/250 [46:42<4:53:43, 81.97s/it]                                                                                  Evaluating commonsenseqa :  14%|█▍        | 36/250 [47:51<4:38:08, 77.98s/it]                                                                                  Evaluating commonsenseqa :  15%|█▍        | 37/250 [49:04<4:31:41, 76.53s/it]Evaluating commonsenseqa :  15%|█▌        | 38/250 [50:28<4:38:42, 78.88s/it]Evaluating commonsenseqa :  16%|█▌        | 39/250 [51:52<4:42:43, 80.40s/it]                                                                                  Evaluating commonsenseqa :  16%|█▌        | 40/250 [53:07<4:35:15, 78.65s/it]                                                                                  Evaluating commonsenseqa :  16%|█▋        | 41/250 [53:58<4:05:31, 70.49s/it]                                                                                  Evaluating commonsenseqa :  17%|█▋        | 42/250 [55:23<4:18:56, 74.69s/it]Evaluating commonsenseqa :  17%|█▋        | 43/250 [56:48<4:28:07, 77.72s/it]  Evaluating commonsenseqa :  18%|█▊        | 44/250 [58:13<4:34:40, 80.00s/it]                                                                                      Evaluating commonsenseqa :  18%|█▊        | 45/250 [59:40<4:40:15, 82.03s/it]  Evaluating commonsenseqa :  18%|█▊        | 46/250 [1:01:05<4:42:21, 83.05s/it]Evaluating commonsenseqa :  24%|██▎       | 59/250 [51:42<2:42:16, 50.98s/it]Evaluating commonsenseqa :  24%|██▍       | 60/250 [52:34<2:42:46, 51.40s/it]Evaluating commonsenseqa :  24%|██▍       | 61/250 [53:26<2:42:22, 51.55s/it]Evaluating commonsenseqa :  25%|██▍       | 62/250 [54:18<2:42:35, 51.89s/it]Evaluating commonsenseqa :  25%|██▌       | 63/250 [55:11<2:42:15, 52.06s/it]Evaluating commonsenseqa :  26%|██▌       | 64/250 [56:03<2:41:31, 52.11s/it]Evaluating commonsenseqa :  26%|██▌       | 65/250 [56:55<2:40:28, 52.05s/it]Evaluating commonsenseqa :  26%|██▋       | 66/250 [57:47<2:39:44, 52.09s/it]Evaluating commonsenseqa :  27%|██▋       | 67/250 [58:39<2:38:59, 52.13s/it]Evaluating commonsenseqa :  27%|██▋       | 68/250 [59:31<2:37:31, 51.93s/it]Evaluating commonsenseqa :  28%|██▊       | 69/250 [1:00:10<2:25:23, 48.20s/it]Evaluating commonsenseqa :  28%|██▊       | 70/250 [1:01:02<2:27:48, 49.27s/it]Evaluating commonsenseqa :  28%|██▊       | 71/250 [1:01:56<2:30:37, 50.49s/it]Evaluating commonsenseqa :  29%|██▉       | 72/250 [1:02:47<2:31:04, 50.92s/it]Evaluating commonsenseqa :  29%|██▉       | 73/250 [1:03:40<2:31:34, 51.38s/it]Evaluating commonsenseqa :  30%|██▉       | 74/250 [1:04:32<2:31:32, 51.66s/it]Evaluating commonsenseqa :  30%|███       | 75/250 [1:05:24<2:30:56, 51.75s/it]Evaluating commonsenseqa :  30%|███       | 76/250 [1:06:17<2:30:34, 51.92s/it]Evaluating commonsenseqa :  31%|███       | 77/250 [1:07:09<2:30:37, 52.24s/it]Evaluating commonsenseqa :  31%|███       | 78/250 [1:08:01<2:29:03, 51.99s/it]Evaluating commonsenseqa :  32%|███▏      | 79/250 [1:08:53<2:28:39, 52.16s/it]Evaluating commonsenseqa :  32%|███▏      | 80/250 [1:09:45<2:27:15, 51.97s/it]Evaluating commonsenseqa :  32%|███▏      | 81/250 [1:10:37<2:26:41, 52.08s/it]Evaluating commonsenseqa :  33%|███▎      | 82/250 [1:11:30<2:26:38, 52.37s/it]Evaluating commonsenseqa :  33%|███▎      | 83/250 [1:12:23<2:25:52, 52.41s/it]Evaluating commonsenseqa :  34%|███▎      | 84/250 [1:13:15<2:24:34, 52.26s/it]Evaluating commonsenseqa :  34%|███▍      | 85/250 [1:14:07<2:23:46, 52.28s/it]Evaluating commonsenseqa :  34%|███▍      | 86/250 [1:14:59<2:22:54, 52.28s/it]Evaluating commonsenseqa :  35%|███▍      | 87/250 [1:15:52<2:22:12, 52.35s/it]Evaluating commonsenseqa :  35%|███▌      | 88/250 [1:16:43<2:20:43, 52.12s/it]Evaluating commonsenseqa :  36%|███▌      | 89/250 [1:17:36<2:20:14, 52.26s/it]Evaluating commonsenseqa :  36%|███▌      | 90/250 [1:18:29<2:19:50, 52.44s/it]Evaluating commonsenseqa :  36%|███▋      | 91/250 [1:19:21<2:18:55, 52.43s/it]Evaluating commonsenseqa :  37%|███▋      | 92/250 [1:20:13<2:17:45, 52.31s/it]Evaluating commonsenseqa :  37%|███▋      | 93/250 [1:20:54<2:07:56, 48.90s/it]Evaluating commonsenseqa :  38%|███▊      | 94/250 [1:21:46<2:09:20, 49.75s/it]Evaluating commonsenseqa :  38%|███▊      | 95/250 [1:22:38<2:10:24, 50.48s/it]Evaluating commonsenseqa :  38%|███▊      | 96/250 [1:23:31<2:11:25, 51.21s/it]Evaluating commonsenseqa :  39%|███▉      | 97/250 [1:24:23<2:11:06, 51.42s/it]Evaluating commonsenseqa :  39%|███▉      | 98/250 [1:25:15<2:10:39, 51.58s/it]Evaluating commonsenseqa :  40%|███▉      | 99/250 [1:26:08<2:10:47, 51.97s/it]Evaluating commonsenseqa :  40%|████      | 100/250 [1:27:01<2:10:33, 52.22s/it]Evaluating commonsenseqa :  40%|████      | 101/250 [1:27:53<2:10:05, 52.38s/it]Evaluating commonsenseqa :  41%|████      | 102/250 [1:28:46<2:09:19, 52.43s/it]Evaluating commonsenseqa :  41%|████      | 103/250 [1:29:38<2:07:58, 52.23s/it]Evaluating commonsenseqa :  42%|████▏     | 104/250 [1:30:30<2:07:20, 52.33s/it]Evaluating commonsenseqa :  30%|███       | 76/250 [1:41:31<4:02:41, 83.69s/it]s/it]Evaluating commonsenseqa :  42%|████▏     | 106/250 [1:32:16<2:06:16, 52.61s/it]Evaluating commonsenseqa :  43%|████▎     | 107/250 [1:33:08<2:04:52, 52.40s/it]Evaluating commonsenseqa :  43%|████▎     | 108/250 [1:34:00<2:04:00, 52.40s/it]Evaluating commonsenseqa :  44%|████▎     | 109/250 [1:34:52<2:03:07, 52.40s/it]Evaluating commonsenseqa :  44%|████▍     | 110/250 [1:35:45<2:02:27, 52.48s/it]Evaluating commonsenseqa :  44%|████▍     | 111/250 [1:36:37<2:01:17, 52.36s/it]Evaluating commonsenseqa :  45%|████▍     | 112/250 [1:37:31<2:01:17, 52.73s/it]Evaluating commonsenseqa :  45%|████▌     | 113/250 [1:38:23<2:00:08, 52.62s/it]Evaluating commonsenseqa :  46%|████▌     | 114/250 [1:39:15<1:58:39, 52.35s/it]Evaluating commonsenseqa :  46%|████▌     | 115/250 [1:40:08<1:58:07, 52.50s/it]Evaluating commonsenseqa :  46%|████▋     | 116/250 [1:41:01<1:57:34, 52.65s/it]Evaluating commonsenseqa :  47%|████▋     | 117/250 [1:41:52<1:55:52, 52.27s/it]Evaluating commonsenseqa :  47%|████▋     | 118/250 [1:42:44<1:54:30, 52.05s/it]Evaluating commonsenseqa :  48%|████▊     | 119/250 [1:43:36<1:53:52, 52.15s/it]Evaluating commonsenseqa :  48%|████▊     | 120/250 [1:44:29<1:53:13, 52.26s/it]Evaluating commonsenseqa :  48%|████▊     | 121/250 [1:45:20<1:52:02, 52.11s/it]Evaluating commonsenseqa :  49%|████▉     | 122/250 [1:45:54<1:39:39, 46.72s/it]Evaluating commonsenseqa :  49%|████▉     | 123/250 [1:46:47<1:42:37, 48.49s/it]Evaluating commonsenseqa :  50%|████▉     | 124/250 [1:47:40<1:44:33, 49.79s/it]Evaluating commonsenseqa :  50%|█████     | 125/250 [1:48:32<1:45:11, 50.49s/it]Evaluating commonsenseqa :  50%|█████     | 126/250 [1:49:24<1:45:21, 50.98s/it]Evaluating commonsenseqa :  51%|█████     | 127/250 [1:50:16<1:45:13, 51.33s/it]Evaluating commonsenseqa :  51%|█████     | 128/250 [1:51:09<1:44:57, 51.62s/it]Evaluating commonsenseqa :  52%|█████▏    | 129/250 [1:52:01<1:44:30, 51.82s/it]Evaluating commonsenseqa :  52%|█████▏    | 130/250 [1:52:52<1:43:26, 51.72s/it]Evaluating commonsenseqa :  52%|█████▏    | 131/250 [1:53:46<1:43:42, 52.29s/it]Evaluating commonsenseqa :  53%|█████▎    | 132/250 [1:54:39<1:43:00, 52.38s/it]Evaluating commonsenseqa :  53%|█████▎    | 133/250 [1:55:31<1:42:05, 52.35s/it]Evaluating commonsenseqa :  54%|█████▎    | 134/250 [1:56:23<1:41:07, 52.31s/it]Evaluating commonsenseqa :  54%|█████▍    | 135/250 [1:57:15<1:40:10, 52.27s/it]Evaluating commonsenseqa :  54%|█████▍    | 136/250 [1:58:07<1:38:45, 51.97s/it]Evaluating commonsenseqa :  55%|█████▍    | 137/250 [1:58:59<1:37:56, 52.00s/it]Evaluating commonsenseqa :  55%|█████▌    | 138/250 [1:59:51<1:37:07, 52.03s/it]Evaluating commonsenseqa :  56%|█████▌    | 139/250 [2:00:43<1:36:12, 52.01s/it]Evaluating commonsenseqa :  56%|█████▌    | 140/250 [2:01:35<1:35:33, 52.12s/it]Evaluating commonsenseqa :  56%|█████▋    | 141/250 [2:02:27<1:34:31, 52.03s/it]Evaluating commonsenseqa :  57%|█████▋    | 142/250 [2:03:20<1:34:07, 52.29s/it]Evaluating commonsenseqa :  57%|█████▋    | 143/250 [2:04:13<1:33:33, 52.46s/it]Evaluating commonsenseqa :  58%|█████▊    | 144/250 [2:05:05<1:32:49, 52.54s/it]Evaluating commonsenseqa :  58%|█████▊    | 145/250 [2:05:57<1:31:43, 52.42s/it]Evaluating commonsenseqa :  58%|█████▊    | 146/250 [2:06:49<1:30:28, 52.20s/it]Evaluating commonsenseqa :  59%|█████▉    | 147/250 [2:07:42<1:29:45, 52.29s/it]Evaluating commonsenseqa :  59%|█████▉    | 148/250 [2:08:34<1:28:50, 52.26s/it]Evaluating commonsenseqa :  60%|█████▉    | 149/250 [2:09:27<1:28:17, 52.45s/it]Evaluating commonsenseqa :  60%|██████    | 150/250 [2:10:19<1:27:04, 52.25s/it]Evaluating commonsenseqa :  42%|████▏     | 106/250 [2:21:05<3:20:24, 83.50s/it]                                                                                               Evaluating commonsenseqa :  43%|████▎     | 107/250 [2:22:26<3:17:43, 82.96s/it]  Evaluating commonsenseqa :  43%|████▎     | 108/250 [2:23:51<3:17:54, 83.62s/it]                                                                                                   Evaluating commonsenseqa :  44%|████▎     | 109/250 [2:24:35<2:48:00, 71.49s/it]                                                                                                   Evaluating commonsenseqa :  44%|████▍     | 110/250 [2:26:00<2:56:42, 75.73s/it]Evaluating commonsenseqa :  44%|████▍     | 111/250 [2:27:24<3:00:50, 78.06s/it]        Evaluating commonsenseqa :  45%|████▍     | 112/250 [2:28:49<3:04:51, 80.37s/it]                                                                                                   Evaluating commonsenseqa :  45%|████▌     | 113/250 [2:30:16<3:07:26, 82.09s/it]                                                                                                   Evaluating commonsenseqa :  46%|████▌     | 114/250 [2:31:40<3:07:30, 82.72s/it]    Evaluating commonsenseqa :  46%|████▌     | 115/250 [2:33:07<3:09:04, 84.03s/it]    Evaluating commonsenseqa :  46%|████▋     | 116/250 [2:33:18<2:19:05, 62.28s/it]                                                                                                   Evaluating commonsenseqa :  47%|████▋     | 117/250 [2:34:44<2:33:32, 69.27s/it]    Evaluating commonsenseqa :  47%|████▋     | 118/250 [2:36:08<2:42:22, 73.80s/it]    Evaluating commonsenseqa :  48%|████▊     | 119/250 [2:37:34<2:48:59, 77.40s/it]                                                                                                   Evaluating commonsenseqa :  48%|████▊     | 120/250 [2:38:12<2:21:54, 65.49s/it]                                                                                                   Evaluating commonsenseqa :  48%|████▊     | 121/250 [2:39:38<2:33:50, 71.56s/it]Evaluating commonsenseqa :  49%|████▉     | 122/250 [2:41:02<2:41:02, 75.49s/it]        Evaluating commonsenseqa :  49%|████▉     | 123/250 [2:42:27<2:45:55, 78.39s/it]                                                                                                   Evaluating commonsenseqa :  50%|████▉     | 124/250 [2:43:53<2:49:06, 80.53s/it]    Evaluating commonsenseqa :  50%|█████     | 125/250 [2:44:36<2:24:13, 69.23s/it]                                                                                                       Evaluating commonsenseqa :  50%|█████     | 126/250 [2:46:01<2:33:06, 74.08s/it]      Evaluating commonsenseqa :  51%|█████     | 127/250 [2:47:27<2:39:13, 77.67s/it]      Evaluating commonsenseqa :  51%|█████     | 128/250 [2:48:47<2:39:11, 78.29s/it]      Evaluating commonsenseqa :  52%|█████▏    | 129/250 [2:50:11<2:41:12, 79.93s/it]                                                                                                   Evaluating commonsenseqa :  52%|█████▏    | 130/250 [2:51:36<2:43:18, 81.65s/it]                                                                                                 Evaluating commonsenseqa :  52%|█████▏    | 131/250 [2:52:45<2:34:06, 77.70s/it]  Evaluating commonsenseqa :  53%|█████▎    | 132/250 [2:54:08<2:36:17, 79.47s/it]                                                                                                                                                                                                Evaluating commonsenseqa :  53%|█████▎    | 133/250 [2:55:32<2:37:07, 80.58s/it]                                                                                                 Evaluating commonsenseqa :  54%|█████▎    | 134/250 [2:56:58<2:39:23, 82.44s/it]  Evaluating commonsenseqa :  54%|█████▍    | 135/250 [2:58:23<2:39:04, 83.00s/it]                                                                                                 Evaluating commonsenseqa :  54%|█████▍    | 136/250 [2:59:40<2:34:17, 81.21s/it]  Evaluating commonsenseqa :  55%|█████▍    | 137/250 [3:00:37<2:19:16, 73.95s/it]                                                                                                 Evaluating commonsenseqa :  55%|█████▌    | 138/250 [3:02:01<2:23:42, 76.99s/it]  Evaluating commonsenseqa :  56%|█████▌    | 139/250 [3:03:26<2:26:57, 79.44s/it]  Evaluating commonsenseqa :  56%|█████▌    | 140/250 [3:04:13<2:07:55, 69.78s/it]                                                                                                 Evaluating commonsenseqa :  56%|█████▋    | 141/250 [3:05:37<2:14:20, 73.95s/it]    Evaluating commonsenseqa :  57%|█████▋    | 142/250 [3:06:31<2:02:16, 67.93s/it]                                                                                                     Evaluating commonsenseqa :  57%|█████▋    | 143/250 [3:07:56<2:10:13, 73.03s/it]    Evaluating commonsenseqa :  58%|█████▊    | 144/250 [3:09:20<2:14:58, 76.41s/it]    Evaluating commonsenseqa :  58%|█████▊    | 145/250 [3:10:46<2:18:31, 79.16s/it]                                                                                                     Evaluating commonsenseqa :  58%|█████▊    | 146/250 [3:12:01<2:15:02, 77.90s/it]                                                                                                     Evaluating commonsenseqa :  59%|█████▉    | 147/250 [3:13:25<2:17:03, 79.84s/it]    Evaluating commonsenseqa :  59%|█████▉    | 148/250 [3:14:47<2:16:45, 80.44s/it]    Evaluating commonsenseqa :  60%|█████▉    | 149/250 [3:16:12<2:17:57, 81.96s/it]                                                                                                     Evaluating commonsenseqa :  60%|██████    | 150/250 [3:17:35<2:17:01, 82.21s/it]                                                                                                     Evaluating commonsenseqa :  60%|██████    | 151/250 [3:18:55<2:14:43, 81.65s/it]    Evaluating commonsenseqa :  61%|██████    | 152/250 [3:20:19<2:14:20, 82.25s/it]    Evaluating commonsenseqa :  61%|██████    | 153/250 [3:21:43<2:13:56, 82.85s/it]                                                                                                     Evaluating commonsenseqa :  62%|██████▏   | 154/250 [3:23:09<2:13:48, 83.63s/it]                                                                                                   Evaluating commonsenseqa :  62%|██████▏   | 155/250 [3:24:32<2:12:12, 83.50s/it]                                                                                                   Evaluating commonsenseqa :  62%|██████▏   | 156/250 [3:25:58<2:12:07, 84.33s/it]  Evaluating commonsenseqa :  63%|██████▎   | 157/250 [3:27:24<2:11:33, 84.87s/it]  Evaluating commonsenseqa :  63%|██████▎   | 158/250 [3:28:50<2:10:26, 85.07s/it]                                                                                                       Evaluating commonsenseqa :  64%|██████▎   | 159/250 [3:30:15<2:09:14, 85.21s/it]                                                                                                       Evaluating commonsenseqa :  64%|██████▍   | 160/250 [3:31:40<2:07:31, 85.02s/it]                                                                                                       Evaluating commonsenseqa :  64%|██████▍   | 161/250 [3:32:48<1:58:21, 79.79s/it]Evaluating commonsenseqa :  65%|██████▍   | 162/250 [3:34:13<1:59:30, 81.48s/it]        Evaluating commonsenseqa :  65%|██████▌   | 163/250 [3:35:36<1:59:01, 82.09s/it]                                                                                                       Evaluating commonsenseqa :  66%|██████▌   | 164/250 [3:37:01<1:58:43, 82.83s/it]    Evaluating commonsenseqa :  66%|██████▌   | 165/250 [3:38:29<1:59:29, 84.35s/it]                                                                                                       Evaluating commonsenseqa :  66%|██████▋   | 166/250 [3:39:54<1:58:21, 84.54s/it]    Evaluating commonsenseqa :  67%|██████▋   | 167/250 [3:41:18<1:56:55, 84.52s/it]                                                                                                       Evaluating commonsenseqa :  67%|██████▋   | 168/250 [3:42:43<1:55:30, 84.51s/it]                                                                                                       Evaluating commonsenseqa :  68%|██████▊   | 169/250 [3:44:08<1:54:30, 84.82s/it]    Evaluating commonsenseqa :  68%|██████▊   | 170/250 [3:45:34<1:53:17, 84.97s/it]                                                                                                       Evaluating commonsenseqa :  68%|██████▊   | 171/250 [3:47:01<1:52:39, 85.56s/it]/it]Evaluating commonsenseqa : 100%|██████████| 250/250 [3:37:28<00:00, 52.19s/it]
name: commonsenseqa | avg. gen lenth: 357.951 | time: 13050.038974285126s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr gpu04 --master_port 12094 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s10-rTrue --seed 10 --max-prompt-length 4096 --rationales --num-out-domain 6 6 7 8 9 10 True 4096 4
[2023-09-03 16:12:02,047] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 6
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o6-tgsm8k-s10-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 650501.77it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:12<00:12, 12.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  7.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  8.44s/it]
 > number of parameters: 6738415616
[2023-09-03 16:12:20,412] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-03 16:12:20,635] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-03 16:12:20,637] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f3d490>
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-03 16:12:20,638] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-03 16:12:20,639] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-03 16:12:20,639] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/250 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: For the nuts Adam paid 3 * $12 = $<<3*12=36>>36.
And for dried fruits Adam paid 2.5 * $8 = $<<2.5*8=20>>20.
So in total for his purchases Adam paid $36 + $20 = $<<36+20=56>>56.
So the final answer is 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: He spends 60/3=<<60/3=20>>20 minutes warming up
So he spends 60+20=<<60+20=80>>80 minutes at the gym per day
That means he spends 80*3=<<80*3=240>>240 minutes at the gym
So he spends 240/60=<<240/60=4>>4 hours at the gym a week
So the final answer is 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: The cost to fill a tank went up 200*.2=$<<200*.2=40>>40
So it cost 200+40=$<<200+40=240>>240 to fill the tank
That means he now pays 240*2=$<<240*2=480>>480
So the final answer is 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: If the total number of goals scored in the league that season against Barca is 300, the two players scored 20/100*300=<<300*20/100=60>>60 goals.
If the players scored an equal number of goals, each scored 60/2=<<60/2=30>>30 goals.
So the final answer is 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: He drinks 12 * 5 = <<12*5=60>>60 ounces of soda a day
So he drinks 60 + 64 = <<60+64=124>>124 ounces of liquid a day
So in total he drinks 124 * 7 = <<124*7=868>>868 ounces of liquid a week
So the final answer is 868

Input: Stella and Twinkle are filling up a truck with a capacity of 6000 stone blocks at the rate of 250 blocks per hour per person. They work for four hours and are then joined by 6 other people who also work at the same rate. How many hours did filling the truck take?
Output: Stella and Twinkle filled up the truck at the rate of 250 blocks per hour per person, a total of 2*250 = <<250*2=500>>500 blocks per hour for both.
After working for four hours, Stella and Twinkle had filled 4*500 = <<4*500=2000>>2000 blocks into the truck.
The number of blocks they had to put into the truck for it to be full is 6000-2000 = <<6000-2000=4000>>4000
When 6 more people joined Stella and Twinkle, a total of 2+6 = <<2+6=8>>8 people were filling the truck now.
Working at the rate of 250 blocks per person, the eight people filled the truck with 250*8 = <<250*8=2000>>2000 blocks in one hour.
If there were 4000 blocks that still needed to be put into the truck, the 8 people took 4000/2000 = <<4000/2000=2>>2 hours to fill the truck with the blocks.
The total time it took to fill up the tank is 4+2 = <<4+2=6>>6 hours.
So the final answer is 6

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o6-tgsm8k-s10-rTrue-m4096
Evaluating commonsenseqa :   0%|          | 1/250 [01:04<4:28:40, 64.74s/it]Evaluating commonsenseqa :   1%|          | 2/250 [01:56<3:56:28, 57.21s/it]Evaluating commonsenseqa :   1%|          | 3/250 [02:51<3:50:16, 55.94s/it]Evaluating commonsenseqa :   2%|▏         | 4/250 [03:56<4:03:55, 59.49s/it]Evaluating commonsenseqa :   2%|▏         | 5/250 [05:00<4:09:56, 61.21s/it]Evaluating commonsenseqa :   2%|▏         | 6/250 [06:05<4:13:51, 62.42s/it]Evaluating commonsenseqa :   3%|▎         | 7/250 [07:07<4:12:51, 62.43s/it]Evaluating commonsenseqa :   3%|▎         | 8/250 [08:10<4:12:37, 62.64s/it]                Evaluating commonsenseqa :   4%|▎         | 9/250 [09:13<4:12:11, 62.79s/it]                Evaluating commonsenseqa :   4%|▍         | 10/250 [10:17<4:12:17, 63.07s/it]                 Evaluating commonsenseqa :   4%|▍         | 11/250 [11:22<4:13:10, 63.56s/it]                 Evaluating commonsenseqa :   5%|▍         | 12/250 [12:24<4:10:51, 63.24s/it]                 Evaluating commonsenseqa :   5%|▌         | 13/250 [12:54<3:30:27, 53.28s/it]Evaluating commonsenseqa :   6%|▌         | 14/250 [13:57<3:40:24, 56.04s/it]Evaluating commonsenseqa :   6%|▌         | 15/250 [15:01<3:48:34, 58.36s/it]Evaluating commonsenseqa :   6%|▋         | 16/250 [16:05<3:54:33, 60.14s/it]                 Evaluating commonsenseqa :   7%|▋         | 17/250 [17:09<3:58:40, 61.46s/it]Evaluating commonsenseqa :   7%|▋         | 18/250 [18:14<4:01:12, 62.38s/it]Evaluating commonsenseqa :   8%|▊         | 19/250 [19:17<4:00:55, 62.58s/it]Evaluating commonsenseqa :   8%|▊         | 20/250 [20:20<4:00:55, 62.85s/it]                                                                    Evaluating commonsenseqa :   8%|▊         | 21/250 [21:23<3:59:57, 62.87s/it]Evaluating commonsenseqa :   9%|▉         | 22/250 [22:27<4:00:07, 63.19s/it]                 Evaluating commonsenseqa :   9%|▉         | 23/250 [23:30<3:58:51, 63.13s/it]                 Evaluating commonsenseqa :  10%|▉         | 24/250 [24:34<3:58:10, 63.23s/it]                 Evaluating commonsenseqa :  10%|█         | 25/250 [25:37<3:57:18, 63.28s/it]                 Evaluating commonsenseqa :  10%|█         | 26/250 [26:40<3:55:33, 63.10s/it]                 Evaluating commonsenseqa :  11%|█         | 27/250 [27:44<3:55:54, 63.48s/it]Evaluating commonsenseqa :  11%|█         | 28/250 [28:48<3:55:20, 63.61s/it]Evaluating commonsenseqa :  12%|█▏        | 29/250 [29:13<3:11:22, 51.96s/it]Evaluating commonsenseqa :  12%|█▏        | 30/250 [30:16<3:22:27, 55.22s/it]               Evaluating commonsenseqa :  12%|█▏        | 31/250 [31:19<3:30:23, 57.64s/it]Evaluating commonsenseqa :  13%|█▎        | 32/250 [32:22<3:35:25, 59.29s/it]Evaluating commonsenseqa :  13%|█▎        | 33/250 [33:25<3:38:39, 60.46s/it]Evaluating commonsenseqa :  14%|█▎        | 34/250 [34:29<3:40:44, 61.31s/it]Evaluating commonsenseqa :  14%|█▍        | 35/250 [35:31<3:41:03, 61.69s/it]Evaluating commonsenseqa :  14%|█▍        | 36/250 [36:35<3:41:57, 62.23s/it]Evaluating commonsenseqa :  15%|█▍        | 37/250 [37:39<3:43:13, 62.88s/it]Evaluating commonsenseqa :  15%|█▌        | 38/250 [38:43<3:43:25, 63.23s/it]Evaluating commonsenseqa :  16%|█▌        | 39/250 [39:47<3:42:31, 63.28s/it]Evaluating commonsenseqa :  16%|█▌        | 40/250 [40:51<3:42:33, 63.59s/it]Evaluating commonsenseqa :  16%|█▋        | 41/250 [41:36<3:22:37, 58.17s/it]Evaluating commonsenseqa :  17%|█▋        | 42/250 [42:40<3:27:08, 59.75s/it]Evaluating commonsenseqa :  17%|█▋        | 43/250 [43:45<3:31:48, 61.40s/it]Evaluating commonsenseqa :  18%|█▊        | 44/250 [44:50<3:34:19, 62.43s/it]                                  Evaluating commonsenseqa :  18%|█▊        | 45/250 [45:37<3:17:10, 57.71s/it]Evaluating commonsenseqa :  18%|█▊        | 46/250 [46:39<3:20:58, 59.11s/it]Evaluating commonsenseqa :  19%|█▉        | 47/250 [47:43<3:24:27, 60.43s/it]Evaluating commonsenseqa :  19%|█▉        | 48/250 [48:46<3:26:48, 61.43s/it]Evaluating commonsenseqa :  20%|█▉        | 49/250 [49:51<3:29:25, 62.52s/it]Evaluating commonsenseqa :  20%|██        | 50/250 [50:54<3:29:00, 62.70s/it]Ev, 81.59s/it]Evaluating commonsenseqa :  85%|████████▌ | 213/250 [4:39:51<50:42, 82.24s/it]Evaluating commonsenseqa :  86%|████████▌ | 214/250 [4:41:17<49:59, 83.33s/it]                                     Evaluating commonsenseqa :  86%|████████▌ | 215/250 [4:42:44<49:14, 84.42s/it]Evaluating commonsenseqa :  86%|████████▋ | 216/250 [4:44:09<47:57, 84.65s/it]                                                          Evaluating commonsenseqa :  87%|████████▋ | 217/250 [4:45:34<46:30, 84.56s/it]Evaluating commonsenseqa :  87%|████████▋ | 218/250 [4:47:00<45:18, 84.96s/it]Evaluating commonsenseqa :  88%|████████▊ | 219/250 [4:47:51<38:38, 74.79s/it]Evaluating commonsenseqa :  88%|████████▊ | 220/250 [4:48:43<34:02, 68.07s/it]Evaluating commonsenseqa :  88%|████████▊ | 221/250 [4:49:42<31:31, 65.23s/it]                                                                                      Evaluating commonsenseqa :  89%|████████▉ | 222/250 [4:51:07<33:15, 71.27s/it]Evaluating commonsenseqa :  89%|████████▉ | 223/250 [4:52:33<34:07, 75.84s/it]Evaluating commonsenseqa :  90%|████████▉ | 224/250 [4:53:58<33:59, 78.45s/it]Evaluating commonsenseqa :  90%|█████████ | 225/250 [4:55:23<33:31, 80.48s/it]                                                     Evaluating commonsenseqa :  90%|█████████ | 226/250 [4:56:08<27:55, 69.80s/it]Evaluating commonsenseqa :  91%|█████████ | 227/250 [4:57:35<28:40, 74.81s/it]Evaluating commonsenseqa :  91%|█████████ | 228/250 [4:59:00<28:36, 78.02s/it]Evaluating commonsenseqa :  92%|█████████▏| 229/250 [5:00:26<28:05, 80.26s/it]Evaluating commonsenseqa :  92%|█████████▏| 230/250 [5:00:55<21:40, 65.02s/it]                                                                                      Evaluating commonsenseqa :  92%|█████████▏| 231/250 [5:02:22<22:40, 71.61s/it]Evaluating commonsenseqa :  93%|█████████▎| 232/250 [5:03:43<22:19, 74.40s/it]Evaluating commonsenseqa :  93%|█████████▎| 233/250 [5:05:07<21:55, 77.39s/it]Evaluating commonsenseqa :  94%|█████████▎| 234/250 [5:06:23<20:30, 76.88s/it]Evaluating commonsenseqa :  94%|█████████▍| 235/250 [5:07:49<19:56, 79.74s/it]Evaluating commonsenseqa :  94%|█████████▍| 236/250 [5:08:52<17:24, 74.60s/it]Evaluating commonsenseqa :  95%|█████████▍| 237/250 [5:09:31<13:49, 63.83s/it]              Evaluating commonsenseqa :  95%|█████████▌| 238/250 [5:10:56<14:02, 70.21s/it]Evaluating commonsenseqa :  96%|█████████▌| 239/250 [5:12:20<13:37, 74.31s/it]Evaluating commonsenseqa :  96%|█████████▌| 240/250 [5:13:45<12:57, 77.74s/it]Evaluating commonsenseqa :  96%|█████████▋| 241/250 [5:14:53<11:11, 74.60s/it]Evaluating commonsenseqa :  97%|█████████▋| 242/250 [5:16:19<10:23, 77.98s/it]Evaluating commonsenseqa :  97%|█████████▋| 243/250 [5:17:45<09:22, 80.41s/it]                                 Evaluating commonsenseqa :  98%|█████████▊| 244/250 [5:19:11<08:13, 82.20s/it]Evaluating commonsenseqa :  98%|█████████▊| 245/250 [5:20:37<06:57, 83.43s/it]                                                                  Evaluating commonsenseqa :  98%|█████████▊| 246/250 [5:22:04<05:37, 84.37s/it]Evaluating commonsenseqa :  99%|█████████▉| 247/250 [5:23:27<04:12, 84.12s/it]Evaluating commonsenseqa :  99%|█████████▉| 248/250 [5:24:53<02:49, 84.62s/it]                                                       Evaluating commonsenseqa : 100%|█████████▉|9:03<2:43:55, 63.87s/it]Evaluating commonsenseqa :  39%|███▉      | 97/250 [1:39:51<2:30:30, 59.02s/it]Evaluating commonsenseqa :  39%|███▉      | 98/250 [1:40:55<2:33:32, 60.61s/it]50/250 [5:27:46<00:00, 78.67s/it]
name: commonsenseqa | avg. gen lenth: 281.858 | time: 19668.08032298088s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr gpu03 --master_port 17129 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s10-rTrue --seed 10 --max-prompt-length 4096 --rationales --num-out-domain 2 1 2 3 4 5 True 4096 4
[2023-09-03 17:53:24,670] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 2
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o2-tgsm8k-s10-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 1182744.19it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:13<00:13, 13.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  7.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.63s/it]
 > number of parameters: 6738415616
[2023-09-03 17:53:43,223] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-03 17:53:43,443] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-03 17:53:43,444] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-03 17:53:43,445] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-03 17:53:43,445] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-03 17:53:43,445] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-03 17:53:43,445] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-03 17:53:43,445] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-03 17:53:43,445] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-03 17:53:43,445] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-03 17:53:43,445] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-03 17:53:43,445] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-03 17:53:43,445] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f3f490>
[2023-09-03 17:53:43,445] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-03 17:53:43,445] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-03 17:53:43,445] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-03 17:53:43,445] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-03 17:53:43,445] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-03 17:53:43,445] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-03 17:53:43,445] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-03 17:53:43,445] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-03 17:53:43,445] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-03 17:53:43,445] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-03 17:53:43,445] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-03 17:53:43,445] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-03 17:53:43,445] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-03 17:53:43,445] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-03 17:53:43,445] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-03 17:53:43,445] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-03 17:53:43,445] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-03 17:53:43,445] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-03 17:53:43,445] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-03 17:53:43,446] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-03 17:53:43,446] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/250 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: For the nuts Adam paid 3 * $12 = $<<3*12=36>>36.
And for dried fruits Adam paid 2.5 * $8 = $<<2.5*8=20>>20.
So in total for his purchases Adam paid $36 + $20 = $<<36+20=56>>56.
So the final answer is 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: He spends 60/3=<<60/3=20>>20 minutes warming up
So he spends 60+20=<<60+20=80>>80 minutes at the gym per day
That means he spends 80*3=<<80*3=240>>240 minutes at the gym
So he spends 240/60=<<240/60=4>>4 hours at the gym a week
So the final answer is 4

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o2-tgsm8k-s10-rTrue-m4096
                                                                                        Evaluating commonsenseqa :   0%|          | 1/250 [01:20<5:32:27, 80.11s/it]Evaluating commonsenseqa :   1%|          | 2/250 [02:26<4:57:48, 72.05s/it]Evaluating commonsenseqa :   1%|          | 3/250 [03:47<5:12:37, 75.94s/it]                                    Evaluating commonsenseqa :   2%|▏         | 4/250 [05:05<5:15:52, 77.04s/it]          Evaluating commonsenseqa :   2%|▏         | 5/250 [06:12<4:58:46, 73.17s/it]            Evaluating commonsenseqa :   2%|▏         | 6/250 [07:32<5:06:49, 75.45s/it]            Evaluating commonsenseqa :   3%|▎         | 7/250 [08:51<5:11:13, 76.85s/it]            Evaluating commonsenseqa :   3%|▎         | 8/250 [10:12<5:14:42, 78.03s/it]                                                                                                       Evaluating commonsenseqa :   4%|▎         | 9/250 [11:31<5:14:34, 78.32s/it]            Evaluating commonsenseqa :   4%|▍         | 10/250 [12:50<5:13:53, 78.47s/it]           Evaluating commonsenseqa :   4%|▍         | 11/250 [13:34<4:31:32, 68.17s/it]           Evaluating commonsenseqa :   5%|▍         | 12/250 [14:44<4:31:56, 68.56s/it]           Evaluating commonsenseqa :   5%|▌         | 13/250 [16:05<4:46:16, 72.48s/it]           Evaluating commonsenseqa :   6%|▌         | 14/250 [17:25<4:53:13, 74.55s/it]           Evaluating commonsenseqa :   6%|▌         | 15/250 [18:44<4:57:57, 76.07s/it]                                                                                                      Evaluating commonsenseqa :   6%|▋         | 16/250 [20:04<5:01:16, 77.25s/it]                                                                                                      Evaluating commonsenseqa :   7%|▋         | 17/250 [21:21<4:59:51, 77.21s/it]Evaluating commonsenseqa :   7%|▋         | 18/250 [22:40<5:00:44, 77.78s/it]                      Evaluating commonsenseqa :   8%|▊         | 19/250 [23:59<5:00:52, 78.15s/it]           Evaluating commonsenseqa :   8%|▊         | 20/250 [25:22<5:04:17, 79.38s/it]           Evaluating commonsenseqa :   8%|▊         | 21/250 [26:42<5:04:05, 79.68s/it]           Evaluating commonsenseqa :   9%|▉         | 22/250 [28:04<5:04:55, 80.24s/it]                                                                                                      Evaluating commonsenseqa :   9%|▉         | 23/250 [29:24<5:04:13, 80.41s/it]           Evaluating commonsenseqa :  10%|▉         | 24/250 [30:45<5:03:11, 80.49s/it]           Evaluating commonsenseqa :  10%|█         | 25/250 [32:06<5:02:05, 80.56s/it]           Evaluating commonsenseqa :  10%|█         | 26/250 [33:26<5:00:12, 80.41s/it]                                                                                                          Evaluating commonsenseqa :  11%|█         | 27/250 [33:47<3:52:47, 62.64s/it]             Evaluating commonsenseqa :  11%|█         | 28/250 [35:08<4:11:59, 68.11s/it]Evaluating commonsenseqa :  12%|█▏        | 29/250 [36:29<4:25:34, 72.10s/it]                        Evaluating commonsenseqa :  12%|█▏        | 30/250 [37:50<4:33:54, 74.70s/it]           Evaluating commonsenseqa :  12%|█▏        | 31/250 [39:10<4:38:30, 76.30s/it]           Evaluating commonsenseqa :  13%|█▎        | 32/250 [40:30<4:41:28, 77.47s/it]           Evaluating commonsenseqa :  13%|█▎        | 33/250 [41:50<4:42:51, 78.21s/it]                                                                                                        Evaluating commonsenseqa :  14%|█▎        | 34/250 [42:59<4:31:05, 75.30s/it]           Evaluating commonsenseqa :  14%|█▍        | 35/250 [44:05<4:19:45, 72.49s/it]           Evaluating commonsenseqa :  14%|█▍        | 36/250 [45:26<4:28:10, 75.19s/it] 57.01s/it]Evaluating commonsenseqa :  57%|█████▋    | 142/250 [2:26:48<1:46:00, 58.90s/it]Evaluating commonsenseqa :  57%|█████▋    | 143/250 [2:27:52<1:47:23, 60.22s/it]Evaluating commonsenseqa :  58%|█████▊    | 144/250 [2:28:53<1:47:13, 60.69s/it]Evaluating commonsenseqa :  58%|█████▊    | 145/250 [2:29:56<1:47:16, 61.30s/it]Evaluating commonsenseqa :  58%|█████▊    | 146/250 [2:31:00<1:47:25, 61.98s/it]Evaluating commonsenseqa :  59%|█████▉    | 147/250 [2:32:01<1:46:13, 61.88s/it]Evaluating commonsenseqa :  59%|█████▉    | 148/250 [2:33:04<1:45:49, 62.25s/it]Evaluating commonsenseqa :  60%|█████▉    | 149/250 [2:34:06<1:44:42, 62.20s/it]Evaluating commonsenseqa :  60%|██████    | 150/250 [2:35:08<1:43:33, 62.13s/it]Evaluating commonsenseqa :  60%|██████    | 151/250 [2:36:10<1:42:29, 62.11s/it]Evaluating commonsenseqa :  61%|██████    | 152/250 [2:37:13<1:41:30, 62.15s/it]Evaluating commonsenseqa :  61%|██████    | 153/250 [2:38:14<1:40:11, 61.98s/it]Evaluating commonsenseqa :  62%|██████▏   | 154/250 [2:39:16<1:39:13, 62.01s/it]Evaluating commonsenseqa :  62%|██████▏   | 155/250 [2:40:19<1:38:17, 62.08s/it]Evaluating commonsenseqa :  62%|██████▏   | 156/250 [2:41:20<1:37:00, 61.93s/it]Evaluating commonsenseqa :  63%|██████▎   | 157/250 [2:42:24<1:36:38, 62.35s/it]Evaluating commonsenseqa :  63%|██████▎   | 158/250 [2:43:27<1:36:14, 62.77s/it]Evaluating commonsenseqa :  64%|██████▎   | 159/250 [2:44:29<1:34:39, 62.41s/it]Evaluating commonsenseqa :  64%|██████▍   | 160/250 [2:45:31<1:33:41, 62.46s/it]Evaluating commonsenseqa :  64%|██████▍   | 161/250 [2:46:34<1:32:41, 62.48s/it]Evaluating commonsenseqa :  65%|██████▍   | 162/250 [2:47:36<1:31:13, 62.20s/it]Evaluating commonsenseqa :  65%|██████▌   | 163/250 [2:48:39<1:30:34, 62.47s/it]Evaluating commonsenseqa :  66%|██████▌   | 164/250 [2:49:42<1:29:59, 62.78s/it]Evaluating commonsenseqa :  66%|██████▌   | 165/250 [2:50:45<1:28:57, 62.79s/it]Evaluating commonsenseqa :  66%|██████▋   | 166/250 [2:51:48<1:28:06, 62.94s/it]Evaluating commonsenseqa :  67%|██████▋   | 167/250 [2:52:50<1:26:32, 62.57s/it]Evaluating commonsenseqa :  67%|██████▋   | 168/250 [2:53:52<1:25:22, 62.47s/it]Evaluating commonsenseqa :  68%|██████▊   | 169/250 [2:54:55<1:24:21, 62.48s/it]Evaluating commonsenseqa :  68%|██████▊   | 170/250 [2:55:58<1:23:32, 62.66s/it]Evaluating commonsenseqa :  68%|██████▊   | 171/250 [2:56:59<1:22:03, 62.32s/it]Evaluating commonsenseqa :  69%|██████▉   | 172/250 [2:58:02<1:21:18, 62.55s/it]Evaluating commonsenseqa :  69%|██████▉   | 173/250 [2:59:06<1:20:37, 62.82s/it]Evaluating commonsenseqa :  70%|██████▉   | 174/250 [3:00:07<1:19:07, 62.46s/it]Evaluating commonsenseqa :  70%|███████   | 175/250 [3:01:10<1:18:10, 62.55s/it]Evaluating commonsenseqa :  70%|███████   | 176/250 [3:02:13<1:17:16, 62.65s/it]Evaluating commonsenseqa :  71%|███████   | 177/250 [3:03:16<1:16:17, 62.70s/it]Evaluating commonsenseqa :  71%|███████   | 178/250 [3:04:18<1:14:56, 62.46s/it]Evaluating commonsenseqa :  72%|███████▏  | 179/250 [3:05:20<1:13:59, 62.52s/it]Evaluating commonsenseqa :  72%|███████▏  | 180/250 [3:06:22<1:12:37, 62.25s/it]Evaluating commonsenseqa :  72%|███████▏  | 181/250 [3:07:26<1:12:06, 62.70s/it]Evaluating commonsenseqa :  73%|███████▎  | 182/250 [3:08:28<1:11:02, 62.68s/it]Evaluating commonsenseqa :  73%|███████▎  | 183/250 [3:09:30<1:09:35, 62.31s/it]Evaluating commonsenseqa :  74%|███████▎  | 184/250 [3:10:32<1:08:31, 62.29s/it]Evaluating commonsenseqa :  74%|███████▍  | 185/250 [3:11:35<1:07:36,Evaluating commonsenseqa :  29%|██▉       | 73/250 [1:31:16<3:43:35, 75.79s/it]                      Evaluating commonsenseqa :  30%|██▉       | 74/250 [1:31:56<3:11:08, 65.16s/it]           Evaluating commonsenseqa :  30%|███       | 75/250 [1:33:18<3:24:30, 70.12s/it]Evaluating commonsenseqa :  30%|███       | 76/250 [1:34:37<3:31:51, 73.05s/it]                      Evaluating commonsenseqa :  31%|███       | 77/250 [1:35:58<3:37:21, 75.38s/it]           Evaluating commonsenseqa :  31%|███       | 78/250 [1:37:21<3:42:10, 77.50s/it]           Evaluating commonsenseqa :  32%|███▏      | 79/250 [1:38:40<3:42:23, 78.03s/it]                                                                                                          Evaluating commonsenseqa :  32%|███▏      | 80/250 [1:39:59<3:42:09, 78.41s/it]       Evaluating commonsenseqa :  32%|███▏      | 81/250 [1:41:20<3:42:29, 78.99s/it]       Evaluating commonsenseqa :  33%|███▎      | 82/250 [1:42:40<3:42:38, 79.51s/it]       Evaluating commonsenseqa :  33%|███▎      | 83/250 [1:44:01<3:42:00, 79.77s/it]                                                                                                      Evaluating commonsenseqa :  34%|███▎      | 84/250 [1:45:19<3:39:42, 79.42s/it]       Evaluating commonsenseqa :  34%|███▍      | 85/250 [1:45:53<3:00:15, 65.55s/it]       Evaluating commonsenseqa :  34%|███▍      | 86/250 [1:47:13<3:11:09, 69.94s/it]       Evaluating commonsenseqa :  35%|███▍      | 87/250 [1:48:34<3:18:52, 73.21s/it]       Evaluating commonsenseqa :  35%|███▌      | 88/250 [1:49:53<3:22:31, 75.01s/it]       Evaluating commonsenseqa :  36%|███▌      | 89/250 [1:51:12<3:24:42, 76.29s/it]                                                                                                          Evaluating commonsenseqa :  36%|███▌      | 90/250 [1:52:33<3:26:57, 77.61s/it]         Evaluating commonsenseqa :  36%|███▋      | 91/250 [1:53:52<3:27:22, 78.25s/it]         Evaluating commonsenseqa :  37%|███▋      | 92/250 [1:55:14<3:28:53, 79.33s/it]         Evaluating commonsenseqa :  37%|███▋      | 93/250 [1:56:35<3:28:52, 79.82s/it]                                                                                                          Evaluating commonsenseqa :  38%|███▊      | 94/250 [1:57:56<3:28:28, 80.18s/it]         Evaluating commonsenseqa :  38%|███▊      | 95/250 [1:59:16<3:27:04, 80.16s/it]         Evaluating commonsenseqa :  38%|███▊      | 96/250 [1:59:55<2:53:28, 67.59s/it]         Evaluating commonsenseqa :  39%|███▉      | 97/250 [2:01:14<3:01:33, 71.20s/it]         Evaluating commonsenseqa :  39%|███▉      | 98/250 [2:02:31<3:04:32, 72.85s/it]         Evaluating commonsenseqa :  40%|███▉      | 99/250 [2:03:51<3:08:27, 74.88s/it]                                                                                                          Evaluating commonsenseqa :  40%|████      | 100/250 [2:05:11<3:11:14, 76.50s/it]        Evaluating commonsenseqa :  40%|████      | 101/250 [2:06:30<3:11:51, 77.26s/it]                                                                                                         Evaluating commonsenseqa :  41%|████      | 102/250 [2:07:51<3:13:03, 78.26s/it]        Evaluating commonsenseqa :  41%|████      | 103/250 [2:09:08<3:11:14, 78.06s/it]        Evaluating commonsenseqa :  42%|████▏     | 104/250 [2:10:29<3:11:51, 78.85s/it]      Evaluating commonsenseqa :  42%|████▏     | 105/250 [2:11:48<3:10:43, 78.92s/it]                                                                                                       Evaluating commonsenseqa :  42%|████▏     | 106/250 [2:13:09<3:10:45, 79.48s/it]      Evaluating commonsenseqa :  43%|████▎     | 107/250 [2:14:29<3:10:04, 79.75s/it]      Evaluating commonsenseqa :  43%|████▎     | 108/250 [2:15:51<3:10:22, 80.44s/it]                                                                                                         Evaluating commonsenseqa :  44%|████▎     | 109/250 [2:17:13<3:09:53, 80.80s/it]                                                                                                           Evaluating commonsenseqa :  44%|████▍     | 110/250 [2:18:32<3:07:41, 80.44s/it]        Evaluating commonsenseqa :  44%|████▍     | 111/250 [2:19:51<3:05:05, 79.90s/it]        Evaluating commonsenseqa :  45%|████▍     | 112/250 [2:21:12<3:04:25, 80.18s/it]                                                                                                           Evaluating commonsenseqa :  45%|████▌     | 113/250 [2:22:33<3:03:41, 80.45s/it]        Evaluating commonsenseqa :  46%|████▌     | 114/250 [2:23:55<3:03:15, 80.85s/it]                                                                                                           Evaluating commonsenseqa :  46%|████▌     | 115/250 [2:25:15<3:01:35, 80.71s/it]        Evaluating commonsenseqa :  46%|████▋     | 116/250 [2:26:35<2:59:57, 80.57s/it]        Evaluating commonsenseqa :  47%|████▋     | 117/250 [2:27:54<2:57:20, 80.00s/it]        Evaluating commonsenseqa :  47%|████▋     | 118/250 [2:29:13<2:55:11, 79.63s/it]                                                                                                           Evaluating commonsenseqa :  48%|████▊     | 119/250 [2:30:34<2:54:49, 80.07s/it]        Evaluating commonsenseqa :  48%|████▊     | 120/250 [2:31:54<2:53:47, 80.21s/it]        Evaluating commonsenseqa :  48%|████▊     | 121/250 [2:33:15<2:53:01, 80.48s/it]                                                                                                           Evaluating commonsenseqa :  49%|████▉     | 122/250 [2:34:36<2:51:59, 80.62s/it]        Evaluating commonsenseqa :  49%|████▉     | 123/250 [2:35:57<2:50:44, 80.66s/it]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Evaluating commonsenseqa :  50%|████▉     | 124/250 [2:37:18<2:49:14, 80.59s/it]erator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o7-tgsm8k-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 7
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o7-tgsm8k-s10-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 632447.10it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Evaluating commonsenseqa :  50%|█████     | 125/250 [2:37:36<2:09:11, 62.01s/it] checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  6.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  7.58s/it]
 > number of parameters: 6738415616
[2023-09-03 20:31:11,072] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-03 20:31:11,287] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-03 20:31:11,288] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-03 20:31:11,288] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-03 20:31:11,288] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-03 20:31:11,288] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f3f460>
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-03 20:31:11,289] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-03 20:31:11,290] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-03 20:31:11,290] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-03 20:31:11,290] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-03 20:31:11,290] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-03 20:31:11,290] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-03 20:31:11,290] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-03 20:31:11,290] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-03 20:31:11,290] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-03 20:31:11,290] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-03 20:31:11,290] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-03 20:31:11,290] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-03 20:31:11,290] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-03 20:31:11,290] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-03 20:31:11,290] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-03 20:31:11,290] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-03 20:31:11,290] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-03 20:31:11,290] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-03 20:31:11,290] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-03 20:31:11,290] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-03 20:31:11,290] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-03 20:31:11,290] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-03 20:31:11,290] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-03 20:31:11,290] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-03 20:31:11,290] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-03 20:31:11,290] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-03 20:31:11,290] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-03 20:31:11,290] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-03 20:31:11,290] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-03 20:31:11,290] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/250 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: For the nuts Adam paid 3 * $12 = $<<3*12=36>>36.
And for dried fruits Adam paid 2.5 * $8 = $<<2.5*8=20>>20.
So in total for his purchases Adam paid $36 + $20 = $<<36+20=56>>56.
So the final answer is 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: He spends 60/3=<<60/3=20>>20 minutes warming up
So he spends 60+20=<<60+20=80>>80 minutes at the gym per day
That means he spends 80*3=<<80*3=240>>240 minutes at the gym
So he spends 240/60=<<240/60=4>>4 hours at the gym a week
So the final answer is 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: The cost to fill a tank went up 200*.2=$<<200*.2=40>>40
So it cost 200+40=$<<200+40=240>>240 to fill the tank
That means he now pays 240*2=$<<240*2=480>>480
So the final answer is 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: If the total number of goals scored in the league that season against Barca is 300, the two players scored 20/100*300=<<300*20/100=60>>60 goals.
If the players scored an equal number of goals, each scored 60/2=<<60/2=30>>30 goals.
So the final answer is 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: He drinks 12 * 5 = <<12*5=60>>60 ounces of soda a day
So he drinks 60 + 64 = <<60+64=124>>124 ounces of liquid a day
So in total he drinks 124 * 7 = <<124*7=868>>868 ounces of liquid a week
So the final answer is 868

Input: Stella and Twinkle are filling up a truck with a capacity of 6000 stone blocks at the rate of 250 blocks per hour per person. They work for four hours and are then joined by 6 other people who also work at the same rate. How many hours did filling the truck take?
Output: Stella and Twinkle filled up the truck at the rate of 250 blocks per hour per person, a total of 2*250 = <<250*2=500>>500 blocks per hour for both.
After working for four hours, Stella and Twinkle had filled 4*500 = <<4*500=2000>>2000 blocks into the truck.
The number of blocks they had to put into the truck for it to be full is 6000-2000 = <<6000-2000=4000>>4000
When 6 more people joined Stella and Twinkle, a total of 2+6 = <<2+6=8>>8 people were filling the truck now.
Working at the rate of 250 blocks per person, the eight people filled the truck with 250*8 = <<250*8=2000>>2000 blocks in one hour.
If there were 4000 blocks that still needed to be put into the truck, the 8 people took 4000/2000 = <<4000/2000=2>>2 hours to fill the truck with the blocks.
The total time it took to fill up the tank is 4+2 = <<4+2=6>>6 hours.
So the final answer is 6

Input: Elijah drank 8.5 pints of coffee yesterday. Emilio drank 9.5 pints of water yesterday. How many cups of liquid did the two boys drink yesterday?
Output: Total drunk: 8.5 + 9.5 = <<8.5+9.5=18>>18 pints
18 pints * 2 = <<18*2=36>>36 cups
The two boys drank a total of 36 cups of liquid yesterday.
So the final answer is 36

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o7-tgsm8k-s10-rTrue-m4096
Evaluating commonsenseqa :   0%|          | 1/250 [01:00<4:12:02, 60.73s/it]Evaluating commonsenseqa :   1%|          | 2/250 [01:33<3:03:10, 44.32s/it]              Evaluating commonsenseqa :   1%|          | 3/250 [02:34<3:33:13, 51.80s/it]Evaluating commonsenseqa :   2%|▏         | 4/250 [03:34<3:46:36, 55.27s/it]            Evaluating commonsenseqa :   2%|▏         | 5/250 [04:36<3:54:41, 57.47s/it]            Evaluating commonsenseqa :   2%|▏         | 6/250 [05:37<3:58:40, 58.69s/it]              Evaluating commonsenseqa :   3%|▎         | 7/250 [06:36<3:58:45, 58.95s/it]Evaluating commonsenseqa :   3%|▎         | 8/250 [07:36<3:58:36, 59.16s/it]              Evaluating commonsenseqa :   4%|▎         | 9/250 [08:36<3:59:04, 59.52s/it]              Evaluating commonsenseqa :   4%|▍         | 10/250 [09:37<3:59:05, 59.77s/it]             Evaluating commonsenseqa :   4%|▍         | 11/250 [10:37<3:58:26, 59.86s/it]             Evaluating commonsenseqa :   5%|▍         | 12/250 [11:37<3:58:13, 60.06s/it]Evaluating commonsenseqa :   5%|▌         | 13/250 [12:38<3:58:27, 60.37s/it]             Evaluating commonsenseqa :   6%|▌         | 14/250 [13:39<3:58:02, 60.52s/it]             Evaluating commonsenseqa :   6%|▌         | 15/250 [14:40<3:57:20, 60.60s/it]             Evaluating commonsenseqa :   6%|▋         | 16/250 [15:39<3:55:03, 60.27s/it]Evaluating commonsenseqa :   7%|▋         | 17/250 [16:40<3:54:24, 60.36s/it]             Evaluating commonsenseqa :   7%|▋         | 18/250 [17:18<3:27:39, 53.70s/it]             Evaluating commonsenseqa :   8%|▊         | 19/250 [18:08<3:22:28, 52.59s/it]Evaluating commonsenseqa :   8%|▊         | 20/250 [19:09<3:31:26, 55.16s/it]             Evaluating commonsenseqa :   8%|▊         | 21/250 [20:10<3:36:50, 56.81s/it]             Evaluating commonsenseqa :   9%|▉         | 22/250 [21:10<3:39:41, 57.81s/it]             Evaluating commonsenseqa :   9%|▉         | 23/250 [22:10<3:41:15, 58.48s/it]             Evaluating commonsenseqa :  10%|▉         | 24/250 [23:11<3:43:32, 59.35s/it]Evaluating commonsenseqa :  10%|█         | 25/250 [24:12<3:44:08, 59.77s/it]Evaluating commonsenseqa :  10%|█         | 26/250 [25:12<3:42:55, 59.71s/it]             Evaluating commonsenseqa :  11%|█         | 27/250 [26:14<3:44:17, 60.35s/it]             Evaluating commonsenseqa :  11%|█         | 28/250 [27:14<3:43:13, 60.33s/it]Evaluating commonsenseqa :  12%|█▏        | 29/250 [28:15<3:42:31, 60.41s/it]Evaluating commonsenseqa :  12%|█▏        | 30/250 [29:16<3:42:20, 60.64s/it]           Evaluating commonsenseqa :  12%|█▏        | 31/250 [30:16<3:41:06, 60.58s/it]           Evaluating commonsenseqa :  13%|█▎        | 32/250 [31:17<3:40:25, 60.67s/it]Evaluating commonsenseqa :  13%|█▎        | 33/250 [32:17<3:38:15, 60.35s/it]Evaluating commonsenseqa :  14%|█▎        | 34/250 [32:56<3:14:57, 54.16s/it]Evaluating commonsenseqa :  14%|█▍        | 35/250 [33:56<3:19:56, 55.80s/it]Evaluating commonsenseqa :  14%|█▍        | 36/250 [34:57<3:24:19, 57.29s/it]Evaluating commonsenseqa :  15%|Evaluating commonsenseqa :  61%|██████    | 153/250 [3:13:58<2:06:59, 78.55s/it]Evaluating commonsenseqa :  62%|██████▏   | 154/250 [3:15:19<2:06:34, 79.11s/it]                         Evaluating commonsenseqa :  62%|██████▏   | 155/250 [3:16:39<2:05:57, 79.56s/it]Evaluating commonsenseqa :  62%|██████▏   | 156/250 [3:17:58<2:04:04, 79.20s/it]Evaluating commonsenseqa :  63%|██████▎   | 157/250 [3:19:19<2:03:28, 79.66s/it]                                           Evaluating commonsenseqa :  63%|██████▎   | 158/250 [3:20:40<2:02:48, 80.10s/it]Evaluating commonsenseqa :  64%|██████▎   | 159/250 [3:22:00<2:01:23, 80.04s/it]Evaluating commonsenseqa :  64%|██████▍   | 160/250 [3:23:22<2:01:05, 80.73s/it]                                           Evaluating commonsenseqa :  64%|██████▍   | 161/250 [3:24:43<1:59:59, 80.89s/it]Evaluating commonsenseqa :  65%|██████▍   | 162/250 [3:26:04<1:58:32, 80.82s/it]Evaluating commonsenseqa :  65%|██████▌   | 163/250 [3:27:25<1:57:26, 80.99s/it]                                           Evaluating commonsenseqa :  66%|██████▌   | 164/250 [3:28:44<1:55:17, 80.44s/it]                                                                     Evaluating commonsenseqa :  66%|██████▌   | 165/250 [3:30:05<1:54:00, 80.48s/it]Evaluating commonsenseqa :  66%|██████▋   | 166/250 [3:31:27<1:53:15, 80.89s/it]Evaluating commonsenseqa :  67%|██████▋   | 167/250 [3:32:48<1:52:01, 80.98s/it]                                                   Evaluating commonsenseqa :  67%|██████▋   | 168/250 [3:34:11<1:51:32, 81.62s/it]Evaluating commonsenseqa :  68%|██████▊   | 169/250 [3:35:17<1:43:40, 76.80s/it]Evaluating commonsenseqa :  68%|██████▊   | 170/250 [3:36:04<1:30:32, 67.91s/it]                                                   Evaluating commonsenseqa :  68%|██████▊   | 171/250 [3:37:26<1:34:51, 72.05s/it]Evaluating commonsenseqa :  69%|██████▉   | 172/250 [3:38:46<1:36:46, 74.45s/it]Evaluating commonsenseqa :  69%|██████▉   | 173/250 [3:40:09<1:38:49, 77.00s/it]Evaluating commonsenseqa :  70%|██████▉   | 174/250 [3:41:29<1:39:00, 78.17s/it]Evaluating commonsenseqa :  70%|███████   | 175/250 [3:42:49<1:38:08, 78.51s/it]                                                  Evaluating commonsenseqa :  70%|███████   | 176/250 [3:44:10<1:37:52, 79.36s/it]Evaluating commonsenseqa :  71%|███████   | 177/250 [3:45:31<1:37:09, 79.86s/it]Evaluating commonsenseqa :  71%|███████   | 178/250 [3:46:52<1:36:12, 80.17s/it]                                                           Evaluating commonsenseqa :  72%|███████▏  | 179/250 [3:48:02<1:31:15, 77.12s/it]Evaluating commonsenseqa :  72%|███████▏  | 180/250 [3:49:23<1:31:14, 78.20s/it]                                                                Evaluating commonsenseqa :  72%|███████▏  | 181/250 [3:50:44<1:31:03, 79.18s/it]Evaluating commonsenseqa :  73%|███████▎  | 182/250 [3:52:05<1:30:09, 79.56s/it]Evaluating commonsenseqa :  73%|███████▎  | 183/250 [3:53:23<1:28:35, 79.33s/it]                                                     Evaluating commonsenseqa :  74%|███████▎  | 184/250 [3:54:45<1:27:57, 79.97s/it]Evaluating commonsenseqa :  74%|███████▍  | 185/250 [3:56:02<1:25:42, 79.12s/it]Evaluating commonsenseqa :  74%|███████▍  | 186/250 [3:57:24<1:25:10, 79.86s/it]                                                             Evaluating commonsenseqa :  75%|███████▍  | 187/250 [3:58:45<1:24:16, 80.26s/it]Evaluating commonsenseqa :  75%|███████▌  | 188/250 [3:59:29<1:11:37, 69.32s/it]Evaluating commonsenseqa :  76%|███████5/250 [1:23:18<2:46:18, 60.47s/it]Evaluating commonsenseqa :  34%|███▍      | 86/250 [1:24:19<2:45:31, 60.56s/it]Evaluating commonsenseqa :  35%|███▍      | 87/250 [1:25:19<2:44:39, 60.61s/it]Evaluating commonsenseqa :  35%|███▌      | 88/250 [1:26:20<2:43:30, 60.56s/it]Evaluating commonsenseqa :  36%|███▌      | 89/250 [1:27:19<2:41:30, 60.19s/it]Evaluating commonsenseqa :  36%|███▌      | 90/250 [1:28:20<2:40:36, 60.23s/it]Evaluating commonsenseqa :  36%|███▋      | 91/250 [1:29:21<2:40:14, 60.47s/it]Evaluating commonsenseqa :  37%|███▋      | 92/250 [1:30:21<2:39:31, 60.58s/it]Evaluating commonsenseqa :  37%|███▋      | 93/250 [1:31:21<2:37:48, 60.31s/it]Evaluating commonsenseqa :  38%|███▊      | 94/250 [1:32:20<2:36:05, 60.04s/it]Evaluating commonsenseqa :  38%|███▊      | 95/250 [1:33:21<2:35:18, 60.12s/it]Evaluating commonsenseqa :  38%|███▊      | 96/250 [1:34:22<2:34:47, 60.31s/it]Evaluating commonsenseqa :  39%|███▉      | 97/250 [1:35:21<2:33:11, 60.08s/it]         Evaluating commonsenseqa :  39%|███▉      | 98/250 [1:36:22<2:33:03, 60.42s/it]Evaluating commonsenseqa :  40%|███▉      | 99/250 [1:37:23<2:32:01, 60.41s/it]Evaluating commonsenseqa :  40%|████      | 100/250 [1:38:23<2:31:17, 60.52s/it]Evaluating commonsenseqa :  40%|████      | 101/250 [1:39:24<2:30:10, 60.47s/it]Evaluating commonsenseqa :  41%|████      | 102/250 [1:40:25<2:29:41, 60.69s/it]Evaluating commonsenseqa :  41%|████      | 103/250 [1:41:26<2:28:59, 60.82s/it]Evaluating commonsenseqa :  42%|████▏     | 104/250 [1:42:25<2:26:51, 60.35s/it]Evaluating commonsenseqa :  42%|████▏     | 105/250 [1:43:26<2:25:46, 60.32s/it]Evaluating commonsenseqa :  42%|████▏     | 106/250 [1:44:26<2:24:58, 60.41s/it]Evaluating commonsenseqa :  43%|████▎     | 107/250 [1:45:26<2:23:26, 60.19s/it]Evaluating commonsenseqa :  43%|████▎     | 108/250 [1:46:27<2:23:12, 60.51s/it]Evaluating commonsenseqa :  44%|████▎     | 109/250 [1:47:27<2:21:43, 60.31s/it]Evaluating commonsenseqa :  44%|████▍     | 110/250 [1:48:28<2:21:03, 60.45s/it]Evaluating commonsenseqa :  44%|████▍     | 111/250 [1:49:29<2:20:29, 60.64s/it]Evaluating commonsenseqa :  45%|████▍     | 112/250 [1:50:29<2:19:27, 60.63s/it]Evaluating commonsenseqa :  45%|████▌     | 113/250 [1:51:31<2:19:04, 60.91s/it]Evaluating commonsenseqa :  46%|████▌     | 114/250 [1:52:31<2:17:29, 60.66s/it]Evaluating commonsenseqa :  46%|████▌     | 115/250 [1:53:31<2:16:16, 60.57s/it]Evaluating commonsenseqa :  46%|████▋     | 116/250 [1:54:32<2:15:02, 60.46s/it]Evaluating commonsenseqa :  47%|████▋     | 117/250 [1:55:32<2:13:36, 60.27s/it]Evaluating commonsenseqa :  47%|████▋     | 118/250 [1:56:32<2:12:26, 60.20s/it]Evaluating commonsenseqa :  48%|████▊     | 119/250 [1:57:32<2:11:28, 60.22s/it]Evaluating commonsenseqa :  48%|████▊     | 120/250 [1:58:34<2:11:30, 60.70s/it]Evaluating commonsenseqa :  48%|████▊     | 121/250 [1:58:53<1:43:57, 48.36s/it]Evaluating commonsenseqa :  49%|████▉     | 122/250 [1:59:53<1:50:41, 51.89s/it]Evaluating commonsenseqa :  49%|████▉     | 123/250 [2:00:55<1:55:52, 54.74s/it]Evaluating commonsenseqa :  50%|████▉     | 124/250 [2:01:57<1:59:40, 56.99s/it]Evaluating commonsenseqa :  50%|█████     | 125/250 [2:02:59<2:01:48, 58.47s/it]Evaluating commonsenseqa :  50%|█████     | 126/250 [2:03:58<2:01:23, 58.74s/it]Evaluating commonsenseqa :  51%|█████     | 127/250 [2:05:00<2:01:57, 59.49s/it]Evaluating commonsenseqa :  51%|█████     | 128/250 [2:06:00<2:01:38, 59.82s/it]Evaluating commonsenseqa :  52%|█████▏    | 129/250 [2:07:02<2:01:40, 60.34s/it]Evaluating commonsenseqa :  52%|█████▏    | 130/250 [2:08:02<2:00:45, 60.38s/it]Evaluating commonsenseqa :  52%|█████▏    | 131/250 [2:09:03<2:00:06, 60.56s/it]Evaluating commonsenseqa :  53%|█████▎    | 132/250 [2:10:02<1:58:18, 60.15s/it]Evaluating commonsenseqa :  53%|█████▎    | 133/250 [2:11:03<1:57:32, 60.28s/it]Evaluating commonsenseqa :  54%|█████▎    | 134/250 [2:12:03<1:56:24, 60.21s/it]Evaluating commonsenseqa :  54%|█████▍    | 135/250 [2:13:03<1:55:18, 60.16s/it]Evaluating commonsenseqa :  54%|█████▍    | 136/250 [2:14:03<1:54:05, 60.05s/it]Evaluating commonsenseqa :  55%|█████▍    | 137/250 [2:15:02<1:52:41, 59.83s/it]Evaluating commonsenseqa :  55%|█████▌    | 138/250 [2:16:02<1:51:29, 59.73s/it]Evaluating commonsenseqa :  56%|█████▌    | 139/250 [2:17:03<1:51:32, 60.29s/it]Evaluating commonsenseqa :  56%|█████▌    | 140/250 [2:18:03<1:50:24, 60.22s/it]Evaluating commonsenseqa :  56%|█████▋    | 141/250 [2:19:03<1:48:54, 59.95s/it]Evaluating commonsenseqa :  57%|█████▋    | 142/250 [2:20:03<1:48:15, 60.15s/it]Evaluating commonsenseqa :  57%|█████▋    | 143/250 [2:21:03<1:46:50, 59.91s/it]Evaluating commonsenseqa :  58%|█████▊    | 144/250 [2:22:04<1:46:32, 60.31s/it]Evaluating commonsenseqa :  58%|█████▊    | 145/250 [2:23:04<1:45:17, 60.17s/it]Evaluating commonsenseqa :  58%|█████▊    | 146/250 [2:24:04<1:44:26, 60.25s/it]Evaluating commonsenseqa :  59%|█████▉    | 147/250 [2:25:04<1:43:24, 60.23s/it]Evaluating commonsenseqa :  59%|█████▉    | 148/250 [2:26:05<1:42:39, 60.39s/it]Evaluating commonsenseqa :  60%|█████▉    | 149/250 [2:27:05<1:41:18, 60.18s/it]Evaluating commonsenseqa :  60%|██████    | 150/250 [2:28:05<1:40:14, 60.14s/it]Evaluating commonsenseqa :  60%|██████    | 151/250 [2:29:05<1:39:31, 60.31s/it]Evaluating commonsenseqa :  61%|██████    | 152/250 [2:29:47<1:29:22, 54.72s/it]Evaluating commonsenseqa :  61%|██████    | 153/250 [2:30:47<1:31:05, 56.34s/it]Evaluating commonsenseqa :  62%|██████▏   | 154/250 [2:31:48<1:32:05, 57.56s/it]Evaluating commonsenseqa :  62%|██████▏   | 155/250 [2:32:48<1:32:15, 58.27s/it]Evaluating commonsenseqa :  62%|██████▏   | 156/250 [2:33:48<1:32:21, 58.96s/it]Evaluating commonsenseqa :  63%|██████▎   | 157/250 [2:34:49<1:32:14, 59.51s/it]Evaluating commonsenseqa :  63%|██████▎   | 158/250 [2:35:50<1:31:45, 59.84s/it]Evaluating commonsenseqa :  64%|██████▎   | 159/250 [2:36:49<1:30:41, 59.80s/it]Evaluating commonsenseqa :  64%|██████▍   | 160/250 [2:37:49<1:29:39, 59.77s/it]Evaluating commonsenseqa :  64%|██████▍   | 161/250 [2:38:50<1:29:15, 60.17s/it]Evaluating commonsenseqa :  65%|██████▍   | 162/250 [2:39:50<1:28:16, 60.18s/it]Evaluating commonsenseqa :  65%|██████▌   | 163/250 [2:40:50<1:26:55, 59.95s/it]Evaluating commonsenseqa :  66%|██████▌   | 164/250 [2:41:50<1:26:14, 60.17s/it]Evaluating commonsenseqa :  66%|██████▌   | 165/250 [2:42:50<1:25:13, 60.16s/it]0:00, 76.82s/it]
name: commonsenseqa | avg. gen lenth: 306.814 | time: 19205.64701104164s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr gpu03 --master_port 17129 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o3-tgsm8k-s10-rTrue --seed 10 --max-prompt-length 4096 --rationales --num-out-domain 3 1 2 3 4 5 True 4096 4
Evaluating commonsenseqa :  66%|██████▋   | 166/250 [2:43:50<1:23:56, 59.96s/it]or to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o3-tgsm8k-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 3
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o3-tgsm8k-s10-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 1054475.69it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:11<00:11, 11.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  7.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  8.03s/it]
 > number of parameters: 6738415616
[2023-09-03 23:14:12,812] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-03 23:14:13,032] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-03 23:14:13,033] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-03 23:14:13,034] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-03 23:14:13,034] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-03 23:14:13,034] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-03 23:14:13,034] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-03 23:14:13,034] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-03 23:14:13,034] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-03 23:14:13,034] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-03 23:14:13,034] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-03 23:14:13,034] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-03 23:14:13,034] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f3d460>
[2023-09-03 23:14:13,034] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-03 23:14:13,034] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-03 23:14:13,034] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-03 23:14:13,034] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-03 23:14:13,034] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-03 23:14:13,034] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-03 23:14:13,034] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-03 23:14:13,034] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-03 23:14:13,034] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-03 23:14:13,034] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-03 23:14:13,034] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-03 23:14:13,034] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-03 23:14:13,034] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-03 23:14:13,034] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-03 23:14:13,034] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-03 23:14:13,034] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-03 23:14:13,034] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-03 23:14:13,034] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-03 23:14:13,035] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-03 23:14:13,035] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/250 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: For the nuts Adam paid 3 * $12 = $<<3*12=36>>36.
And for dried fruits Adam paid 2.5 * $8 = $<<2.5*8=20>>20.
So in total for his purchases Adam paid $36 + $20 = $<<36+20=56>>56.
So the final answer is 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: He spends 60/3=<<60/3=20>>20 minutes warming up
So he spends 60+20=<<60+20=80>>80 minutes at the gym per day
That means he spends 80*3=<<80*3=240>>240 minutes at the gym
So he spends 240/60=<<240/60=4>>4 hours at the gym a week
So the final answer is 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: The cost to fill a tank went up 200*.2=$<<200*.2=40>>40
So it cost 200+40=$<<200+40=240>>240 to fill the tank
That means he now pays 240*2=$<<240*2=480>>480
So the final answer is 480

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o3-tgsm8k-s10-rTrue-m4096
Evaluating commonsenseqa :   0%|          | 1/250 [01:18<5:27:12, 78.84s/it]Evaluating commonsenseqa :   1%|          | 2/250 [02:38<5:27:38, 79.27s/it]                                    Evaluating commonsenseqa :   1%|          | 3/250 [03:54<5:20:16, 77.80s/it]                                                                                                                 Evaluating commonsenseqa :   2%|▏         | 4/250 [05:10<5:16:52, 77.29s/it]                Evaluating commonsenseqa :   2%|▏         | 5/250 [06:30<5:18:58, 78.12s/it]5:39, 58.20s/it]Evaluating commonsenseqa :  69%|██████▉   | 173/250 [2:50:22<1:15:38, 58.94s/it]Evaluating commonsenseqa :  70%|██████▉   | 174/250 [2:51:22<1:15:07, 59.31s/it]Evaluating commonsenseqa :  70%|███████   | 175/250 [2:51:58<1:05:16, 52.22s/it]Evaluating commonsenseqa :  70%|███████   | 176/250 [2:52:58<1:07:20, 54.60s/it]Evaluating commonsenseqa :  71%|███████   | 177/250 [2:53:58<1:08:32, 56.34s/it]Evaluating commonsenseqa :  71%|███████   | 178/250 [2:55:00<1:09:29, 57.92s/it]Evaluating commonsenseqa :  72%|███████▏  | 179/250 [2:56:00<1:09:21, 58.62s/it]Evaluating commonsenseqa :  72%|███████▏  | 180/250 [2:57:01<1:09:14, 59.35s/it]Evaluating commonsenseqa :  72%|███████▏  | 181/250 [2:58:02<1:08:44, 59.77s/it]Evaluating commonsenseqa :  73%|███████▎  | 182/250 [2:59:02<1:07:43, 59.76s/it]Evaluating commonsenseqa :  73%|███████▎  | 183/250 [2:59:52<1:03:25, 56.80s/it]Evaluating commonsenseqa :  74%|███████▎  | 184/250 [3:00:53<1:03:52, 58.07s/it]Evaluating commonsenseqa :  74%|███████▍  | 185/250 [3:01:53<1:03:39, 58.76s/it]Evaluating commonsenseqa :  74%|███████▍  | 186/250 [3:02:53<1:02:53, 58.96s/it]Evaluating commonsenseqa :  75%|███████▍  | 187/250 [3:03:53<1:02:17, 59.32s/it]Evaluating commonsenseqa :  75%|███████▌  | 188/250 [3:04:54<1:01:52, 59.88s/it]Evaluating commonsenseqa :  76%|███████▌  | 189/250 [3:05:56<1:01:26, 60.43s/it]Evaluating commonsenseqa :  76%|███████▌  | 190/250 [3:06:56<1:00:27, 60.47s/it]Evaluating commonsenseqa :  76%|███████▋  | 191/250 [3:07:57<59:27, 60.47s/it]  Evaluating commonsenseqa :  77%|███████▋  | 192/250 [3:08:26<49:23, 51.09s/it]Evaluating commonsenseqa :  77%|███████▋  | 193/250 [3:09:26<51:14, 53.93s/it]Evaluating commonsenseqa :  78%|███████▊  | 194/250 [3:10:28<52:26, 56.20s/it]Evaluating commonsenseqa :  78%|███████▊  | 195/250 [3:11:28<52:40, 57.46s/it]Evaluating commonsenseqa :  78%|███████▊  | 196/250 [3:12:29<52:28, 58.31s/it]Evaluating commonsenseqa :  79%|███████▉  | 197/250 [3:13:04<45:31, 51.53s/it]Evaluating commonsenseqa :  79%|███████▉  | 198/250 [3:14:04<46:42, 53.90s/it]Evaluating commonsenseqa :  80%|███████▉  | 199/250 [3:15:04<47:32, 55.93s/it]Evaluating commonsenseqa :  80%|████████  | 200/250 [3:16:04<47:24, 56.90s/it]Evaluating commonsenseqa :  80%|████████  | 201/250 [3:17:04<47:20, 57.96s/it]Evaluating commonsenseqa :  81%|████████  | 202/250 [3:18:05<47:04, 58.84s/it]Evaluating commonsenseqa :  81%|████████  | 203/250 [3:19:05<46:25, 59.26s/it]Evaluating commonsenseqa :  82%|████████▏ | 204/250 [3:20:05<45:27, 59.30s/it]Evaluating commonsenseqa :  82%|████████▏ | 205/250 [3:20:33<37:34, 50.09s/it]Evaluating commonsenseqa :  82%|████████▏ | 206/250 [3:21:34<39:07, 53.36s/it]Evaluating commonsenseqa :  83%|████████▎ | 207/250 [3:22:35<39:51, 55.60s/it]Evaluating commonsenseqa :  83%|████████▎ | 208/250 [3:23:34<39:42, 56.74s/it]Evaluating commonsenseqa :  84%|████████▎ | 209/250 [3:24:35<39:31, 57.84s/it]Evaluating commonsenseqa :  84%|████████▍ | 210/250 [3:25:35<38:57, 58.45s/it]Evaluating commonsenseqa :  84%|████████▍ | 211/250 [3:26:35<38:16, 58.89s/it]Evaluating commonsenseqa :  85%|████████▍ | 212/250 [3:27:35<37:35, 59.35s/it]Evaluating commonsenseqa :  85%|████████▌ | 213/250 [3:28:31<35:56, 58.28s/it]Evaluating commonsenseqa :  86%|████████▌ | 214/250 [3:29:31<35:22, 58.95s/it]Evaluating commonsenseqa :  15%|█▌        | 38/250 [47:37<4:21:16, 73.94s/it]                                                                                                                Evaluating commonsenseqa :  16%|█▌        | 39/250 [48:53<4:22:43, 74.71s/it]               Evaluating commonsenseqa :  16%|█▌        | 40/250 [50:11<4:25:10, 75.77s/it]               Evaluating commonsenseqa :  16%|█▋        | 41/250 [51:15<4:10:37, 71.95s/it]               Evaluating commonsenseqa :  17%|█▋        | 42/250 [52:17<3:59:49, 69.18s/it]               Evaluating commonsenseqa :  17%|█▋        | 43/250 [53:35<4:07:09, 71.64s/it]               Evaluating commonsenseqa :  18%|█▊        | 44/250 [54:52<4:12:07, 73.43s/it]                                                                                                                Evaluating commonsenseqa :  18%|█▊        | 45/250 [56:09<4:13:49, 74.29s/it]               Evaluating commonsenseqa :  18%|█▊        | 46/250 [57:25<4:15:00, 75.00s/it]               Evaluating commonsenseqa :  19%|█▉        | 47/250 [58:44<4:17:17, 76.05s/it]                                                                                                                Evaluating commonsenseqa :  19%|█▉        | 48/250 [1:00:02<4:18:41, 76.84s/it]             Evaluating commonsenseqa :  20%|█▉        | 49/250 [1:01:19<4:17:09, 76.76s/it]               Evaluating commonsenseqa :  20%|██        | 50/250 [1:02:37<4:16:48, 77.04s/it]                                                                                                                  Evaluating commonsenseqa :  20%|██        | 51/250 [1:03:54<4:15:56, 77.17s/it]               Evaluating commonsenseqa :  21%|██        | 52/250 [1:05:12<4:15:47, 77.51s/it]               Evaluating commonsenseqa :  21%|██        | 53/250 [1:06:30<4:14:07, 77.40s/it]               Evaluating commonsenseqa :  22%|██▏       | 54/250 [1:07:48<4:13:37, 77.64s/it]                                                                                                                Evaluating commonsenseqa :  22%|██▏       | 55/250 [1:09:03<4:10:22, 77.04s/it]             Evaluating commonsenseqa :  22%|██▏       | 56/250 [1:10:21<4:09:21, 77.12s/it]             Evaluating commonsenseqa :  23%|██▎       | 57/250 [1:11:26<3:56:16, 73.46s/it]                                                                                                                Evaluating commonsenseqa :  23%|██▎       | 58/250 [1:12:44<3:59:44, 74.92s/it]             Evaluating commonsenseqa :  24%|██▎       | 59/250 [1:13:54<3:54:17, 73.60s/it]             Evaluating commonsenseqa :  24%|██▍       | 60/250 [1:15:10<3:54:31, 74.06s/it]             Evaluating commonsenseqa :  24%|██▍       | 61/250 [1:16:28<3:57:01, 75.24s/it]                                                                                                                Evaluating commonsenseqa :  25%|██▍       | 62/250 [1:17:43<3:56:13, 75.39s/it]             Evaluating commonsenseqa :  25%|██▌       | 63/250 [1:19:01<3:56:44, 75.96s/it]             Evaluating commonsenseqa :  26%|██▌       | 64/250 [1:20:18<3:57:13, 76.53s/it]             Evaluating commonsenseqa :  26%|██▌       | 65/250 [1:21:36<3:56:39, 76.75s/it]0, 60.93s/it]Evaluating commonsenseqa : 100%|██████████| 250/250 [4:04:55<00:00, 60.54s/it]Evaluating commonsenseqa : 100%|██████████| 250/250 [4:04:55<00:00, 58.78s/it]
name: commonsenseqa | avg. gen lenth: 345.836 | time: 14697.000158786774s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr gpu04 --master_port 12094 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s10-rTrue --seed 10 --max-prompt-length 4096 --rationales --num-out-domain 8 6 7 8 9 10 True 4096 4
Evaluating commonsenseqa :  26%|██▋       | 66/250 [1:22:53<3:55:50, 76.90s/it]accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 8
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o8-tgsm8k-s10-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 564912.27it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:11<00:11, 11.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  6.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  7.64s/it]
 > number of parameters: 6738415616
[2023-09-04 00:36:32,995] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-04 00:36:33,221] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-04 00:36:33,223] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-04 00:36:33,223] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-04 00:36:33,223] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-04 00:36:33,223] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-04 00:36:33,223] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-04 00:36:33,224] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-04 00:36:33,224] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-04 00:36:33,224] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-04 00:36:33,224] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-04 00:36:33,224] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-04 00:36:33,224] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f3d460>
[2023-09-04 00:36:33,224] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-04 00:36:33,224] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-04 00:36:33,224] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-04 00:36:33,224] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-04 00:36:33,224] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-04 00:36:33,224] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-04 00:36:33,224] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-04 00:36:33,224] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-04 00:36:33,224] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-04 00:36:33,224] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-04 00:36:33,224] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-04 00:36:33,224] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-04 00:36:33,224] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-04 00:36:33,224] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-04 00:36:33,224] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-04 00:36:33,224] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-04 00:36:33,224] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-04 00:36:33,224] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-04 00:36:33,224] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-04 00:36:33,224] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-04 00:36:33,224] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-04 00:36:33,225] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-04 00:36:33,226] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-04 00:36:33,226] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-04 00:36:33,226] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/250 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: For the nuts Adam paid 3 * $12 = $<<3*12=36>>36.
And for dried fruits Adam paid 2.5 * $8 = $<<2.5*8=20>>20.
So in total for his purchases Adam paid $36 + $20 = $<<36+20=56>>56.
So the final answer is 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: He spends 60/3=<<60/3=20>>20 minutes warming up
So he spends 60+20=<<60+20=80>>80 minutes at the gym per day
That means he spends 80*3=<<80*3=240>>240 minutes at the gym
So he spends 240/60=<<240/60=4>>4 hours at the gym a week
So the final answer is 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: The cost to fill a tank went up 200*.2=$<<200*.2=40>>40
So it cost 200+40=$<<200+40=240>>240 to fill the tank
That means he now pays 240*2=$<<240*2=480>>480
So the final answer is 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: If the total number of goals scored in the league that season against Barca is 300, the two players scored 20/100*300=<<300*20/100=60>>60 goals.
If the players scored an equal number of goals, each scored 60/2=<<60/2=30>>30 goals.
So the final answer is 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: He drinks 12 * 5 = <<12*5=60>>60 ounces of soda a day
So he drinks 60 + 64 = <<60+64=124>>124 ounces of liquid a day
So in total he drinks 124 * 7 = <<124*7=868>>868 ounces of liquid a week
So the final answer is 868

Input: Stella and Twinkle are filling up a truck with a capacity of 6000 stone blocks at the rate of 250 blocks per hour per person. They work for four hours and are then joined by 6 other people who also work at the same rate. How many hours did filling the truck take?
Output: Stella and Twinkle filled up the truck at the rate of 250 blocks per hour per person, a total of 2*250 = <<250*2=500>>500 blocks per hour for both.
After working for four hours, Stella and Twinkle had filled 4*500 = <<4*500=2000>>2000 blocks into the truck.
The number of blocks they had to put into the truck for it to be full is 6000-2000 = <<6000-2000=4000>>4000
When 6 more people joined Stella and Twinkle, a total of 2+6 = <<2+6=8>>8 people were filling the truck now.
Working at the rate of 250 blocks per person, the eight people filled the truck with 250*8 = <<250*8=2000>>2000 blocks in one hour.
If there were 4000 blocks that still needed to be put into the truck, the 8 people took 4000/2000 = <<4000/2000=2>>2 hours to fill the truck with the blocks.
The total time it took to fill up the tank is 4+2 = <<4+2=6>>6 hours.
So the final answer is 6

Input: Elijah drank 8.5 pints of coffee yesterday. Emilio drank 9.5 pints of water yesterday. How many cups of liquid did the two boys drink yesterday?
Output: Total drunk: 8.5 + 9.5 = <<8.5+9.5=18>>18 pints
18 pints * 2 = <<18*2=36>>36 cups
The two boys drank a total of 36 cups of liquid yesterday.
So the final answer is 36

Input: Doris works at the Widget Factory in the packing department. She puts 3 widgets in each carton, which are 4 inches wide, 4 inches long, and 5 inches tall. She then packs those cartons into a shipping box before sending it to the loading bay. The shipping boxes are 20 inches wide, 20 inches long, and 20 inches high. How many widgets get shipped in each shipping box?
Output: Each carton has an area of 4*4*5 = <<4*4*5=80>>80 square inches.
Each shipping box has an area of 20*20*20 = <<20*20*20=8000>>8000 square inches
The total number of cartons that will fit into each box is 8000/80 = <<8000/80=100>>100
Since there are 3 widgets in each carton, the total number of cartons in each box will be 3*100 = <<3*100=300>>300
So the final answer is 300

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o8-tgsm8k-s10-rTrue-m4096
Evaluating commonsenseqa :   0%|          | 1/250 [00:57<3:58:42, 57.52s/it]Evaluating commonsenseqa :   1%|          | 2/250 [01:55<3:58:33, 57.72s/it]Evaluating commonsenseqa :   1%|          | 3/250 [02:51<3:53:44, 56.78s/it]Evaluating commonsenseqa :   2%|▏         | 4/250 [03:47<3:52:35, 56.73s/it]Evaluating commonsenseqa :   2%|▏         | 5/250 [04:44<3:52:13, 56.87s/it]Evaluating commonsenseqa :   2%|▏         | 6/250 [05:40<3:49:50, 56.52s/it]Evaluating commonsenseqa :   3%|▎         | 7/250 [06:36<3:48:29, 56.42s/it]Evaluating commonsenseqa :   3%|▎         | 8/250 [07:21<3:32:14, 52.62s/it]Evaluating commonsenseqa :   4%|▎         | 9/250 [08:18<3:36:27, 53.89s/it]Evaluating commonsenseqa :   4%|▍         | 10/250 [09:14<3:39:16, 54.82s/it]Evaluating commonsenseqa :   4%|▍         | 11/250 [10:11<3:40:59, 55.48s/it]Evaluating commonsenseqa :   5%|▍         | 12/250 [11:08<3:41:50, 55.93s/it]Evaluating commonsenseqa :   5%|▌         | 13/250 [12:05<3:41:50, 56.16s/it]Evaluating commonsenseqa :   6%|▌         | 14/250 [13:01<3:40:57, 56.18s/it]Evaluating commonsenseqa :   6%|▌         | 15/250 [13:59<3:42:23:03:45, 63.73s/it]Evaluating commonsenseqa :  31%|███       | 78/250 [1:37:14<3:14:22, 67.81s/it]Evaluating commonsenseqa :  32%|███▏      | 79/250 [1:38:32<3:22:02, 70.89s/it]Evaluating commonsenseqa :  32%|███▏      | 80/250 [1:39:47<3:24:35, 72.21s/it]                                                          Evaluating commonsenseqa :  32%|███▏      | 81/250 [1:41:04<3:27:00, 73.49s/it]Evaluating commonsenseqa :  33%|███▎      | 82/250 [1:42:19<3:27:13, 74.01s/it]Evaluating commonsenseqa :  33%|███▎      | 83/250 [1:43:35<3:27:59, 74.73s/it]                                                        Evaluating commonsenseqa :  34%|███▎      | 84/250 [1:44:53<3:29:19, 75.66s/it]Evaluating commonsenseqa :  34%|███▍      | 85/250 [1:45:42<3:06:20, 67.76s/it]                                                                Evaluating commonsenseqa :  34%|███▍      | 86/250 [1:47:00<3:13:06, 70.65s/it]Evaluating commonsenseqa :  35%|███▍      | 87/250 [1:48:16<3:16:43, 72.42s/it]Evaluating commonsenseqa :  35%|███▌      | 88/250 [1:49:32<3:18:18, 73.45s/it]Evaluating commonsenseqa :  36%|███▌      | 89/250 [1:50:51<3:21:13, 74.99s/it]                                                              Evaluating commonsenseqa :  36%|███▌      | 90/250 [1:51:30<2:51:37, 64.36s/it]Evaluating commonsenseqa :  36%|███▋      | 91/250 [1:52:47<3:00:03, 67.95s/it]Evaluating commonsenseqa :  37%|███▋      | 92/250 [1:53:37<2:45:24, 62.82s/it]Evaluating commonsenseqa :  37%|███▋      | 93/250 [1:54:54<2:55:10, 66.95s/it]Evaluating commonsenseqa :  38%|███▊      | 94/250 [1:56:11<3:02:09, 70.06s/it]Evaluating commonsenseqa :  38%|███▊      | 95/250 [1:57:28<3:06:27, 72.18s/it]                                                                Evaluating commonsenseqa :  38%|███▊      | 96/250 [1:58:45<3:08:55, 73.61s/it]Evaluating commonsenseqa :  39%|███▉      | 97/250 [2:00:01<3:09:32, 74.33s/it]Evaluating commonsenseqa :  39%|███▉      | 98/250 [2:01:17<3:09:09, 74.67s/it]                                                                Evaluating commonsenseqa :  40%|███▉      | 99/250 [2:02:32<3:08:23, 74.86s/it]Evaluating commonsenseqa :  40%|████      | 100/250 [2:03:43<3:03:46, 73.51s/it]Evaluating commonsenseqa :  40%|████      | 101/250 [2:05:00<3:05:40, 74.77s/it]Evaluating commonsenseqa :  41%|████      | 102/250 [2:06:17<3:06:10, 75.48s/it]                                                       Evaluating commonsenseqa :  41%|████      | 103/250 [2:07:34<3:05:35, 75.75s/it]Evaluating commonsenseqa :  42%|████▏     | 104/250 [2:08:50<3:04:37, 75.87s/it]                                                                  Evaluating commonsenseqa :  42%|████▏     | 105/250 [2:09:51<2:52:19, 71.31s/it]Evaluating commonsenseqa :  42%|████▏     | 106/250 [2:11:08<2:55:25, 73.10s/it]Evaluating commonsenseqa :  43%|████▎     | 107/250 [2:11:22<2:11:46, 55.29s/it]                                                                  Evaluating commonsenseqa :  43%|████▎     | 108/250 [2:12:39<2:26:48, 62.03s/it]Evaluating commonsenseqa :  44%|████▎     | 109/250 [2:13:56<2:36:16, 66.50s/it]Evaluating commonsenseqa :  44%|████▍     | 110/250 [2:15:14<2:42:49, 69.78s/it]Evaluating commonsenseqa :  44%|████▍     | 111/250 [2:16:30<2:46:18, 71.79s/it]Evaluating commonsenseqa :  45%|████▍     | 112/250 [2:17:47<2:48:28, 73.25s/it]                                                        Evaluating commonsenseqa :  45%|████▌     | 113/250 [2:19:04<2:50:10, 74.53s/it]Evaluating commonsenseqa :  46%|████▌     | 114/250 [2:20:24<2:52:09, 75.96s/it]                                                                      Evaluating commonsenseqa :  46%|████▌     | 115/250 [2:21:43<2:53:07, 76.94s/it]Evaluating comeqa :  26%|██▌       | 65/250 [1:00:13<2:50:14, 55.21s/it]Evaluating commonsenseqa :  26%|██▋       | 66/250 [1:01:10<2:50:35, 55.63s/it]Evaluating commonsenseqa :  27%|██▋       | 67/250 [1:02:08<2:51:41, 56.29s/it]Evaluating commonsenseqa :  27%|██▋       | 68/250 [1:02:58<2:45:05, 54.43s/it]Evaluating commonsenseqa :  28%|██▊       | 69/250 [1:03:54<2:45:26, 54.84s/it]Evaluating commonsenseqa :  28%|██▊       | 70/250 [1:04:49<2:45:12, 55.07s/it]Evaluating commonsenseqa :  28%|██▊       | 71/250 [1:05:45<2:45:17, 55.41s/it]Evaluating commonsenseqa :  29%|██▉       | 72/250 [1:06:41<2:44:24, 55.42s/it]Evaluating commonsenseqa :  29%|██▉       | 73/250 [1:07:37<2:44:16, 55.69s/it]Evaluating commonsenseqa :  30%|██▉       | 74/250 [1:08:32<2:43:03, 55.59s/it]     Evaluating commonsenseqa :  30%|███       | 75/250 [1:09:30<2:43:34, 56.09s/it]Evaluating commonsenseqa :  30%|███       | 76/250 [1:10:26<2:42:55, 56.18s/it]Evaluating commonsenseqa :  31%|███       | 77/250 [1:11:23<2:42:51, 56.48s/it]Evaluating commonsenseqa :  31%|███       | 78/250 [1:12:19<2:41:00, 56.16s/it]Evaluating commonsenseqa :  32%|███▏      | 79/250 [1:13:16<2:40:42, 56.39s/it]Evaluating commonsenseqa :  32%|███▏      | 80/250 [1:14:12<2:39:38, 56.35s/it]Evaluating commonsenseqa :  32%|███▏      | 81/250 [1:14:47<2:20:58, 50.05s/it]Evaluating commonsenseqa :  33%|███▎      | 82/250 [1:15:46<2:27:05, 52.53s/it]Evaluating commonsenseqa :  33%|███▎      | 83/250 [1:16:42<2:29:31, 53.72s/it]Evaluating commonsenseqa :  34%|███▎      | 84/250 [1:17:39<2:31:08, 54.63s/it]Evaluating commonsenseqa :  34%|███▍      | 85/250 [1:18:35<2:31:28, 55.08s/it]Evaluating commonsenseqa :  34%|███▍      | 86/250 [1:19:32<2:32:00, 55.61s/it]Evaluating commonsenseqa :  35%|███▍      | 87/250 [1:20:28<2:31:11, 55.65s/it]Evaluating commonsenseqa :  35%|███▌      | 88/250 [1:21:24<2:30:33, 55.76s/it]Evaluating commonsenseqa :  36%|███▌      | 89/250 [1:22:19<2:29:18, 55.64s/it]Evaluating commonsenseqa :  36%|███▌      | 90/250 [1:23:14<2:28:16, 55.60s/it]Evaluating commonsenseqa :  36%|███▋      | 91/250 [1:24:11<2:28:03, 55.87s/it]Evaluating commonsenseqa :  37%|███▋      | 92/250 [1:24:57<2:19:31, 52.98s/it]Evaluating commonsenseqa :  37%|███▋      | 93/250 [1:25:54<2:21:22, 54.03s/it]Evaluating commonsenseqa :  38%|███▊      | 94/250 [1:26:49<2:21:37, 54.47s/it]Evaluating commonsenseqa :  38%|███▊      | 95/250 [1:27:46<2:22:26, 55.14s/it]Evaluating commonsenseqa :  38%|███▊      | 96/250 [1:28:42<2:22:13, 55.42s/it]Evaluating commonsenseqa :  39%|███▉      | 97/250 [1:29:38<2:21:53, 55.64s/it]Evaluating commonsenseqa :  39%|███▉      | 98/250 [1:30:34<2:21:08, 55.71s/it]Evaluating commonsenseqa :  40%|███▉      | 99/250 [1:31:30<2:20:09, 55.69s/it]Evaluating commonsenseqa :  40%|████      | 100/250 [1:32:27<2:20:28, 56.19s/it]Evaluating commonsenseqa :  40%|████      | 101/250 [1:33:23<2:19:34, 56.21s/it]Evaluating commonsenseqa :  41%|████      | 102/250 [1:34:20<2:18:59, 56.35s/it]Evaluating commonsenseqa :  41%|████      | 103/250 [1:35:09<2:12:57, 54.27s/it]Evaluating commonsenseqa :  42%|████▏     | 104/250 [1:36:05<2:13:21, 54.81s/it]Evaluating commonsenseqa :  42%|████▏     | 105/250 [1:37:02<2:13:42, 55.33s/it]Evaluating commonsenseqa :  42%|████▏     | 106/250 [1:37:58<2:13:11, 55.50s/it]Evaluating commonsenseqa :  43%|████▎     | 107/250 [1:38:54<2:13:08, 55.86s/it]Evaluating commonsenseqa :  43%|████▎     | 108/250 [1:39:51<2:12:35, 56.02s/it]Evaluating commonsenseqa :  44%|████▎     | 109/250 [1:40:28<1:58:36, 50.47s/it]Evaluating commonsenseqa :  44%|████▍     | 110/250 [1:41:25<2:02:07, 52.34s/it]Evaluating commonsenseqa :  44%|████▍     | 111/250 [1:4250 [3:04:05<1:20:55, 48.56s/it]Evaluating commonsenseqa :  60%|██████    | 151/250 [3:05:22<1:34:18, 57.16s/it]Evaluating commonsenseqa :  61%|██████    | 152/250 [3:06:40<1:43:17, 63.24s/it]Evaluating commonsenseqa :  61%|██████    | 153/250 [3:07:18<1:30:18, 55.86s/it]Evaluating commonsenseqa :  62%|██████▏   | 154/250 [3:08:35<1:39:32, 62.21s/it]Evaluating commonsenseqa :  62%|██████▏   | 155/250 [3:09:53<1:45:44, 66.79s/it]                                                                             Evaluating commonsenseqa :  62%|██████▏   | 156/250 [3:11:09<1:49:07, 69.65s/it]Evaluating commonsenseqa :  63%|██████▎   | 157/250 [3:12:24<1:50:18, 71.16s/it]Evaluating commonsenseqa :  63%|██████▎   | 158/250 [3:13:42<1:52:12, 73.18s/it]                                                                               Evaluating commonsenseqa :  64%|██████▎   | 159/250 [3:14:49<1:48:19, 71.42s/it]Evaluating commonsenseqa :  64%|██████▍   | 160/250 [3:15:39<1:37:42, 65.14s/it]                                                                                   Evaluating commonsenseqa :  64%|██████▍   | 161/250 [3:16:57<1:42:15, 68.94s/it]Evaluating commonsenseqa :  65%|██████▍   | 162/250 [3:18:14<1:44:24, 71.19s/it]Evaluating commonsenseqa :  65%|██████▌   | 163/250 [3:19:31<1:45:51, 73.00s/it]                                                                               Evaluating commonsenseqa :  66%|██████▌   | 164/250 [3:20:48<1:46:23, 74.22s/it]Evaluating commonsenseqa :  66%|██████▌   | 165/250 [3:22:05<1:46:07, 74.91s/it]Evaluating commonsenseqa :  66%|██████▋   | 166/250 [3:23:22<1:46:09, 75.83s/it]                                                                                       Evaluating commonsenseqa :  67%|██████▋   | 167/250 [3:24:41<1:45:59, 76.62s/it]Evaluating commonsenseqa :  67%|██████▋   | 168/250 [3:25:56<1:44:12, 76.25s/it]                                                                                         Evaluating commonsenseqa :  68%|██████▊   | 169/250 [3:26:57<1:36:36, 71.56s/it]Evaluating commonsenseqa :  68%|██████▊   | 170/250 [3:28:12<1:36:51, 72.64s/it]Evaluating commonsenseqa :  68%|██████▊   | 171/250 [3:29:30<1:37:38, 74.16s/it]Evaluating commonsenseqa :  69%|██████▉   | 172/250 [3:30:46<1:37:20, 74.88s/it]                                                                                       Evaluating commonsenseqa :  69%|██████▉   | 173/250 [3:32:04<1:37:00, 75.59s/it]Evaluating commonsenseqa :  70%|██████▉   | 174/250 [3:33:21<1:36:27, 76.15s/it]Evaluating commonsenseqa :  70%|███████   | 175/250 [3:34:39<1:35:42, 76.57s/it]                                                                                       Evaluating commonsenseqa :  70%|███████   | 176/250 [3:35:57<1:35:02, 77.06s/it]Evaluating commonsenseqa :  71%|███████   | 177/250 [3:37:02<1:29:27, 73.52s/it]                                                                                         Evaluating commonsenseqa :  71%|███████   | 178/250 [3:38:17<1:28:49, 74.02s/it]Evaluating commonsenseqa :  72%|███████▏  | 179/250 [3:39:35<1:28:51, 75.09s/it]Evaluating commonsenseqa :  72%|███████▏  | 180/250 [3:40:34<1:22:06, 70.38s/it]                                                                                   Evaluating commonsenseqa :  72%|███████▏  | 181/250 [3:41:52<1:23:22, 72.50s/it]Evaluating commonsenseqa :  73%|███████▎  | 182/250 [3:43:08<1:23:29, 73.68s/it]Evaluating commonsenseqa :  73%|███████▎  | 183/250 [3:44:24<1:23:02, 74.37s/it]                                                                                     Evaluating commonsenseqa :  74%|███████▎  | 184/250 [3:45:42<1:22:48, 75.29s/it]Evaluating commonsenseqa :  74%|███████▍  | 185/250 [3:46:58<1:22:05, 75.78s/it]Evaluating commonsenseqa :  74%|███████▍  | 186/250 [3:48:15<1:20:56, 75.89s/it]                                                                                         Evaluating commonsenseqa :  75%|███████▍  | 187/250 [3:48:55<1:08:34, 65.31s/it]Evaluating commonsenseqa :  75%|███████▌  | 188/250 [3:50:11<1:10:38, 68.36s/it]Evaluating commonsenseqa :  76%|███████▌  | 189/250 [3:51:29<1:12:35, 71.41s/it]Evaluating commonsenseqa :  76%|███████▌  | 190/250 [3:52:45<1:12:42, 72.71s/it]Evaluating commonsenseqa :  76%|███████▋  | 191/250 [3:54:02<1:12:52, 74.10s/it]                                                                                       Evaluating commonsenseqa :  77%|███████▋  | 192/250 [3:55:18<1:12:01, 74.51s/it]Evaluating commonsenseqa :  77%|███████▋  | 193/250 [3:56:31<1:10:30, 74.22s/it]                                                                                           Evaluating commonsenseqa :  78%|███████▊  | 194/250 [3:57:50<1:10:27, 75.50s/it]                                                                                             Evaluating commonsenseqa :  78%|███████▊  | 195/250 [3:59:06<1:09:30, 75.83s/it]Evaluating commonsenseqa :  78%|███████▊  | 196/250 [4:00:23<1:08:30, 76.12s/it]                                                                                           Evaluating commonsenseqa :  79%|███████▉  | 197/250 [4:01:39<1:07:13, 76.10s/it]Evaluating commonsenseqa :  79%|███████▉  | 198/250 [4:02:57<1:06:27, 76.68s/it]                                                                                           Evaluating commonsenseqa :  80%|███████▉  | 199/250 [4:04:14<1:05:10, 76.67s/it]Evaluating commonsenseqa :  80%|████████  | 200/250 [4:05:24<1:02:20, 74.80s/it]Evaluating commonsenseqa :  80%|████████  | 201/250 [4:06:40<1:01:20, 75.11s/it]Evaluating commonsenseqa :  81%|████████  | 202/250 [4:07:56<1:00:13, 75.28s/it]                                                                                             Evaluating commonsenseqa :  81%|████████  | 203/250 [4:09:13<59:24, 75.83s/it]  Evaluating commonsenseqa :  82%|████████▏ | 204/250 [4:10:31<58:31, 76.34s/it]                                                                                                 Evaluating commonsenseqa :  82%|████████▏ | 205/250 [4:11:47<57:20, 76.46s/it]Evaluating commonsenseqa :  82%|████████▏ | 206/250 [4:13:04<56:03, 76.43s/it]Evaluating commonsenseqa :  83%|████████▎ | 207/250 [4:14:19<54:36, 76.21s/it]                                                                                             Evaluating commonsenseqa :  83%|████████▎ | 208/250 [4:15:36<53:28, 76.40s/it]                                                                                             Evaluating commonsenseqa :  84%|████████▎ | 209/250 [4:16:45<50:42, 74.22s/it]Evaluating commonsenseqa :  84%|████████▍ | 210/250 [4:18:02<50:02, 75.06s/it]Evaluating commonsenseqa :  84%|████████▍ | 211/250 [4:19:20<49:13, 75.72s/it]                                                                                         Evaluating commonsenseqa :  85%|████████▍ | 212/250 [4:20:35<47:48, 75.47s/it]Evaluating commonsenseqa :  85%|████████▌ | 213/250 [4:21:51<46:43, 75.77s/it]                                                                                           Evaluating commonsenseqa :  86%|████████▌ | 214/250 [4:23:08<45:45, 76.27s/it]                                                                                             Evaluating commonsenseqa :  86%|████████▌ | 215/250 [4:24:26<44:43, 76.67s/it]Evaluating commonsenseqa :  86%|████████▋ | 216/250 [4:25:42<43:20, 76.47s/it]                                                                                           Evaluating commonsenseqa :  87%|████████▋ | 217/250 [4:26:58<41:55, 76.23s/it]Evaluating commonsenseqa :  87%|████████▋ | 218/250 [4:27:45<36:02, 67.59s/it]                                                                                               Evaluating commonsenseqa :  88%|████████▊ | 219/250 [4:29:02<36:25, 70.51s/it]Evaluating commonsenseqa :  88%|████████▊ | 220/250 [4:30:20<36:17, 72.59s/it]Evaluating commonsenseqa :  88%|████████▊ | 221/250 [4:31:36<35:39, 73.78s/it]Evaluating commonsenseqa :  89%|████████▉ | 222/250 [4:32:53<34:48, 74.61s/it]                                                                                                 Evaluating commonsenseqa :  89%|████████▉ | 223/250 [4:34:07<33:30, 74.46s/it]Evaluating commonsenseqa :  90%|████████▉ | 224/250 [4:35:24<32:33, 75.13s/it]Evaluating commonsenseqa :  90%|█████████ | 225/250 [4:36:41<31:37, 75.89s/it]                                                                                                 Evaluating commonsenseqa :  90%|█████████ | 226/250 [4:37:57<30:15, 75.64s/it]Evaluating commonsenseqa :  91%|█████████ | 227/250 [4:39:14<29:11, 76.17s/it]Evaluating commonsenseqa :  91%|█████████ | 228/250 [4:40:32<28:07, 76.69s/it]                                                                                                 Evaluating commonsenseqa :  92%|█████████▏| 229/250 [4:41:10<22:50, 65.24s/it]Evaluating commonsenseqa :  92%|█████████▏| 230/250 [4:41:44<18:34, 55.73s/it]Evaluating commonsenseqa :  92%|█████████▏| 231/250 [4:43:00<19:37, 61.97s/it]Evaluating commonsenseqa :  93%|█████████▎| 232/250 [4:43:16<14:26, 48.12s/it]Evaluating commonsenseqa :  93%|█████████▎| 233/250 [4:44:26<15:30, 54.75s/it]                                                                                               Evaluating commonsenseqa :  94%|█████████▎| 234/250 [4:45:44<16:26, 61.65s/it]Evaluating commonsenseqa :  94%|█████████▍| 235/250 [4:47:02<16:38, 66.60s/it]Evaluating commonsenseqa :  94%|█████████▍| 236/250 [4:48:20<16:17, 69.83s/it]                                                                                           Evaluating commonsenseqa :  95%|█████████▍| 237/250 [4:49:37<15:37, 72.14s/it]Evaluating commonsenseqa :  95%|█████████▌| 238/250 [4:50:54<14:42, 73.50s/it]                                                                                                 Evaluating commonsenseqa :  96%|█████████▌| 239/250 [4:52:12<13:44, 74.92s/it]Evaluating commonsenseqa :  96%|█████████▌| 240/250 [4:53:28<12:30, 75.10s/it]                                                                                                   Evaluating commonsenseqa :  96%|█████████▋| 241/250 [4:54:43<11:17, 75.28s/it]Evaluating commonsenseqa :  97%|█████████▋| 242/250 [4:55:59<10:04, 75.53s/it]Evaluating commonsenseqa :  97%|█████████▋| 243/250 [4:57:16<08:49, 75.71s/it]                                                                                                   Evaluating commonsenseqa :  98%|█████████▊| 244/250 [4:58:32<07:35, 75.95s/it]Evaluating commonsenseqa :  98%|█████████▊| 245/250 [4:59:50<06:22, 76.44s/it]Evaluating commonsenseqa :  96%|█████████▌| 240/250 [3:38:09<09:22, 56.30s/it]Evaluating commonsenseqa :  96%|█████████▋| 241/250 [3:38:45<07:31, 50.14s/it]Evaluating commonsenseqa :  97%|█████████▋| 242/250 [3:39:41<06:56, 52.05s/it]Evaluating commonsenseqa :  97%|█████████▋| 243/250 [3:40:38<06:14, 53.46s/it]Evaluating commonsenseqa :  98%|█████████▊| 244/250 [3:41:34<05:25, 54.24s/it]Evaluating commonsenseqa :  98%|█████████▊| 245/250 [3:42:30<04:33, 54.78s/it]Evaluating commonsenseqa :  98%|█████████▊| 246/250 [3:43:02<03:12, 48.04s/it]Evaluating commonsenseqa :  99%|█████████▉| 247/250 [3:43:59<02:31, 50.62s/it] 1 --nnodes 1 --master_addr gpu03 --master_port 17129 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o4-tgsm8k-s10-rTrue --seed 10 --max-prompt-length 4096 --rationales --num-out-domain 4 1 2 3 4 5 True 4096 4
[2023-09-04 04:19:55,116] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o4-tgsm8k-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 4
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o4-tgsm8k-s10-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 916008.23it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:12<00:12, 12.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  7.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  8.46s/it]
 > number of parameters: 6738415616
[2023-09-04 04:20:13,555] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-04 04:20:13,779] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-04 04:20:13,780] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f3d490>
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-04 04:20:13,781] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-04 04:20:13,782] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-04 04:20:13,782] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/250 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: For the nuts Adam paid 3 * $12 = $<<3*12=36>>36.
And for dried fruits Adam paid 2.5 * $8 = $<<2.5*8=20>>20.
So in total for his purchases Adam paid $36 + $20 = $<<36+20=56>>56.
So the final answer is 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: He spends 60/3=<<60/3=20>>20 minutes warming up
So he spends 60+20=<<60+20=80>>80 minutes at the gym per day
That means he spends 80*3=<<80*3=240>>240 minutes at the gym
So he spends 240/60=<<240/60=4>>4 hours at the gym a week
So the final answer is 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: The cost to fill a tank went up 200*.2=$<<200*.2=40>>40
So it cost 200+40=$<<200+40=240>>240 to fill the tank
That means he now pays 240*2=$<<240*2=480>>480
So the final answer is 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: If the total number of goals scored in the league that season against Barca is 300, the two players scored 20/100*300=<<300*20/100=60>>60 goals.
If the players scored an equal number of goals, each scored 60/2=<<60/2=30>>30 goals.
So the final answer is 30

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o4-tgsm8k-s10-rTrue-m4096
Evaluating commonsenseqa :   0%|          | 1/250 [01:14<5:09:48, 74.65s/it]                      Evaluating commonsenseqa :   1%|          | 2/250 [02:29<5:09:14, 74.82s/it]                      Evaluating commonsenseqa :   1%|          | 3/250 [03:42<5:03:39, 73.76s/it]6:44<00:00, 53.64s/it]Evaluating commonsenseqa : 100%|██████████| 250/250 [3:46:44<00:00, 54.42s/it]
name: commonsenseqa | avg. gen lenth: 348.977 | time: 13605.902559280396s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr gpu04 --master_port 12094 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o9-tgsm8k-s10-rTrue --seed 10 --max-prompt-length 4096 --rationales --num-out-domain 9 6 7 8 9 10 True 4096 4
[2023-09-04 04:23:26,700] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o9-tgsm8k-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 9
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o9-tgsm8k-s10-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 525218.09it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.30s/it]
 > number of parameters: 6738415616
[2023-09-04 04:23:36,736] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-04 04:23:36,949] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-04 04:23:36,950] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f3d460>
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-04 04:23:36,951] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-04 04:23:36,952] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-04 04:23:36,952] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/250 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: For the nuts Adam paid 3 * $12 = $<<3*12=36>>36.
And for dried fruits Adam paid 2.5 * $8 = $<<2.5*8=20>>20.
So in total for his purchases Adam paid $36 + $20 = $<<36+20=56>>56.
So the final answer is 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: He spends 60/3=<<60/3=20>>20 minutes warming up
So he spends 60+20=<<60+20=80>>80 minutes at the gym per day
That means he spends 80*3=<<80*3=240>>240 minutes at the gym
So he spends 240/60=<<240/60=4>>4 hours at the gym a week
So the final answer is 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: The cost to fill a tank went up 200*.2=$<<200*.2=40>>40
So it cost 200+40=$<<200+40=240>>240 to fill the tank
That means he now pays 240*2=$<<240*2=480>>480
So the final answer is 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: If the total number of goals scored in the league that season against Barca is 300, the two players scored 20/100*300=<<300*20/100=60>>60 goals.
If the players scored an equal number of goals, each scored 60/2=<<60/2=30>>30 goals.
So the final answer is 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: He drinks 12 * 5 = <<12*5=60>>60 ounces of soda a day
So he drinks 60 + 64 = <<60+64=124>>124 ounces of liquid a day
So in total he drinks 124 * 7 = <<124*7=868>>868 ounces of liquid a week
So the final answer is 868

Input: Stella and Twinkle are filling up a truck with a capacity of 6000 stone blocks at the rate of 250 blocks per hour per person. They work for four hours and are then joined by 6 other people who also work at the same rate. How many hours did filling the truck take?
Output: Stella and Twinkle filled up the truck at the rate of 250 blocks per hour per person, a total of 2*250 = <<250*2=500>>500 blocks per hour for both.
After working for four hours, Stella and Twinkle had filled 4*500 = <<4*500=2000>>2000 blocks into the truck.
The number of blocks they had to put into the truck for it to be full is 6000-2000 = <<6000-2000=4000>>4000
When 6 more people joined Stella and Twinkle, a total of 2+6 = <<2+6=8>>8 people were filling the truck now.
Working at the rate of 250 blocks per person, the eight people filled the truck with 250*8 = <<250*8=2000>>2000 blocks in one hour.
If there were 4000 blocks that still needed to be put into the truck, the 8 people took 4000/2000 = <<4000/2000=2>>2 hours to fill the truck with the blocks.
The total time it took to fill up the tank is 4+2 = <<4+2=6>>6 hours.
So the final answer is 6

Input: Elijah drank 8.5 pints of coffee yesterday. Emilio drank 9.5 pints of water yesterday. How many cups of liquid did the two boys drink yesterday?
Output: Total drunk: 8.5 + 9.5 = <<8.5+9.5=18>>18 pints
18 pints * 2 = <<18*2=36>>36 cups
The two boys drank a total of 36 cups of liquid yesterday.
So the final answer is 36

Input: Doris works at the Widget Factory in the packing department. She puts 3 widgets in each carton, which are 4 inches wide, 4 inches long, and 5 inches tall. She then packs those cartons into a shipping box before sending it to the loading bay. The shipping boxes are 20 inches wide, 20 inches long, and 20 inches high. How many widgets get shipped in each shipping box?
Output: Each carton has an area of 4*4*5 = <<4*4*5=80>>80 square inches.
Each shipping box has an area of 20*20*20 = <<20*20*20=8000>>8000 square inches
The total number of cartons that will fit into each box is 8000/80 = <<8000/80=100>>100
Since there are 3 widgets in each carton, the total number of cartons in each box will be 3*100 = <<3*100=300>>300
So the final answer is 300

Input: Queenie earns $150 a day as a part-time clerk. She earns an additional $5 per hour as overtime pay. How much will Queenie receive for working 5 days with 4 hours overtime?
Output: Queenie will earn $150 x 5 = $<<150*5=750>>750 for working 5 days.
She will receive an additional $5 x 4 = $<<5*4=20>>20 for overtime pay.
Hence, Queenie will receive a total of $750 + $20 = $<<750+20=770>>770.
So the final answer is 770

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o9-tgsm8k-s10-rTrue-m4096
Evaluating commonsenseqa :   0%|          | 1/250 [00:54<3:47:27, 54.81s/it]Evaluating commonsenseqa :   1%|          | 2/250 [01:49<3:46:42, 54.85s/it]Evaluating commonsenseqa :   1%|          | 3/250 [02:43<3:43:14, 54.23s/it]Evaluating commonsenseqa :   2%|▏         | 4/250 [03:37<3:42:18, 54.22s/it]Evaluating commonsenseqa :   2%|▏         | 5/250 [04:31<3:41:47, 54.32s/it]Evaluating commonsenseqa :   2%|▏         | 6/250 [05:26<3:40:38, 54.26s/it]Evaluating commonsenseqa :   3%|▎         | 7/250 [06:21<3:41:08, 54.60s/it]Evaluating commonsenseqa :   3%|▎         | 8/250 [07:16<3:40:25, 54.65s/it]Evaluating commonsenseqa :   4%|▎         | 9/250 [08:10<3:39:17, 54.60s/it] Evaluating commonsenseqa :   4%|▍         | 10/250 [09:05<3:39:12, 54.80s/it]Evaluating commonsenseqa :   4%|▍         | 11/250 [10:00<3:37:53, 54.70s/it]Evaluating commonsenseqa :   5%|▍         | 12/250 [10:54<3:36:19, 54.54s/it]Evaluating commonsenseqa :   5%|▌         | 13/250 [11:48<3:34:35, 54.33s/it]Evaluating commonsenseqa :   6%|▌         | 14/250 [12:43<3:34:44, 54.59s/it]Evaluating commonsenseqa :   6%|▌         | 15/250 [13:38<3:34:06, 54.66s/it]Evaluating commonsenseqa :   6%|▋         | 16/250 [14:32<3:32:15, 54.43s/it]Evaluating commonsenseqa :   7%|▋         | 17/250 [15:26<3:31:03, 54.35s/it]Evaluating commonsenseqa :   7%|▋         | 18/250 [16:20<3:30:08, 54.35s/it]Evaluating commonsenseqa :   8%|▊         | 19/250 [17:16<3:30:27, 54.67s/it]Evaluating commonsenseqa :   8%|▊         | 20/250 [18:11<3:30:02, 54.79s/it]Evaluating commonsenseqa :   8%|▊         | 21/250 [19:06<3:29:18, 54.84s/it]Evaluating commonsenseqa :   9%|▉         | 22/250 [20:01<3:28:37, 54.90s/it]Evaluating commonsenseqa :   9%|▉         | 23/250 [20:54<3:26:07, 54.48s/it]Evaluating commonsenseqa :  10%|▉         | 24/250 [21:49<3:25:15, 54.49s/it]Evaluating commonsenseqa :  10%|█         | 25/250 [22:42<3:23:30, 54.27s/it]Evaluating commonsenseqa :  10%|█         | 26/250 [23:37<3:22:52, 54.34s/it]Evaluating commonsenseqa :  11%|█         | 27/250 [24:31<3:21:08, 54.12s/it]Evaluating commonsenseqa :  11%|█         | 28/250 [25:25<3:20:31, 54.20s/it]Evaluating commonsenseqa :  12%|█▏        | 29/250 [26:19<3:19:51, 54.26s/it]Evaluating commonsenseqa :  12%|█▏        | 30/250 [27:14<3:19:23, 54.38s/it]Evaluating commonsenseqa :  11%|█         | 27/250 [31:51<4:27:04, 71.86s/it]  Evaluating commonsenseqa :  11%|█         | 28/250 [33:03<4:25:28, 71.75s/it]  Evaluating commonsenseqa :  12%|█▏        | 29/250 [34:16<4:25:59, 72.21s/it]                                                                                  Evaluating commonsenseqa :  12%|█▏        | 30/250 [35:30<4:26:28, 72.67s/it]Evaluating commonsenseqa :  12%|█▏        | 31/250 [36:41<4:24:21, 72.43s/it]Evaluating commonsenseqa :  13%|█▎        | 32/250 [37:54<4:23:50, 72.62s/it]                                                                                  Evaluating commonsenseqa :  13%|█▎        | 33/250 [39:08<4:23:51, 72.96s/it]Evaluating commonsenseqa :  14%|█▎        | 34/250 [40:19<4:20:41, 72.41s/it]Evaluating commonsenseqa :  14%|█▍        | 35/250 [41:31<4:18:37, 72.18s/it]                                                                                  Evaluating commonsenseqa :  14%|█▍        | 36/250 [42:43<4:17:25, 72.17s/it]Evaluating commonsenseqa :  15%|█▍        | 37/250 [43:58<4:19:07, 72.99s/it]Evaluating commonsenseqa :  15%|█▌        | 38/250 [45:09<4:15:46, 72.39s/it]                                                                                  Evaluating commonsenseqa :  16%|█▌        | 39/250 [46:23<4:16:21, 72.90s/it]Evaluating commonsenseqa :  16%|█▌        | 40/250 [47:34<4:13:17, 72.37s/it]Evaluating commonsenseqa :  16%|█▋        | 41/250 [48:47<4:12:36, 72.52s/it]                                                                                  Evaluating commonsenseqa :  17%|█▋        | 42/250 [50:00<4:11:26, 72.53s/it]Evaluating commonsenseqa :  17%|█▋        | 43/250 [51:12<4:09:29, 72.32s/it]Evaluating commonsenseqa :  18%|█▊        | 44/250 [51:27<3:10:03, 55.36s/it]Evaluating commonsenseqa :  18%|█▊        | 45/250 [52:40<3:26:38, 60.48s/it]  Evaluating commonsenseqa :  18%|█▊        | 46/250 [53:51<3:37:03, 63.84s/it]                                                                                      Evaluating commonsenseqa :  19%|█▉        | 47/250 [54:59<3:39:44, 64.95s/it]Evaluating commonsenseqa :  19%|█▉        | 48/250 [56:10<3:44:56, 66.81s/it]    Evaluating commonsenseqa :  20%|█▉        | 49/250 [57:23<3:49:46, 68.59s/it]  Evaluating commonsenseqa :  20%|██        | 50/250 [58:37<3:54:30, 70.35s/it]  Evaluating commonsenseqa :  20%|██        | 51/250 [59:43<3:49:02, 69.06s/it]                                                                                      Evaluating commonsenseqa :  21%|██        | 52/250 [1:00:53<3:48:26, 69.22s/it]Evaluating commonsenseqa :  21%|██        | 53/250 [1:02:07<3:52:09, 70.71s/it]Evaluating commonsenseqa :  22%|██▏       | 54/250 [1:03:19<3:52:19, 71.12s/it]                                                                                  Evaluating commonsenseqa :  22%|██▏       | 55/250 [1:04:33<3:53:28, 71.84s/it]Evaluating commonsenseqa :  22%|██▏       | 56/250 [1:05:45<3:53:01, 72.07s/it]Evaluating commonsenseqa :  23%|██▎       | 57/250 [1:06:58<3:52:07, 72.16s/it]                                                                                      Evaluating commonsenseqa :  23%|██▎       | 58/250 [1:08:12<3:52:49, 72.76s/it]Evaluating commonsenseqa :  24%|██▎       | 59/250 [1:09:24<3:51:27, 72.71s/it]Evaluating commonsenseqa :  24%|██▍       | 60/250 [1:10:37<3:50:20, 72.74s/it]                                                                                      Evaluating commonsenseqa :  24%|██▍       | 61/250 [1:11:49<3:48:17, 72.48s/it]                                                                                      Evaluating commonsenseqa :  25%|██▍       | 62/250 [1:13:01<3:46:50, 72.40s/it]Evaluating commonsenseqa :  25%|██▌       | 63/250 [1:14:14<3:45:29, 72.35s/it]Evaluating commonsenseqa :  26%|██▌       | 64/250 [1:15:26<3:44:21, 72.37s/it]t]Evaluating commonsenseqa :  32%|███▏      | 80/250 [1:12:26<2:32:54, 53.97s/it]Evaluating commonsenseqa :  32%|███▏      | 81/250 [1:13:21<2:32:59, 54.32s/it]Evaluating commonsenseqa :  33%|███▎      | 82/250 [1:14:16<2:32:12, 54.36s/it]Evaluating commonsenseqa :  33%|███▎      | 83/250 [1:15:09<2:30:50, 54.20s/it]Evaluating commonsenseqa :  34%|███▎      | 84/250 [1:16:05<2:31:04, 54.61s/it]Evaluating commonsenseqa :  34%|███▍      | 85/250 [1:17:00<2:30:29, 54.73s/it]Evaluating commonsenseqa :  34%|███▍      | 86/250 [1:17:54<2:28:35, 54.37s/it]Evaluating commonsenseqa :  35%|███▍      | 87/250 [1:18:48<2:27:24, 54.26s/it]Evaluating commonsenseqa :  35%|███▌      | 88/250 [1:19:42<2:26:33, 54.28s/it]Evaluating commonsenseqa :  36%|███▌      | 89/250 [1:20:36<2:25:41, 54.30s/it]Evaluating commonsenseqa :  36%|███▌      | 90/250 [1:21:30<2:24:24, 54.16s/it]Evaluating commonsenseqa :  36%|███▋      | 91/250 [1:22:24<2:22:59, 53.96s/it]Evaluating commonsenseqa :  37%|███▋      | 92/250 [1:23:19<2:22:54, 54.27s/it]Evaluating commonsenseqa :  37%|███▋      | 93/250 [1:24:13<2:21:55, 54.24s/it]Evaluating commonsenseqa :  38%|███▊      | 94/250 [1:25:07<2:21:09, 54.29s/it]Evaluating commonsenseqa :  38%|███▊      | 95/250 [1:26:01<2:20:02, 54.21s/it]Evaluating commonsenseqa :  38%|███▊      | 96/250 [1:26:55<2:19:10, 54.22s/it]Evaluating commonsenseqa :  39%|███▉      | 97/250 [1:27:51<2:19:00, 54.52s/it]Evaluating commonsenseqa :  39%|███▉      | 98/250 [1:28:45<2:17:40, 54.35s/it]Evaluating commonsenseqa :  40%|███▉      | 99/250 [1:29:39<2:16:28, 54.23s/it]                                                                                        Evaluating commonsenseqa :  40%|████      | 100/250 [1:30:32<2:15:11, 54.08s/it]Evaluating commonsenseqa :  40%|████      | 101/250 [1:31:27<2:14:52, 54.31s/it]Evaluating commonsenseqa :  41%|████      | 102/250 [1:32:21<2:13:32, 54.14s/it]Evaluating commonsenseqa :  41%|████      | 103/250 [1:33:16<2:13:17, 54.41s/it]Evaluating commonsenseqa :  42%|████▏     | 104/250 [1:34:11<2:12:48, 54.58s/it]Evaluating commonsenseqa :  42%|████▏     | 105/250 [1:35:05<2:11:32, 54.43s/it]Evaluating commonsenseqa :  42%|████▏     | 106/250 [1:35:59<2:10:37, 54.43s/it]Evaluating commonsenseqa :  43%|████▎     | 107/250 [1:36:53<2:09:24, 54.29s/it]Evaluating commonsenseqa :  43%|████▎     | 108/250 [1:37:47<2:08:08, 54.15s/it]Evaluating commonsenseqa :  44%|████▎     | 109/250 [1:38:41<2:06:52, 53.99s/it]Evaluating commonsenseqa :  44%|████▍     | 110/250 [1:39:36<2:06:53, 54.38s/it]Evaluating commonsenseqa :  44%|████▍     | 111/250 [1:40:30<2:05:57, 54.37s/it]Evaluating commonsenseqa :  45%|████▍     | 112/250 [1:41:16<1:58:43, 51.62s/it]Evaluating commonsenseqa :  45%|████▌     | 113/250 [1:42:10<1:59:35, 52.37s/it]Evaluating commonsenseqa :  46%|████▌     | 114/250 [1:43:05<2:00:41, 53.24s/it]Evaluating commonsenseqa :  46%|████▌     | 115/250 [1:43:59<2:00:21, 53.49s/it]Evaluating commonsenseqa :  46%|████▋     | 116/250 [1:44:54<2:00:18, 53.87s/it]Evaluating commonsenseqa :  47%|████▋     | 117/250 [1:45:48<1:59:24, 53.87s/it]Evaluating commonsenseqa :  47%|████▋     | 118/250 [1:46:41<1:58:26, 53.84s/it]Evaluating commonsenseqa :  48%|████▊     | 119/250 [1:47:35<1:57:17, 53.72s/it]Evaluating commonsenseqa :  48%|████▊     | 120/250 [1:48:29<1:56:29, 53.77s/it]Evaluating commonsenseqa :  48%|████▊     | 121/250 [1:49:23<1:56:03, 53.98s/it]Evaluating commonsenseqa :  49%|████▉     | 122/250 [1:50:17<1:55:07, 53.96s/it]Evaluating commonsenseqa :  49%|████▉     | 123/250 [1:50:56<1:44:50, 49.53s/it]Evaluating commonsenseqa :  40%|███▉      | 99/250 [1:55:57<3:01:07, 71.97s/it]   Evaluating commonsenseqa :  40%|████      | 100/250 [1:57:09<3:00:29, 72.19s/it]                                                                                             Evaluating commonsenseqa :  40%|████      | 101/250 [1:58:21<2:59:07, 72.13s/it]  Evaluating commonsenseqa :  41%|████      | 102/250 [1:59:34<2:58:21, 72.30s/it]                                                                                                                                                                                            Evaluating commonsenseqa :  41%|████      | 103/250 [2:00:46<2:57:13, 72.33s/it]Evaluating commonsenseqa :  42%|████▏     | 104/250 [2:02:00<2:56:52, 72.69s/it]      Evaluating commonsenseqa :  42%|████▏     | 105/250 [2:03:12<2:55:14, 72.51s/it]                                                                                               Evaluating commonsenseqa :  42%|████▏     | 106/250 [2:04:24<2:53:51, 72.44s/it]Evaluating commonsenseqa :  43%|████▎     | 107/250 [2:04:52<2:20:23, 58.90s/it]Evaluating commonsenseqa :  43%|████▎     | 108/250 [2:05:16<1:55:08, 48.65s/it]Evaluating commonsenseqa :  44%|████▎     | 109/250 [2:06:04<1:53:55, 48.48s/it]Evaluating commonsenseqa :  44%|████▍     | 110/250 [2:07:18<2:10:53, 56.10s/it]      Evaluating commonsenseqa :  44%|████▍     | 111/250 [2:08:31<2:21:45, 61.19s/it]  Evaluating commonsenseqa :  45%|████▍     | 112/250 [2:09:07<2:03:22, 53.64s/it]  Evaluating commonsenseqa :  45%|████▌     | 113/250 [2:10:21<2:16:17, 59.69s/it]  Evaluating commonsenseqa :  46%|████▌     | 114/250 [2:11:33<2:23:48, 63.45s/it]  Evaluating commonsenseqa :  46%|████▌     | 115/250 [2:12:25<2:14:58, 59.99s/it]                                                                                               Evaluating commonsenseqa :  46%|████▋     | 116/250 [2:13:39<2:23:25, 64.22s/it]  Evaluating commonsenseqa :  47%|████▋     | 117/250 [2:14:54<2:28:54, 67.17s/it]                                                                                               Evaluating commonsenseqa :  47%|████▋     | 118/250 [2:16:06<2:31:08, 68.70s/it]  Evaluating commonsenseqa :  48%|████▊     | 119/250 [2:17:18<2:32:34, 69.89s/it]  Evaluating commonsenseqa :  48%|████▊     | 120/250 [2:18:30<2:32:30, 70.39s/it]                                                                                               Evaluating commonsenseqa :  48%|████▊     | 121/250 [2:19:42<2:32:39, 71.00s/it]  Evaluating commonsenseqa :  49%|████▉     | 122/250 [2:20:55<2:32:41, 71.57s/it]  Evaluating commonsenseqa :  49%|████▉     | 123/250 [2:22:08<2:32:26, 72.02s/it]                                                                                                   Evaluating commonsenseqa :  50%|████▉     | 124/250 [2:23:22<2:32:25, 72.58s/it]    Evaluating commonsenseqa :  50%|█████     | 125/250 [2:24:36<2:32:11, 73.05s/it]    Evaluating commonsenseqa :  50%|█████     | 126/250 [2:25:28<2:17:23, 66.48s/it]                                                                                                   Evaluating commonsenseqa :  51%|█████     | 127/250 [2:26:41<2:20:34, 68.57s/it]Evaluating commonsenseqa :  51%|█████     | 128/250 [2:27:26<2:04:43, 61.34s/it]Evaluating commonsenseqa :  52%|█████▏    | 129/250 [2:28:40<2:11:36, 65.26s/it]Evaluating commonsenseqa :  52%|█████▏    | 130/250 [2:29:55<2:16:20, 68.17s/it]            Evaluating commonsenseqa :  52%|█████▏    | 131/250 [2:30:48<2:06:24, 63.74s/it]  Evaluating commonsenseqa :  53%|█████▎    | 132/250 [2:32:02<2:11:19, 66.78s/it]  Evaluating commonsenseqa :  53%|█████▎    | 133/250 [2:33:17<2:14:58, 69.22s/it]  Evaluating commonsenseqa :  54%|█████▎    | 134/250 [2:34:31<2:16:44, 70.73s/it]  Evaluating commonsenseqa :  54%|█████▍    | 135/250 [2:35:38<2:13:30, 69.65s/it]                                                                                                 Evaluating commonsenseqa :  54%|█████▍    | 136/250 [2:36:53<2:15:07, 71.12s/it]  Evaluating commonsenseqa :  55%|█████▍    | 137/250 [2:38:06<2:15:15, 71.82s/it]  Evaluating commonsenseqa :  55%|█████▌    | 138/250 [2:39:22<2:15:59, 72.85s/it]                                                                                                 Evaluating commonsenseqa :  56%|█████▌    | 139/250 [2:40:36<2:15:19, 73.15s/it]Evaluating commonsenseqa :  56%|█████▌    | 140/250 [2:41:52<2:15:42, 74.03s/it]    Evaluating commonsenseqa :  56%|█████▋    | 141/250 [2:43:05<2:14:08, 73.84s/it]  Evaluating commonsenseqa :  57%|█████▋    | 142/250 [2:44:19<2:12:54, 73.84s/it]  Evaluating commonsenseqa :  57%|█████▋    | 143/250 [2:45:33<2:11:33, 73.78s/it]                                                                                                   Evaluating commonsenseqa :  58%|█████▊    | 144/250 [2:46:47<2:10:37, 73.94s/it]                                                                                                     Evaluating commonsenseqa :  58%|█████▊    | 145/250 [2:48:01<2:09:27, 73.98s/it]Evaluating commonsenseqa :  58%|█████▊    | 146/250 [2:49:13<2:07:30, 73.56s/it]        Evaluating commonsenseqa :  59%|█████▉    | 147/250 [2:50:28<2:06:53, 73.92s/it]    Evaluating commonsenseqa :  59%|█████▉    | 148/250 [2:51:44<2:06:23, 74.35s/it]    Evaluating commonsenseqa :  60%|█████▉    | 149/250 [2:52:59<2:05:29, 74.55s/it]                                                                                                     Evaluating commonsenseqa :  60%|██████    | 150/250 [2:54:11<2:03:16, 73.97s/it]    Evaluating commonsenseqa :  60%|██████    | 151/250 [2:55:26<2:02:22, 74.16s/it]    Evaluating commonsenseqa :  61%|██████    | 152/250 [2:56:39<2:00:28, 73.76s/it]                                                                                                 Evaluating commonsenseqa :  61%|██████    | 153/250 [2:57:05<1:36:07, 59.46s/it]Evaluating commonsenseqa :  62%|██████▏   | 154/250 [2:58:19<1:42:06, 63.81s/it]Evaluating commonsenseqa :  62%|██████▏   | 155/250 [2:59:33<1:46:06, 67.01s/it]Evaluating commonsenseqa :  62%|██████▏   | 156/250 [3:00:48<1:48:28, 69.24s/it]  Evaluating commonsenseqa :  63%|██████▎   | 157/250 [3:02:03<1:50:21, 71.19s/it]Evaluating commonsenseqa :  63%|██████▎   | 158/250 [3:03:18<1:50:39, 72.17s/it]Evaluating commonsenseqa :  64%|██████▎   | 159/250 [3:04:32<1:50:18, 72.73s/it]                                                                                               Evaluating commonsenseqa :  64%|██████▍   | 160/250 [3:05:46<1:49:56, 73.29s/it]Evaluating commonsenseqa :  64%|██████▍   | 161/250 [3:06:27<1:34:04, 63.42s/it]Evaluating commonsenseqa :  65%|██████▍   | 162/250 [3:07:42<1:38:04, 66.86s/it]Evaluating commonsenseqa :  65%|██████▌   | 163/250 [3:08:57<1:40:30, 69.32s/it]Evaluating commonsenseqa :  66%|██████▌   | 164/250 [3:10:10<1:41:01, 70.48s/it]  Evaluating commonsenseqa :  66%|██████▌   | 165/250 [3:11:26<1:42:21, 72.25s/it]  Evaluating commonsenseqa :  66%|██████▋   | 166/250 [3:12:43<1:42:55, 73.51s/it]                                                                                                   Evaluating commonsenseqa :  67%|██████▋   | 167/250 [3:13:29<1:30:10, 65.18s/it]Evaluating commonsenseqa :  67%|██████▋   | 168/250 [3:14:42<1:32:24, 67.62s/it]    Evaluating commonsenseqa :  68%|██████▊   | 169/250 [3:15:55<1:33:30, 69.27s/it]  Evaluating commonsenseqa :  68%|██████▊   | 170/250 [3:16:24<1:16:06, 57.08s/it]  Evaluating commonsenseqa :  68%|██████▊   | 171/250 [3:17:38<1:21:50, 62.16s/it]  Evaluating commonsenseqa :  69%|██████▉   | 172/250 [3:18:52<1:25:42, 65.93s/it]  Evaluating commonsenseqa :  69%|██████▉   | 173/250 [3:19:13<1:07:04, 52.26s/it]  Evaluating commonsenseqa :  70%|██████▉   | 174/250 [3:20:27<1:14:23, 58.74s/it]  Evaluating commonsenseqa :  70%|███████   | 175/250 [3:21:41<1:19:25, 63.54s/it]  Evaluating commonsenseqa :  70%|███████   | 176/250 [3:22:56<1:22:37, 66.99s/it]  Evaluating commonsenseqa :  71%|███████   | 177/250 [3:23:28<1:08:34, 56.36s/it]  Evaluating commonsenseqa :  71%|███████   | 178/250 [3:24:44<1:14:37, 62.19s/it]  Evaluating commonsenseqa :  72%|███████▏  | 179/250 [3:25:59<1:18:09, 66.04s/it]                                                                                                 Evaluating commonsenseqa :  72%|███████▏  | 180/250 [3:27:13<1:20:03, 68.63s/it]Evaluating commonsenseqa :  72%|███████▏  | 181/250 [3:28:29<1:21:25, 70.80s/it]Evaluating commonsenseqa :  73%|███████▎  | 182/250 [3:29:44<1:21:35, 71.99s/it]Evaluating commonsenseqa :  73%|███████▎  | 183/250 [3:30:59<1:21:16, 72.79s/it]Evaluating commonsenseqa :  74%|███████▎  | 184/250 [3:32:13<1:20:30, 73.18s/it]                                                                                                 Evaluating commonsenseqa :  74%|███████▍  | 185/250 [3:33:28<1:19:49, 73.68s/it]Evaluating commonsenseqa :  74%|███████▍  | 186/250 [3:34:43<1:19:05, 74.16s/it]  Evaluating commonsenseqa :  75%|███████▍  | 187/250 [3:35:59<1:18:22, 74.64s/it]                                                                                                     Evaluating commonsenseqa :  75%|███████▌  | 188/250 [3:37:15<1:17:32, 75.03s/it]  Evaluating commonsenseqa :  76%|███████▌  | 189/250 [3:38:17<1:12:31, 71.33s/it]  Evaluating commonsenseqa :  76%|███████▌  | 190/250 [3:39:26<1:10:38, 70.64s/it]  Evaluating commonsenseqa :  76%|███████▋  | 191/250 [3:40:39<1:10:05, 71.28s/it]  Evaluating commonsenseqa :  77%|███████▋  | 192/250 [3:41:19<59:43, 61.78s/it]    Evaluating commonsenseqa :  77%|███████▋  | 193/250 [3:42:34<1:02:27, 65.75s/it]  Evaluating commonsenseqa :  78%|███████▊  | 194/250 [3:43:47<1:03:32, 68.09s/it]                                                                                                     Evaluating commonsenseqa :  78%|███████▊  | 195/250 [3:45:03<1:04:24, 70.27s/it]  Evaluating commonsenseqa :  78%|███████▊  | 196/250 [3:46:16<1:04:08, 71.27s/it]  Evaluating commonsenseqa :  79%|███████▉  | 197/250 [3:47:33<1:04:16, 72.77s/it]                                                                                                     Evaluating commonsenseqa :  79%|███████▉  | 198/250 [3:48:47<1:03:29, 73.26s/it]  Evaluating commonsenseqa :  80%|███████▉  | 199/250 [3:50:00<1:02:16, 73.26s/it]  Evaluating commonsenseqa :  80%|████████  | 200/250 [3:50:40<52:33, 63.07s/it]    Evaluating commonsenseqa :  80%|████████  | 201/250 [3:51:52<53:55, 66.03s/it]    Evaluating commonsenseqa :  81%|████████  | 202/250 [3:53:07<54:46, 68.47s/it]                                                                                                       Evaluating commonsenseqa :  81%|████████  | 203/250 [3:54:19<54:29, 69.57s/it]/it]Evaluating commonsenseqa : 100%|██████████| 250/250 [3:51:01<00:00, 55.45s/it]
name: commonsenseqa | avg. gen lenth: 356.802 | time: 13863.437021493912s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr gpu04 --master_port 12094 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o10-tgsm8k-s10-rTrue --seed 10 --max-prompt-length 4096 --rationales --num-out-domain 10 6 7 8 9 10 True 4096 4
Evaluating commonsenseqa :  82%|████████▏ | 204/250 [3:55:32<54:10, 70.67s/it] to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o10-tgsm8k-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 10
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o10-tgsm8k-s10-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 432740.01it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.09s/it]
 > number of parameters: 6738415616
[2023-09-04 08:15:02,226] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-04 08:15:02,475] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-04 08:15:02,477] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-04 08:15:02,477] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-04 08:15:02,477] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-04 08:15:02,477] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-04 08:15:02,477] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-04 08:15:02,477] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f3f460>
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-04 08:15:02,478] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-04 08:15:02,479] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-04 08:15:02,479] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-04 08:15:02,479] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-04 08:15:02,479] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-04 08:15:02,479] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-04 08:15:02,479] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-04 08:15:02,479] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-04 08:15:02,479] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-04 08:15:02,479] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-04 08:15:02,479] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-04 08:15:02,479] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-04 08:15:02,479] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-04 08:15:02,479] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-04 08:15:02,479] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-04 08:15:02,479] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-04 08:15:02,479] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-04 08:15:02,479] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-04 08:15:02,479] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/250 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: For the nuts Adam paid 3 * $12 = $<<3*12=36>>36.
And for dried fruits Adam paid 2.5 * $8 = $<<2.5*8=20>>20.
So in total for his purchases Adam paid $36 + $20 = $<<36+20=56>>56.
So the final answer is 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: He spends 60/3=<<60/3=20>>20 minutes warming up
So he spends 60+20=<<60+20=80>>80 minutes at the gym per day
That means he spends 80*3=<<80*3=240>>240 minutes at the gym
So he spends 240/60=<<240/60=4>>4 hours at the gym a week
So the final answer is 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: The cost to fill a tank went up 200*.2=$<<200*.2=40>>40
So it cost 200+40=$<<200+40=240>>240 to fill the tank
That means he now pays 240*2=$<<240*2=480>>480
So the final answer is 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: If the total number of goals scored in the league that season against Barca is 300, the two players scored 20/100*300=<<300*20/100=60>>60 goals.
If the players scored an equal number of goals, each scored 60/2=<<60/2=30>>30 goals.
So the final answer is 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: He drinks 12 * 5 = <<12*5=60>>60 ounces of soda a day
So he drinks 60 + 64 = <<60+64=124>>124 ounces of liquid a day
So in total he drinks 124 * 7 = <<124*7=868>>868 ounces of liquid a week
So the final answer is 868

Input: Stella and Twinkle are filling up a truck with a capacity of 6000 stone blocks at the rate of 250 blocks per hour per person. They work for four hours and are then joined by 6 other people who also work at the same rate. How many hours did filling the truck take?
Output: Stella and Twinkle filled up the truck at the rate of 250 blocks per hour per person, a total of 2*250 = <<250*2=500>>500 blocks per hour for both.
After working for four hours, Stella and Twinkle had filled 4*500 = <<4*500=2000>>2000 blocks into the truck.
The number of blocks they had to put into the truck for it to be full is 6000-2000 = <<6000-2000=4000>>4000
When 6 more people joined Stella and Twinkle, a total of 2+6 = <<2+6=8>>8 people were filling the truck now.
Working at the rate of 250 blocks per person, the eight people filled the truck with 250*8 = <<250*8=2000>>2000 blocks in one hour.
If there were 4000 blocks that still needed to be put into the truck, the 8 people took 4000/2000 = <<4000/2000=2>>2 hours to fill the truck with the blocks.
The total time it took to fill up the tank is 4+2 = <<4+2=6>>6 hours.
So the final answer is 6

Input: Elijah drank 8.5 pints of coffee yesterday. Emilio drank 9.5 pints of water yesterday. How many cups of liquid did the two boys drink yesterday?
Output: Total drunk: 8.5 + 9.5 = <<8.5+9.5=18>>18 pints
18 pints * 2 = <<18*2=36>>36 cups
The two boys drank a total of 36 cups of liquid yesterday.
So the final answer is 36

Input: Doris works at the Widget Factory in the packing department. She puts 3 widgets in each carton, which are 4 inches wide, 4 inches long, and 5 inches tall. She then packs those cartons into a shipping box before sending it to the loading bay. The shipping boxes are 20 inches wide, 20 inches long, and 20 inches high. How many widgets get shipped in each shipping box?
Output: Each carton has an area of 4*4*5 = <<4*4*5=80>>80 square inches.
Each shipping box has an area of 20*20*20 = <<20*20*20=8000>>8000 square inches
The total number of cartons that will fit into each box is 8000/80 = <<8000/80=100>>100
Since there are 3 widgets in each carton, the total number of cartons in each box will be 3*100 = <<3*100=300>>300
So the final answer is 300

Input: Queenie earns $150 a day as a part-time clerk. She earns an additional $5 per hour as overtime pay. How much will Queenie receive for working 5 days with 4 hours overtime?
Output: Queenie will earn $150 x 5 = $<<150*5=750>>750 for working 5 days.
She will receive an additional $5 x 4 = $<<5*4=20>>20 for overtime pay.
Hence, Queenie will receive a total of $750 + $20 = $<<750+20=770>>770.
So the final answer is 770

Input: Jodi starts off walking 1 mile a day for 6 days a week.  On the second week, she walks 2 miles a day, 6 days a week.  On the third week, she walks 3 miles a day, 6 days a week. Finally on the fourth week, she walks 4 miles a day, 6 days a week.  How many miles has she walked in 4 weeks?
Output: The first week she walked 1 mile, 6 days a week for a total of 1*6 = <<1*6=6>>6 miles
The second week she walked 2 miles, 6 days a week for a total of 2*6 = <<2*6=12>>12 miles
The third week she walked 3 miles, 6 days a week for a total of 3*6 = <<3*6=18>>18 miles
On the fourth week, she walked 4 miles, 6 days a week for a total of 4*6 = <<4*6=24>>24 miles
Over four weeks she has walked 6+12+18+24 = <<6+12+18+24=60>>60 miles
So the final answer is 60

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o10-tgsm8k-s10-rTrue-m4096
Evaluating commonsenseqa :   0%|          | 1/250 [00:55<3:51:58, 55.90s/it]Evaluating commonsenseqa :   1%|          | 2/250 [01:51<3:49:14, 55.46s/it]Evaluating commonsenseqa :   1%|          | 3/250 [02:46<3:48:26, 55.49s/it]Evaluating commonsenseqa :   2%|▏         | 4/250 [03:42<3:47:42, 55.54s/it]Evaluating commonsenseqa :   2%|▏         | 5/250 [04:37<3:47:03, 55.61s/it]Evaluating commonsenseqa :   2%|▏         | 6/250 [05:33<3:45:27, 55.44s/it]Evaluating commonsenseqa :   3%|▎         | 7/250 [06:27<3:43:43, 55.24s/it]Evaluating commonsenseqa :   3%|▎         | 8/250 [07:23<3:43:08, 55.32s/it]Evaluating commonsenseqa :   4%|▎         | 9/250 [08:19<3:42:38, 55.43s/it]Evaluating commonsenseqa :   4%|▍         | 10/250 [09:14<3:42:17, 55.57s/it]Evaluating commonsenseqa :   4%|▍         | 11/250 [10:09<3:40:42, 55.41s/it]Evaluating commonsenseqa :   5%|▍         | 12/250 [11:06<3:40:47, 55.66s/it]Evaluating commonsenseqa :   5%|▌         | 13/250 [12:01<3:39:10, 55.49s/it]Evaluating commonsenseqa :   6%|▌         | 14/250 [12:57<3:38:41, 55.60s/it]Evaluating commonsenseqa :   6%|▌         | 15/250 [13:53<3:38:21, 55.75s/it]Evaluating commonsenseqa :   6%|▋         | 16/250 [14:48<3:36:33, 55.53s/it]Evaluating commonsenseqa :   7%|▋         | 17/250 [15:43<3:35:37, 55.52s/it]Evaluating commonsenseqa :   7%|▋         | 18/250 [16:40<3:35:37, 55.77s/it]Evaluating commonsenseqa :   8%|▊         | 19/250 [17:35<3:33:50, 55.55s/it]Evaluating commonsenseqa :   8%|▊         | 20/250 [18:30<3:32:21, 55.40s/it]Evaluating commonsenseqa :   8%|▊         | 21/250 [19:26<3:31:57, 55.53s/it]Evaluating commonsenseqa :   9%|▉         | 22/250 [20:17<3:26:09, 54.25s/it]Evaluating commonsenseqa :   9%|▉         | 23/250 [21:12<3:26:47, 54.66s/it]Evaluating commonsenseqa :  10%|▉         | 24/250 [22:08<3:26:50, 54.91s/it]Evaluating commonsenseqa :  10%|█         | 25/250 [23:03<3:26:08, 54.97s/it]Evaluating commonsenseqa :  10%|█         | 26/250 [23:58<3:25:25, 55.03s/it]Evaluating commonsenseqa :  11%|█         | 27/250 [24:54<3:24:55, 55.14s/it]Evaluating commonsenseqa :  11%|█         | 28/250 [25:49<3:24:42, 55.33s/it]Evaluating commonsenseqa :  12%|█▏        | 29/250 [26:44<3:23:31, 55.25s/it]Evaluating commonsenseqa :  12%|█▏        | 30/250 [27:40<3:22:27, 55.22s/it]Evaluating commonsenseqa :  12%|█▏        | 31/250 [28:35<3:21:45, 55.28s/it]Evaluating commonsenseqa :  13%|█▎        | 32/250 [28:58<2:45:59, 45.68s/it]Evaluating commonsenseqa :  13%|█▎        | 33/250 [29:53<2:55:30, 48.53s/it]               Evaluating commonsenseqa :  14%|█▎        | 34/250 [30:48<3:01:35, 50.44s/it]Evaluating commonsenseqa :  14%|█▍        | 35/250 [31:44<3:05:54, 51.88s/it]Evaluating commonsenseqa :  14%|█▍        | 36/250 [32:39<3:08:43, 52.91s/it]Evaluating commonsenseqa :  15%|█▍        | 37/250 [33:34<3:10:41, 53.72s/it]Evaluating commonsenseqa :  15%|█▌        | 38/250 [34:30<3:11:22, 54.16s/it]Evaluating commonsenseqa :  16%|█▌        | 39/250 [35:25<3:11:43, 54.52s/it]Evaluating commonsenseqa :  16%|█▌        | 40/250 [36:20<3:11:34, 54.74s/it]Evaluating commonsenseqa :  16%|█▋        | 41/250 [37:15<3:10:58, 54.82s/it]Evaluating commonsenseqa :  17%|█▋        | 42/250 [38:11<3:10:49, 55.04s/it]Evaluating commonsenseqa :  17%|█▋        | 43/250 [39:07<3:10:47, 55.30s/it]Evaluating commonsenseqa :  18%|█▊        | 44/250 [40:02<3:09:35, 55.22s/it]Evaluating commonsenseqa :  18%|E▊        | 45/250 [40:57<3:08:44, 55.24s/it]Evaluating commonsenseqa :  18%|█▊        | 46/250 [41:52<3:07:02, 55.01s/it]Evaluating commonsenseqa :  19%|█▉        | 47/250 [42:46<3:05:47, 54.92s/it]Evaluating commonsenseqa :  19%|█▉        | 48/250 [43:41<3:04:58, 54.94s/it]Evaluating commonsenseqa :  20%|█▉        | 49/250 [44:36<3:03:54, 54.90s/it]Evaluating commonsenseqa :  20%|██        | 50/250 [45:31<3:03:27, 55.04s/it]Evaluating commonsenseqa :  20%|██        | 51/250 [46:27<3:02:49, 55.12s/it]Evaluating commonsenseqa :  21%|██        | 52/250 [47:22<3:01:53, 55.12s/it]Evaluating commonsenseqa :  21%|██        | 53/250 [48:17<3:01:12, 55.19s/it]                 Evaluating commonsenseqa :  22%|██▏       | 54/250 [49:13<3:00:27, 55.24s/it]Evaluating commonsenseqa :  22%|██▏       | 55/250 [50:08<2:59:46, 55.32s/it]Evaluating commonsenseqa :  22%|██▏       | 56/250 [51:04<2:59:10, 55.42s/it]Evaluating commonsenseqa :  23%|██▎       | 57/250 [51:59<2:58:06, 55.37s/it]               Evaluating commonsenseqa :  23%|██▎       | 58/250 [52:54<2:56:47, 55.25s/it]Evaluating commonsenseqa :  24%|██▎       | 59/250 [53:50<2:56:20, 55.39s/it]Evaluating commonsenseqa :  24%|██▍       | 60/250 [54:45<2:55:21, 55.38s/it]Evaluating commonsenseqa :  24%|██▍       | 61/250 [55:41<2:55:07, 55.60s/it]Evaluating commonsenseqa :  25%|██▍       | 62/250 [56:36<2:53:36, 55.41s/it]Evaluating commonsenseqa :  25%|██▌       | 63/250 [57:32<2:53:26, 55.65s/it]mmonsenseqa | avg. gen lenth: 309.873 | time: 17500.94433236122s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr gpu03 --master_port 17129 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o5-tgsm8k-s10-rTrue --seed 10 --max-prompt-length 4096 --rationales --num-out-domain 5 1 2 3 4 5 True 4096 4
[2023-09-04 09:12:00,661] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o5-tgsm8k-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 5
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o5-tgsm8k-s10-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 819708.19it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:11<00:11, 11.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  6.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  7.63s/it]
 > number of parameters: 6738415616
[2023-09-04 09:12:17,536] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-04 09:12:17,761] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-04 09:12:17,763] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-04 09:12:17,763] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-04 09:12:17,763] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-04 09:12:17,763] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-04 09:12:17,763] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-04 09:12:17,763] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-04 09:12:17,763] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-04 09:12:17,763] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-04 09:12:17,763] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-04 09:12:17,763] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f3f430>
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-04 09:12:17,764] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-04 09:12:17,765] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-04 09:12:17,765] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-04 09:12:17,765] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-04 09:12:17,765] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-04 09:12:17,765] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-04 09:12:17,765] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-04 09:12:17,765] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-04 09:12:17,765] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-04 09:12:17,765] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-04 09:12:17,765] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/250 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: For the nuts Adam paid 3 * $12 = $<<3*12=36>>36.
And for dried fruits Adam paid 2.5 * $8 = $<<2.5*8=20>>20.
So in total for his purchases Adam paid $36 + $20 = $<<36+20=56>>56.
So the final answer is 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: He spends 60/3=<<60/3=20>>20 minutes warming up
So he spends 60+20=<<60+20=80>>80 minutes at the gym per day
That means he spends 80*3=<<80*3=240>>240 minutes at the gym
So he spends 240/60=<<240/60=4>>4 hours at the gym a week
So the final answer is 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: The cost to fill a tank went up 200*.2=$<<200*.2=40>>40
So it cost 200+40=$<<200+40=240>>240 to fill the tank
That means he now pays 240*2=$<<240*2=480>>480
So the final answer is 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: If the total number of goals scored in the league that season against Barca is 300, the two players scored 20/100*300=<<300*20/100=60>>60 goals.
If the players scored an equal number of goals, each scored 60/2=<<60/2=30>>30 goals.
So the final answer is 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: He drinks 12 * 5 = <<12*5=60>>60 ounces of soda a day
So he drinks 60 + 64 = <<60+64=124>>124 ounces of liquid a day
So in total he drinks 124 * 7 = <<124*7=868>>868 ounces of liquid a week
So the final answer is 868

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o5-tgsm8k-s10-rTrue-m4096
Evaluating commonsenseqa :   0%|          | 1/250 [01:12<4:59:08, 72.08s/it]       Evaluating commonsenseqa :   1%|          | 2/250 [02:14<4:33:33, 66.19s/it]       Evaluating commonsenseqa :   1%|          | 3/250 [03:25<4:42:27, 68.61s/it]         Evaluating commonsenseqa :   2%|▏         | 4/250 [04:37<4:46:58, 69.99s/it]                                                                                             Evaluating commonsenseqa :   2%|▏         | 5/250 [05:49<4:48:49, 70.73s/it]       Evaluating commonsenseqa :   2%|▏         | 6/250 [07:01<4:49:29, 71.19s/it]       Evaluating commonsenseqa :   3%|▎         | 7/250 [08:14<4:49:57, 71.60s/it]                                                                                             Evaluating commonsenseqa :   3%|▎         | 8/250 [09:25<4:48:11, 71.45s/it]Evaluating commonsenseqa :   4%|▎         | 9/250 [10:37<4:48:07, 71.73s/it]              Evaluating commonsenseqa :   4%|▍         | 10/250 [11:49<4:46:53, 71.72s/it]      Evaluating commonsenseqa :   4%|▍         | 11/250 [13:02<4:46:57, 72.04s/it]      Evaluating commonsenseqa :   5%|▍         | 12/250 [14:14<4:45:29, 71.97s/it]                                                                                            Evaluating commonsenseqa :   5%|▌         | 13/250 [15:26<4:45:03, 72.17s/it]        Evaluating commonsenseqa :   6%|▌         | 14/250 [16:36<4:41:23, 71.54s/it]        Evaluating commonsenseqa :   6%|▌         | 15/250 [17:49<4:41:23, 71.85s/it]                                                                                                Evaluating commonsenseqa :   6%|▋         | 16/250 [19:01<4:40:25, 71.90s/it]        Evaluating commonsenseqa :   7%|▋         | 17/250 [20:13<4:39:36, 72.00s/it]        Evaluating commonsenseqa :   7%|▋         | 18/250 [21:23<4:36:18, 71.46s/it]                                                                                                Evaluating commonsenseqa :   8%|▊         | 19/250 [22:36<4:36:24, 71.79s/it]        Evaluating commonsenseqa :   8%|▊         | 20/250 [23:46<4:33:08, 71.25s/it]        Evaluating commonsenseqa :   8%|▊         | 21/250 [24:59<4:33:53, 71.76s/it]                                                                                                Evaluating commonsenseqa :   9%|▉         | 22/250 [26:09<4:31:13, 71.37s/it]        Evaluating commonsenseqa :   9%|▉         | 23/250 [27:22<4:31:18, 71.71s/it]                                                                                                Evaluating commonsenseqa :  10%|▉         | 24/250 [28:34<4:30:10, 71.73s/it]        Evaluating commonsenseqa :  10%|█         | 25/250 [29:46<4:29:20, 71.83s/it]        Evaluating commonsenseqa :  10%|█         | 26/250 [30:57<4:27:38, 71.69s/it]                                                                                                Evaluating commonsenseqa :  11%|█         | 27/250 [31:47<4:01:53, 65.08s/it]Evaluating commonsenseqa :  11%|█         | 28/250 [32:58<4:07:37, 66.93s/it]                Evaluating commonsenseqa :  12%|█▏        | 29/250 [34:10<4:12:42, 68.61s/it]       Evaluating commonsenseqa :  12%|█▏        | 30/250 [35:22<4:14:36, 69.44s/it]       Evaluating commonsenseqa :  12%|█▏        | 31/250 [36:33<4:15:24, 69.97s/it]                                                                                                Evaluating commonsenseqa :  13%|█▎        | 32/250 [37:44<4:15:12, 70.24s/it]         Evaluating commonsenseqa :  13%|█▎        | 33/250 [38:56<4:15:33, 70.66s/it]         Evaluating commonsenseqa :  14%|█▎        | 34/250 [40:07<4:15:21, 70.93s/it]                                                                                                    Evaluating commonsenseqa :  14%|█▍        | 35/250 [40:54<3:48:22, 63.73s/it]Evaluating commonsenseqa :  14%|█▍        | 36/250 [42:06<3:55:44, 66.10s/it]                  Evaluating commonsenseqa :  15%|█▍        | 37/250 [43:16<3:59:15, 67.39s/it]         Evaluating commonsenseqa :  15%|█▌        | 38/250 [44:26<4:00:42, 68.13s/it]         Evaluating commonsenseqa :  16%|█▌        | 39/250 [45:39<4:04:38, 69.57s/it]                                                                                                    Evaluating commonsenseqa :  16%|█▌        | 40/250 [46:52<4:07:40, 70.76s/it]         Evaluating commonsenseqa :  16%|█▋        | 41/250 [48:02<4:05:39, 70.53s/it]         Evaluating commonsenseqa :  17%|█▋        | 42/250 [49:13<4:04:39, 70.57s/it]                                                                                                    Evaluating commonsenseqa :  17%|█▋        | 43/250 [50:25<4:04:49, 70.96s/it]Evaluating commonsenseqa :  18%|█▊        | 44/250 [51:35<4:03:10, 70.83s/it]                  Evaluating commonsenseqa :  18%|█▊        | 45/250 [52:45<4:00:55, 70.51s/it]                                                                                                    Evaluating commonsenseqa :  18%|█▊        | 46/250 [53:55<3:59:17, 70.38s/it]Evaluating commonsenseqa :  19%|█▉        | 47/250 [55:07<3:59:54, 70.91s/it]                  Evaluating commonsenseqa :  19%|█▉        | 48/250 [56:19<3:59:05, 71.02s/it]         Evaluating commonsenseqa :  20%|█▉        | 49/250 [57:29<3:57:28, 70.89s/it]         Evaluating commonsenseqa :  20%|██        | 50/250 [58:07<3:22:56, 60.88s/it]         Evaluating commonsenseqa :  20%|██        | 51/250 [59:17<3:31:29, 63.77s/it]         Evaluating commonsenseqa :  21%|██        | 52/250 [1:00:29<3:38:14, 66.13s/it]                                                                                                    Evaluating commonsenseqa :  21%|██        | 53/250 [1:01:39<3:40:57, 67.30s/it]         Evaluating commonsenseqa :  22%|██▏       | 54/250 [1:02:50<3:43:22, 68.38s/it]       Evaluating commonsenseqa :  22%|██▏       | 55/250 [1:03:34<3:18:07, 60.96s/it]       Evaluating commonsenseqa :  22%|██▏       | 56/250 [1:04:21<3:04:18, 57.00s/it]       Evaluating commonsenseqa :  23%|██▎       | 57/250 [1:05:31<3:16:01, 60.94s/it]       Evaluating commonsenseqa :  23%|██▎       | 58/250 [1:06:43<3:24:52, 64.02s/it]       Evaluating commonsenseqa :  24%|██▎       | 59/250 [1:07:56<3:32:23, 66.72s/it]                                                                                                    Evaluating commonsenseqa :  24%|██▍       | 60/250 [1:09:09<3:37:11, 68.59s/it]       Evaluating commonsenseqa :  24%|██▍       | 61/250 [1:10:20<3:38:59, 69.52s/it]       Evaluating commonsenseqa :  25%|██▍       | 62/250 [1:11:30<3:38:10, 69.63s/it]                                                                                                    Evaluating commonsenseqa :  25%|██▌       | 63/250 [1:12:42<3:38:51, 70.22s/it]       Evaluating commonsenseqa :  26%|██▌       | 64/250 [1:13:53<3:38:26, 70.47s/it]       Evaluating commonsenseqa :  26%|██▌       | 65/250 [1:15:04<3:38:08, 70.75s/it]                                                                                                    Evaluating commonsenseqa :  26%|██▋       | 66/250 [1:16:15<3:37:10, 70.82s/it]       Evaluating commonsenseqa :  27%|██▋       | 67/250 [1:17:27<3:37:17, 71.24s/it]       Evaluating commonsenseqa :  27%|██▋       | 68/250 [1:18:38<3:35:47, 71.14s/it]                                                                                                    Evaluating commonsenseqa :  28%|██▊       | 69/250 [1:19:50<3:34:45, 71.19s/it]       Evaluating commonsenseqa :  28%|██▊       | 70/250 [1:21:02<3:35:02, 71.68s/it]       Evaluating commonsenseqa :  28%|██▊       | 71/250 [1:22:13<3:32:32, 71.24s/it]                                                                                                    Evaluating commonsenseqa :  29%|██▉       | 72/250 [1:23:24<3:31:14, 71.20s/it]         Evaluating commonsenseqa :  29%|██▉       | 73/250 [1:24:35<3:29:47, 71.11s/it]                                                                                                        Evaluating commonsenseqa :  30%|██▉       | 74/250 [1:25:37<3:20:24, 68.32s/it]         Evaluating commonsenseqa :  30%|███       | 75/250 [1:26:48<3:21:53, 69.22s/it]         Evaluating commonsenseqa :  30%|███       | 76/250 [1:27:58<3:21:23, 69.44s/it]                                                                                                        Evaluating commonsenseqa :  31%|███       | 77/250 [1:29:09<3:21:37, 69.93s/it]Evaluating commonsenseqa :  31%|███       | 78/250 [1:30:21<3:22:18, 70.57s/it]                  Evaluating commonsenseqa :  32%|███▏      | 79/250 [1:31:32<3:21:45, 70.79s/it]                                                                                                      Evaluating commonsenseqa :  32%|███▏      | 80/250 [1:32:43<3:20:42, 70.84s/it]       Evaluating commonsenseqa :  32%|███▏      | 81/250 [1:33:56<3:21:34, 71.57s/it]       Evaluating commonsenseqa :  33%|███▎      | 82/250 [1:34:39<2:55:55, 62.83s/it]       Evaluating commonsenseqa :  33%|███▎      | 83/250 [1:35:52<3:03:30, 65.93s/it]       Evaluating commonsenseqa :  34%|███▎      | 84/250 [1:37:02<3:05:38, 67.10s/it]                                                                                                      Evaluating commonsenseqa :  34%|███▍      | 85/250 [1:38:15<3:09:26, 68.89s/it]       Evaluating commonsenseqa :  34%|███▍      | 86/250 [1:39:27<3:10:52, 69.84s/it]       Evaluating commonsenseqa :  35%|███▍      | 87/250 [1:40:39<3:11:38, 70.54s/it]                                                                                                      Evaluating commonsenseqa :  35%|███▌      | 88/250 [1:41:52<3:12:39, 71.36s/it]       Evaluating commonsenseqa :  36%|███▌      | 89/250 [1:43:03<3:11:12, 71.26s/it]       Evaluating commonsenseqa :  36%|███▌      | 90/250 [1:44:16<3:11:15, 71.72s/it]                                                                                                      Evaluating commonsenseqa :  36%|███▋      | 91/250 [1:45:28<3:09:59, 71.70s/it]         Evaluating commonsenseqa :  37%|███▋      | 92/250 [1:46:41<3:10:05, 72.19s/it]         Evaluating commonsenseqa :  37%|███▋      | 93/250 [1:47:52<3:07:35, 71.69s/it]                                                                                                        Evaluating commonsenseqa :  38%|███▊      | 94/250 [1:49:03<3:06:06, 71.58s/it]         Evaluating commonsenseqa :  38%|███▊      | 95/250 [1:50:13<3:03:55, 71.20s/it]       Evaluating commonsenseqa :  38%|███▊      | 96/250 [1:51:24<3:01:53, 70.87s/it]                                                                                                      Evaluating commonsenseqa :  39%|███▉      | 97/250 [1:52:35<3:01:34, 71.20s/it]       Evaluating commonsenseqa :  39%|███▉      | 98/250 [1:53:47<3:00:36, 71.29s/it]       Evaluating commonsenseqa :  40%|███▉      | 99/250 [1:54:58<2:59:23, 71.28s/it]                                                                                                      Evaluating commonsenseqa :  40%|████      | 100/250 [1:56:08<2:57:25, 70.97s/it]Evaluating commonsenseqa :  40%|████      | 101/250 [1:57:21<2:57:06, 71.32s/it]            Evaluating commonsenseqa :  41%|████      | 102/250 [1:58:31<2:55:33, 71.17s/it]      Evaluating commonsenseqa :  41%|████      | 103/250 [1:59:43<2:54:41, 71.30s/it]      Evaluating commonsenseqa :  42%|████▏     | 104/250 [2:00:55<2:53:41, 71.38s/it]                                                                                                   Evaluating commonsenseqa :  42%|████▏     | 105/250 [2:02:05<2:51:50, 71.11s/it]    Evaluating commonsenseqa :  42%|████▏     | 106/250 [2:03:17<2:51:10, 71.32s/it]    Evaluating commonsenseqa :  43%|████▎     | 107/250 [2:04:30<2:50:57, 71.73s/it]                                                                                                   Evaluating commonsenseqa :  43%|████▎     | 108/250 [2:05:41<2:49:36, 71.66s/it]    Evaluating commonsenseqa :  44%|████▎     | 109/250 [2:06:54<2:49:05, 71.95s/it]    Evaluating commonsenseqa :  44%|████▍     | 110/250 [2:07:48<2:35:49, 66.78s/it]                                                                                                     Evaluating commonsenseqa :  44%|████▍     | 111/250 [2:08:59<2:37:05, 67.81s/it]Evaluating commonsenseqa :  45%|████▍     | 112/250 [2:10:10<2:38:03, 68.72s/it]            Evaluating commonsenseqa :  45%|████▌     | 113/250 [2:10:54<2:20:27, 61.51s/it]Evaluating commonsenseqa :  46%|████▌     | 114/250 [2:12:05<2:25:44, 64.30s/it]            Evaluating commonsenseqa :  46%|████▌     | 115/250 [2:13:15<2:28:40, 66.08s/it]      Evaluating commonsenseqa :  46%|████▋     | 116/250 [2:14:26<2:30:56, 67.58s/it]2s/it]Evaluating commonsenseqa :  84%|████████▍ | 211/250 [3:11:17<29:24, 45.24s/it]Evaluating commonsenseqa :  85%|████████▍ | 212/250 [3:12:11<30:29, 48.14s/it]Evaluating commonsenseqa :  85%|████████▌ | 213/250 [3:13:07<31:00, 50.29s/it]Evaluating commonsenseqa :  86%|████████▌ | 214/250 [3:14:02<31:07, 51.87s/it]Evaluating commonsenseqa :  86%|████████▌ | 215/250 [3:14:45<28:39, 49.12s/it]Evaluating commonsenseqa :  86%|████████▋ | 216/250 [3:15:40<28:49, 50.88s/it]Evaluating commonsenseqa :  87%|████████▋ | 217/250 [3:16:35<28:42, 52.18s/it]Evaluating commonsenseqa :  87%|████████▋ | 218/250 [3:17:12<25:21, 47.56s/it]Evaluating commonsenseqa :  88%|████████▊ | 219/250 [3:18:07<25:45, 49.86s/it]Evaluating commonsenseqa :  88%|████████▊ | 220/250 [3:19:03<25:46, 51.56s/it]Evaluating commonsenseqa :  88%|████████▊ | 221/250 [3:19:58<25:31, 52.82s/it]Evaluating commonsenseqa :  89%|████████▉ | 222/250 [3:20:42<23:24, 50.16s/it]Evaluating commonsenseqa :  89%|████████▉ | 223/250 [3:21:37<23:11, 51.54s/it]Evaluating commonsenseqa :  90%|████████▉ | 224/250 [3:22:33<22:54, 52.87s/it]Evaluating commonsenseqa :  90%|█████████ | 225/250 [3:23:30<22:28, 53.95s/it]Evaluating commonsenseqa :  90%|█████████ | 226/250 [3:24:25<21:44, 54.37s/it]Evaluating commonsenseqa :  91%|█████████ | 227/250 [3:25:20<20:57, 54.66s/it]Evaluating commonsenseqa :  91%|█████████ | 228/250 [3:26:16<20:08, 54.95s/it]Evaluating commonsenseqa :  92%|█████████▏| 229/250 [3:27:11<19:16, 55.08s/it]Evaluating commonsenseqa :  92%|█████████▏| 230/250 [3:28:06<18:19, 54.97s/it]Evaluating commonsenseqa :  92%|█████████▏| 231/250 [3:29:01<17:25, 55.02s/it]Evaluating commonsenseqa :  93%|█████████▎| 232/250 [3:29:57<16:34, 55.24s/it]Evaluating commonsenseqa :  93%|█████████▎| 233/250 [3:30:52<15:38, 55.22s/it]Evaluating commonsenseqa :  94%|█████████▎| 234/250 [3:31:48<14:45, 55.35s/it]Evaluating commonsenseqa :  94%|█████████▍| 235/250 [3:32:44<13:52, 55.52s/it]Evaluating commonsenseqa :  94%|█████████▍| 236/250 [3:33:39<12:58, 55.59s/it]Evaluating commonsenseqa :  95%|█████████▍| 237/250 [3:34:35<12:00, 55.46s/it]Evaluating commonsenseqa :  95%|█████████▌| 238/250 [3:35:31<11:07, 55.66s/it]Evaluating commonsenseqa :  96%|█████████▌| 239/250 [3:36:26<10:11, 55.63s/it]Evaluating commonsenseqa :  96%|█████████▌| 240/250 [3:37:21<09:13, 55.37s/it]Evaluating commonsenseqa :  96%|█████████▋| 241/250 [3:37:46<06:56, 46.26s/it]Evaluating commonsenseqa :  97%|█████████▋| 242/250 [3:38:22<05:46, 43.31s/it]Evaluating commonsenseqa :  97%|█████████▋| 243/250 [3:39:18<05:28, 46.88s/it]Evaluating commonsenseqa :  98%|█████████▊| 244/250 [3:40:13<04:55, 49.25s/it]Evaluating commonsenseqa :  98%|█████████▊| 245/250 [3:41:07<04:14, 50.90s/it]Evaluating commonsenseqa :  98%|█████████▊| 246/250 [3:42:02<03:28, 52.07s/it]Evaluating commonsenseqa :  99%|█████████▉| 247/250 [3:42:57<02:38, 52.97s/it]Evaluating commonsenseqa :  99%|█████████▉| 248/250 [3:43:52<01:47, 53.61s/it]Evaluating commonsenseqa : 100%|█████████▉| 249/250 [3:44:47<00:54, 54.03s/it]Evaluating commonsenseqa : 100%|██████████| 250/250 [3:45:43<00:00, 54.42s/it]Evaluating commonsenseqa : 100%|██████████| 250/250 [3:45:43<00:00, 54.17s/it]
name: commonsenseqa | avg. gen lenth: 364.313 | time: 13545.288569450378s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr gpu04 --master_port 12094 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s20-rTrue --seed 20 --max-prompt-length 4096 --rationales --num-out-domain 6 6 7 8 9 10 True 4096 4
[2023-09-04 12:00:54,213] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s20-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 6
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o6-tgsm8k-s20-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 546103.26it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.78s/it]
 > number of parameters: 6738415616
[2023-09-04 12:01:07,451] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-04 12:01:07,709] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-04 12:01:07,711] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-04 12:01:07,711] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-04 12:01:07,711] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-04 12:01:07,711] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-04 12:01:07,711] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f41490>
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-04 12:01:07,712] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-04 12:01:07,713] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-04 12:01:07,713] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-04 12:01:07,713] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-04 12:01:07,713] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-04 12:01:07,713] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-04 12:01:07,713] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-04 12:01:07,713] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-04 12:01:07,713] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-04 12:01:07,713] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-04 12:01:07,713] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-04 12:01:07,713] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-04 12:01:07,713] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-04 12:01:07,713] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-04 12:01:07,713] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-04 12:01:07,713] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-04 12:01:07,713] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-04 12:01:07,713] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-04 12:01:07,713] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-04 12:01:07,713] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-04 12:01:07,713] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-04 12:01:07,713] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-04 12:01:07,713] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-04 12:01:07,713] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-04 12:01:07,713] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-04 12:01:07,713] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/250 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: Let x = the total number of candies Corey has.
x + 8 = the total number of candies Tapanga has.
The equation for the total number of candies is x + (x + 8) = 66
Combining like terms, we get 2x + 8 = 66
Subtracting 8 from both sides, we get 2x = 58
Dividing both sides by 2, we get x = <<29=29>>29, so Corey has 29 candies.
So the final answer is 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: At 5 cents a minute, calling his father cost Freddy 5* 45 = <<5*45=225>>225 cents.
At 25 cents a minute, calling his brother cost Freddy 25 * 31 = <<25*31=775>>775 cents.
Adding the cost of calling his father and brother, we find that Freddy paid a total of 225 + 775 = <<225+775=1000>>1000 cents.
Since each dollar has 100 cents, Freddy paid 1000 / 100 = <<1000/100=10>>10 dollars
So the final answer is 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 8 hours * 3 = <<8*3=24>>24 hours
5.5 * 2 = <<5.5*2=11>>11 hours
24 + 11 = <<24+11=35>>35 hours
35/7 = <<35/7=5>>5 hours
Lawrence would work 5 hours each of the 7 days in a week.
So the final answer is 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: We look first for the total number of books that were sold: 60 + 10 + 20 + 44 + 66 = <<60+10+20+44+66=200>>200 books.
So the total number of books that were not sold is: 800 – 200 = <<800-200=600>>600 books.
So the final answer is 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: Michael sold 2 large birdhouses for $22 each, so he made 2*$22= $<<2*22=44>>44 from large birdhouse sales.
Michael also sold 2 medium birdhouses for $16 each, so he made 2*$16= $<<2*16=32>>32 from medium birdhouse sales.
Michael sold 3 small birdhouses for $7 each, so he made 3*7=$<<3*7=21>>21 from small birdhouse sales.
Since Michael made $44 from large birdhouse sales, $32 from medium birdhouse sales, and $21 for small birdhouse sales, he made $44+$32+$21= $<<44+32+21=97>>97 total this week.
So the final answer is 97

Input: Nalani had two female dogs that were expecting and after a month gave birth to 10 puppies each. She then sold 3/4 of the puppies after they came of age, each at $200. Calculate the total amount of money she received from the sale of the puppies.
Output: If the two expectant dogs gave birth to 10 puppies each, the total number of puppies Nalani had is 10+10= <<10+10=20>>20
When they came of age, Nalani sold 3/4 of the dogs, a total of 3/4*20 = <<3/4*20=15>>15 dogs.
If each dog sold for $200, Nalani received 15*200 = $<<15*200=3000>>3000 from the sale of the dogs.
So the final answer is 3000

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o6-tgsm8k-s20-rTrue-m4096
Evaluating commonsenseqa :   0%|          | 1/250 [01:07<4:41:29, 67.83s/it]Evaluating commonsenseqa :   1%|          | 2/250 [02:12<4:33:42, 66.22s/it]Evaluating commonsenseqa :   1%|          | 3/250 [03:17<4:28:59, 65.34s/it]Evaluating commonsenseqa :   2%|▏         | 4/250 [04:23<4:29:10, 65.65s/it]Evaluating commonsenseqa :   2%|▏         | 5/250 [05:30<4:29:36, 66.03s/it]Evaluating commonsenseqa :   2%|▏         | 6/250 [06:35<4:27:41, 65.82s/it]Evaluating commonsenseqa :   3%|▎         | 7/250 [07:40<4:25:39, 65.59s/it]Evaluating commonsenseqa :   3%|▎         | 8/250 [08:45<4:23:54, 65.43s/it]Evaluating commonsenseqa :   4%|▎         | 9/250 [09:49<4:21:22, 65.07s/it]Evaluating commonsenseqa :   4%|▍         | 10/250 [10:55<4:20:40, 65.17s/it]Evaluating commonsenseqa :   4%|▍         | 11/250 [12:00<4:19:20, 65.11s/it]Evaluating commonsenseqa :   5%|▍         | 12/250 [13:04<4:17:33, 64.93s/it]Evaluating commonsenseqa :   5%|▌         | 13/250 [13:37<3:38:17, 55.26s/it]Evaluating commonsenseqa :   6%|▌         | 14/250 [14:42<3:48:34, 58.11s/it]Evaluating commonsenseqa :   6%|▌         | 15/250 [15:47<3:55:13, 60.06s/it]Evaluating commonsenseqa :   6%|▋         | 16/250 [16:52<4:00:58, 61.79s/it]Evaluating commonsenseqa :   7%|▋         | 17/250 [17:57<4:03:05, 62.60s/it]Evaluating commonsenseqa :   7%|▋         | 18/250 [19:01<4:04:08, 63.14s/it]Evaluating commonsenseqa :   8%|▊         | 19/250 [20:07<4:06:08, 63.93s/it]Evaluating commonsenseqa :   8%|▊         | 20/250 [21:12<4:06:05, 64.20s/it]Evaluating commonsenseqa :   8%|▊         | 21/250 [22:17<4:06:30, 64.59s/it]Evaluating commonsenseqa :   9%|▉         | 22/250 [23:05<3:45:29, 59.34s/it]Evaluating commonsenseqa :   9%|▉         | 23/250 [24:11<3:52:14, 61.39s/it]Evaluating commonsenseqa :  10%|▉         | 24/250 [25:16<3:56:03, 62.67s/it]Evaluating commonsenseqa :  10%|█         | 25/250 [26:20<3:55:49, 62.89s/it]Evaluating commonsenseqa :  10%|█         | 26/250 [27:25<3:57:08, 63.52s/it]Evaluating commonsenseqa :  11%|█         | 27/250 [28:31<3:58:39, 64.21s/it]Evaluating commonsenseqa :  11%|█         | 28/250 [29:35<3:57:42, 64.24s/it]Evaluating commonsenseqa :  12%|█▏        | 29/250 [30:31<3:47:17, 61.71s/it]Evaluating commonsenseqa :  12%|█▏        | 30/250 [31:36<3:50:32, 62.87s/it]Evaluating commonsenseqa :  12%|█▏        | 31/250 [32:42<3:52:23, 63.67s/it]Evaluating commonsenseqa :  13%|█▎        | 32/250 [33:47<3:53:27, 64.26s/it]Evaluating commonsenseqa :  13%|█▎        | 33/250 [34:40<3:40:04, 60.85s/it]Evaluating commonsenseqa :  14%|█▎        | 34/250 [35:46<3:44:09, 62.26s/it]Evaluating commonsenseqa :  14%|█▍        | 35/250 [36:53<3:48:25, 63.74s/it]Evaluating commonsenseqa :  14%|█▍        | 36/250 [37:59<3:50:11, 64.54s/it]Evaluating commonsenseqa :  15%|█▍        | 37/250 [39:04<3:49:38, 64.69s/it]Evaluating commonsenseqa :  15%|█▌        | 38/250 [40:10<3:49:51, 65.05s/it]Evaluating commonsenseqa :  16%|█▌        | 39/250 [41:16<3:48:55, 65.10s/it]Evaluating commonsenseqa :  16%|█▌        | 40/250 [42:22<3:49:06, 65.46s/it]Evaluating commonsenseqa :  16%|█▋        | 41/250 [43:16<3:36:37, 62.19s/it]Evaluating commonsenseqa :  17%|█▋        | 42/250 [44:22<3:39:24, 63.29s/it]Evaluating commonsenseqa :  17%|█▋        | 43/250 [45:27<3:39:26, 63.61s/it]Evaluating commonsenseqa :  18%|█▊        | 44/250 [46:32<3:40:07, 64.11s/it]Evaluating commonsenseqa :  18%|█▊        | 45/250 [47:39<3:41:55, 64.95s/it]Evaluating commonsenseqa :  18%|█▊        | 46/250 [48:44<3:41:19, 65.10s/it]Evaluating commonsenseqa :  19%|█▉        | 47/250 [49:49<3:39:49, 64.97s/it]Evaluating commonsenseqa :  19%|█▉        | 48/250 [50:54<3:39:04, 65.07s/it]Evaluating commonsenseqa :  20%|█▉        | 49/250 [52:00<3:38:59, 65.37s/it]Evaluating commonsenseqa :  20%|██        | 50/250 [53:07<3:38:45, 65.63s/it]Evaluating commonsenseqa :  20%|██        | 51/250 [54:12<3:37:04, 65.45s/it]Evaluating commonsenseqa :  21%|██        | 52/250 [55:17<3:35:50, 65.41s/it]Evaluating commonsenseqa :  21%|██        | 53/250 [56:22<3:34:50, 65.43s/it]Evaluating commonsenseqa :  22%|██▏       | 54/250 [57:26<3:32:14, 64.97s/it]Evaluating commonsenseqa :  22%|██▏       | 55/250 [58:31<3:31:03, 64.94s/it]Evaluating commonsenseqa :  22%|██▏       | 56/250 [59:36<3:30:08, 64.99s/it]Evaluating commonsenseqa :  23%|██▎       | 57/250 [1:00:42<3:29:40, 65.18s/it]Evaluating commonsenseqa :  23%|██▎       | 58/250 [1:01:47<3:28:15, 65.08s/it]Evaluating commonsenseqa :  24%|██▎       | 59/250 [1:02:52<3:27:22, 65.14s/it]Evaluating commonsenseqa :  24%|██▍       | 60/250 [1:03:57<3:26:04, 65.08s/it]Evaluating commonsenseqa :  24%|██▍       | 61/250 [1:05:02<3:24:29, 64.92s/it]Evaluating commonsenseqa :  25%|██▍       | 62/250 [1:06:07<3:24:23, 65.23s/it]Evaluating commonsenseqa :  25%|██▌       | 63/250 [1:06:46<2:57:52, 57.07s/it]Evaluating commonsenseqa :  26%|██▌       | 64/250 [1:07:50<3:04:01, 59.36s/it]Evaluating commonsenseqa :  26%|██▌       | 65/250 [1:08:21<2:36:21, 50.71s/it]Evaluating commonsenseqa :  26%|██▋       | 66/250 [1:09:26<2:48:56, 55.09s/it]Evaluating commonsenseqa :  27%|██▋       | 67/250 [1:10:30<2:56:20, 57.81s/it]Evaluating commonsenseqa :  27%|██▋       | 68/250 [1:11:37<3:03:19, 60.44s/it]Evaluating commonsenseqa :  28%|██▊       | 69/250 [1:12:41<3:05:58, 61.65s/it]Evaluating commonsenseqa :  28%|██▊       | 70/250 [1:13:47<3:08:51, 62.95s/it]Evaluating commonsenseqa :  28%|██▊       | 71/250 [1:14:04<2:26:34, 49.13s/it]Evaluating commonsenseqa :  29%|██▉       | 72/250 [1:15:09<2:39:48, 53.87s/it]Evaluating commonsenseqa :  29%|██▉       | 73/250 [1:16:13<2:48:05, 56.98s/it]Evaluating commonsenseqa :  30%|██▉       | 74/250 [1:17:18<2:54:11, 59.39s/it]Evaluating commonsenseqa :  30%|███       | 75/250 [1:18:24<2:58:48, 61.31s/it]Evaluating commonsenseqa :  30%|███       | 76/250 [1:19:30<3:01:59, 62.76s/it]Evaluating commonsenseqa :  31%|███       | 77/250 [1:20:35<3:02:59, 63.47s/it]Evaluating commonsenseqa :  31%|███       | 78/250 [1:21:41<3:03:27, 64.00s/it]Evaluating commonsenseqa :  32%|███▏      | 79/250 [1:22:46<3:03:16, 64.31s/it]Evaluating commonsenseqa :  32%|███▏      | 80/250 [1:23:51<3:02:46, 64.51s/it]Evaluating commonsenseqa :  32%|███▏      | 81/250 [1:24:16<2:28:16, 52.64s/it]Evaluating commonsenseqa :  33%|███▎      | 82/250 [1:25:20<2:37:24, 56.22s/it]Evaluating commonsenseqa :  33%|███▎      | 83/250 [1:26:25<2:44:01, 58.93s/it]Evaluating commonsenseqa :  34%|███▎      | 84/250 [1:27:31<2:48:48, 61.01s/it]Evaluating commonsenseqa :  34%|███▍      | 85/250 [1:28:35<2:50:09, 61.87s/it]Evaluating commonsenseqa :  34%|███▍      | 86/250 [1:29:39<2:50:49, 62.50s/it]Evaluating commonsenseqa :  35%|███▍      | 87/250 [1:30:43<2:51:01, 62.95s/it]Evaluating commonsenseqa :  35%|███▌      | 88/250 [1:31:48<2:51:38, 63.57s/it]Evaluating commonsenseqa :  36%|███▌      | 89/250 [1:32:23<2:27:34, 55.00s/it]Evaluating commonsenseqa :  36%|███▌      | 90/250 [1:33:10<2:20:29, 52.68s/it]Evaluating commonsenseqa :  36%|███▋      | 91/250 [1:34:15<2:28:48, 56.15s/it]Evaluating commonsenseqa :  37%|███▋      | 92/250 [1:35:20<2:34:54, 58.82s/it]Evaluating commonsenseqa :  37%|███▋      | 93/250 [1:36:25<2:38:44, 60.67s/it]Evaluating commonsenseqa :  38%|███▊      | 94/250 [1:37:29<2:40:40, 61.80s/it]Evaluating commonsenseqa :  38%|███▊      | 95/250 [1:38:34<2:42:20, 62.84s/it]Evaluating commonsenseqa :  38%|███▊      | 96/250 [1:39:38<2:42:09, 63.18s/it]Evaluating commonsenseqa :  39%|███▉      | 97/250 [1:40:42<2:41:47, 63.45s/it]Evaluating commonsenseqa :  39%|███▉      | 98/250 [1:41:48<2:42:25, 64.11s/it]Evaluating commonsenseqa :  40%|███▉      | 99/250 [1:42:52<2:41:35, 64.21s/it]Evaluating commonsenseqa :  40%|████      | 100/250 [1:43:57<2:40:45, 64.30s/it]Evaluating commonsenseqa :  40%|████      | 101/250 [1:45:01<2:39:25, 64.20s/it]Evaluating commonsenseqa :  41%|████      | 102/250 [1:46:06<2:39:12, 64.54s/it]Evaluating commonsenseqa :  41%|████      | 103/250 [1:47:11<2:38:35, 64.73s/it]Evaluating commonsenseqa :  42%|████▏     | 104/250 [1:48:18<2:38:36, 65.18s/it]Evaluating commonsenseqa :  42%|████▏     | 105/250 [1:49:24<2:38:15, 65.49s/it]Evaluating commonsenseqa :  42%|████▏     | 106/250 [1:50:29<2:36:37, 65.26s/it]Evaluating commonsenseqa :  43%|████▎     | 107/250 [1:51:33<2:35:07, 65.09s/it]Evaluating commonsenseqa :  43%|████▎     | 108/250 [1:52:39<2:34:24, 65.24s/it]Evaluating commonsenseqa :  44%|████▎     | 109/250 [1:53:23<2:18:23, 58.89s/it]Evaluating commonsenseqa :  44%|████▍     | 110/250 [1:54:29<2:22:31, 61.08s/it]Evaluating commonsenseqa :  44%|████▍     | 111/250 [1:55:35<2:24:32, 62.39s/it]Evaluating commonsenseqa :  45%|████▍     | 112/250 [1:56:40<2:25:25, 63.23s/it]Evaluating commonsenseqa :  45%|████▌     | 113/250 [1:57:44<2:24:56, 63.48s/it]Evaluating commonsenseqa :  46%|████▌     | 114/250 [1:58:48<2:24:25, 63.71s/it]Evaluating commonsenseqa :  46%|████▌     | 115/250 [1:59:39<2:14:56, 59.97s/it]Evaluating commonsenseqa :  46%|████▋     | 116/250 [2:00:45<2:17:47, 61.70s/it]Evaluating commonsenseqa :  47%|████▋     | 117/250 [2:01:49<2:18:20, 62.41s/it]Evaluating commonsenseqa :  47%|████▋     | 118/250 [2:02:53<2:18:20, 62.88s/it]Evaluating commonsenseqa :  48%|████▊     | 119/250 [2:03:59<2:19:03, 63.69s/it]Evaluating commonsenseqa :  48%|████▊     | 120/250 [2:05:04<2:19:16, 64.28s/it]Evaluating commonsenseqa :  48%|████▊     | 121/250 [2:06:09<2:18:38, 64.49s/it]Evaluating commonsenseqa :  49%|████▉     | 122/250 [2:07:15<2:18:13, 64.79s/it]Evaluating commonsenseqa :  49%|████▉     | 123/250 [2:08:20<2:17:26, 64.93s/it]Evaluating commonsenseqa :  50%|████▉     | 124/250 [2:09:26<2:16:59, 65.24s/it]Evaluating commonsenseqa :  50%|█████     | 125/250 [2:10:32<2:16:04, 65.32s/it]Evaluating commonsenseqa :  50%|█████     | 126/250 [2:11:11<1:58:56, 57.56s/it]Evaluating commonsenseqa :  51%|█████     | 127/250 [2:12:15<2:01:49, 59.42s/it]Evaluating commonsenseqa :  51%|█████     | 128/250 [2:13:20<2:04:21, 61.16s/it]Evaluating commonsenseqa :  52%|█████▏    | 129/250 [2:14:25<2:05:55, 62.44s/it]Evaluating commonsenseqa :  52%|█████▏    | 130/250 [2:15:30<2:06:06, 63.06s/it]Evaluating commonsenseqa :  52%|█████▏    | 131/250 [2:16:35<2:05:58, 63.52s/it]Evaluating commonsenseqa :  53%|█████▎    | 132/250 [2:17:39<2:05:41, 63.91s/it]Evaluating commonsenseqa :  53%|█████▎    | 133/250 [2:18:44<2:04:55, 64.06s/it]Evaluating commonsenseqa :  54%|█████▎    | 134/250 [2:19:48<2:04:13, 64.25s/it]Evaluating commonsenseqa :  54%|█████▍    | 135/250 [2:20:54<2:04:07, 64.76s/it]Evaluating commonsenseqa :  54%|█████▍    | 136/250 [2:21:58<2:02:26, 64.44s/it]Evaluating commonsenseqa :  55%|█████▍    | 137/250 [2:23:03<2:01:42, 64.62s/it]Evaluating commonsenseqa :  55%|█████▌    | 138/250 [2:23:43<1:46:38, 57.13s/it]Evaluating commonsenseqa :  56%|█████▌    | 139/250 [2:24:48<1:50:04, 59.50s/it]Evaluating commonsenseqa :  56%|█████▌    | 140/250 [2:25:53<1:51:56, 61.06s/it]Evaluating commonsenseqa :  56%|█████▋    | 141/250 [2:26:59<1:53:45, 62.62s/it]Evaluating commonsenseqa :  57%|█████▋    | 142/250 [2:28:05<1:54:27, 63.59s/it]Evaluating commonsenseqa :  57%|█████▋    | 143/250 [2:29:09<1:53:58, 63.91s/it]Evaluating commonsenseqa :  58%|█████▊    | 144/250 [2:30:14<1:53:06, 64.03s/it]Evaluating commonsenseqa :  58%|█████▊    | 145/250 [2:31:18<1:52:18, 64.18s/it]Evaluating commonsenseqa :  58%|█████▊    | 146/250 [2:32:24<1:51:54, 64.56s/it]Evaluating commonsenseqa :  59%|█████▉    | 147/250 [2:33:28<1:50:58, 64.65s/it]Evaluating commonsenseqa :  59%|█████▉    | 148/250 [2:34:34<1:50:22, 64.93s/it]Evaluating commonsenseqa :  60%|█████▉    | 149/250 [2:35:40<1:49:33, 65.09s/it]Evaluating commonsenseqa :  60%|██████    | 150/250 [2:36:46<1:49:01, 65.42s/it]Evaluating commonsenseqa :  60%|██████    | 151/250 [2:37:50<1:47:36, 65.22s/it]Evaluating commonsenseqa :  61%|██████    | 152/250 [2:38:56<1:46:53, 65.45s/it]Evaluating commonsenseqa :  61%|██████    | 153/250 [2:39:54<1:41:55, 63.04s/it]Evaluating commonsenseqa :  62%|██████▏   | 154/250 [2:40:59<1:42:02, 63.78s/it]Evaluating commonsenseqa :  62%|██████▏   | 155/250 [2:42:04<1:41:23, 64.03s/it]Evaluating commonsenseqa :  62%|██████▏   | 156/250 [2:43:08<1:40:17, 64.01s/it]Evaluating commonsenseqa :  63%|██████▎   | 157/250 [2:44:07<1:36:57, 62.55s/it]Evaluating commonsenseqa :  63%|██████▎   | 158/250 [2:45:12<1:36:58, 63.25s/it]Evaluating commonsenseqa :  64%|██████▎   | 159/250 [2:46:17<1:36:33, 63.66s/it]Evaluating commonsenseqa :  64%|██████▍   | 160/250 [2:47:21<1:35:48, 63.87s/it]Evaluating commonsenseqa :  64%|██████▍   | 161/250 [2:48:26<1:35:04, 64.10s/it]Evaluating commonsenseqa :  65%|██████▍   | 162/250 [2:49:32<1:35:04, 64.83s/it]Evaluating commonsenseqa :  65%|██████▌   | 163/250 [2:50:38<1:34:21, 65.07s/it]Evaluating commonsenseqa :  66%|██████▌   | 164/250 [2:51:43<1:33:26, 65.19s/it]Evaluating commonsenseqa :  66%|██████▌   | 165/250 [2:52:48<1:32:09, 65.05s/it]Evaluating commonsenseqa :  66%|██████▋   | 166/250 [2:53:52<1:30:50, 64.89s/it]Evaluating commonsenseqa :  67%|██████▋   | 167/250 [2:54:57<1:29:34, 64.75s/it]Evaluating commonsenseqa :  67%|██████▋   | 168/250 [2:56:03<1:29:02, 65.16s/it]Evaluating commonsenseqa :  68%|██████▊   | 169/250 [2:57:07<1:27:21, 64.71s/it]Evaluating commonsenseqa :  68%|██████▊   | 170/250 [2:58:14<1:27:17, 65.47s/it]Evaluating commonsenseqa :  68%|██████▊   | 171/250 [2:59:20<1:26:29, 65.70s/it]Evaluating commonsenseqa :  69%|██████▉   | 172/250 [3:00:25<1:25:08, 65.50s/it]Evaluating commonsenseqa :  69%|██████▉   | 173/250 [3:01:30<1:23:52, 65.36s/it]Evaluating commonsenseqa :  70%|██████▉   | 174/250 [3:02:36<1:23:00, 65.53s/it]Evaluating commonsenseqa :  70%|███████   | 175/250 [3:03:41<1:21:48, 65.45s/it]Evaluating commonsenseqa :  70%|███████   | 176/250 [3:04:46<1:20:32, 65.30s/it]Evaluating commonsenseqa :  71%|███████   | 177/250 [3:05:51<1:19:22, 65.25s/it]Evaluating commonsenseqa :  71%|███████   | 178/250 [3:06:57<1:18:13, 65.19s/it]Evaluating commonsenseqa :  72%|███████▏  | 179/250 [3:08:02<1:17:07, 65.17s/it]Evaluating commonsenseqa :  72%|███████▏  | 180/250 [3:09:06<1:15:53, 65.05s/it]Evaluating commonsenseqa :  72%|███████▏  | 181/250 [3:10:11<1:14:35, 64.86s/it]Evaluating commonsenseqa :  73%|███████▎  | 182/250 [3:11:16<1:13:31, 64.87s/it]Evaluating commonsenseqa :  73%|███████▎  | 183/250 [3:12:21<1:12:34, 65.00s/it]Evaluating commonsenseqa :  74%|███████▎  | 184/250 [3:13:27<1:11:51, 65.32s/it]Evaluating commonsenseqa :  74%|███████▍  | 185/250 [3:14:34<1:11:23, 65.89s/it]Evaluating commonsenseqa :  74%|███████▍  | 186/250 [3:15:19<1:03:33, 59.59s/it]Evaluating commonsenseqa :  75%|███████▍  | 187/250 [3:16:24<1:04:20, 61.28s/it]Evaluating commonsenseqa :  75%|███████▌  | 188/250 [3:17:23<1:02:36, 60.58s/it]Evaluating commonsenseqa :  76%|███████▌  | 189/250 [3:18:29<1:03:04, 62.04s/it]Evaluating commonsenseqa :  76%|███████▌  | 190/250 [3:19:34<1:02:53, 62.90s/it]Evaluating commonsenseqa :  76%|███████▋  | 191/250 [3:20:40<1:02:59, 64.06s/it]Evaluating commonsenseqa :  77%|███████▋  | 192/250 [3:21:46<1:02:19, 64.48s/it]Evaluating commonsenseqa :  77%|███████▋  | 193/250 [3:22:51<1:01:32, 64.78s/it]Evaluating commonsenseqa :  78%|███████▊  | 194/250 [3:23:57<1:00:43, 65.05s/it]Evaluating commonsenseqa :  78%|███████▊  | 195/250 [3:25:03<59:50, 65.27s/it]  Evaluating commonsenseqa :  78%|███████▊  | 196/250 [3:26:01<56:45, 63.07s/it]Evaluating commonsenseqa :  79%|███████▉  | 197/250 [3:27:06<56:18, 63.74s/it]Evaluating commonsenseqa :  79%|███████▉  | 198/250 [3:28:14<56:13, 64.87s/it]Evaluating commonsenseqa :  80%|███████▉  | 199/250 [3:29:19<55:20, 65.10s/it]Evaluating commonsenseqa :  80%|████████  | 200/250 [3:29:41<43:29, 52.20s/it]Evaluating commonsenseqa :  80%|████████  | 201/250 [3:30:28<41:17, 50.55s/it]Evaluating commonsenseqa :  81%|████████  | 202/250 [3:31:04<37:02, 46.29s/it]Evaluating commonsenseqa :  81%|████████  | 203/250 [3:32:10<40:40, 51.94s/it]Evaluating commonsenseqa :  82%|████████▏ | 204/250 [3:33:15<42:56, 56.01s/it]Evaluating commonsenseqa :  82%|████████▏ | 205/250 [3:34:08<41:12, 54.94s/it]Evaluating commonsenseqa :  82%|████████▏ | 206/250 [3:35:13<42:42, 58.24s/it]Evaluating commonsenseqa :  83%|████████▎ | 207/250 [3:36:19<43:12, 60.29s/it]Evaluating commonsenseqa :  83%|████████▎ | 208/250 [3:37:23<43:07, 61.60s/it]Evaluating commonsenseqa :  84%|████████▎ | 209/250 [3:38:30<43:11, 63.20s/it]Evaluating commonsenseqa :  84%|████████▍ | 210/250 [3:39:37<42:48, 64.22s/it]Evaluating commonsenseqa :  84%|████████▍ | 211/250 [3:40:11<35:51, 55.17s/it]Evaluating commonsenseqa :  85%|████████▍ | 212/250 [3:40:58<33:20, 52.65s/it]Evaluating commonsenseqa :  85%|████████▌ | 213/250 [3:42:04<34:57, 56.68s/it]Evaluating commonsenseqa :  86%|████████▌ | 214/250 [3:43:10<35:42, 59.51s/it]Evaluating commonsenseqa :  86%|████████▌ | 215/250 [3:43:33<28:21, 48.61s/it]Evaluating commonsenseqa :  86%|████████▋ | 216/250 [3:44:38<30:18, 53.49s/it]Evaluating commonsenseqa :  87%|████████▋ | 217/250 [3:45:43<31:21, 57.01s/it]Evaluating commonsenseqa :  87%|████████▋ | 218/250 [3:46:48<31:45, 59.54s/it]Evaluating commonsenseqa :  88%|████████▊ | 219/250 [3:47:52<31:25, 60.82s/it]Evaluating commonsenseqa :  88%|████████▊ | 220/250 [3:48:58<31:08, 62.28s/it]Evaluating commonsenseqa :  88%|████████▊ | 221/250 [3:50:04<30:35, 63.28s/it]Evaluating commonsenseqa :  89%|████████▉ | 222/250 [3:51:09<29:51, 64.00s/it]Evaluating commonsenseqa :  89%|████████▉ | 223/250 [3:52:15<29:01, 64.50s/it]Evaluating commonsenseqa :  90%|████████▉ | 224/250 [3:53:20<28:02, 64.71s/it]Evaluating commonsenseqa :  90%|█████████ | 225/250 [3:54:25<27:01, 64.86s/it]Evaluating commonsenseqa :  90%|█████████ | 226/250 [3:55:31<26:00, 65.03s/it]Evaluating commonsenseqa :  91%|█████████ | 227/250 [3:56:37<25:04, 65.40s/it]Evaluating commonsenseqa :  91%|█████████ | 228/250 [3:57:42<23:53, 65.18s/it]Evaluating commonsenseqa :  92%|█████████▏| 229/250 [3:58:46<22:43, 64.94s/it]Evaluating commonsenseqa :  92%|█████████▏| 230/250 [3:59:52<21:46, 65.34s/it]Evaluating commonsenseqa :  92%|█████████▏| 231/250 [4:00:47<19:42, 62.23s/it]Evaluating commonsenseqa :  93%|█████████▎| 232/250 [4:01:53<19:00, 63.35s/it]Evaluating commonsenseqa :  93%|█████████▎| 233/250 [4:02:59<18:09, 64.06s/it]Evaluating commonsenseqa :  94%|█████████▎| 234/250 [4:03:54<16:22, 61.41s/it]Evaluating commonsenseqa :  94%|█████████▍| 235/250 [4:04:37<13:56, 55.78s/it]Evaluating commonsenseqa :  94%|█████████▍| 236/250 [4:05:42<13:38, 58.44s/it]Evaluating commonsenseqa :  95%|█████████▍| 237/250 [4:06:47<13:06, 60.52s/it]Evaluating commonsenseqa :  95%|█████████▌| 238/250 [4:07:52<12:23, 61.95s/it]Evaluating commonsenseqa :  96%|█████████▌| 239/250 [4:08:58<11:33, 63.01s/it]Evaluating commonsenseqa :  96%|█████████▌| 240/250 [4:10:04<10:40, 64.06s/it]Evaluating commonsenseqa :  96%|█████████▋| 241/250 [4:11:10<09:42, 64.72s/it]Evaluating commonsenseqa :  97%|█████████▋| 242/250 [4:12:15<08:38, 64.82s/it]Evaluating commonsenseqa :  97%|█████████▋| 243/250 [4:13:20<07:33, 64.77s/it]Evaluating commonsenseqa :  98%|█████████▊| 244/250 [4:14:25<06:29, 64.88s/it]Evaluating commonsenseqa :  98%|█████████▊| 245/250 [4:15:29<05:23, 64.66s/it]Evaluating commonsenseqa :  98%|█████████▊| 246/250 [4:16:35<04:19, 64.82s/it]Evaluating commonsenseqa :  99%|█████████▉| 247/250 [4:17:40<03:14, 64.91s/it]Evaluating commonsenseqa :  99%|█████████▉| 248/250 [4:18:46<02:10, 65.29s/it]Evaluating commonsenseqa : 100%|█████████▉| 249/250 [4:19:52<01:05, 65.67s/it]Evaluating commonsenseqa : 100%|██████████| 250/250 [4:20:59<00:00, 65.97s/it]Evaluating commonsenseqa : 100%|██████████| 250/250 [4:20:59<00:00, 62.64s/it]
name: commonsenseqa | avg. gen lenth: 324.371 | time: 15661.436842441559s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr gpu04 --master_port 12094 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o7-tgsm8k-s20-rTrue --seed 20 --max-prompt-length 4096 --rationales --num-out-domain 7 6 7 8 9 10 True 4096 4
[2023-09-04 16:22:17,547] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o7-tgsm8k-s20-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 7
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o7-tgsm8k-s20-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 482375.41it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.28s/it]
 > number of parameters: 6738415616
[2023-09-04 16:22:31,724] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-04 16:22:31,966] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-04 16:22:31,968] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f3f490>
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-04 16:22:31,969] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-04 16:22:31,970] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-04 16:22:31,970] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/250 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: Let x = the total number of candies Corey has.
x + 8 = the total number of candies Tapanga has.
The equation for the total number of candies is x + (x + 8) = 66
Combining like terms, we get 2x + 8 = 66
Subtracting 8 from both sides, we get 2x = 58
Dividing both sides by 2, we get x = <<29=29>>29, so Corey has 29 candies.
So the final answer is 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: At 5 cents a minute, calling his father cost Freddy 5* 45 = <<5*45=225>>225 cents.
At 25 cents a minute, calling his brother cost Freddy 25 * 31 = <<25*31=775>>775 cents.
Adding the cost of calling his father and brother, we find that Freddy paid a total of 225 + 775 = <<225+775=1000>>1000 cents.
Since each dollar has 100 cents, Freddy paid 1000 / 100 = <<1000/100=10>>10 dollars
So the final answer is 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 8 hours * 3 = <<8*3=24>>24 hours
5.5 * 2 = <<5.5*2=11>>11 hours
24 + 11 = <<24+11=35>>35 hours
35/7 = <<35/7=5>>5 hours
Lawrence would work 5 hours each of the 7 days in a week.
So the final answer is 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: We look first for the total number of books that were sold: 60 + 10 + 20 + 44 + 66 = <<60+10+20+44+66=200>>200 books.
So the total number of books that were not sold is: 800 – 200 = <<800-200=600>>600 books.
So the final answer is 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: Michael sold 2 large birdhouses for $22 each, so he made 2*$22= $<<2*22=44>>44 from large birdhouse sales.
Michael also sold 2 medium birdhouses for $16 each, so he made 2*$16= $<<2*16=32>>32 from medium birdhouse sales.
Michael sold 3 small birdhouses for $7 each, so he made 3*7=$<<3*7=21>>21 from small birdhouse sales.
Since Michael made $44 from large birdhouse sales, $32 from medium birdhouse sales, and $21 for small birdhouse sales, he made $44+$32+$21= $<<44+32+21=97>>97 total this week.
So the final answer is 97

Input: Nalani had two female dogs that were expecting and after a month gave birth to 10 puppies each. She then sold 3/4 of the puppies after they came of age, each at $200. Calculate the total amount of money she received from the sale of the puppies.
Output: If the two expectant dogs gave birth to 10 puppies each, the total number of puppies Nalani had is 10+10= <<10+10=20>>20
When they came of age, Nalani sold 3/4 of the dogs, a total of 3/4*20 = <<3/4*20=15>>15 dogs.
If each dog sold for $200, Nalani received 15*200 = $<<15*200=3000>>3000 from the sale of the dogs.
So the final answer is 3000

Input: Boris has 24 books and he donates a fourth of his books to the library. Cameron has 30 books and he donates a third of his books to the library. After donating their books, how many books in total do Boris and Cameron have together?
Output: Boris donates 24 / 4 = <<24/4=6>>6 books
Then Boris has a total of 24 - 6 = <<24-6=18>>18 books
Cameron donates 30 / 3 = <<30/3=10>>10 books
Then Cameron has a total of 30 - 10 = <<30-10=20>>20 books
Altogether, Boris and Cameron have 18 + 20 = <<18+20=38>>38 books
So the final answer is 38

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o7-tgsm8k-s20-rTrue-m4096
Evaluating commonsenseqa :   0%|          | 1/250 [01:03<4:24:36, 63.76s/it]Evaluating commonsenseqa :   1%|          | 2/250 [02:06<4:20:35, 63.05s/it]Evaluating commonsenseqa :   1%|          | 3/250 [03:07<4:16:25, 62.29s/it]Evaluating commonsenseqa :   2%|▏         | 4/250 [04:09<4:15:14, 62.26s/it]Evaluating commonsenseqa :   2%|▏         | 5/250 [05:13<4:16:14, 62.75s/it]Evaluating commonsenseqa :   2%|▏         | 6/250 [06:15<4:13:45, 62.40s/it]Evaluating commonsenseqa :   3%|▎         | 7/250 [07:17<4:12:16, 62.29s/it]Evaluating commonsenseqa :   3%|▎         | 8/250 [08:19<4:11:11, 62.28s/it]Evaluating commonsenseqa :   4%|▎         | 9/250 [09:22<4:11:00, 62.49s/it]Evaluating commonsenseqa :   4%|▍         | 10/250 [10:24<4:09:26, 62.36s/it]Evaluating commonsenseqa :   4%|▍         | 11/250 [11:27<4:09:08, 62.55s/it]Evaluating commonsenseqa :   5%|▍         | 12/250 [12:28<4:06:43, 62.20s/it]Evaluating commonsenseqa :   5%|▌         | 13/250 [13:05<3:34:53, 54.40s/it]Evaluating commonsenseqa :   6%|▌         | 14/250 [14:07<3:42:33, 56.58s/it]Evaluating commonsenseqa :   6%|▌         | 15/250 [15:09<3:48:14, 58.27s/it]Evaluating commonsenseqa :   6%|▋         | 16/250 [16:13<3:53:50, 59.96s/it]Evaluating commonsenseqa :   7%|▋         | 17/250 [17:15<3:55:39, 60.69s/it]Evaluating commonsenseqa :   7%|▋         | 18/250 [18:18<3:57:04, 61.31s/it]Evaluating commonsenseqa :   8%|▊         | 19/250 [19:19<3:55:54, 61.28s/it]Evaluating commonsenseqa :   8%|▊         | 20/250 [20:22<3:57:16, 61.90s/it]Evaluating commonsenseqa :   8%|▊         | 21/250 [21:25<3:57:26, 62.21s/it]Evaluating commonsenseqa :   9%|▉         | 22/250 [22:27<3:55:58, 62.10s/it]Evaluating commonsenseqa :   9%|▉         | 23/250 [23:28<3:54:08, 61.89s/it]Evaluating commonsenseqa :  10%|▉         | 24/250 [24:31<3:53:49, 62.08s/it]Evaluating commonsenseqa :  10%|█         | 25/250 [25:34<3:53:31, 62.27s/it]Evaluating commonsenseqa :  10%|█         | 26/250 [26:35<3:51:39, 62.05s/it]Evaluating commonsenseqa :  11%|█         | 27/250 [27:37<3:50:29, 62.02s/it]Evaluating commonsenseqa :  11%|█         | 28/250 [28:38<3:48:24, 61.73s/it]Evaluating commonsenseqa :  12%|█▏        | 29/250 [29:40<3:47:42, 61.82s/it]Evaluating commonsenseqa :  12%|█▏        | 30/250 [30:42<3:46:44, 61.84s/it]Evaluating commonsenseqa :  12%|█▏        | 31/250 [31:44<3:45:51, 61.88s/it]Evaluating commonsenseqa :  13%|█▎        | 32/250 [32:46<3:44:47, 61.87s/it]Evaluating commonsenseqa :  13%|█▎        | 33/250 [33:48<3:44:22, 62.04s/it]Evaluating commonsenseqa :  14%|█▎        | 34/250 [34:50<3:43:17, 62.03s/it]Evaluating commonsenseqa :  14%|█▍        | 35/250 [35:53<3:42:34, 62.11s/it]Evaluating commonsenseqa :  14%|█▍        | 36/250 [36:54<3:40:33, 61.84s/it]Evaluating commonsenseqa :  15%|█▍        | 37/250 [37:56<3:39:48, 61.92s/it]Evaluating commonsenseqa :  15%|█▌        | 38/250 [38:57<3:37:53, 61.67s/it]Evaluating commonsenseqa :  16%|█▌        | 39/250 [40:00<3:37:45, 61.92s/it]Evaluating commonsenseqa :  16%|█▌        | 40/250 [41:02<3:36:59, 62.00s/it]Evaluating commonsenseqa :  16%|█▋        | 41/250 [42:04<3:36:28, 62.14s/it]Evaluating commonsenseqa :  17%|█▋        | 42/250 [43:07<3:35:34, 62.18s/it]Evaluating commonsenseqa :  17%|█▋        | 43/250 [44:09<3:35:13, 62.39s/it]Evaluating commonsenseqa :  18%|█▊        | 44/250 [45:13<3:34:58, 62.61s/it]Evaluating commonsenseqa :  18%|█▊        | 45/250 [46:15<3:33:42, 62.55s/it]Evaluating commonsenseqa :  18%|█▊        | 46/250 [47:16<3:30:57, 62.05s/it]Evaluating commonsenseqa :  19%|█▉        | 47/250 [48:17<3:28:58, 61.77s/it]Evaluating commonsenseqa :  19%|█▉        | 48/250 [49:19<3:28:24, 61.90s/it]Evaluating commonsenseqa :  20%|█▉        | 49/250 [50:22<3:28:18, 62.18s/it]Evaluating commonsenseqa :  20%|██        | 50/250 [51:24<3:26:47, 62.04s/it]Evaluating commonsenseqa :  20%|██        | 51/250 [52:26<3:25:48, 62.05s/it]Evaluating commonsenseqa :  21%|██        | 52/250 [53:28<3:24:30, 61.97s/it]Evaluating commonsenseqa :  21%|██        | 53/250 [54:28<3:22:25, 61.65s/it]Evaluating commonsenseqa :  22%|██▏       | 54/250 [55:03<2:54:32, 53.43s/it]Evaluating commonsenseqa :  22%|██▏       | 55/250 [56:06<3:02:49, 56.25s/it]Evaluating commonsenseqa :  22%|██▏       | 56/250 [57:07<3:07:11, 57.90s/it]Evaluating commonsenseqa :  23%|██▎       | 57/250 [58:09<3:09:58, 59.06s/it]Evaluating commonsenseqa :  23%|██▎       | 58/250 [59:11<3:12:07, 60.04s/it]Evaluating commonsenseqa :  24%|██▎       | 59/250 [1:00:14<3:13:33, 60.80s/it]Evaluating commonsenseqa :  24%|██▍       | 60/250 [1:01:16<3:13:45, 61.19s/it]Evaluating commonsenseqa :  24%|██▍       | 61/250 [1:02:19<3:13:57, 61.57s/it]Evaluating commonsenseqa :  25%|██▍       | 62/250 [1:03:20<3:12:27, 61.42s/it]Evaluating commonsenseqa :  25%|██▌       | 63/250 [1:04:16<3:06:50, 59.95s/it]Evaluating commonsenseqa :  26%|██▌       | 64/250 [1:05:18<3:07:42, 60.55s/it]Evaluating commonsenseqa :  26%|██▌       | 65/250 [1:06:19<3:07:21, 60.76s/it]Evaluating commonsenseqa :  26%|██▋       | 66/250 [1:07:22<3:08:08, 61.35s/it]Evaluating commonsenseqa :  27%|██▋       | 67/250 [1:08:23<3:07:09, 61.36s/it]Evaluating commonsenseqa :  27%|██▋       | 68/250 [1:09:26<3:07:29, 61.81s/it]Evaluating commonsenseqa :  28%|██▊       | 69/250 [1:10:28<3:06:21, 61.78s/it]Evaluating commonsenseqa :  28%|██▊       | 70/250 [1:11:31<3:06:03, 62.02s/it]Evaluating commonsenseqa :  28%|██▊       | 71/250 [1:12:33<3:05:28, 62.17s/it]Evaluating commonsenseqa :  29%|██▉       | 72/250 [1:13:34<3:03:42, 61.93s/it]Evaluating commonsenseqa :  29%|██▉       | 73/250 [1:14:37<3:03:08, 62.08s/it]Evaluating commonsenseqa :  30%|██▉       | 74/250 [1:15:40<3:02:57, 62.37s/it]Evaluating commonsenseqa :  30%|███       | 75/250 [1:16:43<3:02:21, 62.52s/it]Evaluating commonsenseqa :  30%|███       | 76/250 [1:17:44<3:00:22, 62.20s/it]Evaluating commonsenseqa :  31%|███       | 77/250 [1:18:46<2:59:07, 62.12s/it]Evaluating commonsenseqa :  31%|███       | 78/250 [1:19:48<2:57:58, 62.09s/it]Evaluating commonsenseqa :  32%|███▏      | 79/250 [1:20:50<2:57:01, 62.12s/it]Evaluating commonsenseqa :  32%|███▏      | 80/250 [1:21:53<2:56:40, 62.35s/it]Evaluating commonsenseqa :  32%|███▏      | 81/250 [1:22:55<2:55:12, 62.21s/it]Evaluating commonsenseqa :  33%|███▎      | 82/250 [1:23:57<2:53:39, 62.02s/it]Evaluating commonsenseqa :  33%|███▎      | 83/250 [1:25:00<2:53:12, 62.23s/it]Evaluating commonsenseqa :  34%|███▎      | 84/250 [1:26:01<2:51:11, 61.88s/it]Evaluating commonsenseqa :  34%|███▍      | 85/250 [1:27:02<2:50:01, 61.83s/it]Evaluating commonsenseqa :  34%|███▍      | 86/250 [1:28:05<2:49:30, 62.02s/it]Evaluating commonsenseqa :  35%|███▍      | 87/250 [1:29:06<2:48:15, 61.93s/it]Evaluating commonsenseqa :  35%|███▌      | 88/250 [1:30:08<2:46:30, 61.67s/it]Evaluating commonsenseqa :  36%|███▌      | 89/250 [1:31:09<2:45:26, 61.66s/it]Evaluating commonsenseqa :  36%|███▌      | 90/250 [1:32:12<2:45:37, 62.11s/it]Evaluating commonsenseqa :  36%|███▋      | 91/250 [1:33:15<2:45:02, 62.28s/it]Evaluating commonsenseqa :  37%|███▋      | 92/250 [1:34:17<2:44:10, 62.34s/it]Evaluating commonsenseqa :  37%|███▋      | 93/250 [1:35:19<2:42:34, 62.13s/it]Evaluating commonsenseqa :  38%|███▊      | 94/250 [1:36:22<2:41:52, 62.26s/it]Evaluating commonsenseqa :  38%|███▊      | 95/250 [1:37:23<2:40:03, 61.96s/it]Evaluating commonsenseqa :  38%|███▊      | 96/250 [1:38:25<2:39:03, 61.97s/it]Evaluating commonsenseqa :  39%|███▉      | 97/250 [1:39:27<2:38:23, 62.12s/it]Evaluating commonsenseqa :  39%|███▉      | 98/250 [1:40:30<2:37:44, 62.27s/it]Evaluating commonsenseqa :  40%|███▉      | 99/250 [1:41:31<2:35:56, 61.97s/it]Evaluating commonsenseqa :  40%|████      | 100/250 [1:42:34<2:35:22, 62.15s/it]Evaluating commonsenseqa :  40%|████      | 101/250 [1:43:37<2:34:46, 62.33s/it]Evaluating commonsenseqa :  41%|████      | 102/250 [1:44:38<2:33:22, 62.18s/it]Evaluating commonsenseqa :  41%|████      | 103/250 [1:45:40<2:31:44, 61.93s/it]Evaluating commonsenseqa :  42%|████▏     | 104/250 [1:46:41<2:30:23, 61.81s/it]Evaluating commonsenseqa :  42%|████▏     | 105/250 [1:47:44<2:30:07, 62.12s/it]Evaluating commonsenseqa :  42%|████▏     | 106/250 [1:48:46<2:28:54, 62.04s/it]Evaluating commonsenseqa :  43%|████▎     | 107/250 [1:49:48<2:27:57, 62.08s/it]Evaluating commonsenseqa :  43%|████▎     | 108/250 [1:50:18<2:04:04, 52.42s/it]Evaluating commonsenseqa :  44%|████▎     | 109/250 [1:51:05<1:59:16, 50.76s/it]Evaluating commonsenseqa :  44%|████▍     | 110/250 [1:52:07<2:06:25, 54.18s/it]Evaluating commonsenseqa :  44%|████▍     | 111/250 [1:53:09<2:10:33, 56.36s/it]Evaluating commonsenseqa :  45%|████▍     | 112/250 [1:54:11<2:13:30, 58.05s/it]Evaluating commonsenseqa :  45%|████▌     | 113/250 [1:55:12<2:15:07, 59.18s/it]Evaluating commonsenseqa :  46%|████▌     | 114/250 [1:56:14<2:15:58, 59.99s/it]Evaluating commonsenseqa :  46%|████▌     | 115/250 [1:57:17<2:16:58, 60.88s/it]Evaluating commonsenseqa :  46%|████▋     | 116/250 [1:58:18<2:16:07, 60.95s/it]Evaluating commonsenseqa :  47%|████▋     | 117/250 [1:59:09<2:08:35, 58.01s/it]Evaluating commonsenseqa :  47%|████▋     | 118/250 [2:00:11<2:09:40, 58.95s/it]Evaluating commonsenseqa :  48%|████▊     | 119/250 [2:00:36<1:46:49, 48.93s/it]Evaluating commonsenseqa :  48%|████▊     | 120/250 [2:01:38<1:54:36, 52.89s/it]Evaluating commonsenseqa :  48%|████▊     | 121/250 [2:02:40<1:59:41, 55.67s/it]Evaluating commonsenseqa :  49%|████▉     | 122/250 [2:03:41<2:01:34, 56.99s/it]Evaluating commonsenseqa :  49%|████▉     | 123/250 [2:04:41<2:02:40, 57.96s/it]Evaluating commonsenseqa :  50%|████▉     | 124/250 [2:05:38<2:01:28, 57.84s/it]Evaluating commonsenseqa :  50%|█████     | 125/250 [2:06:38<2:01:29, 58.32s/it]Evaluating commonsenseqa :  50%|█████     | 126/250 [2:07:36<2:00:37, 58.36s/it]Evaluating commonsenseqa :  51%|█████     | 127/250 [2:08:34<1:59:05, 58.10s/it]Evaluating commonsenseqa :  51%|█████     | 128/250 [2:08:59<1:37:52, 48.14s/it]Evaluating commonsenseqa :  52%|█████▏    | 129/250 [2:09:56<1:42:58, 51.06s/it]Evaluating commonsenseqa :  52%|█████▏    | 130/250 [2:10:54<1:45:56, 52.97s/it]Evaluating commonsenseqa :  52%|█████▏    | 131/250 [2:11:53<1:48:53, 54.90s/it]Evaluating commonsenseqa :  53%|█████▎    | 132/250 [2:12:51<1:49:33, 55.71s/it]Evaluating commonsenseqa :  53%|█████▎    | 133/250 [2:13:50<1:50:48, 56.83s/it]Evaluating commonsenseqa :  54%|█████▎    | 134/250 [2:14:50<1:51:24, 57.62s/it]Evaluating commonsenseqa :  54%|█████▍    | 135/250 [2:15:49<1:51:10, 58.00s/it]Evaluating commonsenseqa :  54%|█████▍    | 136/250 [2:16:46<1:49:52, 57.83s/it]Evaluating commonsenseqa :  55%|█████▍    | 137/250 [2:17:46<1:50:07, 58.47s/it]Evaluating commonsenseqa :  55%|█████▌    | 138/250 [2:18:45<1:49:22, 58.59s/it]Evaluating commonsenseqa :  56%|█████▌    | 139/250 [2:19:43<1:48:18, 58.55s/it]Evaluating commonsenseqa :  56%|█████▌    | 140/250 [2:20:42<1:47:13, 58.49s/it]Evaluating commonsenseqa :  56%|█████▋    | 141/250 [2:21:07<1:28:21, 48.64s/it]Evaluating commonsenseqa :  57%|█████▋    | 142/250 [2:22:07<1:33:27, 51.92s/it]Evaluating commonsenseqa :  57%|█████▋    | 143/250 [2:23:06<1:36:31, 54.12s/it]Evaluating commonsenseqa :  58%|█████▊    | 144/250 [2:24:06<1:38:49, 55.94s/it]Evaluating commonsenseqa :  58%|█████▊    | 145/250 [2:25:07<1:40:08, 57.23s/it]Evaluating commonsenseqa :  58%|█████▊    | 146/250 [2:26:08<1:41:24, 58.50s/it]Evaluating commonsenseqa :  59%|█████▉    | 147/250 [2:27:08<1:41:01, 58.85s/it]Evaluating commonsenseqa :  59%|█████▉    | 148/250 [2:28:09<1:41:09, 59.50s/it]Evaluating commonsenseqa :  60%|█████▉    | 149/250 [2:29:10<1:40:48, 59.89s/it]Evaluating commonsenseqa :  60%|██████    | 150/250 [2:30:11<1:40:31, 60.32s/it]Evaluating commonsenseqa :  60%|██████    | 151/250 [2:31:13<1:40:20, 60.82s/it]Evaluating commonsenseqa :  61%|██████    | 152/250 [2:32:14<1:39:16, 60.79s/it]Evaluating commonsenseqa :  61%|██████    | 153/250 [2:33:14<1:38:18, 60.81s/it]Evaluating commonsenseqa :  62%|██████▏   | 154/250 [2:34:15<1:37:05, 60.68s/it]Evaluating commonsenseqa :  62%|██████▏   | 155/250 [2:35:15<1:35:43, 60.46s/it]Evaluating commonsenseqa :  62%|██████▏   | 156/250 [2:36:14<1:34:10, 60.11s/it]Evaluating commonsenseqa :  63%|██████▎   | 157/250 [2:37:14<1:33:12, 60.13s/it]Evaluating commonsenseqa :  63%|██████▎   | 158/250 [2:38:13<1:31:44, 59.83s/it]Evaluating commonsenseqa :  64%|██████▎   | 159/250 [2:39:13<1:30:52, 59.91s/it]Evaluating commonsenseqa :  64%|██████▍   | 160/250 [2:40:14<1:30:13, 60.15s/it]Evaluating commonsenseqa :  64%|██████▍   | 161/250 [2:41:16<1:29:57, 60.64s/it]Evaluating commonsenseqa :  65%|██████▍   | 162/250 [2:42:16<1:28:51, 60.59s/it]Evaluating commonsenseqa :  65%|██████▌   | 163/250 [2:43:17<1:27:48, 60.55s/it]Evaluating commonsenseqa :  66%|██████▌   | 164/250 [2:44:18<1:27:01, 60.71s/it]Evaluating commonsenseqa :  66%|██████▌   | 165/250 [2:45:19<1:26:00, 60.71s/it]Evaluating commonsenseqa :  66%|██████▋   | 166/250 [2:45:34<1:06:07, 47.23s/it]Evaluating commonsenseqa :  67%|██████▋   | 167/250 [2:46:36<1:11:22, 51.60s/it]Evaluating commonsenseqa :  67%|██████▋   | 168/250 [2:47:37<1:14:26, 54.47s/it]Evaluating commonsenseqa :  68%|██████▊   | 169/250 [2:48:39<1:16:23, 56.59s/it]Evaluating commonsenseqa :  68%|██████▊   | 170/250 [2:49:40<1:17:13, 57.91s/it]Evaluating commonsenseqa :  68%|██████▊   | 171/250 [2:50:40<1:16:55, 58.43s/it]Evaluating commonsenseqa :  69%|██████▉   | 172/250 [2:51:40<1:16:50, 59.11s/it]Evaluating commonsenseqa :  69%|██████▉   | 173/250 [2:52:41<1:16:32, 59.64s/it]Evaluating commonsenseqa :  70%|██████▉   | 174/250 [2:53:33<1:12:32, 57.27s/it]Evaluating commonsenseqa :  70%|███████   | 175/250 [2:54:35<1:13:23, 58.72s/it]Evaluating commonsenseqa :  70%|███████   | 176/250 [2:55:37<1:13:36, 59.68s/it]Evaluating commonsenseqa :  71%|███████   | 177/250 [2:56:38<1:13:10, 60.15s/it]Evaluating commonsenseqa :  71%|███████   | 178/250 [2:57:40<1:12:45, 60.64s/it]Evaluating commonsenseqa :  72%|███████▏  | 179/250 [2:58:40<1:11:33, 60.47s/it]Evaluating commonsenseqa :  72%|███████▏  | 180/250 [2:59:16<1:02:08, 53.26s/it]Evaluating commonsenseqa :  72%|███████▏  | 181/250 [3:00:17<1:03:35, 55.30s/it]Evaluating commonsenseqa :  73%|███████▎  | 182/250 [3:01:17<1:04:26, 56.86s/it]Evaluating commonsenseqa :  73%|███████▎  | 183/250 [3:02:12<1:02:55, 56.35s/it]Evaluating commonsenseqa :  74%|███████▎  | 184/250 [3:03:13<1:03:30, 57.74s/it]Evaluating commonsenseqa :  74%|███████▍  | 185/250 [3:04:14<1:03:32, 58.65s/it]Evaluating commonsenseqa :  74%|███████▍  | 186/250 [3:05:15<1:03:21, 59.40s/it]Evaluating commonsenseqa :  75%|███████▍  | 187/250 [3:06:16<1:02:46, 59.79s/it]Evaluating commonsenseqa :  75%|███████▌  | 188/250 [3:07:17<1:02:03, 60.06s/it]Evaluating commonsenseqa :  76%|███████▌  | 189/250 [3:08:18<1:01:21, 60.35s/it]Evaluating commonsenseqa :  76%|███████▌  | 190/250 [3:09:18<1:00:19, 60.33s/it]Evaluating commonsenseqa :  76%|███████▋  | 191/250 [3:10:18<59:16, 60.28s/it]  Evaluating commonsenseqa :  77%|███████▋  | 192/250 [3:11:18<58:13, 60.24s/it]Evaluating commonsenseqa :  77%|███████▋  | 193/250 [3:12:19<57:18, 60.32s/it]Evaluating commonsenseqa :  78%|███████▊  | 194/250 [3:13:18<56:07, 60.13s/it]Evaluating commonsenseqa :  78%|███████▊  | 195/250 [3:14:20<55:25, 60.46s/it]Evaluating commonsenseqa :  78%|███████▊  | 196/250 [3:15:19<54:06, 60.12s/it]Evaluating commonsenseqa :  79%|███████▉  | 197/250 [3:16:18<52:57, 59.96s/it]Evaluating commonsenseqa :  79%|███████▉  | 198/250 [3:17:18<51:57, 59.95s/it]Evaluating commonsenseqa :  80%|███████▉  | 199/250 [3:18:18<50:53, 59.88s/it]Evaluating commonsenseqa :  80%|████████  | 200/250 [3:19:17<49:45, 59.70s/it]Evaluating commonsenseqa :  80%|████████  | 201/250 [3:20:00<44:39, 54.67s/it]Evaluating commonsenseqa :  81%|████████  | 202/250 [3:21:01<45:08, 56.43s/it]Evaluating commonsenseqa :  81%|████████  | 203/250 [3:22:01<45:04, 57.54s/it]Evaluating commonsenseqa :  82%|████████▏ | 204/250 [3:23:01<44:41, 58.29s/it]Evaluating commonsenseqa :  82%|████████▏ | 205/250 [3:24:02<44:15, 59.01s/it]Evaluating commonsenseqa :  82%|████████▏ | 206/250 [3:25:01<43:21, 59.12s/it]Evaluating commonsenseqa :  83%|████████▎ | 207/250 [3:25:59<42:00, 58.61s/it]Evaluating commonsenseqa :  83%|████████▎ | 208/250 [3:26:58<41:09, 58.80s/it]Evaluating commonsenseqa :  84%|████████▎ | 209/250 [3:27:59<40:37, 59.45s/it]Evaluating commonsenseqa :  84%|████████▍ | 210/250 [3:28:59<39:51, 59.78s/it]Evaluating commonsenseqa :  84%|████████▍ | 211/250 [3:30:00<38:57, 59.93s/it]Evaluating commonsenseqa :  85%|████████▍ | 212/250 [3:30:59<37:53, 59.83s/it]Evaluating commonsenseqa :  85%|████████▌ | 213/250 [3:32:00<37:01, 60.04s/it]Evaluating commonsenseqa :  86%|████████▌ | 214/250 [3:33:00<36:05, 60.14s/it]Evaluating commonsenseqa :  86%|████████▌ | 215/250 [3:34:00<34:57, 59.94s/it]Evaluating commonsenseqa :  86%|████████▋ | 216/250 [3:35:01<34:17, 60.52s/it]Evaluating commonsenseqa :  87%|████████▋ | 217/250 [3:36:03<33:28, 60.85s/it]Evaluating commonsenseqa :  87%|████████▋ | 218/250 [3:37:03<32:15, 60.47s/it]Evaluating commonsenseqa :  88%|████████▊ | 219/250 [3:38:02<31:08, 60.29s/it]Evaluating commonsenseqa :  88%|████████▊ | 220/250 [3:39:02<30:00, 60.03s/it]Evaluating commonsenseqa :  88%|████████▊ | 221/250 [3:40:03<29:11, 60.39s/it]Evaluating commonsenseqa :  89%|████████▉ | 222/250 [3:41:03<28:05, 60.18s/it]Evaluating commonsenseqa :  89%|████████▉ | 223/250 [3:42:03<27:07, 60.27s/it]Evaluating commonsenseqa :  90%|████████▉ | 224/250 [3:43:04<26:06, 60.26s/it]Evaluating commonsenseqa :  90%|█████████ | 225/250 [3:44:05<25:16, 60.67s/it]Evaluating commonsenseqa :  90%|█████████ | 226/250 [3:45:05<24:06, 60.26s/it]Evaluating commonsenseqa :  91%|█████████ | 227/250 [3:46:04<23:01, 60.06s/it]Evaluating commonsenseqa :  91%|█████████ | 228/250 [3:47:05<22:04, 60.19s/it]Evaluating commonsenseqa :  92%|█████████▏| 229/250 [3:48:06<21:09, 60.44s/it]Evaluating commonsenseqa :  92%|█████████▏| 230/250 [3:49:02<19:45, 59.26s/it]Evaluating commonsenseqa :  92%|█████████▏| 231/250 [3:50:03<18:54, 59.69s/it]Evaluating commonsenseqa :  93%|█████████▎| 232/250 [3:51:03<17:57, 59.89s/it]Evaluating commonsenseqa :  93%|█████████▎| 233/250 [3:52:03<16:59, 59.97s/it]Evaluating commonsenseqa :  94%|█████████▎| 234/250 [3:53:03<16:00, 60.02s/it]Evaluating commonsenseqa :  94%|█████████▍| 235/250 [3:54:05<15:05, 60.36s/it]Evaluating commonsenseqa :  94%|█████████▍| 236/250 [3:55:04<14:02, 60.16s/it]Evaluating commonsenseqa :  95%|█████████▍| 237/250 [3:56:05<13:05, 60.43s/it]Evaluating commonsenseqa :  95%|█████████▌| 238/250 [3:57:05<12:02, 60.23s/it]Evaluating commonsenseqa :  96%|█████████▌| 239/250 [3:58:05<11:01, 60.18s/it]Evaluating commonsenseqa :  96%|█████████▌| 240/250 [3:59:06<10:05, 60.50s/it]Evaluating commonsenseqa :  96%|█████████▋| 241/250 [4:00:07<09:04, 60.47s/it]Evaluating commonsenseqa :  97%|█████████▋| 242/250 [4:01:07<08:03, 60.38s/it]Evaluating commonsenseqa :  97%|█████████▋| 243/250 [4:02:06<07:00, 60.04s/it]Evaluating commonsenseqa :  98%|█████████▊| 244/250 [4:03:07<06:01, 60.17s/it]Evaluating commonsenseqa :  98%|█████████▊| 245/250 [4:04:07<05:01, 60.29s/it]Evaluating commonsenseqa :  98%|█████████▊| 246/250 [4:05:08<04:01, 60.46s/it]Evaluating commonsenseqa :  99%|█████████▉| 247/250 [4:06:09<03:01, 60.61s/it]Evaluating commonsenseqa :  99%|█████████▉| 248/250 [4:07:01<01:55, 57.86s/it]Evaluating commonsenseqa : 100%|█████████▉| 249/250 [4:08:01<00:58, 58.58s/it]Evaluating commonsenseqa : 100%|██████████| 250/250 [4:09:01<00:00, 58.93s/it]Evaluating commonsenseqa : 100%|██████████| 250/250 [4:09:01<00:00, 59.76s/it]
name: commonsenseqa | avg. gen lenth: 324.594 | time: 14942.838659524918s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr gpu04 --master_port 12094 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 4 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s20-rTrue --seed 20 --max-prompt-length 4096 --rationales --num-out-domain 8 6 7 8 9 10 True 4096 4
[2023-09-04 20:31:43,997] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s20-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 8
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o8-tgsm8k-s20-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 4
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 526809.56it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:14<00:14, 14.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  8.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  9.50s/it]
 > number of parameters: 6738415616
[2023-09-04 20:32:05,625] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-04 20:32:05,851] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-04 20:32:05,853] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-04 20:32:05,853] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-04 20:32:05,853] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-04 20:32:05,853] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-04 20:32:05,853] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f3f400>
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-04 20:32:05,854] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-04 20:32:05,855] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-04 20:32:05,855] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/250 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: Let x = the total number of candies Corey has.
x + 8 = the total number of candies Tapanga has.
The equation for the total number of candies is x + (x + 8) = 66
Combining like terms, we get 2x + 8 = 66
Subtracting 8 from both sides, we get 2x = 58
Dividing both sides by 2, we get x = <<29=29>>29, so Corey has 29 candies.
So the final answer is 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: At 5 cents a minute, calling his father cost Freddy 5* 45 = <<5*45=225>>225 cents.
At 25 cents a minute, calling his brother cost Freddy 25 * 31 = <<25*31=775>>775 cents.
Adding the cost of calling his father and brother, we find that Freddy paid a total of 225 + 775 = <<225+775=1000>>1000 cents.
Since each dollar has 100 cents, Freddy paid 1000 / 100 = <<1000/100=10>>10 dollars
So the final answer is 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 8 hours * 3 = <<8*3=24>>24 hours
5.5 * 2 = <<5.5*2=11>>11 hours
24 + 11 = <<24+11=35>>35 hours
35/7 = <<35/7=5>>5 hours
Lawrence would work 5 hours each of the 7 days in a week.
So the final answer is 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: We look first for the total number of books that were sold: 60 + 10 + 20 + 44 + 66 = <<60+10+20+44+66=200>>200 books.
So the total number of books that were not sold is: 800 – 200 = <<800-200=600>>600 books.
So the final answer is 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: Michael sold 2 large birdhouses for $22 each, so he made 2*$22= $<<2*22=44>>44 from large birdhouse sales.
Michael also sold 2 medium birdhouses for $16 each, so he made 2*$16= $<<2*16=32>>32 from medium birdhouse sales.
Michael sold 3 small birdhouses for $7 each, so he made 3*7=$<<3*7=21>>21 from small birdhouse sales.
Since Michael made $44 from large birdhouse sales, $32 from medium birdhouse sales, and $21 for small birdhouse sales, he made $44+$32+$21= $<<44+32+21=97>>97 total this week.
So the final answer is 97

Input: Nalani had two female dogs that were expecting and after a month gave birth to 10 puppies each. She then sold 3/4 of the puppies after they came of age, each at $200. Calculate the total amount of money she received from the sale of the puppies.
Output: If the two expectant dogs gave birth to 10 puppies each, the total number of puppies Nalani had is 10+10= <<10+10=20>>20
When they came of age, Nalani sold 3/4 of the dogs, a total of 3/4*20 = <<3/4*20=15>>15 dogs.
If each dog sold for $200, Nalani received 15*200 = $<<15*200=3000>>3000 from the sale of the dogs.
So the final answer is 3000

Input: Boris has 24 books and he donates a fourth of his books to the library. Cameron has 30 books and he donates a third of his books to the library. After donating their books, how many books in total do Boris and Cameron have together?
Output: Boris donates 24 / 4 = <<24/4=6>>6 books
Then Boris has a total of 24 - 6 = <<24-6=18>>18 books
Cameron donates 30 / 3 = <<30/3=10>>10 books
Then Cameron has a total of 30 - 10 = <<30-10=20>>20 books
Altogether, Boris and Cameron have 18 + 20 = <<18+20=38>>38 books
So the final answer is 38

Input: There are 3 boxes of cereal. One box holds 14 ounces of cereal. Another box holds half the amount of the first box and 5 ounces less than the third box. How much cereal is there in all 3 cereal boxes?
Output: First = <<14=14>>14 oz
Second = (1/2) * 14 = <<(1/2)*14=7>>7 oz
Third = 7 + 5 = <<7+5=12>>12 oz
14 + 7 + 12 = <<14+7+12=33>>33 oz
There are 33 ounces of cereal in those 3 boxes.
So the final answer is 33

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o8-tgsm8k-s20-rTrue-m4096
Evaluating commonsenseqa :   0%|          | 1/250 [00:59<4:05:13, 59.09s/it]Evaluating commonsenseqa :   1%|          | 2/250 [01:57<4:02:06, 58.57s/it]Evaluating commonsenseqa :   1%|          | 3/250 [02:54<3:59:17, 58.13s/it]Evaluating commonsenseqa :   2%|▏         | 4/250 [03:52<3:57:27, 57.92s/it]Evaluating commonsenseqa :   2%|▏         | 5/250 [04:51<3:58:12, 58.34s/it]Evaluating commonsenseqa :   2%|▏         | 6/250 [05:49<3:56:05, 58.05s/it]Evaluating commonsenseqa :   3%|▎         | 7/250 [06:46<3:54:51, 57.99s/it]Evaluating commonsenseqa :   3%|▎         | 8/250 [07:43<3:52:39, 57.69s/it]Evaluating commonsenseqa :   4%|▎         | 9/250 [08:17<3:21:34, 50.19s/it]Evaluating commonsenseqa :   4%|▍         | 10/250 [09:17<3:32:32, 53.13s/it]Evaluating commonsenseqa :   4%|▍         | 11/250 [10:15<3:37:19, 54.56s/it]Evaluating commonsenseqa :   5%|▍         | 12/250 [11:12<3:39:18, 55.29s/it]Evaluating commonsenseqa :   5%|▌         | 13/250 [12:10<3:42:32, 56.34s/it]slurmstepd: error: *** JOB 642094 ON gpu04 CANCELLED AT 2023-09-04T20:44:42 DUE TO TIME LIMIT ***
