WORLD_SIZE=1
MASTER_ADDR=icgpu06
WORLD_SIZE=1
MASTER_ADDR=icgpu06
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 18586 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 1 1 2 3 4 5 True 4096 8
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 19045 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 6 6 7 8 9 10 True 4096 8
[2023-09-06 15:03:22,535] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-06 15:03:22,535] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 1
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o1-tgsm8k-s1-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 8
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Answers already exist, exiting...
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 1234938.80it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 19045 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o7-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 7 6 7 8 9 10 True 4096 8
[2023-09-06 15:03:29,084] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 19045 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 8 6 7 8 9 10 True 4096 8
Loading checkpoint shards:  50%|█████     | 1/2 [00:10<00:10, 10.94s/it][2023-09-06 15:03:36,173] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
Loading checkpoint shards: 100%|██████████| 2/2 [00:14<00:00,  6.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:14<00:00,  7.21s/it]
 > number of parameters: 6738415616
[2023-09-06 15:03:38,568] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-06 15:03:38,786] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-06 15:03:38,788] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-06 15:03:38,788] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-06 15:03:38,788] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-06 15:03:38,788] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-06 15:03:38,788] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-06 15:03:38,788] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-06 15:03:38,788] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-06 15:03:38,788] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-06 15:03:38,788] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-06 15:03:38,788] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-06 15:03:38,788] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554ba358310>
[2023-09-06 15:03:38,788] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-06 15:03:38,788] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-06 15:03:38,788] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-06 15:03:38,788] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-06 15:03:38,788] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-06 15:03:38,789] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-06 15:03:38,790] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-06 15:03:38,790] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-06 15:03:38,790] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-06 15:03:38,790] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-06 15:03:38,790] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-06 15:03:38,790] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-06 15:03:38,790] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-06 15:03:38,790] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-06 15:03:38,790] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/125 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: Mary added a total of 7 stickers/page * 6 pages= <<7*6=42>>42 stickers to the 6 other pages.
In total, Mary added 3 large stickers + 42 stickers = <<3+42=45>>45 stickers to her journal.
Since she started with 89 stickers, she now has 89 - 45 = <<89-45=44>>44 stickers left.
So the final answer is 44

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o1-tgsm8k-s1-rTrue-m4096
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 19045 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o9-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 9 6 7 8 9 10 True 4096 8
[2023-09-06 15:03:42,953] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 19045 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o10-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 10 6 7 8 9 10 True 4096 8
[2023-09-06 15:03:50,009] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 19045 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s10-rTrue --seed 10 --max-prompt-length 4096 --rationales --num-out-domain 6 6 7 8 9 10 True 4096 8
[2023-09-06 15:03:56,820] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 19045 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o7-tgsm8k-s10-rTrue --seed 10 --max-prompt-length 4096 --rationales --num-out-domain 7 6 7 8 9 10 True 4096 8
[2023-09-06 15:04:03,687] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 19045 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s10-rTrue --seed 10 --max-prompt-length 4096 --rationales --num-out-domain 8 6 7 8 9 10 True 4096 8
[2023-09-06 15:04:10,505] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 19045 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o9-tgsm8k-s10-rTrue --seed 10 --max-prompt-length 4096 --rationales --num-out-domain 9 6 7 8 9 10 True 4096 8
[2023-09-06 15:04:17,364] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 19045 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o10-tgsm8k-s10-rTrue --seed 10 --max-prompt-length 4096 --rationales --num-out-domain 10 6 7 8 9 10 True 4096 8
[2023-09-06 15:04:24,248] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 19045 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s20-rTrue --seed 20 --max-prompt-length 4096 --rationales --num-out-domain 6 6 7 8 9 10 True 4096 8
[2023-09-06 15:04:31,044] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 19045 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o7-tgsm8k-s20-rTrue --seed 20 --max-prompt-length 4096 --rationales --num-out-domain 7 6 7 8 9 10 True 4096 8
[2023-09-06 15:04:37,874] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 19045 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s20-rTrue --seed 20 --max-prompt-length 4096 --rationales --num-out-domain 8 6 7 8 9 10 True 4096 8
[2023-09-06 15:04:44,762] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s20-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 8
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o8-tgsm8k-s20-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 8
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 481437.54it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  2.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.27s/it]
 > number of parameters: 6738415616
[2023-09-06 15:04:52,795] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-06 15:04:53,000] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-06 15:04:53,001] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-06 15:04:53,002] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-06 15:04:53,002] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-06 15:04:53,002] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-06 15:04:53,002] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-06 15:04:53,002] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-06 15:04:53,002] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-06 15:04:53,002] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-06 15:04:53,002] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-06 15:04:53,002] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-06 15:04:53,002] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f46490>
[2023-09-06 15:04:53,002] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-06 15:04:53,002] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-06 15:04:53,002] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-06 15:04:53,002] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-06 15:04:53,002] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-06 15:04:53,002] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-06 15:04:53,002] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-06 15:04:53,002] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-06 15:04:53,002] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-06 15:04:53,002] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-06 15:04:53,002] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-06 15:04:53,002] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-06 15:04:53,002] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-06 15:04:53,002] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-06 15:04:53,002] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-06 15:04:53,002] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-06 15:04:53,002] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-06 15:04:53,003] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-06 15:04:53,004] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/125 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: Let x = the total number of candies Corey has.
x + 8 = the total number of candies Tapanga has.
The equation for the total number of candies is x + (x + 8) = 66
Combining like terms, we get 2x + 8 = 66
Subtracting 8 from both sides, we get 2x = 58
Dividing both sides by 2, we get x = <<29=29>>29, so Corey has 29 candies.
So the final answer is 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: At 5 cents a minute, calling his father cost Freddy 5* 45 = <<5*45=225>>225 cents.
At 25 cents a minute, calling his brother cost Freddy 25 * 31 = <<25*31=775>>775 cents.
Adding the cost of calling his father and brother, we find that Freddy paid a total of 225 + 775 = <<225+775=1000>>1000 cents.
Since each dollar has 100 cents, Freddy paid 1000 / 100 = <<1000/100=10>>10 dollars
So the final answer is 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 8 hours * 3 = <<8*3=24>>24 hours
5.5 * 2 = <<5.5*2=11>>11 hours
24 + 11 = <<24+11=35>>35 hours
35/7 = <<35/7=5>>5 hours
Lawrence would work 5 hours each of the 7 days in a week.
So the final answer is 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: We look first for the total number of books that were sold: 60 + 10 + 20 + 44 + 66 = <<60+10+20+44+66=200>>200 books.
So the total number of books that were not sold is: 800 – 200 = <<800-200=600>>600 books.
So the final answer is 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: Michael sold 2 large birdhouses for $22 each, so he made 2*$22= $<<2*22=44>>44 from large birdhouse sales.
Michael also sold 2 medium birdhouses for $16 each, so he made 2*$16= $<<2*16=32>>32 from medium birdhouse sales.
Michael sold 3 small birdhouses for $7 each, so he made 3*7=$<<3*7=21>>21 from small birdhouse sales.
Since Michael made $44 from large birdhouse sales, $32 from medium birdhouse sales, and $21 for small birdhouse sales, he made $44+$32+$21= $<<44+32+21=97>>97 total this week.
So the final answer is 97

Input: Nalani had two female dogs that were expecting and after a month gave birth to 10 puppies each. She then sold 3/4 of the puppies after they came of age, each at $200. Calculate the total amount of money she received from the sale of the puppies.
Output: If the two expectant dogs gave birth to 10 puppies each, the total number of puppies Nalani had is 10+10= <<10+10=20>>20
When they came of age, Nalani sold 3/4 of the dogs, a total of 3/4*20 = <<3/4*20=15>>15 dogs.
If each dog sold for $200, Nalani received 15*200 = $<<15*200=3000>>3000 from the sale of the dogs.
So the final answer is 3000

Input: Boris has 24 books and he donates a fourth of his books to the library. Cameron has 30 books and he donates a third of his books to the library. After donating their books, how many books in total do Boris and Cameron have together?
Output: Boris donates 24 / 4 = <<24/4=6>>6 books
Then Boris has a total of 24 - 6 = <<24-6=18>>18 books
Cameron donates 30 / 3 = <<30/3=10>>10 books
Then Cameron has a total of 30 - 10 = <<30-10=20>>20 books
Altogether, Boris and Cameron have 18 + 20 = <<18+20=38>>38 books
So the final answer is 38

Input: There are 3 boxes of cereal. One box holds 14 ounces of cereal. Another box holds half the amount of the first box and 5 ounces less than the third box. How much cereal is there in all 3 cereal boxes?
Output: First = <<14=14>>14 oz
Second = (1/2) * 14 = <<(1/2)*14=7>>7 oz
Third = 7 + 5 = <<7+5=12>>12 oz
14 + 7 + 12 = <<14+7+12=33>>33 oz
There are 33 ounces of cereal in those 3 boxes.
So the final answer is 33

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o8-tgsm8k-s20-rTrue-m4096
Evaluating commonsenseqa :   1%|          | 1/125 [02:11<4:32:40, 131.94s/it]Evaluating commonsenseqa :   1%|          | 1/125 [03:55<8:05:59, 235.16s/it]Evaluating commonsenseqa :   2%|▏         | 2/125 [04:23<4:29:57, 131.68s/it]Evaluating commonsenseqa :   2%|▏         | 2/125 [07:44<7:55:30, 231.95s/it]Evaluating commonsenseqa :   2%|▏         | 3/125 [06:33<4:26:07, 130.88s/it]Evaluating commonsenseqa :   3%|▎         | 4/125 [08:40<4:20:55, 129.39s/it]Evaluating commonsenseqa :   2%|▏         | 3/125 [11:41<7:56:10, 234.18s/it]Evaluating commonsenseqa :   4%|▍         | 5/125 [10:52<4:20:23, 130.19s/it]Evaluating commonsenseqa :   5%|▍         | 6/125 [13:01<4:17:50, 130.00s/it]Evaluating commonsenseqa :   3%|▎         | 4/125 [15:35<7:51:37, 233.86s/it]Evaluating commonsenseqa :   6%|▌         | 7/125 [15:14<4:17:40, 131.02s/it]Evaluating commonsenseqa :   6%|▋         | 8/125 [17:24<4:14:54, 130.72s/it]Evaluating commonsenseqa :   4%|▍         | 5/125 [19:34<7:51:43, 235.86s/it]Evaluating commonsenseqa :   7%|▋         | 9/125 [19:34<4:12:00, 130.35s/it]Evaluating commonsenseqa :   8%|▊         | 10/125 [21:44<4:09:48, 130.34s/it]Evaluating commonsenseqa :   5%|▍         | 6/125 [23:28<7:46:22, 235.15s/it]Evaluating commonsenseqa :   9%|▉         | 11/125 [23:55<4:07:41, 130.36s/it]Evaluating commonsenseqa :   6%|▌         | 7/125 [27:23<7:42:14, 235.04s/it]Evaluating commonsenseqa :  10%|▉         | 12/125 [26:09<4:07:30, 131.42s/it]Evaluating commonsenseqa :  10%|█         | 13/125 [28:22<4:06:36, 132.11s/it]Evaluating commonsenseqa :   6%|▋         | 8/125 [31:12<7:35:02, 233.36s/it]Evaluating commonsenseqa :  11%|█         | 14/125 [30:30<4:02:05, 130.86s/it]Evaluating commonsenseqa :  12%|█▏        | 15/125 [32:39<3:58:58, 130.35s/it]Evaluating commonsenseqa :   7%|▋         | 9/125 [34:55<7:24:32, 229.94s/it]Evaluating commonsenseqa :  13%|█▎        | 16/125 [34:49<3:56:13, 130.03s/it]Evaluating commonsenseqa :  14%|█▎        | 17/125 [36:58<3:53:45, 129.86s/it]Evaluating commonsenseqa :   8%|▊         | 10/125 [38:50<7:23:57, 231.63s/it]Evaluating commonsenseqa :  14%|█▍        | 18/125 [39:08<3:51:49, 129.99s/it]Evaluating commonsenseqa :  15%|█▌        | 19/125 [41:18<3:49:25, 129.87s/it]Evaluating commonsenseqa :   9%|▉         | 11/125 [42:47<7:22:51, 233.08s/it]Evaluating commonsenseqa :  16%|█▌        | 20/125 [43:28<3:47:10, 129.82s/it]Evaluating commonsenseqa :  10%|▉         | 12/125 [46:42<7:20:09, 233.72s/it]Evaluating commonsenseqa :  17%|█▋        | 21/125 [45:37<3:44:41, 129.63s/it]Evaluating commonsenseqa :  18%|█▊        | 22/125 [47:46<3:42:17, 129.49s/it]Evaluating commonsenseqa :  10%|█         | 13/125 [50:35<7:16:16, 233.72s/it]Evaluating commonsenseqa :  18%|█▊        | 23/125 [49:57<3:40:51, 129.92s/it]Evaluating commonsenseqa :  19%|█▉        | 24/125 [52:06<3:38:22, 129.72s/it]Evaluating commonsenseqa :  11%|█         | 14/125 [54:31<7:13:27, 234.31s/it]Evaluating commonsenseqa :  20%|██        | 25/125 [54:17<3:36:54, 130.14s/it]Evaluating commonsenseqa :  21%|██        | 26/125 [56:29<3:35:27, 130.58s/it]Evaluating commonsenseqa :  12%|█▏        | 15/125 [58:24<7:08:57, 233.98s/it]Evaluating commonsenseqa :  22%|██▏       | 27/125 [58:40<3:33:44, 130.86s/it]Evaluating commonsenseqa :  22%|██▏       | 28/125 [1:00:50<3:31:06, 130.58s/it]Evaluating commonsenseqa :  13%|█▎        | 16/125 [1:02:23<7:07:48, 235.49s/it]Evaluating commonsenseqa :  23%|██▎       | 29/125 [1:02:58<3:27:42, 129.82s/it]Evaluating commonsenseqa :  14%|█▎        | 17/125 [1:06:18<7:03:15, 235.15s/it]Evaluating commonsenseqa :  24%|██▍       | 30/125 [1:05:08<3:25:29, 129.78s/it]Evaluating commonsenseqa :  25%|██▍       | 31/125 [1:07:19<3:23:36, 129.96s/it]Evaluating commonsenseqa :  14%|█▍        | 18/125 [1:10:11<6:58:24, 234.62s/it]Evaluating commonsenseqa :  26%|██▌       | 32/125 [1:09:27<3:20:37, 129.43s/it]Evaluating commonsenseqa :  26%|██▋       | 33/125 [1:11:40<3:20:11, 130.56s/it]Evaluating commonsenseqa :  15%|█▌        | 19/125 [1:14:06<6:54:53, 234.85s/it]Evaluating commonsenseqa :  27%|██▋       | 34/125 [1:13:48<3:17:04, 129.94s/it]Evaluating commonsenseqa :  28%|██▊       | 35/125 [1:15:59<3:15:17, 130.20s/it]Evaluating commonsenseqa :  16%|█▌        | 20/125 [1:18:08<6:54:27, 236.83s/it]Evaluating commonsenseqa :  29%|██▉       | 36/125 [1:18:08<3:12:42, 129.92s/it]Evaluating commonsenseqa :  30%|██▉       | 37/125 [1:20:17<3:09:50, 129.44s/it]Evaluating commonsenseqa :  17%|█▋        | 21/125 [1:22:05<6:50:55, 237.07s/it]Evaluating commonsenseqa :  30%|███       | 38/125 [1:22:26<3:07:23, 129.23s/it]Evaluating commonsenseqa :  31%|███       | 39/125 [1:24:36<3:05:44, 129.59s/it]Evaluating commonsenseqa :  18%|█▊        | 22/125 [1:26:01<6:46:04, 236.55s/it]Evaluating commonsenseqa :  32%|███▏      | 40/125 [1:26:45<3:03:24, 129.46s/it]Evaluating commonsenseqa :  18%|█▊        | 23/125 [1:29:51<6:38:55, 234.66s/it]Evaluating commonsenseqa :  33%|███▎      | 41/125 [1:28:57<3:02:14, 130.17s/it]Evaluating commonsenseqa :  34%|███▎      | 42/125 [1:31:10<3:01:10, 130.97s/it]Evaluating commonsenseqa :  19%|█▉        | 24/125 [1:33:47<6:35:51, 235.17s/it]Evaluating commonsenseqa :  34%|███▍      | 43/125 [1:33:20<2:58:49, 130.84s/it]Evaluating commonsenseqa :  35%|███▌      | 44/125 [1:35:29<2:55:54, 130.30s/it]Evaluating commonsenseqa :  20%|██        | 25/125 [1:37:45<6:32:58, 235.79s/it]Evaluating commonsenseqa :  36%|███▌      | 45/125 [1:37:41<2:54:24, 130.80s/it]Evaluating commonsenseqa :  37%|███▋      | 46/125 [1:39:52<2:52:04, 130.69s/it]Evaluating commonsenseqa :  21%|██        | 26/125 [1:41:39<6:28:15, 235.31s/it]Evaluating commonsenseqa :  38%|███▊      | 47/125 [1:42:02<2:49:32, 130.41s/it]Evaluating commonsenseqa :  22%|██▏       | 27/125 [1:43:45<5:30:38, 202.43s/it]Evaluating commonsenseqa :  38%|███▊      | 48/125 [1:44:13<2:47:43, 130.70s/it]Evaluating commonsenseqa :  39%|███▉      | 49/125 [1:46:23<2:45:14, 130.45s/it]Evaluating commonsenseqa :  22%|██▏       | 28/125 [1:47:40<5:43:03, 212.20s/it]Evaluating commonsenseqa :  40%|████      | 50/125 [1:48:25<2:39:52, 127.90s/it]Evaluating commonsenseqa :  23%|██▎       | 29/125 [1:51:32<5:49:07, 218.20s/it]Evaluating commonsenseqa :  41%|████      | 51/125 [1:50:36<2:38:57, 128.89s/it]Evaluating commonsenseqa :  42%|████▏     | 52/125 [1:52:45<2:36:58, 129.03s/it]Evaluating commonsenseqa :  24%|██▍       | 30/125 [1:55:26<5:53:01, 222.96s/it]Evaluating commonsenseqa :  42%|████▏     | 53/125 [1:54:56<2:35:29, 129.57s/it]Evaluating commonsenseqa :  43%|████▎     | 54/125 [1:57:06<2:33:32, 129.75s/it]Evaluating commonsenseqa :  25%|██▍       | 31/125 [1:59:20<5:54:21, 226.19s/it]Evaluating commonsenseqa :  44%|████▍     | 55/125 [1:59:17<2:31:39, 129.99s/it]Evaluating commonsenseqa :  45%|████▍     | 56/125 [2:01:25<2:29:00, 129.58s/it]Evaluating commonsenseqa :  26%|██▌       | 32/125 [2:03:14<5:54:33, 228.75s/it]Evaluating commonsenseqa :  46%|████▌     | 57/125 [2:03:37<2:27:35, 130.23s/it]Evaluating commonsenseqa :  46%|████▋     | 58/125 [2:05:48<2:25:27, 130.26s/it]Evaluating commonsenseqa :  26%|██▋       | 33/125 [2:07:07<5:52:42, 230.03s/it]Evaluating commonsenseqa :  47%|████▋     | 59/125 [2:07:57<2:23:09, 130.14s/it]Evaluating commonsenseqa :  27%|██▋       | 34/125 [2:11:02<5:51:00, 231.44s/it]Evaluating commonsenseqa :  48%|████▊     | 60/125 [2:10:05<2:20:08, 129.37s/it]Evaluating commonsenseqa :  49%|████▉     | 61/125 [2:12:14<2:17:50, 129.23s/it]Evaluating commonsenseqa :  28%|██▊       | 35/125 [2:14:54<5:47:23, 231.59s/it]Evaluating commonsenseqa :  50%|████▉     | 62/125 [2:14:20<2:14:37, 128.22s/it]Evaluating commonsenseqa :  50%|█████     | 63/125 [2:16:31<2:13:23, 129.09s/it]Evaluating commonsenseqa :  29%|██▉       | 36/125 [2:18:51<5:45:55, 233.20s/it]Evaluating commonsenseqa :  51%|█████     | 64/125 [2:18:44<2:12:35, 130.42s/it]Evaluating commonsenseqa :  52%|█████▏    | 65/125 [2:20:53<2:09:54, 129.91s/it]Evaluating commonsenseqa :  30%|██▉       | 37/125 [2:22:43<5:41:21, 232.74s/it]Evaluating commonsenseqa :  53%|█████▎    | 66/125 [2:23:03<2:07:39, 129.82s/it]Evaluating commonsenseqa :  54%|█████▎    | 67/125 [2:25:12<2:05:23, 129.71s/it]Evaluating commonsenseqa :  30%|███       | 38/125 [2:26:40<5:39:23, 234.06s/it]Evaluating commonsenseqa :  54%|█████▍    | 68/125 [2:27:22<2:03:21, 129.84s/it]Evaluating commonsenseqa :  31%|███       | 39/125 [2:30:32<5:34:48, 233.59s/it]Evaluating commonsenseqa :  55%|█████▌    | 69/125 [2:29:34<2:01:48, 130.51s/it]Evaluating commonsenseqa :  56%|█████▌    | 70/125 [2:31:44<1:59:23, 130.24s/it]Evaluating commonsenseqa :  32%|███▏      | 40/125 [2:34:29<5:32:18, 234.58s/it]Evaluating commonsenseqa :  57%|█████▋    | 71/125 [2:33:53<1:56:57, 129.96s/it]Evaluating commonsenseqa :  58%|█████▊    | 72/125 [2:36:04<1:54:57, 130.14s/it]Evaluating commonsenseqa :  33%|███▎      | 41/125 [2:38:21<5:27:13, 233.74s/it]Evaluating commonsenseqa :  58%|█████▊    | 73/125 [2:38:18<1:53:44, 131.23s/it]Evaluating commonsenseqa :  59%|█████▉    | 74/125 [2:40:28<1:51:25, 131.10s/it]Evaluating commonsenseqa :  34%|███▎      | 42/125 [2:42:12<5:22:03, 232.82s/it]Evaluating commonsenseqa :  60%|██████    | 75/125 [2:42:39<1:49:10, 131.02s/it]Evaluating commonsenseqa :  61%|██████    | 76/125 [2:44:48<1:46:27, 130.37s/it]Evaluating commonsenseqa :  34%|███▍      | 43/125 [2:46:09<5:20:05, 234.21s/it]Evaluating commonsenseqa :  62%|██████▏   | 77/125 [2:46:59<1:44:24, 130.51s/it]Evaluating commonsenseqa :  35%|███▌      | 44/125 [2:49:57<5:13:38, 232.33s/it]Evaluating commonsenseqa :  62%|██████▏   | 78/125 [2:49:10<1:42:20, 130.64s/it]Evaluating commonsenseqa :  63%|██████▎   | 79/125 [2:51:18<1:39:39, 130.00s/it]Evaluating commonsenseqa :  36%|███▌      | 45/125 [2:53:50<5:09:59, 232.50s/it]Evaluating commonsenseqa :  64%|██████▍   | 80/125 [2:53:30<1:37:50, 130.46s/it]Evaluating commonsenseqa :  65%|██████▍   | 81/125 [2:55:41<1:35:50, 130.70s/it]Evaluating commonsenseqa :  37%|███▋      | 46/125 [2:57:47<5:07:49, 233.80s/it]Evaluating commonsenseqa :  66%|██████▌   | 82/125 [2:57:48<1:32:47, 129.48s/it]Evaluating commonsenseqa :  66%|██████▋   | 83/125 [2:59:59<1:30:56, 129.91s/it]Evaluating commonsenseqa :  38%|███▊      | 47/125 [3:01:42<5:04:33, 234.27s/it]Evaluating commonsenseqa :  67%|██████▋   | 84/125 [3:02:07<1:28:24, 129.37s/it]Evaluating commonsenseqa :  68%|██████▊   | 85/125 [3:04:14<1:25:51, 128.79s/it]Evaluating commonsenseqa :  38%|███▊      | 48/125 [3:05:32<4:58:58, 232.97s/it]Evaluating commonsenseqa :  69%|██████▉   | 86/125 [3:06:25<1:24:00, 129.24s/it]Evaluating commonsenseqa :  39%|███▉      | 49/125 [3:09:28<4:56:19, 233.94s/it]Evaluating commonsenseqa :  70%|██████▉   | 87/125 [3:08:31<1:21:21, 128.47s/it]Evaluating commonsenseqa :  70%|███████   | 88/125 [3:10:38<1:18:55, 127.98s/it]Evaluating commonsenseqa :  40%|████      | 50/125 [3:13:16<4:50:02, 232.03s/it]Evaluating commonsenseqa :  71%|███████   | 89/125 [3:12:47<1:16:59, 128.32s/it]Evaluating commonsenseqa :  72%|███████▏  | 90/125 [3:14:56<1:14:51, 128.33s/it]Evaluating commonsenseqa :  41%|████      | 51/125 [3:17:10<4:47:08, 232.82s/it]Evaluating commonsenseqa :  73%|███████▎  | 91/125 [3:17:03<1:12:33, 128.05s/it]Evaluating commonsenseqa :  74%|███████▎  | 92/125 [3:19:13<1:10:46, 128.68s/it]Evaluating commonsenseqa :  42%|████▏     | 52/125 [3:20:59<4:41:49, 231.63s/it]Evaluating commonsenseqa :  74%|███████▍  | 93/125 [3:21:24<1:08:57, 129.28s/it]Evaluating commonsenseqa :  75%|███████▌  | 94/125 [3:23:34<1:06:53, 129.46s/it]Evaluating commonsenseqa :  42%|████▏     | 53/125 [3:24:50<4:37:31, 231.27s/it]Evaluating commonsenseqa :  76%|███████▌  | 95/125 [3:25:43<1:04:46, 129.55s/it]Evaluating commonsenseqa :  43%|████▎     | 54/125 [3:28:45<4:34:59, 232.38s/it]Evaluating commonsenseqa :  77%|███████▋  | 96/125 [3:27:52<1:02:25, 129.17s/it]Evaluating commonsenseqa :  78%|███████▊  | 97/125 [3:29:59<59:57, 128.50s/it]  Evaluating commonsenseqa :  44%|████▍     | 55/125 [3:32:39<4:31:45, 232.94s/it]Evaluating commonsenseqa :  78%|███████▊  | 98/125 [3:32:06<57:42, 128.25s/it]Evaluating commonsenseqa :  79%|███████▉  | 99/125 [3:34:14<55:31, 128.15s/it]Evaluating commonsenseqa :  45%|████▍     | 56/125 [3:36:31<4:27:33, 232.65s/it]Evaluating commonsenseqa :  80%|████████  | 100/125 [3:36:24<53:33, 128.55s/it]Evaluating commonsenseqa :  81%|████████  | 101/125 [3:38:34<51:38, 129.10s/it]Evaluating commonsenseqa :  46%|████▌     | 57/125 [3:40:23<4:23:26, 232.46s/it]Evaluating commonsenseqa :  82%|████████▏ | 102/125 [3:40:44<49:34, 129.31s/it]Evaluating commonsenseqa :  82%|████████▏ | 103/125 [3:42:52<47:13, 128.82s/it]Evaluating commonsenseqa :  46%|████▋     | 58/125 [3:44:15<4:19:16, 232.19s/it]Evaluating commonsenseqa :  83%|████████▎ | 104/125 [3:45:01<45:09, 129.02s/it]Evaluating commonsenseqa :  47%|████▋     | 59/125 [3:48:06<4:15:03, 231.86s/it]Evaluating commonsenseqa :  84%|████████▍ | 105/125 [3:47:08<42:46, 128.31s/it]Evaluating commonsenseqa :  85%|████████▍ | 106/125 [3:49:19<40:55, 129.23s/it]Evaluating commonsenseqa :  48%|████▊     | 60/125 [3:51:56<4:10:46, 231.49s/it]Evaluating commonsenseqa :  86%|████████▌ | 107/125 [3:51:27<38:37, 128.76s/it]Evaluating commonsenseqa :  86%|████████▋ | 108/125 [3:53:39<36:46, 129.80s/it]Evaluating commonsenseqa :  49%|████▉     | 61/125 [3:55:18<3:57:28, 222.63s/it]Evaluating commonsenseqa :  87%|████████▋ | 109/125 [3:55:48<34:33, 129.57s/it]Evaluating commonsenseqa :  88%|████████▊ | 110/125 [3:57:54<32:07, 128.50s/it]Evaluating commonsenseqa :  50%|████▉     | 62/125 [3:59:16<3:58:39, 227.30s/it]Evaluating commonsenseqa :  89%|████████▉ | 111/125 [4:00:05<30:11, 129.37s/it]Evaluating commonsenseqa :  50%|█████     | 63/125 [4:03:08<3:56:11, 228.58s/it]Evaluating commonsenseqa :  90%|████████▉ | 112/125 [4:02:12<27:49, 128.46s/it]Evaluating commonsenseqa :  90%|█████████ | 113/125 [4:04:19<25:36, 128.07s/it]Evaluating commonsenseqa :  51%|█████     | 64/125 [4:07:00<3:53:23, 229.57s/it]Evaluating commonsenseqa :  91%|█████████ | 114/125 [4:06:30<23:38, 128.96s/it]Evaluating commonsenseqa :  92%|█████████▏| 115/125 [4:08:37<21:22, 128.27s/it]Evaluating commonsenseqa :  52%|█████▏    | 65/125 [4:10:52<3:50:12, 230.21s/it]Evaluating commonsenseqa :  93%|█████████▎| 116/125 [4:10:49<19:24, 129.39s/it]Evaluating commonsenseqa :  94%|█████████▎| 117/125 [4:12:58<17:15, 129.39s/it]Evaluating commonsenseqa :  53%|█████▎    | 66/125 [4:14:45<3:47:27, 231.32s/it]Evaluating commonsenseqa :  94%|█████████▍| 118/125 [4:15:06<15:02, 128.94s/it]Evaluating commonsenseqa :  95%|█████████▌| 119/125 [4:17:10<12:45, 127.57s/it]Evaluating commonsenseqa :  54%|█████▎    | 67/125 [4:18:33<3:42:38, 230.33s/it]Evaluating commonsenseqa :  96%|█████████▌| 120/125 [4:19:19<10:39, 127.81s/it]Evaluating commonsenseqa :  54%|█████▍    | 68/125 [4:22:22<3:38:16, 229.76s/it]Evaluating commonsenseqa :  97%|█████████▋| 121/125 [4:21:28<08:33, 128.29s/it]Evaluating commonsenseqa :  98%|█████████▊| 122/125 [4:23:35<06:23, 127.88s/it]Evaluating commonsenseqa :  55%|█████▌    | 69/125 [4:26:17<3:36:00, 231.44s/it]Evaluating commonsenseqa :  98%|█████████▊| 123/125 [4:25:42<04:15, 127.50s/it]Evaluating commonsenseqa :  99%|█████████▉| 124/125 [4:27:55<02:09, 129.37s/it]Evaluating commonsenseqa :  56%|█████▌    | 70/125 [4:30:12<3:33:04, 232.45s/it]Evaluating commonsenseqa : 100%|██████████| 125/125 [4:30:04<00:00, 129.23s/it]Evaluating commonsenseqa : 100%|██████████| 125/125 [4:30:04<00:00, 129.64s/it]
name: commonsenseqa | avg. gen lenth: 342.016 | time: 16206.737360477448s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 19045 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o9-tgsm8k-s20-rTrue --seed 20 --max-prompt-length 4096 --rationales --num-out-domain 9 6 7 8 9 10 True 4096 8
[2023-09-06 19:35:08,310] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o9-tgsm8k-s20-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 9
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o9-tgsm8k-s20-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 8
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 445615.64it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.19s/it]
 > number of parameters: 6738415616
[2023-09-06 19:35:20,408] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-06 19:35:20,611] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-06 19:35:20,612] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-06 19:35:20,613] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-06 19:35:20,613] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-06 19:35:20,613] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-06 19:35:20,613] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-06 19:35:20,613] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-06 19:35:20,613] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-06 19:35:20,613] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-06 19:35:20,613] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-06 19:35:20,613] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-06 19:35:20,613] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f46490>
[2023-09-06 19:35:20,613] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-06 19:35:20,613] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-06 19:35:20,613] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-06 19:35:20,613] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-06 19:35:20,613] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-06 19:35:20,613] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-06 19:35:20,613] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-06 19:35:20,613] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-06 19:35:20,613] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-06 19:35:20,613] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-06 19:35:20,613] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-06 19:35:20,613] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-06 19:35:20,613] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-06 19:35:20,613] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-06 19:35:20,613] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-06 19:35:20,613] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-06 19:35:20,613] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-06 19:35:20,613] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-06 19:35:20,614] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-06 19:35:20,615] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/125 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: Let x = the total number of candies Corey has.
x + 8 = the total number of candies Tapanga has.
The equation for the total number of candies is x + (x + 8) = 66
Combining like terms, we get 2x + 8 = 66
Subtracting 8 from both sides, we get 2x = 58
Dividing both sides by 2, we get x = <<29=29>>29, so Corey has 29 candies.
So the final answer is 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: At 5 cents a minute, calling his father cost Freddy 5* 45 = <<5*45=225>>225 cents.
At 25 cents a minute, calling his brother cost Freddy 25 * 31 = <<25*31=775>>775 cents.
Adding the cost of calling his father and brother, we find that Freddy paid a total of 225 + 775 = <<225+775=1000>>1000 cents.
Since each dollar has 100 cents, Freddy paid 1000 / 100 = <<1000/100=10>>10 dollars
So the final answer is 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 8 hours * 3 = <<8*3=24>>24 hours
5.5 * 2 = <<5.5*2=11>>11 hours
24 + 11 = <<24+11=35>>35 hours
35/7 = <<35/7=5>>5 hours
Lawrence would work 5 hours each of the 7 days in a week.
So the final answer is 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: We look first for the total number of books that were sold: 60 + 10 + 20 + 44 + 66 = <<60+10+20+44+66=200>>200 books.
So the total number of books that were not sold is: 800 – 200 = <<800-200=600>>600 books.
So the final answer is 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: Michael sold 2 large birdhouses for $22 each, so he made 2*$22= $<<2*22=44>>44 from large birdhouse sales.
Michael also sold 2 medium birdhouses for $16 each, so he made 2*$16= $<<2*16=32>>32 from medium birdhouse sales.
Michael sold 3 small birdhouses for $7 each, so he made 3*7=$<<3*7=21>>21 from small birdhouse sales.
Since Michael made $44 from large birdhouse sales, $32 from medium birdhouse sales, and $21 for small birdhouse sales, he made $44+$32+$21= $<<44+32+21=97>>97 total this week.
So the final answer is 97

Input: Nalani had two female dogs that were expecting and after a month gave birth to 10 puppies each. She then sold 3/4 of the puppies after they came of age, each at $200. Calculate the total amount of money she received from the sale of the puppies.
Output: If the two expectant dogs gave birth to 10 puppies each, the total number of puppies Nalani had is 10+10= <<10+10=20>>20
When they came of age, Nalani sold 3/4 of the dogs, a total of 3/4*20 = <<3/4*20=15>>15 dogs.
If each dog sold for $200, Nalani received 15*200 = $<<15*200=3000>>3000 from the sale of the dogs.
So the final answer is 3000

Input: Boris has 24 books and he donates a fourth of his books to the library. Cameron has 30 books and he donates a third of his books to the library. After donating their books, how many books in total do Boris and Cameron have together?
Output: Boris donates 24 / 4 = <<24/4=6>>6 books
Then Boris has a total of 24 - 6 = <<24-6=18>>18 books
Cameron donates 30 / 3 = <<30/3=10>>10 books
Then Cameron has a total of 30 - 10 = <<30-10=20>>20 books
Altogether, Boris and Cameron have 18 + 20 = <<18+20=38>>38 books
So the final answer is 38

Input: There are 3 boxes of cereal. One box holds 14 ounces of cereal. Another box holds half the amount of the first box and 5 ounces less than the third box. How much cereal is there in all 3 cereal boxes?
Output: First = <<14=14>>14 oz
Second = (1/2) * 14 = <<(1/2)*14=7>>7 oz
Third = 7 + 5 = <<7+5=12>>12 oz
14 + 7 + 12 = <<14+7+12=33>>33 oz
There are 33 ounces of cereal in those 3 boxes.
So the final answer is 33

Input: A jug needs 40 cups of water to be full. A custodian at Truman Elementary School has to fill water jugs for 200 students, who drink 10 cups of water in a day. How many water jugs will the custodian fill with cups of water to provide the students with all the water they need in a day?
Output: Since each student needs 10 cups of water per day and there are 200 students, the custodian has to provide 200*10 = <<200*10=2000>>2000 cups of water.
A jug of water needs 40 cups to be full, so 2000 cups of water will fill 2000/40 = <<2000/40=50>>50 jugs
So the final answer is 50

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o9-tgsm8k-s20-rTrue-m4096
Evaluating commonsenseqa :   1%|          | 1/125 [02:02<4:12:31, 122.19s/it]Evaluating commonsenseqa :  57%|█████▋    | 71/125 [4:34:00<3:27:53, 231.00s/it]Evaluating commonsenseqa :   2%|▏         | 2/125 [03:59<4:04:17, 119.17s/it]Evaluating commonsenseqa :   2%|▏         | 3/125 [05:57<4:01:06, 118.58s/it]Evaluating commonsenseqa :  58%|█████▊    | 72/125 [4:37:54<3:24:58, 232.04s/it]Evaluating commonsenseqa :   3%|▎         | 4/125 [07:54<3:58:20, 118.19s/it]Evaluating commonsenseqa :   4%|▍         | 5/125 [09:53<3:56:57, 118.48s/it]Evaluating commonsenseqa :  58%|█████▊    | 73/125 [4:41:49<3:21:56, 233.00s/it]Evaluating commonsenseqa :   5%|▍         | 6/125 [11:54<3:56:42, 119.35s/it]Evaluating commonsenseqa :   6%|▌         | 7/125 [13:53<3:54:03, 119.01s/it]Evaluating commonsenseqa :  59%|█████▉    | 74/125 [4:45:43<3:18:17, 233.28s/it]Evaluating commonsenseqa :   6%|▋         | 8/125 [15:53<3:52:51, 119.41s/it]Evaluating commonsenseqa :   7%|▋         | 9/125 [17:51<3:50:23, 119.16s/it]Evaluating commonsenseqa :  60%|██████    | 75/125 [4:49:41<3:15:35, 234.70s/it]Evaluating commonsenseqa :   8%|▊         | 10/125 [19:48<3:47:06, 118.49s/it]Evaluating commonsenseqa :   9%|▉         | 11/125 [21:46<3:44:27, 118.14s/it]Evaluating commonsenseqa :  61%|██████    | 76/125 [4:53:33<3:10:56, 233.80s/it]Evaluating commonsenseqa :  10%|▉         | 12/125 [23:45<3:43:04, 118.44s/it]Evaluating commonsenseqa :  62%|██████▏   | 77/125 [4:57:23<3:06:06, 232.63s/it]Evaluating commonsenseqa :  10%|█         | 13/125 [25:43<3:41:06, 118.45s/it]Evaluating commonsenseqa :  11%|█         | 14/125 [27:41<3:38:45, 118.25s/it]Evaluating commonsenseqa :  62%|██████▏   | 78/125 [5:01:12<3:01:18, 231.46s/it]Evaluating commonsenseqa :  12%|█▏        | 15/125 [29:38<3:36:12, 117.93s/it]Evaluating commonsenseqa :  13%|█▎        | 16/125 [31:38<3:35:20, 118.54s/it]Evaluating commonsenseqa :  63%|██████▎   | 79/125 [5:05:03<2:57:25, 231.43s/it]Evaluating commonsenseqa :  14%|█▎        | 17/125 [33:35<3:32:13, 117.90s/it]Evaluating commonsenseqa :  14%|█▍        | 18/125 [35:34<3:30:45, 118.18s/it]Evaluating commonsenseqa :  64%|██████▍   | 80/125 [5:08:53<2:53:08, 230.85s/it]Evaluating commonsenseqa :  15%|█▌        | 19/125 [37:30<3:27:42, 117.57s/it]Evaluating commonsenseqa :  16%|█▌        | 20/125 [39:28<3:26:05, 117.76s/it]Evaluating commonsenseqa :  65%|██████▍   | 81/125 [5:12:46<2:49:56, 231.74s/it]Evaluating commonsenseqa :  17%|█▋        | 21/125 [41:26<3:24:04, 117.74s/it]Evaluating commonsenseqa :  18%|█▊        | 22/125 [43:24<3:22:34, 118.00s/it]Evaluating commonsenseqa :  66%|██████▌   | 82/125 [5:16:44<2:47:17, 233.44s/it]Evaluating commonsenseqa :  18%|█▊        | 23/125 [45:22<3:20:43, 118.08s/it]Evaluating commonsenseqa :  19%|█▉        | 24/125 [47:21<3:19:00, 118.22s/it]Evaluating commonsenseqa :  66%|██████▋   | 83/125 [5:20:38<2:43:38, 233.79s/it]Evaluating commonsenseqa :  20%|██        | 25/125 [49:21<3:18:00, 118.80s/it]Evaluating commonsenseqa :  21%|██        | 26/125 [51:23<3:17:40, 119.81s/it]Evaluating commonsenseqa :  67%|██████▋   | 84/125 [5:24:26<2:38:30, 231.96s/it]Evaluating commonsenseqa :  22%|██▏       | 27/125 [53:22<3:14:58, 119.37s/it]Evaluating commonsenseqa :  22%|██▏       | 28/125 [55:20<3:12:40, 119.18s/it]Evaluating commonsenseqa :  68%|██████▊   | 85/125 [5:28:19<2:34:48, 232.21s/it]Evaluating commonsenseqa :  23%|██▎       | 29/125 [57:21<3:11:17, 119.56s/it]Evaluating commonsenseqa :  24%|██▍       | 30/125 [59:18<3:08:03, 118.77s/it]Evaluating commonsenseqa :  69%|██████▉   | 86/125 [5:32:12<2:31:07, 232.50s/it]Evaluating commonsenseqa :  25%|██▍       | 31/125 [1:01:15<3:05:15, 118.25s/it]Evaluating commonsenseqa :  26%|██▌       | 32/125 [1:03:13<3:03:18, 118.27s/it]Evaluating commonsenseqa :  70%|██████▉   | 87/125 [5:36:03<2:26:56, 232.02s/it]Evaluating commonsenseqa :  26%|██▋       | 33/125 [1:05:11<3:01:15, 118.21s/it]Evaluating commonsenseqa :  27%|██▋       | 34/125 [1:07:08<2:58:43, 117.84s/it]Evaluating commonsenseqa :  70%|███████   | 88/125 [5:39:59<2:23:48, 233.19s/it]Evaluating commonsenseqa :  28%|██▊       | 35/125 [1:09:09<2:58:07, 118.75s/it]Evaluating commonsenseqa :  29%|██▉       | 36/125 [1:11:08<2:56:09, 118.76s/it]Evaluating commonsenseqa :  71%|███████   | 89/125 [5:43:48<2:19:11, 232.00s/it]Evaluating commonsenseqa :  30%|██▉       | 37/125 [1:13:06<2:53:57, 118.61s/it]Evaluating commonsenseqa :  30%|███       | 38/125 [1:15:05<2:52:01, 118.64s/it]Evaluating commonsenseqa :  72%|███████▏  | 90/125 [5:47:44<2:15:59, 233.14s/it]Evaluating commonsenseqa :  31%|███       | 39/125 [1:17:04<2:50:13, 118.76s/it]Evaluating commonsenseqa :  32%|███▏      | 40/125 [1:19:03<2:48:16, 118.79s/it]Evaluating commonsenseqa :  73%|███████▎  | 91/125 [5:51:36<2:11:56, 232.84s/it]Evaluating commonsenseqa :  33%|███▎      | 41/125 [1:21:04<2:47:16, 119.48s/it]Evaluating commonsenseqa :  34%|███▎      | 42/125 [1:23:05<2:46:00, 120.00s/it]Evaluating commonsenseqa :  74%|███████▎  | 92/125 [5:55:31<2:08:26, 233.52s/it]Evaluating commonsenseqa :  34%|███▍      | 43/125 [1:25:07<2:44:37, 120.46s/it]Evaluating commonsenseqa :  35%|███▌      | 44/125 [1:27:07<2:42:40, 120.50s/it]Evaluating commonsenseqa :  74%|███████▍  | 93/125 [5:59:28<2:05:09, 234.68s/it]Evaluating commonsenseqa :  36%|███▌      | 45/125 [1:29:06<2:40:04, 120.06s/it]Evaluating commonsenseqa :  37%|███▋      | 46/125 [1:31:05<2:37:32, 119.65s/it]Evaluating commonsenseqa :  75%|███████▌  | 94/125 [6:03:24<2:01:19, 234.82s/it]Evaluating commonsenseqa :  38%|███▊      | 47/125 [1:33:03<2:35:03, 119.28s/it]Evaluating commonsenseqa :  38%|███▊      | 48/125 [1:35:06<2:34:20, 120.27s/it]Evaluating commonsenseqa :  76%|███████▌  | 95/125 [6:07:19<1:57:26, 234.89s/it]Evaluating commonsenseqa :  39%|███▉      | 49/125 [1:37:06<2:32:09, 120.12s/it]Evaluating commonsenseqa :  40%|████      | 50/125 [1:39:06<2:30:11, 120.15s/it]Evaluating commonsenseqa :  77%|███████▋  | 96/125 [6:11:18<1:54:08, 236.16s/it]Evaluating commonsenseqa :  41%|████      | 51/125 [1:41:04<2:27:35, 119.66s/it]Evaluating commonsenseqa :  42%|████▏     | 52/125 [1:43:06<2:26:12, 120.18s/it]Evaluating commonsenseqa :  78%|███████▊  | 97/125 [6:15:11<1:49:45, 235.20s/it]Evaluating commonsenseqa :  42%|████▏     | 53/125 [1:45:03<2:23:17, 119.41s/it]Evaluating commonsenseqa :  43%|████▎     | 54/125 [1:47:05<2:22:15, 120.22s/it]Evaluating commonsenseqa :  78%|███████▊  | 98/125 [6:19:05<1:45:44, 234.97s/it]Evaluating commonsenseqa :  44%|████▍     | 55/125 [1:49:02<2:18:48, 118.98s/it]Evaluating commonsenseqa :  45%|████▍     | 56/125 [1:51:01<2:16:51, 119.00s/it]Evaluating commonsenseqa :  79%|███████▉  | 99/125 [6:23:00<1:41:51, 235.07s/it]Evaluating commonsenseqa :  46%|████▌     | 57/125 [1:52:58<2:14:26, 118.62s/it]Evaluating commonsenseqa :  46%|████▋     | 58/125 [1:54:57<2:12:37, 118.77s/it]Evaluating commonsenseqa :  80%|████████  | 100/125 [6:26:54<1:37:46, 234.66s/it]Evaluating commonsenseqa :  47%|████▋     | 59/125 [1:56:58<2:11:09, 119.23s/it]Evaluating commonsenseqa :  48%|████▊     | 60/125 [1:58:56<2:08:49, 118.91s/it]Evaluating commonsenseqa :  81%|████████  | 101/125 [6:30:50<1:34:02, 235.09s/it]Evaluating commonsenseqa :  49%|████▉     | 61/125 [2:00:52<2:05:54, 118.03s/it]Evaluating commonsenseqa :  50%|████▉     | 62/125 [2:02:54<2:05:20, 119.38s/it]Evaluating commonsenseqa :  82%|████████▏ | 102/125 [6:34:39<1:29:25, 233.27s/it]Evaluating commonsenseqa :  50%|█████     | 63/125 [2:04:54<2:03:27, 119.48s/it]Evaluating commonsenseqa :  51%|█████     | 64/125 [2:06:55<2:01:47, 119.79s/it]Evaluating commonsenseqa :  82%|████████▏ | 103/125 [6:38:40<1:26:20, 235.49s/it]Evaluating commonsenseqa :  52%|█████▏    | 65/125 [2:08:54<1:59:47, 119.79s/it]Evaluating commonsenseqa :  83%|████████▎ | 104/125 [6:42:32<1:22:03, 234.43s/it]Evaluating commonsenseqa :  53%|█████▎    | 66/125 [2:10:54<1:57:51, 119.85s/it]Evaluating commonsenseqa :  54%|█████▎    | 67/125 [2:12:54<1:55:48, 119.79s/it]Evaluating commonsenseqa :  84%|████████▍ | 105/125 [6:46:30<1:18:27, 235.38s/it]Evaluating commonsenseqa :  54%|█████▍    | 68/125 [2:14:56<1:54:25, 120.46s/it]Evaluating commonsenseqa :  55%|█████▌    | 69/125 [2:16:55<1:51:52, 119.86s/it]Evaluating commonsenseqa :  85%|████████▍ | 106/125 [6:50:18<1:13:50, 233.21s/it]Evaluating commonsenseqa :  56%|█████▌    | 70/125 [2:18:54<1:49:43, 119.70s/it]Evaluating commonsenseqa :  57%|█████▋    | 71/125 [2:20:53<1:47:39, 119.62s/it]Evaluating commonsenseqa :  86%|████████▌ | 107/125 [6:53:00<1:03:35, 211.95s/it]Evaluating commonsenseqa :  58%|█████▊    | 72/125 [2:22:52<1:45:24, 119.32s/it]Evaluating commonsenseqa :  58%|█████▊    | 73/125 [2:24:52<1:43:35, 119.53s/it]Evaluating commonsenseqa :  86%|████████▋ | 108/125 [6:56:57<1:02:12, 219.54s/it]Evaluating commonsenseqa :  59%|█████▉    | 74/125 [2:26:52<1:41:36, 119.53s/it]Evaluating commonsenseqa :  60%|██████    | 75/125 [2:28:54<1:40:21, 120.43s/it]Evaluating commonsenseqa :  87%|████████▋ | 109/125 [7:00:49<59:29, 223.12s/it]  Evaluating commonsenseqa :  61%|██████    | 76/125 [2:30:53<1:37:59, 120.00s/it]Evaluating commonsenseqa :  62%|██████▏   | 77/125 [2:32:55<1:36:32, 120.69s/it]Evaluating commonsenseqa :  88%|████████▊ | 110/125 [7:04:43<56:35, 226.39s/it]Evaluating commonsenseqa :  62%|██████▏   | 78/125 [2:34:55<1:34:12, 120.26s/it]Evaluating commonsenseqa :  89%|████████▉ | 111/125 [7:08:35<53:15, 228.23s/it]Evaluating commonsenseqa :  63%|██████▎   | 79/125 [2:36:54<1:32:02, 120.06s/it]Evaluating commonsenseqa :  64%|██████▍   | 80/125 [2:38:52<1:29:29, 119.31s/it]Evaluating commonsenseqa :  90%|████████▉ | 112/125 [7:12:25<49:34, 228.81s/it]Evaluating commonsenseqa :  65%|██████▍   | 81/125 [2:40:52<1:27:45, 119.66s/it]Evaluating commonsenseqa :  66%|██████▌   | 82/125 [2:42:53<1:25:52, 119.84s/it]Evaluating commonsenseqa :  90%|█████████ | 113/125 [7:16:20<46:06, 230.53s/it]Evaluating commonsenseqa :  66%|██████▋   | 83/125 [2:44:51<1:23:32, 119.35s/it]Evaluating commonsenseqa :  67%|██████▋   | 84/125 [2:46:50<1:21:32, 119.33s/it]Evaluating commonsenseqa :  91%|█████████ | 114/125 [7:20:18<42:39, 232.68s/it]Evaluating commonsenseqa :  68%|██████▊   | 85/125 [2:48:51<1:19:50, 119.77s/it]Evaluating commonsenseqa :  69%|██████▉   | 86/125 [2:50:52<1:18:07, 120.19s/it]Evaluating commonsenseqa :  92%|█████████▏| 115/125 [7:24:19<39:11, 235.14s/it]Evaluating commonsenseqa :  70%|██████▉   | 87/125 [2:52:51<1:15:55, 119.87s/it]Evaluating commonsenseqa :  70%|███████   | 88/125 [2:54:49<1:13:37, 119.38s/it]Evaluating commonsenseqa :  93%|█████████▎| 116/125 [7:28:07<34:59, 233.28s/it]Evaluating commonsenseqa :  71%|███████   | 89/125 [2:56:47<1:11:20, 118.91s/it]Evaluating commonsenseqa :  72%|███████▏  | 90/125 [2:58:46<1:09:18, 118.82s/it]Evaluating commonsenseqa :  94%|█████████▎| 117/125 [7:32:08<31:24, 235.57s/it]Evaluating commonsenseqa :  73%|███████▎  | 91/125 [3:00:47<1:07:44, 119.54s/it]Evaluating commonsenseqa :  74%|███████▎  | 92/125 [3:02:46<1:05:39, 119.39s/it]Evaluating commonsenseqa :  94%|█████████▍| 118/125 [7:36:02<27:25, 235.04s/it]Evaluating commonsenseqa :  74%|███████▍  | 93/125 [3:04:46<1:03:41, 119.43s/it]Evaluating commonsenseqa :  75%|███████▌  | 94/125 [3:06:22<58:07, 112.51s/it]  Evaluating commonsenseqa :  95%|█████████▌| 119/125 [7:39:58<23:31, 235.23s/it]Evaluating commonsenseqa :  76%|███████▌  | 95/125 [3:08:21<57:18, 114.63s/it]Evaluating commonsenseqa :  77%|███████▋  | 96/125 [3:10:22<56:16, 116.44s/it]Evaluating commonsenseqa :  96%|█████████▌| 120/125 [7:43:50<19:31, 234.32s/it]Evaluating commonsenseqa :  78%|███████▊  | 97/125 [3:12:23<54:59, 117.82s/it]Evaluating commonsenseqa :  78%|███████▊  | 98/125 [3:14:26<53:44, 119.44s/it]Evaluating commonsenseqa :  97%|█████████▋| 121/125 [7:47:52<15:46, 236.72s/it]Evaluating commonsenseqa :  79%|███████▉  | 99/125 [3:16:26<51:49, 119.58s/it]Evaluating commonsenseqa :  80%|████████  | 100/125 [3:18:25<49:46, 119.45s/it]Evaluating commonsenseqa :  98%|█████████▊| 122/125 [7:51:50<11:50, 236.93s/it]Evaluating commonsenseqa :  81%|████████  | 101/125 [3:20:23<47:36, 119.02s/it]Evaluating commonsenseqa :  82%|████████▏ | 102/125 [3:22:26<46:02, 120.12s/it]Evaluating commonsenseqa :  98%|█████████▊| 123/125 [7:55:48<07:54, 237.23s/it]Evaluating commonsenseqa :  82%|████████▏ | 103/125 [3:24:27<44:09, 120.44s/it]Evaluating commonsenseqa :  83%|████████▎ | 104/125 [3:26:29<42:15, 120.72s/it]Evaluating commonsenseqa :  99%|█████████▉| 124/125 [7:59:40<03:55, 235.72s/it]Evaluating commonsenseqa :  84%|████████▍ | 105/125 [3:28:30<40:19, 120.98s/it]Evaluating commonsenseqa :  85%|████████▍ | 106/125 [3:30:34<38:31, 121.64s/it]Evaluating commonsenseqa : 100%|██████████| 125/125 [8:03:32<00:00, 234.62s/it]Evaluating commonsenseqa : 100%|██████████| 125/125 [8:03:32<00:00, 232.10s/it]
name: commonsenseqa | avg. gen lenth: 309.459 | time: 29013.90417289734s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 18586 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 2 1 2 3 4 5 True 4096 8
[2023-09-06 23:07:18,501] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 18586 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o3-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 3 1 2 3 4 5 True 4096 8
[2023-09-06 23:07:25,181] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 18586 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o4-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 4 1 2 3 4 5 True 4096 8
[2023-09-06 23:07:32,162] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 18586 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o5-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 4096 --rationales --num-out-domain 5 1 2 3 4 5 True 4096 8
[2023-09-06 23:07:38,991] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 18586 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s10-rTrue --seed 10 --max-prompt-length 4096 --rationales --num-out-domain 1 1 2 3 4 5 True 4096 8
[2023-09-06 23:07:45,904] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 18586 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s10-rTrue --seed 10 --max-prompt-length 4096 --rationales --num-out-domain 2 1 2 3 4 5 True 4096 8
[2023-09-06 23:07:52,756] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
Evaluating commonsenseqa :  86%|████████▌ | 107/125 [3:32:34<36:21, 121.17s/it]torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 18586 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o3-tgsm8k-s10-rTrue --seed 10 --max-prompt-length 4096 --rationales --num-out-domain 3 1 2 3 4 5 True 4096 8
[2023-09-06 23:07:59,650] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 18586 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o4-tgsm8k-s10-rTrue --seed 10 --max-prompt-length 4096 --rationales --num-out-domain 4 1 2 3 4 5 True 4096 8
[2023-09-06 23:08:06,629] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
Answers already exist, exiting...
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 18586 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o5-tgsm8k-s10-rTrue --seed 10 --max-prompt-length 4096 --rationales --num-out-domain 5 1 2 3 4 5 True 4096 8
[2023-09-06 23:08:13,559] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o5-tgsm8k-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 5
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o5-tgsm8k-s10-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 8
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 747894.26it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.11s/it]
 > number of parameters: 6738415616
[2023-09-06 23:08:27,184] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-06 23:08:27,394] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-06 23:08:27,396] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-06 23:08:27,396] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-06 23:08:27,396] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-06 23:08:27,396] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-06 23:08:27,396] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f48460>
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-06 23:08:27,397] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-06 23:08:27,398] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-06 23:08:27,398] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-06 23:08:27,398] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-06 23:08:27,398] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-06 23:08:27,398] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-06 23:08:27,398] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-06 23:08:27,398] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-06 23:08:27,398] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-06 23:08:27,398] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-06 23:08:27,398] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-06 23:08:27,398] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-06 23:08:27,398] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-06 23:08:27,398] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-06 23:08:27,398] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-06 23:08:27,398] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-06 23:08:27,398] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-06 23:08:27,398] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-06 23:08:27,398] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-06 23:08:27,398] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-06 23:08:27,398] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-06 23:08:27,398] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-06 23:08:27,398] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-06 23:08:27,398] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-06 23:08:27,398] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-06 23:08:27,398] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-06 23:08:27,398] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-06 23:08:27,398] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-06 23:08:27,398] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-06 23:08:27,398] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-06 23:08:27,399] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-06 23:08:27,399] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-06 23:08:27,399] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/125 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: For the nuts Adam paid 3 * $12 = $<<3*12=36>>36.
And for dried fruits Adam paid 2.5 * $8 = $<<2.5*8=20>>20.
So in total for his purchases Adam paid $36 + $20 = $<<36+20=56>>56.
So the final answer is 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: He spends 60/3=<<60/3=20>>20 minutes warming up
So he spends 60+20=<<60+20=80>>80 minutes at the gym per day
That means he spends 80*3=<<80*3=240>>240 minutes at the gym
So he spends 240/60=<<240/60=4>>4 hours at the gym a week
So the final answer is 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: The cost to fill a tank went up 200*.2=$<<200*.2=40>>40
So it cost 200+40=$<<200+40=240>>240 to fill the tank
That means he now pays 240*2=$<<240*2=480>>480
So the final answer is 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: If the total number of goals scored in the league that season against Barca is 300, the two players scored 20/100*300=<<300*20/100=60>>60 goals.
If the players scored an equal number of goals, each scored 60/2=<<60/2=30>>30 goals.
So the final answer is 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: He drinks 12 * 5 = <<12*5=60>>60 ounces of soda a day
So he drinks 60 + 64 = <<60+64=124>>124 ounces of liquid a day
So in total he drinks 124 * 7 = <<124*7=868>>868 ounces of liquid a week
So the final answer is 868

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o5-tgsm8k-s10-rTrue-m4096
Evaluating commonsenseqa :  86%|████████▋ | 108/125 [3:34:35<34:19, 121.13s/it]Evaluating commonsenseqa :   1%|          | 1/125 [03:04<6:22:18, 184.99s/it]Evaluating commonsenseqa :  87%|████████▋ | 109/125 [3:36:35<32:12, 120.81s/it]Evaluating commonsenseqa :  88%|████████▊ | 110/125 [3:38:36<30:13, 120.91s/it]Evaluating commonsenseqa :   2%|▏         | 2/125 [06:05<6:14:07, 182.50s/it]Evaluating commonsenseqa :  89%|████████▉ | 111/125 [3:40:34<28:02, 120.15s/it]Evaluating commonsenseqa :   2%|▏         | 3/125 [09:06<6:09:40, 181.81s/it]Evaluating commonsenseqa :  90%|████████▉ | 112/125 [3:42:32<25:51, 119.31s/it]Evaluating commonsenseqa :  90%|█████████ | 113/125 [3:44:33<23:57, 119.81s/it]Evaluating commonsenseqa :   3%|▎         | 4/125 [12:11<6:09:22, 183.16s/it]Evaluating commonsenseqa :  91%|█████████ | 114/125 [3:46:35<22:05, 120.52s/it]Evaluating commonsenseqa :   4%|▍         | 5/125 [15:12<6:04:24, 182.20s/it]Evaluating commonsenseqa :  92%|█████████▏| 115/125 [3:48:34<20:00, 120.09s/it]Evaluating commonsenseqa :  93%|█████████▎| 116/125 [3:50:35<18:03, 120.34s/it]Evaluating commonsenseqa :   5%|▍         | 6/125 [18:16<6:02:33, 182.80s/it]Evaluating commonsenseqa :  94%|█████████▎| 117/125 [3:52:38<16:09, 121.21s/it]Evaluating commonsenseqa :   6%|▌         | 7/125 [21:22<6:01:27, 183.79s/it]Evaluating commonsenseqa :  94%|█████████▍| 118/125 [3:54:35<14:00, 120.06s/it]Evaluating commonsenseqa :  95%|█████████▌| 119/125 [3:56:36<12:01, 120.19s/it]Evaluating commonsenseqa :   6%|▋         | 8/125 [24:25<5:57:46, 183.48s/it]Evaluating commonsenseqa :  96%|█████████▌| 120/125 [3:58:35<09:59, 119.90s/it]Evaluating commonsenseqa :   7%|▋         | 9/125 [27:28<5:54:50, 183.54s/it]Evaluating commonsenseqa :  97%|█████████▋| 121/125 [4:00:39<08:04, 121.11s/it]Evaluating commonsenseqa :  98%|█████████▊| 122/125 [4:02:37<06:00, 120.24s/it]Evaluating commonsenseqa :   8%|▊         | 10/125 [30:29<5:50:03, 182.64s/it]Evaluating commonsenseqa :  98%|█████████▊| 123/125 [4:04:36<03:59, 119.93s/it]Evaluating commonsenseqa :  99%|█████████▉| 124/125 [4:06:34<01:59, 119.34s/it]Evaluating commonsenseqa :   9%|▉         | 11/125 [33:31<5:46:46, 182.52s/it]Evaluating commonsenseqa : 100%|██████████| 125/125 [4:08:35<00:00, 119.77s/it]Evaluating commonsenseqa : 100%|██████████| 125/125 [4:08:35<00:00, 119.32s/it]
name: commonsenseqa | avg. gen lenth: 351.691 | time: 14917.868517160416s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 19045 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o10-tgsm8k-s20-rTrue --seed 20 --max-prompt-length 4096 --rationales --num-out-domain 10 6 7 8 9 10 True 4096 8
[2023-09-06 23:44:05,440] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o10-tgsm8k-s20-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 10
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o10-tgsm8k-s20-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 8
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 403395.62it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.22s/it]
 > number of parameters: 6738415616
[2023-09-06 23:44:19,479] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-06 23:44:19,694] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-06 23:44:19,696] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-06 23:44:19,696] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-06 23:44:19,696] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-06 23:44:19,696] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-06 23:44:19,696] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-06 23:44:19,696] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-06 23:44:19,696] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-06 23:44:19,696] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-06 23:44:19,696] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-06 23:44:19,696] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-06 23:44:19,696] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554ba358310>
[2023-09-06 23:44:19,696] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-06 23:44:19,696] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-06 23:44:19,696] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-06 23:44:19,697] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-06 23:44:19,698] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-06 23:44:19,698] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-06 23:44:19,698] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-06 23:44:19,698] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-06 23:44:19,698] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-06 23:44:19,698] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-06 23:44:19,698] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-06 23:44:19,698] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-06 23:44:19,698] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-06 23:44:19,698] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-06 23:44:19,698] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-06 23:44:19,698] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-06 23:44:19,698] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-06 23:44:19,698] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/125 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: Let x = the total number of candies Corey has.
x + 8 = the total number of candies Tapanga has.
The equation for the total number of candies is x + (x + 8) = 66
Combining like terms, we get 2x + 8 = 66
Subtracting 8 from both sides, we get 2x = 58
Dividing both sides by 2, we get x = <<29=29>>29, so Corey has 29 candies.
So the final answer is 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: At 5 cents a minute, calling his father cost Freddy 5* 45 = <<5*45=225>>225 cents.
At 25 cents a minute, calling his brother cost Freddy 25 * 31 = <<25*31=775>>775 cents.
Adding the cost of calling his father and brother, we find that Freddy paid a total of 225 + 775 = <<225+775=1000>>1000 cents.
Since each dollar has 100 cents, Freddy paid 1000 / 100 = <<1000/100=10>>10 dollars
So the final answer is 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 8 hours * 3 = <<8*3=24>>24 hours
5.5 * 2 = <<5.5*2=11>>11 hours
24 + 11 = <<24+11=35>>35 hours
35/7 = <<35/7=5>>5 hours
Lawrence would work 5 hours each of the 7 days in a week.
So the final answer is 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: We look first for the total number of books that were sold: 60 + 10 + 20 + 44 + 66 = <<60+10+20+44+66=200>>200 books.
So the total number of books that were not sold is: 800 – 200 = <<800-200=600>>600 books.
So the final answer is 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: Michael sold 2 large birdhouses for $22 each, so he made 2*$22= $<<2*22=44>>44 from large birdhouse sales.
Michael also sold 2 medium birdhouses for $16 each, so he made 2*$16= $<<2*16=32>>32 from medium birdhouse sales.
Michael sold 3 small birdhouses for $7 each, so he made 3*7=$<<3*7=21>>21 from small birdhouse sales.
Since Michael made $44 from large birdhouse sales, $32 from medium birdhouse sales, and $21 for small birdhouse sales, he made $44+$32+$21= $<<44+32+21=97>>97 total this week.
So the final answer is 97

Input: Nalani had two female dogs that were expecting and after a month gave birth to 10 puppies each. She then sold 3/4 of the puppies after they came of age, each at $200. Calculate the total amount of money she received from the sale of the puppies.
Output: If the two expectant dogs gave birth to 10 puppies each, the total number of puppies Nalani had is 10+10= <<10+10=20>>20
When they came of age, Nalani sold 3/4 of the dogs, a total of 3/4*20 = <<3/4*20=15>>15 dogs.
If each dog sold for $200, Nalani received 15*200 = $<<15*200=3000>>3000 from the sale of the dogs.
So the final answer is 3000

Input: Boris has 24 books and he donates a fourth of his books to the library. Cameron has 30 books and he donates a third of his books to the library. After donating their books, how many books in total do Boris and Cameron have together?
Output: Boris donates 24 / 4 = <<24/4=6>>6 books
Then Boris has a total of 24 - 6 = <<24-6=18>>18 books
Cameron donates 30 / 3 = <<30/3=10>>10 books
Then Cameron has a total of 30 - 10 = <<30-10=20>>20 books
Altogether, Boris and Cameron have 18 + 20 = <<18+20=38>>38 books
So the final answer is 38

Input: There are 3 boxes of cereal. One box holds 14 ounces of cereal. Another box holds half the amount of the first box and 5 ounces less than the third box. How much cereal is there in all 3 cereal boxes?
Output: First = <<14=14>>14 oz
Second = (1/2) * 14 = <<(1/2)*14=7>>7 oz
Third = 7 + 5 = <<7+5=12>>12 oz
14 + 7 + 12 = <<14+7+12=33>>33 oz
There are 33 ounces of cereal in those 3 boxes.
So the final answer is 33

Input: A jug needs 40 cups of water to be full. A custodian at Truman Elementary School has to fill water jugs for 200 students, who drink 10 cups of water in a day. How many water jugs will the custodian fill with cups of water to provide the students with all the water they need in a day?
Output: Since each student needs 10 cups of water per day and there are 200 students, the custodian has to provide 200*10 = <<200*10=2000>>2000 cups of water.
A jug of water needs 40 cups to be full, so 2000 cups of water will fill 2000/40 = <<2000/40=50>>50 jugs
So the final answer is 50

Input: It takes 1 hour for refrigerated dough to come to room temperature.  It takes 15 minutes to shape the dough and 2 hours to proof.  The bread takes 30 minutes to bake and 15 minutes to cool.  If the bakery opens at 6:00 am, what is the latest time the head baker can make it to the store to start working?
Output: It takes 1 hour to bring the dough to room temp and 2 hours to proof the dough so that's 1+2 = <<1+2=3>>3 hours
It takes 15 minutes to shape the dough, 30 minutes to bake and another 15 minutes to cool for a total of 15+30+15 = <<15+30+15=60>>60 minutes
There are 60 minutes in 1 hour so that takes him 60/60 = <<60/60=1>>1 hour
In total it takes 3+1 = <<3+1=4>>4 hours from start to finish to make the bread
If the bakery opens at 6:00 am and it takes 4 hours to prep then the latest the head baker can show up is 6-4 = <<6-4=2>>2:00 am
So the final answer is 2

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o10-tgsm8k-s20-rTrue-m4096
Evaluating commonsenseqa :  10%|▉         | 12/125 [36:31<5:42:27, 181.84s/it]Evaluating commonsenseqa :   1%|          | 1/125 [01:48<3:44:44, 108.74s/it]Evaluating commonsenseqa :   2%|▏         | 2/125 [03:35<3:40:15, 107.44s/it]Evaluating commonsenseqa :  10%|█         | 13/125 [39:31<5:37:59, 181.07s/it]Evaluating commonsenseqa :   2%|▏         | 3/125 [05:22<3:38:33, 107.49s/it]Evaluating commonsenseqa :  11%|█         | 14/125 [42:31<5:34:20, 180.73s/it]Evaluating commonsenseqa :   3%|▎         | 4/125 [07:08<3:35:06, 106.67s/it]Evaluating commonsenseqa :   4%|▍         | 5/125 [08:53<3:32:06, 106.06s/it]Evaluating commonsenseqa :  12%|█▏        | 15/125 [45:34<5:32:49, 181.54s/it]Evaluating commonsenseqa :   5%|▍         | 6/125 [10:40<3:31:00, 106.39s/it]Evaluating commonsenseqa :   6%|▌         | 7/125 [12:27<3:29:46, 106.66s/it]Evaluating commonsenseqa :  13%|█▎        | 16/125 [48:33<5:28:30, 180.83s/it]Evaluating commonsenseqa :   6%|▋         | 8/125 [14:13<3:27:20, 106.33s/it]Evaluating commonsenseqa :  14%|█▎        | 17/125 [51:34<5:25:33, 180.86s/it]Evaluating commonsenseqa :   7%|▋         | 9/125 [15:59<3:25:35, 106.34s/it]Evaluating commonsenseqa :   8%|▊         | 10/125 [17:47<3:24:49, 106.87s/it]Evaluating commonsenseqa :  14%|█▍        | 18/125 [54:32<5:20:59, 180.00s/it]Evaluating commonsenseqa :   9%|▉         | 11/125 [19:35<3:23:30, 107.11s/it]Evaluating commonsenseqa :  10%|▉         | 12/125 [21:23<3:22:21, 107.45s/it]Evaluating commonsenseqa :  15%|█▌        | 19/125 [57:32<5:17:45, 179.86s/it]Evaluating commonsenseqa :  10%|█         | 13/125 [23:11<3:21:04, 107.72s/it]Evaluating commonsenseqa :  16%|█▌        | 20/125 [1:00:34<5:15:55, 180.53s/it]Evaluating commonsenseqa :  11%|█         | 14/125 [24:58<3:18:40, 107.39s/it]Evaluating commonsenseqa :  12%|█▏        | 15/125 [26:44<3:16:16, 107.06s/it]Evaluating commonsenseqa :  17%|█▋        | 21/125 [1:03:35<5:13:02, 180.60s/it]Evaluating commonsenseqa :  13%|█▎        | 16/125 [28:32<3:15:09, 107.43s/it]Evaluating commonsenseqa :  14%|█▎        | 17/125 [30:21<3:14:11, 107.88s/it]Evaluating commonsenseqa :  18%|█▊        | 22/125 [1:06:37<5:10:46, 181.04s/it]Evaluating commonsenseqa :  14%|█▍        | 18/125 [32:09<3:12:27, 107.92s/it]Evaluating commonsenseqa :  18%|█▊        | 23/125 [1:09:42<5:09:50, 182.26s/it]Evaluating commonsenseqa :  15%|█▌        | 19/125 [33:58<3:10:46, 107.98s/it]Evaluating commonsenseqa :  16%|█▌        | 20/125 [35:44<3:08:11, 107.53s/it]Evaluating commonsenseqa :  19%|█▉        | 24/125 [1:12:45<5:07:26, 182.64s/it]Evaluating commonsenseqa :  17%|█▋        | 21/125 [37:30<3:05:42, 107.14s/it]Evaluating commonsenseqa :  18%|█▊        | 22/125 [39:16<3:03:11, 106.71s/it]Evaluating commonsenseqa :  20%|██        | 25/125 [1:15:48<5:04:35, 182.75s/it]Evaluating commonsenseqa :  18%|█▊        | 23/125 [41:03<3:01:28, 106.75s/it]Evaluating commonsenseqa :  19%|█▉        | 24/125 [42:50<2:59:47, 106.80s/it]Evaluating commonsenseqa :  21%|██        | 26/125 [1:18:48<5:00:15, 181.97s/it]Evaluating commonsenseqa :  20%|██        | 25/125 [44:38<2:58:37, 107.18s/it]Evaluating commonsenseqa :  22%|██▏       | 27/125 [1:21:51<4:57:20, 182.05s/it]Evaluating commonsenseqa :  21%|██        | 26/125 [46:25<2:57:06, 107.34s/it]Evaluating commonsenseqa :  22%|██▏       | 27/125 [48:13<2:55:34, 107.50s/it]Evaluating commonsenseqa :  22%|██▏       | 28/125 [1:24:52<4:54:12, 181.99s/it]Evaluating commonsenseqa :  22%|██▏       | 28/125 [50:02<2:54:07, 107.70s/it]Evaluating commonsenseqa :  23%|██▎       | 29/125 [51:47<2:51:04, 106.92s/it]Evaluating commonsenseqa :  23%|██▎       | 29/125 [1:27:55<4:51:12, 182.00s/it]Evaluating commonsenseqa :  24%|██▍       | 30/125 [53:34<2:49:34, 107.10s/it]Evaluating commonsenseqa :  24%|██▍       | 30/125 [1:30:53<4:46:26, 180.91s/it]Evaluating commonsenseqa :  25%|██▍       | 31/125 [55:22<2:48:19, 107.44s/it]Evaluating commonsenseqa :  26%|██▌       | 32/125 [57:11<2:47:12, 107.88s/it]Evaluating commonsenseqa :  25%|██▍       | 31/125 [1:33:53<4:42:52, 180.56s/it]Evaluating commonsenseqa :  26%|██▋       | 33/125 [58:58<2:44:50, 107.51s/it]Evaluating commonsenseqa :  27%|██▋       | 34/125 [1:00:46<2:43:08, 107.57s/it]Evaluating commonsenseqa :  26%|██▌       | 32/125 [1:36:54<4:40:09, 180.75s/it]Evaluating commonsenseqa :  28%|██▊       | 35/125 [1:02:35<2:42:08, 108.10s/it]Evaluating commonsenseqa :  26%|██▋       | 33/125 [1:39:53<4:36:20, 180.22s/it]Evaluating commonsenseqa :  29%|██▉       | 36/125 [1:04:23<2:40:06, 107.94s/it]Evaluating commonsenseqa :  30%|██▉       | 37/125 [1:06:09<2:37:42, 107.53s/it]Evaluating commonsenseqa :  27%|██▋       | 34/125 [1:42:16<4:16:19, 169.01s/it]Evaluating commonsenseqa :  30%|███       | 38/125 [1:07:57<2:36:03, 107.63s/it]Evaluating commonsenseqa :  28%|██▊       | 35/125 [1:45:16<4:18:39, 172.44s/it]Evaluating commonsenseqa :  31%|███       | 39/125 [1:09:42<2:33:17, 106.95s/it]Evaluating commonsenseqa :  32%|███▏      | 40/125 [1:11:27<2:30:44, 106.40s/it]Evaluating commonsenseqa :  29%|██▉       | 36/125 [1:48:15<4:18:42, 174.41s/it]Evaluating commonsenseqa :  33%|███▎      | 41/125 [1:13:15<2:29:33, 106.83s/it]Evaluating commonsenseqa :  34%|███▎      | 42/125 [1:15:01<2:27:14, 106.44s/it]Evaluating commonsenseqa :  30%|██▉       | 37/125 [1:51:17<4:19:05, 176.65s/it]Evaluating commonsenseqa :  34%|███▍      | 43/125 [1:16:47<2:25:26, 106.42s/it]Evaluating commonsenseqa :  30%|███       | 38/125 [1:54:19<4:18:16, 178.12s/it]Evaluating commonsenseqa :  35%|███▌      | 44/125 [1:18:34<2:23:43, 106.46s/it]Evaluating commonsenseqa :  36%|███▌      | 45/125 [1:20:20<2:21:58, 106.49s/it]Evaluating commonsenseqa :  31%|███       | 39/125 [1:57:19<4:16:27, 178.92s/it]Evaluating commonsenseqa :  37%|███▋      | 46/125 [1:22:08<2:20:39, 106.83s/it]Evaluating commonsenseqa :  38%|███▊      | 47/125 [1:23:53<2:18:22, 106.45s/it]Evaluating commonsenseqa :  32%|███▏      | 40/125 [2:00:19<4:13:56, 179.26s/it]Evaluating commonsenseqa :  38%|███▊      | 48/125 [1:25:41<2:17:10, 106.89s/it]Evaluating commonsenseqa :  33%|███▎      | 41/125 [2:03:19<4:10:59, 179.27s/it]Evaluating commonsenseqa :  39%|███▉      | 49/125 [1:27:29<2:15:39, 107.10s/it]Evaluating commonsenseqa :  40%|████      | 50/125 [1:29:16<2:13:53, 107.11s/it]Evaluating commonsenseqa :  34%|███▎      | 42/125 [2:06:22<4:09:44, 180.53s/it]Evaluating commonsenseqa :  41%|████      | 51/125 [1:31:04<2:12:15, 107.23s/it]Evaluating commonsenseqa :  42%|████▏     | 52/125 [1:32:54<2:11:29, 108.08s/it]Evaluating commonsenseqa :  34%|███▍      | 43/125 [2:09:28<4:08:58, 182.17s/it]Evaluating commonsenseqa :  42%|████▏     | 53/125 [1:34:41<2:09:28, 107.90s/it]Evaluating commonsenseqa :  43%|████▎     | 54/125 [1:36:29<2:07:43, 107.94s/it]Evaluating commonsenseqa :  35%|███▌      | 44/125 [2:12:32<4:06:47, 182.81s/it]Evaluating commonsenseqa :  44%|████▍     | 55/125 [1:38:15<2:05:02, 107.17s/it]Evaluating commonsenseqa :  36%|███▌      | 45/125 [2:15:33<4:02:45, 182.07s/it]Evaluating commonsenseqa :  45%|████▍     | 56/125 [1:40:02<2:03:25, 107.32s/it]Evaluating commonsenseqa :  46%|████▌     | 57/125 [1:41:50<2:01:53, 107.56s/it]Evaluating commonsenseqa :  37%|███▋      | 46/125 [2:18:38<4:01:08, 183.14s/it]Evaluating commonsenseqa :  46%|████▋     | 58/125 [1:43:36<1:59:32, 107.05s/it]Evaluating commonsenseqa :  47%|████▋     | 59/125 [1:45:23<1:57:37, 106.94s/it]Evaluating commonsenseqa :  38%|███▊      | 47/125 [2:21:39<3:57:06, 182.40s/it]Evaluating commonsenseqa :  48%|████▊     | 60/125 [1:47:09<1:55:41, 106.79s/it]Evaluating commonsenseqa :  38%|███▊      | 48/125 [2:24:40<3:53:33, 182.00s/it]Evaluating commonsenseqa :  49%|████▉     | 61/125 [1:48:57<1:54:02, 106.91s/it]Evaluating commonsenseqa :  50%|████▉     | 62/125 [1:50:44<1:52:29, 107.13s/it]Evaluating commonsenseqa :  39%|███▉      | 49/125 [2:27:43<3:50:58, 182.34s/it]Evaluating commonsenseqa :  50%|█████     | 63/125 [1:52:31<1:50:41, 107.13s/it]Evaluating commonsenseqa :  51%|█████     | 64/125 [1:54:20<1:49:15, 107.46s/it]Evaluating commonsenseqa :  40%|████      | 50/125 [2:30:43<3:46:50, 181.47s/it]Evaluating commonsenseqa :  52%|█████▏    | 65/125 [1:56:05<1:46:54, 106.90s/it]Evaluating commonsenseqa :  41%|████      | 51/125 [2:33:43<3:43:11, 180.96s/it]Evaluating commonsenseqa :  53%|█████▎    | 66/125 [1:57:52<1:45:13, 107.01s/it]Evaluating commonsenseqa :  54%|█████▎    | 67/125 [1:59:38<1:43:07, 106.68s/it]Evaluating commonsenseqa :  42%|████▏     | 52/125 [2:36:44<3:40:18, 181.07s/it]Evaluating commonsenseqa :  54%|█████▍    | 68/125 [2:01:25<1:41:28, 106.81s/it]Evaluating commonsenseqa :  55%|█████▌    | 69/125 [2:03:13<1:39:54, 107.05s/it]Evaluating commonsenseqa :  42%|████▏     | 53/125 [2:39:44<3:36:53, 180.75s/it]Evaluating commonsenseqa :  56%|█████▌    | 70/125 [2:05:00<1:38:10, 107.10s/it]Evaluating commonsenseqa :  57%|█████▋    | 71/125 [2:06:46<1:36:03, 106.72s/it]Evaluating commonsenseqa :  43%|████▎     | 54/125 [2:42:43<3:33:24, 180.34s/it]Evaluating commonsenseqa :  58%|█████▊    | 72/125 [2:08:32<1:33:59, 106.40s/it]Evaluating commonsenseqa :  44%|████▍     | 55/125 [2:45:42<3:29:56, 179.95s/it]Evaluating commonsenseqa :  58%|█████▊    | 73/125 [2:10:19<1:32:32, 106.78s/it]Evaluating commonsenseqa :  59%|█████▉    | 74/125 [2:12:09<1:31:25, 107.57s/it]Evaluating commonsenseqa :  45%|████▍     | 56/125 [2:48:41<3:26:23, 179.47s/it]Evaluating commonsenseqa :  60%|██████    | 75/125 [2:13:59<1:30:10, 108.22s/it]Evaluating commonsenseqa :  61%|██████    | 76/125 [2:15:44<1:27:40, 107.37s/it]Evaluating commonsenseqa :  46%|████▌     | 57/125 [2:51:43<3:24:28, 180.42s/it]Evaluating commonsenseqa :  62%|██████▏   | 77/125 [2:17:32<1:26:05, 107.61s/it]Evaluating commonsenseqa :  46%|████▋     | 58/125 [2:54:45<3:21:53, 180.80s/it]Evaluating commonsenseqa :  62%|██████▏   | 78/125 [2:19:19<1:24:02, 107.28s/it]Evaluating commonsenseqa :  63%|██████▎   | 79/125 [2:21:06<1:22:12, 107.22s/it]Evaluating commonsenseqa :  47%|████▋     | 59/125 [2:57:43<3:17:58, 179.97s/it]Evaluating commonsenseqa :  64%|██████▍   | 80/125 [2:22:52<1:20:13, 106.97s/it]Evaluating commonsenseqa :  65%|██████▍   | 81/125 [2:24:37<1:17:59, 106.36s/it]Evaluating commonsenseqa :  48%|████▊     | 60/125 [3:00:44<3:15:09, 180.15s/it]Evaluating commonsenseqa :  66%|██████▌   | 82/125 [2:26:25<1:16:36, 106.90s/it]Evaluating commonsenseqa :  49%|████▉     | 61/125 [3:03:41<3:11:14, 179.28s/it]Evaluating commonsenseqa :  66%|██████▋   | 83/125 [2:28:11<1:14:40, 106.67s/it]Evaluating commonsenseqa :  67%|██████▋   | 84/125 [2:29:57<1:12:46, 106.49s/it]Evaluating commonsenseqa :  50%|████▉     | 62/125 [3:06:43<3:09:07, 180.11s/it]Evaluating commonsenseqa :  68%|██████▊   | 85/125 [2:31:45<1:11:14, 106.87s/it]Evaluating commonsenseqa :  69%|██████▉   | 86/125 [2:33:32<1:09:22, 106.73s/it]Evaluating commonsenseqa :  50%|█████     | 63/125 [3:09:46<3:06:57, 180.92s/it]Evaluating commonsenseqa :  70%|██████▉   | 87/125 [2:35:18<1:07:30, 106.59s/it]Evaluating commonsenseqa :  51%|█████     | 64/125 [3:12:50<3:04:58, 181.94s/it]Evaluating commonsenseqa :  70%|███████   | 88/125 [2:37:05<1:05:53, 106.85s/it]Evaluating commonsenseqa :  71%|███████   | 89/125 [2:38:53<1:04:13, 107.03s/it]Evaluating commonsenseqa :  52%|█████▏    | 65/125 [3:15:50<3:01:21, 181.35s/it]Evaluating commonsenseqa :  72%|███████▏  | 90/125 [2:40:42<1:02:47, 107.65s/it]Evaluating commonsenseqa :  73%|███████▎  | 91/125 [2:42:30<1:01:08, 107.90s/it]Evaluating commonsenseqa :  53%|█████▎    | 66/125 [3:18:54<2:59:03, 182.10s/it]Evaluating commonsenseqa :  74%|███████▎  | 92/125 [2:44:17<59:07, 107.50s/it]  Evaluating commonsenseqa :  74%|███████▍  | 93/125 [2:46:04<57:16, 107.40s/it]Evaluating commonsenseqa :  54%|█████▎    | 67/125 [3:21:58<2:56:40, 182.77s/it]Evaluating commonsenseqa :  75%|███████▌  | 94/125 [2:47:51<55:23, 107.22s/it]Evaluating commonsenseqa :  54%|█████▍    | 68/125 [3:24:59<2:53:08, 182.25s/it]Evaluating commonsenseqa :  76%|███████▌  | 95/125 [2:49:38<53:39, 107.33s/it]Evaluating commonsenseqa :  77%|███████▋  | 96/125 [2:51:27<52:07, 107.83s/it]Evaluating commonsenseqa :  55%|█████▌    | 69/125 [3:28:03<2:50:25, 182.61s/it]Evaluating commonsenseqa :  78%|███████▊  | 97/125 [2:53:15<50:14, 107.66s/it]Evaluating commonsenseqa :  78%|███████▊  | 98/125 [2:55:02<48:24, 107.59s/it]Evaluating commonsenseqa :  56%|█████▌    | 70/125 [3:31:03<2:46:51, 182.02s/it]Evaluating commonsenseqa :  79%|███████▉  | 99/125 [2:56:50<46:41, 107.74s/it]Evaluating commonsenseqa :  57%|█████▋    | 71/125 [3:34:07<2:44:13, 182.48s/it]Evaluating commonsenseqa :  80%|████████  | 100/125 [2:58:35<44:32, 106.89s/it]Evaluating commonsenseqa :  81%|████████  | 101/125 [3:00:24<42:56, 107.36s/it]Evaluating commonsenseqa :  58%|█████▊    | 72/125 [3:37:07<2:40:33, 181.77s/it]Evaluating commonsenseqa :  82%|████████▏ | 102/125 [3:02:11<41:13, 107.53s/it]Evaluating commonsenseqa :  82%|████████▏ | 103/125 [3:03:57<39:14, 107.03s/it]Evaluating commonsenseqa :  58%|█████▊    | 73/125 [3:40:08<2:37:23, 181.61s/it]Evaluating commonsenseqa :  83%|████████▎ | 104/125 [3:05:43<37:21, 106.76s/it]Evaluating commonsenseqa :  59%|█████▉    | 74/125 [3:43:06<2:33:30, 180.60s/it]Evaluating commonsenseqa :  84%|████████▍ | 105/125 [3:07:30<35:35, 106.80s/it]Evaluating commonsenseqa :  85%|████████▍ | 106/125 [3:09:16<33:44, 106.55s/it]Evaluating commonsenseqa :  60%|██████    | 75/125 [3:46:06<2:30:18, 180.38s/it]Evaluating commonsenseqa :  86%|████████▌ | 107/125 [3:11:02<31:54, 106.36s/it]Evaluating commonsenseqa :  86%|████████▋ | 108/125 [3:12:51<30:21, 107.13s/it]Evaluating commonsenseqa :  61%|██████    | 76/125 [3:49:07<2:27:17, 180.35s/it]Evaluating commonsenseqa :  87%|████████▋ | 109/125 [3:14:39<28:36, 107.27s/it]Evaluating commonsenseqa :  62%|██████▏   | 77/125 [3:52:06<2:24:01, 180.03s/it]Evaluating commonsenseqa :  88%|████████▊ | 110/125 [3:16:25<26:44, 106.95s/it]Evaluating commonsenseqa :  89%|████████▉ | 111/125 [3:18:15<25:09, 107.79s/it]Evaluating commonsenseqa :  62%|██████▏   | 78/125 [3:55:04<2:20:39, 179.57s/it]Evaluating commonsenseqa :  90%|████████▉ | 112/125 [3:20:00<23:12, 107.08s/it]Evaluating commonsenseqa :  90%|█████████ | 113/125 [3:21:45<21:17, 106.43s/it]Evaluating commonsenseqa :  63%|██████▎   | 79/125 [3:58:07<2:18:25, 180.55s/it]Evaluating commonsenseqa :  91%|█████████ | 114/125 [3:23:33<19:37, 107.01s/it]Evaluating commonsenseqa :  64%|██████▍   | 80/125 [4:01:06<2:15:05, 180.11s/it]Evaluating commonsenseqa :  92%|█████████▏| 115/125 [3:25:21<17:51, 107.13s/it]Evaluating commonsenseqa :  93%|█████████▎| 116/125 [3:27:07<16:01, 106.86s/it]Evaluating commonsenseqa :  65%|██████▍   | 81/125 [4:04:08<2:12:25, 180.58s/it]Evaluating commonsenseqa :  94%|█████████▎| 117/125 [3:28:53<14:11, 106.44s/it]Evaluating commonsenseqa :  94%|█████████▍| 118/125 [3:30:41<12:29, 107.09s/it]Evaluating commonsenseqa :  66%|██████▌   | 82/125 [4:07:12<2:10:07, 181.58s/it]Evaluating commonsenseqa :  95%|█████████▌| 119/125 [3:32:29<10:43, 107.21s/it]Evaluating commonsenseqa :  96%|█████████▌| 120/125 [3:34:17<08:57, 107.60s/it]Evaluating commonsenseqa :  66%|██████▋   | 83/125 [4:10:17<2:07:49, 182.61s/it]Evaluating commonsenseqa :  97%|█████████▋| 121/125 [3:36:06<07:12, 108.09s/it]Evaluating commonsenseqa :  67%|██████▋   | 84/125 [4:13:17<2:04:13, 181.79s/it]Evaluating commonsenseqa :  98%|█████████▊| 122/125 [3:37:54<05:23, 107.88s/it]Evaluating commonsenseqa :  98%|█████████▊| 123/125 [3:39:42<03:35, 107.90s/it]Evaluating commonsenseqa :  68%|██████▊   | 85/125 [4:16:18<2:01:05, 181.63s/it]Evaluating commonsenseqa :  99%|█████████▉| 124/125 [3:41:28<01:47, 107.39s/it]Evaluating commonsenseqa : 100%|██████████| 125/125 [3:43:13<00:00, 106.85s/it]Evaluating commonsenseqa : 100%|██████████| 125/125 [3:43:13<00:00, 107.15s/it]
name: commonsenseqa | avg. gen lenth: 369.58 | time: 13396.416607379913s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 19045 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s30-rTrue --seed 30 --max-prompt-length 4096 --rationales --num-out-domain 6 6 7 8 9 10 True 4096 8
[2023-09-07 03:27:40,948] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s30-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 6
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o6-tgsm8k-s30-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 8
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 598720.92it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Evaluating commonsenseqa :  69%|██████▉   | 86/125 [4:19:18<1:57:45, 181.18s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:10<00:10, 10.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:14<00:00,  6.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:14<00:00,  7.13s/it]
 > number of parameters: 6738415616
[2023-09-07 03:27:56,851] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-07 03:27:57,058] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-07 03:27:57,059] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-07 03:27:57,059] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-07 03:27:57,059] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-07 03:27:57,059] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-07 03:27:57,059] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554ba358310>
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-07 03:27:57,060] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-07 03:27:57,061] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-07 03:27:57,061] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/125 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: The car-rental agency charges $30/day for a car, or $190 for the first week for a rental that lasts an entire week or longer. Jennie rented a car for 11 days. How much, in dollars, did she pay for the rental?
Output: The first 7 days were $190.
There were 11-7=<<11-7=4>>4 days left.
The additional 4 days were 4*30=<<4*30=120>>120.
And 190+120=<<190+120=310>>310.
So the final answer is 310

Input: A hurricane is approaching the southern coast of Texas, and a rancher is planning to move 400 head of cattle 60 miles to higher ground to protect them from possible inland flooding that might occur.  His animal transport truck holds 20 head of cattle.  Traveling at 60 miles per hour, what is the total driving time, in hours, it will take to transport all of his cattle to higher ground?
Output: Given the limited capacity of his transport vehicle (20 head of cattle), the 400 head of cattle will require 400/20=<<400/20=20>>20 trips using his transport vehicle.
Traveling to the site at 60 mph for 60 miles it will take 60/60=<<60/60=1>>1 hour to travel one-way.
Since each trip requires driving to and returning from the relocation site, each complete round trip will take 2*1=<<2*1=2>>2 hours.
Thus, 20 complete trips will take 20*2=<<20*2=40>>40 hours of driving time.
So the final answer is 40

Input: Jason has a carriage house that he rents out.  He’s charging $50.00 per day or $500.00 for 14 days.  Eric wants to rent the house for 20 days.  How much will it cost him?
Output: He wants to rent for 20 days and there is a deal if you rent for 14 days so that leaves 20-14 = <<20-14=6>>6 individual days
Each individual day is $50.00 and he will have 6 individual days for a total of 50*6 = $<<50*6=300.00>>300.00
14 days costs $500.00 and 6 days costs $300.00 for a total of 500+300 = $800.00
So the final answer is 800

Input: Melissa works on a poultry farm. She drives to town twice each month to buy supplies. If it takes her 3 hours to drive to town and back, how many hours does Melissa spend driving in a year?
Output: Melissa spends 2x3=<<2*3=6>>6 hours driving each month.
Since there are 12 months in a year, she spends 6x12=<<6*12=72>>72 hours driving each year.
So the final answer is 72

Input: The ratio of boys to girls in a family is 5:7. The total number of children in the family is 180. If the boys are given $3900 to share, how much money does each boy receive?
Output: The total ratio representing the number of children in the family is 5+7 = <<5+7=12>>12
From the total ratio of children in the family, 5/12 represent the number of boys, meaning that the number of boys in the family is 5/12*180 = <<5/12*180=75>>75
If the boys are given $3900 to share, each boy receives $3900/75 = $<<3900/75=52>>52
So the final answer is 52

Input: Josephine receives a bill from the hospital for 5000$.  50 percent of the bill is for medication.  25 percent of the remaining bill is for overnight stays, and 175$ is for food.  The rest of the bill is for the ambulance ride.  How much did the ambulance ride cost?
Output: Medication:5000(.50)=2500
Overnight Stays:2500(.25)=625
2500-625=<<2500-625=1875>>1875
Food:1875-175=<<1875-175=1700>>1700$
Ambulance ride:1700$
So the final answer is 1700

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o6-tgsm8k-s30-rTrue-m4096
Evaluating commonsenseqa :   1%|          | 1/125 [02:42<5:35:29, 162.34s/it]Evaluating commonsenseqa :  70%|██████▉   | 87/125 [4:22:16<1:54:04, 180.11s/it]Evaluating commonsenseqa :   2%|▏         | 2/125 [05:23<5:31:14, 161.58s/it]Evaluating commonsenseqa :  70%|███████   | 88/125 [4:25:16<1:51:04, 180.12s/it]Evaluating commonsenseqa :   2%|▏         | 3/125 [08:01<5:25:37, 160.15s/it]Evaluating commonsenseqa :  71%|███████   | 89/125 [4:28:15<1:47:55, 179.88s/it]Evaluating commonsenseqa :   3%|▎         | 4/125 [10:44<5:25:03, 161.19s/it]Evaluating commonsenseqa :  72%|███████▏  | 90/125 [4:31:17<1:45:14, 180.41s/it]Evaluating commonsenseqa :   4%|▍         | 5/125 [13:25<5:22:29, 161.24s/it]Evaluating commonsenseqa :  73%|███████▎  | 91/125 [4:34:15<1:41:49, 179.70s/it]Evaluating commonsenseqa :   5%|▍         | 6/125 [16:07<5:19:46, 161.24s/it]Evaluating commonsenseqa :  74%|███████▎  | 92/125 [4:37:12<1:38:28, 179.04s/it]Evaluating commonsenseqa :   6%|▌         | 7/125 [18:46<5:15:38, 160.50s/it]Evaluating commonsenseqa :  74%|███████▍  | 93/125 [4:40:19<1:36:44, 181.39s/it]Evaluating commonsenseqa :   6%|▋         | 8/125 [21:25<5:12:12, 160.11s/it]Evaluating commonsenseqa :  75%|███████▌  | 94/125 [4:43:22<1:33:58, 181.87s/it]Evaluating commonsenseqa :   7%|▋         | 9/125 [24:07<5:10:27, 160.58s/it]Evaluating commonsenseqa :   8%|▊         | 10/125 [26:49<5:08:40, 161.05s/it]Evaluating commonsenseqa :  76%|███████▌  | 95/125 [4:46:21<1:30:31, 181.05s/it]Evaluating commonsenseqa :   9%|▉         | 11/125 [29:30<5:06:17, 161.20s/it]Evaluating commonsenseqa :  77%|███████▋  | 96/125 [4:49:26<1:28:00, 182.09s/it]Evaluating commonsenseqa :  10%|▉         | 12/125 [32:09<5:02:17, 160.51s/it]Evaluating commonsenseqa :  78%|███████▊  | 97/125 [4:52:26<1:24:42, 181.53s/it]Evaluating commonsenseqa :  10%|█         | 13/125 [34:51<5:00:37, 161.05s/it]Evaluating commonsenseqa :  78%|███████▊  | 98/125 [4:55:30<1:22:01, 182.29s/it]Evaluating commonsenseqa :  11%|█         | 14/125 [37:30<4:56:43, 160.39s/it]Evaluating commonsenseqa :  79%|███████▉  | 99/125 [4:58:32<1:18:57, 182.21s/it]Evaluating commonsenseqa :  12%|█▏        | 15/125 [40:13<4:55:11, 161.02s/it]Evaluating commonsenseqa :  80%|████████  | 100/125 [5:01:32<1:15:37, 181.50s/it]Evaluating commonsenseqa :  13%|█▎        | 16/125 [42:53<4:52:01, 160.75s/it]Evaluating commonsenseqa :  81%|████████  | 101/125 [5:04:29<1:12:02, 180.09s/it]Evaluating commonsenseqa :  14%|█▎        | 17/125 [45:30<4:47:15, 159.58s/it]Evaluating commonsenseqa :  82%|████████▏ | 102/125 [5:07:27<1:08:47, 179.45s/it]Evaluating commonsenseqa :  14%|█▍        | 18/125 [48:09<4:44:10, 159.35s/it]Evaluating commonsenseqa :  15%|█▌        | 19/125 [50:51<4:43:11, 160.30s/it]Evaluating commonsenseqa :  82%|████████▏ | 103/125 [5:10:25<1:05:42, 179.19s/it]Evaluating commonsenseqa :  16%|█▌        | 20/125 [53:29<4:39:16, 159.59s/it]Evaluating commonsenseqa :  83%|████████▎ | 104/125 [5:13:25<1:02:45, 179.33s/it]Evaluating commonsenseqa :  17%|█▋        | 21/125 [56:14<4:39:39, 161.35s/it]Evaluating commonsenseqa :  84%|████████▍ | 105/125 [5:16:28<1:00:09, 180.45s/it]Evaluating commonsenseqa :  18%|█▊        | 22/125 [58:55<4:36:35, 161.12s/it]Evaluating commonsenseqa :  85%|████████▍ | 106/125 [5:19:27<57:00, 180.03s/it]  Evaluating commonsenseqa :  18%|█▊        | 23/125 [1:01:32<4:31:56, 159.97s/it]Evaluating commonsenseqa :  86%|████████▌ | 107/125 [5:22:25<53:50, 179.49s/it]Evaluating commonsenseqa :  19%|█▉        | 24/125 [1:04:15<4:30:37, 160.77s/it]Evaluating commonsenseqa :  86%|████████▋ | 108/125 [5:25:29<51:10, 180.64s/it]Evaluating commonsenseqa :  20%|██        | 25/125 [1:06:55<4:27:38, 160.58s/it]Evaluating commonsenseqa :  87%|████████▋ | 109/125 [5:28:29<48:08, 180.52s/it]Evaluating commonsenseqa :  21%|██        | 26/125 [1:09:39<4:26:41, 161.63s/it]Evaluating commonsenseqa :  88%|████████▊ | 110/125 [5:31:25<44:48, 179.23s/it]Evaluating commonsenseqa :  22%|██▏       | 27/125 [1:12:18<4:22:31, 160.73s/it]Evaluating commonsenseqa :  89%|████████▉ | 111/125 [5:34:26<41:57, 179.81s/it]Evaluating commonsenseqa :  22%|██▏       | 28/125 [1:14:59<4:20:04, 160.87s/it]Evaluating commonsenseqa :  23%|██▎       | 29/125 [1:17:41<4:18:03, 161.29s/it]Evaluating commonsenseqa :  90%|████████▉ | 112/125 [5:37:26<38:56, 179.72s/it]Evaluating commonsenseqa :  24%|██▍       | 30/125 [1:20:21<4:14:25, 160.68s/it]Evaluating commonsenseqa :  90%|█████████ | 113/125 [5:40:32<36:19, 181.66s/it]Evaluating commonsenseqa :  25%|██▍       | 31/125 [1:22:58<4:09:59, 159.57s/it]Evaluating commonsenseqa :  91%|█████████ | 114/125 [5:43:35<33:21, 182.00s/it]Evaluating commonsenseqa :  26%|██▌       | 32/125 [1:25:36<4:06:39, 159.13s/it]Evaluating commonsenseqa :  92%|█████████▏| 115/125 [5:46:34<30:12, 181.29s/it]Evaluating commonsenseqa :  26%|██▋       | 33/125 [1:28:17<4:04:53, 159.71s/it]Evaluating commonsenseqa :  93%|█████████▎| 116/125 [5:49:35<27:09, 181.08s/it]Evaluating commonsenseqa :  27%|██▋       | 34/125 [1:30:57<4:02:34, 159.94s/it]Evaluating commonsenseqa :  94%|█████████▎| 117/125 [5:52:37<24:10, 181.30s/it]Evaluating commonsenseqa :  28%|██▊       | 35/125 [1:33:38<4:00:25, 160.29s/it]Evaluating commonsenseqa :  94%|█████████▍| 118/125 [5:55:42<21:16, 182.40s/it]Evaluating commonsenseqa :  29%|██▉       | 36/125 [1:36:16<3:56:25, 159.39s/it]Evaluating commonsenseqa :  30%|██▉       | 37/125 [1:38:52<3:52:34, 158.57s/it]Evaluating commonsenseqa :  95%|█████████▌| 119/125 [5:58:44<18:13, 182.31s/it]Evaluating commonsenseqa :  30%|███       | 38/125 [1:41:35<3:51:41, 159.79s/it]Evaluating commonsenseqa :  96%|█████████▌| 120/125 [6:01:47<15:13, 182.66s/it]Evaluating commonsenseqa :  31%|███       | 39/125 [1:44:13<3:48:17, 159.27s/it]Evaluating commonsenseqa :  97%|█████████▋| 121/125 [6:04:55<12:16, 184.23s/it]Evaluating commonsenseqa :  32%|███▏      | 40/125 [1:46:55<3:46:45, 160.07s/it]Evaluating commonsenseqa :  98%|█████████▊| 122/125 [6:07:59<09:12, 184.11s/it]Evaluating commonsenseqa :  33%|███▎      | 41/125 [1:49:31<3:42:36, 159.00s/it]Evaluating commonsenseqa :  98%|█████████▊| 123/125 [6:11:04<06:08, 184.44s/it]Evaluating commonsenseqa :  34%|███▎      | 42/125 [1:52:14<3:41:31, 160.14s/it]Evaluating commonsenseqa :  99%|█████████▉| 124/125 [6:14:06<03:03, 183.56s/it]Evaluating commonsenseqa :  34%|███▍      | 43/125 [1:54:54<3:38:44, 160.05s/it]Evaluating commonsenseqa :  35%|███▌      | 44/125 [1:57:34<3:35:52, 159.91s/it]Evaluating commonsenseqa : 100%|██████████| 125/125 [6:17:07<00:00, 182.77s/it]Evaluating commonsenseqa : 100%|██████████| 125/125 [6:17:07<00:00, 181.02s/it]
name: commonsenseqa | avg. gen lenth: 332.685 | time: 22628.94637656212s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 18586 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s20-rTrue --seed 20 --max-prompt-length 4096 --rationales --num-out-domain 1 1 2 3 4 5 True 4096 8
[2023-09-07 05:25:43,582] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s20-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 1
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o1-tgsm8k-s20-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 8
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 1245555.61it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:10<00:10, 10.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.80s/it]
 > number of parameters: 6738415616
[2023-09-07 05:25:58,546] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-07 05:25:58,752] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-07 05:25:58,754] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-07 05:25:58,754] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-07 05:25:58,754] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-07 05:25:58,754] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-07 05:25:58,754] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5ef0310>
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-07 05:25:58,755] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-07 05:25:58,756] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-07 05:25:58,756] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-07 05:25:58,756] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-07 05:25:58,756] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-07 05:25:58,756] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-07 05:25:58,756] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-07 05:25:58,756] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-07 05:25:58,756] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-07 05:25:58,756] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-07 05:25:58,756] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-07 05:25:58,756] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-07 05:25:58,756] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-07 05:25:58,756] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-07 05:25:58,756] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-07 05:25:58,756] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-07 05:25:58,756] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-07 05:25:58,756] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-07 05:25:58,756] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-07 05:25:58,756] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-07 05:25:58,756] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-07 05:25:58,756] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-07 05:25:58,756] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-07 05:25:58,756] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-07 05:25:58,756] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-07 05:25:58,756] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/125 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: Let x = the total number of candies Corey has.
x + 8 = the total number of candies Tapanga has.
The equation for the total number of candies is x + (x + 8) = 66
Combining like terms, we get 2x + 8 = 66
Subtracting 8 from both sides, we get 2x = 58
Dividing both sides by 2, we get x = <<29=29>>29, so Corey has 29 candies.
So the final answer is 29

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o1-tgsm8k-s20-rTrue-m4096
Evaluating commonsenseqa :  36%|███▌      | 45/125 [2:00:10<3:31:51, 158.89s/it]Evaluating commonsenseqa :   1%|          | 1/125 [03:55<8:07:20, 235.81s/it]Evaluating commonsenseqa :  37%|███▋      | 46/125 [2:02:49<3:29:01, 158.75s/it]Evaluating commonsenseqa :  38%|███▊      | 47/125 [2:05:26<3:25:55, 158.40s/it]Evaluating commonsenseqa :   2%|▏         | 2/125 [07:52<8:04:50, 236.51s/it]Evaluating commonsenseqa :  38%|███▊      | 48/125 [2:08:09<3:24:54, 159.67s/it]Evaluating commonsenseqa :   2%|▏         | 3/125 [11:45<7:57:34, 234.88s/it]Evaluating commonsenseqa :  39%|███▉      | 49/125 [2:10:47<3:21:41, 159.23s/it]Evaluating commonsenseqa :  40%|████      | 50/125 [2:13:27<3:19:32, 159.63s/it]Evaluating commonsenseqa :   3%|▎         | 4/125 [15:36<7:50:20, 233.23s/it]Evaluating commonsenseqa :  41%|████      | 51/125 [2:16:06<3:16:23, 159.24s/it]Evaluating commonsenseqa :   4%|▍         | 5/125 [19:34<7:50:02, 235.02s/it]Evaluating commonsenseqa :  42%|████▏     | 52/125 [2:18:46<3:14:08, 159.56s/it]Evaluating commonsenseqa :  42%|████▏     | 53/125 [2:21:26<3:11:40, 159.73s/it]Evaluating commonsenseqa :   5%|▍         | 6/125 [23:26<7:44:05, 234.00s/it]Evaluating commonsenseqa :  43%|████▎     | 54/125 [2:24:06<3:08:59, 159.71s/it]Evaluating commonsenseqa :   6%|▌         | 7/125 [27:20<7:39:59, 233.90s/it]Evaluating commonsenseqa :  44%|████▍     | 55/125 [2:26:46<3:06:33, 159.90s/it]Evaluating commonsenseqa :   6%|▋         | 8/125 [30:39<7:14:17, 222.71s/it]Evaluating commonsenseqa :  45%|████▍     | 56/125 [2:29:24<3:03:07, 159.23s/it]Evaluating commonsenseqa :  46%|████▌     | 57/125 [2:32:03<3:00:29, 159.25s/it]Evaluating commonsenseqa :   7%|▋         | 9/125 [34:42<7:23:05, 229.18s/it]Evaluating commonsenseqa :  46%|████▋     | 58/125 [2:34:41<2:57:19, 158.80s/it]Evaluating commonsenseqa :   8%|▊         | 10/125 [38:39<7:23:39, 231.47s/it]Evaluating commonsenseqa :  47%|████▋     | 59/125 [2:37:25<2:56:16, 160.25s/it]Evaluating commonsenseqa :  48%|████▊     | 60/125 [2:40:02<2:52:47, 159.50s/it]Evaluating commonsenseqa :   9%|▉         | 11/125 [42:28<7:18:20, 230.71s/it]Evaluating commonsenseqa :  49%|████▉     | 61/125 [2:42:41<2:49:44, 159.13s/it]Evaluating commonsenseqa :  10%|▉         | 12/125 [46:17<7:13:39, 230.26s/it]Evaluating commonsenseqa :  50%|████▉     | 62/125 [2:45:25<2:48:50, 160.81s/it]Evaluating commonsenseqa :  50%|█████     | 63/125 [2:48:08<2:46:36, 161.24s/it]Evaluating commonsenseqa :  10%|█         | 13/125 [50:09<7:11:08, 230.97s/it]Evaluating commonsenseqa :  51%|█████     | 64/125 [2:50:45<2:42:41, 160.02s/it]Evaluating commonsenseqa :  11%|█         | 14/125 [54:01<7:07:44, 231.22s/it]Evaluating commonsenseqa :  52%|█████▏    | 65/125 [2:53:24<2:39:38, 159.65s/it]Evaluating commonsenseqa :  12%|█▏        | 15/125 [57:56<7:05:59, 232.36s/it]Evaluating commonsenseqa :  53%|█████▎    | 66/125 [2:56:02<2:36:33, 159.20s/it]Evaluating commonsenseqa :  54%|█████▎    | 67/125 [2:58:40<2:33:31, 158.82s/it]Evaluating commonsenseqa :  13%|█▎        | 16/125 [1:01:48<7:02:02, 232.31s/it]Evaluating commonsenseqa :  54%|█████▍    | 68/125 [3:01:18<2:30:47, 158.74s/it]Evaluating commonsenseqa :  14%|█▎        | 17/125 [1:05:45<7:00:26, 233.58s/it]Evaluating commonsenseqa :  55%|█████▌    | 69/125 [3:03:54<2:27:19, 157.84s/it]Evaluating commonsenseqa :  56%|█████▌    | 70/125 [3:06:38<2:26:24, 159.71s/it]Evaluating commonsenseqa :  14%|█▍        | 18/125 [1:09:40<6:57:25, 234.07s/it]Evaluating commonsenseqa :  57%|█████▋    | 71/125 [3:09:19<2:24:01, 160.02s/it]Evaluating commonsenseqa :  15%|█▌        | 19/125 [1:13:34<6:53:09, 233.86s/it]Evaluating commonsenseqa :  58%|█████▊    | 72/125 [3:11:57<2:20:50, 159.44s/it]Evaluating commonsenseqa :  58%|█████▊    | 73/125 [3:14:37<2:18:17, 159.57s/it]Evaluating commonsenseqa :  16%|█▌        | 20/125 [1:17:22<6:46:33, 232.32s/it]Evaluating commonsenseqa :  59%|█████▉    | 74/125 [3:17:15<2:15:22, 159.27s/it]Evaluating commonsenseqa :  17%|█▋        | 21/125 [1:21:16<6:43:22, 232.71s/it]Evaluating commonsenseqa :  60%|██████    | 75/125 [3:19:50<2:11:41, 158.02s/it]Evaluating commonsenseqa :  61%|██████    | 76/125 [3:22:31<2:09:38, 158.75s/it]Evaluating commonsenseqa :  18%|█▊        | 22/125 [1:25:15<6:42:37, 234.54s/it]Evaluating commonsenseqa :  62%|██████▏   | 77/125 [3:25:13<2:07:54, 159.88s/it]Evaluating commonsenseqa :  18%|█▊        | 23/125 [1:29:03<6:35:22, 232.57s/it]Evaluating commonsenseqa :  62%|██████▏   | 78/125 [3:27:54<2:05:26, 160.14s/it]Evaluating commonsenseqa :  63%|██████▎   | 79/125 [3:30:35<2:02:51, 160.26s/it]Evaluating commonsenseqa :  19%|█▉        | 24/125 [1:32:57<6:32:28, 233.16s/it]Evaluating commonsenseqa :  64%|██████▍   | 80/125 [3:33:20<2:01:26, 161.91s/it]Evaluating commonsenseqa :  20%|██        | 25/125 [1:36:57<6:31:43, 235.03s/it]Evaluating commonsenseqa :  65%|██████▍   | 81/125 [3:36:01<1:58:28, 161.55s/it]Evaluating commonsenseqa :  66%|██████▌   | 82/125 [3:38:41<1:55:22, 160.98s/it]Evaluating commonsenseqa :  21%|██        | 26/125 [1:40:56<6:29:47, 236.23s/it]Evaluating commonsenseqa :  66%|██████▋   | 83/125 [3:41:23<1:53:02, 161.49s/it]Evaluating commonsenseqa :  22%|██▏       | 27/125 [1:43:56<5:58:38, 219.58s/it]Evaluating commonsenseqa :  67%|██████▋   | 84/125 [3:44:02<1:49:40, 160.51s/it]Evaluating commonsenseqa :  22%|██▏       | 28/125 [1:47:11<5:43:07, 212.24s/it]Evaluating commonsenseqa :  68%|██████▊   | 85/125 [3:46:46<1:47:44, 161.62s/it]Evaluating commonsenseqa :  23%|██▎       | 29/125 [1:51:06<5:50:24, 219.00s/it]Evaluating commonsenseqa :  69%|██████▉   | 86/125 [3:49:29<1:45:21, 162.10s/it]Evaluating commonsenseqa :  70%|██████▉   | 87/125 [3:52:12<1:42:50, 162.39s/it]Evaluating commonsenseqa :  24%|██▍       | 30/125 [1:54:59<5:53:25, 223.22s/it]Evaluating commonsenseqa :  70%|███████   | 88/125 [3:54:48<1:38:55, 160.41s/it]Evaluating commonsenseqa :  25%|██▍       | 31/125 [1:58:52<5:54:00, 225.97s/it]Evaluating commonsenseqa :  71%|███████   | 89/125 [3:57:31<1:36:42, 161.19s/it]Evaluating commonsenseqa :  72%|███████▏  | 90/125 [4:00:10<1:33:38, 160.53s/it]Evaluating commonsenseqa :  26%|██▌       | 32/125 [2:02:43<5:52:46, 227.60s/it]Evaluating commonsenseqa :  73%|███████▎  | 91/125 [4:02:49<1:30:40, 160.03s/it]Evaluating commonsenseqa :  26%|██▋       | 33/125 [2:06:39<5:52:45, 230.06s/it]Evaluating commonsenseqa :  74%|███████▎  | 92/125 [4:05:29<1:28:03, 160.12s/it]Evaluating commonsenseqa :  27%|██▋       | 34/125 [2:09:22<5:18:19, 209.88s/it]Evaluating commonsenseqa :  74%|███████▍  | 93/125 [4:08:13<1:25:56, 161.14s/it]Evaluating commonsenseqa :  75%|███████▌  | 94/125 [4:10:50<1:22:36, 159.90s/it]Evaluating commonsenseqa :  28%|██▊       | 35/125 [2:13:18<5:26:36, 217.74s/it]Evaluating commonsenseqa :  76%|███████▌  | 95/125 [4:13:29<1:19:53, 159.80s/it]Evaluating commonsenseqa :  29%|██▉       | 36/125 [2:15:28<4:43:56, 191.42s/it]Evaluating commonsenseqa :  77%|███████▋  | 96/125 [4:16:08<1:17:07, 159.57s/it]Evaluating commonsenseqa :  30%|██▉       | 37/125 [2:19:23<4:59:59, 204.54s/it]Evaluating commonsenseqa :  78%|███████▊  | 97/125 [4:18:45<1:14:06, 158.79s/it]Evaluating commonsenseqa :  30%|███       | 38/125 [2:23:18<5:09:57, 213.76s/it]Evaluating commonsenseqa :  78%|███████▊  | 98/125 [4:21:27<1:11:48, 159.59s/it]Evaluating commonsenseqa :  79%|███████▉  | 99/125 [4:24:09<1:09:30, 160.41s/it]Evaluating commonsenseqa :  31%|███       | 39/125 [2:27:11<5:14:23, 219.35s/it]Evaluating commonsenseqa :  80%|████████  | 100/125 [4:26:47<1:06:31, 159.67s/it]Evaluating commonsenseqa :  32%|███▏      | 40/125 [2:31:02<5:15:48, 222.93s/it]Evaluating commonsenseqa :  81%|████████  | 101/125 [4:29:27<1:03:55, 159.81s/it]Evaluating commonsenseqa :  82%|████████▏ | 102/125 [4:32:06<1:01:11, 159.65s/it]Evaluating commonsenseqa :  33%|███▎      | 41/125 [2:34:54<5:16:08, 225.82s/it]Evaluating commonsenseqa :  82%|████████▏ | 103/125 [4:34:48<58:42, 160.11s/it]  Evaluating commonsenseqa :  34%|███▎      | 42/125 [2:38:47<5:15:14, 227.88s/it]Evaluating commonsenseqa :  83%|████████▎ | 104/125 [4:37:24<55:39, 159.02s/it]Evaluating commonsenseqa :  84%|████████▍ | 105/125 [4:40:04<53:05, 159.27s/it]Evaluating commonsenseqa :  34%|███▍      | 43/125 [2:42:45<5:15:31, 230.87s/it]Evaluating commonsenseqa :  85%|████████▍ | 106/125 [4:42:41<50:16, 158.75s/it]Evaluating commonsenseqa :  35%|███▌      | 44/125 [2:46:32<5:10:12, 229.78s/it]Evaluating commonsenseqa :  86%|████████▌ | 107/125 [4:45:20<47:38, 158.80s/it]Evaluating commonsenseqa :  86%|████████▋ | 108/125 [4:48:01<45:09, 159.39s/it]Evaluating commonsenseqa :  36%|███▌      | 45/125 [2:50:27<5:08:24, 231.31s/it]Evaluating commonsenseqa :  87%|████████▋ | 109/125 [4:50:45<42:52, 160.79s/it]Evaluating commonsenseqa :  37%|███▋      | 46/125 [2:54:23<5:06:18, 232.63s/it]Evaluating commonsenseqa :  88%|████████▊ | 110/125 [4:53:31<40:32, 162.18s/it]Evaluating commonsenseqa :  38%|███▊      | 47/125 [2:57:21<4:41:09, 216.28s/it]Evaluating commonsenseqa :  89%|████████▉ | 111/125 [4:56:06<37:20, 160.04s/it]Evaluating commonsenseqa :  90%|████████▉ | 112/125 [4:58:48<34:48, 160.63s/it]Evaluating commonsenseqa :  38%|███▊      | 48/125 [3:01:07<4:41:28, 219.33s/it]Evaluating commonsenseqa :  90%|█████████ | 113/125 [5:01:28<32:05, 160.48s/it]Evaluating commonsenseqa :  39%|███▉      | 49/125 [3:05:05<4:44:48, 224.84s/it]Evaluating commonsenseqa :  91%|█████████ | 114/125 [5:04:08<29:25, 160.48s/it]Evaluating commonsenseqa :  92%|█████████▏| 115/125 [5:06:45<26:34, 159.40s/it]Evaluating commonsenseqa :  40%|████      | 50/125 [3:08:59<4:44:22, 227.50s/it]Evaluating commonsenseqa :  93%|█████████▎| 116/125 [5:09:23<23:49, 158.87s/it]Evaluating commonsenseqa :  41%|████      | 51/125 [3:12:53<4:42:57, 229.43s/it]Evaluating commonsenseqa :  94%|█████████▎| 117/125 [5:12:01<21:08, 158.59s/it]Evaluating commonsenseqa :  94%|█████████▍| 118/125 [5:14:41<18:33, 159.01s/it]Evaluating commonsenseqa :  42%|████▏     | 52/125 [3:16:43<4:39:37, 229.83s/it]Evaluating commonsenseqa :  95%|█████████▌| 119/125 [5:17:24<16:01, 160.26s/it]Evaluating commonsenseqa :  42%|████▏     | 53/125 [3:20:44<4:39:30, 232.93s/it]Evaluating commonsenseqa :  96%|█████████▌| 120/125 [5:20:06<13:23, 160.78s/it]Evaluating commonsenseqa :  43%|████▎     | 54/125 [3:24:37<4:35:51, 233.12s/it]Evaluating commonsenseqa :  97%|█████████▋| 121/125 [5:22:46<10:42, 160.73s/it]Evaluating commonsenseqa :  98%|█████████▊| 122/125 [5:25:24<07:59, 159.87s/it]Evaluating commonsenseqa :  44%|████▍     | 55/125 [3:28:32<4:32:43, 233.76s/it]Evaluating commonsenseqa :  98%|█████████▊| 123/125 [5:28:06<05:20, 160.38s/it]Evaluating commonsenseqa :  45%|████▍     | 56/125 [3:32:25<4:28:32, 233.51s/it]Evaluating commonsenseqa :  99%|█████████▉| 124/125 [5:30:45<02:40, 160.12s/it]Evaluating commonsenseqa : 100%|██████████| 125/125 [5:33:26<00:00, 160.29s/it]Evaluating commonsenseqa : 100%|██████████| 125/125 [5:33:26<00:00, 160.05s/it]
name: commonsenseqa | avg. gen lenth: 333.844 | time: 20008.45719408989s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 19045 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o7-tgsm8k-s30-rTrue --seed 30 --max-prompt-length 4096 --rationales --num-out-domain 7 6 7 8 9 10 True 4096 8
[2023-09-07 09:01:33,112] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o7-tgsm8k-s30-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 7
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o7-tgsm8k-s30-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 8
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 546914.69it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.46s/it]
 > number of parameters: 6738415616
[2023-09-07 09:01:47,708] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-07 09:01:47,912] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-07 09:01:47,914] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-07 09:01:47,914] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-07 09:01:47,914] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-07 09:01:47,914] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-07 09:01:47,914] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f46490>
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-07 09:01:47,915] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-07 09:01:47,916] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-07 09:01:47,916] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-07 09:01:47,916] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-07 09:01:47,916] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-07 09:01:47,916] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-07 09:01:47,916] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-07 09:01:47,916] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-07 09:01:47,916] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-07 09:01:47,916] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-07 09:01:47,916] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-07 09:01:47,916] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-07 09:01:47,916] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-07 09:01:47,916] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-07 09:01:47,916] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-07 09:01:47,916] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-07 09:01:47,916] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-07 09:01:47,916] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-07 09:01:47,916] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-07 09:01:47,916] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-07 09:01:47,916] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-07 09:01:47,916] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-07 09:01:47,916] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-07 09:01:47,916] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-07 09:01:47,916] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-07 09:01:47,916] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/125 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: The car-rental agency charges $30/day for a car, or $190 for the first week for a rental that lasts an entire week or longer. Jennie rented a car for 11 days. How much, in dollars, did she pay for the rental?
Output: The first 7 days were $190.
There were 11-7=<<11-7=4>>4 days left.
The additional 4 days were 4*30=<<4*30=120>>120.
And 190+120=<<190+120=310>>310.
So the final answer is 310

Input: A hurricane is approaching the southern coast of Texas, and a rancher is planning to move 400 head of cattle 60 miles to higher ground to protect them from possible inland flooding that might occur.  His animal transport truck holds 20 head of cattle.  Traveling at 60 miles per hour, what is the total driving time, in hours, it will take to transport all of his cattle to higher ground?
Output: Given the limited capacity of his transport vehicle (20 head of cattle), the 400 head of cattle will require 400/20=<<400/20=20>>20 trips using his transport vehicle.
Traveling to the site at 60 mph for 60 miles it will take 60/60=<<60/60=1>>1 hour to travel one-way.
Since each trip requires driving to and returning from the relocation site, each complete round trip will take 2*1=<<2*1=2>>2 hours.
Thus, 20 complete trips will take 20*2=<<20*2=40>>40 hours of driving time.
So the final answer is 40

Input: Jason has a carriage house that he rents out.  He’s charging $50.00 per day or $500.00 for 14 days.  Eric wants to rent the house for 20 days.  How much will it cost him?
Output: He wants to rent for 20 days and there is a deal if you rent for 14 days so that leaves 20-14 = <<20-14=6>>6 individual days
Each individual day is $50.00 and he will have 6 individual days for a total of 50*6 = $<<50*6=300.00>>300.00
14 days costs $500.00 and 6 days costs $300.00 for a total of 500+300 = $800.00
So the final answer is 800

Input: Melissa works on a poultry farm. She drives to town twice each month to buy supplies. If it takes her 3 hours to drive to town and back, how many hours does Melissa spend driving in a year?
Output: Melissa spends 2x3=<<2*3=6>>6 hours driving each month.
Since there are 12 months in a year, she spends 6x12=<<6*12=72>>72 hours driving each year.
So the final answer is 72

Input: The ratio of boys to girls in a family is 5:7. The total number of children in the family is 180. If the boys are given $3900 to share, how much money does each boy receive?
Output: The total ratio representing the number of children in the family is 5+7 = <<5+7=12>>12
From the total ratio of children in the family, 5/12 represent the number of boys, meaning that the number of boys in the family is 5/12*180 = <<5/12*180=75>>75
If the boys are given $3900 to share, each boy receives $3900/75 = $<<3900/75=52>>52
So the final answer is 52

Input: Josephine receives a bill from the hospital for 5000$.  50 percent of the bill is for medication.  25 percent of the remaining bill is for overnight stays, and 175$ is for food.  The rest of the bill is for the ambulance ride.  How much did the ambulance ride cost?
Output: Medication:5000(.50)=2500
Overnight Stays:2500(.25)=625
2500-625=<<2500-625=1875>>1875
Food:1875-175=<<1875-175=1700>>1700$
Ambulance ride:1700$
So the final answer is 1700

Input: It was time for Kelly to harvest her carrots that she had planted in three different beds.  In the first bed she pulled out 55 carrots.  In the second bed she pulled out 101 carrots and in the third bed she pulled out 78 carrots.  She found that 6 carrots weighed one pound.  How many pounds of carrots did Kelly harvest?
Output: She pulled out 55 + 101 + 78 = <<55+101+78=234>>234
6 carrots weigh one pound so 234/6 = <<234/6=39>>39 pounds of carrots
So the final answer is 39

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o7-tgsm8k-s30-rTrue-m4096
Evaluating commonsenseqa :  46%|████▌     | 57/125 [3:36:23<4:25:53, 234.61s/it]Evaluating commonsenseqa :   1%|          | 1/125 [02:29<5:07:58, 149.02s/it]Evaluating commonsenseqa :  46%|████▋     | 58/125 [3:40:15<4:21:20, 234.04s/it]Evaluating commonsenseqa :   2%|▏         | 2/125 [05:00<5:08:23, 150.44s/it]Evaluating commonsenseqa :   2%|▏         | 3/125 [07:28<5:03:58, 149.50s/it]Evaluating commonsenseqa :  47%|████▋     | 59/125 [3:44:06<4:16:30, 233.18s/it]Evaluating commonsenseqa :   3%|▎         | 4/125 [09:58<5:01:14, 149.37s/it]Evaluating commonsenseqa :  48%|████▊     | 60/125 [3:48:02<4:13:29, 234.00s/it]Evaluating commonsenseqa :   4%|▍         | 5/125 [12:30<5:00:54, 150.46s/it]Evaluating commonsenseqa :   5%|▍         | 6/125 [15:01<4:58:45, 150.63s/it]Evaluating commonsenseqa :  49%|████▉     | 61/125 [3:51:58<4:10:01, 234.39s/it]Evaluating commonsenseqa :   6%|▌         | 7/125 [17:29<4:54:36, 149.80s/it]Evaluating commonsenseqa :   6%|▋         | 8/125 [19:59<4:52:27, 149.98s/it]Evaluating commonsenseqa :  50%|████▉     | 62/125 [3:55:50<4:05:20, 233.65s/it]Evaluating commonsenseqa :   7%|▋         | 9/125 [22:29<4:49:58, 149.99s/it]Evaluating commonsenseqa :  50%|█████     | 63/125 [3:59:41<4:00:40, 232.91s/it]Evaluating commonsenseqa :   8%|▊         | 10/125 [24:59<4:47:03, 149.77s/it]Evaluating commonsenseqa :   9%|▉         | 11/125 [27:25<4:42:51, 148.87s/it]Evaluating commonsenseqa :  51%|█████     | 64/125 [4:03:32<3:56:21, 232.48s/it]Evaluating commonsenseqa :  10%|▉         | 12/125 [29:52<4:39:16, 148.29s/it]Evaluating commonsenseqa :  52%|█████▏    | 65/125 [4:07:26<3:52:47, 232.79s/it]Evaluating commonsenseqa :  10%|█         | 13/125 [32:22<4:37:26, 148.63s/it]Evaluating commonsenseqa :  11%|█         | 14/125 [34:47<4:33:00, 147.58s/it]Evaluating commonsenseqa :  53%|█████▎    | 66/125 [4:11:21<3:49:35, 233.48s/it]Evaluating commonsenseqa :  12%|█▏        | 15/125 [37:05<4:25:28, 144.81s/it]Evaluating commonsenseqa :  54%|█████▎    | 67/125 [4:15:15<3:45:48, 233.59s/it]Evaluating commonsenseqa :  13%|█▎        | 16/125 [39:33<4:24:36, 145.65s/it]Evaluating commonsenseqa :  14%|█▎        | 17/125 [42:01<4:23:40, 146.49s/it]Evaluating commonsenseqa :  54%|█████▍    | 68/125 [4:19:07<3:41:37, 233.29s/it]Evaluating commonsenseqa :  14%|█▍        | 18/125 [44:33<4:23:58, 148.02s/it]Evaluating commonsenseqa :  15%|█▌        | 19/125 [47:05<4:23:39, 149.24s/it]Evaluating commonsenseqa :  55%|█████▌    | 69/125 [4:22:59<3:37:18, 232.83s/it]Evaluating commonsenseqa :  16%|█▌        | 20/125 [49:30<4:18:54, 147.95s/it]Evaluating commonsenseqa :  56%|█████▌    | 70/125 [4:26:52<3:33:28, 232.88s/it]Evaluating commonsenseqa :  17%|█▋        | 21/125 [51:59<4:17:05, 148.32s/it]Evaluating commonsenseqa :  18%|█▊        | 22/125 [54:25<4:13:22, 147.59s/it]Evaluating commonsenseqa :  57%|█████▋    | 71/125 [4:30:46<3:29:50, 233.16s/it]Evaluating commonsenseqa :  18%|█▊        | 23/125 [56:51<4:10:17, 147.23s/it]Evaluating commonsenseqa :  58%|█████▊    | 72/125 [4:34:37<3:25:31, 232.68s/it]Evaluating commonsenseqa :  19%|█▉        | 24/125 [59:21<4:09:06, 147.98s/it]Evaluating commonsenseqa :  20%|██        | 25/125 [1:01:47<4:05:27, 147.28s/it]Evaluating commonsenseqa :  58%|█████▊    | 73/125 [4:38:33<3:22:31, 233.68s/it]Evaluating commonsenseqa :  21%|██        | 26/125 [1:04:13<4:02:22, 146.90s/it]Evaluating commonsenseqa :  59%|█████▉    | 74/125 [4:42:23<3:17:27, 232.31s/it]Evaluating commonsenseqa :  22%|██▏       | 27/125 [1:06:38<3:59:17, 146.51s/it]Evaluating commonsenseqa :  22%|██▏       | 28/125 [1:09:09<3:58:54, 147.77s/it]Evaluating commonsenseqa :  60%|██████    | 75/125 [4:46:19<3:14:35, 233.51s/it]Evaluating commonsenseqa :  23%|██▎       | 29/125 [1:11:37<3:56:17, 147.68s/it]Evaluating commonsenseqa :  24%|██▍       | 30/125 [1:14:04<3:53:44, 147.63s/it]Evaluating commonsenseqa :  61%|██████    | 76/125 [4:50:09<3:09:53, 232.51s/it]Evaluating commonsenseqa :  25%|██▍       | 31/125 [1:16:30<3:50:38, 147.22s/it]Evaluating commonsenseqa :  62%|██████▏   | 77/125 [4:54:02<3:06:01, 232.53s/it]Evaluating commonsenseqa :  26%|██▌       | 32/125 [1:18:58<3:48:30, 147.42s/it]Evaluating commonsenseqa :  26%|██▋       | 33/125 [1:21:23<3:44:54, 146.68s/it]Evaluating commonsenseqa :  62%|██████▏   | 78/125 [4:57:54<3:02:03, 232.41s/it]Evaluating commonsenseqa :  27%|██▋       | 34/125 [1:23:49<3:41:53, 146.31s/it]Evaluating commonsenseqa :  63%|██████▎   | 79/125 [5:01:48<2:58:36, 232.98s/it]Evaluating commonsenseqa :  28%|██▊       | 35/125 [1:26:16<3:39:48, 146.54s/it]Evaluating commonsenseqa :  29%|██▉       | 36/125 [1:28:42<3:37:22, 146.55s/it]Evaluating commonsenseqa :  64%|██████▍   | 80/125 [5:05:39<2:54:23, 232.52s/it]Evaluating commonsenseqa :  30%|██▉       | 37/125 [1:31:08<3:34:36, 146.33s/it]Evaluating commonsenseqa :  65%|██████▍   | 81/125 [5:08:40<2:39:08, 217.01s/it]Evaluating commonsenseqa :  30%|███       | 38/125 [1:33:37<3:33:06, 146.97s/it]Evaluating commonsenseqa :  31%|███       | 39/125 [1:36:04<3:30:41, 146.99s/it]Evaluating commonsenseqa :  66%|██████▌   | 82/125 [5:12:36<2:39:31, 222.59s/it]Evaluating commonsenseqa :  32%|███▏      | 40/125 [1:38:33<3:29:20, 147.77s/it]Evaluating commonsenseqa :  66%|██████▋   | 83/125 [5:16:30<2:38:08, 225.92s/it]Evaluating commonsenseqa :  33%|███▎      | 41/125 [1:41:02<3:27:18, 148.08s/it]Evaluating commonsenseqa :  34%|███▎      | 42/125 [1:43:29<3:24:21, 147.73s/it]Evaluating commonsenseqa :  67%|██████▋   | 84/125 [5:20:22<2:35:47, 227.99s/it]Evaluating commonsenseqa :  34%|███▍      | 43/125 [1:45:57<3:22:11, 147.94s/it]Evaluating commonsenseqa :  35%|███▌      | 44/125 [1:48:25<3:19:46, 147.99s/it]Evaluating commonsenseqa :  68%|██████▊   | 85/125 [5:24:17<2:33:23, 230.08s/it]Evaluating commonsenseqa :  36%|███▌      | 45/125 [1:50:53<3:17:10, 147.88s/it]Evaluating commonsenseqa :  69%|██████▉   | 86/125 [5:28:06<2:29:17, 229.68s/it]Evaluating commonsenseqa :  37%|███▋      | 46/125 [1:53:18<3:13:36, 147.04s/it]Evaluating commonsenseqa :  38%|███▊      | 47/125 [1:55:45<3:10:52, 146.83s/it]Evaluating commonsenseqa :  70%|██████▉   | 87/125 [5:31:48<2:23:57, 227.30s/it]Evaluating commonsenseqa :  38%|███▊      | 48/125 [1:58:12<3:08:42, 147.04s/it]Evaluating commonsenseqa :  70%|███████   | 88/125 [5:35:44<2:21:51, 230.05s/it]Evaluating commonsenseqa :  39%|███▉      | 49/125 [2:00:40<3:06:45, 147.44s/it]Evaluating commonsenseqa :  40%|████      | 50/125 [2:03:08<3:04:21, 147.48s/it]Evaluating commonsenseqa :  71%|███████   | 89/125 [5:39:41<2:19:13, 232.04s/it]Evaluating commonsenseqa :  41%|████      | 51/125 [2:05:37<3:02:25, 147.91s/it]Evaluating commonsenseqa :  72%|███████▏  | 90/125 [5:43:34<2:15:36, 232.47s/it]Evaluating commonsenseqa :  42%|████▏     | 52/125 [2:08:02<2:59:02, 147.15s/it]Evaluating commonsenseqa :  42%|████▏     | 53/125 [2:10:34<2:58:14, 148.53s/it]Evaluating commonsenseqa :  73%|███████▎  | 91/125 [5:47:32<2:12:34, 233.94s/it]Evaluating commonsenseqa :  43%|████▎     | 54/125 [2:13:03<2:55:46, 148.54s/it]Evaluating commonsenseqa :  44%|████▍     | 55/125 [2:15:29<2:52:30, 147.86s/it]Evaluating commonsenseqa :  74%|███████▎  | 92/125 [5:51:31<2:09:30, 235.48s/it]Evaluating commonsenseqa :  45%|████▍     | 56/125 [2:17:54<2:49:03, 147.01s/it]Evaluating commonsenseqa :  74%|███████▍  | 93/125 [5:55:28<2:05:54, 236.07s/it]Evaluating commonsenseqa :  46%|████▌     | 57/125 [2:20:23<2:47:19, 147.64s/it]Evaluating commonsenseqa :  46%|████▋     | 58/125 [2:22:52<2:45:15, 147.99s/it]Evaluating commonsenseqa :  75%|███████▌  | 94/125 [5:59:22<2:01:31, 235.20s/it]Evaluating commonsenseqa :  47%|████▋     | 59/125 [2:25:17<2:41:59, 147.26s/it]Evaluating commonsenseqa :  76%|███████▌  | 95/125 [6:03:13<1:57:04, 234.14s/it]Evaluating commonsenseqa :  48%|████▊     | 60/125 [2:27:46<2:39:51, 147.57s/it]Evaluating commonsenseqa :  49%|████▉     | 61/125 [2:30:15<2:37:55, 148.05s/it]Evaluating commonsenseqa :  77%|███████▋  | 96/125 [6:07:04<1:52:43, 233.24s/it]Evaluating commonsenseqa :  50%|████▉     | 62/125 [2:32:47<2:36:54, 149.43s/it]Evaluating commonsenseqa :  78%|███████▊  | 97/125 [6:10:58<1:48:53, 233.34s/it]Evaluating commonsenseqa :  50%|█████     | 63/125 [2:35:12<2:32:44, 147.81s/it]Evaluating commonsenseqa :  51%|█████     | 64/125 [2:37:42<2:31:12, 148.72s/it]Evaluating commonsenseqa :  78%|███████▊  | 98/125 [6:14:50<1:44:46, 232.85s/it]Evaluating commonsenseqa :  52%|█████▏    | 65/125 [2:40:16<2:30:03, 150.05s/it]Evaluating commonsenseqa :  53%|█████▎    | 66/125 [2:42:46<2:27:43, 150.23s/it]Evaluating commonsenseqa :  79%|███████▉  | 99/125 [6:18:43<1:41:01, 233.13s/it]Evaluating commonsenseqa :  54%|█████▎    | 67/125 [2:45:16<2:25:09, 150.17s/it]Evaluating commonsenseqa :  80%|████████  | 100/125 [6:22:39<1:37:28, 233.94s/it]Evaluating commonsenseqa :  54%|█████▍    | 68/125 [2:47:48<2:23:03, 150.59s/it]Evaluating commonsenseqa :  55%|█████▌    | 69/125 [2:50:15<2:19:32, 149.52s/it]Evaluating commonsenseqa :  81%|████████  | 101/125 [6:26:33<1:33:34, 233.92s/it]Evaluating commonsenseqa :  56%|█████▌    | 70/125 [2:52:47<2:17:42, 150.22s/it]Evaluating commonsenseqa :  82%|████████▏ | 102/125 [6:30:29<1:29:55, 234.59s/it]Evaluating commonsenseqa :  57%|█████▋    | 71/125 [2:55:13<2:14:12, 149.11s/it]Evaluating commonsenseqa :  58%|█████▊    | 72/125 [2:57:38<2:10:32, 147.78s/it]Evaluating commonsenseqa :  82%|████████▏ | 103/125 [6:34:29<1:26:36, 236.20s/it]Evaluating commonsenseqa :  58%|█████▊    | 73/125 [3:00:06<2:08:13, 147.95s/it]Evaluating commonsenseqa :  59%|█████▉    | 74/125 [3:02:35<2:06:02, 148.29s/it]Evaluating commonsenseqa :  83%|████████▎ | 104/125 [6:38:28<1:22:55, 236.93s/it]Evaluating commonsenseqa :  60%|██████    | 75/125 [3:05:00<2:02:46, 147.32s/it]Evaluating commonsenseqa :  84%|████████▍ | 105/125 [6:42:24<1:18:55, 236.75s/it]Evaluating commonsenseqa :  61%|██████    | 76/125 [3:07:25<1:59:36, 146.46s/it]Evaluating commonsenseqa :  62%|██████▏   | 77/125 [3:09:52<1:57:25, 146.78s/it]Evaluating commonsenseqa :  85%|████████▍ | 106/125 [6:46:18<1:14:43, 235.99s/it]Evaluating commonsenseqa :  62%|██████▏   | 78/125 [3:12:19<1:54:55, 146.71s/it]Evaluating commonsenseqa :  86%|████████▌ | 107/125 [6:50:16<1:10:58, 236.58s/it]Evaluating commonsenseqa :  63%|██████▎   | 79/125 [3:14:49<1:53:13, 147.68s/it]Evaluating commonsenseqa :  64%|██████▍   | 80/125 [3:17:19<1:51:14, 148.32s/it]Evaluating commonsenseqa :  86%|████████▋ | 108/125 [6:54:14<1:07:07, 236.93s/it]Evaluating commonsenseqa :  65%|██████▍   | 81/125 [3:19:47<1:48:47, 148.36s/it]Evaluating commonsenseqa :  66%|██████▌   | 82/125 [3:22:14<1:45:56, 147.83s/it]Evaluating commonsenseqa :  87%|████████▋ | 109/125 [6:58:10<1:03:06, 236.67s/it]Evaluating commonsenseqa :  66%|██████▋   | 83/125 [3:24:43<1:43:42, 148.17s/it]Evaluating commonsenseqa :  88%|████████▊ | 110/125 [7:02:04<58:58, 235.88s/it]  Evaluating commonsenseqa :  67%|██████▋   | 84/125 [3:27:11<1:41:19, 148.28s/it]Evaluating commonsenseqa :  68%|██████▊   | 85/125 [3:29:36<1:38:13, 147.34s/it]Evaluating commonsenseqa :  89%|████████▉ | 111/125 [7:05:59<54:58, 235.58s/it]Evaluating commonsenseqa :  69%|██████▉   | 86/125 [3:32:04<1:35:54, 147.56s/it]Evaluating commonsenseqa :  90%|████████▉ | 112/125 [7:09:56<51:07, 235.94s/it]Evaluating commonsenseqa :  70%|██████▉   | 87/125 [3:34:34<1:33:48, 148.12s/it]Evaluating commonsenseqa :  70%|███████   | 88/125 [3:37:00<1:30:59, 147.55s/it]Evaluating commonsenseqa :  90%|█████████ | 113/125 [7:13:54<47:18, 236.52s/it]Evaluating commonsenseqa :  71%|███████   | 89/125 [3:39:29<1:28:47, 147.97s/it]Evaluating commonsenseqa :  91%|█████████ | 114/125 [7:17:44<43:02, 234.73s/it]Evaluating commonsenseqa :  72%|███████▏  | 90/125 [3:41:58<1:26:34, 148.41s/it]Evaluating commonsenseqa :  73%|███████▎  | 91/125 [3:44:24<1:23:38, 147.60s/it]Evaluating commonsenseqa :  92%|█████████▏| 115/125 [7:21:36<38:59, 233.96s/it]Evaluating commonsenseqa :  74%|███████▎  | 92/125 [3:46:50<1:20:50, 146.97s/it]Evaluating commonsenseqa :  74%|███████▍  | 93/125 [3:49:20<1:18:59, 148.11s/it]Evaluating commonsenseqa :  93%|█████████▎| 116/125 [7:25:32<35:10, 234.55s/it]Evaluating commonsenseqa :  75%|███████▌  | 94/125 [3:51:45<1:16:02, 147.16s/it]Evaluating commonsenseqa :  94%|█████████▎| 117/125 [7:29:26<31:13, 234.16s/it]Evaluating commonsenseqa :  76%|███████▌  | 95/125 [3:54:12<1:13:29, 146.97s/it]Evaluating commonsenseqa :  77%|███████▋  | 96/125 [3:56:42<1:11:31, 147.99s/it]Evaluating commonsenseqa :  94%|█████████▍| 118/125 [7:33:21<27:22, 234.67s/it]Evaluating commonsenseqa :  78%|███████▊  | 97/125 [3:59:11<1:09:08, 148.16s/it]Evaluating commonsenseqa :  95%|█████████▌| 119/125 [7:37:18<23:31, 235.22s/it]Evaluating commonsenseqa :  78%|███████▊  | 98/125 [4:01:38<1:06:29, 147.77s/it]Evaluating commonsenseqa :  79%|███████▉  | 99/125 [4:04:05<1:03:59, 147.68s/it]Evaluating commonsenseqa :  96%|█████████▌| 120/125 [7:41:09<19:30, 234.04s/it]Evaluating commonsenseqa :  80%|████████  | 100/125 [4:06:33<1:01:34, 147.79s/it]Evaluating commonsenseqa :  81%|████████  | 101/125 [4:09:00<58:59, 147.47s/it]  Evaluating commonsenseqa :  97%|█████████▋| 121/125 [7:45:05<15:37, 234.41s/it]Evaluating commonsenseqa :  82%|████████▏ | 102/125 [4:11:30<56:47, 148.16s/it]Evaluating commonsenseqa :  98%|█████████▊| 122/125 [7:49:00<11:44, 234.87s/it]Evaluating commonsenseqa :  82%|████████▏ | 103/125 [4:13:57<54:16, 148.04s/it]Evaluating commonsenseqa :  83%|████████▎ | 104/125 [4:16:27<52:01, 148.64s/it]Evaluating commonsenseqa :  98%|█████████▊| 123/125 [7:52:59<07:51, 235.89s/it]Evaluating commonsenseqa :  84%|████████▍ | 105/125 [4:18:54<49:20, 148.01s/it]Evaluating commonsenseqa :  99%|█████████▉| 124/125 [7:56:50<03:54, 234.59s/it]Evaluating commonsenseqa :  85%|████████▍ | 106/125 [4:21:21<46:48, 147.80s/it]Evaluating commonsenseqa :  86%|████████▌ | 107/125 [4:23:46<44:05, 146.98s/it]Evaluating commonsenseqa : 100%|██████████| 125/125 [8:00:44<00:00, 234.36s/it]Evaluating commonsenseqa : 100%|██████████| 125/125 [8:00:44<00:00, 230.76s/it]
name: commonsenseqa | avg. gen lenth: 273.206 | time: 28845.95066857338s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 18586 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s20-rTrue --seed 20 --max-prompt-length 4096 --rationales --num-out-domain 2 1 2 3 4 5 True 4096 8
[2023-09-07 13:26:49,646] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s20-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 2
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o2-tgsm8k-s20-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 8
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 963874.57it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:10<00:10, 10.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:14<00:00,  6.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:14<00:00,  7.31s/it]
 > number of parameters: 6738415616
[2023-09-07 13:27:05,683] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-07 13:27:05,887] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-07 13:27:05,889] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-07 13:27:05,889] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-07 13:27:05,889] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-07 13:27:05,889] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-07 13:27:05,889] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-07 13:27:05,889] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-07 13:27:05,889] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-07 13:27:05,889] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-07 13:27:05,889] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554ba358310>
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-07 13:27:05,890] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-07 13:27:05,891] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-07 13:27:05,891] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-07 13:27:05,891] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-07 13:27:05,891] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-07 13:27:05,891] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-07 13:27:05,891] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-07 13:27:05,891] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-07 13:27:05,891] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-07 13:27:05,891] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-07 13:27:05,891] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-07 13:27:05,891] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-07 13:27:05,891] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-07 13:27:05,891] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-07 13:27:05,891] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-07 13:27:05,891] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-07 13:27:05,891] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-07 13:27:05,891] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-07 13:27:05,891] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-07 13:27:05,891] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/125 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: Let x = the total number of candies Corey has.
x + 8 = the total number of candies Tapanga has.
The equation for the total number of candies is x + (x + 8) = 66
Combining like terms, we get 2x + 8 = 66
Subtracting 8 from both sides, we get 2x = 58
Dividing both sides by 2, we get x = <<29=29>>29, so Corey has 29 candies.
So the final answer is 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: At 5 cents a minute, calling his father cost Freddy 5* 45 = <<5*45=225>>225 cents.
At 25 cents a minute, calling his brother cost Freddy 25 * 31 = <<25*31=775>>775 cents.
Adding the cost of calling his father and brother, we find that Freddy paid a total of 225 + 775 = <<225+775=1000>>1000 cents.
Since each dollar has 100 cents, Freddy paid 1000 / 100 = <<1000/100=10>>10 dollars
So the final answer is 10

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o2-tgsm8k-s20-rTrue-m4096
Evaluating commonsenseqa :  86%|████████▋ | 108/125 [4:26:15<41:44, 147.35s/it]Evaluating commonsenseqa :  87%|████████▋ | 109/125 [4:28:46<39:39, 148.71s/it]Evaluating commonsenseqa :   1%|          | 1/125 [03:29<7:13:22, 209.70s/it]Evaluating commonsenseqa :  88%|████████▊ | 110/125 [4:31:15<37:10, 148.68s/it]Evaluating commonsenseqa :   2%|▏         | 2/125 [07:00<7:10:49, 210.16s/it]Evaluating commonsenseqa :  89%|████████▉ | 111/125 [4:33:42<34:32, 148.04s/it]Evaluating commonsenseqa :   2%|▏         | 3/125 [10:26<7:03:45, 208.41s/it]Evaluating commonsenseqa :  90%|████████▉ | 112/125 [4:36:12<32:12, 148.65s/it]Evaluating commonsenseqa :  90%|█████████ | 113/125 [4:38:38<29:33, 147.81s/it]Evaluating commonsenseqa :   3%|▎         | 4/125 [13:57<7:02:39, 209.59s/it]Evaluating commonsenseqa :  91%|█████████ | 114/125 [4:41:05<27:04, 147.68s/it]Evaluating commonsenseqa :   4%|▍         | 5/125 [17:29<7:00:21, 210.18s/it]Evaluating commonsenseqa :  92%|█████████▏| 115/125 [4:43:30<24:29, 146.96s/it]Evaluating commonsenseqa :  93%|█████████▎| 116/125 [4:45:58<22:03, 147.07s/it]Evaluating commonsenseqa :   5%|▍         | 6/125 [20:56<6:54:56, 209.22s/it]Evaluating commonsenseqa :  94%|█████████▎| 117/125 [4:48:26<19:39, 147.50s/it]Evaluating commonsenseqa :   6%|▌         | 7/125 [24:28<6:52:59, 209.99s/it]Evaluating commonsenseqa :  94%|█████████▍| 118/125 [4:50:52<17:09, 147.12s/it]Evaluating commonsenseqa :   6%|▋         | 8/125 [27:57<6:48:53, 209.68s/it]Evaluating commonsenseqa :  95%|█████████▌| 119/125 [4:53:23<14:48, 148.13s/it]Evaluating commonsenseqa :  96%|█████████▌| 120/125 [4:55:51<12:20, 148.16s/it]Evaluating commonsenseqa :   7%|▋         | 9/125 [31:26<6:44:55, 209.45s/it]Evaluating commonsenseqa :  97%|█████████▋| 121/125 [4:58:16<09:48, 147.16s/it]Evaluating commonsenseqa :   8%|▊         | 10/125 [34:55<6:41:30, 209.48s/it]Evaluating commonsenseqa :  98%|█████████▊| 122/125 [5:00:44<07:22, 147.47s/it]Evaluating commonsenseqa :  98%|█████████▊| 123/125 [5:03:11<04:54, 147.40s/it]Evaluating commonsenseqa :   9%|▉         | 11/125 [38:26<6:38:48, 209.90s/it]Evaluating commonsenseqa :  99%|█████████▉| 124/125 [5:05:38<02:27, 147.19s/it]Evaluating commonsenseqa :  10%|▉         | 12/125 [41:53<6:33:35, 208.99s/it]Evaluating commonsenseqa : 100%|██████████| 125/125 [5:08:06<00:00, 147.49s/it]Evaluating commonsenseqa : 100%|██████████| 125/125 [5:08:06<00:00, 147.89s/it]
name: commonsenseqa | avg. gen lenth: 352.735 | time: 18488.574913978577s
torchrun --nproc_per_node 1 --nnodes 1 --master_addr icgpu06 --master_port 19045 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch4/danielk/ylu130/model-hf --model-hf-name meta-llama/Llama-2-7b-hf --is-opensource --is-slurm --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --batch-size 8 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --data-dir /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s30-rTrue --seed 30 --max-prompt-length 4096 --rationales --num-out-domain 8 6 7 8 9 10 True 4096 8
[2023-09-07 14:10:03,890] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch4/danielk/ylu130/model-hf
  model_hf_name ................ meta-llama/Llama-2-7b-hf
  is_opensource ................ True
  is_slurm ..................... True
  data_name .................... commonsenseqa
  data_dir ..................... /scratch4/danielk/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s30-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 8
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 4096
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o8-tgsm8k-s30-rTrue-m4096
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  batch_size ................... 8
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  gpus_per_node ................ 1
  world_size ................... 1
Loading data:   0%|          | 0/9741 [00:00<?, ?it/s]Loading data: 100%|██████████| 9741/9741 [00:00<00:00, 497149.20it/s]
Num instances: 1000
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:11<00:11, 11.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:14<00:00,  6.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:14<00:00,  7.38s/it]
 > number of parameters: 6738415616
[2023-09-07 14:10:20,423] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[2023-09-07 14:10:20,626] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-07 14:10:20,628] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-07 14:10:20,628] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-07 14:10:20,628] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-07 14:10:20,628] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-07 14:10:20,628] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1554b5f40460>
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2023-09-07 14:10:20,629] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-07 14:10:20,630] [INFO] [config.py:964:print]   loss_scale ................... 0
[2023-09-07 14:10:20,630] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-07 14:10:20,630] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-07 14:10:20,630] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-07 14:10:20,630] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-07 14:10:20,630] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-07 14:10:20,630] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-07 14:10:20,630] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-07 14:10:20,630] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-07 14:10:20,630] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-07 14:10:20,630] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-07 14:10:20,630] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-07 14:10:20,630] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-07 14:10:20,630] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-07 14:10:20,630] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-07 14:10:20,630] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-07 14:10:20,630] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-07 14:10:20,630] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2023-09-07 14:10:20,630] [INFO] [config.py:964:print]   train_batch_size ............. 1
[2023-09-07 14:10:20,630] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-09-07 14:10:20,630] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-07 14:10:20,630] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-07 14:10:20,630] [INFO] [config.py:964:print]   world_size ................... 1
[2023-09-07 14:10:20,630] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-07 14:10:20,630] [INFO] [config.py:964:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-07 14:10:20,630] [INFO] [config.py:964:print]   zero_enabled ................. False
[2023-09-07 14:10:20,630] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-07 14:10:20,630] [INFO] [config.py:964:print]   zero_optimization_stage ...... 0
[2023-09-07 14:10:20,630] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false
}
Evaluating commonsenseqa :   0%|          | 0/125 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: The car-rental agency charges $30/day for a car, or $190 for the first week for a rental that lasts an entire week or longer. Jennie rented a car for 11 days. How much, in dollars, did she pay for the rental?
Output: The first 7 days were $190.
There were 11-7=<<11-7=4>>4 days left.
The additional 4 days were 4*30=<<4*30=120>>120.
And 190+120=<<190+120=310>>310.
So the final answer is 310

Input: A hurricane is approaching the southern coast of Texas, and a rancher is planning to move 400 head of cattle 60 miles to higher ground to protect them from possible inland flooding that might occur.  His animal transport truck holds 20 head of cattle.  Traveling at 60 miles per hour, what is the total driving time, in hours, it will take to transport all of his cattle to higher ground?
Output: Given the limited capacity of his transport vehicle (20 head of cattle), the 400 head of cattle will require 400/20=<<400/20=20>>20 trips using his transport vehicle.
Traveling to the site at 60 mph for 60 miles it will take 60/60=<<60/60=1>>1 hour to travel one-way.
Since each trip requires driving to and returning from the relocation site, each complete round trip will take 2*1=<<2*1=2>>2 hours.
Thus, 20 complete trips will take 20*2=<<20*2=40>>40 hours of driving time.
So the final answer is 40

Input: Jason has a carriage house that he rents out.  He’s charging $50.00 per day or $500.00 for 14 days.  Eric wants to rent the house for 20 days.  How much will it cost him?
Output: He wants to rent for 20 days and there is a deal if you rent for 14 days so that leaves 20-14 = <<20-14=6>>6 individual days
Each individual day is $50.00 and he will have 6 individual days for a total of 50*6 = $<<50*6=300.00>>300.00
14 days costs $500.00 and 6 days costs $300.00 for a total of 500+300 = $800.00
So the final answer is 800

Input: Melissa works on a poultry farm. She drives to town twice each month to buy supplies. If it takes her 3 hours to drive to town and back, how many hours does Melissa spend driving in a year?
Output: Melissa spends 2x3=<<2*3=6>>6 hours driving each month.
Since there are 12 months in a year, she spends 6x12=<<6*12=72>>72 hours driving each year.
So the final answer is 72

Input: The ratio of boys to girls in a family is 5:7. The total number of children in the family is 180. If the boys are given $3900 to share, how much money does each boy receive?
Output: The total ratio representing the number of children in the family is 5+7 = <<5+7=12>>12
From the total ratio of children in the family, 5/12 represent the number of boys, meaning that the number of boys in the family is 5/12*180 = <<5/12*180=75>>75
If the boys are given $3900 to share, each boy receives $3900/75 = $<<3900/75=52>>52
So the final answer is 52

Input: Josephine receives a bill from the hospital for 5000$.  50 percent of the bill is for medication.  25 percent of the remaining bill is for overnight stays, and 175$ is for food.  The rest of the bill is for the ambulance ride.  How much did the ambulance ride cost?
Output: Medication:5000(.50)=2500
Overnight Stays:2500(.25)=625
2500-625=<<2500-625=1875>>1875
Food:1875-175=<<1875-175=1700>>1700$
Ambulance ride:1700$
So the final answer is 1700

Input: It was time for Kelly to harvest her carrots that she had planted in three different beds.  In the first bed she pulled out 55 carrots.  In the second bed she pulled out 101 carrots and in the third bed she pulled out 78 carrots.  She found that 6 carrots weighed one pound.  How many pounds of carrots did Kelly harvest?
Output: She pulled out 55 + 101 + 78 = <<55+101+78=234>>234
6 carrots weigh one pound so 234/6 = <<234/6=39>>39 pounds of carrots
So the final answer is 39

Input: Iris’ family is planning a surprise birthday party for her. The party will include her 3 uncles and 4 aunts who have a son and daughter each as well as her brother and mother. In total, how many people are coming to Iris’ birthday party?
Output: Each of her aunts and uncles have a family unit of 1 son + 1 daughter + 1 aunt/uncle = <<1+1+1=3>>3 people.
Iris has a total of 3 uncles + 4 aunts = <<3+4=7>>7 aunts or uncles in these family units.
So among her aunts, uncles, and cousins, there will be 7 family units * 3 people in each family unit = <<7*3=21>>21 people.
Including her mother and brother, there will be a total of 21 people + 1 mother + 1 brother = <<21+1+1=23>>23 people coming to her party.
So the final answer is 23

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o8-tgsm8k-s30-rTrue-m4096
Evaluating commonsenseqa :  10%|█         | 13/125 [45:23<6:30:51, 209.39s/it]Evaluating commonsenseqa :   1%|          | 1/125 [02:17<4:44:18, 137.57s/it]Evaluating commonsenseqa :   2%|▏         | 2/125 [04:34<4:41:11, 137.16s/it]Evaluating commonsenseqa :  11%|█         | 14/125 [48:49<6:25:20, 208.29s/it]Evaluating commonsenseqa :   2%|▏         | 3/125 [06:48<4:35:51, 135.66s/it]Evaluating commonsenseqa :   3%|▎         | 4/125 [09:04<4:34:08, 135.94s/it]Evaluating commonsenseqa :  12%|█▏        | 15/125 [52:20<6:23:38, 209.26s/it]Evaluating commonsenseqa :   4%|▍         | 5/125 [11:21<4:32:45, 136.38s/it]Evaluating commonsenseqa :  13%|█▎        | 16/125 [55:49<6:19:58, 209.16s/it]Evaluating commonsenseqa :   5%|▍         | 6/125 [13:37<4:30:01, 136.14s/it]Evaluating commonsenseqa :   6%|▌         | 7/125 [15:50<4:25:23, 134.95s/it]Evaluating commonsenseqa :  14%|█▎        | 17/125 [59:21<6:17:56, 209.97s/it]Evaluating commonsenseqa :   6%|▋         | 8/125 [18:04<4:23:05, 134.91s/it]Evaluating commonsenseqa :  14%|█▍        | 18/125 [1:02:50<6:13:41, 209.54s/it]Evaluating commonsenseqa :   7%|▋         | 9/125 [20:23<4:22:47, 135.93s/it]Evaluating commonsenseqa :   8%|▊         | 10/125 [22:35<4:18:13, 134.73s/it]Evaluating commonsenseqa :  15%|█▌        | 19/125 [1:06:17<6:08:45, 208.73s/it]Evaluating commonsenseqa :   9%|▉         | 11/125 [24:51<4:16:43, 135.12s/it]Evaluating commonsenseqa :  16%|█▌        | 20/125 [1:09:47<6:06:21, 209.35s/it]Evaluating commonsenseqa :  10%|▉         | 12/125 [27:03<4:13:06, 134.39s/it]Evaluating commonsenseqa :  10%|█         | 13/125 [29:19<4:11:44, 134.86s/it]Evaluating commonsenseqa :  17%|█▋        | 21/125 [1:13:18<6:03:39, 209.80s/it]Evaluating commonsenseqa :  11%|█         | 14/125 [31:32<4:08:13, 134.18s/it]Evaluating commonsenseqa :  18%|█▊        | 22/125 [1:16:47<5:59:53, 209.64s/it]Evaluating commonsenseqa :  12%|█▏        | 15/125 [33:48<4:06:54, 134.68s/it]Evaluating commonsenseqa :  13%|█▎        | 16/125 [36:01<4:03:47, 134.19s/it]Evaluating commonsenseqa :  18%|█▊        | 23/125 [1:20:12<5:53:52, 208.16s/it]Evaluating commonsenseqa :  14%|█▎        | 17/125 [38:17<4:02:27, 134.70s/it]Evaluating commonsenseqa :  19%|█▉        | 24/125 [1:23:38<5:49:18, 207.51s/it]Evaluating commonsenseqa :  14%|█▍        | 18/125 [40:32<4:00:30, 134.87s/it]Evaluating commonsenseqa :  15%|█▌        | 19/125 [42:46<3:58:05, 134.77s/it]Evaluating commonsenseqa :  20%|██        | 25/125 [1:27:07<5:46:23, 207.84s/it]Evaluating commonsenseqa :  16%|█▌        | 20/125 [44:59<3:54:48, 134.17s/it]Evaluating commonsenseqa :  17%|█▋        | 21/125 [47:12<3:51:48, 133.74s/it]Evaluating commonsenseqa :  21%|██        | 26/125 [1:30:34<5:42:43, 207.71s/it]Evaluating commonsenseqa :  18%|█▊        | 22/125 [49:27<3:50:30, 134.28s/it]Evaluating commonsenseqa :  22%|██▏       | 27/125 [1:34:04<5:40:21, 208.38s/it]Evaluating commonsenseqa :  18%|█▊        | 23/125 [51:42<3:48:24, 134.36s/it]slurmstepd: error: *** JOB 1108586 ON icgpu06 CANCELLED AT 2023-09-07T15:03:32 DUE TO TIME LIMIT ***
slurmstepd: error: *** JOB 999045 ON icgpu06 CANCELLED AT 2023-09-07T15:03:32 DUE TO TIME LIMIT ***
