PYTHONPATH=/home/ylu130/workspace/in-context-generalization
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 2048 --rationales --num-out-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-21 17:33:12,218] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 1
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o1-tgsm8k-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  2%|█▌                                                                                 | 190/9741 [00:00<00:05, 1899.37it/s]  4%|███▎                                                                               | 392/9741 [00:00<00:04, 1965.04it/s]  6%|█████                                                                              | 594/9741 [00:00<00:04, 1990.06it/s]  8%|██████▊                                                                            | 799/9741 [00:00<00:04, 2010.06it/s] 10%|████████▍                                                                         | 1005/9741 [00:00<00:04, 2026.40it/s] 12%|██████████▏                                                                       | 1211/9741 [00:00<00:04, 2037.27it/s] 15%|███████████▉                                                                      | 1416/9741 [00:00<00:04, 2039.90it/s] 17%|█████████████▋                                                                    | 1621/9741 [00:00<00:03, 2042.69it/s] 19%|███████████████▎                                                                  | 1826/9741 [00:00<00:03, 2035.76it/s] 21%|█████████████████                                                                 | 2030/9741 [00:01<00:03, 1989.75it/s] 23%|██████████████████▊                                                               | 2234/9741 [00:01<00:03, 2002.99it/s] 25%|████████████████████▌                                                             | 2440/9741 [00:01<00:03, 2018.62it/s] 27%|██████████████████████▎                                                           | 2645/9741 [00:01<00:03, 2025.90it/s] 29%|███████████████████████▉                                                          | 2848/9741 [00:01<00:03, 2024.41it/s] 31%|█████████████████████████▋                                                        | 3053/9741 [00:01<00:03, 2030.97it/s] 33%|███████████████████████████▍                                                      | 3258/9741 [00:01<00:03, 2036.45it/s] 36%|█████████████████████████████▏                                                    | 3463/9741 [00:01<00:03, 2039.88it/s] 38%|██████████████████████████████▉                                                   | 3668/9741 [00:01<00:02, 2037.65it/s] 40%|████████████████████████████████▌                                                 | 3874/9741 [00:01<00:02, 2044.02it/s] 42%|██████████████████████████████████▎                                               | 4079/9741 [00:02<00:02, 2040.69it/s] 44%|████████████████████████████████████                                              | 4284/9741 [00:02<00:02, 2043.42it/s] 46%|█████████████████████████████████████▊                                            | 4489/9741 [00:02<00:02, 2027.37it/s] 48%|███████████████████████████████████████▌                                          | 4698/9741 [00:02<00:02, 2044.28it/s] 50%|█████████████████████████████████████████▎                                        | 4903/9741 [00:02<00:03, 1502.82it/s] 53%|███████████████████████████████████████████▏                                      | 5131/9741 [00:02<00:02, 1687.82it/s] 56%|█████████████████████████████████████████████▊                                    | 5447/9741 [00:02<00:02, 2061.49it/s] 59%|████████████████████████████████████████████████▌                                 | 5768/9741 [00:02<00:01, 2366.00it/s] 62%|███████████████████████████████████████████████████                               | 6072/9741 [00:02<00:01, 2548.31it/s] 65%|█████████████████████████████████████████████████████▋                            | 6379/9741 [00:03<00:01, 2694.55it/s] 69%|████████████████████████████████████████████████████████▍                         | 6701/9741 [00:03<00:01, 2844.15it/s] 72%|███████████████████████████████████████████████████████████                       | 7012/9741 [00:03<00:00, 2919.46it/s] 75%|█████████████████████████████████████████████████████████████▋                    | 7331/9741 [00:03<00:00, 2998.53it/s] 78%|████████████████████████████████████████████████████████████████▎                 | 7636/9741 [00:03<00:00, 3006.09it/s] 82%|██████████████████████████████████████████████████████████████████▉               | 7955/9741 [00:03<00:00, 3059.54it/s] 85%|█████████████████████████████████████████████████████████████████████▋            | 8277/9741 [00:03<00:00, 3105.86it/s] 88%|████████████████████████████████████████████████████████████████████████▎         | 8597/9741 [00:03<00:00, 3133.65it/s] 92%|███████████████████████████████████████████████████████████████████████████       | 8919/9741 [00:03<00:00, 3156.53it/s] 95%|█████████████████████████████████████████████████████████████████████████████▊    | 9240/9741 [00:03<00:00, 3171.46it/s] 98%|████████████████████████████████████████████████████████████████████████████████▍ | 9562/9741 [00:04<00:00, 3183.85it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:04<00:00, 2377.08it/s]
Load End
Num instances: 1000
[2023-08-21 17:33:27,244] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-21 17:33:30,118] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-21 17:33:30,118] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fea2f42aa60>
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-21 17:33:30,119] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-21 17:33:30,120] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fea2f42a940>
[2023-08-21 17:33:30,120] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-21 17:33:30,120] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-21 17:33:30,120] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-21 17:33:30,120] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-21 17:33:30,120] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-21 17:33:30,120] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-21 17:33:30,120] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-21 17:33:30,120] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-21 17:33:30,120] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-21 17:33:30,120] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-21 17:33:30,120] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-21 17:33:30,120] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-21 17:33:30,120] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-21 17:33:30,120] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-21 17:33:30,120] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-21 17:33:30,120] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-21 17:33:30,120] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-21 17:33:30,120] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-21 17:33:30,120] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-21 17:33:30,120] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-21 17:33:30,120] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-21 17:33:30,120] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-21 17:33:30,120] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4434196949005127 seconds
Loading extension module utils...
Time to load utils op: 0.5047733783721924 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: Mary added a total of 7 stickers/page * 6 pages= <<7*6=42>>42 stickers to the 6 other pages.
In total, Mary added 3 large stickers + 42 stickers = <<3+42=45>>45 stickers to her journal.
Since she started with 89 stickers, she now has 89 - 45 = <<89-45=44>>44 stickers left.
So the final answer is 44

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o1-tgsm8k-s1-rTrue
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [01:05<53:17, 65.25s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [02:10<52:05, 65.12s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [03:16<51:31, 65.79s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [04:19<49:37, 64.74s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [05:24<48:21, 64.49s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [06:28<47:22, 64.61s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [07:32<46:06, 64.33s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [08:36<44:50, 64.07s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [09:39<43:40, 63.90s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [10:43<42:29, 63.73s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [11:45<41:14, 63.45s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [12:50<40:29, 63.94s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [13:51<38:52, 63.03s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [14:54<37:42, 62.86s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [15:56<36:37, 62.78s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [17:00<35:41, 62.99s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [18:03<34:40, 63.03s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [19:06<33:40, 63.13s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [20:11<32:47, 63.46s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [21:13<31:36, 63.21s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [22:15<30:19, 62.73s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [23:18<29:16, 62.73s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [24:21<28:21, 63.01s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [25:26<27:30, 63.50s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [26:31<26:36, 63.85s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [27:34<25:30, 63.78s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [28:37<24:18, 63.43s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [29:43<23:32, 64.19s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [30:46<22:21, 63.88s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [31:49<21:11, 63.59s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [32:52<20:06, 63.51s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [33:57<19:08, 63.83s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [35:01<18:08, 64.02s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [36:04<16:59, 63.74s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [37:10<16:06, 64.43s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [38:13<14:55, 63.97s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [39:18<13:54, 64.20s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [40:22<12:50, 64.20s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [41:26<11:45, 64.16s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [42:30<10:41, 64.13s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [43:34<09:35, 63.91s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [44:36<08:27, 63.44s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [45:39<07:23, 63.30s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [46:42<06:19, 63.18s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [47:45<05:15, 63.19s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [48:47<04:11, 62.92s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [49:51<03:09, 63.21s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [50:54<02:06, 63.15s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [51:59<01:03, 63.73s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [53:05<00:00, 64.21s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [53:05<00:00, 63.70s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 2.1391} | avg. gen lenth: 337.474
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 2048 --rationales --num-out-domain 2
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date![nltk_data]   Package punkt is already up-to-date!

using world size: 2
[2023-08-21 18:26:41,957] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 2
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o2-tgsm8k-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|▊                                                                                    | 91/9741 [00:00<00:10, 901.59it/s]  2%|█▌                                                                                  | 184/9741 [00:00<00:10, 918.06it/s]  3%|██▍                                                                                 | 280/9741 [00:00<00:10, 934.21it/s]  4%|███▏                                                                                | 376/9741 [00:00<00:09, 943.75it/s]  5%|████                                                                                | 472/9741 [00:00<00:09, 948.43it/s]  6%|████▉                                                                               | 568/9741 [00:00<00:09, 952.17it/s]  7%|█████▋                                                                              | 665/9741 [00:00<00:09, 957.26it/s]  8%|██████▌                                                                             | 762/9741 [00:00<00:09, 961.17it/s]  9%|███████▍                                                                            | 859/9741 [00:00<00:09, 938.42it/s] 10%|████████▏                                                                           | 955/9741 [00:01<00:09, 943.66it/s] 11%|████████▉                                                                          | 1052/9741 [00:01<00:09, 951.38it/s] 12%|█████████▊                                                                         | 1149/9741 [00:01<00:08, 955.29it/s] 13%|██████████▋                                                                       | 1273/9741 [00:01<00:08, 1039.37it/s] 15%|███████████▉                                                                      | 1418/9741 [00:01<00:07, 1161.73it/s] 16%|█████████████▏                                                                    | 1563/9741 [00:01<00:06, 1248.15it/s] 18%|██████████████▍                                                                   | 1710/9741 [00:01<00:06, 1312.14it/s] 19%|███████████████▌                                                                  | 1848/9741 [00:01<00:05, 1331.01it/s] 20%|████████████████▊                                                                 | 1993/9741 [00:01<00:05, 1366.23it/s] 22%|█████████████████▉                                                                | 2138/9741 [00:01<00:05, 1389.78it/s] 23%|███████████████████▏                                                              | 2284/9741 [00:02<00:05, 1408.50it/s] 25%|████████████████████▍                                                             | 2431/9741 [00:02<00:05, 1424.85it/s] 26%|█████████████████████▋                                                            | 2578/9741 [00:02<00:04, 1435.77it/s] 28%|██████████████████████▉                                                           | 2723/9741 [00:02<00:04, 1439.89it/s] 29%|████████████████████████▏                                                         | 2870/9741 [00:02<00:04, 1447.81it/s] 31%|█████████████████████████▍                                                        | 3017/9741 [00:02<00:04, 1452.51it/s] 32%|██████████████████████████▋                                                       | 3163/9741 [00:02<00:04, 1450.14it/s] 34%|███████████████████████████▊                                                      | 3310/9741 [00:02<00:04, 1455.88it/s] 35%|█████████████████████████████                                                     | 3456/9741 [00:02<00:04, 1456.80it/s] 37%|██████████████████████████████▎                                                   | 3602/9741 [00:02<00:04, 1451.95it/s] 38%|███████████████████████████████▌                                                  | 3748/9741 [00:03<00:04, 1452.90it/s] 40%|████████████████████████████████▊                                                 | 3894/9741 [00:03<00:04, 1449.28it/s] 41%|██████████████████████████████████                                                | 4039/9741 [00:03<00:03, 1430.33it/s] 43%|███████████████████████████████████▏                                              | 4185/9741 [00:03<00:03, 1437.56it/s] 44%|████████████████████████████████████▍                                             | 4331/9741 [00:03<00:03, 1442.59it/s] 46%|█████████████████████████████████████▋                                            | 4477/9741 [00:03<00:03, 1447.15it/s] 47%|██████████████████████████████████████▉                                           | 4622/9741 [00:03<00:03, 1405.51it/s] 49%|████████████████████████████████████████                                          | 4763/9741 [00:03<00:04, 1077.77it/s] 50%|█████████████████████████████████████████▎                                        | 4907/9741 [00:03<00:04, 1165.05it/s] 52%|██████████████████████████████████████████▌                                       | 5050/9741 [00:04<00:03, 1233.11it/s] 53%|███████████████████████████████████████████▋                                      | 5194/9741 [00:04<00:03, 1286.75it/s] 55%|████████████████████████████████████████████▉                                     | 5339/9741 [00:04<00:03, 1330.96it/s] 56%|██████████████████████████████████████████████▏                                   | 5482/9741 [00:04<00:03, 1358.38it/s] 58%|███████████████████████████████████████████████▎                                  | 5627/9741 [00:04<00:02, 1383.90it/s] 59%|████████████████████████████████████████████████▌                                 | 5772/9741 [00:04<00:02, 1401.03it/s] 61%|█████████████████████████████████████████████████▊                                | 5915/9741 [00:04<00:02, 1407.91it/s] 62%|███████████████████████████████████████████████████                               | 6061/9741 [00:04<00:02, 1421.24it/s] 64%|████████████████████████████████████████████████████▏                             | 6206/9741 [00:04<00:02, 1427.82it/s] 65%|█████████████████████████████████████████████████████▍                            | 6350/9741 [00:04<00:02, 1402.34it/s] 67%|██████████████████████████████████████████████████████▋                           | 6494/9741 [00:05<00:02, 1410.70it/s] 68%|███████████████████████████████████████████████████████▊                          | 6637/9741 [00:05<00:02, 1414.01it/s] 70%|█████████████████████████████████████████████████████████                         | 6781/9741 [00:05<00:02, 1421.65it/s] 71%|██████████████████████████████████████████████████████████▎                       | 6926/9741 [00:05<00:01, 1429.06it/s] 73%|███████████████████████████████████████████████████████████▌                      | 7071/9741 [00:05<00:01, 1433.30it/s] 74%|████████████████████████████████████████████████████████████▋                     | 7215/9741 [00:05<00:01, 1432.32it/s] 76%|█████████████████████████████████████████████████████████████▉                    | 7360/9741 [00:05<00:01, 1434.94it/s] 77%|███████████████████████████████████████████████████████████████▏                  | 7504/9741 [00:05<00:01, 1391.69it/s] 78%|████████████████████████████████████████████████████████████████▎                 | 7646/9741 [00:05<00:01, 1398.19it/s] 80%|█████████████████████████████████████████████████████████████████▌                | 7788/9741 [00:05<00:01, 1403.22it/s] 81%|██████████████████████████████████████████████████████████████████▊               | 7931/9741 [00:06<00:01, 1408.54it/s] 83%|███████████████████████████████████████████████████████████████████▉              | 8075/9741 [00:06<00:01, 1415.47it/s] 84%|█████████████████████████████████████████████████████████████████████▏            | 8218/9741 [00:06<00:01, 1417.81it/s] 86%|██████████████████████████████████████████████████████████████████████▎           | 8360/9741 [00:06<00:00, 1413.61it/s] 87%|███████████████████████████████████████████████████████████████████████▌          | 8504/9741 [00:06<00:00, 1418.99it/s] 89%|████████████████████████████████████████████████████████████████████████▊         | 8646/9741 [00:06<00:00, 1418.56it/s] 90%|█████████████████████████████████████████████████████████████████████████▉        | 8789/9741 [00:06<00:00, 1420.41it/s] 92%|███████████████████████████████████████████████████████████████████████████▏      | 8932/9741 [00:06<00:00, 1420.11it/s] 93%|████████████████████████████████████████████████████████████████████████████▍     | 9075/9741 [00:06<00:00, 1419.36it/s] 95%|█████████████████████████████████████████████████████████████████████████████▌    | 9217/9741 [00:06<00:00, 1414.14it/s] 96%|██████████████████████████████████████████████████████████████████████████████▊   | 9359/9741 [00:07<00:00, 1412.94it/s] 98%|███████████████████████████████████████████████████████████████████████████████▉  | 9501/9741 [00:07<00:00, 1391.18it/s] 99%|█████████████████████████████████████████████████████████████████████████████████▏| 9643/9741 [00:07<00:00, 1397.13it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:07<00:00, 1325.42it/s]
Load End
Num instances: 1000
[2023-08-21 18:27:00,179] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-21 18:27:03,244] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-21 18:27:03,244] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7ff236166a60>
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-21 18:27:03,245] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-21 18:27:03,246] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-21 18:27:03,246] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-21 18:27:03,246] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-21 18:27:03,246] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-21 18:27:03,246] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-21 18:27:03,246] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-21 18:27:03,246] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7ff236166940>
[2023-08-21 18:27:03,246] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-21 18:27:03,246] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-21 18:27:03,246] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-21 18:27:03,246] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-21 18:27:03,246] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-21 18:27:03,246] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-21 18:27:03,246] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-21 18:27:03,246] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-21 18:27:03,246] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-21 18:27:03,246] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-21 18:27:03,246] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-21 18:27:03,246] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-21 18:27:03,246] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-21 18:27:03,246] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-21 18:27:03,246] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-21 18:27:03,246] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-21 18:27:03,246] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-21 18:27:03,246] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-21 18:27:03,246] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-21 18:27:03,246] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-21 18:27:03,246] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-21 18:27:03,246] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-21 18:27:03,246] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4313321113586426 seconds
Loading extension module utils...
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Time to load utils op: 0.30437779426574707 seconds
Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: Mary added a total of 7 stickers/page * 6 pages= <<7*6=42>>42 stickers to the 6 other pages.
In total, Mary added 3 large stickers + 42 stickers = <<3+42=45>>45 stickers to her journal.
Since she started with 89 stickers, she now has 89 - 45 = <<89-45=44>>44 stickers left.
So the final answer is 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: If he babysits for 2 hours at $7 per hour, he will earn 2*7 = $<<2*7=14>>14
This week he will earn $5 allowance, $10 mowing the lawn and $14 from babysitting for a total of 5+10+14 = $<<5+10+14=29>>29
If we add the $29 he will earn to his $65 savings, he will have a total of 29 + 65 = $<<29+65=94>>94
The bike costs $100 and he will have $94 leaving $100-$94 = $<<100-94=6>>6 more that he will need to earn
So the final answer is 6

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o2-tgsm8k-s1-rTrue
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:54<44:36, 54.63s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:48<43:09, 53.95s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:40<41:46, 53.32s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:34<41:03, 53.56s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [04:28<40:15, 53.68s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [05:22<39:21, 53.68s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [06:15<38:29, 53.71s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [07:08<37:23, 53.42s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [08:01<36:20, 53.18s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [08:55<35:38, 53.46s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [09:48<34:43, 53.43s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [10:43<34:09, 53.94s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [11:38<33:18, 54.01s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [12:30<32:11, 53.65s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [13:25<31:22, 53.80s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [14:18<30:23, 53.62s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [15:10<29:17, 53.26s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [16:04<28:29, 53.41s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [16:57<27:32, 53.29s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [17:51<26:44, 53.47s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [18:45<25:55, 53.65s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [19:39<25:03, 53.69s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [20:32<24:03, 53.47s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [21:26<23:15, 53.68s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [22:18<22:10, 53.24s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [23:13<21:29, 53.71s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [24:06<20:33, 53.64s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [25:00<19:42, 53.74s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [25:54<18:46, 53.64s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [26:48<17:57, 53.87s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [27:41<16:58, 53.59s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [28:35<16:03, 53.54s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [29:30<15:18, 54.03s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [30:23<14:22, 53.93s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [31:16<13:23, 53.55s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [32:10<12:31, 53.70s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [33:04<11:36, 53.61s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [33:57<10:44, 53.69s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [34:51<09:49, 53.61s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [35:44<08:53, 53.37s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [36:37<08:01, 53.49s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [37:32<07:09, 53.73s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [38:26<06:17, 53.92s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [39:19<05:21, 53.56s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [40:13<04:29, 53.87s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [41:08<03:36, 54.08s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [42:02<02:41, 53.95s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [42:55<01:47, 53.82s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [43:49<00:53, 53.74s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [44:42<00:00, 53.74s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [44:42<00:00, 53.66s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.4321} | avg. gen lenth: 413.456
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o3-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 2048 --rationales --num-out-domain 3
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-21 19:11:56,021] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o3-tgsm8k-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 3
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o3-tgsm8k-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|▌                                                                                    | 70/9741 [00:00<00:13, 697.34it/s]  1%|█▏                                                                                  | 142/9741 [00:00<00:13, 707.67it/s]  2%|█▊                                                                                  | 215/9741 [00:00<00:13, 716.03it/s]  3%|██▍                                                                                 | 289/9741 [00:00<00:13, 722.89it/s]  4%|███▏                                                                                | 363/9741 [00:00<00:12, 728.69it/s]  4%|███▊                                                                                | 438/9741 [00:00<00:12, 733.04it/s]  5%|████▍                                                                               | 513/9741 [00:00<00:12, 737.97it/s]  6%|█████                                                                               | 588/9741 [00:00<00:12, 740.27it/s]  7%|█████▋                                                                              | 663/9741 [00:00<00:12, 721.37it/s]  8%|██████▎                                                                             | 737/9741 [00:01<00:12, 724.58it/s]  8%|███████                                                                             | 812/9741 [00:01<00:12, 730.81it/s]  9%|███████▋                                                                            | 886/9741 [00:01<00:12, 732.46it/s] 10%|████████▎                                                                           | 961/9741 [00:01<00:11, 736.16it/s] 11%|████████▊                                                                          | 1036/9741 [00:01<00:11, 739.95it/s] 11%|█████████▍                                                                         | 1111/9741 [00:01<00:11, 740.36it/s] 12%|██████████                                                                         | 1186/9741 [00:01<00:11, 739.12it/s] 13%|██████████▋                                                                        | 1261/9741 [00:01<00:11, 740.67it/s] 14%|███████████▍                                                                       | 1336/9741 [00:01<00:11, 739.04it/s] 14%|████████████                                                                       | 1410/9741 [00:01<00:11, 738.72it/s] 15%|████████████▋                                                                      | 1485/9741 [00:02<00:11, 740.11it/s] 16%|█████████████▎                                                                     | 1560/9741 [00:02<00:11, 738.66it/s] 17%|█████████████▉                                                                     | 1634/9741 [00:02<00:10, 738.67it/s] 18%|██████████████▌                                                                    | 1709/9741 [00:02<00:10, 739.36it/s] 18%|███████████████▏                                                                   | 1783/9741 [00:02<00:11, 722.29it/s] 19%|███████████████▉                                                                   | 1866/9741 [00:02<00:10, 752.95it/s] 20%|████████████████▊                                                                  | 1978/9741 [00:02<00:09, 859.81it/s] 21%|█████████████████▊                                                                 | 2088/9741 [00:02<00:08, 930.59it/s] 23%|██████████████████▋                                                                | 2199/9741 [00:02<00:07, 983.34it/s] 24%|███████████████████▍                                                              | 2310/9741 [00:02<00:07, 1019.05it/s] 25%|████████████████████▍                                                             | 2422/9741 [00:03<00:06, 1046.77it/s] 26%|█████████████████████▎                                                            | 2532/9741 [00:03<00:06, 1061.11it/s] 27%|██████████████████████▏                                                           | 2639/9741 [00:03<00:06, 1062.71it/s] 28%|███████████████████████▏                                                          | 2749/9741 [00:03<00:06, 1072.07it/s] 29%|████████████████████████                                                          | 2860/9741 [00:03<00:06, 1081.96it/s] 30%|█████████████████████████                                                         | 2970/9741 [00:03<00:06, 1086.73it/s] 32%|█████████████████████████▉                                                        | 3081/9741 [00:03<00:06, 1093.30it/s] 33%|██████████████████████████▊                                                       | 3191/9741 [00:03<00:05, 1094.56it/s] 34%|███████████████████████████▊                                                      | 3302/9741 [00:03<00:05, 1098.46it/s] 35%|████████████████████████████▋                                                     | 3412/9741 [00:03<00:05, 1098.71it/s] 36%|█████████████████████████████▋                                                    | 3522/9741 [00:04<00:05, 1097.61it/s] 37%|██████████████████████████████▌                                                   | 3633/9741 [00:04<00:05, 1098.70it/s] 38%|███████████████████████████████▌                                                  | 3745/9741 [00:04<00:05, 1102.67it/s] 40%|████████████████████████████████▍                                                 | 3856/9741 [00:04<00:05, 1102.25it/s] 41%|█████████████████████████████████▍                                                | 3967/9741 [00:04<00:05, 1104.08it/s] 42%|██████████████████████████████████▎                                               | 4078/9741 [00:04<00:05, 1102.88it/s] 43%|███████████████████████████████████▎                                              | 4189/9741 [00:04<00:05, 1101.58it/s] 44%|████████████████████████████████████▏                                             | 4300/9741 [00:04<00:04, 1097.75it/s] 45%|█████████████████████████████████████                                             | 4410/9741 [00:04<00:04, 1087.16it/s] 46%|██████████████████████████████████████                                            | 4519/9741 [00:04<00:05, 1037.38it/s] 48%|██████████████████████████████████████▉                                           | 4629/9741 [00:05<00:04, 1055.13it/s] 49%|████████████████████████████████████████▎                                          | 4735/9741 [00:05<00:06, 815.97it/s] 50%|█████████████████████████████████████████▎                                         | 4845/9741 [00:05<00:05, 883.48it/s] 51%|██████████████████████████████████████████▏                                        | 4955/9741 [00:05<00:05, 938.66it/s] 52%|███████████████████████████████████████████▏                                       | 5066/9741 [00:05<00:04, 983.28it/s] 53%|███████████████████████████████████████████▌                                      | 5176/9741 [00:05<00:04, 1013.57it/s] 54%|████████████████████████████████████████████▌                                     | 5287/9741 [00:05<00:04, 1038.36it/s] 55%|█████████████████████████████████████████████▍                                    | 5396/9741 [00:05<00:04, 1051.20it/s] 57%|██████████████████████████████████████████████▎                                   | 5506/9741 [00:05<00:03, 1064.56it/s] 58%|███████████████████████████████████████████████▎                                  | 5616/9741 [00:06<00:03, 1073.94it/s] 59%|████████████████████████████████████████████████▏                                 | 5727/9741 [00:06<00:03, 1083.65it/s] 60%|█████████████████████████████████████████████████▏                                | 5837/9741 [00:06<00:03, 1087.15it/s] 61%|██████████████████████████████████████████████████                                | 5947/9741 [00:06<00:03, 1089.55it/s] 62%|██████████████████████████████████████████████████▉                               | 6057/9741 [00:06<00:03, 1045.64it/s] 63%|███████████████████████████████████████████████████▉                              | 6166/9741 [00:06<00:03, 1057.00it/s] 64%|████████████████████████████████████████████████████▊                             | 6275/9741 [00:06<00:03, 1063.13it/s] 66%|█████████████████████████████████████████████████████▋                            | 6384/9741 [00:06<00:03, 1068.90it/s] 67%|██████████████████████████████████████████████████████▋                           | 6493/9741 [00:06<00:03, 1074.75it/s] 68%|███████████████████████████████████████████████████████▌                          | 6602/9741 [00:06<00:02, 1077.87it/s] 69%|████████████████████████████████████████████████████████▍                         | 6710/9741 [00:07<00:02, 1064.82it/s] 70%|█████████████████████████████████████████████████████████▍                        | 6819/9741 [00:07<00:02, 1069.81it/s] 71%|██████████████████████████████████████████████████████████▎                       | 6929/9741 [00:07<00:02, 1076.39it/s] 72%|███████████████████████████████████████████████████████████▏                      | 7038/9741 [00:07<00:02, 1077.82it/s] 73%|████████████████████████████████████████████████████████████▏                     | 7148/9741 [00:07<00:02, 1081.78it/s] 74%|█████████████████████████████████████████████████████████████                     | 7257/9741 [00:07<00:02, 1079.62it/s] 76%|██████████████████████████████████████████████████████████████                    | 7366/9741 [00:07<00:02, 1082.15it/s] 77%|██████████████████████████████████████████████████████████████▉                   | 7475/9741 [00:07<00:02, 1039.73it/s] 78%|███████████████████████████████████████████████████████████████▊                  | 7584/9741 [00:07<00:02, 1051.88it/s] 79%|████████████████████████████████████████████████████████████████▊                 | 7692/9741 [00:08<00:01, 1059.37it/s] 80%|█████████████████████████████████████████████████████████████████▋                | 7801/9741 [00:08<00:01, 1066.32it/s] 81%|██████████████████████████████████████████████████████████████████▌               | 7909/9741 [00:08<00:01, 1069.30it/s] 82%|███████████████████████████████████████████████████████████████████▍              | 8018/9741 [00:08<00:01, 1073.40it/s] 83%|████████████████████████████████████████████████████████████████████▍             | 8127/9741 [00:08<00:01, 1075.56it/s] 85%|█████████████████████████████████████████████████████████████████████▎            | 8236/9741 [00:08<00:01, 1078.79it/s] 86%|██████████████████████████████████████████████████████████████████████▏           | 8344/9741 [00:08<00:01, 1076.96it/s] 87%|███████████████████████████████████████████████████████████████████████▏          | 8452/9741 [00:08<00:01, 1077.64it/s] 88%|████████████████████████████████████████████████████████████████████████          | 8560/9741 [00:08<00:01, 1076.57it/s] 89%|████████████████████████████████████████████████████████████████████████▉         | 8668/9741 [00:08<00:00, 1075.21it/s] 90%|█████████████████████████████████████████████████████████████████████████▉        | 8776/9741 [00:09<00:00, 1073.82it/s] 91%|██████████████████████████████████████████████████████████████████████████▊       | 8884/9741 [00:09<00:00, 1074.40it/s] 92%|███████████████████████████████████████████████████████████████████████████▋      | 8992/9741 [00:09<00:00, 1075.59it/s] 93%|████████████████████████████████████████████████████████████████████████████▌     | 9100/9741 [00:09<00:00, 1070.47it/s] 95%|█████████████████████████████████████████████████████████████████████████████▌    | 9208/9741 [00:09<00:00, 1070.80it/s] 96%|██████████████████████████████████████████████████████████████████████████████▍   | 9316/9741 [00:09<00:00, 1068.26it/s] 97%|███████████████████████████████████████████████████████████████████████████████▎  | 9424/9741 [00:09<00:00, 1069.49it/s] 98%|████████████████████████████████████████████████████████████████████████████████▏ | 9531/9741 [00:09<00:00, 1067.09it/s] 99%|█████████████████████████████████████████████████████████████████████████████████▏| 9638/9741 [00:09<00:00, 1067.85it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:09<00:00, 981.23it/s]
Load End
Num instances: 1000
[2023-08-21 19:12:17,151] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-21 19:12:19,874] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-21 19:12:19,874] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7faf4bd93a60>
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-21 19:12:19,875] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7faf4bd93940>
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-21 19:12:19,876] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-21 19:12:19,876] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.45754194259643555 seconds
Loading extension module utils...
Time to load utils op: 0.5049591064453125 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: Mary added a total of 7 stickers/page * 6 pages= <<7*6=42>>42 stickers to the 6 other pages.
In total, Mary added 3 large stickers + 42 stickers = <<3+42=45>>45 stickers to her journal.
Since she started with 89 stickers, she now has 89 - 45 = <<89-45=44>>44 stickers left.
So the final answer is 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: If he babysits for 2 hours at $7 per hour, he will earn 2*7 = $<<2*7=14>>14
This week he will earn $5 allowance, $10 mowing the lawn and $14 from babysitting for a total of 5+10+14 = $<<5+10+14=29>>29
If we add the $29 he will earn to his $65 savings, he will have a total of 29 + 65 = $<<29+65=94>>94
The bike costs $100 and he will have $94 leaving $100-$94 = $<<100-94=6>>6 more that he will need to earn
So the final answer is 6

Input: Mark has kangaroos and goats.  Kangaroos have two legs and goats have four legs.  If he has 23 kangaroos and three times as many goats as kangaroos what is the total number of legs of all his animals?
Output: His kangaroos have a total of 23*2=<<23*2=46>>46 legs
He has 23*3=<<23*3=69>>69 goats
The goats have 69*4=<<69*4=276>>276 legs
So in total his animals have 276+46=<<276+46=322>>322 legs
So the final answer is 322

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o3-tgsm8k-s1-rTrue
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:49<40:23, 49.46s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:41<40:53, 51.11s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:29<38:55, 49.69s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:18<37:47, 49.29s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [04:07<36:54, 49.22s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [04:56<36:07, 49.27s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [05:45<35:10, 49.07s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [06:35<34:32, 49.35s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [07:23<33:26, 48.93s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [08:11<32:23, 48.58s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [09:00<31:40, 48.73s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [09:51<31:19, 49.45s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [10:40<30:28, 49.42s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [11:30<29:41, 49.48s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [12:19<28:43, 49.24s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [13:07<27:45, 48.98s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [13:56<26:53, 48.89s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [14:45<26:06, 48.96s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [15:34<25:21, 49.10s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [16:23<24:29, 48.97s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [17:11<23:30, 48.64s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [17:59<22:36, 48.43s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [18:47<21:45, 48.36s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [19:36<21:06, 48.73s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [20:26<20:21, 48.85s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [21:13<19:24, 48.53s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [22:01<18:30, 48.27s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [22:49<17:42, 48.29s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [23:38<16:56, 48.38s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [24:27<16:08, 48.45s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [25:17<15:29, 48.95s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [26:05<14:37, 48.76s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [26:54<13:49, 48.77s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [27:42<12:58, 48.65s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [28:31<12:11, 48.76s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [29:20<11:22, 48.75s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [30:08<10:31, 48.60s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [30:58<09:47, 48.97s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [31:47<09:00, 49.10s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [32:36<08:08, 48.85s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [33:24<07:17, 48.56s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [34:12<06:27, 48.49s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [35:00<05:38, 48.40s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [35:48<04:50, 48.37s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [36:37<04:02, 48.59s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [37:27<03:15, 48.81s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [38:16<02:26, 48.89s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [39:04<01:37, 48.57s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [39:53<00:48, 48.91s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [40:42<00:00, 48.87s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [40:42<00:00, 48.85s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.409} | avg. gen lenth: 433.884
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o4-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 2048 --rationales --num-out-domain 4
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date![nltk_data]   Package punkt is already up-to-date!

using world size: 2
[2023-08-21 19:53:10,021] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o4-tgsm8k-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 4
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o4-tgsm8k-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|▌                                                                                    | 58/9741 [00:00<00:16, 571.66it/s]  1%|█                                                                                   | 118/9741 [00:00<00:16, 583.84it/s]  2%|█▌                                                                                  | 178/9741 [00:00<00:16, 587.14it/s]  2%|██                                                                                  | 238/9741 [00:00<00:16, 591.72it/s]  3%|██▌                                                                                 | 299/9741 [00:00<00:15, 595.36it/s]  4%|███                                                                                 | 360/9741 [00:00<00:15, 598.43it/s]  4%|███▋                                                                                | 421/9741 [00:00<00:15, 599.22it/s]  5%|████▏                                                                               | 481/9741 [00:00<00:15, 592.90it/s]  6%|████▋                                                                               | 542/9741 [00:00<00:15, 595.97it/s]  6%|█████▏                                                                              | 604/9741 [00:01<00:15, 600.53it/s]  7%|█████▋                                                                              | 665/9741 [00:01<00:15, 601.24it/s]  7%|██████▎                                                                             | 726/9741 [00:01<00:14, 603.80it/s]  8%|██████▊                                                                             | 788/9741 [00:01<00:14, 606.12it/s]  9%|███████▎                                                                            | 849/9741 [00:01<00:14, 607.08it/s]  9%|███████▉                                                                            | 921/9741 [00:01<00:13, 640.46it/s] 10%|████████▌                                                                          | 1012/9741 [00:01<00:12, 721.11it/s] 11%|█████████▍                                                                         | 1104/9741 [00:01<00:11, 778.91it/s] 12%|██████████▏                                                                        | 1196/9741 [00:01<00:10, 818.76it/s] 13%|██████████▉                                                                        | 1288/9741 [00:01<00:09, 847.40it/s] 14%|███████████▊                                                                       | 1379/9741 [00:02<00:09, 865.72it/s] 15%|████████████▌                                                                      | 1471/9741 [00:02<00:09, 880.48it/s] 16%|█████████████▎                                                                     | 1562/9741 [00:02<00:09, 887.17it/s] 17%|██████████████                                                                     | 1654/9741 [00:02<00:09, 894.25it/s] 18%|██████████████▉                                                                    | 1746/9741 [00:02<00:08, 900.68it/s] 19%|███████████████▋                                                                   | 1837/9741 [00:02<00:08, 882.17it/s] 20%|████████████████▍                                                                  | 1928/9741 [00:02<00:08, 889.97it/s] 21%|█████████████████▏                                                                 | 2018/9741 [00:02<00:08, 892.85it/s] 22%|█████████████████▉                                                                 | 2109/9741 [00:02<00:08, 897.69it/s] 23%|██████████████████▊                                                                | 2201/9741 [00:02<00:08, 902.10it/s] 24%|███████████████████▌                                                               | 2292/9741 [00:03<00:08, 901.64it/s] 24%|████████████████████▎                                                              | 2383/9741 [00:03<00:08, 893.29it/s] 25%|█████████████████████                                                              | 2473/9741 [00:03<00:08, 890.60it/s] 26%|█████████████████████▊                                                             | 2563/9741 [00:03<00:08, 891.42it/s] 27%|██████████████████████▌                                                            | 2653/9741 [00:03<00:07, 893.09it/s] 28%|███████████████████████▎                                                           | 2743/9741 [00:03<00:07, 891.98it/s] 29%|████████████████████████▏                                                          | 2833/9741 [00:03<00:07, 892.06it/s] 30%|████████████████████████▉                                                          | 2923/9741 [00:03<00:07, 892.95it/s] 31%|█████████████████████████▋                                                         | 3013/9741 [00:03<00:07, 894.14it/s] 32%|██████████████████████████▍                                                        | 3103/9741 [00:03<00:07, 893.25it/s] 33%|███████████████████████████▏                                                       | 3193/9741 [00:04<00:07, 888.49it/s] 34%|███████████████████████████▉                                                       | 3282/9741 [00:04<00:07, 886.87it/s] 35%|████████████████████████████▋                                                      | 3371/9741 [00:04<00:07, 883.78it/s] 36%|█████████████████████████████▍                                                     | 3460/9741 [00:04<00:07, 884.72it/s] 36%|██████████████████████████████▏                                                    | 3549/9741 [00:04<00:07, 884.22it/s] 37%|██████████████████████████████▉                                                    | 3638/9741 [00:04<00:06, 882.37it/s] 38%|███████████████████████████████▊                                                   | 3727/9741 [00:04<00:06, 883.99it/s] 39%|████████████████████████████████▌                                                  | 3816/9741 [00:04<00:06, 882.73it/s] 40%|█████████████████████████████████▎                                                 | 3905/9741 [00:04<00:06, 884.46it/s] 41%|██████████████████████████████████                                                 | 3994/9741 [00:04<00:06, 885.02it/s] 42%|██████████████████████████████████▊                                                | 4083/9741 [00:05<00:06, 884.57it/s] 43%|███████████████████████████████████▌                                               | 4172/9741 [00:05<00:06, 885.26it/s] 44%|████████████████████████████████████▎                                              | 4261/9741 [00:05<00:06, 881.55it/s] 45%|█████████████████████████████████████                                              | 4350/9741 [00:05<00:06, 882.38it/s] 46%|█████████████████████████████████████▊                                             | 4439/9741 [00:05<00:06, 882.79it/s] 46%|██████████████████████████████████████▌                                            | 4528/9741 [00:05<00:06, 850.04it/s] 47%|███████████████████████████████████████▎                                           | 4617/9741 [00:05<00:05, 860.05it/s] 48%|████████████████████████████████████████                                           | 4706/9741 [00:05<00:05, 866.69it/s] 49%|████████████████████████████████████████▊                                          | 4793/9741 [00:05<00:06, 712.17it/s] 50%|█████████████████████████████████████████▌                                         | 4881/9741 [00:06<00:06, 754.84it/s] 51%|██████████████████████████████████████████▎                                        | 4963/9741 [00:06<00:06, 771.87it/s] 52%|███████████████████████████████████████████                                        | 5050/9741 [00:06<00:05, 798.76it/s] 53%|███████████████████████████████████████████▊                                       | 5138/9741 [00:06<00:05, 820.03it/s] 54%|████████████████████████████████████████████▌                                      | 5225/9741 [00:06<00:05, 833.88it/s] 55%|█████████████████████████████████████████████▎                                     | 5313/9741 [00:06<00:05, 846.02it/s] 55%|██████████████████████████████████████████████                                     | 5400/9741 [00:06<00:05, 850.36it/s] 56%|██████████████████████████████████████████████▊                                    | 5488/9741 [00:06<00:04, 857.82it/s] 57%|███████████████████████████████████████████████▌                                   | 5576/9741 [00:06<00:04, 863.28it/s] 58%|████████████████████████████████████████████████▎                                  | 5663/9741 [00:06<00:04, 863.31it/s] 59%|█████████████████████████████████████████████████                                  | 5752/9741 [00:07<00:04, 869.97it/s] 60%|█████████████████████████████████████████████████▊                                 | 5840/9741 [00:07<00:04, 870.17it/s] 61%|██████████████████████████████████████████████████▌                                | 5928/9741 [00:07<00:04, 872.53it/s] 62%|███████████████████████████████████████████████████▎                               | 6016/9741 [00:07<00:04, 872.31it/s] 63%|████████████████████████████████████████████████████                               | 6104/9741 [00:07<00:04, 868.89it/s] 64%|████████████████████████████████████████████████████▊                              | 6192/9741 [00:07<00:04, 870.41it/s] 64%|█████████████████████████████████████████████████████▌                             | 6280/9741 [00:07<00:03, 868.58it/s] 65%|██████████████████████████████████████████████████████▎                            | 6368/9741 [00:07<00:03, 869.38it/s] 66%|███████████████████████████████████████████████████████                            | 6455/9741 [00:07<00:03, 867.22it/s] 67%|███████████████████████████████████████████████████████▋                           | 6542/9741 [00:07<00:03, 865.73it/s] 68%|████████████████████████████████████████████████████████▍                          | 6629/9741 [00:08<00:03, 866.48it/s] 69%|█████████████████████████████████████████████████████████▏                         | 6717/9741 [00:08<00:03, 868.94it/s] 70%|█████████████████████████████████████████████████████████▉                         | 6805/9741 [00:08<00:03, 869.98it/s] 71%|██████████████████████████████████████████████████████████▋                        | 6893/9741 [00:08<00:03, 870.02it/s] 72%|███████████████████████████████████████████████████████████▍                       | 6981/9741 [00:08<00:03, 869.14it/s] 73%|████████████████████████████████████████████████████████████▏                      | 7070/9741 [00:08<00:03, 873.28it/s] 73%|████████████████████████████████████████████████████████████▉                      | 7159/9741 [00:08<00:02, 876.03it/s] 74%|█████████████████████████████████████████████████████████████▋                     | 7247/9741 [00:08<00:02, 875.38it/s] 75%|██████████████████████████████████████████████████████████████▍                    | 7335/9741 [00:08<00:02, 875.10it/s] 76%|███████████████████████████████████████████████████████████████▏                   | 7423/9741 [00:08<00:02, 842.05it/s] 77%|███████████████████████████████████████████████████████████████▉                   | 7510/9741 [00:09<00:02, 847.85it/s] 78%|████████████████████████████████████████████████████████████████▋                  | 7598/9741 [00:09<00:02, 854.54it/s] 79%|█████████████████████████████████████████████████████████████████▍                 | 7686/9741 [00:09<00:02, 859.56it/s] 80%|██████████████████████████████████████████████████████████████████▏                | 7774/9741 [00:09<00:02, 864.74it/s] 81%|██████████████████████████████████████████████████████████████████▉                | 7862/9741 [00:09<00:02, 867.39it/s] 82%|███████████████████████████████████████████████████████████████████▋               | 7949/9741 [00:09<00:02, 866.52it/s] 83%|████████████████████████████████████████████████████████████████████▍              | 8037/9741 [00:09<00:01, 867.94it/s] 83%|█████████████████████████████████████████████████████████████████████▏             | 8124/9741 [00:09<00:01, 866.98it/s] 84%|█████████████████████████████████████████████████████████████████████▉             | 8212/9741 [00:09<00:01, 869.44it/s] 85%|██████████████████████████████████████████████████████████████████████▋            | 8300/9741 [00:09<00:01, 870.79it/s] 86%|███████████████████████████████████████████████████████████████████████▍           | 8388/9741 [00:10<00:01, 870.05it/s] 87%|████████████████████████████████████████████████████████████████████████▏          | 8476/9741 [00:10<00:01, 869.43it/s] 88%|████████████████████████████████████████████████████████████████████████▉          | 8563/9741 [00:10<00:01, 866.83it/s] 89%|█████████████████████████████████████████████████████████████████████████▋         | 8650/9741 [00:10<00:01, 864.33it/s] 90%|██████████████████████████████████████████████████████████████████████████▍        | 8738/9741 [00:10<00:01, 866.41it/s] 91%|███████████████████████████████████████████████████████████████████████████▏       | 8825/9741 [00:10<00:01, 865.78it/s] 91%|███████████████████████████████████████████████████████████████████████████▉       | 8913/9741 [00:10<00:00, 868.45it/s] 92%|████████████████████████████████████████████████████████████████████████████▋      | 9000/9741 [00:10<00:00, 867.79it/s] 93%|█████████████████████████████████████████████████████████████████████████████▍     | 9087/9741 [00:10<00:00, 867.77it/s] 94%|██████████████████████████████████████████████████████████████████████████████▏    | 9174/9741 [00:10<00:00, 867.31it/s] 95%|██████████████████████████████████████████████████████████████████████████████▉    | 9261/9741 [00:11<00:00, 867.20it/s] 96%|███████████████████████████████████████████████████████████████████████████████▋   | 9349/9741 [00:11<00:00, 868.59it/s] 97%|████████████████████████████████████████████████████████████████████████████████▍  | 9436/9741 [00:11<00:00, 868.86it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▏ | 9523/9741 [00:11<00:00, 868.04it/s] 99%|█████████████████████████████████████████████████████████████████████████████████▉ | 9610/9741 [00:11<00:00, 866.73it/s]100%|██████████████████████████████████████████████████████████████████████████████████▋| 9697/9741 [00:11<00:00, 864.70it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:11<00:00, 835.87it/s]
Load End
Num instances: 1000
[2023-08-21 19:53:33,099] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-21 19:53:35,981] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-21 19:53:35,982] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-21 19:53:35,982] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-21 19:53:35,982] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-21 19:53:35,982] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-21 19:53:35,982] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-21 19:53:35,982] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-21 19:53:35,982] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-21 19:53:35,982] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f590defda60>
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f590defd940>
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-21 19:53:35,983] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-21 19:53:35,984] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-21 19:53:35,984] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-21 19:53:35,984] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-21 19:53:35,984] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.47977256774902344 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: Mary added a total of 7 stickers/page * 6 pages= <<7*6=42>>42 stickers to the 6 other pages.
In total, Mary added 3 large stickers + 42 stickers = <<3+42=45>>45 stickers to her journal.
Since she started with 89 stickers, she now has 89 - 45 = <<89-45=44>>44 stickers left.
So the final answer is 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: If he babysits for 2 hours at $7 per hour, he will earn 2*7 = $<<2*7=14>>14
This week he will earn $5 allowance, $10 mowing the lawn and $14 from babysitting for a total of 5+10+14 = $<<5+10+14=29>>29
If we add the $29 he will earn to his $65 savings, he will have a total of 29 + 65 = $<<29+65=94>>94
The bike costs $100 and he will have $94 leaving $100-$94 = $<<100-94=6>>6 more that he will need to earn
So the final answer is 6

Input: Mark has kangaroos and goats.  Kangaroos have two legs and goats have four legs.  If he has 23 kangaroos and three times as many goats as kangaroos what is the total number of legs of all his animals?
Output: His kangaroos have a total of 23*2=<<23*2=46>>46 legs
He has 23*3=<<23*3=69>>69 goats
The goats have 69*4=<<69*4=276>>276 legs
So in total his animals have 276+46=<<276+46=322>>322 legs
So the final answer is 322

Input: Josh’s mom gives him $20 to go shopping at the mall. He buys a hat for $10 and a pencil for $2. Then he buys four cookies. If each cookie costs $1.25, how much money does Josh have left?
Output: After buying a hat, Josh has $20 - $10 = $<<20-10=10>>10
After buying a pencil, Josh has $10 - $2 = $<<10-2=8>>8
The total cost of cookies is 4 * $1.25 = $<<4*1.25=5>>5
After buying the cookies, Josh has $8 - $5 = $<<8-5=3>>3
So the final answer is 3

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o4-tgsm8k-s1-rTrue
Loading extension module utils...
Time to load utils op: 0.4045267105102539 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:44<36:16, 44.42s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:28<35:28, 44.35s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:13<34:45, 44.38s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [02:57<34:00, 44.36s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [03:41<33:18, 44.41s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [04:26<32:28, 44.29s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [05:11<31:54, 44.51s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [05:55<31:08, 44.50s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [06:39<30:23, 44.47s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [07:23<29:26, 44.15s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [08:07<28:38, 44.06s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [08:50<27:51, 43.98s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [09:36<27:19, 44.32s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [10:20<26:40, 44.45s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [11:05<25:54, 44.43s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [11:49<25:12, 44.47s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [12:34<24:26, 44.44s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [13:18<23:41, 44.41s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [14:02<22:54, 44.33s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [14:47<22:11, 44.38s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [15:31<21:27, 44.38s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [16:15<20:36, 44.18s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [16:59<19:55, 44.28s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [17:44<19:12, 44.33s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [18:28<18:28, 44.33s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [19:12<17:44, 44.37s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [19:57<17:02, 44.47s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [20:42<16:20, 44.58s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [21:27<15:36, 44.57s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [22:11<14:51, 44.57s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [22:56<14:10, 44.78s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [23:41<13:23, 44.67s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [24:26<12:40, 44.71s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [25:10<11:54, 44.66s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [25:55<11:08, 44.59s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [26:38<10:20, 44.33s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [27:23<09:36, 44.32s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [28:08<08:54, 44.58s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [28:53<08:11, 44.72s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [29:38<07:27, 44.74s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [30:22<06:42, 44.68s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [31:06<05:54, 44.34s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [31:50<05:11, 44.47s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [32:34<04:25, 44.28s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [33:18<03:40, 44.13s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [34:02<02:56, 44.15s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [34:46<02:11, 43.95s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [35:30<01:28, 44.01s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [36:15<00:44, 44.35s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [37:00<00:00, 44.38s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [37:00<00:00, 44.40s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.3034} | avg. gen lenth: 439.78
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o5-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 2048 --rationales --num-out-domain 5
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-21 20:30:43,695] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o5-tgsm8k-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 5
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o5-tgsm8k-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  0%|▍                                                                                    | 45/9741 [00:00<00:21, 440.92it/s]  1%|▊                                                                                    | 91/9741 [00:00<00:21, 447.78it/s]  1%|█▏                                                                                  | 137/9741 [00:00<00:21, 451.34it/s]  2%|█▌                                                                                  | 183/9741 [00:00<00:21, 450.55it/s]  2%|█▉                                                                                  | 229/9741 [00:00<00:20, 453.87it/s]  3%|██▎                                                                                 | 275/9741 [00:00<00:20, 455.77it/s]  3%|██▊                                                                                 | 322/9741 [00:00<00:20, 457.47it/s]  4%|███▏                                                                                | 368/9741 [00:00<00:20, 448.75it/s]  4%|███▌                                                                                | 414/9741 [00:00<00:20, 449.66it/s]  5%|███▉                                                                                | 461/9741 [00:01<00:20, 453.74it/s]  5%|████▍                                                                               | 508/9741 [00:01<00:20, 455.75it/s]  6%|████▊                                                                               | 555/9741 [00:01<00:20, 457.77it/s]  6%|█████▏                                                                              | 602/9741 [00:01<00:19, 459.19it/s]  7%|█████▋                                                                              | 657/9741 [00:01<00:18, 484.36it/s]  7%|██████▎                                                                             | 728/9741 [00:01<00:16, 549.46it/s]  8%|██████▉                                                                             | 798/9741 [00:01<00:15, 592.28it/s]  9%|███████▍                                                                            | 868/9741 [00:01<00:14, 622.43it/s] 10%|████████                                                                            | 937/9741 [00:01<00:13, 640.73it/s] 10%|████████▌                                                                          | 1008/9741 [00:01<00:13, 659.95it/s] 11%|█████████▏                                                                         | 1079/9741 [00:02<00:12, 674.01it/s] 12%|█████████▊                                                                         | 1149/9741 [00:02<00:12, 681.75it/s] 13%|██████████▍                                                                        | 1219/9741 [00:02<00:12, 685.76it/s] 13%|██████████▉                                                                        | 1289/9741 [00:02<00:12, 689.52it/s] 14%|███████████▌                                                                       | 1359/9741 [00:02<00:12, 689.96it/s] 15%|████████████▏                                                                      | 1429/9741 [00:02<00:12, 691.25it/s] 15%|████████████▊                                                                      | 1499/9741 [00:02<00:11, 692.42it/s] 16%|█████████████▎                                                                     | 1569/9741 [00:02<00:11, 691.60it/s] 17%|█████████████▉                                                                     | 1639/9741 [00:02<00:11, 690.24it/s] 18%|██████████████▌                                                                    | 1709/9741 [00:02<00:11, 691.61it/s] 18%|███████████████▏                                                                   | 1779/9741 [00:03<00:11, 672.85it/s] 19%|███████████████▋                                                                   | 1847/9741 [00:03<00:11, 666.98it/s] 20%|████████████████▎                                                                  | 1916/9741 [00:03<00:11, 671.63it/s] 20%|████████████████▉                                                                  | 1985/9741 [00:03<00:11, 675.09it/s] 21%|█████████████████▍                                                                 | 2053/9741 [00:03<00:11, 675.33it/s] 22%|██████████████████                                                                 | 2122/9741 [00:03<00:11, 677.27it/s] 22%|██████████████████▋                                                                | 2190/9741 [00:03<00:11, 677.68it/s] 23%|███████████████████▏                                                               | 2258/9741 [00:03<00:11, 677.92it/s] 24%|███████████████████▊                                                               | 2327/9741 [00:03<00:10, 680.22it/s] 25%|████████████████████▍                                                              | 2396/9741 [00:03<00:10, 680.09it/s] 25%|█████████████████████                                                              | 2465/9741 [00:04<00:10, 678.09it/s] 26%|█████████████████████▌                                                             | 2533/9741 [00:04<00:10, 677.75it/s] 27%|██████████████████████▏                                                            | 2602/9741 [00:04<00:10, 678.83it/s] 27%|██████████████████████▊                                                            | 2670/9741 [00:04<00:10, 677.41it/s] 28%|███████████████████████▎                                                           | 2738/9741 [00:04<00:10, 677.24it/s] 29%|███████████████████████▉                                                           | 2806/9741 [00:04<00:10, 675.49it/s] 30%|████████████████████████▍                                                          | 2874/9741 [00:04<00:10, 676.58it/s] 30%|█████████████████████████                                                          | 2942/9741 [00:04<00:10, 674.38it/s] 31%|█████████████████████████▋                                                         | 3010/9741 [00:04<00:10, 672.45it/s] 32%|██████████████████████████▏                                                        | 3078/9741 [00:04<00:09, 673.27it/s] 32%|██████████████████████████▊                                                        | 3146/9741 [00:05<00:09, 673.90it/s] 33%|███████████████████████████▍                                                       | 3214/9741 [00:05<00:09, 675.27it/s] 34%|███████████████████████████▉                                                       | 3282/9741 [00:05<00:09, 676.55it/s] 34%|████████████████████████████▌                                                      | 3350/9741 [00:05<00:09, 674.94it/s] 35%|█████████████████████████████                                                      | 3418/9741 [00:05<00:09, 674.29it/s] 36%|█████████████████████████████▋                                                     | 3487/9741 [00:05<00:09, 677.52it/s] 36%|██████████████████████████████▎                                                    | 3555/9741 [00:05<00:09, 674.58it/s] 37%|██████████████████████████████▊                                                    | 3623/9741 [00:05<00:09, 672.52it/s] 38%|███████████████████████████████▍                                                   | 3691/9741 [00:05<00:09, 671.74it/s] 39%|████████████████████████████████                                                   | 3759/9741 [00:05<00:08, 671.17it/s] 39%|████████████████████████████████▌                                                  | 3827/9741 [00:06<00:08, 657.99it/s] 40%|█████████████████████████████████▏                                                 | 3894/9741 [00:06<00:08, 660.13it/s] 41%|█████████████████████████████████▊                                                 | 3961/9741 [00:06<00:08, 660.98it/s] 41%|██████████████████████████████████▎                                                | 4028/9741 [00:06<00:08, 663.40it/s] 42%|██████████████████████████████████▉                                                | 4096/9741 [00:06<00:08, 667.40it/s] 43%|███████████████████████████████████▍                                               | 4164/9741 [00:06<00:08, 668.58it/s] 43%|████████████████████████████████████                                               | 4231/9741 [00:06<00:08, 666.73it/s] 44%|████████████████████████████████████▌                                              | 4298/9741 [00:06<00:08, 663.92it/s] 45%|█████████████████████████████████████▏                                             | 4365/9741 [00:06<00:08, 664.37it/s] 45%|█████████████████████████████████████▊                                             | 4432/9741 [00:06<00:07, 664.17it/s] 46%|██████████████████████████████████████▎                                            | 4499/9741 [00:07<00:08, 623.79it/s] 47%|██████████████████████████████████████▉                                            | 4566/9741 [00:07<00:08, 636.65it/s] 48%|███████████████████████████████████████▍                                           | 4633/9741 [00:07<00:07, 643.93it/s] 48%|████████████████████████████████████████                                           | 4700/9741 [00:07<00:07, 649.12it/s] 49%|████████████████████████████████████████▌                                          | 4766/9741 [00:07<00:10, 478.86it/s] 50%|█████████████████████████████████████████▏                                         | 4832/9741 [00:07<00:09, 521.42it/s] 50%|█████████████████████████████████████████▋                                         | 4896/9741 [00:07<00:08, 550.88it/s] 51%|██████████████████████████████████████████▎                                        | 4962/9741 [00:07<00:08, 578.94it/s] 52%|██████████████████████████████████████████▊                                        | 5028/9741 [00:08<00:07, 599.76it/s] 52%|███████████████████████████████████████████▍                                       | 5094/9741 [00:08<00:07, 616.08it/s] 53%|███████████████████████████████████████████▉                                       | 5159/9741 [00:08<00:07, 625.72it/s] 54%|████████████████████████████████████████████▌                                      | 5225/9741 [00:08<00:07, 634.48it/s] 54%|█████████████████████████████████████████████                                      | 5291/9741 [00:08<00:06, 640.11it/s] 55%|█████████████████████████████████████████████▋                                     | 5357/9741 [00:08<00:06, 644.51it/s] 56%|██████████████████████████████████████████████▏                                    | 5423/9741 [00:08<00:06, 648.68it/s] 56%|██████████████████████████████████████████████▊                                    | 5489/9741 [00:08<00:06, 651.27it/s] 57%|███████████████████████████████████████████████▎                                   | 5556/9741 [00:08<00:06, 654.17it/s] 58%|███████████████████████████████████████████████▉                                   | 5622/9741 [00:08<00:06, 652.33it/s] 58%|████████████████████████████████████████████████▍                                  | 5688/9741 [00:09<00:06, 652.88it/s] 59%|█████████████████████████████████████████████████                                  | 5754/9741 [00:09<00:06, 652.82it/s] 60%|█████████████████████████████████████████████████▌                                 | 5820/9741 [00:09<00:05, 653.96it/s] 60%|██████████████████████████████████████████████████▏                                | 5886/9741 [00:09<00:05, 652.94it/s] 61%|██████████████████████████████████████████████████▋                                | 5952/9741 [00:09<00:05, 653.25it/s] 62%|███████████████████████████████████████████████████▎                               | 6018/9741 [00:09<00:05, 653.92it/s] 62%|███████████████████████████████████████████████████▊                               | 6084/9741 [00:09<00:05, 652.23it/s] 63%|████████████████████████████████████████████████████▍                              | 6151/9741 [00:09<00:05, 654.85it/s] 64%|████████████████████████████████████████████████████▉                              | 6218/9741 [00:09<00:05, 657.21it/s] 65%|█████████████████████████████████████████████████████▌                             | 6284/9741 [00:09<00:05, 656.43it/s] 65%|██████████████████████████████████████████████████████                             | 6350/9741 [00:10<00:05, 657.33it/s] 66%|██████████████████████████████████████████████████████▋                            | 6417/9741 [00:10<00:05, 658.97it/s] 67%|███████████████████████████████████████████████████████▏                           | 6483/9741 [00:10<00:04, 657.94it/s] 67%|███████████████████████████████████████████████████████▊                           | 6549/9741 [00:10<00:04, 655.81it/s] 68%|████████████████████████████████████████████████████████▎                          | 6615/9741 [00:10<00:04, 656.61it/s] 69%|████████████████████████████████████████████████████████▉                          | 6681/9741 [00:10<00:04, 656.73it/s] 69%|█████████████████████████████████████████████████████████▍                         | 6747/9741 [00:10<00:04, 654.63it/s] 70%|██████████████████████████████████████████████████████████                         | 6813/9741 [00:10<00:04, 654.94it/s] 71%|██████████████████████████████████████████████████████████▌                        | 6880/9741 [00:10<00:04, 656.86it/s] 71%|███████████████████████████████████████████████████████████▏                       | 6946/9741 [00:10<00:04, 657.20it/s] 72%|███████████████████████████████████████████████████████████▋                       | 7012/9741 [00:11<00:04, 655.61it/s] 73%|████████████████████████████████████████████████████████████▎                      | 7079/9741 [00:11<00:04, 657.28it/s] 73%|████████████████████████████████████████████████████████████▉                      | 7146/9741 [00:11<00:03, 658.71it/s] 74%|█████████████████████████████████████████████████████████████▍                     | 7212/9741 [00:11<00:03, 656.95it/s] 75%|██████████████████████████████████████████████████████████████                     | 7279/9741 [00:11<00:03, 658.37it/s] 75%|██████████████████████████████████████████████████████████████▌                    | 7346/9741 [00:11<00:03, 660.12it/s] 76%|███████████████████████████████████████████████████████████████▏                   | 7413/9741 [00:11<00:03, 632.33it/s] 77%|███████████████████████████████████████████████████████████████▋                   | 7478/9741 [00:11<00:03, 636.92it/s] 77%|████████████████████████████████████████████████████████████████▎                  | 7544/9741 [00:11<00:03, 642.24it/s] 78%|████████████████████████████████████████████████████████████████▊                  | 7611/9741 [00:11<00:03, 649.07it/s] 79%|█████████████████████████████████████████████████████████████████▍                 | 7677/9741 [00:12<00:03, 649.00it/s] 79%|█████████████████████████████████████████████████████████████████▉                 | 7742/9741 [00:12<00:03, 637.12it/s] 80%|██████████████████████████████████████████████████████████████████▌                | 7806/9741 [00:12<00:03, 637.69it/s] 81%|███████████████████████████████████████████████████████████████████                | 7870/9741 [00:12<00:02, 636.02it/s] 81%|███████████████████████████████████████████████████████████████████▌               | 7935/9741 [00:12<00:02, 637.36it/s] 82%|████████████████████████████████████████████████████████████████████▏              | 7999/9741 [00:12<00:02, 637.93it/s] 83%|████████████████████████████████████████████████████████████████████▋              | 8063/9741 [00:12<00:02, 638.52it/s] 83%|█████████████████████████████████████████████████████████████████████▏             | 8127/9741 [00:12<00:02, 638.04it/s] 84%|█████████████████████████████████████████████████████████████████████▊             | 8192/9741 [00:12<00:02, 639.61it/s] 85%|██████████████████████████████████████████████████████████████████████▎            | 8257/9741 [00:13<00:02, 640.17it/s] 85%|██████████████████████████████████████████████████████████████████████▉            | 8322/9741 [00:13<00:02, 638.47it/s] 86%|███████████████████████████████████████████████████████████████████████▍           | 8387/9741 [00:13<00:02, 639.59it/s] 87%|████████████████████████████████████████████████████████████████████████           | 8452/9741 [00:13<00:02, 642.28it/s] 87%|████████████████████████████████████████████████████████████████████████▌          | 8518/9741 [00:13<00:01, 646.25it/s] 88%|█████████████████████████████████████████████████████████████████████████▏         | 8583/9741 [00:13<00:01, 646.45it/s] 89%|█████████████████████████████████████████████████████████████████████████▋         | 8649/9741 [00:13<00:01, 649.95it/s] 89%|██████████████████████████████████████████████████████████████████████████▎        | 8715/9741 [00:13<00:01, 650.23it/s] 90%|██████████████████████████████████████████████████████████████████████████▊        | 8781/9741 [00:13<00:01, 650.88it/s] 91%|███████████████████████████████████████████████████████████████████████████▍       | 8847/9741 [00:13<00:01, 653.10it/s] 91%|███████████████████████████████████████████████████████████████████████████▉       | 8913/9741 [00:14<00:01, 654.97it/s] 92%|████████████████████████████████████████████████████████████████████████████▌      | 8979/9741 [00:14<00:01, 655.60it/s] 93%|█████████████████████████████████████████████████████████████████████████████      | 9045/9741 [00:14<00:01, 653.38it/s] 94%|█████████████████████████████████████████████████████████████████████████████▋     | 9111/9741 [00:14<00:00, 654.14it/s] 94%|██████████████████████████████████████████████████████████████████████████████▏    | 9177/9741 [00:14<00:00, 650.55it/s] 95%|██████████████████████████████████████████████████████████████████████████████▊    | 9243/9741 [00:14<00:00, 648.94it/s] 96%|███████████████████████████████████████████████████████████████████████████████▎   | 9309/9741 [00:14<00:00, 651.36it/s] 96%|███████████████████████████████████████████████████████████████████████████████▉   | 9376/9741 [00:14<00:00, 654.16it/s] 97%|████████████████████████████████████████████████████████████████████████████████▍  | 9442/9741 [00:14<00:00, 655.59it/s] 98%|█████████████████████████████████████████████████████████████████████████████████  | 9508/9741 [00:14<00:00, 653.59it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▌ | 9574/9741 [00:15<00:00, 652.97it/s] 99%|██████████████████████████████████████████████████████████████████████████████████▏| 9640/9741 [00:15<00:00, 649.33it/s]100%|██████████████████████████████████████████████████████████████████████████████████▋| 9705/9741 [00:15<00:00, 646.22it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:15<00:00, 636.90it/s]
Load End
Num instances: 1000
[2023-08-21 20:31:10,094] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-21 20:31:12,633] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-21 20:31:12,633] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f7c6c323a60>
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-21 20:31:12,634] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-21 20:31:12,635] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-21 20:31:12,635] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-21 20:31:12,635] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-21 20:31:12,635] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f7c6c323940>
[2023-08-21 20:31:12,635] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-21 20:31:12,635] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-21 20:31:12,635] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-21 20:31:12,635] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-21 20:31:12,635] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-21 20:31:12,635] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-21 20:31:12,635] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-21 20:31:12,635] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-21 20:31:12,635] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-21 20:31:12,635] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-21 20:31:12,635] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-21 20:31:12,635] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-21 20:31:12,635] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-21 20:31:12,635] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-21 20:31:12,635] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-21 20:31:12,635] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-21 20:31:12,635] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-21 20:31:12,635] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-21 20:31:12,635] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-21 20:31:12,635] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-21 20:31:12,635] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-21 20:31:12,635] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-21 20:31:12,635] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.46372032165527344 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: Mary added a total of 7 stickers/page * 6 pages= <<7*6=42>>42 stickers to the 6 other pages.
In total, Mary added 3 large stickers + 42 stickers = <<3+42=45>>45 stickers to her journal.
Since she started with 89 stickers, she now has 89 - 45 = <<89-45=44>>44 stickers left.
So the final answer is 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: If he babysits for 2 hours at $7 per hour, he will earn 2*7 = $<<2*7=14>>14
This week he will earn $5 allowance, $10 mowing the lawn and $14 from babysitting for a total of 5+10+14 = $<<5+10+14=29>>29
If we add the $29 he will earn to his $65 savings, he will have a total of 29 + 65 = $<<29+65=94>>94
The bike costs $100 and he will have $94 leaving $100-$94 = $<<100-94=6>>6 more that he will need to earn
So the final answer is 6

Input: Mark has kangaroos and goats.  Kangaroos have two legs and goats have four legs.  If he has 23 kangaroos and three times as many goats as kangaroos what is the total number of legs of all his animals?
Output: His kangaroos have a total of 23*2=<<23*2=46>>46 legs
He has 23*3=<<23*3=69>>69 goats
The goats have 69*4=<<69*4=276>>276 legs
So in total his animals have 276+46=<<276+46=322>>322 legs
So the final answer is 322

Input: Josh’s mom gives him $20 to go shopping at the mall. He buys a hat for $10 and a pencil for $2. Then he buys four cookies. If each cookie costs $1.25, how much money does Josh have left?
Output: After buying a hat, Josh has $20 - $10 = $<<20-10=10>>10
After buying a pencil, Josh has $10 - $2 = $<<10-2=8>>8
The total cost of cookies is 4 * $1.25 = $<<4*1.25=5>>5
After buying the cookies, Josh has $8 - $5 = $<<8-5=3>>3
So the final answer is 3

Input: George's bowling team is one round away from breaking the league record for most points scored in a season. The old record is an average score per player of 287 per round. Each team has 4 players and there are 10 rounds in the season. Through the first 9 rounds, his team has scored a total of 10,440. How many points less than the current league record per game average is the minimum average they need to score, per player, in the final round to tie the league record?
Output: The old team per round record is 1,148 because 287 x 4 = <<1148=1148>>1,148
The team season record is 11,480 because 10 x 1,248 = 11,480
They need 1,040 points in the final round to tie the record because 11,480 - 10,440 = <<11480-10440=1040>>1,040
They need to average 260 points each because 1,040 / 4 = <<1040/4=260>>260
This is 27 points less than the current record average because 287 - 260 = <<27=27>>27
So the final answer is 27

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o5-tgsm8k-s1-rTrue
Loading extension module utils...
Time to load utils op: 0.5047574043273926 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:39<32:13, 39.45s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:18<31:22, 39.23s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [01:57<30:29, 38.92s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [02:36<29:55, 39.04s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [03:16<29:34, 39.44s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [03:56<28:57, 39.49s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [04:34<28:06, 39.22s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [05:13<27:25, 39.18s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [05:52<26:37, 38.96s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [06:31<26:02, 39.06s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [07:12<25:47, 39.68s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [07:51<24:55, 39.34s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [08:30<24:18, 39.42s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [09:10<23:43, 39.54s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [09:49<23:01, 39.46s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [10:29<22:19, 39.40s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [11:08<21:43, 39.49s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [11:49<21:15, 39.87s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [12:29<20:36, 39.87s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [13:08<19:50, 39.69s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [13:47<19:06, 39.54s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [14:26<18:21, 39.35s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [15:07<17:50, 39.64s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [15:46<17:06, 39.48s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [16:25<16:21, 39.28s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [17:04<15:40, 39.17s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [17:42<14:59, 39.11s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [18:22<14:22, 39.22s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [19:01<13:41, 39.10s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [19:40<13:03, 39.20s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [20:20<12:27, 39.33s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [20:59<11:46, 39.25s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [21:38<11:06, 39.23s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [22:18<10:31, 39.44s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [22:57<09:51, 39.42s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [23:37<09:13, 39.55s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [24:16<08:32, 39.42s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [24:56<07:53, 39.50s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [25:35<07:12, 39.33s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [26:14<06:33, 39.38s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [26:55<05:56, 39.65s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [27:34<05:15, 39.44s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [28:12<04:34, 39.22s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [28:52<03:56, 39.37s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [29:31<03:16, 39.27s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [30:10<02:36, 39.08s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [30:50<01:57, 39.33s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [31:29<01:18, 39.25s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [32:08<00:39, 39.27s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [32:48<00:00, 39.41s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [32:48<00:00, 39.37s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.2587} | avg. gen lenth: 438.188
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 2048 --rationales --num-out-domain 6
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-21 21:04:12,109] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 6
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o6-tgsm8k-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  0%|▎                                                                                    | 38/9741 [00:00<00:26, 371.09it/s]  1%|▋                                                                                    | 77/9741 [00:00<00:25, 378.14it/s]  1%|█                                                                                   | 116/9741 [00:00<00:25, 380.83it/s]  2%|█▎                                                                                  | 155/9741 [00:00<00:25, 382.87it/s]  2%|█▋                                                                                  | 194/9741 [00:00<00:24, 382.02it/s]  2%|██                                                                                  | 233/9741 [00:00<00:24, 383.73it/s]  3%|██▎                                                                                 | 272/9741 [00:00<00:24, 384.84it/s]  3%|██▋                                                                                 | 311/9741 [00:00<00:24, 378.03it/s]  4%|███                                                                                 | 350/9741 [00:00<00:24, 379.57it/s]  4%|███▎                                                                                | 390/9741 [00:01<00:24, 383.02it/s]  4%|███▋                                                                                | 429/9741 [00:01<00:24, 382.07it/s]  5%|████                                                                                | 468/9741 [00:01<00:24, 384.37it/s]  5%|████▍                                                                               | 508/9741 [00:01<00:23, 386.27it/s]  6%|████▋                                                                               | 547/9741 [00:01<00:23, 387.20it/s]  6%|█████                                                                               | 586/9741 [00:01<00:23, 387.27it/s]  6%|█████▍                                                                              | 625/9741 [00:01<00:23, 386.62it/s]  7%|█████▋                                                                              | 665/9741 [00:01<00:23, 388.00it/s]  7%|██████                                                                              | 704/9741 [00:01<00:23, 386.38it/s]  8%|██████▍                                                                             | 744/9741 [00:01<00:23, 387.62it/s]  8%|██████▊                                                                             | 783/9741 [00:02<00:23, 388.30it/s]  8%|███████                                                                             | 823/9741 [00:02<00:22, 389.54it/s]  9%|███████▍                                                                            | 869/9741 [00:02<00:21, 410.10it/s] 10%|████████                                                                            | 928/9741 [00:02<00:19, 462.83it/s] 10%|████████▌                                                                           | 987/9741 [00:02<00:17, 498.90it/s] 11%|████████▉                                                                          | 1046/9741 [00:02<00:16, 524.42it/s] 11%|█████████▍                                                                         | 1104/9741 [00:02<00:15, 540.36it/s] 12%|█████████▉                                                                         | 1163/9741 [00:02<00:15, 554.07it/s] 13%|██████████▍                                                                        | 1221/9741 [00:02<00:15, 561.70it/s] 13%|██████████▉                                                                        | 1280/9741 [00:02<00:14, 567.56it/s] 14%|███████████▍                                                                       | 1338/9741 [00:03<00:14, 571.13it/s] 14%|███████████▉                                                                       | 1396/9741 [00:03<00:14, 566.58it/s] 15%|████████████▍                                                                      | 1455/9741 [00:03<00:14, 570.85it/s] 16%|████████████▉                                                                      | 1513/9741 [00:03<00:14, 572.59it/s] 16%|█████████████▍                                                                     | 1571/9741 [00:03<00:14, 572.62it/s] 17%|█████████████▉                                                                     | 1629/9741 [00:03<00:14, 573.91it/s] 17%|██████████████▎                                                                    | 1687/9741 [00:03<00:13, 575.59it/s] 18%|██████████████▊                                                                    | 1745/9741 [00:03<00:13, 576.57it/s] 19%|███████████████▎                                                                   | 1803/9741 [00:03<00:14, 549.87it/s] 19%|███████████████▊                                                                   | 1861/9741 [00:03<00:14, 558.11it/s] 20%|████████████████▎                                                                  | 1919/9741 [00:04<00:13, 563.63it/s] 20%|████████████████▊                                                                  | 1977/9741 [00:04<00:13, 567.61it/s] 21%|█████████████████▎                                                                 | 2034/9741 [00:04<00:13, 568.26it/s] 21%|█████████████████▊                                                                 | 2091/9741 [00:04<00:13, 567.91it/s] 22%|██████████████████▎                                                                | 2148/9741 [00:04<00:13, 568.36it/s] 23%|██████████████████▊                                                                | 2206/9741 [00:04<00:13, 569.59it/s] 23%|███████████████████▎                                                               | 2263/9741 [00:04<00:13, 568.16it/s] 24%|███████████████████▊                                                               | 2321/9741 [00:04<00:13, 569.03it/s] 24%|████████████████████▎                                                              | 2379/9741 [00:04<00:12, 570.71it/s] 25%|████████████████████▊                                                              | 2437/9741 [00:04<00:12, 571.76it/s] 26%|█████████████████████▎                                                             | 2495/9741 [00:05<00:12, 569.69it/s] 26%|█████████████████████▊                                                             | 2553/9741 [00:05<00:12, 569.90it/s] 27%|██████████████████████▏                                                            | 2610/9741 [00:05<00:12, 569.46it/s] 27%|██████████████████████▋                                                            | 2667/9741 [00:05<00:12, 568.22it/s] 28%|███████████████████████▏                                                           | 2725/9741 [00:05<00:12, 568.91it/s] 29%|███████████████████████▋                                                           | 2783/9741 [00:05<00:12, 569.61it/s] 29%|████████████████████████▏                                                          | 2841/9741 [00:05<00:12, 570.14it/s] 30%|████████████████████████▋                                                          | 2899/9741 [00:05<00:12, 568.34it/s] 30%|█████████████████████████▏                                                         | 2956/9741 [00:05<00:11, 567.85it/s] 31%|█████████████████████████▋                                                         | 3014/9741 [00:05<00:11, 568.59it/s] 32%|██████████████████████████▏                                                        | 3071/9741 [00:06<00:11, 559.38it/s] 32%|██████████████████████████▋                                                        | 3127/9741 [00:06<00:11, 557.48it/s] 33%|███████████████████████████▏                                                       | 3184/9741 [00:06<00:11, 559.79it/s] 33%|███████████████████████████▌                                                       | 3241/9741 [00:06<00:11, 561.47it/s] 34%|████████████████████████████                                                       | 3298/9741 [00:06<00:11, 561.93it/s] 34%|████████████████████████████▌                                                      | 3355/9741 [00:06<00:11, 559.74it/s] 35%|█████████████████████████████                                                      | 3412/9741 [00:06<00:11, 560.40it/s] 36%|█████████████████████████████▌                                                     | 3469/9741 [00:06<00:11, 560.20it/s] 36%|██████████████████████████████                                                     | 3526/9741 [00:06<00:11, 559.63it/s] 37%|██████████████████████████████▌                                                    | 3582/9741 [00:07<00:11, 557.76it/s] 37%|██████████████████████████████▉                                                    | 3638/9741 [00:07<00:10, 558.31it/s] 38%|███████████████████████████████▍                                                   | 3695/9741 [00:07<00:10, 558.91it/s] 39%|███████████████████████████████▉                                                   | 3752/9741 [00:07<00:10, 559.24it/s] 39%|████████████████████████████████▍                                                  | 3808/9741 [00:07<00:10, 557.28it/s] 40%|████████████████████████████████▉                                                  | 3865/9741 [00:07<00:10, 558.85it/s] 40%|█████████████████████████████████▍                                                 | 3922/9741 [00:07<00:10, 560.96it/s] 41%|█████████████████████████████████▉                                                 | 3979/9741 [00:07<00:10, 562.13it/s] 41%|██████████████████████████████████▍                                                | 4036/9741 [00:07<00:10, 558.60it/s] 42%|██████████████████████████████████▉                                                | 4093/9741 [00:07<00:10, 559.79it/s] 43%|███████████████████████████████████▎                                               | 4150/9741 [00:08<00:09, 560.49it/s] 43%|███████████████████████████████████▊                                               | 4207/9741 [00:08<00:09, 561.16it/s] 44%|████████████████████████████████████▎                                              | 4264/9741 [00:08<00:09, 559.43it/s] 44%|████████████████████████████████████▊                                              | 4321/9741 [00:08<00:09, 560.91it/s] 45%|█████████████████████████████████████▎                                             | 4378/9741 [00:08<00:09, 561.75it/s] 46%|█████████████████████████████████████▊                                             | 4435/9741 [00:08<00:09, 561.60it/s] 46%|██████████████████████████████████████▎                                            | 4492/9741 [00:08<00:09, 528.11it/s] 47%|██████████████████████████████████████▊                                            | 4549/9741 [00:08<00:09, 537.46it/s] 47%|███████████████████████████████████████▏                                           | 4606/9741 [00:08<00:09, 544.18it/s] 48%|███████████████████████████████████████▋                                           | 4662/9741 [00:08<00:09, 548.06it/s] 48%|████████████████████████████████████████▏                                          | 4717/9741 [00:09<00:12, 404.83it/s] 49%|████████████████████████████████████████▋                                          | 4773/9741 [00:09<00:11, 440.41it/s] 50%|█████████████████████████████████████████▏                                         | 4829/9741 [00:09<00:10, 468.58it/s] 50%|█████████████████████████████████████████▌                                         | 4885/9741 [00:09<00:09, 491.52it/s] 51%|██████████████████████████████████████████                                         | 4941/9741 [00:09<00:09, 507.78it/s] 51%|██████████████████████████████████████████▌                                        | 4997/9741 [00:09<00:09, 520.99it/s] 52%|███████████████████████████████████████████                                        | 5053/9741 [00:09<00:08, 530.49it/s] 52%|███████████████████████████████████████████▌                                       | 5109/9741 [00:09<00:08, 537.14it/s] 53%|████████████████████████████████████████████                                       | 5164/9741 [00:09<00:08, 540.31it/s] 54%|████████████████████████████████████████████▍                                      | 5220/9741 [00:10<00:08, 544.36it/s] 54%|████████████████████████████████████████████▉                                      | 5276/9741 [00:10<00:08, 548.37it/s] 55%|█████████████████████████████████████████████▍                                     | 5333/9741 [00:10<00:07, 552.14it/s] 55%|█████████████████████████████████████████████▉                                     | 5389/9741 [00:10<00:07, 552.58it/s] 56%|██████████████████████████████████████████████▍                                    | 5446/9741 [00:10<00:07, 555.19it/s] 56%|██████████████████████████████████████████████▉                                    | 5503/9741 [00:10<00:07, 556.72it/s] 57%|███████████████████████████████████████████████▍                                   | 5560/9741 [00:10<00:07, 558.05it/s] 58%|███████████████████████████████████████████████▊                                   | 5616/9741 [00:10<00:07, 556.60it/s] 58%|████████████████████████████████████████████████▎                                  | 5672/9741 [00:10<00:07, 557.46it/s] 59%|████████████████████████████████████████████████▊                                  | 5729/9741 [00:11<00:07, 558.37it/s] 59%|█████████████████████████████████████████████████▎                                 | 5786/9741 [00:11<00:07, 559.25it/s] 60%|█████████████████████████████████████████████████▊                                 | 5842/9741 [00:11<00:06, 557.71it/s] 61%|██████████████████████████████████████████████████▎                                | 5899/9741 [00:11<00:06, 558.44it/s] 61%|██████████████████████████████████████████████████▋                                | 5955/9741 [00:11<00:06, 557.22it/s] 62%|███████████████████████████████████████████████████▏                               | 6011/9741 [00:11<00:06, 556.07it/s] 62%|███████████████████████████████████████████████████▋                               | 6067/9741 [00:11<00:06, 553.08it/s] 63%|████████████████████████████████████████████████████▏                              | 6123/9741 [00:11<00:06, 553.20it/s] 63%|████████████████████████████████████████████████████▋                              | 6179/9741 [00:11<00:06, 554.09it/s] 64%|█████████████████████████████████████████████████████▏                             | 6235/9741 [00:11<00:06, 555.14it/s] 65%|█████████████████████████████████████████████████████▌                             | 6291/9741 [00:12<00:06, 554.09it/s] 65%|██████████████████████████████████████████████████████                             | 6347/9741 [00:12<00:06, 555.52it/s] 66%|██████████████████████████████████████████████████████▌                            | 6403/9741 [00:12<00:06, 546.80it/s] 66%|███████████████████████████████████████████████████████                            | 6459/9741 [00:12<00:05, 549.31it/s] 67%|███████████████████████████████████████████████████████▌                           | 6514/9741 [00:12<00:05, 548.66it/s] 67%|███████████████████████████████████████████████████████▉                           | 6570/9741 [00:12<00:05, 550.33it/s] 68%|████████████████████████████████████████████████████████▍                          | 6626/9741 [00:12<00:05, 552.06it/s] 69%|████████████████████████████████████████████████████████▉                          | 6682/9741 [00:12<00:05, 552.84it/s] 69%|█████████████████████████████████████████████████████████▍                         | 6738/9741 [00:12<00:05, 552.21it/s] 70%|█████████████████████████████████████████████████████████▉                         | 6794/9741 [00:12<00:05, 553.83it/s] 70%|██████████████████████████████████████████████████████████▎                        | 6850/9741 [00:13<00:05, 554.92it/s] 71%|██████████████████████████████████████████████████████████▊                        | 6906/9741 [00:13<00:05, 555.66it/s] 71%|███████████████████████████████████████████████████████████▎                       | 6962/9741 [00:13<00:05, 554.59it/s] 72%|███████████████████████████████████████████████████████████▊                       | 7018/9741 [00:13<00:04, 554.45it/s] 73%|████████████████████████████████████████████████████████████▎                      | 7074/9741 [00:13<00:04, 554.76it/s] 73%|████████████████████████████████████████████████████████████▊                      | 7130/9741 [00:13<00:04, 555.18it/s] 74%|█████████████████████████████████████████████████████████████▏                     | 7186/9741 [00:13<00:04, 553.98it/s] 74%|█████████████████████████████████████████████████████████████▋                     | 7242/9741 [00:13<00:04, 554.79it/s] 75%|██████████████████████████████████████████████████████████████▏                    | 7298/9741 [00:13<00:04, 555.69it/s] 75%|██████████████████████████████████████████████████████████████▋                    | 7354/9741 [00:13<00:04, 556.07it/s] 76%|███████████████████████████████████████████████████████████████▏                   | 7410/9741 [00:14<00:04, 528.39it/s] 77%|███████████████████████████████████████████████████████████████▌                   | 7466/9741 [00:14<00:04, 536.19it/s] 77%|████████████████████████████████████████████████████████████████                   | 7522/9741 [00:14<00:04, 540.79it/s] 78%|████████████████████████████████████████████████████████████████▌                  | 7577/9741 [00:14<00:04, 540.03it/s] 78%|█████████████████████████████████████████████████████████████████                  | 7632/9741 [00:14<00:03, 542.59it/s] 79%|█████████████████████████████████████████████████████████████████▍                 | 7687/9741 [00:14<00:03, 541.44it/s] 79%|█████████████████████████████████████████████████████████████████▉                 | 7743/9741 [00:14<00:03, 545.20it/s] 80%|██████████████████████████████████████████████████████████████████▍                | 7799/9741 [00:14<00:03, 547.28it/s] 81%|██████████████████████████████████████████████████████████████████▉                | 7855/9741 [00:14<00:03, 549.23it/s] 81%|███████████████████████████████████████████████████████████████████▍               | 7910/9741 [00:14<00:03, 548.71it/s] 82%|███████████████████████████████████████████████████████████████████▉               | 7966/9741 [00:15<00:03, 549.93it/s] 82%|████████████████████████████████████████████████████████████████████▎              | 8022/9741 [00:15<00:03, 550.21it/s] 83%|████████████████████████████████████████████████████████████████████▊              | 8078/9741 [00:15<00:03, 549.96it/s] 84%|█████████████████████████████████████████████████████████████████████▎             | 8134/9741 [00:15<00:02, 548.68it/s] 84%|█████████████████████████████████████████████████████████████████████▊             | 8190/9741 [00:15<00:02, 550.02it/s] 85%|██████████████████████████████████████████████████████████████████████▎            | 8246/9741 [00:15<00:02, 551.09it/s] 85%|██████████████████████████████████████████████████████████████████████▋            | 8302/9741 [00:15<00:02, 551.17it/s] 86%|███████████████████████████████████████████████████████████████████████▏           | 8358/9741 [00:15<00:02, 550.12it/s] 86%|███████████████████████████████████████████████████████████████████████▋           | 8414/9741 [00:15<00:02, 551.64it/s] 87%|████████████████████████████████████████████████████████████████████████▏          | 8471/9741 [00:15<00:02, 554.07it/s] 88%|████████████████████████████████████████████████████████████████████████▋          | 8527/9741 [00:16<00:02, 555.54it/s] 88%|█████████████████████████████████████████████████████████████████████████▏         | 8583/9741 [00:16<00:02, 552.96it/s] 89%|█████████████████████████████████████████████████████████████████████████▌         | 8639/9741 [00:16<00:01, 554.22it/s] 89%|██████████████████████████████████████████████████████████████████████████         | 8695/9741 [00:16<00:01, 555.73it/s] 90%|██████████████████████████████████████████████████████████████████████████▌        | 8751/9741 [00:16<00:01, 556.75it/s] 90%|███████████████████████████████████████████████████████████████████████████        | 8807/9741 [00:16<00:01, 554.41it/s] 91%|███████████████████████████████████████████████████████████████████████████▌       | 8863/9741 [00:16<00:01, 555.64it/s] 92%|████████████████████████████████████████████████████████████████████████████       | 8920/9741 [00:16<00:01, 557.30it/s] 92%|████████████████████████████████████████████████████████████████████████████▍      | 8976/9741 [00:16<00:01, 557.87it/s] 93%|████████████████████████████████████████████████████████████████████████████▉      | 9032/9741 [00:16<00:01, 556.05it/s] 93%|█████████████████████████████████████████████████████████████████████████████▍     | 9088/9741 [00:17<00:01, 556.15it/s] 94%|█████████████████████████████████████████████████████████████████████████████▉     | 9144/9741 [00:17<00:01, 556.38it/s] 94%|██████████████████████████████████████████████████████████████████████████████▍    | 9200/9741 [00:17<00:00, 556.97it/s] 95%|██████████████████████████████████████████████████████████████████████████████▊    | 9256/9741 [00:17<00:00, 555.28it/s] 96%|███████████████████████████████████████████████████████████████████████████████▎   | 9313/9741 [00:17<00:00, 556.72it/s] 96%|███████████████████████████████████████████████████████████████████████████████▊   | 9369/9741 [00:17<00:00, 557.00it/s] 97%|████████████████████████████████████████████████████████████████████████████████▎  | 9425/9741 [00:17<00:00, 557.31it/s] 97%|████████████████████████████████████████████████████████████████████████████████▊  | 9481/9741 [00:17<00:00, 554.72it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▎ | 9537/9741 [00:17<00:00, 553.55it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▋ | 9593/9741 [00:18<00:00, 553.06it/s] 99%|██████████████████████████████████████████████████████████████████████████████████▏| 9649/9741 [00:18<00:00, 553.66it/s]100%|██████████████████████████████████████████████████████████████████████████████████▋| 9705/9741 [00:18<00:00, 552.31it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:18<00:00, 533.21it/s]
Load End
Num instances: 1000
[2023-08-21 21:04:41,615] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-21 21:04:45,771] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-21 21:04:45,771] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f6e28e55a60>
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-21 21:04:45,772] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f6e28e55940>
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-21 21:04:45,773] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-21 21:04:45,773] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4559798240661621 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Loading extension module utils...
Time to load utils op: 0.3045485019683838 seconds
Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: Mary added a total of 7 stickers/page * 6 pages= <<7*6=42>>42 stickers to the 6 other pages.
In total, Mary added 3 large stickers + 42 stickers = <<3+42=45>>45 stickers to her journal.
Since she started with 89 stickers, she now has 89 - 45 = <<89-45=44>>44 stickers left.
So the final answer is 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: If he babysits for 2 hours at $7 per hour, he will earn 2*7 = $<<2*7=14>>14
This week he will earn $5 allowance, $10 mowing the lawn and $14 from babysitting for a total of 5+10+14 = $<<5+10+14=29>>29
If we add the $29 he will earn to his $65 savings, he will have a total of 29 + 65 = $<<29+65=94>>94
The bike costs $100 and he will have $94 leaving $100-$94 = $<<100-94=6>>6 more that he will need to earn
So the final answer is 6

Input: Mark has kangaroos and goats.  Kangaroos have two legs and goats have four legs.  If he has 23 kangaroos and three times as many goats as kangaroos what is the total number of legs of all his animals?
Output: His kangaroos have a total of 23*2=<<23*2=46>>46 legs
He has 23*3=<<23*3=69>>69 goats
The goats have 69*4=<<69*4=276>>276 legs
So in total his animals have 276+46=<<276+46=322>>322 legs
So the final answer is 322

Input: Josh’s mom gives him $20 to go shopping at the mall. He buys a hat for $10 and a pencil for $2. Then he buys four cookies. If each cookie costs $1.25, how much money does Josh have left?
Output: After buying a hat, Josh has $20 - $10 = $<<20-10=10>>10
After buying a pencil, Josh has $10 - $2 = $<<10-2=8>>8
The total cost of cookies is 4 * $1.25 = $<<4*1.25=5>>5
After buying the cookies, Josh has $8 - $5 = $<<8-5=3>>3
So the final answer is 3

Input: George's bowling team is one round away from breaking the league record for most points scored in a season. The old record is an average score per player of 287 per round. Each team has 4 players and there are 10 rounds in the season. Through the first 9 rounds, his team has scored a total of 10,440. How many points less than the current league record per game average is the minimum average they need to score, per player, in the final round to tie the league record?
Output: The old team per round record is 1,148 because 287 x 4 = <<1148=1148>>1,148
The team season record is 11,480 because 10 x 1,248 = 11,480
They need 1,040 points in the final round to tie the record because 11,480 - 10,440 = <<11480-10440=1040>>1,040
They need to average 260 points each because 1,040 / 4 = <<1040/4=260>>260
This is 27 points less than the current record average because 287 - 260 = <<27=27>>27
So the final answer is 27

Input: Max was doing homework in three different subjects. It took him 20 minutes to finish tasks from biology and two times more time to finish history. Geography took him the most time, three times more than history. How much time did Max spend on doing his homework?
Output: Max finished history in 20 * 2 = <<20*2=40>>40 minutes.
Finishing geography took the most time, which is 40 * 3 = <<40*3=120>>120 minutes.
In total, for all three subjects, Max needed 20 + 40 + 120 = <<20+40+120=180>>180 minutes.
So the final answer is 180

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o6-tgsm8k-s1-rTrue
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:38<31:33, 38.64s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:15<30:07, 37.66s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [01:52<29:19, 37.43s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [02:29<28:27, 37.12s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [03:06<27:57, 37.29s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [03:44<27:22, 37.32s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [04:21<26:35, 37.10s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [04:57<25:55, 37.03s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [05:34<25:14, 36.93s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [06:11<24:31, 36.79s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [06:47<23:52, 36.74s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [07:24<23:22, 36.90s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [08:02<22:51, 37.08s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [08:41<22:31, 37.55s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [09:18<21:55, 37.60s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [09:56<21:17, 37.58s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [10:33<20:31, 37.30s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [11:10<19:52, 37.26s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [11:47<19:13, 37.21s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [12:24<18:36, 37.20s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [13:02<18:04, 37.40s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [13:39<17:25, 37.34s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [14:16<16:44, 37.21s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [14:54<16:11, 37.37s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [15:32<15:38, 37.52s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [16:09<14:57, 37.41s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [16:46<14:20, 37.42s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [17:23<13:38, 37.22s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [18:00<12:59, 37.10s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [18:37<12:23, 37.15s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [19:14<11:43, 37.03s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [19:51<11:05, 36.97s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [20:28<10:30, 37.10s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [21:05<09:52, 37.06s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [21:42<09:14, 36.93s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [22:19<08:40, 37.20s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [22:56<08:01, 37.02s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [23:33<07:23, 36.93s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [24:09<06:45, 36.88s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [24:46<06:08, 36.82s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [25:23<05:30, 36.76s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [25:59<04:53, 36.67s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [26:36<04:17, 36.80s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [27:13<03:41, 36.89s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [27:50<03:03, 36.77s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [28:27<02:27, 36.83s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [29:03<01:50, 36.71s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [29:40<01:13, 36.76s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [30:17<00:36, 36.87s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [30:54<00:00, 36.78s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [30:54<00:00, 37.09s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.1491} | avg. gen lenth: 458.894
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o7-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 2048 --rationales --num-out-domain 7
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-21 21:35:50,470] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o7-tgsm8k-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 7
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o7-tgsm8k-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  0%|▎                                                                                    | 34/9741 [00:00<00:29, 333.27it/s]  1%|▌                                                                                    | 69/9741 [00:00<00:28, 337.60it/s]  1%|▉                                                                                   | 104/9741 [00:00<00:28, 339.25it/s]  1%|█▏                                                                                  | 139/9741 [00:00<00:28, 340.24it/s]  2%|█▌                                                                                  | 174/9741 [00:00<00:28, 339.59it/s]  2%|█▊                                                                                  | 209/9741 [00:00<00:28, 340.05it/s]  3%|██                                                                                  | 244/9741 [00:00<00:27, 340.80it/s]  3%|██▍                                                                                 | 279/9741 [00:00<00:28, 335.04it/s]  3%|██▋                                                                                 | 314/9741 [00:00<00:27, 337.53it/s]  4%|███                                                                                 | 349/9741 [00:01<00:27, 340.21it/s]  4%|███▎                                                                                | 384/9741 [00:01<00:27, 341.89it/s]  4%|███▌                                                                                | 419/9741 [00:01<00:27, 341.56it/s]  5%|███▉                                                                                | 454/9741 [00:01<00:27, 343.54it/s]  5%|████▏                                                                               | 489/9741 [00:01<00:26, 345.11it/s]  5%|████▌                                                                               | 524/9741 [00:01<00:26, 345.96it/s]  6%|████▊                                                                               | 559/9741 [00:01<00:26, 346.27it/s]  6%|█████                                                                               | 594/9741 [00:01<00:26, 346.23it/s]  6%|█████▍                                                                              | 629/9741 [00:01<00:26, 341.37it/s]  7%|█████▋                                                                              | 664/9741 [00:01<00:26, 342.45it/s]  7%|██████                                                                              | 699/9741 [00:02<00:26, 343.50it/s]  8%|██████▎                                                                             | 734/9741 [00:02<00:26, 343.72it/s]  8%|██████▊                                                                             | 785/9741 [00:02<00:22, 390.88it/s]  9%|███████▏                                                                            | 837/9741 [00:02<00:20, 428.49it/s]  9%|███████▋                                                                            | 889/9741 [00:02<00:19, 453.34it/s] 10%|████████                                                                            | 941/9741 [00:02<00:18, 472.84it/s] 10%|████████▌                                                                           | 991/9741 [00:02<00:18, 479.52it/s] 11%|████████▉                                                                          | 1043/9741 [00:02<00:17, 491.23it/s] 11%|█████████▎                                                                         | 1095/9741 [00:02<00:17, 498.16it/s] 12%|█████████▊                                                                         | 1148/9741 [00:02<00:17, 504.91it/s] 12%|██████████▏                                                                        | 1199/9741 [00:03<00:16, 504.10it/s] 13%|██████████▋                                                                        | 1251/9741 [00:03<00:16, 507.29it/s] 13%|███████████                                                                        | 1303/9741 [00:03<00:16, 510.41it/s] 14%|███████████▌                                                                       | 1355/9741 [00:03<00:16, 509.13it/s] 14%|███████████▉                                                                       | 1407/9741 [00:03<00:16, 510.66it/s] 15%|████████████▍                                                                      | 1459/9741 [00:03<00:16, 511.38it/s] 16%|████████████▊                                                                      | 1511/9741 [00:03<00:16, 511.85it/s] 16%|█████████████▎                                                                     | 1563/9741 [00:03<00:16, 509.95it/s] 17%|█████████████▊                                                                     | 1615/9741 [00:03<00:15, 510.18it/s] 17%|██████████████▏                                                                    | 1667/9741 [00:03<00:15, 511.17it/s] 18%|██████████████▋                                                                    | 1719/9741 [00:04<00:15, 511.78it/s] 18%|███████████████                                                                    | 1771/9741 [00:04<00:16, 486.28it/s] 19%|███████████████▌                                                                   | 1823/9741 [00:04<00:16, 493.88it/s] 19%|███████████████▉                                                                   | 1874/9741 [00:04<00:15, 498.26it/s] 20%|████████████████▍                                                                  | 1926/9741 [00:04<00:15, 502.83it/s] 20%|████████████████▊                                                                  | 1978/9741 [00:04<00:15, 505.86it/s] 21%|█████████████████▎                                                                 | 2029/9741 [00:04<00:15, 506.00it/s] 21%|█████████████████▋                                                                 | 2080/9741 [00:04<00:15, 506.52it/s] 22%|██████████████████▏                                                                | 2131/9741 [00:04<00:15, 507.22it/s] 22%|██████████████████▌                                                                | 2183/9741 [00:04<00:14, 508.44it/s] 23%|███████████████████                                                                | 2234/9741 [00:05<00:14, 505.69it/s] 23%|███████████████████▍                                                               | 2285/9741 [00:05<00:14, 505.88it/s] 24%|███████████████████▉                                                               | 2336/9741 [00:05<00:14, 505.21it/s] 25%|████████████████████▎                                                              | 2387/9741 [00:05<00:14, 502.88it/s] 25%|████████████████████▊                                                              | 2438/9741 [00:05<00:14, 504.47it/s] 26%|█████████████████████▏                                                             | 2489/9741 [00:05<00:14, 503.40it/s] 26%|█████████████████████▋                                                             | 2540/9741 [00:05<00:14, 504.27it/s] 27%|██████████████████████                                                             | 2591/9741 [00:05<00:14, 502.80it/s] 27%|██████████████████████▌                                                            | 2642/9741 [00:05<00:14, 502.52it/s] 28%|██████████████████████▉                                                            | 2693/9741 [00:06<00:14, 499.91it/s] 28%|███████████████████████▎                                                           | 2743/9741 [00:06<00:14, 493.82it/s] 29%|███████████████████████▊                                                           | 2794/9741 [00:06<00:14, 496.08it/s] 29%|████████████████████████▏                                                          | 2845/9741 [00:06<00:13, 497.98it/s] 30%|████████████████████████▋                                                          | 2895/9741 [00:06<00:13, 497.35it/s] 30%|█████████████████████████                                                          | 2946/9741 [00:06<00:13, 498.48it/s] 31%|█████████████████████████▌                                                         | 2997/9741 [00:06<00:13, 499.79it/s] 31%|█████████████████████████▉                                                         | 3047/9741 [00:06<00:13, 499.33it/s] 32%|██████████████████████████▍                                                        | 3098/9741 [00:06<00:13, 499.69it/s] 32%|██████████████████████████▊                                                        | 3148/9741 [00:06<00:13, 497.41it/s] 33%|███████████████████████████▎                                                       | 3199/9741 [00:07<00:13, 498.73it/s] 33%|███████████████████████████▋                                                       | 3250/9741 [00:07<00:12, 499.46it/s] 34%|████████████████████████████                                                       | 3300/9741 [00:07<00:12, 498.98it/s] 34%|████████████████████████████▌                                                      | 3350/9741 [00:07<00:12, 496.31it/s] 35%|████████████████████████████▉                                                      | 3400/9741 [00:07<00:12, 496.02it/s] 35%|█████████████████████████████▍                                                     | 3450/9741 [00:07<00:12, 495.15it/s] 36%|█████████████████████████████▊                                                     | 3500/9741 [00:07<00:12, 494.88it/s] 36%|██████████████████████████████▏                                                    | 3550/9741 [00:07<00:12, 495.25it/s] 37%|██████████████████████████████▋                                                    | 3600/9741 [00:07<00:12, 489.13it/s] 37%|███████████████████████████████                                                    | 3650/9741 [00:07<00:12, 491.82it/s] 38%|███████████████████████████████▌                                                   | 3700/9741 [00:08<00:12, 492.57it/s] 38%|███████████████████████████████▉                                                   | 3750/9741 [00:08<00:12, 493.52it/s] 39%|████████████████████████████████▍                                                  | 3800/9741 [00:08<00:12, 494.37it/s] 40%|████████████████████████████████▊                                                  | 3850/9741 [00:08<00:11, 493.49it/s] 40%|█████████████████████████████████▏                                                 | 3900/9741 [00:08<00:11, 494.74it/s] 41%|█████████████████████████████████▋                                                 | 3950/9741 [00:08<00:11, 495.29it/s] 41%|██████████████████████████████████                                                 | 4000/9741 [00:08<00:11, 495.54it/s] 42%|██████████████████████████████████▌                                                | 4050/9741 [00:08<00:11, 493.52it/s] 42%|██████████████████████████████████▉                                                | 4100/9741 [00:08<00:11, 494.04it/s] 43%|███████████████████████████████████▎                                               | 4150/9741 [00:08<00:11, 493.93it/s] 43%|███████████████████████████████████▊                                               | 4200/9741 [00:09<00:11, 493.07it/s] 44%|████████████████████████████████████▏                                              | 4250/9741 [00:09<00:11, 493.84it/s] 44%|████████████████████████████████████▋                                              | 4300/9741 [00:09<00:11, 492.13it/s] 45%|█████████████████████████████████████                                              | 4350/9741 [00:09<00:10, 492.90it/s] 45%|█████████████████████████████████████▍                                             | 4400/9741 [00:09<00:10, 493.51it/s] 46%|█████████████████████████████████████▉                                             | 4450/9741 [00:09<00:10, 493.43it/s] 46%|██████████████████████████████████████▎                                            | 4500/9741 [00:09<00:11, 461.77it/s] 47%|██████████████████████████████████████▊                                            | 4550/9741 [00:09<00:11, 470.49it/s] 47%|███████████████████████████████████████▏                                           | 4599/9741 [00:09<00:10, 476.08it/s] 48%|███████████████████████████████████████▌                                           | 4649/9741 [00:09<00:10, 481.14it/s] 48%|████████████████████████████████████████                                           | 4698/9741 [00:10<00:10, 483.69it/s] 49%|████████████████████████████████████████▍                                          | 4747/9741 [00:10<00:14, 348.72it/s] 49%|████████████████████████████████████████▊                                          | 4796/9741 [00:10<00:12, 381.03it/s] 50%|█████████████████████████████████████████▎                                         | 4845/9741 [00:10<00:12, 407.17it/s] 50%|█████████████████████████████████████████▋                                         | 4894/9741 [00:10<00:11, 428.08it/s] 51%|██████████████████████████████████████████                                         | 4943/9741 [00:10<00:10, 443.09it/s] 51%|██████████████████████████████████████████▌                                        | 4992/9741 [00:10<00:10, 455.32it/s] 52%|██████████████████████████████████████████▉                                        | 5041/9741 [00:10<00:10, 464.25it/s] 52%|███████████████████████████████████████████▎                                       | 5090/9741 [00:11<00:09, 470.94it/s] 53%|███████████████████████████████████████████▊                                       | 5139/9741 [00:11<00:09, 473.83it/s] 53%|████████████████████████████████████████████▏                                      | 5188/9741 [00:11<00:09, 477.79it/s] 54%|████████████████████████████████████████████▌                                      | 5237/9741 [00:11<00:09, 479.49it/s] 54%|█████████████████████████████████████████████                                      | 5286/9741 [00:11<00:09, 480.82it/s] 55%|█████████████████████████████████████████████▍                                     | 5335/9741 [00:11<00:09, 483.29it/s] 55%|█████████████████████████████████████████████▉                                     | 5384/9741 [00:11<00:09, 483.20it/s] 56%|██████████████████████████████████████████████▎                                    | 5433/9741 [00:11<00:08, 484.14it/s] 56%|██████████████████████████████████████████████▋                                    | 5482/9741 [00:11<00:08, 484.49it/s] 57%|███████████████████████████████████████████████▏                                   | 5532/9741 [00:11<00:08, 486.37it/s] 57%|███████████████████████████████████████████████▌                                   | 5581/9741 [00:12<00:08, 487.41it/s] 58%|███████████████████████████████████████████████▉                                   | 5630/9741 [00:12<00:08, 486.10it/s] 58%|████████████████████████████████████████████████▍                                  | 5679/9741 [00:12<00:08, 479.54it/s] 59%|████████████████████████████████████████████████▊                                  | 5727/9741 [00:12<00:08, 471.73it/s] 59%|█████████████████████████████████████████████████▏                                 | 5775/9741 [00:12<00:08, 468.89it/s] 60%|█████████████████████████████████████████████████▌                                 | 5824/9741 [00:12<00:08, 473.38it/s] 60%|██████████████████████████████████████████████████                                 | 5874/9741 [00:12<00:08, 478.86it/s] 61%|██████████████████████████████████████████████████▍                                | 5924/9741 [00:12<00:07, 482.68it/s] 61%|██████████████████████████████████████████████████▉                                | 5974/9741 [00:12<00:07, 486.64it/s] 62%|███████████████████████████████████████████████████▎                               | 6024/9741 [00:12<00:07, 487.82it/s] 62%|███████████████████████████████████████████████████▋                               | 6073/9741 [00:13<00:07, 485.73it/s] 63%|████████████████████████████████████████████████████▏                              | 6123/9741 [00:13<00:07, 488.16it/s] 63%|████████████████████████████████████████████████████▌                              | 6173/9741 [00:13<00:07, 489.69it/s] 64%|█████████████████████████████████████████████████████                              | 6223/9741 [00:13<00:07, 490.54it/s] 64%|█████████████████████████████████████████████████████▍                             | 6273/9741 [00:13<00:07, 489.00it/s] 65%|█████████████████████████████████████████████████████▊                             | 6322/9741 [00:13<00:07, 471.52it/s] 65%|██████████████████████████████████████████████████████▎                            | 6372/9741 [00:13<00:07, 477.36it/s] 66%|██████████████████████████████████████████████████████▋                            | 6422/9741 [00:13<00:06, 482.09it/s] 66%|███████████████████████████████████████████████████████▏                           | 6472/9741 [00:13<00:06, 484.66it/s] 67%|███████████████████████████████████████████████████████▌                           | 6521/9741 [00:13<00:06, 485.18it/s] 67%|███████████████████████████████████████████████████████▉                           | 6571/9741 [00:14<00:06, 487.02it/s] 68%|████████████████████████████████████████████████████████▍                          | 6621/9741 [00:14<00:06, 488.58it/s] 68%|████████████████████████████████████████████████████████▊                          | 6670/9741 [00:14<00:06, 488.77it/s] 69%|█████████████████████████████████████████████████████████▎                         | 6719/9741 [00:14<00:06, 482.68it/s] 69%|█████████████████████████████████████████████████████████▋                         | 6768/9741 [00:14<00:06, 480.82it/s] 70%|██████████████████████████████████████████████████████████                         | 6817/9741 [00:14<00:06, 483.10it/s] 70%|██████████████████████████████████████████████████████████▌                        | 6866/9741 [00:14<00:05, 484.76it/s] 71%|██████████████████████████████████████████████████████████▉                        | 6915/9741 [00:14<00:05, 486.08it/s] 71%|███████████████████████████████████████████████████████████▎                       | 6964/9741 [00:14<00:05, 485.37it/s] 72%|███████████████████████████████████████████████████████████▊                       | 7013/9741 [00:15<00:05, 486.22it/s] 73%|████████████████████████████████████████████████████████████▏                      | 7063/9741 [00:15<00:05, 487.39it/s] 73%|████████████████████████████████████████████████████████████▌                      | 7112/9741 [00:15<00:05, 487.95it/s] 74%|█████████████████████████████████████████████████████████████                      | 7162/9741 [00:15<00:05, 488.64it/s] 74%|█████████████████████████████████████████████████████████████▍                     | 7211/9741 [00:15<00:05, 486.87it/s] 75%|█████████████████████████████████████████████████████████████▊                     | 7260/9741 [00:15<00:05, 487.59it/s] 75%|██████████████████████████████████████████████████████████████▎                    | 7309/9741 [00:15<00:04, 487.67it/s] 76%|██████████████████████████████████████████████████████████████▋                    | 7358/9741 [00:15<00:04, 487.63it/s] 76%|███████████████████████████████████████████████████████████████                    | 7407/9741 [00:15<00:04, 487.01it/s] 77%|███████████████████████████████████████████████████████████████▌                   | 7456/9741 [00:15<00:05, 447.20it/s] 77%|███████████████████████████████████████████████████████████████▉                   | 7505/9741 [00:16<00:04, 458.42it/s] 78%|████████████████████████████████████████████████████████████████▎                  | 7554/9741 [00:16<00:04, 467.07it/s] 78%|████████████████████████████████████████████████████████████████▊                  | 7604/9741 [00:16<00:04, 473.90it/s] 79%|█████████████████████████████████████████████████████████████████▏                 | 7653/9741 [00:16<00:04, 476.51it/s] 79%|█████████████████████████████████████████████████████████████████▋                 | 7702/9741 [00:16<00:04, 480.23it/s] 80%|██████████████████████████████████████████████████████████████████                 | 7752/9741 [00:16<00:04, 483.68it/s] 80%|██████████████████████████████████████████████████████████████████▍                | 7801/9741 [00:16<00:04, 483.68it/s] 81%|██████████████████████████████████████████████████████████████████▉                | 7850/9741 [00:16<00:03, 484.16it/s] 81%|███████████████████████████████████████████████████████████████████▎               | 7899/9741 [00:16<00:03, 483.61it/s] 82%|███████████████████████████████████████████████████████████████████▋               | 7948/9741 [00:16<00:03, 485.27it/s] 82%|████████████████████████████████████████████████████████████████████▏              | 7997/9741 [00:17<00:03, 486.49it/s] 83%|████████████████████████████████████████████████████████████████████▌              | 8047/9741 [00:17<00:03, 487.58it/s] 83%|████████████████████████████████████████████████████████████████████▉              | 8096/9741 [00:17<00:03, 486.71it/s] 84%|█████████████████████████████████████████████████████████████████████▍             | 8146/9741 [00:17<00:03, 487.73it/s] 84%|█████████████████████████████████████████████████████████████████████▊             | 8196/9741 [00:17<00:03, 488.85it/s] 85%|██████████████████████████████████████████████████████████████████████▎            | 8245/9741 [00:17<00:03, 488.85it/s] 85%|██████████████████████████████████████████████████████████████████████▋            | 8294/9741 [00:17<00:02, 487.78it/s] 86%|███████████████████████████████████████████████████████████████████████            | 8343/9741 [00:17<00:02, 485.54it/s] 86%|███████████████████████████████████████████████████████████████████████▌           | 8392/9741 [00:17<00:02, 485.49it/s] 87%|███████████████████████████████████████████████████████████████████████▉           | 8441/9741 [00:17<00:02, 486.01it/s] 87%|████████████████████████████████████████████████████████████████████████▎          | 8490/9741 [00:18<00:02, 487.11it/s] 88%|████████████████████████████████████████████████████████████████████████▊          | 8540/9741 [00:18<00:02, 488.20it/s] 88%|█████████████████████████████████████████████████████████████████████████▏         | 8589/9741 [00:18<00:02, 486.56it/s] 89%|█████████████████████████████████████████████████████████████████████████▌         | 8638/9741 [00:18<00:02, 487.21it/s] 89%|██████████████████████████████████████████████████████████████████████████         | 8687/9741 [00:18<00:02, 487.97it/s] 90%|██████████████████████████████████████████████████████████████████████████▍        | 8737/9741 [00:18<00:02, 488.59it/s] 90%|██████████████████████████████████████████████████████████████████████████▊        | 8786/9741 [00:18<00:01, 484.67it/s] 91%|███████████████████████████████████████████████████████████████████████████▎       | 8835/9741 [00:18<00:01, 485.80it/s] 91%|███████████████████████████████████████████████████████████████████████████▋       | 8884/9741 [00:18<00:01, 486.99it/s] 92%|████████████████████████████████████████████████████████████████████████████       | 8933/9741 [00:18<00:01, 484.36it/s] 92%|████████████████████████████████████████████████████████████████████████████▌      | 8983/9741 [00:19<00:01, 486.22it/s] 93%|████████████████████████████████████████████████████████████████████████████▉      | 9032/9741 [00:19<00:01, 486.13it/s] 93%|█████████████████████████████████████████████████████████████████████████████▍     | 9082/9741 [00:19<00:01, 488.33it/s] 94%|█████████████████████████████████████████████████████████████████████████████▊     | 9132/9741 [00:19<00:01, 489.29it/s] 94%|██████████████████████████████████████████████████████████████████████████████▏    | 9181/9741 [00:19<00:01, 484.02it/s] 95%|██████████████████████████████████████████████████████████████████████████████▋    | 9230/9741 [00:19<00:01, 482.91it/s] 95%|███████████████████████████████████████████████████████████████████████████████    | 9279/9741 [00:19<00:00, 484.69it/s] 96%|███████████████████████████████████████████████████████████████████████████████▍   | 9328/9741 [00:19<00:00, 485.62it/s] 96%|███████████████████████████████████████████████████████████████████████████████▉   | 9377/9741 [00:19<00:00, 486.16it/s] 97%|████████████████████████████████████████████████████████████████████████████████▎  | 9426/9741 [00:19<00:00, 486.78it/s] 97%|████████████████████████████████████████████████████████████████████████████████▋  | 9475/9741 [00:20<00:00, 484.47it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▏ | 9524/9741 [00:20<00:00, 484.45it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▌ | 9573/9741 [00:20<00:00, 484.39it/s] 99%|█████████████████████████████████████████████████████████████████████████████████▉ | 9622/9741 [00:20<00:00, 484.41it/s] 99%|██████████████████████████████████████████████████████████████████████████████████▍| 9671/9741 [00:20<00:00, 484.36it/s]100%|██████████████████████████████████████████████████████████████████████████████████▊| 9720/9741 [00:20<00:00, 482.04it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:20<00:00, 471.82it/s]
Load End
Num instances: 1000
[2023-08-21 21:36:22,327] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-21 21:36:25,130] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-21 21:36:25,131] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-21 21:36:25,131] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-21 21:36:25,131] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-21 21:36:25,131] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-21 21:36:25,131] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-21 21:36:25,131] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-21 21:36:25,131] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-21 21:36:25,131] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-21 21:36:25,131] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-21 21:36:25,131] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-21 21:36:25,131] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f81cf70aa60>
[2023-08-21 21:36:25,131] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-21 21:36:25,131] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-21 21:36:25,131] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-21 21:36:25,131] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-21 21:36:25,131] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-21 21:36:25,131] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-21 21:36:25,131] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-21 21:36:25,131] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-21 21:36:25,131] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-21 21:36:25,131] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-21 21:36:25,131] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-21 21:36:25,131] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-21 21:36:25,131] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-21 21:36:25,131] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-21 21:36:25,131] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f81cf70a940>
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-21 21:36:25,132] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-21 21:36:25,132] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.45428466796875 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: Mary added a total of 7 stickers/page * 6 pages= <<7*6=42>>42 stickers to the 6 other pages.
In total, Mary added 3 large stickers + 42 stickers = <<3+42=45>>45 stickers to her journal.
Since she started with 89 stickers, she now has 89 - 45 = <<89-45=44>>44 stickers left.
So the final answer is 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: If he babysits for 2 hours at $7 per hour, he will earn 2*7 = $<<2*7=14>>14
This week he will earn $5 allowance, $10 mowing the lawn and $14 from babysitting for a total of 5+10+14 = $<<5+10+14=29>>29
If we add the $29 he will earn to his $65 savings, he will have a total of 29 + 65 = $<<29+65=94>>94
The bike costs $100 and he will have $94 leaving $100-$94 = $<<100-94=6>>6 more that he will need to earn
So the final answer is 6

Input: Mark has kangaroos and goats.  Kangaroos have two legs and goats have four legs.  If he has 23 kangaroos and three times as many goats as kangaroos what is the total number of legs of all his animals?
Output: His kangaroos have a total of 23*2=<<23*2=46>>46 legs
He has 23*3=<<23*3=69>>69 goats
The goats have 69*4=<<69*4=276>>276 legs
So in total his animals have 276+46=<<276+46=322>>322 legs
So the final answer is 322

Input: Josh’s mom gives him $20 to go shopping at the mall. He buys a hat for $10 and a pencil for $2. Then he buys four cookies. If each cookie costs $1.25, how much money does Josh have left?
Output: After buying a hat, Josh has $20 - $10 = $<<20-10=10>>10
After buying a pencil, Josh has $10 - $2 = $<<10-2=8>>8
The total cost of cookies is 4 * $1.25 = $<<4*1.25=5>>5
After buying the cookies, Josh has $8 - $5 = $<<8-5=3>>3
So the final answer is 3

Input: George's bowling team is one round away from breaking the league record for most points scored in a season. The old record is an average score per player of 287 per round. Each team has 4 players and there are 10 rounds in the season. Through the first 9 rounds, his team has scored a total of 10,440. How many points less than the current league record per game average is the minimum average they need to score, per player, in the final round to tie the league record?
Output: The old team per round record is 1,148 because 287 x 4 = <<1148=1148>>1,148
The team season record is 11,480 because 10 x 1,248 = 11,480
They need 1,040 points in the final round to tie the record because 11,480 - 10,440 = <<11480-10440=1040>>1,040
They need to average 260 points each because 1,040 / 4 = <<1040/4=260>>260
This is 27 points less than the current record average because 287 - 260 = <<27=27>>27
So the final answer is 27

Input: Max was doing homework in three different subjects. It took him 20 minutes to finish tasks from biology and two times more time to finish history. Geography took him the most time, three times more than history. How much time did Max spend on doing his homework?
Output: Max finished history in 20 * 2 = <<20*2=40>>40 minutes.
Finishing geography took the most time, which is 40 * 3 = <<40*3=120>>120 minutes.
In total, for all three subjects, Max needed 20 + 40 + 120 = <<20+40+120=180>>180 minutes.
So the final answer is 180

Input: Sophia ate 1/6 of her pie and she put the rest on the fridge. If the pie left in the fridge weighs 1200 grams, how many grams did Sophia eat?
Output: If Sophia ate 1/6 of the pie, then 6/6 - 1/6 = 5/6 is left in the fridge.
Let x be the pie's original weight.
The current weight of the pie can be described by 5x/6=1200 grams
So, 5x=7200.
And, the original weight is x = <<1440=1440>>1440 grams.
So, Sophia ate 1440 grams original - 1200 grams after= <<1440-1200=240>>240 grams of pie.
So the final answer is 240

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o7-tgsm8k-s1-rTrue
Loading extension module utils...
Time to load utils op: 0.5050289630889893 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:35<28:51, 35.33s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:10<28:11, 35.23s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [01:45<27:34, 35.20s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [02:20<26:57, 35.16s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [02:55<26:13, 34.96s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [03:30<25:40, 35.01s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [04:05<25:04, 34.99s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [04:40<24:29, 34.99s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [05:15<23:55, 35.02s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [05:50<23:21, 35.04s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [06:25<22:48, 35.09s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [07:00<22:08, 34.95s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [07:35<21:33, 34.96s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [08:10<21:02, 35.06s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [08:45<20:22, 34.94s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [09:20<19:51, 35.04s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [09:55<19:10, 34.87s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [10:30<18:36, 34.88s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [11:04<18:01, 34.90s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [11:40<17:28, 34.95s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [12:14<16:53, 34.94s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [12:49<16:17, 34.92s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [13:24<15:41, 34.87s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [13:59<15:09, 34.99s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [14:34<14:33, 34.92s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [15:10<14:02, 35.09s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [15:45<13:26, 35.07s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [16:19<12:49, 34.98s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [16:54<12:15, 35.02s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [17:29<11:37, 34.89s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [18:04<11:02, 34.87s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [18:39<10:27, 34.85s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [19:14<09:54, 34.98s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [19:49<09:19, 34.95s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [20:24<08:44, 34.96s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [20:59<08:08, 34.89s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [21:33<07:33, 34.85s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [22:09<07:00, 35.00s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [22:44<06:24, 34.96s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [23:20<05:52, 35.27s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [23:55<05:16, 35.20s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [24:29<04:39, 34.97s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [25:04<04:05, 35.04s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [25:39<03:29, 34.91s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [26:14<02:54, 34.93s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [26:50<02:21, 35.26s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [27:24<01:45, 35.06s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [27:59<01:10, 35.02s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [28:34<00:34, 35.00s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [29:09<00:00, 34.89s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [29:09<00:00, 34.99s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.1376} | avg. gen lenth: 449.17
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 2048 --rationales --num-out-domain 8
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-21 22:05:48,458] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 8
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o8-tgsm8k-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  0%|▎                                                                                    | 31/9741 [00:00<00:32, 303.39it/s]  1%|▌                                                                                    | 62/9741 [00:00<00:31, 307.17it/s]  1%|▊                                                                                    | 94/9741 [00:00<00:31, 309.47it/s]  1%|█                                                                                   | 126/9741 [00:00<00:30, 310.81it/s]  2%|█▎                                                                                  | 158/9741 [00:00<00:30, 311.47it/s]  2%|█▋                                                                                  | 190/9741 [00:00<00:30, 310.46it/s]  2%|█▉                                                                                  | 222/9741 [00:00<00:30, 312.04it/s]  3%|██▏                                                                                 | 254/9741 [00:00<00:30, 306.51it/s]  3%|██▍                                                                                 | 286/9741 [00:00<00:30, 307.88it/s]  3%|██▋                                                                                 | 318/9741 [00:01<00:30, 308.78it/s]  4%|███                                                                                 | 350/9741 [00:01<00:30, 309.61it/s]  4%|███▎                                                                                | 382/9741 [00:01<00:30, 310.07it/s]  4%|███▌                                                                                | 414/9741 [00:01<00:30, 308.48it/s]  5%|███▊                                                                                | 446/9741 [00:01<00:30, 309.12it/s]  5%|████                                                                                | 478/9741 [00:01<00:29, 310.22it/s]  5%|████▍                                                                               | 510/9741 [00:01<00:29, 311.17it/s]  6%|████▋                                                                               | 542/9741 [00:01<00:29, 309.44it/s]  6%|████▉                                                                               | 574/9741 [00:01<00:29, 309.91it/s]  6%|█████▏                                                                              | 606/9741 [00:01<00:29, 310.56it/s]  7%|█████▌                                                                              | 638/9741 [00:02<00:29, 308.06it/s]  7%|█████▊                                                                              | 669/9741 [00:02<00:30, 302.24it/s]  7%|██████                                                                              | 700/9741 [00:02<00:29, 304.14it/s]  8%|██████▎                                                                             | 732/9741 [00:02<00:29, 305.83it/s]  8%|██████▌                                                                             | 763/9741 [00:02<00:29, 302.06it/s]  8%|██████▊                                                                             | 794/9741 [00:02<00:29, 302.33it/s]  9%|███████▏                                                                            | 832/9741 [00:02<00:27, 324.24it/s]  9%|███████▌                                                                            | 878/9741 [00:02<00:24, 362.85it/s]  9%|███████▉                                                                            | 925/9741 [00:02<00:22, 392.12it/s] 10%|████████▍                                                                           | 972/9741 [00:02<00:21, 412.75it/s] 10%|████████▋                                                                          | 1019/9741 [00:03<00:20, 426.98it/s] 11%|█████████                                                                          | 1065/9741 [00:03<00:19, 436.59it/s] 11%|█████████▍                                                                         | 1111/9741 [00:03<00:19, 441.59it/s] 12%|█████████▊                                                                         | 1158/9741 [00:03<00:19, 447.69it/s] 12%|██████████▎                                                                        | 1205/9741 [00:03<00:18, 452.46it/s] 13%|██████████▋                                                                        | 1252/9741 [00:03<00:18, 455.54it/s] 13%|███████████                                                                        | 1298/9741 [00:03<00:18, 456.74it/s] 14%|███████████▍                                                                       | 1344/9741 [00:03<00:18, 454.63it/s] 14%|███████████▊                                                                       | 1390/9741 [00:03<00:18, 454.54it/s] 15%|████████████▏                                                                      | 1436/9741 [00:04<00:18, 455.53it/s] 15%|████████████▋                                                                      | 1482/9741 [00:04<00:18, 456.25it/s] 16%|█████████████                                                                      | 1528/9741 [00:04<00:18, 456.01it/s] 16%|█████████████▍                                                                     | 1574/9741 [00:04<00:17, 454.04it/s] 17%|█████████████▊                                                                     | 1620/9741 [00:04<00:17, 453.23it/s] 17%|██████████████▏                                                                    | 1666/9741 [00:04<00:17, 454.02it/s] 18%|██████████████▌                                                                    | 1712/9741 [00:04<00:17, 451.67it/s] 18%|██████████████▉                                                                    | 1758/9741 [00:04<00:17, 452.12it/s] 19%|███████████████▎                                                                   | 1804/9741 [00:04<00:18, 433.76it/s] 19%|███████████████▊                                                                   | 1850/9741 [00:04<00:17, 438.74it/s] 19%|████████████████▏                                                                  | 1895/9741 [00:05<00:17, 439.19it/s] 20%|████████████████▌                                                                  | 1940/9741 [00:05<00:17, 441.65it/s] 20%|████████████████▉                                                                  | 1986/9741 [00:05<00:17, 443.01it/s] 21%|█████████████████▎                                                                 | 2032/9741 [00:05<00:17, 446.20it/s] 21%|█████████████████▋                                                                 | 2078/9741 [00:05<00:17, 448.53it/s] 22%|██████████████████                                                                 | 2123/9741 [00:05<00:16, 448.87it/s] 22%|██████████████████▍                                                                | 2169/9741 [00:05<00:16, 450.47it/s] 23%|██████████████████▊                                                                | 2215/9741 [00:05<00:17, 440.92it/s] 23%|███████████████████▎                                                               | 2261/9741 [00:05<00:16, 444.05it/s] 24%|███████████████████▋                                                               | 2306/9741 [00:05<00:16, 445.72it/s] 24%|████████████████████                                                               | 2351/9741 [00:06<00:16, 446.24it/s] 25%|████████████████████▍                                                              | 2396/9741 [00:06<00:16, 447.05it/s] 25%|████████████████████▊                                                              | 2441/9741 [00:06<00:16, 440.18it/s] 26%|█████████████████████▏                                                             | 2486/9741 [00:06<00:16, 441.56it/s] 26%|█████████████████████▌                                                             | 2531/9741 [00:06<00:16, 443.90it/s] 26%|█████████████████████▉                                                             | 2577/9741 [00:06<00:16, 445.81it/s] 27%|██████████████████████▎                                                            | 2623/9741 [00:06<00:15, 447.59it/s] 27%|██████████████████████▋                                                            | 2668/9741 [00:06<00:15, 445.92it/s] 28%|███████████████████████                                                            | 2713/9741 [00:06<00:15, 446.21it/s] 28%|███████████████████████▌                                                           | 2758/9741 [00:06<00:15, 444.08it/s] 29%|███████████████████████▉                                                           | 2803/9741 [00:07<00:15, 443.46it/s] 29%|████████████████████████▎                                                          | 2848/9741 [00:07<00:15, 443.57it/s] 30%|████████████████████████▋                                                          | 2893/9741 [00:07<00:15, 444.02it/s] 30%|█████████████████████████                                                          | 2938/9741 [00:07<00:15, 437.08it/s] 31%|█████████████████████████▍                                                         | 2983/9741 [00:07<00:15, 439.34it/s] 31%|█████████████████████████▊                                                         | 3027/9741 [00:07<00:15, 434.78it/s] 32%|██████████████████████████▏                                                        | 3072/9741 [00:07<00:15, 437.32it/s] 32%|██████████████████████████▌                                                        | 3117/9741 [00:07<00:15, 439.72it/s] 32%|██████████████████████████▉                                                        | 3161/9741 [00:07<00:14, 438.83it/s] 33%|███████████████████████████▎                                                       | 3206/9741 [00:07<00:14, 440.97it/s] 33%|███████████████████████████▋                                                       | 3251/9741 [00:08<00:14, 442.30it/s] 34%|████████████████████████████                                                       | 3296/9741 [00:08<00:14, 441.98it/s] 34%|████████████████████████████▍                                                      | 3341/9741 [00:08<00:14, 435.02it/s] 35%|████████████████████████████▊                                                      | 3385/9741 [00:08<00:14, 435.65it/s] 35%|█████████████████████████████▏                                                     | 3430/9741 [00:08<00:14, 438.32it/s] 36%|█████████████████████████████▌                                                     | 3474/9741 [00:08<00:14, 427.93it/s] 36%|█████████████████████████████▉                                                     | 3517/9741 [00:08<00:14, 425.94it/s] 37%|██████████████████████████████▎                                                    | 3562/9741 [00:08<00:14, 430.78it/s] 37%|██████████████████████████████▋                                                    | 3606/9741 [00:08<00:14, 431.90it/s] 37%|███████████████████████████████                                                    | 3651/9741 [00:09<00:13, 435.19it/s] 38%|███████████████████████████████▍                                                   | 3695/9741 [00:09<00:13, 436.60it/s] 38%|███████████████████████████████▊                                                   | 3739/9741 [00:09<00:13, 437.42it/s] 39%|████████████████████████████████▏                                                  | 3784/9741 [00:09<00:13, 438.24it/s] 39%|████████████████████████████████▌                                                  | 3828/9741 [00:09<00:13, 437.60it/s] 40%|████████████████████████████████▉                                                  | 3872/9741 [00:09<00:13, 438.03it/s] 40%|█████████████████████████████████▎                                                 | 3916/9741 [00:09<00:13, 436.96it/s] 41%|█████████████████████████████████▋                                                 | 3960/9741 [00:09<00:13, 428.71it/s] 41%|██████████████████████████████████                                                 | 4003/9741 [00:09<00:13, 427.05it/s] 42%|██████████████████████████████████▍                                                | 4046/9741 [00:09<00:13, 427.00it/s] 42%|██████████████████████████████████▊                                                | 4090/9741 [00:10<00:13, 429.87it/s] 42%|███████████████████████████████████▏                                               | 4134/9741 [00:10<00:12, 431.94it/s] 43%|███████████████████████████████████▌                                               | 4178/9741 [00:10<00:12, 433.51it/s] 43%|███████████████████████████████████▉                                               | 4222/9741 [00:10<00:12, 434.70it/s] 44%|████████████████████████████████████▎                                              | 4266/9741 [00:10<00:12, 434.02it/s] 44%|████████████████████████████████████▋                                              | 4311/9741 [00:10<00:12, 435.96it/s] 45%|█████████████████████████████████████                                              | 4355/9741 [00:10<00:12, 436.97it/s] 45%|█████████████████████████████████████▍                                             | 4399/9741 [00:10<00:12, 437.84it/s] 46%|█████████████████████████████████████▊                                             | 4443/9741 [00:10<00:12, 432.17it/s] 46%|██████████████████████████████████████▏                                            | 4487/9741 [00:10<00:13, 401.62it/s] 47%|██████████████████████████████████████▌                                            | 4531/9741 [00:11<00:12, 411.68it/s] 47%|██████████████████████████████████████▉                                            | 4576/9741 [00:11<00:12, 420.00it/s] 47%|███████████████████████████████████████▎                                           | 4619/9741 [00:11<00:12, 419.95it/s] 48%|███████████████████████████████████████▋                                           | 4663/9741 [00:11<00:11, 423.41it/s] 48%|████████████████████████████████████████                                           | 4707/9741 [00:11<00:11, 426.00it/s] 49%|████████████████████████████████████████▍                                          | 4750/9741 [00:11<00:14, 333.60it/s] 49%|████████████████████████████████████████▊                                          | 4794/9741 [00:11<00:13, 358.75it/s] 50%|█████████████████████████████████████████▏                                         | 4838/9741 [00:11<00:12, 378.70it/s] 50%|█████████████████████████████████████████▌                                         | 4880/9741 [00:11<00:12, 388.74it/s] 51%|█████████████████████████████████████████▉                                         | 4921/9741 [00:12<00:12, 393.10it/s] 51%|██████████████████████████████████████████▎                                        | 4965/9741 [00:12<00:11, 404.49it/s] 51%|██████████████████████████████████████████▋                                        | 5009/9741 [00:12<00:11, 412.81it/s] 52%|███████████████████████████████████████████                                        | 5053/9741 [00:12<00:11, 418.58it/s] 52%|███████████████████████████████████████████▍                                       | 5097/9741 [00:12<00:10, 423.29it/s] 53%|███████████████████████████████████████████▊                                       | 5141/9741 [00:12<00:10, 425.46it/s] 53%|████████████████████████████████████████████▏                                      | 5185/9741 [00:12<00:10, 429.01it/s] 54%|████████████████████████████████████████████▌                                      | 5229/9741 [00:12<00:10, 431.38it/s] 54%|████████████████████████████████████████████▉                                      | 5273/9741 [00:12<00:10, 427.86it/s] 55%|█████████████████████████████████████████████▎                                     | 5316/9741 [00:12<00:10, 426.54it/s] 55%|█████████████████████████████████████████████▋                                     | 5359/9741 [00:13<00:10, 421.68it/s] 55%|██████████████████████████████████████████████                                     | 5402/9741 [00:13<00:10, 423.19it/s] 56%|██████████████████████████████████████████████▍                                    | 5445/9741 [00:13<00:10, 420.63it/s] 56%|██████████████████████████████████████████████▊                                    | 5489/9741 [00:13<00:10, 423.93it/s] 57%|███████████████████████████████████████████████▏                                   | 5533/9741 [00:13<00:09, 426.67it/s] 57%|███████████████████████████████████████████████▌                                   | 5577/9741 [00:13<00:09, 428.69it/s] 58%|███████████████████████████████████████████████▉                                   | 5620/9741 [00:13<00:09, 427.57it/s] 58%|████████████████████████████████████████████████▎                                  | 5663/9741 [00:13<00:09, 422.64it/s] 59%|████████████████████████████████████████████████▌                                  | 5706/9741 [00:13<00:09, 419.63it/s] 59%|████████████████████████████████████████████████▉                                  | 5750/9741 [00:14<00:09, 423.53it/s] 59%|█████████████████████████████████████████████████▎                                 | 5794/9741 [00:14<00:09, 426.32it/s] 60%|█████████████████████████████████████████████████▋                                 | 5837/9741 [00:14<00:09, 425.55it/s] 60%|██████████████████████████████████████████████████                                 | 5881/9741 [00:14<00:09, 428.05it/s] 61%|██████████████████████████████████████████████████▍                                | 5925/9741 [00:14<00:08, 428.95it/s] 61%|██████████████████████████████████████████████████▊                                | 5968/9741 [00:14<00:08, 428.76it/s] 62%|███████████████████████████████████████████████████▏                               | 6011/9741 [00:14<00:08, 428.84it/s] 62%|███████████████████████████████████████████████████▌                               | 6054/9741 [00:14<00:08, 426.84it/s] 63%|███████████████████████████████████████████████████▉                               | 6097/9741 [00:14<00:08, 427.45it/s] 63%|████████████████████████████████████████████████████▎                              | 6140/9741 [00:14<00:08, 427.66it/s] 63%|████████████████████████████████████████████████████▋                              | 6183/9741 [00:15<00:08, 428.08it/s] 64%|█████████████████████████████████████████████████████                              | 6226/9741 [00:15<00:08, 427.84it/s] 64%|█████████████████████████████████████████████████████▍                             | 6269/9741 [00:15<00:08, 422.01it/s] 65%|█████████████████████████████████████████████████████▊                             | 6312/9741 [00:15<00:08, 418.96it/s] 65%|██████████████████████████████████████████████████████▏                            | 6355/9741 [00:15<00:08, 421.06it/s] 66%|██████████████████████████████████████████████████████▌                            | 6398/9741 [00:15<00:07, 423.51it/s] 66%|██████████████████████████████████████████████████████▉                            | 6441/9741 [00:15<00:07, 421.53it/s] 67%|███████████████████████████████████████████████████████▏                           | 6484/9741 [00:15<00:07, 422.40it/s] 67%|███████████████████████████████████████████████████████▌                           | 6527/9741 [00:15<00:07, 421.84it/s] 67%|███████████████████████████████████████████████████████▉                           | 6570/9741 [00:15<00:07, 424.17it/s] 68%|████████████████████████████████████████████████████████▎                          | 6613/9741 [00:16<00:07, 425.15it/s] 68%|████████████████████████████████████████████████████████▋                          | 6657/9741 [00:16<00:07, 426.90it/s] 69%|█████████████████████████████████████████████████████████                          | 6701/9741 [00:16<00:07, 428.75it/s] 69%|█████████████████████████████████████████████████████████▍                         | 6744/9741 [00:16<00:07, 424.79it/s] 70%|█████████████████████████████████████████████████████████▊                         | 6787/9741 [00:16<00:06, 424.43it/s] 70%|██████████████████████████████████████████████████████████▏                        | 6830/9741 [00:16<00:06, 420.41it/s] 71%|██████████████████████████████████████████████████████████▌                        | 6874/9741 [00:16<00:06, 423.85it/s] 71%|██████████████████████████████████████████████████████████▉                        | 6918/9741 [00:16<00:06, 425.91it/s] 71%|███████████████████████████████████████████████████████████▎                       | 6961/9741 [00:16<00:06, 426.02it/s] 72%|███████████████████████████████████████████████████████████▋                       | 7005/9741 [00:16<00:06, 428.22it/s] 72%|████████████████████████████████████████████████████████████                       | 7049/9741 [00:17<00:06, 429.88it/s] 73%|████████████████████████████████████████████████████████████▍                      | 7093/9741 [00:17<00:06, 430.65it/s] 73%|████████████████████████████████████████████████████████████▊                      | 7137/9741 [00:17<00:06, 431.36it/s] 74%|█████████████████████████████████████████████████████████████▏                     | 7181/9741 [00:17<00:06, 425.51it/s] 74%|█████████████████████████████████████████████████████████████▌                     | 7224/9741 [00:17<00:06, 418.87it/s] 75%|█████████████████████████████████████████████████████████████▉                     | 7267/9741 [00:17<00:05, 421.57it/s] 75%|██████████████████████████████████████████████████████████████▎                    | 7310/9741 [00:17<00:05, 423.49it/s] 75%|██████████████████████████████████████████████████████████████▋                    | 7354/9741 [00:17<00:05, 425.62it/s] 76%|███████████████████████████████████████████████████████████████                    | 7398/9741 [00:17<00:05, 427.09it/s] 76%|███████████████████████████████████████████████████████████████▍                   | 7441/9741 [00:18<00:05, 404.25it/s] 77%|███████████████████████████████████████████████████████████████▊                   | 7485/9741 [00:18<00:05, 412.46it/s] 77%|████████████████████████████████████████████████████████████████▏                  | 7527/9741 [00:18<00:05, 411.45it/s] 78%|████████████████████████████████████████████████████████████████▌                  | 7571/9741 [00:18<00:05, 417.57it/s] 78%|████████████████████████████████████████████████████████████████▉                  | 7615/9741 [00:18<00:05, 422.57it/s] 79%|█████████████████████████████████████████████████████████████████▎                 | 7658/9741 [00:18<00:04, 423.21it/s] 79%|█████████████████████████████████████████████████████████████████▋                 | 7702/9741 [00:18<00:04, 425.36it/s] 80%|██████████████████████████████████████████████████████████████████                 | 7746/9741 [00:18<00:04, 427.75it/s] 80%|██████████████████████████████████████████████████████████████████▍                | 7790/9741 [00:18<00:04, 428.90it/s] 80%|██████████████████████████████████████████████████████████████████▊                | 7834/9741 [00:18<00:04, 430.06it/s] 81%|███████████████████████████████████████████████████████████████████▏               | 7878/9741 [00:19<00:04, 428.56it/s] 81%|███████████████████████████████████████████████████████████████████▌               | 7922/9741 [00:19<00:04, 429.73it/s] 82%|███████████████████████████████████████████████████████████████████▊               | 7965/9741 [00:19<00:04, 413.43it/s] 82%|████████████████████████████████████████████████████████████████████▏              | 8008/9741 [00:19<00:04, 416.79it/s] 83%|████████████████████████████████████████████████████████████████████▌              | 8052/9741 [00:19<00:04, 421.60it/s] 83%|████████████████████████████████████████████████████████████████████▉              | 8095/9741 [00:19<00:03, 424.02it/s] 84%|█████████████████████████████████████████████████████████████████████▎             | 8139/9741 [00:19<00:03, 428.00it/s] 84%|█████████████████████████████████████████████████████████████████████▋             | 8183/9741 [00:19<00:03, 430.95it/s] 84%|██████████████████████████████████████████████████████████████████████             | 8227/9741 [00:19<00:03, 432.75it/s] 85%|██████████████████████████████████████████████████████████████████████▍            | 8271/9741 [00:19<00:03, 434.46it/s] 85%|██████████████████████████████████████████████████████████████████████▊            | 8315/9741 [00:20<00:03, 433.46it/s] 86%|███████████████████████████████████████████████████████████████████████▏           | 8359/9741 [00:20<00:03, 435.06it/s] 86%|███████████████████████████████████████████████████████████████████████▌           | 8403/9741 [00:20<00:03, 430.63it/s] 87%|███████████████████████████████████████████████████████████████████████▉           | 8447/9741 [00:20<00:03, 429.96it/s] 87%|████████████████████████████████████████████████████████████████████████▎          | 8491/9741 [00:20<00:02, 426.42it/s] 88%|████████████████████████████████████████████████████████████████████████▋          | 8535/9741 [00:20<00:02, 428.50it/s] 88%|█████████████████████████████████████████████████████████████████████████          | 8578/9741 [00:20<00:02, 427.33it/s] 89%|█████████████████████████████████████████████████████████████████████████▍         | 8622/9741 [00:20<00:02, 429.33it/s] 89%|█████████████████████████████████████████████████████████████████████████▊         | 8666/9741 [00:20<00:02, 431.08it/s] 89%|██████████████████████████████████████████████████████████████████████████▏        | 8710/9741 [00:20<00:02, 433.02it/s] 90%|██████████████████████████████████████████████████████████████████████████▌        | 8754/9741 [00:21<00:02, 434.16it/s] 90%|██████████████████████████████████████████████████████████████████████████▉        | 8798/9741 [00:21<00:02, 432.48it/s] 91%|███████████████████████████████████████████████████████████████████████████▎       | 8842/9741 [00:21<00:02, 433.15it/s] 91%|███████████████████████████████████████████████████████████████████████████▋       | 8886/9741 [00:21<00:01, 433.70it/s] 92%|████████████████████████████████████████████████████████████████████████████       | 8930/9741 [00:21<00:01, 434.45it/s] 92%|████████████████████████████████████████████████████████████████████████████▍      | 8974/9741 [00:21<00:01, 434.20it/s] 93%|████████████████████████████████████████████████████████████████████████████▊      | 9018/9741 [00:21<00:01, 432.43it/s] 93%|█████████████████████████████████████████████████████████████████████████████▏     | 9062/9741 [00:21<00:01, 433.44it/s] 93%|█████████████████████████████████████████████████████████████████████████████▌     | 9106/9741 [00:21<00:01, 434.59it/s] 94%|█████████████████████████████████████████████████████████████████████████████▉     | 9150/9741 [00:21<00:01, 435.15it/s] 94%|██████████████████████████████████████████████████████████████████████████████▎    | 9194/9741 [00:22<00:01, 435.85it/s] 95%|██████████████████████████████████████████████████████████████████████████████▋    | 9238/9741 [00:22<00:01, 433.69it/s] 95%|███████████████████████████████████████████████████████████████████████████████    | 9282/9741 [00:22<00:01, 431.62it/s] 96%|███████████████████████████████████████████████████████████████████████████████▍   | 9326/9741 [00:22<00:00, 430.56it/s] 96%|███████████████████████████████████████████████████████████████████████████████▊   | 9370/9741 [00:22<00:00, 431.42it/s] 97%|████████████████████████████████████████████████████████████████████████████████▏  | 9414/9741 [00:22<00:00, 431.71it/s] 97%|████████████████████████████████████████████████████████████████████████████████▌  | 9458/9741 [00:22<00:00, 430.23it/s] 98%|████████████████████████████████████████████████████████████████████████████████▉  | 9502/9741 [00:22<00:00, 430.19it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▎ | 9546/9741 [00:22<00:00, 430.02it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▋ | 9590/9741 [00:23<00:00, 428.66it/s] 99%|██████████████████████████████████████████████████████████████████████████████████ | 9633/9741 [00:23<00:00, 429.02it/s] 99%|██████████████████████████████████████████████████████████████████████████████████▍| 9676/9741 [00:23<00:00, 428.76it/s]100%|██████████████████████████████████████████████████████████████████████████████████▊| 9719/9741 [00:23<00:00, 426.50it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:23<00:00, 416.94it/s]
Load End
Num instances: 1000
[2023-08-21 22:06:23,383] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-21 22:06:26,125] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-21 22:06:26,127] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-21 22:06:26,127] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-21 22:06:26,127] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-21 22:06:26,127] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-21 22:06:26,127] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-21 22:06:26,128] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-21 22:06:26,128] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-21 22:06:26,128] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-21 22:06:26,128] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-21 22:06:26,128] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-21 22:06:26,128] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f5d585c2a60>
[2023-08-21 22:06:26,128] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-21 22:06:26,128] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-21 22:06:26,128] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-21 22:06:26,128] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-21 22:06:26,128] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-21 22:06:26,128] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-21 22:06:26,129] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-21 22:06:26,129] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-21 22:06:26,129] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-21 22:06:26,129] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-21 22:06:26,129] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-21 22:06:26,129] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-21 22:06:26,129] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-21 22:06:26,129] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-21 22:06:26,129] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-21 22:06:26,129] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-21 22:06:26,129] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-21 22:06:26,129] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-21 22:06:26,129] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-21 22:06:26,129] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-21 22:06:26,129] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-21 22:06:26,129] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-21 22:06:26,129] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-21 22:06:26,129] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-21 22:06:26,129] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-21 22:06:26,129] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-21 22:06:26,129] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-21 22:06:26,129] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-21 22:06:26,129] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-21 22:06:26,129] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-21 22:06:26,129] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-21 22:06:26,130] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-21 22:06:26,130] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f5d585c2940>
[2023-08-21 22:06:26,130] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-21 22:06:26,130] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-21 22:06:26,130] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-21 22:06:26,130] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-21 22:06:26,130] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-21 22:06:26,130] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-21 22:06:26,130] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-21 22:06:26,130] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-21 22:06:26,130] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-21 22:06:26,130] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-21 22:06:26,130] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-21 22:06:26,130] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-21 22:06:26,130] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-21 22:06:26,130] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-21 22:06:26,130] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-21 22:06:26,130] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-21 22:06:26,130] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-21 22:06:26,130] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-21 22:06:26,130] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-21 22:06:26,130] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-21 22:06:26,131] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-21 22:06:26,131] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-21 22:06:26,131] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.45505666732788086 seconds
Loading extension module utils...
Time to load utils op: 0.504899263381958 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: Mary added a total of 7 stickers/page * 6 pages= <<7*6=42>>42 stickers to the 6 other pages.
In total, Mary added 3 large stickers + 42 stickers = <<3+42=45>>45 stickers to her journal.
Since she started with 89 stickers, she now has 89 - 45 = <<89-45=44>>44 stickers left.
So the final answer is 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: If he babysits for 2 hours at $7 per hour, he will earn 2*7 = $<<2*7=14>>14
This week he will earn $5 allowance, $10 mowing the lawn and $14 from babysitting for a total of 5+10+14 = $<<5+10+14=29>>29
If we add the $29 he will earn to his $65 savings, he will have a total of 29 + 65 = $<<29+65=94>>94
The bike costs $100 and he will have $94 leaving $100-$94 = $<<100-94=6>>6 more that he will need to earn
So the final answer is 6

Input: Mark has kangaroos and goats.  Kangaroos have two legs and goats have four legs.  If he has 23 kangaroos and three times as many goats as kangaroos what is the total number of legs of all his animals?
Output: His kangaroos have a total of 23*2=<<23*2=46>>46 legs
He has 23*3=<<23*3=69>>69 goats
The goats have 69*4=<<69*4=276>>276 legs
So in total his animals have 276+46=<<276+46=322>>322 legs
So the final answer is 322

Input: Josh’s mom gives him $20 to go shopping at the mall. He buys a hat for $10 and a pencil for $2. Then he buys four cookies. If each cookie costs $1.25, how much money does Josh have left?
Output: After buying a hat, Josh has $20 - $10 = $<<20-10=10>>10
After buying a pencil, Josh has $10 - $2 = $<<10-2=8>>8
The total cost of cookies is 4 * $1.25 = $<<4*1.25=5>>5
After buying the cookies, Josh has $8 - $5 = $<<8-5=3>>3
So the final answer is 3

Input: George's bowling team is one round away from breaking the league record for most points scored in a season. The old record is an average score per player of 287 per round. Each team has 4 players and there are 10 rounds in the season. Through the first 9 rounds, his team has scored a total of 10,440. How many points less than the current league record per game average is the minimum average they need to score, per player, in the final round to tie the league record?
Output: The old team per round record is 1,148 because 287 x 4 = <<1148=1148>>1,148
The team season record is 11,480 because 10 x 1,248 = 11,480
They need 1,040 points in the final round to tie the record because 11,480 - 10,440 = <<11480-10440=1040>>1,040
They need to average 260 points each because 1,040 / 4 = <<1040/4=260>>260
This is 27 points less than the current record average because 287 - 260 = <<27=27>>27
So the final answer is 27

Input: Max was doing homework in three different subjects. It took him 20 minutes to finish tasks from biology and two times more time to finish history. Geography took him the most time, three times more than history. How much time did Max spend on doing his homework?
Output: Max finished history in 20 * 2 = <<20*2=40>>40 minutes.
Finishing geography took the most time, which is 40 * 3 = <<40*3=120>>120 minutes.
In total, for all three subjects, Max needed 20 + 40 + 120 = <<20+40+120=180>>180 minutes.
So the final answer is 180

Input: Sophia ate 1/6 of her pie and she put the rest on the fridge. If the pie left in the fridge weighs 1200 grams, how many grams did Sophia eat?
Output: If Sophia ate 1/6 of the pie, then 6/6 - 1/6 = 5/6 is left in the fridge.
Let x be the pie's original weight.
The current weight of the pie can be described by 5x/6=1200 grams
So, 5x=7200.
And, the original weight is x = <<1440=1440>>1440 grams.
So, Sophia ate 1440 grams original - 1200 grams after= <<1440-1200=240>>240 grams of pie.
So the final answer is 240

Input: Sarah, Mary, and Tuan decided to go to the restaurant for a meal. They decided to split the cost of the meal evenly. If the total price of the meal comes to $67 and they have a coupon for $4, how much does each person need to contribute to the bill?
Output: After using the coupon, the final price comes to 67 - 4 = <<67-4=63>>63 dollars.
With three people, they each need to pay 63 / 3 = <<63/3=21>>21 dollars each.
So the final answer is 21

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o8-tgsm8k-s1-rTrue
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:35<28:40, 35.11s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:09<27:46, 34.73s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [01:43<27:05, 34.59s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [02:18<26:26, 34.49s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [02:52<25:41, 34.26s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [03:26<25:01, 34.12s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [04:00<24:26, 34.11s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [04:34<23:56, 34.21s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [05:08<23:24, 34.26s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [05:42<22:45, 34.14s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [06:16<22:07, 34.03s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [06:50<21:28, 33.90s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [07:24<20:55, 33.93s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [07:58<20:25, 34.03s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [08:32<19:54, 34.13s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [09:06<19:21, 34.15s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [09:41<18:46, 34.12s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [10:15<18:11, 34.10s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [10:49<17:43, 34.30s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [11:23<17:06, 34.20s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [11:57<16:30, 34.16s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [12:31<15:55, 34.12s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [13:05<15:18, 34.02s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [13:39<14:44, 34.01s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [14:13<14:09, 33.98s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [14:47<13:33, 33.91s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [15:22<13:08, 34.28s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [15:56<12:31, 34.17s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [16:29<11:52, 33.91s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [17:03<11:17, 33.86s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [17:36<10:41, 33.75s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [18:10<10:05, 33.65s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [18:44<09:33, 33.76s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [19:17<08:58, 33.65s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [19:51<08:23, 33.57s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [20:24<07:50, 33.63s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [20:58<07:17, 33.66s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [21:32<06:43, 33.62s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [22:06<06:11, 33.74s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [22:39<05:37, 33.72s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [23:13<05:03, 33.75s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [23:47<04:29, 33.66s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [24:20<03:55, 33.70s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [24:54<03:22, 33.68s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [25:27<02:47, 33.59s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [26:01<02:14, 33.56s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [26:34<01:40, 33.53s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [27:08<01:06, 33.47s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [27:41<00:33, 33.51s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [28:15<00:00, 33.48s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [28:15<00:00, 33.91s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.2409} | avg. gen lenth: 452.38
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o9-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 2048 --rationales --num-out-domain 9
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-21 22:34:51,309] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o9-tgsm8k-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 9
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o9-tgsm8k-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  0%|▏                                                                                    | 28/9741 [00:00<00:34, 279.17it/s]  1%|▍                                                                                    | 57/9741 [00:00<00:34, 282.43it/s]  1%|▊                                                                                    | 86/9741 [00:00<00:34, 281.11it/s]  1%|▉                                                                                   | 115/9741 [00:00<00:34, 281.25it/s]  1%|█▏                                                                                  | 144/9741 [00:00<00:34, 281.89it/s]  2%|█▍                                                                                  | 173/9741 [00:00<00:34, 279.99it/s]  2%|█▋                                                                                  | 202/9741 [00:00<00:33, 280.81it/s]  2%|█▉                                                                                  | 231/9741 [00:00<00:33, 282.57it/s]  3%|██▏                                                                                 | 260/9741 [00:00<00:33, 283.12it/s]  3%|██▍                                                                                 | 289/9741 [00:01<00:34, 277.94it/s]  3%|██▋                                                                                 | 318/9741 [00:01<00:33, 279.91it/s]  4%|██▉                                                                                 | 347/9741 [00:01<00:33, 280.73it/s]  4%|███▏                                                                                | 376/9741 [00:01<00:33, 281.82it/s]  4%|███▍                                                                                | 405/9741 [00:01<00:33, 280.92it/s]  4%|███▋                                                                                | 434/9741 [00:01<00:32, 282.29it/s]  5%|███▉                                                                                | 463/9741 [00:01<00:32, 282.95it/s]  5%|████▏                                                                               | 492/9741 [00:01<00:32, 283.13it/s]  5%|████▍                                                                               | 521/9741 [00:01<00:32, 284.03it/s]  6%|████▋                                                                               | 550/9741 [00:01<00:32, 284.64it/s]  6%|████▉                                                                               | 579/9741 [00:02<00:32, 281.91it/s]  6%|█████▏                                                                              | 608/9741 [00:02<00:32, 282.29it/s]  7%|█████▍                                                                              | 637/9741 [00:02<00:32, 280.04it/s]  7%|█████▋                                                                              | 666/9741 [00:02<00:32, 281.39it/s]  7%|█████▉                                                                              | 695/9741 [00:02<00:31, 282.70it/s]  7%|██████▏                                                                             | 724/9741 [00:02<00:31, 283.77it/s]  8%|██████▍                                                                             | 753/9741 [00:02<00:31, 284.44it/s]  8%|██████▊                                                                             | 786/9741 [00:02<00:30, 295.89it/s]  9%|███████▏                                                                            | 829/9741 [00:02<00:26, 334.79it/s]  9%|███████▌                                                                            | 871/9741 [00:02<00:24, 359.83it/s]  9%|███████▉                                                                            | 914/9741 [00:03<00:23, 380.14it/s] 10%|████████▎                                                                           | 957/9741 [00:03<00:22, 394.68it/s] 10%|████████▌                                                                          | 1000/9741 [00:03<00:21, 404.31it/s] 11%|████████▉                                                                          | 1043/9741 [00:03<00:21, 411.79it/s] 11%|█████████▎                                                                         | 1086/9741 [00:03<00:20, 414.60it/s] 12%|█████████▌                                                                         | 1129/9741 [00:03<00:20, 419.07it/s] 12%|█████████▉                                                                         | 1172/9741 [00:03<00:20, 419.50it/s] 12%|██████████▎                                                                        | 1215/9741 [00:03<00:20, 420.18it/s] 13%|██████████▋                                                                        | 1258/9741 [00:03<00:20, 422.44it/s] 13%|███████████                                                                        | 1301/9741 [00:03<00:19, 423.86it/s] 14%|███████████▍                                                                       | 1344/9741 [00:04<00:19, 422.99it/s] 14%|███████████▊                                                                       | 1387/9741 [00:04<00:19, 423.16it/s] 15%|████████████▏                                                                      | 1430/9741 [00:04<00:19, 423.40it/s] 15%|████████████▌                                                                      | 1473/9741 [00:04<00:19, 423.22it/s] 16%|████████████▉                                                                      | 1516/9741 [00:04<00:19, 422.82it/s] 16%|█████████████▎                                                                     | 1559/9741 [00:04<00:19, 417.14it/s] 16%|█████████████▋                                                                     | 1602/9741 [00:04<00:19, 419.63it/s] 17%|██████████████                                                                     | 1645/9741 [00:04<00:19, 420.63it/s] 17%|██████████████▍                                                                    | 1688/9741 [00:04<00:19, 422.85it/s] 18%|██████████████▋                                                                    | 1731/9741 [00:05<00:19, 421.52it/s] 18%|███████████████                                                                    | 1774/9741 [00:05<00:20, 398.23it/s] 19%|███████████████▍                                                                   | 1816/9741 [00:05<00:19, 404.07it/s] 19%|███████████████▊                                                                   | 1858/9741 [00:05<00:19, 407.86it/s] 20%|████████████████▏                                                                  | 1901/9741 [00:05<00:19, 412.00it/s] 20%|████████████████▌                                                                  | 1944/9741 [00:05<00:18, 414.44it/s] 20%|████████████████▉                                                                  | 1986/9741 [00:05<00:18, 414.26it/s] 21%|█████████████████▎                                                                 | 2029/9741 [00:05<00:18, 416.22it/s] 21%|█████████████████▋                                                                 | 2071/9741 [00:05<00:18, 415.97it/s] 22%|██████████████████                                                                 | 2113/9741 [00:05<00:18, 412.20it/s] 22%|██████████████████▎                                                                | 2155/9741 [00:06<00:18, 412.56it/s] 23%|██████████████████▋                                                                | 2197/9741 [00:06<00:18, 413.06it/s] 23%|███████████████████                                                                | 2239/9741 [00:06<00:18, 411.73it/s] 23%|███████████████████▍                                                               | 2281/9741 [00:06<00:18, 412.94it/s] 24%|███████████████████▊                                                               | 2323/9741 [00:06<00:17, 413.65it/s] 24%|████████████████████▏                                                              | 2365/9741 [00:06<00:17, 413.11it/s] 25%|████████████████████▌                                                              | 2407/9741 [00:06<00:17, 412.65it/s] 25%|████████████████████▊                                                              | 2449/9741 [00:06<00:17, 409.61it/s] 26%|█████████████████████▏                                                             | 2491/9741 [00:06<00:17, 409.74it/s] 26%|█████████████████████▌                                                             | 2533/9741 [00:06<00:17, 410.76it/s] 26%|█████████████████████▉                                                             | 2575/9741 [00:07<00:17, 411.01it/s] 27%|██████████████████████▎                                                            | 2617/9741 [00:07<00:17, 411.24it/s] 27%|██████████████████████▋                                                            | 2659/9741 [00:07<00:17, 408.97it/s] 28%|███████████████████████                                                            | 2700/9741 [00:07<00:17, 406.23it/s] 28%|███████████████████████▎                                                           | 2741/9741 [00:07<00:17, 405.83it/s] 29%|███████████████████████▋                                                           | 2782/9741 [00:07<00:17, 405.79it/s] 29%|████████████████████████                                                           | 2823/9741 [00:07<00:17, 399.46it/s] 29%|████████████████████████▍                                                          | 2864/9741 [00:07<00:17, 401.74it/s] 30%|████████████████████████▊                                                          | 2905/9741 [00:07<00:17, 400.83it/s] 30%|█████████████████████████                                                          | 2947/9741 [00:07<00:16, 403.95it/s] 31%|█████████████████████████▍                                                         | 2989/9741 [00:08<00:16, 407.00it/s] 31%|█████████████████████████▊                                                         | 3031/9741 [00:08<00:16, 408.82it/s] 32%|██████████████████████████▏                                                        | 3073/9741 [00:08<00:16, 409.96it/s] 32%|██████████████████████████▌                                                        | 3115/9741 [00:08<00:16, 410.50it/s] 32%|██████████████████████████▉                                                        | 3157/9741 [00:08<00:16, 409.43it/s] 33%|███████████████████████████▎                                                       | 3199/9741 [00:08<00:15, 411.18it/s] 33%|███████████████████████████▌                                                       | 3241/9741 [00:08<00:15, 412.13it/s] 34%|███████████████████████████▉                                                       | 3283/9741 [00:08<00:15, 410.92it/s] 34%|████████████████████████████▎                                                      | 3325/9741 [00:08<00:15, 411.03it/s] 35%|████████████████████████████▋                                                      | 3367/9741 [00:09<00:15, 409.68it/s] 35%|█████████████████████████████                                                      | 3409/9741 [00:09<00:15, 410.82it/s] 35%|█████████████████████████████▍                                                     | 3451/9741 [00:09<00:15, 410.86it/s] 36%|█████████████████████████████▊                                                     | 3493/9741 [00:09<00:15, 410.66it/s] 36%|██████████████████████████████                                                     | 3535/9741 [00:09<00:15, 407.68it/s] 37%|██████████████████████████████▍                                                    | 3576/9741 [00:09<00:15, 406.45it/s] 37%|██████████████████████████████▊                                                    | 3617/9741 [00:09<00:15, 407.35it/s] 38%|███████████████████████████████▏                                                   | 3659/9741 [00:09<00:14, 408.26it/s] 38%|███████████████████████████████▌                                                   | 3700/9741 [00:09<00:14, 408.32it/s] 38%|███████████████████████████████▉                                                   | 3741/9741 [00:09<00:14, 408.18it/s] 39%|████████████████████████████████▏                                                  | 3782/9741 [00:10<00:14, 408.04it/s] 39%|████████████████████████████████▌                                                  | 3823/9741 [00:10<00:14, 405.95it/s] 40%|████████████████████████████████▉                                                  | 3864/9741 [00:10<00:14, 406.12it/s] 40%|█████████████████████████████████▎                                                 | 3905/9741 [00:10<00:14, 406.02it/s] 41%|█████████████████████████████████▌                                                 | 3946/9741 [00:10<00:14, 406.19it/s] 41%|█████████████████████████████████▉                                                 | 3987/9741 [00:10<00:14, 406.37it/s] 41%|██████████████████████████████████▎                                                | 4028/9741 [00:10<00:14, 404.70it/s] 42%|██████████████████████████████████▋                                                | 4069/9741 [00:10<00:14, 405.12it/s] 42%|███████████████████████████████████                                                | 4110/9741 [00:10<00:13, 404.35it/s] 43%|███████████████████████████████████▎                                               | 4151/9741 [00:10<00:13, 404.92it/s] 43%|███████████████████████████████████▋                                               | 4192/9741 [00:11<00:13, 404.70it/s] 43%|████████████████████████████████████                                               | 4233/9741 [00:11<00:13, 404.12it/s] 44%|████████████████████████████████████▍                                              | 4274/9741 [00:11<00:13, 402.18it/s] 44%|████████████████████████████████████▊                                              | 4315/9741 [00:11<00:13, 402.46it/s] 45%|█████████████████████████████████████                                              | 4356/9741 [00:11<00:13, 402.82it/s] 45%|█████████████████████████████████████▍                                             | 4397/9741 [00:11<00:13, 403.19it/s] 46%|█████████████████████████████████████▊                                             | 4438/9741 [00:11<00:13, 402.97it/s] 46%|██████████████████████████████████████▏                                            | 4479/9741 [00:11<00:13, 403.27it/s] 46%|██████████████████████████████████████▌                                            | 4520/9741 [00:11<00:13, 377.67it/s] 47%|██████████████████████████████████████▊                                            | 4561/9741 [00:11<00:13, 384.37it/s] 47%|███████████████████████████████████████▏                                           | 4602/9741 [00:12<00:13, 389.86it/s] 48%|███████████████████████████████████████▌                                           | 4643/9741 [00:12<00:12, 393.77it/s] 48%|███████████████████████████████████████▉                                           | 4684/9741 [00:12<00:12, 396.58it/s] 48%|████████████████████████████████████████▎                                          | 4724/9741 [00:12<00:17, 282.09it/s] 49%|████████████████████████████████████████▌                                          | 4765/9741 [00:12<00:16, 310.43it/s] 49%|████████████████████████████████████████▉                                          | 4804/9741 [00:12<00:14, 329.33it/s] 50%|█████████████████████████████████████████▎                                         | 4844/9741 [00:12<00:14, 347.30it/s] 50%|█████████████████████████████████████████▌                                         | 4885/9741 [00:12<00:13, 362.86it/s] 51%|█████████████████████████████████████████▉                                         | 4925/9741 [00:13<00:12, 372.52it/s] 51%|██████████████████████████████████████████▎                                        | 4966/9741 [00:13<00:12, 381.59it/s] 51%|██████████████████████████████████████████▋                                        | 5007/9741 [00:13<00:12, 387.65it/s] 52%|███████████████████████████████████████████                                        | 5048/9741 [00:13<00:11, 392.08it/s] 52%|███████████████████████████████████████████▎                                       | 5089/9741 [00:13<00:11, 395.61it/s] 53%|███████████████████████████████████████████▋                                       | 5130/9741 [00:13<00:11, 398.25it/s] 53%|████████████████████████████████████████████                                       | 5171/9741 [00:13<00:11, 398.34it/s] 54%|████████████████████████████████████████████▍                                      | 5212/9741 [00:13<00:11, 400.07it/s] 54%|████████████████████████████████████████████▊                                      | 5253/9741 [00:13<00:11, 400.99it/s] 54%|█████████████████████████████████████████████                                      | 5294/9741 [00:13<00:11, 400.74it/s] 55%|█████████████████████████████████████████████▍                                     | 5335/9741 [00:14<00:11, 399.81it/s] 55%|█████████████████████████████████████████████▊                                     | 5376/9741 [00:14<00:10, 398.34it/s] 56%|██████████████████████████████████████████████▏                                    | 5417/9741 [00:14<00:10, 399.03it/s] 56%|██████████████████████████████████████████████▍                                    | 5457/9741 [00:14<00:10, 398.11it/s] 56%|██████████████████████████████████████████████▊                                    | 5498/9741 [00:14<00:10, 399.10it/s] 57%|███████████████████████████████████████████████▏                                   | 5539/9741 [00:14<00:10, 400.28it/s] 57%|███████████████████████████████████████████████▌                                   | 5580/9741 [00:14<00:10, 400.73it/s] 58%|███████████████████████████████████████████████▉                                   | 5621/9741 [00:14<00:10, 399.39it/s] 58%|████████████████████████████████████████████████▏                                  | 5661/9741 [00:14<00:10, 398.96it/s] 59%|████████████████████████████████████████████████▌                                  | 5702/9741 [00:14<00:10, 400.21it/s] 59%|████████████████████████████████████████████████▉                                  | 5743/9741 [00:15<00:09, 401.05it/s] 59%|█████████████████████████████████████████████████▎                                 | 5784/9741 [00:15<00:09, 401.74it/s] 60%|█████████████████████████████████████████████████▋                                 | 5825/9741 [00:15<00:09, 399.85it/s] 60%|█████████████████████████████████████████████████▉                                 | 5866/9741 [00:15<00:09, 400.13it/s] 61%|██████████████████████████████████████████████████▎                                | 5907/9741 [00:15<00:09, 400.25it/s] 61%|██████████████████████████████████████████████████▋                                | 5948/9741 [00:15<00:09, 401.16it/s] 61%|███████████████████████████████████████████████████                                | 5989/9741 [00:15<00:09, 401.68it/s] 62%|███████████████████████████████████████████████████▍                               | 6030/9741 [00:15<00:09, 402.18it/s] 62%|███████████████████████████████████████████████████▋                               | 6071/9741 [00:15<00:09, 400.01it/s] 63%|████████████████████████████████████████████████████                               | 6112/9741 [00:15<00:09, 400.80it/s] 63%|████████████████████████████████████████████████████▍                              | 6153/9741 [00:16<00:08, 401.01it/s] 64%|████████████████████████████████████████████████████▊                              | 6194/9741 [00:16<00:08, 401.74it/s] 64%|█████████████████████████████████████████████████████▏                             | 6235/9741 [00:16<00:08, 401.42it/s] 64%|█████████████████████████████████████████████████████▍                             | 6276/9741 [00:16<00:08, 399.61it/s] 65%|█████████████████████████████████████████████████████▊                             | 6317/9741 [00:16<00:08, 400.22it/s] 65%|██████████████████████████████████████████████████████▏                            | 6358/9741 [00:16<00:08, 395.04it/s] 66%|██████████████████████████████████████████████████████▌                            | 6399/9741 [00:16<00:08, 397.16it/s] 66%|██████████████████████████████████████████████████████▊                            | 6440/9741 [00:16<00:08, 398.62it/s] 67%|███████████████████████████████████████████████████████▏                           | 6480/9741 [00:16<00:08, 398.49it/s] 67%|███████████████████████████████████████████████████████▌                           | 6520/9741 [00:17<00:08, 397.31it/s] 67%|███████████████████████████████████████████████████████▉                           | 6561/9741 [00:17<00:07, 398.97it/s] 68%|████████████████████████████████████████████████████████▎                          | 6602/9741 [00:17<00:07, 399.93it/s] 68%|████████████████████████████████████████████████████████▌                          | 6643/9741 [00:17<00:07, 400.65it/s] 69%|████████████████████████████████████████████████████████▉                          | 6684/9741 [00:17<00:07, 400.33it/s] 69%|█████████████████████████████████████████████████████████▎                         | 6725/9741 [00:17<00:07, 398.95it/s] 69%|█████████████████████████████████████████████████████████▋                         | 6765/9741 [00:17<00:07, 394.08it/s] 70%|█████████████████████████████████████████████████████████▉                         | 6806/9741 [00:17<00:07, 397.12it/s] 70%|██████████████████████████████████████████████████████████▎                        | 6847/9741 [00:17<00:07, 399.16it/s] 71%|██████████████████████████████████████████████████████████▋                        | 6888/9741 [00:17<00:07, 400.40it/s] 71%|███████████████████████████████████████████████████████████                        | 6929/9741 [00:18<00:07, 401.42it/s] 72%|███████████████████████████████████████████████████████████▍                       | 6970/9741 [00:18<00:06, 399.84it/s] 72%|███████████████████████████████████████████████████████████▋                       | 7011/9741 [00:18<00:06, 400.56it/s] 72%|████████████████████████████████████████████████████████████                       | 7052/9741 [00:18<00:06, 400.96it/s] 73%|████████████████████████████████████████████████████████████▍                      | 7093/9741 [00:18<00:06, 400.97it/s] 73%|████████████████████████████████████████████████████████████▊                      | 7134/9741 [00:18<00:06, 400.71it/s] 74%|█████████████████████████████████████████████████████████████▏                     | 7175/9741 [00:18<00:06, 400.77it/s] 74%|█████████████████████████████████████████████████████████████▍                     | 7216/9741 [00:18<00:06, 398.88it/s] 74%|█████████████████████████████████████████████████████████████▊                     | 7256/9741 [00:18<00:06, 394.30it/s] 75%|██████████████████████████████████████████████████████████████▏                    | 7296/9741 [00:18<00:06, 395.65it/s] 75%|██████████████████████████████████████████████████████████████▌                    | 7336/9741 [00:19<00:06, 396.30it/s] 76%|██████████████████████████████████████████████████████████████▊                    | 7376/9741 [00:19<00:05, 397.11it/s] 76%|███████████████████████████████████████████████████████████████▏                   | 7416/9741 [00:19<00:06, 355.69it/s] 77%|███████████████████████████████████████████████████████████████▌                   | 7456/9741 [00:19<00:06, 367.29it/s] 77%|███████████████████████████████████████████████████████████████▊                   | 7496/9741 [00:19<00:05, 376.50it/s] 77%|████████████████████████████████████████████████████████████████▏                  | 7536/9741 [00:19<00:05, 382.62it/s] 78%|████████████████████████████████████████████████████████████████▌                  | 7576/9741 [00:19<00:05, 387.28it/s] 78%|████████████████████████████████████████████████████████████████▉                  | 7616/9741 [00:19<00:05, 390.94it/s] 79%|█████████████████████████████████████████████████████████████████▏                 | 7656/9741 [00:19<00:05, 391.23it/s] 79%|█████████████████████████████████████████████████████████████████▌                 | 7696/9741 [00:19<00:05, 393.40it/s] 79%|█████████████████████████████████████████████████████████████████▉                 | 7737/9741 [00:20<00:05, 395.61it/s] 80%|██████████████████████████████████████████████████████████████████▎                | 7777/9741 [00:20<00:04, 396.70it/s] 80%|██████████████████████████████████████████████████████████████████▌                | 7817/9741 [00:20<00:04, 397.59it/s] 81%|██████████████████████████████████████████████████████████████████▉                | 7858/9741 [00:20<00:04, 398.44it/s] 81%|███████████████████████████████████████████████████████████████████▎               | 7898/9741 [00:20<00:04, 397.06it/s] 81%|███████████████████████████████████████████████████████████████████▋               | 7938/9741 [00:20<00:04, 397.65it/s] 82%|███████████████████████████████████████████████████████████████████▉               | 7979/9741 [00:20<00:04, 398.54it/s] 82%|████████████████████████████████████████████████████████████████████▎              | 8019/9741 [00:20<00:04, 398.76it/s] 83%|████████████████████████████████████████████████████████████████████▋              | 8059/9741 [00:20<00:04, 397.40it/s] 83%|█████████████████████████████████████████████████████████████████████              | 8099/9741 [00:21<00:04, 395.01it/s] 84%|█████████████████████████████████████████████████████████████████████▎             | 8139/9741 [00:21<00:04, 396.48it/s] 84%|█████████████████████████████████████████████████████████████████████▋             | 8179/9741 [00:21<00:03, 397.39it/s] 84%|██████████████████████████████████████████████████████████████████████             | 8219/9741 [00:21<00:03, 398.03it/s] 85%|██████████████████████████████████████████████████████████████████████▍            | 8260/9741 [00:21<00:03, 398.73it/s] 85%|██████████████████████████████████████████████████████████████████████▋            | 8300/9741 [00:21<00:03, 399.09it/s] 86%|███████████████████████████████████████████████████████████████████████            | 8340/9741 [00:21<00:03, 397.48it/s] 86%|███████████████████████████████████████████████████████████████████████▍           | 8380/9741 [00:21<00:03, 398.22it/s] 86%|███████████████████████████████████████████████████████████████████████▊           | 8421/9741 [00:21<00:03, 398.78it/s] 87%|████████████████████████████████████████████████████████████████████████           | 8461/9741 [00:21<00:03, 398.69it/s] 87%|████████████████████████████████████████████████████████████████████████▍          | 8501/9741 [00:22<00:03, 398.95it/s] 88%|████████████████████████████████████████████████████████████████████████▊          | 8541/9741 [00:22<00:03, 399.14it/s] 88%|█████████████████████████████████████████████████████████████████████████          | 8581/9741 [00:22<00:02, 397.18it/s] 89%|█████████████████████████████████████████████████████████████████████████▍         | 8621/9741 [00:22<00:02, 397.74it/s] 89%|█████████████████████████████████████████████████████████████████████████▊         | 8662/9741 [00:22<00:02, 398.57it/s] 89%|██████████████████████████████████████████████████████████████████████████▏        | 8702/9741 [00:22<00:02, 398.93it/s] 90%|██████████████████████████████████████████████████████████████████████████▍        | 8742/9741 [00:22<00:02, 399.15it/s] 90%|██████████████████████████████████████████████████████████████████████████▊        | 8782/9741 [00:22<00:02, 397.23it/s] 91%|███████████████████████████████████████████████████████████████████████████▏       | 8822/9741 [00:22<00:02, 397.99it/s] 91%|███████████████████████████████████████████████████████████████████████████▌       | 8862/9741 [00:22<00:02, 397.01it/s] 91%|███████████████████████████████████████████████████████████████████████████▊       | 8902/9741 [00:23<00:02, 397.42it/s] 92%|████████████████████████████████████████████████████████████████████████████▏      | 8943/9741 [00:23<00:02, 398.60it/s] 92%|████████████████████████████████████████████████████████████████████████████▌      | 8983/9741 [00:23<00:01, 398.90it/s] 93%|████████████████████████████████████████████████████████████████████████████▉      | 9023/9741 [00:23<00:01, 396.99it/s] 93%|█████████████████████████████████████████████████████████████████████████████▏     | 9063/9741 [00:23<00:01, 397.70it/s] 93%|█████████████████████████████████████████████████████████████████████████████▌     | 9104/9741 [00:23<00:01, 398.43it/s] 94%|█████████████████████████████████████████████████████████████████████████████▉     | 9144/9741 [00:23<00:01, 394.86it/s] 94%|██████████████████████████████████████████████████████████████████████████████▎    | 9184/9741 [00:23<00:01, 396.14it/s] 95%|██████████████████████████████████████████████████████████████████████████████▌    | 9224/9741 [00:23<00:01, 395.28it/s] 95%|██████████████████████████████████████████████████████████████████████████████▉    | 9264/9741 [00:23<00:01, 396.07it/s] 96%|███████████████████████████████████████████████████████████████████████████████▎   | 9304/9741 [00:24<00:01, 396.93it/s] 96%|███████████████████████████████████████████████████████████████████████████████▌   | 9344/9741 [00:24<00:00, 397.75it/s] 96%|███████████████████████████████████████████████████████████████████████████████▉   | 9385/9741 [00:24<00:00, 398.65it/s] 97%|████████████████████████████████████████████████████████████████████████████████▎  | 9426/9741 [00:24<00:00, 399.22it/s] 97%|████████████████████████████████████████████████████████████████████████████████▋  | 9466/9741 [00:24<00:00, 397.29it/s] 98%|████████████████████████████████████████████████████████████████████████████████▉  | 9506/9741 [00:24<00:00, 397.59it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▎ | 9546/9741 [00:24<00:00, 398.16it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▋ | 9586/9741 [00:24<00:00, 398.42it/s] 99%|██████████████████████████████████████████████████████████████████████████████████ | 9626/9741 [00:24<00:00, 398.72it/s] 99%|██████████████████████████████████████████████████████████████████████████████████▎| 9666/9741 [00:24<00:00, 397.59it/s]100%|██████████████████████████████████████████████████████████████████████████████████▋| 9706/9741 [00:25<00:00, 396.05it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:25<00:00, 387.47it/s]
Load End
Num instances: 1000
[2023-08-21 22:35:27,922] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-21 22:35:30,643] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-21 22:35:30,644] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-21 22:35:30,644] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-21 22:35:30,644] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-21 22:35:30,644] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-21 22:35:30,644] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-21 22:35:30,644] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fbc2d214a60>
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fbc2d214940>
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-21 22:35:30,645] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-21 22:35:30,646] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-21 22:35:30,646] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-21 22:35:30,646] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-21 22:35:30,646] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.43807363510131836 seconds
Loading extension module utils...
Time to load utils op: 0.509070634841919 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: Mary added a total of 7 stickers/page * 6 pages= <<7*6=42>>42 stickers to the 6 other pages.
In total, Mary added 3 large stickers + 42 stickers = <<3+42=45>>45 stickers to her journal.
Since she started with 89 stickers, she now has 89 - 45 = <<89-45=44>>44 stickers left.
So the final answer is 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: If he babysits for 2 hours at $7 per hour, he will earn 2*7 = $<<2*7=14>>14
This week he will earn $5 allowance, $10 mowing the lawn and $14 from babysitting for a total of 5+10+14 = $<<5+10+14=29>>29
If we add the $29 he will earn to his $65 savings, he will have a total of 29 + 65 = $<<29+65=94>>94
The bike costs $100 and he will have $94 leaving $100-$94 = $<<100-94=6>>6 more that he will need to earn
So the final answer is 6

Input: Mark has kangaroos and goats.  Kangaroos have two legs and goats have four legs.  If he has 23 kangaroos and three times as many goats as kangaroos what is the total number of legs of all his animals?
Output: His kangaroos have a total of 23*2=<<23*2=46>>46 legs
He has 23*3=<<23*3=69>>69 goats
The goats have 69*4=<<69*4=276>>276 legs
So in total his animals have 276+46=<<276+46=322>>322 legs
So the final answer is 322

Input: Josh’s mom gives him $20 to go shopping at the mall. He buys a hat for $10 and a pencil for $2. Then he buys four cookies. If each cookie costs $1.25, how much money does Josh have left?
Output: After buying a hat, Josh has $20 - $10 = $<<20-10=10>>10
After buying a pencil, Josh has $10 - $2 = $<<10-2=8>>8
The total cost of cookies is 4 * $1.25 = $<<4*1.25=5>>5
After buying the cookies, Josh has $8 - $5 = $<<8-5=3>>3
So the final answer is 3

Input: George's bowling team is one round away from breaking the league record for most points scored in a season. The old record is an average score per player of 287 per round. Each team has 4 players and there are 10 rounds in the season. Through the first 9 rounds, his team has scored a total of 10,440. How many points less than the current league record per game average is the minimum average they need to score, per player, in the final round to tie the league record?
Output: The old team per round record is 1,148 because 287 x 4 = <<1148=1148>>1,148
The team season record is 11,480 because 10 x 1,248 = 11,480
They need 1,040 points in the final round to tie the record because 11,480 - 10,440 = <<11480-10440=1040>>1,040
They need to average 260 points each because 1,040 / 4 = <<1040/4=260>>260
This is 27 points less than the current record average because 287 - 260 = <<27=27>>27
So the final answer is 27

Input: Max was doing homework in three different subjects. It took him 20 minutes to finish tasks from biology and two times more time to finish history. Geography took him the most time, three times more than history. How much time did Max spend on doing his homework?
Output: Max finished history in 20 * 2 = <<20*2=40>>40 minutes.
Finishing geography took the most time, which is 40 * 3 = <<40*3=120>>120 minutes.
In total, for all three subjects, Max needed 20 + 40 + 120 = <<20+40+120=180>>180 minutes.
So the final answer is 180

Input: Sophia ate 1/6 of her pie and she put the rest on the fridge. If the pie left in the fridge weighs 1200 grams, how many grams did Sophia eat?
Output: If Sophia ate 1/6 of the pie, then 6/6 - 1/6 = 5/6 is left in the fridge.
Let x be the pie's original weight.
The current weight of the pie can be described by 5x/6=1200 grams
So, 5x=7200.
And, the original weight is x = <<1440=1440>>1440 grams.
So, Sophia ate 1440 grams original - 1200 grams after= <<1440-1200=240>>240 grams of pie.
So the final answer is 240

Input: Sarah, Mary, and Tuan decided to go to the restaurant for a meal. They decided to split the cost of the meal evenly. If the total price of the meal comes to $67 and they have a coupon for $4, how much does each person need to contribute to the bill?
Output: After using the coupon, the final price comes to 67 - 4 = <<67-4=63>>63 dollars.
With three people, they each need to pay 63 / 3 = <<63/3=21>>21 dollars each.
So the final answer is 21

Input: Tom's brother is 4 times as old as Tom's dog. If in 6 years, Tom's brother will be 30 years, how old is Tom's dog going to be in six years?
Output: If in six years Tom's brother will be 30 years old, he is currently 30-6 = <<30-6=24>>24 years old.
Since Tom's brother is 4 times as old as Tom's dog, Tom's dog is 24/4 = <<24/4=6>>6 years old currently.
Tom's dog will be 6+6 = <<6+6=12>>12 years old in six years.
So the final answer is 12

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o9-tgsm8k-s1-rTrue
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 126, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 123, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 107, in evaluate_main
    query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 89, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2484, in sample
    outputs = self(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/models/opt/modeling_opt.py", line 983, in forward
    outputs = self.model.decoder(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/models/opt/modeling_opt.py", line 749, in forward
    layer_outputs = decoder_layer(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/models/opt/modeling_opt.py", line 376, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/models/opt/modeling_opt.py", line 276, in forward
    attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(torch.float16)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
terminate called after throwing an instance of 'c10::CUDAError'
  what():  CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Exception raised from create_event_internal at ../c10/cuda/CUDACachingAllocator.cpp:1387 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x3e (0x7f618c9ac20e in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x23a21 (0x7f6194072a21 in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #2: c10::cuda::CUDACachingAllocator::raw_delete(void*) + 0x257 (0x7f61940779a7 in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x463338 (0x7f61788f4338 in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #4: c10::TensorImpl::release_resources() + 0x175 (0x7f618c9937a5 in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #5: <unknown function> + 0x35f355 (0x7f61787f0355 in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #6: <unknown function> + 0x678d38 (0x7f6178b09d38 in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: THPVariable_subclass_dealloc(_object*) + 0x2b5 (0x7f6178b0a0e5 in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #8: /home/ylu130/.conda/envs/distllm/bin/python() [0x4e4277]
frame #9: /home/ylu130/.conda/envs/distllm/bin/python() [0x4d9998]
frame #10: _PyModule_ClearDict + 0xe9 (0x55b3b9 in /home/ylu130/.conda/envs/distllm/bin/python)
frame #11: /home/ylu130/.conda/envs/distllm/bin/python() [0x5c263b]
frame #12: Py_FinalizeEx + 0x179 (0x5c10d9 in /home/ylu130/.conda/envs/distllm/bin/python)
frame #13: Py_RunMain + 0x110 (0x5b4210 in /home/ylu130/.conda/envs/distllm/bin/python)
frame #14: Py_BytesMain + 0x39 (0x587a39 in /home/ylu130/.conda/envs/distllm/bin/python)
frame #15: <unknown function> + 0x29d90 (0x7f6194a44d90 in /lib/x86_64-linux-gnu/libc.so.6)
frame #16: __libc_start_main + 0x80 (0x7f6194a44e40 in /lib/x86_64-linux-gnu/libc.so.6)
frame #17: /home/ylu130/.conda/envs/distllm/bin/python() [0x5878ee]

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:31<?, ?it/s]
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 126, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 123, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 107, in evaluate_main
    query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 89, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2484, in sample
    outputs = self(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/models/opt/modeling_opt.py", line 983, in forward
    outputs = self.model.decoder(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/models/opt/modeling_opt.py", line 749, in forward
    layer_outputs = decoder_layer(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/models/opt/modeling_opt.py", line 376, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/models/opt/modeling_opt.py", line 276, in forward
    attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(torch.float16)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
terminate called after throwing an instance of 'c10::CUDAError'
  what():  CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Exception raised from create_event_internal at ../c10/cuda/CUDACachingAllocator.cpp:1387 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x3e (0x7fbcd586d20e in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x23a21 (0x7fbcd58e4a21 in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #2: c10::cuda::CUDACachingAllocator::raw_delete(void*) + 0x257 (0x7fbcd58e99a7 in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x463338 (0x7fbcc18f4338 in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #4: c10::TensorImpl::release_resources() + 0x175 (0x7fbcd58547a5 in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #5: <unknown function> + 0x35f355 (0x7fbcc17f0355 in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #6: <unknown function> + 0x678d38 (0x7fbcc1b09d38 in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: THPVariable_subclass_dealloc(_object*) + 0x2b5 (0x7fbcc1b0a0e5 in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #8: /home/ylu130/.conda/envs/distllm/bin/python() [0x4e4277]
frame #9: /home/ylu130/.conda/envs/distllm/bin/python() [0x4d9998]
frame #10: _PyModule_ClearDict + 0xe9 (0x55b3b9 in /home/ylu130/.conda/envs/distllm/bin/python)
frame #11: /home/ylu130/.conda/envs/distllm/bin/python() [0x5c263b]
frame #12: Py_FinalizeEx + 0x179 (0x5c10d9 in /home/ylu130/.conda/envs/distllm/bin/python)
frame #13: Py_RunMain + 0x110 (0x5b4210 in /home/ylu130/.conda/envs/distllm/bin/python)
frame #14: Py_BytesMain + 0x39 (0x587a39 in /home/ylu130/.conda/envs/distllm/bin/python)
frame #15: <unknown function> + 0x29d90 (0x7fbcdd8fcd90 in /lib/x86_64-linux-gnu/libc.so.6)
frame #16: __libc_start_main + 0x80 (0x7fbcdd8fce40 in /lib/x86_64-linux-gnu/libc.so.6)
frame #17: /home/ylu130/.conda/envs/distllm/bin/python() [0x5878ee]

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: -6) local_rank: 0 (pid: 3435283) of binary: /home/ylu130/.conda/envs/distllm/bin/python
Traceback (most recent call last):
  File "/home/ylu130/.conda/envs/distllm/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/run.py", line 761, in main
    run(args)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/ylu130/workspace/in-context-generalization/inference.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-08-21_22:36:04
  host      : ia1.wse.jhu.edu
  rank      : 1 (local_rank: 1)
  exitcode  : -6 (pid: 3435284)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 3435284
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-08-21_22:36:04
  host      : ia1.wse.jhu.edu
  rank      : 0 (local_rank: 0)
  exitcode  : -6 (pid: 3435283)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 3435283
============================================================
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 2048 --num-out-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-21 22:36:08,019] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 1
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o1-tgsm8k-s1-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  3%|██▍                                                                                | 288/9741 [00:00<00:03, 2872.42it/s]  6%|█████                                                                              | 592/9741 [00:00<00:03, 2966.51it/s]  9%|███████▋                                                                           | 904/9741 [00:00<00:02, 3034.08it/s] 13%|██████████▎                                                                       | 1220/9741 [00:00<00:02, 3082.53it/s] 16%|████████████▉                                                                     | 1535/9741 [00:00<00:02, 3104.42it/s] 19%|███████████████▌                                                                  | 1850/9741 [00:00<00:02, 3118.17it/s] 22%|██████████████████▏                                                               | 2165/9741 [00:00<00:02, 3126.10it/s] 25%|████████████████████▉                                                             | 2481/9741 [00:00<00:02, 3135.76it/s] 29%|███████████████████████▌                                                          | 2795/9741 [00:00<00:02, 3085.38it/s] 32%|██████████████████████████▏                                                       | 3110/9741 [00:01<00:02, 3103.86it/s] 35%|████████████████████████████▊                                                     | 3427/9741 [00:01<00:02, 3121.62it/s] 38%|███████████████████████████████▌                                                  | 3744/9741 [00:01<00:01, 3135.40it/s] 42%|██████████████████████████████████▏                                               | 4065/9741 [00:01<00:01, 3157.85it/s] 45%|████████████████████████████████████▉                                             | 4386/9741 [00:01<00:01, 3173.21it/s] 48%|███████████████████████████████████████▌                                          | 4704/9741 [00:01<00:01, 3147.33it/s] 52%|██████████████████████████████████████████▎                                       | 5019/9741 [00:01<00:01, 2675.46it/s] 55%|████████████████████████████████████████████▉                                     | 5339/9741 [00:01<00:01, 2812.95it/s] 58%|███████████████████████████████████████████████▋                                  | 5661/9741 [00:01<00:01, 2922.91it/s] 61%|██████████████████████████████████████████████████▎                               | 5983/9741 [00:01<00:01, 3004.88it/s] 65%|█████████████████████████████████████████████████████▎                            | 6326/9741 [00:02<00:01, 3126.19it/s] 70%|█████████████████████████████████████████████████████████▍                        | 6819/9741 [00:02<00:00, 3648.78it/s] 75%|█████████████████████████████████████████████████████████████▌                    | 7314/9741 [00:02<00:00, 4029.53it/s] 80%|█████████████████████████████████████████████████████████████████▋                | 7799/9741 [00:02<00:00, 4270.33it/s] 85%|█████████████████████████████████████████████████████████████████████▊            | 8297/9741 [00:02<00:00, 4480.65it/s] 90%|██████████████████████████████████████████████████████████████████████████        | 8791/9741 [00:02<00:00, 4616.59it/s] 95%|██████████████████████████████████████████████████████████████████████████████▏   | 9285/9741 [00:02<00:00, 4711.81it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:02<00:00, 3522.78it/s]
Load End
Num instances: 1000
[2023-08-21 22:36:22,070] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-21 22:36:26,381] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-21 22:36:26,382] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-21 22:36:26,383] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-21 22:36:26,383] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-21 22:36:26,383] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-21 22:36:26,383] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-21 22:36:26,383] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-21 22:36:26,383] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-21 22:36:26,383] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-21 22:36:26,383] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-21 22:36:26,383] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-21 22:36:26,383] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fc541e50a60>
[2023-08-21 22:36:26,383] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fc541e50940>
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-21 22:36:26,384] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-21 22:36:26,385] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-21 22:36:26,385] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-21 22:36:26,385] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-21 22:36:26,385] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-21 22:36:26,385] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.475419282913208 seconds
Loading extension module utils...
Time to load utils op: 0.5050234794616699 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: 44

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o1-tgsm8k-s1-rFalse
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [01:06<53:56, 66.04s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [02:14<53:50, 67.31s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [03:22<52:54, 67.55s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [04:29<51:38, 67.35s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [05:36<50:30, 67.34s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [06:43<49:22, 67.32s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [07:52<48:35, 67.81s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [08:59<47:12, 67.44s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [10:08<46:26, 67.97s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [11:18<45:50, 68.76s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [12:26<44:24, 68.32s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [13:34<43:12, 68.21s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [14:42<42:01, 68.16s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [15:48<40:38, 67.75s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [16:56<39:28, 67.68s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [18:05<38:30, 67.95s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [19:12<37:17, 67.80s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [20:20<36:08, 67.75s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [21:28<35:05, 67.93s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [22:35<33:50, 67.68s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [23:42<32:39, 67.56s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [24:50<31:36, 67.71s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [25:57<30:16, 67.29s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [27:04<29:12, 67.41s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [28:11<28:02, 67.30s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [29:20<27:02, 67.59s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [30:30<26:10, 68.30s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [31:38<25:05, 68.42s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [32:45<23:43, 67.81s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [33:52<22:35, 67.76s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [35:02<21:39, 68.41s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [36:10<20:28, 68.26s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [37:18<19:19, 68.23s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [38:25<18:05, 67.84s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [39:33<16:58, 67.87s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [40:40<15:45, 67.52s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [41:48<14:38, 67.57s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [42:56<13:34, 67.85s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [44:05<12:30, 68.22s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [45:16<11:29, 68.93s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [46:24<10:17, 68.59s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [47:33<09:10, 68.81s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [48:42<08:01, 68.75s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [49:50<06:51, 68.61s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [50:58<05:41, 68.37s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [52:07<04:34, 68.61s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [53:15<03:25, 68.52s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [54:25<02:17, 68.81s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [55:32<01:08, 68.31s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [56:41<00:00, 68.55s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [56:41<00:00, 68.03s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.8596} | avg. gen lenth: 288.742
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 2048 --num-out-domain 2
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-21 23:33:17,856] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 2
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o2-tgsm8k-s1-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  2%|█▍                                                                                 | 166/9741 [00:00<00:05, 1654.58it/s]  3%|██▉                                                                                | 339/9741 [00:00<00:05, 1698.12it/s]  5%|████▍                                                                              | 514/9741 [00:00<00:05, 1719.75it/s]  7%|█████▉                                                                             | 690/9741 [00:00<00:05, 1733.81it/s]  9%|███████▍                                                                           | 868/9741 [00:00<00:05, 1747.92it/s] 11%|████████▊                                                                         | 1047/9741 [00:00<00:04, 1761.44it/s] 13%|██████████▎                                                                       | 1226/9741 [00:00<00:04, 1769.01it/s] 14%|███████████▊                                                                      | 1405/9741 [00:00<00:04, 1773.12it/s] 16%|█████████████▎                                                                    | 1583/9741 [00:00<00:04, 1746.26it/s] 18%|██████████████▊                                                                   | 1759/9741 [00:01<00:04, 1728.15it/s] 20%|████████████████▎                                                                 | 1937/9741 [00:01<00:04, 1740.55it/s] 22%|█████████████████▊                                                                | 2113/9741 [00:01<00:04, 1745.85it/s] 24%|███████████████████▋                                                              | 2341/9741 [00:01<00:03, 1905.92it/s] 27%|██████████████████████                                                            | 2614/9741 [00:01<00:03, 2152.08it/s] 30%|████████████████████████▎                                                         | 2884/9741 [00:01<00:02, 2315.65it/s] 32%|██████████████████████████▌                                                       | 3156/9741 [00:01<00:02, 2435.22it/s] 35%|████████████████████████████▊                                                     | 3430/9741 [00:01<00:02, 2524.85it/s] 38%|███████████████████████████████▏                                                  | 3701/9741 [00:01<00:02, 2577.84it/s] 41%|█████████████████████████████████▍                                                | 3965/9741 [00:01<00:02, 2595.37it/s] 43%|███████████████████████████████████▋                                              | 4234/9741 [00:02<00:02, 2621.84it/s] 46%|█████████████████████████████████████▊                                            | 4498/9741 [00:02<00:01, 2624.51it/s] 49%|████████████████████████████████████████                                          | 4761/9741 [00:02<00:02, 2296.50it/s] 52%|██████████████████████████████████████████▍                                       | 5034/9741 [00:02<00:01, 2413.77it/s] 54%|████████████████████████████████████████████▋                                     | 5308/9741 [00:02<00:01, 2505.00it/s] 57%|██████████████████████████████████████████████▉                                   | 5583/9741 [00:02<00:01, 2572.83it/s] 60%|█████████████████████████████████████████████████▎                                | 5859/9741 [00:02<00:01, 2625.66it/s] 63%|███████████████████████████████████████████████████▋                              | 6138/9741 [00:02<00:01, 2671.13it/s] 66%|██████████████████████████████████████████████████████                            | 6416/9741 [00:02<00:01, 2700.72it/s] 69%|████████████████████████████████████████████████████████▎                         | 6693/9741 [00:02<00:01, 2718.84it/s] 72%|██████████████████████████████████████████████████████████▋                       | 6972/9741 [00:03<00:01, 2737.80it/s] 74%|█████████████████████████████████████████████████████████████                     | 7251/9741 [00:03<00:00, 2750.56it/s] 77%|███████████████████████████████████████████████████████████████▎                  | 7527/9741 [00:03<00:00, 2660.01it/s] 80%|█████████████████████████████████████████████████████████████████▋                | 7803/9741 [00:03<00:00, 2686.99it/s] 83%|████████████████████████████████████████████████████████████████████              | 8081/9741 [00:03<00:00, 2713.85it/s] 86%|██████████████████████████████████████████████████████████████████████▎           | 8358/9741 [00:03<00:00, 2729.76it/s] 89%|████████████████████████████████████████████████████████████████████████▋         | 8635/9741 [00:03<00:00, 2741.62it/s] 91%|███████████████████████████████████████████████████████████████████████████       | 8913/9741 [00:03<00:00, 2751.99it/s] 94%|█████████████████████████████████████████████████████████████████████████████▍    | 9192/9741 [00:03<00:00, 2760.87it/s] 97%|███████████████████████████████████████████████████████████████████████████████▋  | 9469/9741 [00:03<00:00, 2760.78it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:04<00:00, 2390.17it/s]
Load End
Num instances: 1000
[2023-08-21 23:33:33,360] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-21 23:33:36,247] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-21 23:33:36,247] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fc2a39ada60>
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-21 23:33:36,248] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-21 23:33:36,249] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-21 23:33:36,249] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-21 23:33:36,249] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-21 23:33:36,249] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-21 23:33:36,249] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-21 23:33:36,249] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fc2a39ad940>
[2023-08-21 23:33:36,249] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-21 23:33:36,249] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-21 23:33:36,249] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-21 23:33:36,249] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-21 23:33:36,249] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-21 23:33:36,249] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-21 23:33:36,249] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-21 23:33:36,249] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-21 23:33:36,249] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-21 23:33:36,249] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-21 23:33:36,249] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-21 23:33:36,249] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-21 23:33:36,249] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-21 23:33:36,249] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-21 23:33:36,249] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-21 23:33:36,249] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-21 23:33:36,249] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-21 23:33:36,249] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-21 23:33:36,249] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-21 23:33:36,249] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-21 23:33:36,249] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-21 23:33:36,249] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-21 23:33:36,249] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4459857940673828 seconds
Loading extension module utils...
Time to load utils op: 0.5048997402191162 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: 6

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o2-tgsm8k-s1-rFalse
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [01:02<51:13, 62.73s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [02:05<50:11, 62.73s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [03:08<49:25, 63.10s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [04:09<47:42, 62.22s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [05:12<46:51, 62.48s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [06:16<46:07, 62.90s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [07:19<45:01, 62.82s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [08:18<43:13, 61.75s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [09:20<42:16, 61.85s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [10:25<41:44, 62.62s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [11:27<40:38, 62.52s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [12:30<39:47, 62.83s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [13:34<38:53, 63.06s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [14:36<37:34, 62.62s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [15:37<36:14, 62.13s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [16:39<35:10, 62.08s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [17:41<34:08, 62.08s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [18:43<33:10, 62.20s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [19:45<32:08, 62.20s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [20:46<30:54, 61.82s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [21:47<29:47, 61.64s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [22:49<28:41, 61.49s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [23:51<27:44, 61.65s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [24:53<26:52, 62.03s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [25:56<25:54, 62.17s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [27:00<25:05, 62.73s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [28:02<23:56, 62.44s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [29:04<22:52, 62.40s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [30:05<21:40, 61.94s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [31:05<20:24, 61.23s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [32:08<19:37, 61.96s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [33:11<18:40, 62.23s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [34:14<17:40, 62.39s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [35:17<16:40, 62.51s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [36:20<15:41, 62.76s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [37:22<14:34, 62.45s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [38:26<13:37, 62.86s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [39:29<12:36, 63.07s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [40:33<11:35, 63.22s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [41:36<10:33, 63.40s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [42:40<09:31, 63.48s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [43:42<08:24, 63.06s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [44:44<07:19, 62.73s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [45:46<06:14, 62.48s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [46:48<05:11, 62.29s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [47:50<04:09, 62.32s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [48:54<03:08, 62.73s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [49:59<02:06, 63.27s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [51:03<01:03, 63.56s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [52:07<00:00, 63.73s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [52:07<00:00, 62.55s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.4253} | avg. gen lenth: 313.61
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o3-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 2048 --num-out-domain 3
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 00:25:52,503] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o3-tgsm8k-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 3
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o3-tgsm8k-s1-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|█▏                                                                                 | 133/9741 [00:00<00:07, 1328.84it/s]  3%|██▎                                                                                | 273/9741 [00:00<00:06, 1369.15it/s]  4%|███▌                                                                               | 414/9741 [00:00<00:06, 1386.27it/s]  6%|████▋                                                                              | 556/9741 [00:00<00:06, 1398.51it/s]  7%|█████▉                                                                             | 698/9741 [00:00<00:06, 1404.61it/s]  9%|███████▏                                                                           | 841/9741 [00:00<00:06, 1411.37it/s] 10%|████████▍                                                                          | 984/9741 [00:00<00:06, 1415.80it/s] 12%|█████████▍                                                                        | 1127/9741 [00:00<00:06, 1419.90it/s] 13%|██████████▋                                                                       | 1269/9741 [00:00<00:06, 1387.67it/s] 14%|███████████▊                                                                      | 1409/9741 [00:01<00:05, 1389.26it/s] 16%|█████████████                                                                     | 1551/9741 [00:01<00:05, 1396.66it/s] 17%|██████████████▎                                                                   | 1694/9741 [00:01<00:05, 1404.75it/s] 19%|███████████████▍                                                                  | 1835/9741 [00:01<00:05, 1388.13it/s] 20%|████████████████▋                                                                 | 1977/9741 [00:01<00:05, 1397.33it/s] 22%|█████████████████▊                                                                | 2119/9741 [00:01<00:05, 1401.94it/s] 23%|███████████████████                                                               | 2262/9741 [00:01<00:05, 1409.02it/s] 25%|████████████████████▏                                                             | 2405/9741 [00:01<00:05, 1415.17it/s] 26%|█████████████████████▍                                                            | 2548/9741 [00:01<00:05, 1417.17it/s] 28%|██████████████████████▋                                                           | 2690/9741 [00:01<00:04, 1416.25it/s] 29%|███████████████████████▊                                                          | 2833/9741 [00:02<00:04, 1417.85it/s] 31%|█████████████████████████                                                         | 2976/9741 [00:02<00:04, 1421.00it/s] 32%|██████████████████████████▎                                                       | 3120/9741 [00:02<00:04, 1425.30it/s] 34%|███████████████████████████▍                                                      | 3264/9741 [00:02<00:04, 1428.26it/s] 35%|████████████████████████████▋                                                     | 3412/9741 [00:02<00:04, 1442.78it/s] 37%|██████████████████████████████▌                                                   | 3626/9741 [00:02<00:03, 1650.05it/s] 39%|████████████████████████████████▎                                                 | 3843/9741 [00:02<00:03, 1805.52it/s] 42%|██████████████████████████████████▏                                               | 4062/9741 [00:02<00:02, 1918.37it/s] 44%|████████████████████████████████████                                              | 4281/9741 [00:02<00:02, 1997.80it/s] 46%|█████████████████████████████████████▋                                            | 4483/9741 [00:02<00:02, 2001.79it/s] 48%|███████████████████████████████████████▌                                          | 4698/9741 [00:03<00:02, 2044.17it/s] 50%|█████████████████████████████████████████▎                                        | 4903/9741 [00:03<00:03, 1586.91it/s] 53%|███████████████████████████████████████████                                       | 5118/9741 [00:03<00:02, 1726.04it/s] 55%|████████████████████████████████████████████▉                                     | 5334/9741 [00:03<00:02, 1839.23it/s] 57%|██████████████████████████████████████████████▋                                   | 5552/9741 [00:03<00:02, 1931.89it/s] 59%|████████████████████████████████████████████████▌                                 | 5769/9741 [00:03<00:01, 1998.30it/s] 61%|██████████████████████████████████████████████████▎                               | 5981/9741 [00:03<00:01, 2033.06it/s] 64%|████████████████████████████████████████████████████▏                             | 6198/9741 [00:03<00:01, 2071.81it/s] 66%|██████████████████████████████████████████████████████                            | 6415/9741 [00:03<00:01, 2099.76it/s] 68%|███████████████████████████████████████████████████████▊                          | 6628/9741 [00:04<00:01, 2103.10it/s] 70%|█████████████████████████████████████████████████████████▌                        | 6841/9741 [00:04<00:01, 2101.85it/s] 72%|███████████████████████████████████████████████████████████▍                      | 7057/9741 [00:04<00:01, 2117.38it/s] 75%|█████████████████████████████████████████████████████████████▏                    | 7273/9741 [00:04<00:01, 2129.82it/s] 77%|███████████████████████████████████████████████████████████████                   | 7487/9741 [00:04<00:01, 2100.61it/s] 79%|████████████████████████████████████████████████████████████████▊                 | 7701/9741 [00:04<00:00, 2110.89it/s] 81%|██████████████████████████████████████████████████████████████████▋               | 7916/9741 [00:04<00:00, 2122.23it/s] 83%|████████████████████████████████████████████████████████████████████▍             | 8131/9741 [00:04<00:00, 2130.07it/s] 86%|██████████████████████████████████████████████████████████████████████▏           | 8345/9741 [00:04<00:00, 2057.06it/s] 88%|███████████████████████████████████████████████████████████████████████▉          | 8552/9741 [00:04<00:00, 2051.87it/s] 90%|█████████████████████████████████████████████████████████████████████████▊        | 8764/9741 [00:05<00:00, 2071.42it/s] 92%|███████████████████████████████████████████████████████████████████████████▌      | 8975/9741 [00:05<00:00, 2080.97it/s] 94%|█████████████████████████████████████████████████████████████████████████████▎    | 9189/9741 [00:05<00:00, 2097.64it/s] 97%|███████████████████████████████████████████████████████████████████████████████▏  | 9402/9741 [00:05<00:00, 2106.89it/s] 99%|████████████████████████████████████████████████████████████████████████████████▉ | 9614/9741 [00:05<00:00, 2108.78it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:05<00:00, 1770.68it/s]
Load End
Num instances: 1000
[2023-08-22 00:26:09,014] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 00:26:11,814] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 00:26:11,815] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 00:26:11,815] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 00:26:11,815] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 00:26:11,815] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 00:26:11,815] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 00:26:11,815] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 00:26:11,815] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 00:26:11,815] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 00:26:11,815] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 00:26:11,815] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fa2de68ca60>
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fa2de68c940>
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 00:26:11,816] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 00:26:11,817] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 00:26:11,817] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 00:26:11,817] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 00:26:11,817] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.43296074867248535 seconds
Loading extension module utils...
Time to load utils op: 0.504685640335083 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: 6

Input: Mark has kangaroos and goats.  Kangaroos have two legs and goats have four legs.  If he has 23 kangaroos and three times as many goats as kangaroos what is the total number of legs of all his animals?
Output: 322

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o3-tgsm8k-s1-rFalse
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [01:00<49:32, 60.66s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [02:00<48:02, 60.04s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:59<46:49, 59.77s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:58<45:39, 59.54s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [04:59<44:58, 59.96s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [05:58<43:43, 59.63s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [06:59<42:59, 59.99s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [07:57<41:38, 59.49s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [08:59<41:06, 60.15s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [10:00<40:22, 60.57s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [11:00<39:15, 60.40s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [12:00<38:06, 60.18s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [12:59<36:49, 59.71s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [13:59<35:52, 59.78s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [15:00<35:06, 60.20s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [15:59<33:56, 59.91s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [16:58<32:43, 59.51s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [17:57<31:44, 59.53s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [18:57<30:46, 59.56s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [19:56<29:40, 59.35s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [20:56<28:52, 59.74s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [21:57<27:59, 59.98s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [22:57<26:57, 59.90s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [23:56<25:57, 59.89s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [24:57<25:02, 60.11s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [25:56<23:56, 59.85s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [26:56<22:56, 59.85s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [27:58<22:06, 60.30s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [28:58<21:08, 60.42s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [29:59<20:11, 60.57s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [30:59<19:07, 60.38s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [31:58<18:00, 60.05s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [32:59<17:03, 60.21s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [34:01<16:10, 60.66s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [35:01<15:09, 60.61s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [36:04<14:17, 61.22s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [37:06<13:17, 61.37s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [38:06<12:11, 60.95s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [39:07<11:12, 61.15s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [40:08<10:10, 61.08s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [41:08<09:07, 60.85s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [42:07<08:02, 60.29s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [43:08<07:02, 60.35s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [44:08<06:02, 60.44s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [45:08<05:01, 60.21s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [46:08<04:00, 60.13s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [47:09<03:01, 60.37s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [48:10<02:00, 60.40s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [49:11<01:00, 60.85s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [50:12<00:00, 60.75s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [50:12<00:00, 60.25s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.1214} | avg. gen lenth: 348.818
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o4-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 2048 --num-out-domain 4
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 01:16:42,052] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o4-tgsm8k-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 4
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o4-tgsm8k-s1-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|▉                                                                                  | 115/9741 [00:00<00:08, 1144.55it/s]  2%|█▉                                                                                 | 234/9741 [00:00<00:08, 1170.58it/s]  4%|███                                                                                | 355/9741 [00:00<00:07, 1188.09it/s]  5%|████                                                                               | 477/9741 [00:00<00:07, 1198.42it/s]  6%|█████                                                                              | 599/9741 [00:00<00:07, 1202.88it/s]  7%|██████▏                                                                            | 721/9741 [00:00<00:07, 1205.38it/s]  9%|███████▏                                                                           | 844/9741 [00:00<00:07, 1211.42it/s] 10%|████████▏                                                                          | 966/9741 [00:00<00:07, 1210.56it/s] 11%|█████████▏                                                                        | 1088/9741 [00:00<00:07, 1188.83it/s] 12%|██████████▏                                                                       | 1208/9741 [00:01<00:07, 1191.43it/s] 14%|███████████▏                                                                      | 1329/9741 [00:01<00:07, 1196.03it/s] 15%|████████████▏                                                                     | 1450/9741 [00:01<00:06, 1199.80it/s] 16%|█████████████▏                                                                    | 1571/9741 [00:01<00:06, 1202.25it/s] 17%|██████████████▎                                                                   | 1693/9741 [00:01<00:06, 1206.70it/s] 19%|███████████████▎                                                                  | 1825/9741 [00:01<00:06, 1239.40it/s] 21%|████████████████▉                                                                 | 2008/9741 [00:01<00:05, 1415.57it/s] 23%|██████████████████▍                                                               | 2192/9741 [00:01<00:04, 1540.97it/s] 24%|████████████████████                                                              | 2376/9741 [00:01<00:04, 1630.22it/s] 26%|█████████████████████▌                                                            | 2558/9741 [00:01<00:04, 1686.49it/s] 28%|███████████████████████                                                           | 2739/9741 [00:02<00:04, 1722.53it/s] 30%|████████████████████████▌                                                         | 2922/9741 [00:02<00:03, 1753.35it/s] 32%|██████████████████████████▏                                                       | 3107/9741 [00:02<00:03, 1779.77it/s] 34%|███████████████████████████▋                                                      | 3291/9741 [00:02<00:03, 1796.16it/s] 36%|█████████████████████████████▏                                                    | 3474/9741 [00:02<00:03, 1806.01it/s] 38%|██████████████████████████████▊                                                   | 3656/9741 [00:02<00:03, 1808.61it/s] 39%|████████████████████████████████▎                                                 | 3838/9741 [00:02<00:03, 1811.36it/s] 41%|█████████████████████████████████▊                                                | 4022/9741 [00:02<00:03, 1817.86it/s] 43%|███████████████████████████████████▍                                              | 4204/9741 [00:02<00:03, 1816.80it/s] 45%|████████████████████████████████████▉                                             | 4386/9741 [00:02<00:02, 1814.25it/s] 47%|██████████████████████████████████████▍                                           | 4568/9741 [00:03<00:02, 1781.84it/s] 49%|███████████████████████████████████████▉                                          | 4747/9741 [00:03<00:03, 1518.79it/s] 50%|█████████████████████████████████████████▎                                        | 4915/9741 [00:03<00:03, 1560.69it/s] 52%|██████████████████████████████████████████▉                                       | 5096/9741 [00:03<00:02, 1628.78it/s] 54%|████████████████████████████████████████████▍                                     | 5275/9741 [00:03<00:02, 1673.47it/s] 56%|█████████████████████████████████████████████▉                                    | 5455/9741 [00:03<00:02, 1707.24it/s] 58%|███████████████████████████████████████████████▍                                  | 5635/9741 [00:03<00:02, 1734.05it/s] 60%|████████████████████████████████████████████████▉                                 | 5816/9741 [00:03<00:02, 1754.69it/s] 62%|██████████████████████████████████████████████████▍                               | 5995/9741 [00:03<00:02, 1764.89it/s] 63%|███████████████████████████████████████████████████▉                              | 6175/9741 [00:03<00:02, 1774.83it/s] 65%|█████████████████████████████████████████████████████▍                            | 6354/9741 [00:04<00:01, 1775.87it/s] 67%|███████████████████████████████████████████████████████                           | 6534/9741 [00:04<00:01, 1781.33it/s] 69%|████████████████████████████████████████████████████████▌                         | 6715/9741 [00:04<00:01, 1788.11it/s] 71%|██████████████████████████████████████████████████████████                        | 6896/9741 [00:04<00:01, 1791.81it/s] 73%|███████████████████████████████████████████████████████████▌                      | 7076/9741 [00:04<00:01, 1789.68it/s] 74%|█████████████████████████████████████████████████████████████                     | 7256/9741 [00:04<00:01, 1787.79it/s] 76%|██████████████████████████████████████████████████████████████▌                   | 7435/9741 [00:04<00:01, 1761.56it/s] 78%|████████████████████████████████████████████████████████████████                  | 7614/9741 [00:04<00:01, 1768.58it/s] 80%|█████████████████████████████████████████████████████████████████▌                | 7791/9741 [00:04<00:01, 1745.75it/s] 82%|███████████████████████████████████████████████████████████████████               | 7967/9741 [00:04<00:01, 1748.95it/s] 84%|████████████████████████████████████████████████████████████████████▌             | 8146/9741 [00:05<00:00, 1759.17it/s] 85%|██████████████████████████████████████████████████████████████████████            | 8324/9741 [00:05<00:00, 1764.70it/s] 87%|███████████████████████████████████████████████████████████████████████▌          | 8504/9741 [00:05<00:00, 1774.04it/s] 89%|█████████████████████████████████████████████████████████████████████████         | 8682/9741 [00:05<00:00, 1769.65it/s] 91%|██████████████████████████████████████████████████████████████████████████▌       | 8859/9741 [00:05<00:00, 1769.62it/s] 93%|████████████████████████████████████████████████████████████████████████████      | 9037/9741 [00:05<00:00, 1771.13it/s] 95%|█████████████████████████████████████████████████████████████████████████████▌    | 9216/9741 [00:05<00:00, 1776.17it/s] 96%|███████████████████████████████████████████████████████████████████████████████   | 9394/9741 [00:05<00:00, 1774.19it/s] 98%|████████████████████████████████████████████████████████████████████████████████▌ | 9572/9741 [00:05<00:00, 1772.36it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:05<00:00, 1624.66it/s]
Load End
Num instances: 1000
[2023-08-22 01:16:59,230] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 01:17:02,052] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 01:17:02,052] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f250dcbca60>
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 01:17:02,053] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f250dcbc940>
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 01:17:02,054] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 01:17:02,054] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4700629711151123 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: 6

Input: Mark has kangaroos and goats.  Kangaroos have two legs and goats have four legs.  If he has 23 kangaroos and three times as many goats as kangaroos what is the total number of legs of all his animals?
Output: 322

Input: Josh’s mom gives him $20 to go shopping at the mall. He buys a hat for $10 and a pencil for $2. Then he buys four cookies. If each cookie costs $1.25, how much money does Josh have left?
Output: 3

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o4-tgsm8k-s1-rFalse
Loading extension module utils...
Time to load utils op: 0.40447425842285156 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:57<46:40, 57.15s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:55<46:10, 57.72s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:53<45:30, 58.09s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:49<43:52, 57.23s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [04:48<43:15, 57.68s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [05:46<42:30, 57.96s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [06:43<41:17, 57.62s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [07:40<40:13, 57.46s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [08:37<39:11, 57.35s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [09:37<38:37, 57.95s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [10:35<37:42, 58.00s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [11:32<36:39, 57.89s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [12:31<35:55, 58.25s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [13:29<34:50, 58.07s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [14:27<33:50, 58.02s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [15:26<33:00, 58.26s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [16:24<31:58, 58.15s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [17:23<31:11, 58.49s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [18:21<30:05, 58.23s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [19:18<28:54, 57.83s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [20:16<28:03, 58.04s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [21:15<27:13, 58.33s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [22:14<26:16, 58.37s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [23:12<25:18, 58.39s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [24:10<24:17, 58.32s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [25:09<23:22, 58.44s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [26:07<22:21, 58.30s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [27:04<21:12, 57.86s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [28:02<20:15, 57.87s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [29:00<19:22, 58.12s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [29:59<18:27, 58.27s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [30:55<17:20, 57.78s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [31:52<16:15, 57.41s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [32:52<15:28, 58.05s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [33:50<14:34, 58.27s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [34:48<13:33, 58.09s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [35:45<12:29, 57.63s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [36:42<11:29, 57.50s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [37:40<10:33, 57.58s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [38:38<09:39, 57.92s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [39:36<08:41, 57.98s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [40:34<07:42, 57.78s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [41:31<06:43, 57.60s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [42:29<05:46, 57.80s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [43:26<04:47, 57.58s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [44:26<03:52, 58.15s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [45:24<02:54, 58.08s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [46:21<01:55, 57.93s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [47:19<00:57, 57.89s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [48:17<00:00, 57.83s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [48:17<00:00, 57.94s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.1087} | avg. gen lenth: 359.788
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o5-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 2048 --num-out-domain 5
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 02:05:26,393] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o5-tgsm8k-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 5
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o5-tgsm8k-s1-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|▊                                                                                    | 86/9741 [00:00<00:11, 855.91it/s]  2%|█▌                                                                                  | 176/9741 [00:00<00:10, 881.28it/s]  3%|██▎                                                                                 | 267/9741 [00:00<00:10, 894.07it/s]  4%|███                                                                                 | 359/9741 [00:00<00:10, 902.07it/s]  5%|███▉                                                                                | 451/9741 [00:00<00:10, 907.57it/s]  6%|████▋                                                                               | 544/9741 [00:00<00:10, 913.42it/s]  7%|█████▍                                                                              | 636/9741 [00:00<00:09, 913.91it/s]  7%|██████▎                                                                             | 729/9741 [00:00<00:09, 918.83it/s]  8%|███████                                                                             | 821/9741 [00:00<00:09, 900.34it/s]  9%|███████▊                                                                            | 912/9741 [00:01<00:09, 901.57it/s] 10%|████████▌                                                                          | 1004/9741 [00:01<00:09, 906.99it/s] 11%|█████████▎                                                                         | 1096/9741 [00:01<00:09, 910.34it/s] 12%|██████████▏                                                                        | 1189/9741 [00:01<00:09, 913.14it/s] 13%|██████████▉                                                                        | 1281/9741 [00:01<00:09, 913.59it/s] 14%|███████████▉                                                                       | 1394/9741 [00:01<00:08, 976.33it/s] 16%|████████████▉                                                                     | 1533/9741 [00:01<00:07, 1097.84it/s] 17%|██████████████                                                                    | 1673/9741 [00:01<00:06, 1185.59it/s] 19%|███████████████▏                                                                  | 1804/9741 [00:01<00:06, 1222.51it/s] 20%|████████████████▎                                                                 | 1941/9741 [00:01<00:06, 1265.00it/s] 21%|█████████████████▍                                                                | 2077/9741 [00:02<00:05, 1292.92it/s] 23%|██████████████████▋                                                               | 2214/9741 [00:02<00:05, 1313.77it/s] 24%|███████████████████▊                                                              | 2351/9741 [00:02<00:05, 1330.26it/s] 26%|████████████████████▉                                                             | 2490/9741 [00:02<00:05, 1345.28it/s] 27%|██████████████████████                                                            | 2628/9741 [00:02<00:05, 1354.61it/s] 28%|███████████████████████▎                                                          | 2765/9741 [00:02<00:05, 1357.42it/s] 30%|████████████████████████▍                                                         | 2901/9741 [00:02<00:05, 1358.04it/s] 31%|█████████████████████████▌                                                        | 3039/9741 [00:02<00:04, 1361.99it/s] 33%|██████████████████████████▋                                                       | 3176/9741 [00:02<00:04, 1361.98it/s] 34%|███████████████████████████▉                                                      | 3314/9741 [00:02<00:04, 1366.83it/s] 35%|█████████████████████████████                                                     | 3451/9741 [00:03<00:04, 1360.78it/s] 37%|██████████████████████████████▏                                                   | 3588/9741 [00:03<00:04, 1359.01it/s] 38%|███████████████████████████████▎                                                  | 3724/9741 [00:03<00:04, 1343.23it/s] 40%|████████████████████████████████▍                                                 | 3860/9741 [00:03<00:04, 1346.37it/s] 41%|█████████████████████████████████▋                                                | 3997/9741 [00:03<00:04, 1351.96it/s] 42%|██████████████████████████████████▊                                               | 4133/9741 [00:03<00:04, 1353.96it/s] 44%|███████████████████████████████████▉                                              | 4269/9741 [00:03<00:04, 1352.30it/s] 45%|█████████████████████████████████████                                             | 4405/9741 [00:03<00:03, 1354.24it/s] 47%|██████████████████████████████████████▏                                           | 4541/9741 [00:03<00:03, 1312.29it/s] 48%|███████████████████████████████████████▎                                          | 4677/9741 [00:03<00:03, 1326.07it/s] 49%|████████████████████████████████████████▍                                         | 4810/9741 [00:04<00:04, 1035.17it/s] 51%|█████████████████████████████████████████▋                                        | 4945/9741 [00:04<00:04, 1110.95it/s] 52%|██████████████████████████████████████████▊                                       | 5081/9741 [00:04<00:03, 1174.89it/s] 54%|███████████████████████████████████████████▉                                      | 5216/9741 [00:04<00:03, 1220.46it/s] 55%|█████████████████████████████████████████████                                     | 5351/9741 [00:04<00:03, 1256.01it/s] 56%|██████████████████████████████████████████████▏                                   | 5485/9741 [00:04<00:03, 1277.64it/s] 58%|███████████████████████████████████████████████▎                                  | 5620/9741 [00:04<00:03, 1296.25it/s] 59%|████████████████████████████████████████████████▍                                 | 5756/9741 [00:04<00:03, 1312.07it/s] 60%|█████████████████████████████████████████████████▌                                | 5891/9741 [00:04<00:02, 1321.72it/s] 62%|██████████████████████████████████████████████████▋                               | 6027/9741 [00:05<00:02, 1332.99it/s] 63%|███████████████████████████████████████████████████▊                              | 6162/9741 [00:05<00:02, 1336.50it/s] 65%|█████████████████████████████████████████████████████                             | 6297/9741 [00:05<00:02, 1338.20it/s] 66%|██████████████████████████████████████████████████████▏                           | 6433/9741 [00:05<00:02, 1342.62it/s] 67%|███████████████████████████████████████████████████████▎                          | 6568/9741 [00:05<00:02, 1339.50it/s] 69%|████████████████████████████████████████████████████████▍                         | 6703/9741 [00:05<00:02, 1338.89it/s] 70%|█████████████████████████████████████████████████████████▌                        | 6838/9741 [00:05<00:02, 1341.23it/s] 72%|██████████████████████████████████████████████████████████▋                       | 6973/9741 [00:05<00:02, 1340.13it/s] 73%|███████████████████████████████████████████████████████████▊                      | 7108/9741 [00:05<00:01, 1341.23it/s] 74%|████████████████████████████████████████████████████████████▉                     | 7243/9741 [00:05<00:01, 1339.29it/s] 76%|██████████████████████████████████████████████████████████████                    | 7378/9741 [00:06<00:01, 1340.49it/s] 77%|███████████████████████████████████████████████████████████████▏                  | 7513/9741 [00:06<00:01, 1310.58it/s] 78%|████████████████████████████████████████████████████████████████▎                 | 7646/9741 [00:06<00:01, 1314.29it/s] 80%|█████████████████████████████████████████████████████████████████▍                | 7780/9741 [00:06<00:01, 1320.69it/s] 81%|██████████████████████████████████████████████████████████████████▌               | 7913/9741 [00:06<00:01, 1320.64it/s] 83%|███████████████████████████████████████████████████████████████████▋              | 8046/9741 [00:06<00:01, 1297.35it/s] 84%|████████████████████████████████████████████████████████████████████▊             | 8178/9741 [00:06<00:01, 1302.13it/s] 85%|█████████████████████████████████████████████████████████████████████▉            | 8311/9741 [00:06<00:01, 1308.50it/s] 87%|███████████████████████████████████████████████████████████████████████           | 8444/9741 [00:06<00:00, 1313.61it/s] 88%|████████████████████████████████████████████████████████████████████████▏         | 8577/9741 [00:06<00:00, 1316.83it/s] 89%|█████████████████████████████████████████████████████████████████████████▎        | 8709/9741 [00:07<00:00, 1317.31it/s] 91%|██████████████████████████████████████████████████████████████████████████▍       | 8841/9741 [00:07<00:00, 1314.52it/s] 92%|███████████████████████████████████████████████████████████████████████████▌      | 8974/9741 [00:07<00:00, 1316.18it/s] 93%|████████████████████████████████████████████████████████████████████████████▋     | 9106/9741 [00:07<00:00, 1311.94it/s] 95%|█████████████████████████████████████████████████████████████████████████████▊    | 9238/9741 [00:07<00:00, 1312.74it/s] 96%|██████████████████████████████████████████████████████████████████████████████▉   | 9371/9741 [00:07<00:00, 1316.18it/s] 98%|███████████████████████████████████████████████████████████████████████████████▉  | 9503/9741 [00:07<00:00, 1314.39it/s] 99%|█████████████████████████████████████████████████████████████████████████████████ | 9636/9741 [00:07<00:00, 1316.35it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:07<00:00, 1240.90it/s]
Load End
Num instances: 1000
[2023-08-22 02:05:45,322] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 02:05:48,083] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 02:05:48,083] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 02:05:48,083] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 02:05:48,083] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 02:05:48,083] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 02:05:48,083] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f2931e18a60>
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f2931e18940>
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 02:05:48,084] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 02:05:48,085] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 02:05:48,085] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 02:05:48,085] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 02:05:48,085] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 02:05:48,085] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 02:05:48,085] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 02:05:48,085] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 02:05:48,085] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 02:05:48,085] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 02:05:48,085] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 02:05:48,085] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 02:05:48,085] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 02:05:48,085] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 02:05:48,085] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 02:05:48,085] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 02:05:48,085] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 02:05:48,085] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4545278549194336 seconds
Loading extension module utils...
Time to load utils op: 0.5048437118530273 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: 6

Input: Mark has kangaroos and goats.  Kangaroos have two legs and goats have four legs.  If he has 23 kangaroos and three times as many goats as kangaroos what is the total number of legs of all his animals?
Output: 322

Input: Josh’s mom gives him $20 to go shopping at the mall. He buys a hat for $10 and a pencil for $2. Then he buys four cookies. If each cookie costs $1.25, how much money does Josh have left?
Output: 3

Input: George's bowling team is one round away from breaking the league record for most points scored in a season. The old record is an average score per player of 287 per round. Each team has 4 players and there are 10 rounds in the season. Through the first 9 rounds, his team has scored a total of 10,440. How many points less than the current league record per game average is the minimum average they need to score, per player, in the final round to tie the league record?
Output: 27

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o5-tgsm8k-s1-rFalse
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:53<43:56, 53.81s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:46<42:44, 53.43s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:41<42:20, 54.06s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:34<40:53, 53.34s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [04:28<40:26, 53.93s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [05:22<39:31, 53.91s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [06:16<38:32, 53.78s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [07:09<37:34, 53.67s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [08:02<36:34, 53.52s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [08:57<35:51, 53.79s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [09:50<34:51, 53.63s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [10:43<33:51, 53.47s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [11:37<32:56, 53.43s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [12:31<32:12, 53.68s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [13:23<31:01, 53.17s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [14:16<30:04, 53.07s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [15:08<29:03, 52.82s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [16:00<28:06, 52.71s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [16:54<27:19, 52.88s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [17:47<26:34, 53.14s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [18:40<25:38, 53.06s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [19:32<24:36, 52.72s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [20:25<23:45, 52.80s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [21:18<22:53, 52.81s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [22:12<22:07, 53.10s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [23:06<21:19, 53.31s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [23:59<20:29, 53.48s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [24:53<19:35, 53.44s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [25:47<18:48, 53.73s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [26:41<17:51, 53.60s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [27:34<16:58, 53.59s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [28:28<16:03, 53.55s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [29:22<15:14, 53.77s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [30:16<14:20, 53.76s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [31:09<13:26, 53.78s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [32:03<12:31, 53.67s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [32:57<11:38, 53.72s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [33:53<10:52, 54.40s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [34:47<09:56, 54.25s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [35:41<09:03, 54.32s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [36:34<08:05, 53.92s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [37:27<07:08, 53.60s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [38:20<06:14, 53.51s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [39:15<05:23, 54.00s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [40:08<04:27, 53.52s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [41:02<03:35, 53.83s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [41:55<02:40, 53.47s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [42:48<01:46, 53.41s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [43:42<00:53, 53.60s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [44:37<00:00, 53.93s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [44:37<00:00, 53.55s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 0.9891} | avg. gen lenth: 397.816
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 2048 --num-out-domain 6
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 02:51:00,603] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 6
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o6-tgsm8k-s1-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|▋                                                                                    | 76/9741 [00:00<00:12, 752.44it/s]  2%|█▎                                                                                  | 155/9741 [00:00<00:12, 770.50it/s]  2%|██                                                                                  | 234/9741 [00:00<00:12, 779.11it/s]  3%|██▋                                                                                 | 314/9741 [00:00<00:11, 786.26it/s]  4%|███▍                                                                                | 394/9741 [00:00<00:11, 790.85it/s]  5%|████                                                                                | 474/9741 [00:00<00:11, 792.27it/s]  6%|████▊                                                                               | 555/9741 [00:00<00:11, 795.44it/s]  7%|█████▍                                                                              | 635/9741 [00:00<00:11, 776.79it/s]  7%|██████▏                                                                             | 715/9741 [00:00<00:11, 781.12it/s]  8%|██████▊                                                                             | 796/9741 [00:01<00:11, 787.54it/s]  9%|███████▌                                                                            | 876/9741 [00:01<00:11, 791.02it/s] 10%|████████▎                                                                           | 957/9741 [00:01<00:11, 794.86it/s] 11%|████████▊                                                                          | 1038/9741 [00:01<00:10, 797.54it/s] 11%|█████████▌                                                                         | 1118/9741 [00:01<00:10, 797.75it/s] 12%|██████████▏                                                                        | 1199/9741 [00:01<00:10, 798.46it/s] 13%|██████████▉                                                                        | 1280/9741 [00:01<00:10, 799.03it/s] 14%|███████████▌                                                                       | 1360/9741 [00:01<00:10, 798.30it/s] 15%|████████████▎                                                                      | 1440/9741 [00:01<00:10, 795.84it/s] 16%|████████████▉                                                                      | 1520/9741 [00:01<00:10, 795.54it/s] 16%|█████████████▋                                                                     | 1600/9741 [00:02<00:10, 794.80it/s] 17%|██████████████▎                                                                    | 1681/9741 [00:02<00:10, 796.96it/s] 18%|███████████████▏                                                                   | 1786/9741 [00:02<00:09, 871.38it/s] 20%|████████████████▏                                                                  | 1907/9741 [00:02<00:08, 970.50it/s] 21%|█████████████████                                                                 | 2027/9741 [00:02<00:07, 1037.64it/s] 22%|██████████████████                                                                | 2147/9741 [00:02<00:06, 1085.67it/s] 23%|███████████████████                                                               | 2267/9741 [00:02<00:06, 1117.29it/s] 25%|████████████████████                                                              | 2387/9741 [00:02<00:06, 1140.39it/s] 26%|█████████████████████                                                             | 2506/9741 [00:02<00:06, 1153.22it/s] 27%|██████████████████████                                                            | 2626/9741 [00:02<00:06, 1165.07it/s] 28%|███████████████████████                                                           | 2745/9741 [00:03<00:05, 1171.24it/s] 29%|████████████████████████                                                          | 2863/9741 [00:03<00:05, 1160.45it/s] 31%|█████████████████████████                                                         | 2980/9741 [00:03<00:05, 1162.60it/s] 32%|██████████████████████████                                                        | 3099/9741 [00:03<00:05, 1169.58it/s] 33%|███████████████████████████                                                       | 3219/9741 [00:03<00:05, 1175.90it/s] 34%|████████████████████████████                                                      | 3338/9741 [00:03<00:05, 1179.86it/s] 35%|█████████████████████████████                                                     | 3456/9741 [00:03<00:05, 1177.94it/s] 37%|██████████████████████████████                                                    | 3575/9741 [00:03<00:05, 1176.71it/s] 38%|███████████████████████████████                                                   | 3694/9741 [00:03<00:05, 1179.26it/s] 39%|████████████████████████████████                                                  | 3812/9741 [00:03<00:05, 1178.43it/s] 40%|█████████████████████████████████                                                 | 3931/9741 [00:04<00:04, 1180.53it/s] 42%|██████████████████████████████████                                                | 4050/9741 [00:04<00:04, 1177.52it/s] 43%|███████████████████████████████████                                               | 4169/9741 [00:04<00:04, 1178.92it/s] 44%|████████████████████████████████████                                              | 4287/9741 [00:04<00:04, 1177.23it/s] 45%|█████████████████████████████████████                                             | 4406/9741 [00:04<00:04, 1178.41it/s] 46%|██████████████████████████████████████                                            | 4524/9741 [00:04<00:04, 1144.07it/s] 48%|███████████████████████████████████████                                           | 4642/9741 [00:04<00:04, 1154.47it/s] 49%|████████████████████████████████████████▌                                          | 4758/9741 [00:04<00:05, 897.18it/s] 50%|█████████████████████████████████████████▌                                         | 4875/9741 [00:04<00:05, 964.33it/s] 51%|██████████████████████████████████████████                                        | 4992/9741 [00:05<00:04, 1017.27it/s] 52%|███████████████████████████████████████████                                       | 5110/9741 [00:05<00:04, 1060.89it/s] 54%|████████████████████████████████████████████                                      | 5227/9741 [00:05<00:04, 1090.77it/s] 55%|████████████████████████████████████████████▉                                     | 5345/9741 [00:05<00:03, 1113.56it/s] 56%|█████████████████████████████████████████████▉                                    | 5462/9741 [00:05<00:03, 1128.44it/s] 57%|██████████████████████████████████████████████▉                                   | 5579/9741 [00:05<00:03, 1140.31it/s] 58%|███████████████████████████████████████████████▉                                  | 5696/9741 [00:05<00:03, 1147.68it/s] 60%|████████████████████████████████████████████████▉                                 | 5813/9741 [00:05<00:03, 1154.02it/s] 61%|█████████████████████████████████████████████████▉                                | 5930/9741 [00:05<00:03, 1157.69it/s] 62%|██████████████████████████████████████████████████▉                               | 6048/9741 [00:05<00:03, 1160.72it/s] 63%|███████████████████████████████████████████████████▉                              | 6166/9741 [00:06<00:03, 1163.74it/s] 65%|████████████████████████████████████████████████████▉                             | 6283/9741 [00:06<00:02, 1160.98it/s] 66%|█████████████████████████████████████████████████████▉                            | 6401/9741 [00:06<00:02, 1164.22it/s] 67%|██████████████████████████████████████████████████████▊                           | 6518/9741 [00:06<00:02, 1163.97it/s] 68%|███████████████████████████████████████████████████████▊                          | 6635/9741 [00:06<00:02, 1164.34it/s] 69%|████████████████████████████████████████████████████████▊                         | 6752/9741 [00:06<00:02, 1141.62it/s] 71%|█████████████████████████████████████████████████████████▊                        | 6869/9741 [00:06<00:02, 1147.68it/s] 72%|██████████████████████████████████████████████████████████▊                       | 6984/9741 [00:06<00:02, 1147.66it/s] 73%|███████████████████████████████████████████████████████████▊                      | 7101/9741 [00:06<00:02, 1152.97it/s] 74%|████████████████████████████████████████████████████████████▊                     | 7217/9741 [00:06<00:02, 1152.78it/s] 75%|█████████████████████████████████████████████████████████████▋                    | 7334/9741 [00:07<00:02, 1156.29it/s] 76%|██████████████████████████████████████████████████████████████▋                   | 7450/9741 [00:07<00:02, 1119.83it/s] 78%|███████████████████████████████████████████████████████████████▋                  | 7566/9741 [00:07<00:01, 1130.24it/s] 79%|████████████████████████████████████████████████████████████████▋                 | 7681/9741 [00:07<00:01, 1135.49it/s] 80%|█████████████████████████████████████████████████████████████████▋                | 7798/9741 [00:07<00:01, 1143.42it/s] 81%|██████████████████████████████████████████████████████████████████▌               | 7914/9741 [00:07<00:01, 1147.63it/s] 82%|███████████████████████████████████████████████████████████████████▌              | 8030/9741 [00:07<00:01, 1150.48it/s] 84%|████████████████████████████████████████████████████████████████████▌             | 8146/9741 [00:07<00:01, 1147.97it/s] 85%|█████████████████████████████████████████████████████████████████████▌            | 8262/9741 [00:07<00:01, 1151.11it/s] 86%|██████████████████████████████████████████████████████████████████████▌           | 8378/9741 [00:07<00:01, 1151.46it/s] 87%|███████████████████████████████████████████████████████████████████████▌          | 8495/9741 [00:08<00:01, 1154.27it/s] 88%|████████████████████████████████████████████████████████████████████████▍         | 8611/9741 [00:08<00:00, 1149.98it/s] 90%|█████████████████████████████████████████████████████████████████████████▍        | 8727/9741 [00:08<00:00, 1147.01it/s] 91%|██████████████████████████████████████████████████████████████████████████▍       | 8842/9741 [00:08<00:00, 1146.94it/s] 92%|███████████████████████████████████████████████████████████████████████████▍      | 8958/9741 [00:08<00:00, 1150.13it/s] 93%|████████████████████████████████████████████████████████████████████████████▍     | 9074/9741 [00:08<00:00, 1149.38it/s] 94%|█████████████████████████████████████████████████████████████████████████████▎    | 9189/9741 [00:08<00:00, 1148.34it/s] 96%|██████████████████████████████████████████████████████████████████████████████▎   | 9304/9741 [00:08<00:00, 1140.29it/s] 97%|███████████████████████████████████████████████████████████████████████████████▎  | 9421/9741 [00:08<00:00, 1146.48it/s] 98%|████████████████████████████████████████████████████████████████████████████████▎ | 9537/9741 [00:08<00:00, 1147.95it/s] 99%|█████████████████████████████████████████████████████████████████████████████████▎| 9652/9741 [00:09<00:00, 1147.16it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:09<00:00, 1062.42it/s]
Load End
Num instances: 1000
[2023-08-22 02:51:20,814] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 02:51:23,522] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 02:51:23,523] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 02:51:23,523] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 02:51:23,523] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 02:51:23,523] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 02:51:23,523] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 02:51:23,523] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 02:51:23,523] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 02:51:23,523] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 02:51:23,523] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 02:51:23,523] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 02:51:23,523] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f93cf8c4a60>
[2023-08-22 02:51:23,523] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 02:51:23,523] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 02:51:23,523] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 02:51:23,523] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 02:51:23,523] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 02:51:23,523] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 02:51:23,523] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 02:51:23,523] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 02:51:23,523] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 02:51:23,523] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 02:51:23,523] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 02:51:23,523] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 02:51:23,523] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 02:51:23,523] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 02:51:23,523] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 02:51:23,523] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 02:51:23,523] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 02:51:23,523] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f93cf8c4940>
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 02:51:23,524] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 02:51:23,524] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.43784022331237793 seconds
Loading extension module utils...
Time to load utils op: 0.5048606395721436 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: 6

Input: Mark has kangaroos and goats.  Kangaroos have two legs and goats have four legs.  If he has 23 kangaroos and three times as many goats as kangaroos what is the total number of legs of all his animals?
Output: 322

Input: Josh’s mom gives him $20 to go shopping at the mall. He buys a hat for $10 and a pencil for $2. Then he buys four cookies. If each cookie costs $1.25, how much money does Josh have left?
Output: 3

Input: George's bowling team is one round away from breaking the league record for most points scored in a season. The old record is an average score per player of 287 per round. Each team has 4 players and there are 10 rounds in the season. Through the first 9 rounds, his team has scored a total of 10,440. How many points less than the current league record per game average is the minimum average they need to score, per player, in the final round to tie the league record?
Output: 27

Input: Max was doing homework in three different subjects. It took him 20 minutes to finish tasks from biology and two times more time to finish history. Geography took him the most time, three times more than history. How much time did Max spend on doing his homework?
Output: 180

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o6-tgsm8k-s1-rFalse
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:51<42:00, 51.43s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:42<41:11, 51.49s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:35<40:43, 51.99s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:27<39:56, 52.09s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [04:20<39:11, 52.26s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [05:13<38:28, 52.46s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [06:04<37:23, 52.17s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [06:55<36:10, 51.67s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [07:48<35:35, 52.07s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [08:41<34:53, 52.34s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [09:31<33:41, 51.83s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [10:23<32:42, 51.64s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [11:15<31:58, 51.85s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [12:07<31:08, 51.91s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [12:59<30:17, 51.94s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [13:52<29:32, 52.14s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [14:43<28:30, 51.84s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [15:34<27:30, 51.59s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [16:26<26:45, 51.79s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [17:17<25:44, 51.50s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [18:08<24:49, 51.35s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [18:59<23:53, 51.21s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [19:49<22:55, 50.93s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [20:40<22:06, 51.03s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [21:32<21:17, 51.09s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [22:23<20:30, 51.25s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [23:15<19:45, 51.55s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [24:06<18:50, 51.40s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [24:58<18:02, 51.54s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [25:51<17:15, 51.78s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [26:45<16:36, 52.44s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [27:36<15:40, 52.26s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [28:29<14:48, 52.24s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [29:20<13:53, 52.09s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [30:13<13:04, 52.31s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [31:05<12:09, 52.10s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [31:56<11:11, 51.69s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [32:48<10:24, 52.02s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [33:40<09:31, 51.96s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [34:34<08:45, 52.52s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [35:26<07:50, 52.27s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [36:17<06:55, 51.96s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [37:09<06:03, 51.90s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [38:00<05:09, 51.58s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [38:51<04:17, 51.46s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [39:44<03:27, 51.95s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [40:35<02:35, 51.86s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [41:28<01:43, 52.00s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [42:19<00:51, 51.89s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [43:12<00:00, 51.96s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [43:12<00:00, 51.84s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.3574} | avg. gen lenth: 381.476
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o7-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 2048 --num-out-domain 7
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 03:34:44,680] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o7-tgsm8k-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 7
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o7-tgsm8k-s1-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|▌                                                                                    | 71/9741 [00:00<00:13, 701.44it/s]  1%|█▎                                                                                  | 145/9741 [00:00<00:13, 721.36it/s]  2%|█▉                                                                                  | 219/9741 [00:00<00:13, 726.02it/s]  3%|██▌                                                                                 | 294/9741 [00:00<00:12, 733.02it/s]  4%|███▏                                                                                | 370/9741 [00:00<00:12, 739.58it/s]  5%|███▊                                                                                | 445/9741 [00:00<00:12, 739.80it/s]  5%|████▍                                                                               | 521/9741 [00:00<00:12, 743.53it/s]  6%|█████▏                                                                              | 596/9741 [00:00<00:12, 745.23it/s]  7%|█████▊                                                                              | 671/9741 [00:00<00:12, 727.43it/s]  8%|██████▍                                                                             | 746/9741 [00:01<00:12, 732.85it/s]  8%|███████                                                                             | 821/9741 [00:01<00:12, 737.67it/s]  9%|███████▋                                                                            | 896/9741 [00:01<00:11, 739.59it/s] 10%|████████▎                                                                           | 971/9741 [00:01<00:11, 742.69it/s] 11%|████████▉                                                                          | 1047/9741 [00:01<00:11, 745.15it/s] 12%|█████████▌                                                                         | 1122/9741 [00:01<00:11, 744.99it/s] 12%|██████████▏                                                                        | 1197/9741 [00:01<00:11, 738.85it/s] 13%|██████████▊                                                                        | 1273/9741 [00:01<00:11, 742.32it/s] 14%|███████████▍                                                                       | 1348/9741 [00:01<00:11, 743.87it/s] 15%|████████████                                                                       | 1423/9741 [00:01<00:11, 743.13it/s] 15%|████████████▊                                                                      | 1498/9741 [00:02<00:11, 743.38it/s] 16%|█████████████▍                                                                     | 1573/9741 [00:02<00:10, 743.66it/s] 17%|██████████████                                                                     | 1648/9741 [00:02<00:10, 745.27it/s] 18%|██████████████▋                                                                    | 1723/9741 [00:02<00:10, 746.14it/s] 18%|███████████████▎                                                                   | 1798/9741 [00:02<00:10, 728.89it/s] 19%|███████████████▉                                                                   | 1873/9741 [00:02<00:10, 733.26it/s] 20%|████████████████▌                                                                  | 1948/9741 [00:02<00:10, 736.88it/s] 21%|█████████████████▏                                                                 | 2023/9741 [00:02<00:10, 738.20it/s] 22%|█████████████████▉                                                                 | 2098/9741 [00:02<00:10, 739.09it/s] 22%|██████████████████▌                                                                | 2173/9741 [00:02<00:10, 741.21it/s] 23%|███████████████████▏                                                               | 2248/9741 [00:03<00:10, 741.44it/s] 24%|███████████████████▊                                                               | 2323/9741 [00:03<00:10, 741.34it/s] 25%|████████████████████▍                                                              | 2398/9741 [00:03<00:10, 731.56it/s] 25%|█████████████████████                                                              | 2472/9741 [00:03<00:09, 732.22it/s] 26%|█████████████████████▋                                                             | 2546/9741 [00:03<00:09, 734.34it/s] 27%|██████████████████████▎                                                            | 2621/9741 [00:03<00:09, 737.62it/s] 28%|███████████████████████▎                                                           | 2730/9741 [00:03<00:08, 842.15it/s] 29%|████████████████████████▏                                                          | 2841/9741 [00:03<00:07, 920.32it/s] 30%|█████████████████████████▏                                                         | 2952/9741 [00:03<00:06, 974.47it/s] 31%|█████████████████████████▊                                                        | 3064/9741 [00:03<00:06, 1015.22it/s] 33%|██████████████████████████▋                                                       | 3175/9741 [00:04<00:06, 1041.98it/s] 34%|███████████████████████████▋                                                      | 3286/9741 [00:04<00:06, 1062.02it/s] 35%|████████████████████████████▌                                                     | 3396/9741 [00:04<00:05, 1072.17it/s] 36%|█████████████████████████████▌                                                    | 3507/9741 [00:04<00:05, 1080.77it/s] 37%|██████████████████████████████▍                                                   | 3617/9741 [00:04<00:05, 1084.93it/s] 38%|███████████████████████████████▎                                                  | 3726/9741 [00:04<00:05, 1047.19it/s] 39%|████████████████████████████████▎                                                 | 3836/9741 [00:04<00:05, 1061.06it/s] 41%|█████████████████████████████████▏                                                | 3947/9741 [00:04<00:05, 1074.42it/s] 42%|██████████████████████████████████▏                                               | 4057/9741 [00:04<00:05, 1079.80it/s] 43%|███████████████████████████████████                                               | 4168/9741 [00:04<00:05, 1086.18it/s] 44%|████████████████████████████████████                                              | 4278/9741 [00:05<00:05, 1089.66it/s] 45%|████████████████████████████████████▉                                             | 4389/9741 [00:05<00:04, 1093.19it/s] 46%|█████████████████████████████████████▊                                            | 4499/9741 [00:05<00:04, 1061.85it/s] 47%|██████████████████████████████████████▊                                           | 4609/9741 [00:05<00:04, 1071.75it/s] 48%|████████████████████████████████████████▏                                          | 4717/9741 [00:05<00:06, 819.63it/s] 50%|█████████████████████████████████████████▏                                         | 4827/9741 [00:05<00:05, 885.99it/s] 51%|██████████████████████████████████████████                                         | 4936/9741 [00:05<00:05, 936.97it/s] 52%|██████████████████████████████████████████▉                                        | 5046/9741 [00:05<00:04, 979.49it/s] 53%|███████████████████████████████████████████▍                                      | 5154/9741 [00:05<00:04, 1006.39it/s] 54%|████████████████████████████████████████████▎                                     | 5264/9741 [00:06<00:04, 1031.02it/s] 55%|█████████████████████████████████████████████▏                                    | 5373/9741 [00:06<00:04, 1045.81it/s] 56%|██████████████████████████████████████████████▏                                   | 5482/9741 [00:06<00:04, 1056.43it/s] 57%|███████████████████████████████████████████████                                   | 5591/9741 [00:06<00:03, 1065.36it/s] 59%|███████████████████████████████████████████████▉                                  | 5699/9741 [00:06<00:03, 1069.29it/s] 60%|████████████████████████████████████████████████▉                                 | 5807/9741 [00:06<00:03, 1056.10it/s] 61%|█████████████████████████████████████████████████▊                                | 5914/9741 [00:06<00:03, 1059.91it/s] 62%|██████████████████████████████████████████████████▋                               | 6023/9741 [00:06<00:03, 1066.70it/s] 63%|███████████████████████████████████████████████████▌                              | 6130/9741 [00:06<00:03, 1066.88it/s] 64%|████████████████████████████████████████████████████▌                             | 6238/9741 [00:06<00:03, 1068.77it/s] 65%|█████████████████████████████████████████████████████▍                            | 6346/9741 [00:07<00:03, 1069.99it/s] 66%|██████████████████████████████████████████████████████▎                           | 6455/9741 [00:07<00:03, 1073.34it/s] 67%|███████████████████████████████████████████████████████▏                          | 6563/9741 [00:07<00:02, 1072.09it/s] 68%|████████████████████████████████████████████████████████▏                         | 6671/9741 [00:07<00:02, 1073.27it/s] 70%|█████████████████████████████████████████████████████████                         | 6779/9741 [00:07<00:02, 1073.31it/s] 71%|█████████████████████████████████████████████████████████▉                        | 6887/9741 [00:07<00:02, 1075.00it/s] 72%|██████████████████████████████████████████████████████████▉                       | 6995/9741 [00:07<00:02, 1073.50it/s] 73%|███████████████████████████████████████████████████████████▊                      | 7103/9741 [00:07<00:02, 1073.37it/s] 74%|████████████████████████████████████████████████████████████▋                     | 7211/9741 [00:07<00:02, 1070.47it/s] 75%|█████████████████████████████████████████████████████████████▌                    | 7319/9741 [00:08<00:02, 1070.64it/s] 76%|██████████████████████████████████████████████████████████████▌                   | 7427/9741 [00:08<00:02, 1041.03it/s] 77%|███████████████████████████████████████████████████████████████▍                  | 7535/9741 [00:08<00:02, 1050.64it/s] 78%|████████████████████████████████████████████████████████████████▎                 | 7641/9741 [00:08<00:01, 1051.62it/s] 80%|█████████████████████████████████████████████████████████████████▏                | 7749/9741 [00:08<00:01, 1057.61it/s] 81%|██████████████████████████████████████████████████████████████████▏               | 7856/9741 [00:08<00:01, 1059.36it/s] 82%|███████████████████████████████████████████████████████████████████               | 7962/9741 [00:08<00:01, 1058.45it/s] 83%|███████████████████████████████████████████████████████████████████▉              | 8069/9741 [00:08<00:01, 1061.65it/s] 84%|████████████████████████████████████████████████████████████████████▊             | 8176/9741 [00:08<00:01, 1062.00it/s] 85%|█████████████████████████████████████████████████████████████████████▋            | 8283/9741 [00:08<00:01, 1063.87it/s] 86%|██████████████████████████████████████████████████████████████████████▋           | 8390/9741 [00:09<00:01, 1063.05it/s] 87%|███████████████████████████████████████████████████████████████████████▌          | 8498/9741 [00:09<00:01, 1066.00it/s] 88%|████████████████████████████████████████████████████████████████████████▍         | 8605/9741 [00:09<00:01, 1063.25it/s] 89%|█████████████████████████████████████████████████████████████████████████▎        | 8712/9741 [00:09<00:00, 1063.67it/s] 91%|██████████████████████████████████████████████████████████████████████████▏       | 8819/9741 [00:09<00:00, 1061.64it/s] 92%|███████████████████████████████████████████████████████████████████████████▏      | 8926/9741 [00:09<00:00, 1062.00it/s] 93%|████████████████████████████████████████████████████████████████████████████      | 9033/9741 [00:09<00:00, 1058.97it/s] 94%|████████████████████████████████████████████████████████████████████████████▉     | 9140/9741 [00:09<00:00, 1059.38it/s] 95%|█████████████████████████████████████████████████████████████████████████████▊    | 9246/9741 [00:09<00:00, 1056.97it/s] 96%|██████████████████████████████████████████████████████████████████████████████▋   | 9352/9741 [00:09<00:00, 1056.33it/s] 97%|███████████████████████████████████████████████████████████████████████████████▌  | 9458/9741 [00:10<00:00, 1052.33it/s] 98%|████████████████████████████████████████████████████████████████████████████████▌ | 9564/9741 [00:10<00:00, 1053.59it/s] 99%|█████████████████████████████████████████████████████████████████████████████████▍| 9670/9741 [00:10<00:00, 1052.62it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:10<00:00, 945.61it/s]
Load End
Num instances: 1000
[2023-08-22 03:35:05,966] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 03:35:08,690] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 03:35:08,690] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f2852876a60>
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 03:35:08,691] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f2852876940>
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 03:35:08,692] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 03:35:08,692] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.45701169967651367 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: 6

Input: Mark has kangaroos and goats.  Kangaroos have two legs and goats have four legs.  If he has 23 kangaroos and three times as many goats as kangaroos what is the total number of legs of all his animals?
Output: 322

Input: Josh’s mom gives him $20 to go shopping at the mall. He buys a hat for $10 and a pencil for $2. Then he buys four cookies. If each cookie costs $1.25, how much money does Josh have left?
Output: 3

Input: George's bowling team is one round away from breaking the league record for most points scored in a season. The old record is an average score per player of 287 per round. Each team has 4 players and there are 10 rounds in the season. Through the first 9 rounds, his team has scored a total of 10,440. How many points less than the current league record per game average is the minimum average they need to score, per player, in the final round to tie the league record?
Output: 27

Input: Max was doing homework in three different subjects. It took him 20 minutes to finish tasks from biology and two times more time to finish history. Geography took him the most time, three times more than history. How much time did Max spend on doing his homework?
Output: 180

Input: Sophia ate 1/6 of her pie and she put the rest on the fridge. If the pie left in the fridge weighs 1200 grams, how many grams did Sophia eat?
Output: 240

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o7-tgsm8k-s1-rFalse
Loading extension module utils...
Time to load utils op: 0.504040002822876 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:52<42:43, 52.32s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:43<41:14, 51.56s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:36<40:55, 52.24s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:26<39:31, 51.55s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [04:19<38:53, 51.85s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [05:11<38:02, 51.87s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [06:01<36:48, 51.35s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [06:52<35:58, 51.39s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [07:44<35:12, 51.53s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [08:36<34:25, 51.64s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [09:27<33:24, 51.39s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [10:19<32:38, 51.54s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [11:10<31:40, 51.37s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [12:00<30:38, 51.07s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [12:50<29:32, 50.64s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [13:41<28:45, 50.76s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [14:31<27:51, 50.64s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [15:22<27:04, 50.76s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [16:14<26:26, 51.17s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [17:05<25:30, 51.02s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [17:56<24:34, 50.84s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [18:46<23:38, 50.67s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [19:35<22:38, 50.31s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [20:26<21:54, 50.55s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [21:18<21:12, 50.89s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [22:10<20:27, 51.16s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [23:01<19:34, 51.07s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [23:51<18:38, 50.85s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [24:42<17:45, 50.75s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [25:33<17:00, 51.03s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [26:25<16:10, 51.10s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [27:16<15:20, 51.15s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [28:07<14:28, 51.07s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [28:57<13:32, 50.77s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [29:48<12:41, 50.78s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [30:39<11:52, 50.87s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [31:30<11:03, 51.05s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [32:23<10:17, 51.48s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [33:14<09:26, 51.54s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [34:07<08:39, 51.96s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [34:58<07:43, 51.55s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [35:47<06:47, 50.91s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [36:37<05:54, 50.59s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [37:28<05:03, 50.64s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [38:18<04:13, 50.65s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [39:10<03:23, 50.95s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [40:01<02:32, 50.83s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [40:51<01:41, 50.77s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [41:44<00:51, 51.30s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [42:34<00:00, 50.95s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [42:34<00:00, 51.09s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.2592} | avg. gen lenth: 387.98
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 2048 --num-out-domain 8
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 04:17:53,694] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 8
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o8-tgsm8k-s1-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|▌                                                                                    | 63/9741 [00:00<00:15, 629.71it/s]  1%|█                                                                                   | 130/9741 [00:00<00:14, 649.51it/s]  2%|█▋                                                                                  | 196/9741 [00:00<00:14, 653.88it/s]  3%|██▎                                                                                 | 263/9741 [00:00<00:14, 659.19it/s]  3%|██▊                                                                                 | 331/9741 [00:00<00:14, 663.75it/s]  4%|███▍                                                                                | 398/9741 [00:00<00:14, 665.05it/s]  5%|████                                                                                | 466/9741 [00:00<00:13, 668.19it/s]  5%|████▌                                                                               | 533/9741 [00:00<00:13, 668.69it/s]  6%|█████▏                                                                              | 600/9741 [00:00<00:13, 656.75it/s]  7%|█████▊                                                                              | 667/9741 [00:01<00:13, 659.53it/s]  8%|██████▎                                                                             | 735/9741 [00:01<00:13, 663.05it/s]  8%|██████▉                                                                             | 803/9741 [00:01<00:13, 665.85it/s]  9%|███████▌                                                                            | 870/9741 [00:01<00:13, 667.05it/s] 10%|████████                                                                            | 938/9741 [00:01<00:13, 669.55it/s] 10%|████████▌                                                                          | 1006/9741 [00:01<00:13, 671.32it/s] 11%|█████████▏                                                                         | 1074/9741 [00:01<00:12, 673.47it/s] 12%|█████████▋                                                                         | 1142/9741 [00:01<00:12, 672.65it/s] 13%|██████████▍                                                                        | 1228/9741 [00:01<00:11, 728.55it/s] 14%|███████████▎                                                                       | 1327/9741 [00:01<00:10, 806.08it/s] 15%|████████████▏                                                                      | 1428/9741 [00:02<00:09, 865.69it/s] 16%|█████████████                                                                      | 1529/9741 [00:02<00:09, 907.58it/s] 17%|█████████████▉                                                                     | 1630/9741 [00:02<00:08, 936.15it/s] 18%|██████████████▋                                                                    | 1731/9741 [00:02<00:08, 957.22it/s] 19%|███████████████▌                                                                   | 1827/9741 [00:02<00:08, 950.05it/s] 20%|████████████████▍                                                                  | 1927/9741 [00:02<00:08, 963.71it/s] 21%|█████████████████▎                                                                 | 2026/9741 [00:02<00:07, 970.48it/s] 22%|██████████████████                                                                 | 2126/9741 [00:02<00:07, 976.65it/s] 23%|██████████████████▉                                                                | 2226/9741 [00:02<00:07, 981.13it/s] 24%|███████████████████▊                                                               | 2326/9741 [00:02<00:07, 985.27it/s] 25%|████████████████████▋                                                              | 2426/9741 [00:03<00:07, 986.89it/s] 26%|█████████████████████▌                                                             | 2525/9741 [00:03<00:07, 970.86it/s] 27%|██████████████████████▎                                                            | 2624/9741 [00:03<00:07, 974.13it/s] 28%|███████████████████████▏                                                           | 2723/9741 [00:03<00:07, 975.90it/s] 29%|████████████████████████                                                           | 2822/9741 [00:03<00:07, 978.32it/s] 30%|████████████████████████▉                                                          | 2920/9741 [00:03<00:06, 978.09it/s] 31%|█████████████████████████▋                                                         | 3019/9741 [00:03<00:06, 981.20it/s] 32%|██████████████████████████▌                                                        | 3118/9741 [00:03<00:06, 982.71it/s] 33%|███████████████████████████▍                                                       | 3217/9741 [00:03<00:06, 983.35it/s] 34%|████████████████████████████▎                                                      | 3316/9741 [00:03<00:06, 983.06it/s] 35%|█████████████████████████████                                                      | 3415/9741 [00:04<00:06, 981.11it/s] 36%|█████████████████████████████▉                                                     | 3514/9741 [00:04<00:06, 980.14it/s] 37%|██████████████████████████████▊                                                    | 3613/9741 [00:04<00:06, 978.46it/s] 38%|███████████████████████████████▌                                                   | 3711/9741 [00:04<00:06, 973.66it/s] 39%|████████████████████████████████▍                                                  | 3809/9741 [00:04<00:06, 970.63it/s] 40%|█████████████████████████████████▎                                                 | 3907/9741 [00:04<00:05, 973.32it/s] 41%|██████████████████████████████████▏                                                | 4005/9741 [00:04<00:05, 974.26it/s] 42%|██████████████████████████████████▉                                                | 4103/9741 [00:04<00:05, 972.88it/s] 43%|███████████████████████████████████▊                                               | 4201/9741 [00:04<00:05, 962.55it/s] 44%|████████████████████████████████████▌                                              | 4298/9741 [00:04<00:05, 962.96it/s] 45%|█████████████████████████████████████▍                                             | 4395/9741 [00:05<00:05, 962.68it/s] 46%|██████████████████████████████████████▎                                            | 4492/9741 [00:05<00:05, 924.13it/s] 47%|███████████████████████████████████████                                            | 4590/9741 [00:05<00:05, 938.33it/s] 48%|███████████████████████████████████████▉                                           | 4688/9741 [00:05<00:05, 949.27it/s] 49%|████████████████████████████████████████▊                                          | 4784/9741 [00:05<00:06, 787.27it/s] 50%|█████████████████████████████████████████▌                                         | 4881/9741 [00:05<00:05, 833.90it/s] 51%|██████████████████████████████████████████▍                                        | 4978/9741 [00:05<00:05, 868.69it/s] 52%|███████████████████████████████████████████▎                                       | 5076/9741 [00:05<00:05, 897.05it/s] 53%|████████████████████████████████████████████                                       | 5173/9741 [00:05<00:04, 915.87it/s] 54%|████████████████████████████████████████████▉                                      | 5270/9741 [00:06<00:04, 930.76it/s] 55%|█████████████████████████████████████████████▋                                     | 5367/9741 [00:06<00:04, 940.25it/s] 56%|██████████████████████████████████████████████▌                                    | 5464/9741 [00:06<00:04, 947.22it/s] 57%|███████████████████████████████████████████████▍                                   | 5561/9741 [00:06<00:04, 952.58it/s] 58%|████████████████████████████████████████████████▏                                  | 5657/9741 [00:06<00:04, 952.98it/s] 59%|█████████████████████████████████████████████████                                  | 5753/9741 [00:06<00:04, 953.95it/s] 60%|█████████████████████████████████████████████████▊                                 | 5849/9741 [00:06<00:04, 954.17it/s] 61%|██████████████████████████████████████████████████▋                                | 5946/9741 [00:06<00:03, 957.53it/s] 62%|███████████████████████████████████████████████████▍                               | 6043/9741 [00:06<00:03, 960.30it/s] 63%|████████████████████████████████████████████████████▎                              | 6140/9741 [00:06<00:03, 959.94it/s] 64%|█████████████████████████████████████████████████████▏                             | 6237/9741 [00:07<00:03, 958.69it/s] 65%|█████████████████████████████████████████████████████▉                             | 6333/9741 [00:07<00:03, 956.10it/s] 66%|██████████████████████████████████████████████████████▊                            | 6429/9741 [00:07<00:03, 957.07it/s] 67%|███████████████████████████████████████████████████████▌                           | 6525/9741 [00:07<00:03, 956.06it/s] 68%|████████████████████████████████████████████████████████▍                          | 6621/9741 [00:07<00:03, 956.90it/s] 69%|█████████████████████████████████████████████████████████▏                         | 6717/9741 [00:07<00:03, 957.62it/s] 70%|██████████████████████████████████████████████████████████                         | 6813/9741 [00:07<00:03, 957.28it/s] 71%|██████████████████████████████████████████████████████████▉                        | 6910/9741 [00:07<00:02, 958.53it/s] 72%|███████████████████████████████████████████████████████████▋                       | 7006/9741 [00:07<00:02, 956.16it/s] 73%|████████████████████████████████████████████████████████████▌                      | 7102/9741 [00:07<00:02, 957.04it/s] 74%|█████████████████████████████████████████████████████████████▎                     | 7198/9741 [00:08<00:02, 956.67it/s] 75%|██████████████████████████████████████████████████████████████▏                    | 7295/9741 [00:08<00:02, 957.59it/s] 76%|██████████████████████████████████████████████████████████████▉                    | 7391/9741 [00:08<00:02, 958.22it/s] 77%|███████████████████████████████████████████████████████████████▊                   | 7487/9741 [00:08<00:02, 929.73it/s] 78%|████████████████████████████████████████████████████████████████▌                  | 7582/9741 [00:08<00:02, 935.15it/s] 79%|█████████████████████████████████████████████████████████████████▍                 | 7677/9741 [00:08<00:02, 938.28it/s] 80%|██████████████████████████████████████████████████████████████████▏                | 7773/9741 [00:08<00:02, 943.27it/s] 81%|███████████████████████████████████████████████████████████████████                | 7868/9741 [00:08<00:02, 927.25it/s] 82%|███████████████████████████████████████████████████████████████████▊               | 7964/9741 [00:08<00:01, 935.39it/s] 83%|████████████████████████████████████████████████████████████████████▋              | 8060/9741 [00:08<00:01, 940.61it/s] 84%|█████████████████████████████████████████████████████████████████████▍             | 8155/9741 [00:09<00:01, 942.50it/s] 85%|██████████████████████████████████████████████████████████████████████▎            | 8251/9741 [00:09<00:01, 946.04it/s] 86%|███████████████████████████████████████████████████████████████████████            | 8346/9741 [00:09<00:01, 945.97it/s] 87%|███████████████████████████████████████████████████████████████████████▉           | 8442/9741 [00:09<00:01, 947.27it/s] 88%|████████████████████████████████████████████████████████████████████████▋          | 8537/9741 [00:09<00:01, 946.68it/s] 89%|█████████████████████████████████████████████████████████████████████████▌         | 8632/9741 [00:09<00:01, 945.87it/s] 90%|██████████████████████████████████████████████████████████████████████████▎        | 8727/9741 [00:09<00:01, 946.18it/s] 91%|███████████████████████████████████████████████████████████████████████████▏       | 8822/9741 [00:09<00:00, 944.83it/s] 92%|███████████████████████████████████████████████████████████████████████████▉       | 8917/9741 [00:09<00:00, 946.02it/s] 93%|████████████████████████████████████████████████████████████████████████████▊      | 9012/9741 [00:09<00:00, 944.93it/s] 93%|█████████████████████████████████████████████████████████████████████████████▌     | 9107/9741 [00:10<00:00, 945.26it/s] 94%|██████████████████████████████████████████████████████████████████████████████▍    | 9202/9741 [00:10<00:00, 946.10it/s] 95%|███████████████████████████████████████████████████████████████████████████████▏   | 9297/9741 [00:10<00:00, 944.93it/s] 96%|████████████████████████████████████████████████████████████████████████████████   | 9392/9741 [00:10<00:00, 946.01it/s] 97%|████████████████████████████████████████████████████████████████████████████████▊  | 9487/9741 [00:10<00:00, 945.15it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▋ | 9582/9741 [00:10<00:00, 944.12it/s] 99%|██████████████████████████████████████████████████████████████████████████████████▍| 9677/9741 [00:10<00:00, 941.03it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:10<00:00, 905.89it/s]
Load End
Num instances: 1000
[2023-08-22 04:18:15,746] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 04:18:18,747] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 04:18:18,748] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 04:18:18,748] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 04:18:18,748] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 04:18:18,748] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 04:18:18,748] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 04:18:18,748] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 04:18:18,748] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 04:18:18,748] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 04:18:18,748] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 04:18:18,748] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 04:18:18,748] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f2405361a60>
[2023-08-22 04:18:18,748] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 04:18:18,748] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 04:18:18,748] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 04:18:18,748] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 04:18:18,748] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 04:18:18,748] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 04:18:18,748] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 04:18:18,748] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 04:18:18,748] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 04:18:18,748] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f2405361940>
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 04:18:18,749] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 04:18:18,749] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.47077393531799316 seconds
Loading extension module utils...
Time to load utils op: 0.5048332214355469 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: 6

Input: Mark has kangaroos and goats.  Kangaroos have two legs and goats have four legs.  If he has 23 kangaroos and three times as many goats as kangaroos what is the total number of legs of all his animals?
Output: 322

Input: Josh’s mom gives him $20 to go shopping at the mall. He buys a hat for $10 and a pencil for $2. Then he buys four cookies. If each cookie costs $1.25, how much money does Josh have left?
Output: 3

Input: George's bowling team is one round away from breaking the league record for most points scored in a season. The old record is an average score per player of 287 per round. Each team has 4 players and there are 10 rounds in the season. Through the first 9 rounds, his team has scored a total of 10,440. How many points less than the current league record per game average is the minimum average they need to score, per player, in the final round to tie the league record?
Output: 27

Input: Max was doing homework in three different subjects. It took him 20 minutes to finish tasks from biology and two times more time to finish history. Geography took him the most time, three times more than history. How much time did Max spend on doing his homework?
Output: 180

Input: Sophia ate 1/6 of her pie and she put the rest on the fridge. If the pie left in the fridge weighs 1200 grams, how many grams did Sophia eat?
Output: 240

Input: Sarah, Mary, and Tuan decided to go to the restaurant for a meal. They decided to split the cost of the meal evenly. If the total price of the meal comes to $67 and they have a coupon for $4, how much does each person need to contribute to the bill?
Output: 21

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o8-tgsm8k-s1-rFalse
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:48<39:25, 48.27s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:37<38:58, 48.72s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:26<38:13, 48.81s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:14<37:07, 48.42s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [04:02<36:25, 48.57s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [04:50<35:20, 48.19s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [05:39<34:43, 48.45s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [06:27<33:48, 48.29s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [07:15<32:54, 48.16s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [08:05<32:35, 48.89s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [08:53<31:37, 48.66s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [09:40<30:27, 48.10s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [10:28<29:37, 48.04s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [11:16<28:46, 47.96s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [12:04<28:00, 48.02s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [12:51<27:04, 47.78s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [13:39<26:12, 47.66s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [14:26<25:26, 47.71s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [15:15<24:44, 47.88s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [16:02<23:49, 47.66s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [16:49<23:01, 47.63s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [17:37<22:13, 47.63s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [18:25<21:29, 47.77s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [19:13<20:46, 47.94s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [20:03<20:08, 48.33s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [20:53<19:34, 48.92s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [21:40<18:32, 48.35s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [22:28<17:38, 48.12s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [23:17<16:56, 48.41s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [24:05<16:10, 48.50s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [24:54<15:20, 48.43s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [25:42<14:30, 48.38s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [26:29<13:36, 48.04s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [27:18<12:52, 48.27s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [28:07<12:05, 48.37s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [28:56<11:19, 48.54s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [29:47<10:40, 49.30s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [30:35<09:48, 49.03s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [31:22<08:54, 48.55s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [32:12<08:08, 48.87s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [33:00<07:16, 48.46s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [33:47<06:25, 48.23s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [34:35<05:36, 48.04s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [35:24<04:50, 48.37s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [36:11<03:59, 47.96s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [37:00<03:12, 48.14s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [37:47<02:23, 47.96s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [38:36<01:36, 48.32s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [39:25<00:48, 48.37s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [40:13<00:00, 48.46s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [40:13<00:00, 48.28s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 0.5803} | avg. gen lenth: 402.914
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o9-tgsm8k-s1-rFalse --seed 1 --max-prompt-length 2048 --num-out-domain 9
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 04:58:42,598] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o9-tgsm8k-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 9
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o9-tgsm8k-s1-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|▌                                                                                    | 60/9741 [00:00<00:16, 592.97it/s]  1%|█                                                                                   | 123/9741 [00:00<00:15, 611.48it/s]  2%|█▌                                                                                  | 185/9741 [00:00<00:16, 572.34it/s]  3%|██▏                                                                                 | 249/9741 [00:00<00:15, 595.00it/s]  3%|██▋                                                                                 | 313/9741 [00:00<00:15, 609.54it/s]  4%|███▎                                                                                | 377/9741 [00:00<00:15, 619.12it/s]  5%|███▊                                                                                | 441/9741 [00:00<00:14, 623.39it/s]  5%|████▎                                                                               | 505/9741 [00:00<00:14, 627.95it/s]  6%|████▉                                                                               | 568/9741 [00:00<00:15, 599.81it/s]  6%|█████▍                                                                              | 631/9741 [00:01<00:15, 605.93it/s]  7%|█████▉                                                                              | 695/9741 [00:01<00:14, 613.19it/s]  8%|██████▌                                                                             | 758/9741 [00:01<00:14, 616.19it/s]  8%|███████                                                                             | 822/9741 [00:01<00:14, 621.48it/s]  9%|███████▋                                                                            | 885/9741 [00:01<00:14, 622.88it/s] 10%|████████▏                                                                           | 948/9741 [00:01<00:14, 624.77it/s] 10%|████████▌                                                                          | 1012/9741 [00:01<00:13, 627.08it/s] 11%|█████████▏                                                                         | 1076/9741 [00:01<00:13, 629.14it/s] 12%|█████████▋                                                                         | 1139/9741 [00:01<00:13, 626.54it/s] 12%|██████████▏                                                                        | 1202/9741 [00:01<00:13, 627.33it/s] 13%|██████████▊                                                                        | 1265/9741 [00:02<00:13, 626.46it/s] 14%|███████████▎                                                                       | 1328/9741 [00:02<00:13, 626.88it/s] 14%|███████████▊                                                                       | 1391/9741 [00:02<00:13, 626.65it/s] 15%|████████████▍                                                                      | 1455/9741 [00:02<00:13, 627.79it/s] 16%|████████████▉                                                                      | 1518/9741 [00:02<00:13, 628.26it/s] 16%|█████████████▍                                                                     | 1581/9741 [00:02<00:12, 627.75it/s] 17%|██████████████                                                                     | 1645/9741 [00:02<00:12, 629.41it/s] 18%|██████████████▌                                                                    | 1709/9741 [00:02<00:12, 630.04it/s] 18%|███████████████▎                                                                   | 1796/9741 [00:02<00:11, 699.40it/s] 19%|████████████████                                                                   | 1890/9741 [00:02<00:10, 770.30it/s] 20%|████████████████▉                                                                  | 1983/9741 [00:03<00:09, 816.23it/s] 21%|█████████████████▋                                                                 | 2072/9741 [00:03<00:09, 836.80it/s] 22%|██████████████████▍                                                                | 2165/9741 [00:03<00:08, 863.34it/s] 23%|███████████████████▏                                                               | 2258/9741 [00:03<00:08, 882.34it/s] 24%|████████████████████                                                               | 2352/9741 [00:03<00:08, 896.79it/s] 25%|████████████████████▊                                                              | 2445/9741 [00:03<00:08, 905.29it/s] 26%|█████████████████████▋                                                             | 2539/9741 [00:03<00:07, 913.65it/s] 27%|██████████████████████▍                                                            | 2633/9741 [00:03<00:07, 919.76it/s] 28%|███████████████████████▏                                                           | 2726/9741 [00:03<00:07, 920.87it/s] 29%|████████████████████████                                                           | 2819/9741 [00:03<00:07, 921.54it/s] 30%|████████████████████████▊                                                          | 2912/9741 [00:04<00:07, 922.19it/s] 31%|█████████████████████████▌                                                         | 3006/9741 [00:04<00:07, 925.69it/s] 32%|██████████████████████████▍                                                        | 3099/9741 [00:04<00:07, 925.54it/s] 33%|███████████████████████████▏                                                       | 3192/9741 [00:04<00:07, 924.76it/s] 34%|███████████████████████████▉                                                       | 3285/9741 [00:04<00:06, 922.45it/s] 35%|████████████████████████████▊                                                      | 3378/9741 [00:04<00:06, 921.20it/s] 36%|█████████████████████████████▌                                                     | 3471/9741 [00:04<00:06, 921.43it/s] 37%|██████████████████████████████▎                                                    | 3564/9741 [00:04<00:06, 921.08it/s] 38%|███████████████████████████████▏                                                   | 3657/9741 [00:04<00:06, 917.92it/s] 38%|███████████████████████████████▉                                                   | 3750/9741 [00:04<00:06, 918.58it/s] 39%|████████████████████████████████▋                                                  | 3842/9741 [00:05<00:06, 914.96it/s] 40%|█████████████████████████████████▌                                                 | 3934/9741 [00:05<00:06, 916.03it/s] 41%|██████████████████████████████████▎                                                | 4027/9741 [00:05<00:06, 917.38it/s] 42%|███████████████████████████████████                                                | 4119/9741 [00:05<00:06, 914.06it/s] 43%|███████████████████████████████████▉                                               | 4211/9741 [00:05<00:06, 913.93it/s] 44%|████████████████████████████████████▋                                              | 4303/9741 [00:05<00:05, 911.92it/s] 45%|█████████████████████████████████████▍                                             | 4395/9741 [00:05<00:05, 912.18it/s] 46%|██████████████████████████████████████▏                                            | 4487/9741 [00:05<00:05, 886.22it/s] 47%|███████████████████████████████████████                                            | 4578/9741 [00:05<00:05, 892.99it/s] 48%|███████████████████████████████████████▊                                           | 4670/9741 [00:05<00:05, 898.50it/s] 49%|████████████████████████████████████████▌                                          | 4760/9741 [00:06<00:06, 722.47it/s] 50%|█████████████████████████████████████████▎                                         | 4852/9741 [00:06<00:06, 770.60it/s] 51%|██████████████████████████████████████████                                         | 4943/9741 [00:06<00:05, 807.02it/s] 52%|██████████████████████████████████████████▉                                        | 5035/9741 [00:06<00:05, 836.29it/s] 53%|███████████████████████████████████████████▋                                       | 5122/9741 [00:06<00:05, 841.48it/s] 53%|████████████████████████████████████████████▍                                      | 5211/9741 [00:06<00:05, 855.32it/s] 54%|█████████████████████████████████████████████▏                                     | 5301/9741 [00:06<00:05, 868.05it/s] 55%|█████████████████████████████████████████████▉                                     | 5391/9741 [00:06<00:04, 876.81it/s] 56%|██████████████████████████████████████████████▋                                    | 5483/9741 [00:06<00:04, 886.77it/s] 57%|███████████████████████████████████████████████▌                                   | 5575/9741 [00:07<00:04, 893.92it/s] 58%|████████████████████████████████████████████████▎                                  | 5665/9741 [00:07<00:04, 895.04it/s] 59%|█████████████████████████████████████████████████                                  | 5756/9741 [00:07<00:04, 898.27it/s] 60%|█████████████████████████████████████████████████▊                                 | 5847/9741 [00:07<00:04, 897.02it/s] 61%|██████████████████████████████████████████████████▌                                | 5938/9741 [00:07<00:04, 898.27it/s] 62%|███████████████████████████████████████████████████▎                               | 6029/9741 [00:07<00:04, 900.86it/s] 63%|████████████████████████████████████████████████████▏                              | 6120/9741 [00:07<00:04, 900.84it/s] 64%|████████████████████████████████████████████████████▉                              | 6211/9741 [00:07<00:03, 899.87it/s] 65%|█████████████████████████████████████████████████████▋                             | 6302/9741 [00:07<00:03, 897.70it/s] 66%|██████████████████████████████████████████████████████▍                            | 6392/9741 [00:07<00:03, 898.34it/s] 67%|███████████████████████████████████████████████████████▏                           | 6482/9741 [00:08<00:03, 898.65it/s] 67%|███████████████████████████████████████████████████████▉                           | 6572/9741 [00:08<00:03, 895.55it/s] 68%|████████████████████████████████████████████████████████▊                          | 6662/9741 [00:08<00:03, 893.50it/s] 69%|█████████████████████████████████████████████████████████▌                         | 6752/9741 [00:08<00:03, 894.42it/s] 70%|██████████████████████████████████████████████████████████▎                        | 6842/9741 [00:08<00:03, 894.82it/s] 71%|███████████████████████████████████████████████████████████                        | 6932/9741 [00:08<00:03, 895.65it/s] 72%|███████████████████████████████████████████████████████████▊                       | 7022/9741 [00:08<00:03, 894.71it/s] 73%|████████████████████████████████████████████████████████████▌                      | 7112/9741 [00:08<00:02, 896.27it/s] 74%|█████████████████████████████████████████████████████████████▎                     | 7202/9741 [00:08<00:02, 894.35it/s] 75%|██████████████████████████████████████████████████████████████▏                    | 7292/9741 [00:08<00:02, 895.18it/s] 76%|██████████████████████████████████████████████████████████████▉                    | 7382/9741 [00:09<00:02, 895.53it/s] 77%|███████████████████████████████████████████████████████████████▋                   | 7472/9741 [00:09<00:02, 867.46it/s] 78%|████████████████████████████████████████████████████████████████▍                  | 7562/9741 [00:09<00:02, 875.13it/s] 79%|█████████████████████████████████████████████████████████████████▏                 | 7651/9741 [00:09<00:02, 878.45it/s] 79%|█████████████████████████████████████████████████████████████████▉                 | 7741/9741 [00:09<00:02, 884.26it/s] 80%|██████████████████████████████████████████████████████████████████▋                | 7831/9741 [00:09<00:02, 887.15it/s] 81%|███████████████████████████████████████████████████████████████████▍               | 7920/9741 [00:09<00:02, 885.45it/s] 82%|████████████████████████████████████████████████████████████████████▏              | 8009/9741 [00:09<00:01, 886.38it/s] 83%|█████████████████████████████████████████████████████████████████████              | 8098/9741 [00:09<00:01, 887.09it/s] 84%|█████████████████████████████████████████████████████████████████████▊             | 8187/9741 [00:10<00:01, 886.34it/s] 85%|██████████████████████████████████████████████████████████████████████▌            | 8277/9741 [00:10<00:01, 888.07it/s] 86%|███████████████████████████████████████████████████████████████████████▎           | 8366/9741 [00:10<00:01, 887.99it/s] 87%|████████████████████████████████████████████████████████████████████████           | 8455/9741 [00:10<00:01, 888.37it/s] 88%|████████████████████████████████████████████████████████████████████████▊          | 8544/9741 [00:10<00:01, 886.42it/s] 89%|█████████████████████████████████████████████████████████████████████████▌         | 8633/9741 [00:10<00:01, 886.50it/s] 90%|██████████████████████████████████████████████████████████████████████████▎        | 8722/9741 [00:10<00:01, 887.46it/s] 90%|███████████████████████████████████████████████████████████████████████████        | 8811/9741 [00:10<00:01, 885.64it/s] 91%|███████████████████████████████████████████████████████████████████████████▊       | 8900/9741 [00:10<00:00, 886.78it/s] 92%|████████████████████████████████████████████████████████████████████████████▌      | 8989/9741 [00:10<00:00, 887.67it/s] 93%|█████████████████████████████████████████████████████████████████████████████▎     | 9078/9741 [00:11<00:00, 885.52it/s] 94%|██████████████████████████████████████████████████████████████████████████████     | 9167/9741 [00:11<00:00, 885.63it/s] 95%|██████████████████████████████████████████████████████████████████████████████▊    | 9256/9741 [00:11<00:00, 883.67it/s] 96%|███████████████████████████████████████████████████████████████████████████████▋   | 9345/9741 [00:11<00:00, 884.42it/s] 97%|████████████████████████████████████████████████████████████████████████████████▍  | 9434/9741 [00:11<00:00, 883.57it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▏ | 9523/9741 [00:11<00:00, 880.16it/s] 99%|█████████████████████████████████████████████████████████████████████████████████▉ | 9612/9741 [00:11<00:00, 880.43it/s]100%|██████████████████████████████████████████████████████████████████████████████████▋| 9701/9741 [00:11<00:00, 878.82it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:11<00:00, 827.75it/s]
Load End
Num instances: 1000
[2023-08-22 04:59:05,668] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 04:59:08,458] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 04:59:08,458] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 04:59:08,458] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 04:59:08,458] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 04:59:08,458] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f3c9ad83a60>
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f3c9ad83940>
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 04:59:08,459] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 04:59:08,460] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 04:59:08,460] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 04:59:08,460] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 04:59:08,460] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 04:59:08,460] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 04:59:08,460] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 04:59:08,460] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 04:59:08,460] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 04:59:08,460] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 04:59:08,460] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 04:59:08,460] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 04:59:08,460] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 04:59:08,460] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 04:59:08,460] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 04:59:08,460] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 04:59:08,460] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 04:59:08,460] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 04:59:08,460] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 04:59:08,460] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 04:59:08,460] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 04:59:08,460] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4787135124206543 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: 6

Input: Mark has kangaroos and goats.  Kangaroos have two legs and goats have four legs.  If he has 23 kangaroos and three times as many goats as kangaroos what is the total number of legs of all his animals?
Output: 322

Input: Josh’s mom gives him $20 to go shopping at the mall. He buys a hat for $10 and a pencil for $2. Then he buys four cookies. If each cookie costs $1.25, how much money does Josh have left?
Output: 3

Input: George's bowling team is one round away from breaking the league record for most points scored in a season. The old record is an average score per player of 287 per round. Each team has 4 players and there are 10 rounds in the season. Through the first 9 rounds, his team has scored a total of 10,440. How many points less than the current league record per game average is the minimum average they need to score, per player, in the final round to tie the league record?
Output: 27

Input: Max was doing homework in three different subjects. It took him 20 minutes to finish tasks from biology and two times more time to finish history. Geography took him the most time, three times more than history. How much time did Max spend on doing his homework?
Output: 180

Input: Sophia ate 1/6 of her pie and she put the rest on the fridge. If the pie left in the fridge weighs 1200 grams, how many grams did Sophia eat?
Output: 240

Input: Sarah, Mary, and Tuan decided to go to the restaurant for a meal. They decided to split the cost of the meal evenly. If the total price of the meal comes to $67 and they have a coupon for $4, how much does each person need to contribute to the bill?
Output: 21

Input: Tom's brother is 4 times as old as Tom's dog. If in 6 years, Tom's brother will be 30 years, how old is Tom's dog going to be in six years?
Output: 12

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o9-tgsm8k-s1-rFalse
Loading extension module utils...
Time to load utils op: 0.40453624725341797 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:47<38:33, 47.21s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:33<37:22, 46.73s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:21<37:04, 47.33s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:07<35:55, 46.87s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [03:55<35:19, 47.09s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [04:41<34:15, 46.71s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [05:28<33:30, 46.75s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [06:15<32:50, 46.92s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [07:02<32:06, 46.98s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [07:51<31:41, 47.54s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [08:37<30:39, 47.16s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [09:23<29:42, 46.90s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [10:11<29:04, 47.14s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [10:58<28:16, 47.13s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [11:44<27:17, 46.77s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [12:30<26:22, 46.54s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [13:17<25:35, 46.54s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [14:03<24:46, 46.46s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [14:50<24:05, 46.62s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [15:36<23:17, 46.60s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [16:23<22:30, 46.57s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [17:10<21:49, 46.77s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [17:56<20:54, 46.45s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [18:43<20:11, 46.58s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [19:30<19:29, 46.79s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [20:17<18:41, 46.73s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [21:03<17:55, 46.75s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [21:50<17:04, 46.56s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [22:37<16:20, 46.71s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [23:25<15:44, 47.22s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [24:12<14:57, 47.25s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [24:59<14:09, 47.19s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [25:46<13:18, 47.00s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [26:33<12:32, 47.04s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [27:21<11:47, 47.20s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [28:07<10:58, 47.07s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [28:54<10:10, 46.97s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [29:41<09:23, 46.94s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [30:28<08:35, 46.87s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [31:18<07:59, 47.91s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [32:06<07:11, 47.96s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [32:54<06:22, 47.79s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [33:40<05:31, 47.33s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [34:28<04:46, 47.70s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [35:15<03:57, 47.48s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [36:03<03:09, 47.41s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [36:50<02:21, 47.30s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [37:37<01:34, 47.46s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [38:25<00:47, 47.46s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [39:13<00:00, 47.50s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [39:13<00:00, 47.06s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 0.6921} | avg. gen lenth: 407.616
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s10-rTrue --seed 10 --max-prompt-length 2048 --rationales --num-out-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 05:39:06,589] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 1
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o1-tgsm8k-s10-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  3%|██▎                                                                                | 271/9741 [00:00<00:03, 2702.28it/s]  6%|█████                                                                              | 591/9741 [00:00<00:03, 2991.01it/s]  9%|███████▊                                                                           | 914/9741 [00:00<00:02, 3096.78it/s] 13%|██████████▍                                                                       | 1236/9741 [00:00<00:02, 3142.80it/s] 16%|█████████████▏                                                                    | 1561/9741 [00:00<00:02, 3179.01it/s] 19%|███████████████▊                                                                  | 1880/9741 [00:00<00:02, 3182.34it/s] 23%|██████████████████▌                                                               | 2205/9741 [00:00<00:02, 3201.91it/s] 26%|█████████████████████▎                                                            | 2526/9741 [00:00<00:02, 3201.33it/s] 29%|███████████████████████▉                                                          | 2847/9741 [00:00<00:02, 3108.89it/s] 32%|██████████████████████████▌                                                       | 3159/9741 [00:01<00:02, 3104.69it/s] 36%|█████████████████████████████▏                                                    | 3472/9741 [00:01<00:02, 3110.83it/s] 39%|███████████████████████████████▉                                                  | 3788/9741 [00:01<00:01, 3123.63it/s] 42%|██████████████████████████████████▌                                               | 4109/9741 [00:01<00:01, 3148.50it/s] 46%|█████████████████████████████████████▎                                            | 4439/9741 [00:01<00:01, 3192.21it/s] 49%|████████████████████████████████████████                                          | 4759/9741 [00:01<00:02, 2453.73it/s] 52%|██████████████████████████████████████████▊                                       | 5087/9741 [00:01<00:01, 2657.97it/s] 56%|█████████████████████████████████████████████▌                                    | 5413/9741 [00:01<00:01, 2815.06it/s] 59%|████████████████████████████████████████████████▎                                 | 5735/9741 [00:01<00:01, 2923.75it/s] 62%|███████████████████████████████████████████████████                               | 6064/9741 [00:02<00:01, 3024.33it/s] 66%|█████████████████████████████████████████████████████▊                            | 6394/9741 [00:02<00:01, 3100.70it/s] 69%|████████████████████████████████████████████████████████▌                         | 6723/9741 [00:02<00:00, 3153.58it/s] 72%|███████████████████████████████████████████████████████████▍                      | 7055/9741 [00:02<00:00, 3199.87it/s] 76%|██████████████████████████████████████████████████████████████▏                   | 7388/9741 [00:02<00:00, 3236.52it/s] 79%|████████████████████████████████████████████████████████████████▉                 | 7715/9741 [00:02<00:00, 3219.69it/s] 83%|███████████████████████████████████████████████████████████████████▋              | 8046/9741 [00:02<00:00, 3245.89it/s] 86%|██████████████████████████████████████████████████████████████████████▌           | 8377/9741 [00:02<00:00, 3264.45it/s] 89%|█████████████████████████████████████████████████████████████████████████▎        | 8708/9741 [00:02<00:00, 3276.34it/s] 93%|████████████████████████████████████████████████████████████████████████████      | 9037/9741 [00:02<00:00, 3263.28it/s] 96%|██████████████████████████████████████████████████████████████████████████████▉   | 9372/9741 [00:03<00:00, 3286.24it/s]100%|█████████████████████████████████████████████████████████████████████████████████▋| 9704/9741 [00:03<00:00, 3293.82it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:03<00:00, 3110.24it/s]
Load End
Num instances: 1000
[2023-08-22 05:39:21,059] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 05:39:24,027] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 05:39:24,027] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 05:39:24,028] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 05:39:24,028] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 05:39:24,028] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 05:39:24,028] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 05:39:24,028] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 05:39:24,028] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 05:39:24,028] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 05:39:24,028] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 05:39:24,028] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 05:39:24,028] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f3992b81a60>
[2023-08-22 05:39:24,028] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 05:39:24,028] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 05:39:24,028] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 05:39:24,028] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 05:39:24,028] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 05:39:24,028] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 05:39:24,028] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 05:39:24,028] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 05:39:24,028] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 05:39:24,028] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 05:39:24,028] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 05:39:24,028] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 05:39:24,028] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 05:39:24,028] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 05:39:24,028] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 05:39:24,028] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f3992b81940>
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 05:39:24,029] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 05:39:24,029] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.44471096992492676 seconds
Loading extension module utils...
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Time to load utils op: 0.30441737174987793 seconds
Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: For the nuts Adam paid 3 * $12 = $<<3*12=36>>36.
And for dried fruits Adam paid 2.5 * $8 = $<<2.5*8=20>>20.
So in total for his purchases Adam paid $36 + $20 = $<<36+20=56>>56.
So the final answer is 56

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o1-tgsm8k-s10-rTrue
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [01:04<52:25, 64.20s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [02:06<50:18, 62.89s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [03:09<49:32, 63.25s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [04:12<48:18, 63.01s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [05:13<46:41, 62.26s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [06:16<45:57, 62.68s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [07:20<45:05, 62.92s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [08:23<44:04, 62.96s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [09:28<43:29, 63.64s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [10:30<42:05, 63.14s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [11:35<41:19, 63.58s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [12:35<39:36, 62.54s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [13:37<38:33, 62.53s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [14:40<37:34, 62.61s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [15:42<36:29, 62.55s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [16:45<35:24, 62.49s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [17:49<34:38, 63.00s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [18:52<33:31, 62.85s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [19:55<32:37, 63.14s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [20:56<31:10, 62.34s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [21:58<30:10, 62.42s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [23:04<29:33, 63.34s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [24:08<28:32, 63.43s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [25:11<27:31, 63.51s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [26:13<26:11, 62.86s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [27:15<25:08, 62.87s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [28:18<24:03, 62.76s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [29:22<23:12, 63.28s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [30:27<22:16, 63.62s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [31:30<21:08, 63.40s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [32:34<20:07, 63.58s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [33:37<19:04, 63.57s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [34:42<18:04, 63.82s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [35:45<16:58, 63.67s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [36:49<15:56, 63.74s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [37:54<14:58, 64.19s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [38:58<13:52, 64.04s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [40:01<12:45, 63.76s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [41:05<11:42, 63.83s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [42:08<10:37, 63.73s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [43:13<09:35, 63.94s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [44:17<08:32, 64.06s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [45:21<07:27, 63.91s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [46:25<06:23, 63.93s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [47:29<05:19, 63.99s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [48:33<04:16, 64.17s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [49:37<03:11, 63.95s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [50:43<02:09, 64.51s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [51:47<01:04, 64.50s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [52:55<00:00, 65.62s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [52:55<00:00, 63.52s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 2.2289} | avg. gen lenth: 348.78
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s10-rTrue --seed 10 --max-prompt-length 2048 --rationales --num-out-domain 2
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 06:32:51,235] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 2
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o2-tgsm8k-s10-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|█                                                                                  | 119/9741 [00:00<00:08, 1186.70it/s]  3%|██                                                                                 | 244/9741 [00:00<00:07, 1220.91it/s]  4%|███▏                                                                               | 371/9741 [00:00<00:07, 1241.83it/s]  5%|████▎                                                                              | 499/9741 [00:00<00:07, 1254.94it/s]  6%|█████▎                                                                             | 627/9741 [00:00<00:07, 1261.74it/s]  8%|██████▍                                                                            | 756/9741 [00:00<00:07, 1270.19it/s]  9%|███████▌                                                                           | 884/9741 [00:00<00:06, 1272.57it/s] 10%|████████▌                                                                         | 1013/9741 [00:00<00:06, 1277.16it/s] 12%|█████████▌                                                                        | 1141/9741 [00:00<00:06, 1252.06it/s] 13%|██████████▋                                                                       | 1268/9741 [00:01<00:06, 1254.77it/s] 14%|███████████▊                                                                      | 1396/9741 [00:01<00:06, 1259.82it/s] 16%|████████████▊                                                                     | 1524/9741 [00:01<00:06, 1263.77it/s] 17%|█████████████▉                                                                    | 1652/9741 [00:01<00:06, 1266.42it/s] 18%|██████████████▉                                                                   | 1779/9741 [00:01<00:06, 1247.35it/s] 20%|████████████████                                                                  | 1906/9741 [00:01<00:06, 1253.74it/s] 21%|█████████████████                                                                 | 2033/9741 [00:01<00:06, 1258.22it/s] 22%|██████████████████▏                                                               | 2161/9741 [00:01<00:06, 1262.49it/s] 23%|███████████████████▎                                                              | 2289/9741 [00:01<00:05, 1266.82it/s] 25%|████████████████████▎                                                             | 2416/9741 [00:01<00:05, 1266.90it/s] 26%|█████████████████████▍                                                            | 2543/9741 [00:02<00:05, 1266.17it/s] 27%|██████████████████████▍                                                           | 2671/9741 [00:02<00:05, 1268.62it/s] 29%|███████████████████████▌                                                          | 2799/9741 [00:02<00:05, 1269.64it/s] 30%|████████████████████████▋                                                         | 2929/9741 [00:02<00:05, 1278.65it/s] 32%|██████████████████████████▎                                                       | 3122/9741 [00:02<00:04, 1472.82it/s] 34%|███████████████████████████▉                                                      | 3317/9741 [00:02<00:03, 1615.52it/s] 36%|█████████████████████████████▌                                                    | 3509/9741 [00:02<00:03, 1706.01it/s] 38%|███████████████████████████████▏                                                  | 3701/9741 [00:02<00:03, 1768.92it/s] 40%|████████████████████████████████▊                                                 | 3894/9741 [00:02<00:03, 1815.38it/s] 42%|██████████████████████████████████▍                                               | 4084/9741 [00:02<00:03, 1839.82it/s] 44%|███████████████████████████████████▉                                              | 4276/9741 [00:03<00:02, 1861.90it/s] 46%|█████████████████████████████████████▌                                            | 4467/9741 [00:03<00:02, 1875.83it/s] 48%|███████████████████████████████████████▏                                          | 4655/9741 [00:03<00:02, 1829.85it/s] 50%|████████████████████████████████████████▋                                         | 4839/9741 [00:03<00:03, 1403.25it/s] 52%|██████████████████████████████████████████▎                                       | 5030/9741 [00:03<00:03, 1525.28it/s] 54%|███████████████████████████████████████████▉                                      | 5220/9741 [00:03<00:02, 1621.73it/s] 56%|█████████████████████████████████████████████▌                                    | 5410/9741 [00:03<00:02, 1695.07it/s] 58%|███████████████████████████████████████████████▏                                  | 5602/9741 [00:03<00:02, 1755.19it/s] 59%|████████████████████████████████████████████████▊                                 | 5795/9741 [00:03<00:02, 1803.50it/s] 61%|██████████████████████████████████████████████████▍                               | 5986/9741 [00:04<00:02, 1833.72it/s] 63%|███████████████████████████████████████████████████▉                              | 6177/9741 [00:04<00:01, 1855.67it/s] 65%|█████████████████████████████████████████████████████▌                            | 6368/9741 [00:04<00:01, 1869.94it/s] 67%|███████████████████████████████████████████████████████▏                          | 6558/9741 [00:04<00:01, 1878.68it/s] 69%|████████████████████████████████████████████████████████▊                         | 6748/9741 [00:04<00:01, 1876.40it/s] 71%|██████████████████████████████████████████████████████████▍                       | 6939/9741 [00:04<00:01, 1884.48it/s] 73%|████████████████████████████████████████████████████████████                      | 7129/9741 [00:04<00:01, 1882.24it/s] 75%|█████████████████████████████████████████████████████████████▌                    | 7318/9741 [00:04<00:01, 1884.16it/s] 77%|███████████████████████████████████████████████████████████████▏                  | 7507/9741 [00:04<00:01, 1857.17it/s] 79%|████████████████████████████████████████████████████████████████▊                 | 7694/9741 [00:04<00:01, 1825.71it/s] 81%|██████████████████████████████████████████████████████████████████▎               | 7884/9741 [00:05<00:01, 1844.99it/s] 83%|███████████████████████████████████████████████████████████████████▉              | 8075/9741 [00:05<00:00, 1863.99it/s] 85%|█████████████████████████████████████████████████████████████████████▌            | 8265/9741 [00:05<00:00, 1874.39it/s] 87%|███████████████████████████████████████████████████████████████████████▏          | 8454/9741 [00:05<00:00, 1877.10it/s] 89%|████████████████████████████████████████████████████████████████████████▊         | 8644/9741 [00:05<00:00, 1881.25it/s] 91%|██████████████████████████████████████████████████████████████████████████▎       | 8833/9741 [00:05<00:00, 1878.19it/s] 93%|███████████████████████████████████████████████████████████████████████████▉      | 9021/9741 [00:05<00:00, 1878.00it/s] 95%|█████████████████████████████████████████████████████████████████████████████▌    | 9211/9741 [00:05<00:00, 1882.03it/s] 97%|███████████████████████████████████████████████████████████████████████████████▏  | 9401/9741 [00:05<00:00, 1886.91it/s] 98%|████████████████████████████████████████████████████████████████████████████████▋ | 9590/9741 [00:05<00:00, 1883.61it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:06<00:00, 1614.18it/s]
Load End
Num instances: 1000
[2023-08-22 06:33:08,323] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 06:33:11,194] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 06:33:11,195] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 06:33:11,195] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 06:33:11,195] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 06:33:11,195] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 06:33:11,195] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 06:33:11,195] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 06:33:11,195] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 06:33:11,195] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 06:33:11,195] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 06:33:11,195] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 06:33:11,195] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7ff75f79ea60>
[2023-08-22 06:33:11,195] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 06:33:11,195] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 06:33:11,195] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 06:33:11,195] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 06:33:11,195] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 06:33:11,195] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 06:33:11,195] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 06:33:11,195] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 06:33:11,195] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 06:33:11,195] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 06:33:11,195] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 06:33:11,195] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 06:33:11,195] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 06:33:11,195] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7ff75f79e940>
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 06:33:11,196] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 06:33:11,196] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4344143867492676 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: For the nuts Adam paid 3 * $12 = $<<3*12=36>>36.
And for dried fruits Adam paid 2.5 * $8 = $<<2.5*8=20>>20.
So in total for his purchases Adam paid $36 + $20 = $<<36+20=56>>56.
So the final answer is 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: He spends 60/3=<<60/3=20>>20 minutes warming up
So he spends 60+20=<<60+20=80>>80 minutes at the gym per day
That means he spends 80*3=<<80*3=240>>240 minutes at the gym
So he spends 240/60=<<240/60=4>>4 hours at the gym a week
So the final answer is 4

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o2-tgsm8k-s10-rTrue
Loading extension module utils...
Time to load utils op: 0.5049986839294434 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [01:00<49:26, 60.54s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:57<46:44, 58.43s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:54<45:14, 57.75s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:52<44:30, 58.05s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [04:51<43:33, 58.07s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [05:48<42:18, 57.70s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [06:46<41:27, 57.85s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [07:43<40:25, 57.76s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [08:41<39:31, 57.84s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [09:40<38:40, 58.00s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [10:38<37:47, 58.14s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [11:34<36:28, 57.60s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [12:35<36:06, 58.54s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [13:33<34:57, 58.27s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [14:31<33:55, 58.15s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [15:27<32:37, 57.56s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [16:25<31:41, 57.63s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [17:24<30:56, 58.01s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [18:22<30:00, 58.08s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [19:20<29:00, 58.02s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [20:18<28:08, 58.24s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [21:17<27:12, 58.31s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [22:14<26:05, 57.98s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [23:11<24:56, 57.55s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [24:09<24:08, 57.93s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [25:10<23:26, 58.61s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [26:06<22:11, 57.91s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [27:04<21:18, 58.09s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [28:01<20:11, 57.68s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [28:58<19:09, 57.48s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [29:55<18:10, 57.38s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [30:54<17:21, 57.85s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [31:52<16:24, 57.93s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [32:53<15:38, 58.67s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [33:51<14:38, 58.54s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [34:52<13:48, 59.20s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [35:49<12:41, 58.61s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [36:46<11:37, 58.16s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [37:44<10:37, 57.96s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [38:43<09:43, 58.39s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [39:40<08:40, 57.88s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [40:38<07:43, 57.94s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [41:37<06:47, 58.23s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [42:34<05:47, 57.91s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [43:31<04:49, 57.82s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [44:29<03:51, 57.82s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [45:27<02:53, 57.80s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [46:27<01:56, 58.44s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [47:25<00:58, 58.41s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [48:23<00:00, 58.05s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [48:23<00:00, 58.06s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.8272} | avg. gen lenth: 383.838
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o3-tgsm8k-s10-rTrue --seed 10 --max-prompt-length 2048 --rationales --num-out-domain 3
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 07:21:45,677] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o3-tgsm8k-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 3
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o3-tgsm8k-s10-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|▊                                                                                    | 92/9741 [00:00<00:10, 918.62it/s]  2%|█▋                                                                                  | 189/9741 [00:00<00:10, 944.15it/s]  3%|██▍                                                                                 | 288/9741 [00:00<00:09, 963.39it/s]  4%|███▎                                                                                | 387/9741 [00:00<00:09, 973.63it/s]  5%|████▏                                                                               | 486/9741 [00:00<00:09, 979.43it/s]  6%|█████                                                                               | 586/9741 [00:00<00:09, 985.21it/s]  7%|█████▉                                                                              | 686/9741 [00:00<00:09, 988.73it/s]  8%|██████▊                                                                             | 787/9741 [00:00<00:09, 993.20it/s]  9%|███████▋                                                                            | 887/9741 [00:00<00:09, 972.65it/s] 10%|████████▌                                                                           | 986/9741 [00:01<00:08, 976.26it/s] 11%|█████████▏                                                                         | 1085/9741 [00:01<00:08, 980.35it/s] 12%|██████████                                                                         | 1185/9741 [00:01<00:08, 985.84it/s] 13%|██████████▉                                                                        | 1285/9741 [00:01<00:08, 988.70it/s] 14%|███████████▊                                                                       | 1384/9741 [00:01<00:08, 988.75it/s] 15%|████████████▋                                                                      | 1484/9741 [00:01<00:08, 990.12it/s] 16%|█████████████▍                                                                     | 1584/9741 [00:01<00:08, 990.64it/s] 17%|██████████████▎                                                                    | 1685/9741 [00:01<00:08, 993.81it/s] 18%|███████████████▏                                                                   | 1785/9741 [00:01<00:08, 974.44it/s] 20%|████████████████▏                                                                 | 1916/9741 [00:01<00:07, 1071.74it/s] 21%|█████████████████▍                                                                | 2066/9741 [00:02<00:06, 1197.05it/s] 23%|██████████████████▋                                                               | 2216/9741 [00:02<00:05, 1285.83it/s] 24%|███████████████████▉                                                              | 2368/9741 [00:02<00:05, 1353.58it/s] 26%|█████████████████████▏                                                            | 2519/9741 [00:02<00:05, 1398.94it/s] 27%|██████████████████████▍                                                           | 2670/9741 [00:02<00:04, 1431.04it/s] 29%|███████████████████████▋                                                          | 2820/9741 [00:02<00:04, 1451.01it/s] 30%|█████████████████████████                                                         | 2971/9741 [00:02<00:04, 1467.35it/s] 32%|██████████████████████████▎                                                       | 3122/9741 [00:02<00:04, 1477.44it/s] 34%|███████████████████████████▌                                                      | 3273/9741 [00:02<00:04, 1486.15it/s] 35%|████████████████████████████▊                                                     | 3423/9741 [00:02<00:04, 1490.00it/s] 37%|██████████████████████████████                                                    | 3573/9741 [00:03<00:04, 1489.84it/s] 38%|███████████████████████████████▎                                                  | 3723/9741 [00:03<00:04, 1487.56it/s] 40%|████████████████████████████████▌                                                 | 3872/9741 [00:03<00:03, 1471.23it/s] 41%|█████████████████████████████████▊                                                | 4021/9741 [00:03<00:03, 1474.35it/s] 43%|███████████████████████████████████                                               | 4170/9741 [00:03<00:03, 1476.63it/s] 44%|████████████████████████████████████▎                                             | 4320/9741 [00:03<00:03, 1481.82it/s] 46%|█████████████████████████████████████▋                                            | 4471/9741 [00:03<00:03, 1488.25it/s] 47%|██████████████████████████████████████▉                                           | 4620/9741 [00:03<00:03, 1441.76it/s] 49%|████████████████████████████████████████                                          | 4765/9741 [00:03<00:04, 1116.71it/s] 50%|█████████████████████████████████████████▎                                        | 4915/9741 [00:04<00:03, 1208.44it/s] 52%|██████████████████████████████████████████▋                                       | 5064/9741 [00:04<00:03, 1279.58it/s] 54%|███████████████████████████████████████████▉                                      | 5213/9741 [00:04<00:03, 1335.93it/s] 55%|█████████████████████████████████████████████▏                                    | 5362/9741 [00:04<00:03, 1378.58it/s] 57%|██████████████████████████████████████████████▍                                   | 5512/9741 [00:04<00:02, 1411.99it/s] 58%|███████████████████████████████████████████████▋                                  | 5661/9741 [00:04<00:02, 1432.24it/s] 60%|████████████████████████████████████████████████▉                                 | 5809/9741 [00:04<00:02, 1444.16it/s] 61%|██████████████████████████████████████████████████▏                               | 5958/9741 [00:04<00:02, 1454.90it/s] 63%|███████████████████████████████████████████████████▍                              | 6107/9741 [00:04<00:02, 1464.74it/s] 64%|████████████████████████████████████████████████████▋                             | 6255/9741 [00:04<00:02, 1450.79it/s] 66%|█████████████████████████████████████████████████████▉                            | 6402/9741 [00:05<00:02, 1456.21it/s] 67%|███████████████████████████████████████████████████████▏                          | 6549/9741 [00:05<00:02, 1459.79it/s] 69%|████████████████████████████████████████████████████████▍                         | 6698/9741 [00:05<00:02, 1467.61it/s] 70%|█████████████████████████████████████████████████████████▋                        | 6848/9741 [00:05<00:01, 1474.61it/s] 72%|██████████████████████████████████████████████████████████▉                       | 6996/9741 [00:05<00:01, 1474.75it/s] 73%|████████████████████████████████████████████████████████████▏                     | 7145/9741 [00:05<00:01, 1477.26it/s] 75%|█████████████████████████████████████████████████████████████▍                    | 7293/9741 [00:05<00:01, 1477.68it/s] 76%|██████████████████████████████████████████████████████████████▋                   | 7441/9741 [00:05<00:01, 1436.90it/s] 78%|███████████████████████████████████████████████████████████████▉                  | 7590/9741 [00:05<00:01, 1451.98it/s] 79%|█████████████████████████████████████████████████████████████████▏                | 7739/9741 [00:05<00:01, 1461.41it/s] 81%|██████████████████████████████████████████████████████████████████▍               | 7888/9741 [00:06<00:01, 1468.45it/s] 83%|███████████████████████████████████████████████████████████████████▋              | 8038/9741 [00:06<00:01, 1476.44it/s] 84%|████████████████████████████████████████████████████████████████████▉             | 8186/9741 [00:06<00:01, 1476.66it/s] 86%|██████████████████████████████████████████████████████████████████████▏           | 8334/9741 [00:06<00:00, 1477.50it/s] 87%|███████████████████████████████████████████████████████████████████████▍          | 8483/9741 [00:06<00:00, 1480.65it/s] 89%|████████████████████████████████████████████████████████████████████████▋         | 8632/9741 [00:06<00:00, 1480.86it/s] 90%|█████████████████████████████████████████████████████████████████████████▉        | 8782/9741 [00:06<00:00, 1484.06it/s] 92%|███████████████████████████████████████████████████████████████████████████▏      | 8933/9741 [00:06<00:00, 1489.19it/s] 93%|████████████████████████████████████████████████████████████████████████████▍     | 9083/9741 [00:06<00:00, 1490.73it/s] 95%|█████████████████████████████████████████████████████████████████████████████▋    | 9233/9741 [00:06<00:00, 1490.61it/s] 96%|██████████████████████████████████████████████████████████████████████████████▉   | 9383/9741 [00:07<00:00, 1491.01it/s] 98%|████████████████████████████████████████████████████████████████████████████████▏ | 9533/9741 [00:07<00:00, 1466.38it/s] 99%|█████████████████████████████████████████████████████████████████████████████████▍| 9680/9741 [00:07<00:00, 1465.31it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:07<00:00, 1331.45it/s]
Load End
Num instances: 1000
[2023-08-22 07:22:03,783] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 07:22:07,499] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 07:22:07,499] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 07:22:07,500] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 07:22:07,500] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 07:22:07,500] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 07:22:07,500] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 07:22:07,500] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 07:22:07,500] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 07:22:07,500] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 07:22:07,500] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 07:22:07,500] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 07:22:07,500] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f9ccea26a60>
[2023-08-22 07:22:07,500] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 07:22:07,500] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 07:22:07,500] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 07:22:07,500] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 07:22:07,500] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 07:22:07,500] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 07:22:07,500] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 07:22:07,500] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 07:22:07,500] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 07:22:07,500] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 07:22:07,500] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 07:22:07,500] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 07:22:07,500] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 07:22:07,500] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 07:22:07,500] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 07:22:07,500] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 07:22:07,500] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 07:22:07,500] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 07:22:07,500] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f9ccea26940>
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 07:22:07,501] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 07:22:07,501] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Loading extension module utils...
Time to load utils op: 0.4255695343017578 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
Time to load utils op: 0.40457653999328613 seconds

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: For the nuts Adam paid 3 * $12 = $<<3*12=36>>36.
And for dried fruits Adam paid 2.5 * $8 = $<<2.5*8=20>>20.
So in total for his purchases Adam paid $36 + $20 = $<<36+20=56>>56.
So the final answer is 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: He spends 60/3=<<60/3=20>>20 minutes warming up
So he spends 60+20=<<60+20=80>>80 minutes at the gym per day
That means he spends 80*3=<<80*3=240>>240 minutes at the gym
So he spends 240/60=<<240/60=4>>4 hours at the gym a week
So the final answer is 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: The cost to fill a tank went up 200*.2=$<<200*.2=40>>40
So it cost 200+40=$<<200+40=240>>240 to fill the tank
That means he now pays 240*2=$<<240*2=480>>480
So the final answer is 480

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o3-tgsm8k-s10-rTrue
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:53<43:44, 53.56s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:46<42:27, 53.08s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:38<41:22, 52.82s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:30<40:09, 52.38s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [04:23<39:22, 52.51s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [05:16<38:43, 52.80s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [06:10<38:01, 53.06s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [07:03<37:05, 52.98s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [07:56<36:14, 53.04s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [08:49<35:28, 53.21s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [09:43<34:45, 53.47s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [10:36<33:42, 53.21s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [11:29<32:44, 53.10s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [12:21<31:38, 52.75s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [13:14<30:51, 52.91s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [14:07<29:58, 52.90s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [15:01<29:21, 53.39s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [15:56<28:35, 53.60s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [16:48<27:31, 53.26s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [17:40<26:29, 52.98s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [18:34<25:42, 53.18s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [19:27<24:47, 53.14s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [20:20<23:54, 53.13s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [21:13<23:00, 53.08s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [22:09<22:26, 53.87s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [23:02<21:31, 53.80s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [23:54<20:24, 53.23s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [24:47<19:25, 53.00s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [25:41<18:40, 53.36s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [26:34<17:47, 53.37s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [27:28<16:55, 53.46s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [28:22<16:04, 53.59s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [29:16<15:11, 53.61s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [30:10<14:19, 53.72s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [31:04<13:27, 53.87s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [31:59<12:39, 54.23s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [32:52<11:38, 53.75s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [33:45<10:45, 53.78s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [34:38<09:48, 53.49s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [35:32<08:55, 53.54s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [36:24<07:59, 53.25s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [37:17<07:05, 53.15s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [38:10<06:10, 52.91s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [39:04<05:19, 53.30s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [39:57<04:26, 53.21s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [40:49<03:32, 53.03s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [41:42<02:38, 52.83s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [42:35<01:45, 52.92s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [43:29<00:53, 53.26s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [44:23<00:00, 53.39s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [44:23<00:00, 53.26s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.4534} | avg. gen lenth: 407.328
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o4-tgsm8k-s10-rTrue --seed 10 --max-prompt-length 2048 --rationales --num-out-domain 4
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 08:06:44,837] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o4-tgsm8k-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 4
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o4-tgsm8k-s10-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|▌                                                                                    | 69/9741 [00:00<00:14, 684.90it/s]  1%|█▏                                                                                  | 141/9741 [00:00<00:13, 701.68it/s]  2%|█▊                                                                                  | 212/9741 [00:00<00:13, 699.73it/s]  3%|██▍                                                                                 | 283/9741 [00:00<00:13, 703.33it/s]  4%|███                                                                                 | 356/9741 [00:00<00:13, 709.74it/s]  4%|███▋                                                                                | 428/9741 [00:00<00:13, 713.09it/s]  5%|████▎                                                                               | 501/9741 [00:00<00:12, 718.05it/s]  6%|████▉                                                                               | 573/9741 [00:00<00:13, 702.53it/s]  7%|█████▌                                                                              | 644/9741 [00:00<00:12, 703.60it/s]  7%|██████▏                                                                             | 717/9741 [00:01<00:12, 711.39it/s]  8%|██████▊                                                                             | 790/9741 [00:01<00:12, 716.08it/s]  9%|███████▍                                                                            | 862/9741 [00:01<00:12, 717.23it/s] 10%|████████                                                                            | 935/9741 [00:01<00:12, 719.43it/s] 10%|████████▌                                                                          | 1008/9741 [00:01<00:12, 721.23it/s] 11%|█████████▏                                                                         | 1081/9741 [00:01<00:11, 722.96it/s] 12%|█████████▊                                                                         | 1155/9741 [00:01<00:11, 725.26it/s] 13%|██████████▍                                                                        | 1228/9741 [00:01<00:11, 724.61it/s] 13%|███████████                                                                        | 1301/9741 [00:01<00:11, 723.83it/s] 14%|███████████▋                                                                       | 1374/9741 [00:01<00:11, 722.62it/s] 15%|████████████▎                                                                      | 1447/9741 [00:02<00:11, 723.68it/s] 16%|████████████▉                                                                      | 1520/9741 [00:02<00:11, 723.79it/s] 16%|█████████████▌                                                                     | 1593/9741 [00:02<00:11, 723.04it/s] 17%|██████████████▍                                                                    | 1694/9741 [00:02<00:09, 806.51it/s] 18%|███████████████▎                                                                   | 1795/9741 [00:02<00:09, 867.08it/s] 20%|████████████████▏                                                                  | 1904/9741 [00:02<00:08, 932.64it/s] 21%|█████████████████▏                                                                 | 2012/9741 [00:02<00:07, 975.69it/s] 22%|█████████████████▊                                                                | 2121/9741 [00:02<00:07, 1007.80it/s] 23%|██████████████████▊                                                               | 2230/9741 [00:02<00:07, 1029.94it/s] 24%|███████████████████▋                                                              | 2340/9741 [00:02<00:07, 1048.50it/s] 25%|████████████████████▌                                                             | 2448/9741 [00:03<00:06, 1055.35it/s] 26%|█████████████████████▍                                                            | 2554/9741 [00:03<00:06, 1051.86it/s] 27%|██████████████████████▍                                                           | 2662/9741 [00:03<00:06, 1059.47it/s] 28%|███████████████████████▎                                                          | 2770/9741 [00:03<00:06, 1062.94it/s] 30%|████████████████████████▏                                                         | 2879/9741 [00:03<00:06, 1068.46it/s] 31%|█████████████████████████▏                                                        | 2988/9741 [00:03<00:06, 1071.91it/s] 32%|██████████████████████████                                                        | 3096/9741 [00:03<00:06, 1073.01it/s] 33%|██████████████████████████▉                                                       | 3204/9741 [00:03<00:06, 1075.06it/s] 34%|███████████████████████████▉                                                      | 3312/9741 [00:03<00:05, 1076.07it/s] 35%|████████████████████████████▊                                                     | 3420/9741 [00:03<00:05, 1070.53it/s] 36%|█████████████████████████████▋                                                    | 3528/9741 [00:04<00:05, 1073.00it/s] 37%|██████████████████████████████▌                                                   | 3636/9741 [00:04<00:05, 1070.45it/s] 38%|███████████████████████████████▌                                                  | 3744/9741 [00:04<00:05, 1072.82it/s] 40%|████████████████████████████████▍                                                 | 3852/9741 [00:04<00:05, 1074.17it/s] 41%|█████████████████████████████████▎                                                | 3960/9741 [00:04<00:05, 1075.84it/s] 42%|██████████████████████████████████▏                                               | 4068/9741 [00:04<00:05, 1075.54it/s] 43%|███████████████████████████████████▏                                              | 4177/9741 [00:04<00:05, 1077.70it/s] 44%|████████████████████████████████████                                              | 4285/9741 [00:04<00:05, 1077.40it/s] 45%|████████████████████████████████████▉                                             | 4393/9741 [00:04<00:05, 1062.20it/s] 46%|█████████████████████████████████████▉                                            | 4500/9741 [00:04<00:05, 1013.43it/s] 47%|██████████████████████████████████████▊                                           | 4608/9741 [00:05<00:04, 1029.89it/s] 48%|████████████████████████████████████████▏                                          | 4712/9741 [00:05<00:06, 788.48it/s] 49%|█████████████████████████████████████████                                          | 4820/9741 [00:05<00:05, 857.62it/s] 51%|█████████████████████████████████████████▉                                         | 4927/9741 [00:05<00:05, 911.24it/s] 52%|██████████████████████████████████████████▉                                        | 5035/9741 [00:05<00:04, 955.50it/s] 53%|███████████████████████████████████████████▊                                       | 5143/9741 [00:05<00:04, 987.72it/s] 54%|████████████████████████████████████████████▏                                     | 5251/9741 [00:05<00:04, 1011.95it/s] 55%|█████████████████████████████████████████████                                     | 5359/9741 [00:05<00:04, 1029.85it/s] 56%|██████████████████████████████████████████████                                    | 5465/9741 [00:05<00:04, 1036.75it/s] 57%|██████████████████████████████████████████████▉                                   | 5572/9741 [00:06<00:03, 1045.19it/s] 58%|███████████████████████████████████████████████▊                                  | 5678/9741 [00:06<00:03, 1048.60it/s] 59%|████████████████████████████████████████████████▋                                 | 5785/9741 [00:06<00:03, 1054.75it/s] 60%|█████████████████████████████████████████████████▌                                | 5892/9741 [00:06<00:03, 1057.29it/s] 62%|██████████████████████████████████████████████████▍                               | 5999/9741 [00:06<00:03, 1060.68it/s] 63%|███████████████████████████████████████████████████▍                              | 6106/9741 [00:06<00:03, 1062.35it/s] 64%|████████████████████████████████████████████████████▎                             | 6214/9741 [00:06<00:03, 1064.72it/s] 65%|█████████████████████████████████████████████████████▏                            | 6321/9741 [00:06<00:03, 1061.22it/s] 66%|██████████████████████████████████████████████████████                            | 6428/9741 [00:06<00:03, 1063.80it/s] 67%|███████████████████████████████████████████████████████                           | 6535/9741 [00:06<00:03, 1061.70it/s] 68%|███████████████████████████████████████████████████████▉                          | 6642/9741 [00:07<00:02, 1044.02it/s] 69%|████████████████████████████████████████████████████████▊                         | 6747/9741 [00:07<00:02, 1045.45it/s] 70%|█████████████████████████████████████████████████████████▋                        | 6854/9741 [00:07<00:02, 1051.12it/s] 71%|██████████████████████████████████████████████████████████▌                       | 6961/9741 [00:07<00:02, 1053.91it/s] 73%|███████████████████████████████████████████████████████████▌                      | 7069/9741 [00:07<00:02, 1059.85it/s] 74%|████████████████████████████████████████████████████████████▍                     | 7176/9741 [00:07<00:02, 1061.62it/s] 75%|█████████████████████████████████████████████████████████████▎                    | 7283/9741 [00:07<00:02, 1061.41it/s] 76%|██████████████████████████████████████████████████████████████▏                   | 7390/9741 [00:07<00:02, 1063.11it/s] 77%|███████████████████████████████████████████████████████████████                   | 7497/9741 [00:07<00:02, 1019.85it/s] 78%|████████████████████████████████████████████████████████████████                  | 7603/9741 [00:08<00:02, 1029.57it/s] 79%|████████████████████████████████████████████████████████████████▉                 | 7709/9741 [00:08<00:01, 1037.07it/s] 80%|█████████████████████████████████████████████████████████████████▊                | 7816/9741 [00:08<00:01, 1044.54it/s] 81%|██████████████████████████████████████████████████████████████████▋               | 7923/9741 [00:08<00:01, 1049.31it/s] 82%|███████████████████████████████████████████████████████████████████▌              | 8029/9741 [00:08<00:01, 1051.61it/s] 84%|████████████████████████████████████████████████████████████████████▍             | 8135/9741 [00:08<00:01, 1052.41it/s] 85%|█████████████████████████████████████████████████████████████████████▍            | 8242/9741 [00:08<00:01, 1055.94it/s] 86%|██████████████████████████████████████████████████████████████████████▎           | 8348/9741 [00:08<00:01, 1056.28it/s] 87%|███████████████████████████████████████████████████████████████████████▏          | 8455/9741 [00:08<00:01, 1058.68it/s] 88%|████████████████████████████████████████████████████████████████████████          | 8562/9741 [00:08<00:01, 1059.39it/s] 89%|████████████████████████████████████████████████████████████████████████▉         | 8668/9741 [00:09<00:01, 1059.32it/s] 90%|█████████████████████████████████████████████████████████████████████████▊        | 8774/9741 [00:09<00:00, 1057.35it/s] 91%|██████████████████████████████████████████████████████████████████████████▊       | 8881/9741 [00:09<00:00, 1059.93it/s] 92%|███████████████████████████████████████████████████████████████████████████▋      | 8987/9741 [00:09<00:00, 1059.06it/s] 93%|████████████████████████████████████████████████████████████████████████████▌     | 9093/9741 [00:09<00:00, 1056.74it/s] 94%|█████████████████████████████████████████████████████████████████████████████▍    | 9199/9741 [00:09<00:00, 1057.54it/s] 96%|██████████████████████████████████████████████████████████████████████████████▎   | 9305/9741 [00:09<00:00, 1054.75it/s] 97%|███████████████████████████████████████████████████████████████████████████████▏  | 9411/9741 [00:09<00:00, 1056.15it/s] 98%|████████████████████████████████████████████████████████████████████████████████  | 9517/9741 [00:09<00:00, 1053.52it/s] 99%|█████████████████████████████████████████████████████████████████████████████████ | 9623/9741 [00:09<00:00, 1053.88it/s]100%|█████████████████████████████████████████████████████████████████████████████████▉| 9729/9741 [00:10<00:00, 1045.46it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:10<00:00, 971.42it/s]
Load End
Num instances: 1000
[2023-08-22 08:07:05,900] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 08:07:08,516] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 08:07:08,517] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 08:07:08,517] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 08:07:08,517] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 08:07:08,517] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 08:07:08,517] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 08:07:08,517] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 08:07:08,517] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 08:07:08,517] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 08:07:08,517] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 08:07:08,517] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 08:07:08,517] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f14d71d5a60>
[2023-08-22 08:07:08,517] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f14d71d5940>
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 08:07:08,518] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 08:07:08,519] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Loading extension module utils...
Time to load utils op: 0.42838406562805176 seconds
Time to load utils op: 0.40462708473205566 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: For the nuts Adam paid 3 * $12 = $<<3*12=36>>36.
And for dried fruits Adam paid 2.5 * $8 = $<<2.5*8=20>>20.
So in total for his purchases Adam paid $36 + $20 = $<<36+20=56>>56.
So the final answer is 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: He spends 60/3=<<60/3=20>>20 minutes warming up
So he spends 60+20=<<60+20=80>>80 minutes at the gym per day
That means he spends 80*3=<<80*3=240>>240 minutes at the gym
So he spends 240/60=<<240/60=4>>4 hours at the gym a week
So the final answer is 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: The cost to fill a tank went up 200*.2=$<<200*.2=40>>40
So it cost 200+40=$<<200+40=240>>240 to fill the tank
That means he now pays 240*2=$<<240*2=480>>480
So the final answer is 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: If the total number of goals scored in the league that season against Barca is 300, the two players scored 20/100*300=<<300*20/100=60>>60 goals.
If the players scored an equal number of goals, each scored 60/2=<<60/2=30>>30 goals.
So the final answer is 30

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o4-tgsm8k-s10-rTrue
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:51<41:49, 51.21s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:40<40:05, 50.11s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:28<38:36, 49.28s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:17<37:32, 48.96s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [04:05<36:27, 48.60s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [04:53<35:30, 48.41s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [05:41<34:38, 48.34s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [06:29<33:49, 48.33s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [07:18<33:09, 48.52s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [08:06<32:16, 48.42s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [08:56<31:46, 48.87s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [09:45<30:51, 48.72s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [10:38<30:53, 50.09s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [11:25<29:34, 49.30s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [12:15<28:43, 49.25s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [13:02<27:38, 48.77s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [13:52<26:55, 48.94s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [14:42<26:17, 49.29s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [15:30<25:23, 49.13s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [16:19<24:30, 49.01s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [17:07<23:31, 48.67s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [17:56<22:42, 48.67s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [18:44<21:53, 48.64s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [19:33<21:08, 48.78s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [20:22<20:16, 48.64s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [21:11<19:29, 48.74s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [21:59<18:35, 48.48s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [22:47<17:47, 48.53s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [23:37<17:05, 48.84s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [24:27<16:22, 49.13s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [25:15<15:28, 48.85s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [26:04<14:38, 48.82s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [26:54<14:00, 49.43s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [27:44<13:10, 49.44s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [28:33<12:19, 49.30s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [29:22<11:31, 49.40s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [30:11<10:40, 49.24s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [31:00<09:48, 49.07s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [31:49<08:58, 48.96s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [32:37<08:08, 48.83s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [33:25<07:16, 48.55s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [34:15<06:32, 49.09s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [35:04<05:42, 48.95s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [35:52<04:52, 48.75s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [36:42<04:05, 49.01s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [37:31<03:16, 49.01s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [38:20<02:27, 49.02s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [39:09<01:37, 48.91s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [39:58<00:49, 49.03s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [40:46<00:00, 48.66s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [40:46<00:00, 48.93s/it]
name: commonsenseqa | {'exact_match': 0.2, 'rougeL': 1.8939} | avg. gen lenth: 408.914
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o5-tgsm8k-s10-rTrue --seed 10 --max-prompt-length 2048 --rationales --num-out-domain 5
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date![nltk_data]   Package punkt is already up-to-date!

using world size: 2
[2023-08-22 08:48:03,803] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o5-tgsm8k-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 5
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o5-tgsm8k-s10-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|▌                                                                                    | 60/9741 [00:00<00:16, 596.38it/s]  1%|█                                                                                   | 123/9741 [00:00<00:15, 612.55it/s]  2%|█▌                                                                                  | 186/9741 [00:00<00:15, 617.25it/s]  3%|██▏                                                                                 | 249/9741 [00:00<00:15, 620.20it/s]  3%|██▋                                                                                 | 313/9741 [00:00<00:15, 625.29it/s]  4%|███▎                                                                                | 378/9741 [00:00<00:14, 630.43it/s]  5%|███▊                                                                                | 442/9741 [00:00<00:14, 630.37it/s]  5%|████▎                                                                               | 506/9741 [00:00<00:14, 632.10it/s]  6%|████▉                                                                               | 570/9741 [00:00<00:14, 622.16it/s]  6%|█████▍                                                                              | 633/9741 [00:01<00:14, 623.95it/s]  7%|██████                                                                              | 697/9741 [00:01<00:14, 627.94it/s]  8%|██████▌                                                                             | 761/9741 [00:01<00:14, 629.76it/s]  8%|███████                                                                             | 826/9741 [00:01<00:14, 633.47it/s]  9%|███████▋                                                                            | 890/9741 [00:01<00:13, 634.12it/s] 10%|████████▏                                                                           | 954/9741 [00:01<00:13, 635.82it/s] 10%|████████▋                                                                          | 1019/9741 [00:01<00:13, 637.36it/s] 11%|█████████▏                                                                         | 1083/9741 [00:01<00:13, 637.07it/s] 12%|█████████▊                                                                         | 1148/9741 [00:01<00:13, 639.14it/s] 12%|██████████▎                                                                        | 1212/9741 [00:01<00:13, 637.42it/s] 13%|██████████▉                                                                        | 1277/9741 [00:02<00:13, 638.46it/s] 14%|███████████▋                                                                       | 1371/9741 [00:02<00:11, 727.32it/s] 15%|████████████▌                                                                      | 1468/9741 [00:02<00:10, 797.26it/s] 16%|█████████████▎                                                                     | 1564/9741 [00:02<00:09, 845.09it/s] 17%|██████████████▏                                                                    | 1661/9741 [00:02<00:09, 879.73it/s] 18%|██████████████▉                                                                    | 1758/9741 [00:02<00:08, 906.32it/s] 19%|███████████████▊                                                                   | 1849/9741 [00:02<00:08, 899.97it/s] 20%|████████████████▌                                                                  | 1946/9741 [00:02<00:08, 918.17it/s] 21%|█████████████████▍                                                                 | 2041/9741 [00:02<00:08, 927.38it/s] 22%|██████████████████▏                                                                | 2137/9741 [00:02<00:08, 935.31it/s] 23%|███████████████████                                                                | 2233/9741 [00:03<00:07, 939.84it/s] 24%|███████████████████▊                                                               | 2329/9741 [00:03<00:07, 945.70it/s] 25%|████████████████████▋                                                              | 2424/9741 [00:03<00:07, 937.58it/s] 26%|█████████████████████▍                                                             | 2518/9741 [00:03<00:07, 937.38it/s] 27%|██████████████████████▎                                                            | 2614/9741 [00:03<00:07, 942.59it/s] 28%|███████████████████████                                                            | 2709/9741 [00:03<00:07, 942.91it/s] 29%|███████████████████████▉                                                           | 2805/9741 [00:03<00:07, 946.08it/s] 30%|████████████████████████▋                                                          | 2900/9741 [00:03<00:07, 946.92it/s] 31%|█████████████████████████▌                                                         | 2996/9741 [00:03<00:07, 948.91it/s] 32%|██████████████████████████▎                                                        | 3092/9741 [00:03<00:07, 949.29it/s] 33%|███████████████████████████▏                                                       | 3187/9741 [00:04<00:06, 947.77it/s] 34%|███████████████████████████▉                                                       | 3283/9741 [00:04<00:06, 949.11it/s] 35%|████████████████████████████▊                                                      | 3378/9741 [00:04<00:06, 946.83it/s] 36%|█████████████████████████████▌                                                     | 3474/9741 [00:04<00:06, 948.34it/s] 37%|██████████████████████████████▍                                                    | 3569/9741 [00:04<00:06, 948.75it/s] 38%|███████████████████████████████▏                                                   | 3664/9741 [00:04<00:06, 945.95it/s] 39%|████████████████████████████████                                                   | 3759/9741 [00:04<00:06, 946.72it/s] 40%|████████████████████████████████▊                                                  | 3854/9741 [00:04<00:06, 943.49it/s] 41%|█████████████████████████████████▋                                                 | 3949/9741 [00:04<00:06, 942.69it/s] 42%|██████████████████████████████████▍                                                | 4044/9741 [00:04<00:06, 927.55it/s] 42%|███████████████████████████████████▎                                               | 4139/9741 [00:05<00:06, 931.66it/s] 43%|████████████████████████████████████                                               | 4234/9741 [00:05<00:05, 934.50it/s] 44%|████████████████████████████████████▉                                              | 4328/9741 [00:05<00:05, 935.53it/s] 45%|█████████████████████████████████████▋                                             | 4423/9741 [00:05<00:05, 938.90it/s] 46%|██████████████████████████████████████▍                                            | 4517/9741 [00:05<00:05, 894.08it/s] 47%|███████████████████████████████████████▎                                           | 4611/9741 [00:05<00:05, 905.54it/s] 48%|████████████████████████████████████████                                           | 4704/9741 [00:05<00:05, 912.57it/s] 49%|████████████████████████████████████████▊                                          | 4796/9741 [00:05<00:06, 751.99it/s] 50%|█████████████████████████████████████████▋                                         | 4891/9741 [00:05<00:06, 800.96it/s] 51%|██████████████████████████████████████████▍                                        | 4985/9741 [00:06<00:05, 837.68it/s] 52%|███████████████████████████████████████████▎                                       | 5080/9741 [00:06<00:05, 867.72it/s] 53%|████████████████████████████████████████████                                       | 5173/9741 [00:06<00:05, 885.11it/s] 54%|████████████████████████████████████████████▉                                      | 5267/9741 [00:06<00:04, 898.92it/s] 55%|█████████████████████████████████████████████▋                                     | 5361/9741 [00:06<00:04, 908.44it/s] 56%|██████████████████████████████████████████████▍                                    | 5453/9741 [00:06<00:04, 911.31it/s] 57%|███████████████████████████████████████████████▎                                   | 5548/9741 [00:06<00:04, 920.90it/s] 58%|████████████████████████████████████████████████                                   | 5642/9741 [00:06<00:04, 924.25it/s] 59%|████████████████████████████████████████████████▉                                  | 5737/9741 [00:06<00:04, 930.05it/s] 60%|█████████████████████████████████████████████████▋                                 | 5831/9741 [00:06<00:04, 932.27it/s] 61%|██████████████████████████████████████████████████▍                                | 5926/9741 [00:07<00:04, 936.65it/s] 62%|███████████████████████████████████████████████████▎                               | 6020/9741 [00:07<00:04, 923.42it/s] 63%|████████████████████████████████████████████████████                               | 6113/9741 [00:07<00:03, 912.87it/s] 64%|████████████████████████████████████████████████████▊                              | 6205/9741 [00:07<00:03, 911.37it/s] 65%|█████████████████████████████████████████████████████▋                             | 6297/9741 [00:07<00:03, 907.97it/s] 66%|██████████████████████████████████████████████████████▍                            | 6389/9741 [00:07<00:03, 908.58it/s] 67%|███████████████████████████████████████████████████████▏                           | 6480/9741 [00:07<00:03, 908.93it/s] 67%|███████████████████████████████████████████████████████▉                           | 6571/9741 [00:07<00:03, 906.51it/s] 68%|████████████████████████████████████████████████████████▊                          | 6662/9741 [00:07<00:03, 907.42it/s] 69%|█████████████████████████████████████████████████████████▌                         | 6753/9741 [00:07<00:03, 904.89it/s] 70%|██████████████████████████████████████████████████████████▎                        | 6844/9741 [00:08<00:03, 904.25it/s] 71%|███████████████████████████████████████████████████████████                        | 6935/9741 [00:08<00:03, 903.53it/s] 72%|███████████████████████████████████████████████████████████▊                       | 7026/9741 [00:08<00:03, 899.84it/s] 73%|████████████████████████████████████████████████████████████▋                      | 7117/9741 [00:08<00:02, 901.00it/s] 74%|█████████████████████████████████████████████████████████████▍                     | 7208/9741 [00:08<00:02, 898.86it/s] 75%|██████████████████████████████████████████████████████████████▏                    | 7299/9741 [00:08<00:02, 899.76it/s] 76%|██████████████████████████████████████████████████████████████▉                    | 7390/9741 [00:08<00:02, 900.82it/s] 77%|███████████████████████████████████████████████████████████████▋                   | 7481/9741 [00:08<00:02, 862.27it/s] 78%|████████████████████████████████████████████████████████████████▌                  | 7571/9741 [00:08<00:02, 872.51it/s] 79%|█████████████████████████████████████████████████████████████████▎                 | 7660/9741 [00:08<00:02, 876.48it/s] 80%|██████████████████████████████████████████████████████████████████                 | 7750/9741 [00:09<00:02, 882.50it/s] 80%|██████████████████████████████████████████████████████████████████▊                | 7840/9741 [00:09<00:02, 886.15it/s] 81%|███████████████████████████████████████████████████████████████████▌               | 7929/9741 [00:09<00:02, 883.85it/s] 82%|████████████████████████████████████████████████████████████████████▎              | 8019/9741 [00:09<00:01, 887.20it/s] 83%|█████████████████████████████████████████████████████████████████████              | 8108/9741 [00:09<00:01, 886.18it/s] 84%|█████████████████████████████████████████████████████████████████████▊             | 8198/9741 [00:09<00:01, 887.53it/s] 85%|██████████████████████████████████████████████████████████████████████▌            | 8288/9741 [00:09<00:01, 888.37it/s] 86%|███████████████████████████████████████████████████████████████████████▍           | 8377/9741 [00:09<00:01, 887.09it/s] 87%|████████████████████████████████████████████████████████████████████████▏          | 8467/9741 [00:09<00:01, 888.31it/s] 88%|████████████████████████████████████████████████████████████████████████▉          | 8556/9741 [00:10<00:01, 885.56it/s] 89%|█████████████████████████████████████████████████████████████████████████▋         | 8646/9741 [00:10<00:01, 887.38it/s] 90%|██████████████████████████████████████████████████████████████████████████▍        | 8736/9741 [00:10<00:01, 888.70it/s] 91%|███████████████████████████████████████████████████████████████████████████▏       | 8825/9741 [00:10<00:01, 886.28it/s] 92%|███████████████████████████████████████████████████████████████████████████▉       | 8915/9741 [00:10<00:00, 888.47it/s] 92%|████████████████████████████████████████████████████████████████████████████▋      | 9004/9741 [00:10<00:00, 886.85it/s] 93%|█████████████████████████████████████████████████████████████████████████████▍     | 9093/9741 [00:10<00:00, 887.05it/s] 94%|██████████████████████████████████████████████████████████████████████████████▏    | 9182/9741 [00:10<00:00, 887.42it/s] 95%|██████████████████████████████████████████████████████████████████████████████▉    | 9271/9741 [00:10<00:00, 883.20it/s] 96%|███████████████████████████████████████████████████████████████████████████████▊   | 9360/9741 [00:10<00:00, 881.46it/s] 97%|████████████████████████████████████████████████████████████████████████████████▌  | 9449/9741 [00:11<00:00, 880.11it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▎ | 9538/9741 [00:11<00:00, 876.23it/s] 99%|██████████████████████████████████████████████████████████████████████████████████ | 9626/9741 [00:11<00:00, 875.19it/s]100%|██████████████████████████████████████████████████████████████████████████████████▊| 9714/9741 [00:11<00:00, 870.41it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:11<00:00, 858.26it/s]
Load End
Num instances: 1000
[2023-08-22 08:48:26,656] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 08:48:29,615] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 08:48:29,615] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f7b31671a60>
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 08:48:29,616] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 08:48:29,617] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f7b31671940>
[2023-08-22 08:48:29,617] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 08:48:29,617] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 08:48:29,617] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 08:48:29,617] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 08:48:29,617] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 08:48:29,617] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 08:48:29,617] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 08:48:29,617] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 08:48:29,617] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 08:48:29,617] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 08:48:29,617] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 08:48:29,617] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 08:48:29,617] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 08:48:29,617] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 08:48:29,617] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 08:48:29,617] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 08:48:29,617] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 08:48:29,617] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 08:48:29,617] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 08:48:29,617] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 08:48:29,617] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 08:48:29,617] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 08:48:29,617] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4632084369659424 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: For the nuts Adam paid 3 * $12 = $<<3*12=36>>36.
And for dried fruits Adam paid 2.5 * $8 = $<<2.5*8=20>>20.
So in total for his purchases Adam paid $36 + $20 = $<<36+20=56>>56.
So the final answer is 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: He spends 60/3=<<60/3=20>>20 minutes warming up
So he spends 60+20=<<60+20=80>>80 minutes at the gym per day
That means he spends 80*3=<<80*3=240>>240 minutes at the gym
So he spends 240/60=<<240/60=4>>4 hours at the gym a week
So the final answer is 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: The cost to fill a tank went up 200*.2=$<<200*.2=40>>40
So it cost 200+40=$<<200+40=240>>240 to fill the tank
That means he now pays 240*2=$<<240*2=480>>480
So the final answer is 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: If the total number of goals scored in the league that season against Barca is 300, the two players scored 20/100*300=<<300*20/100=60>>60 goals.
If the players scored an equal number of goals, each scored 60/2=<<60/2=30>>30 goals.
So the final answer is 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: He drinks 12 * 5 = <<12*5=60>>60 ounces of soda a day
So he drinks 60 + 64 = <<60+64=124>>124 ounces of liquid a day
So in total he drinks 124 * 7 = <<124*7=868>>868 ounces of liquid a week
So the final answer is 868

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o5-tgsm8k-s10-rTrue
Loading extension module utils...
Time to load utils op: 0.5049643516540527 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:45<37:27, 45.86s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:31<36:30, 45.64s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:18<36:12, 46.22s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:03<35:08, 45.84s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [03:47<34:00, 45.34s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [04:32<33:05, 45.12s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [05:18<32:25, 45.25s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [06:03<31:46, 45.39s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [06:49<30:58, 45.32s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [07:33<30:03, 45.08s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [08:20<29:44, 45.76s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [09:06<29:02, 45.86s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [09:52<28:16, 45.84s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [10:37<27:21, 45.60s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [11:23<26:36, 45.61s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [12:07<25:39, 45.27s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [12:53<24:59, 45.43s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [13:39<24:17, 45.56s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [14:24<23:29, 45.48s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [15:09<22:36, 45.21s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [15:54<21:46, 45.06s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [16:38<20:58, 44.95s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [17:24<20:16, 45.04s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [18:10<19:43, 45.53s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [18:56<18:57, 45.49s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [19:41<18:12, 45.50s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [20:26<17:19, 45.21s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [21:11<16:36, 45.28s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [21:57<15:52, 45.35s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [22:42<15:08, 45.42s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [23:28<14:21, 45.37s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [24:12<13:34, 45.23s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [24:59<12:56, 45.65s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [25:45<12:10, 45.64s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [26:29<11:19, 45.30s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [27:15<10:38, 45.59s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [28:01<09:51, 45.46s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [28:46<09:03, 45.31s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [29:32<08:21, 45.62s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [30:18<07:36, 45.64s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [31:02<06:48, 45.40s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [31:48<06:02, 45.31s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [32:33<05:16, 45.23s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [33:18<04:32, 45.38s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [34:04<03:46, 45.38s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [34:50<03:02, 45.57s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [35:34<02:15, 45.22s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [36:19<01:30, 45.13s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [37:04<00:45, 45.12s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [37:48<00:00, 44.86s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [37:48<00:00, 45.38s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.55} | avg. gen lenth: 428.148
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s10-rTrue --seed 10 --max-prompt-length 2048 --rationales --num-out-domain 6
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 09:27:07,636] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 6
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o6-tgsm8k-s10-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  0%|▎                                                                                    | 41/9741 [00:00<00:24, 404.00it/s]  1%|▋                                                                                    | 83/9741 [00:00<00:23, 411.63it/s]  1%|█                                                                                   | 126/9741 [00:00<00:22, 418.52it/s]  2%|█▍                                                                                  | 169/9741 [00:00<00:22, 421.43it/s]  2%|█▊                                                                                  | 212/9741 [00:00<00:22, 421.07it/s]  3%|██▏                                                                                 | 255/9741 [00:00<00:22, 423.55it/s]  3%|██▌                                                                                 | 298/9741 [00:00<00:22, 424.65it/s]  4%|██▉                                                                                 | 341/9741 [00:00<00:22, 416.97it/s]  4%|███▎                                                                                | 384/9741 [00:00<00:22, 419.83it/s]  4%|███▋                                                                                | 427/9741 [00:01<00:22, 419.24it/s]  5%|████                                                                                | 470/9741 [00:01<00:21, 422.37it/s]  5%|████▍                                                                               | 514/9741 [00:01<00:21, 425.05it/s]  6%|████▊                                                                               | 558/9741 [00:01<00:21, 426.53it/s]  6%|█████▎                                                                              | 611/9741 [00:01<00:20, 456.17it/s]  7%|█████▊                                                                              | 676/9741 [00:01<00:17, 512.41it/s]  8%|██████▍                                                                             | 741/9741 [00:01<00:16, 552.88it/s]  8%|██████▉                                                                             | 806/9741 [00:01<00:15, 581.47it/s]  9%|███████▌                                                                            | 870/9741 [00:01<00:14, 598.36it/s] 10%|████████                                                                            | 935/9741 [00:01<00:14, 611.18it/s] 10%|████████▌                                                                          | 1000/9741 [00:02<00:14, 619.91it/s] 11%|█████████                                                                          | 1065/9741 [00:02<00:13, 627.83it/s] 12%|█████████▋                                                                         | 1130/9741 [00:02<00:13, 634.09it/s] 12%|██████████▏                                                                        | 1195/9741 [00:02<00:13, 638.34it/s] 13%|██████████▋                                                                        | 1260/9741 [00:02<00:13, 641.17it/s] 14%|███████████▎                                                                       | 1325/9741 [00:02<00:13, 639.60it/s] 14%|███████████▊                                                                       | 1389/9741 [00:02<00:13, 639.60it/s] 15%|████████████▍                                                                      | 1453/9741 [00:02<00:13, 635.67it/s] 16%|████████████▉                                                                      | 1517/9741 [00:02<00:12, 635.13it/s] 16%|█████████████▍                                                                     | 1581/9741 [00:02<00:12, 633.07it/s] 17%|██████████████                                                                     | 1645/9741 [00:03<00:12, 634.02it/s] 18%|██████████████▌                                                                    | 1709/9741 [00:03<00:12, 634.05it/s] 18%|███████████████                                                                    | 1773/9741 [00:03<00:12, 616.83it/s] 19%|███████████████▋                                                                   | 1838/9741 [00:03<00:12, 624.60it/s] 20%|████████████████▏                                                                  | 1902/9741 [00:03<00:12, 628.75it/s] 20%|████████████████▊                                                                  | 1966/9741 [00:03<00:12, 630.73it/s] 21%|█████████████████▎                                                                 | 2030/9741 [00:03<00:12, 631.58it/s] 21%|█████████████████▊                                                                 | 2094/9741 [00:03<00:12, 632.45it/s] 22%|██████████████████▍                                                                | 2158/9741 [00:03<00:11, 633.46it/s] 23%|██████████████████▉                                                                | 2222/9741 [00:03<00:11, 632.80it/s] 23%|███████████████████▍                                                               | 2286/9741 [00:04<00:11, 634.18it/s] 24%|████████████████████                                                               | 2350/9741 [00:04<00:11, 634.80it/s] 25%|████████████████████▌                                                              | 2414/9741 [00:04<00:11, 633.92it/s] 25%|█████████████████████                                                              | 2478/9741 [00:04<00:11, 631.59it/s] 26%|█████████████████████▋                                                             | 2542/9741 [00:04<00:11, 632.79it/s] 27%|██████████████████████▏                                                            | 2607/9741 [00:04<00:11, 635.75it/s] 27%|██████████████████████▊                                                            | 2671/9741 [00:04<00:11, 634.58it/s] 28%|███████████████████████▎                                                           | 2735/9741 [00:04<00:11, 634.18it/s] 29%|███████████████████████▊                                                           | 2799/9741 [00:04<00:10, 634.99it/s] 29%|████████████████████████▍                                                          | 2863/9741 [00:04<00:10, 636.16it/s] 30%|████████████████████████▉                                                          | 2927/9741 [00:05<00:10, 630.12it/s] 31%|█████████████████████████▍                                                         | 2991/9741 [00:05<00:10, 630.35it/s] 31%|██████████████████████████                                                         | 3055/9741 [00:05<00:10, 632.38it/s] 32%|██████████████████████████▌                                                        | 3119/9741 [00:05<00:10, 631.75it/s] 33%|███████████████████████████                                                        | 3183/9741 [00:05<00:10, 631.46it/s] 33%|███████████████████████████▋                                                       | 3247/9741 [00:05<00:10, 633.48it/s] 34%|████████████████████████████▏                                                      | 3311/9741 [00:05<00:10, 632.17it/s] 35%|████████████████████████████▊                                                      | 3375/9741 [00:05<00:10, 618.91it/s] 35%|█████████████████████████████▎                                                     | 3439/9741 [00:05<00:10, 622.90it/s] 36%|█████████████████████████████▊                                                     | 3502/9741 [00:05<00:10, 623.30it/s] 37%|██████████████████████████████▍                                                    | 3565/9741 [00:06<00:09, 624.84it/s] 37%|██████████████████████████████▉                                                    | 3628/9741 [00:06<00:09, 624.97it/s] 38%|███████████████████████████████▍                                                   | 3691/9741 [00:06<00:09, 626.45it/s] 39%|███████████████████████████████▉                                                   | 3755/9741 [00:06<00:09, 628.14it/s] 39%|████████████████████████████████▌                                                  | 3818/9741 [00:06<00:09, 625.32it/s] 40%|█████████████████████████████████                                                  | 3881/9741 [00:06<00:09, 623.93it/s] 40%|█████████████████████████████████▌                                                 | 3944/9741 [00:06<00:09, 625.06it/s] 41%|██████████████████████████████████▏                                                | 4008/9741 [00:06<00:09, 627.13it/s] 42%|██████████████████████████████████▋                                                | 4071/9741 [00:06<00:09, 625.55it/s] 42%|███████████████████████████████████▏                                               | 4134/9741 [00:06<00:08, 626.35it/s] 43%|███████████████████████████████████▊                                               | 4197/9741 [00:07<00:08, 627.15it/s] 44%|████████████████████████████████████▎                                              | 4260/9741 [00:07<00:08, 624.38it/s] 44%|████████████████████████████████████▊                                              | 4324/9741 [00:07<00:08, 627.02it/s] 45%|█████████████████████████████████████▍                                             | 4387/9741 [00:07<00:08, 626.11it/s] 46%|█████████████████████████████████████▉                                             | 4450/9741 [00:07<00:08, 624.65it/s] 46%|██████████████████████████████████████▍                                            | 4513/9741 [00:07<00:08, 585.96it/s] 47%|██████████████████████████████████████▉                                            | 4576/9741 [00:07<00:08, 597.46it/s] 48%|███████████████████████████████████████▌                                           | 4639/9741 [00:07<00:08, 605.82it/s] 48%|████████████████████████████████████████                                           | 4702/9741 [00:07<00:08, 612.08it/s] 49%|████████████████████████████████████████▌                                          | 4764/9741 [00:08<00:10, 475.64it/s] 50%|█████████████████████████████████████████▏                                         | 4827/9741 [00:08<00:09, 512.81it/s] 50%|█████████████████████████████████████████▋                                         | 4890/9741 [00:08<00:08, 541.96it/s] 51%|██████████████████████████████████████████▏                                        | 4953/9741 [00:08<00:08, 563.98it/s] 51%|██████████████████████████████████████████▋                                        | 5016/9741 [00:08<00:08, 581.34it/s] 52%|███████████████████████████████████████████▎                                       | 5079/9741 [00:08<00:07, 593.99it/s] 53%|███████████████████████████████████████████▊                                       | 5140/9741 [00:08<00:07, 591.02it/s] 53%|████████████████████████████████████████████▎                                      | 5203/9741 [00:08<00:07, 601.83it/s] 54%|████████████████████████████████████████████▊                                      | 5266/9741 [00:08<00:07, 607.71it/s] 55%|█████████████████████████████████████████████▍                                     | 5329/9741 [00:09<00:07, 612.02it/s] 55%|█████████████████████████████████████████████▉                                     | 5391/9741 [00:09<00:07, 612.79it/s] 56%|██████████████████████████████████████████████▍                                    | 5454/9741 [00:09<00:06, 616.58it/s] 57%|███████████████████████████████████████████████                                    | 5517/9741 [00:09<00:06, 619.67it/s] 57%|███████████████████████████████████████████████▌                                   | 5580/9741 [00:09<00:06, 620.89it/s] 58%|████████████████████████████████████████████████                                   | 5643/9741 [00:09<00:06, 618.52it/s] 59%|████████████████████████████████████████████████▌                                  | 5706/9741 [00:09<00:06, 619.85it/s] 59%|█████████████████████████████████████████████████▏                                 | 5769/9741 [00:09<00:06, 620.86it/s] 60%|█████████████████████████████████████████████████▋                                 | 5832/9741 [00:09<00:06, 620.18it/s] 61%|██████████████████████████████████████████████████▏                                | 5895/9741 [00:09<00:06, 621.20it/s] 61%|██████████████████████████████████████████████████▊                                | 5958/9741 [00:10<00:06, 622.65it/s] 62%|███████████████████████████████████████████████████▎                               | 6021/9741 [00:10<00:05, 623.40it/s] 62%|███████████████████████████████████████████████████▊                               | 6084/9741 [00:10<00:05, 622.21it/s] 63%|████████████████████████████████████████████████████▍                              | 6147/9741 [00:10<00:05, 622.13it/s] 64%|████████████████████████████████████████████████████▉                              | 6210/9741 [00:10<00:05, 623.40it/s] 64%|█████████████████████████████████████████████████████▍                             | 6273/9741 [00:10<00:05, 620.82it/s] 65%|█████████████████████████████████████████████████████▉                             | 6336/9741 [00:10<00:05, 621.37it/s] 66%|██████████████████████████████████████████████████████▌                            | 6399/9741 [00:10<00:05, 622.31it/s] 66%|███████████████████████████████████████████████████████                            | 6462/9741 [00:10<00:05, 621.46it/s] 67%|███████████████████████████████████████████████████████▌                           | 6525/9741 [00:10<00:05, 619.75it/s] 68%|████████████████████████████████████████████████████████▏                          | 6588/9741 [00:11<00:05, 621.02it/s] 68%|████████████████████████████████████████████████████████▋                          | 6651/9741 [00:11<00:04, 622.38it/s] 69%|█████████████████████████████████████████████████████████▏                         | 6714/9741 [00:11<00:04, 622.84it/s] 70%|█████████████████████████████████████████████████████████▋                         | 6777/9741 [00:11<00:04, 622.01it/s] 70%|██████████████████████████████████████████████████████████▎                        | 6840/9741 [00:11<00:04, 622.80it/s] 71%|██████████████████████████████████████████████████████████▊                        | 6903/9741 [00:11<00:04, 623.33it/s] 72%|███████████████████████████████████████████████████████████▎                       | 6966/9741 [00:11<00:04, 622.21it/s] 72%|███████████████████████████████████████████████████████████▉                       | 7029/9741 [00:11<00:04, 621.12it/s] 73%|████████████████████████████████████████████████████████████▍                      | 7092/9741 [00:11<00:04, 620.31it/s] 73%|████████████████████████████████████████████████████████████▉                      | 7155/9741 [00:11<00:04, 621.54it/s] 74%|█████████████████████████████████████████████████████████████▌                     | 7218/9741 [00:12<00:04, 616.54it/s] 75%|██████████████████████████████████████████████████████████████                     | 7280/9741 [00:12<00:03, 617.38it/s] 75%|██████████████████████████████████████████████████████████████▌                    | 7343/9741 [00:12<00:03, 619.35it/s] 76%|███████████████████████████████████████████████████████████████                    | 7406/9741 [00:12<00:03, 621.47it/s] 77%|███████████████████████████████████████████████████████████████▋                   | 7469/9741 [00:12<00:03, 592.85it/s] 77%|████████████████████████████████████████████████████████████████▏                  | 7531/9741 [00:12<00:03, 600.28it/s] 78%|████████████████████████████████████████████████████████████████▋                  | 7594/9741 [00:12<00:03, 606.35it/s] 79%|█████████████████████████████████████████████████████████████████▏                 | 7656/9741 [00:12<00:03, 608.99it/s] 79%|█████████████████████████████████████████████████████████████████▊                 | 7719/9741 [00:12<00:03, 612.69it/s] 80%|██████████████████████████████████████████████████████████████████▎                | 7782/9741 [00:13<00:03, 615.60it/s] 81%|██████████████████████████████████████████████████████████████████▊                | 7845/9741 [00:13<00:03, 617.40it/s] 81%|███████████████████████████████████████████████████████████████████▎               | 7907/9741 [00:13<00:02, 616.64it/s] 82%|███████████████████████████████████████████████████████████████████▉               | 7969/9741 [00:13<00:02, 617.00it/s] 82%|████████████████████████████████████████████████████████████████████▍              | 8031/9741 [00:13<00:02, 615.83it/s] 83%|████████████████████████████████████████████████████████████████████▉              | 8093/9741 [00:13<00:02, 614.23it/s] 84%|█████████████████████████████████████████████████████████████████████▍             | 8155/9741 [00:13<00:02, 615.45it/s] 84%|██████████████████████████████████████████████████████████████████████             | 8217/9741 [00:13<00:02, 615.35it/s] 85%|██████████████████████████████████████████████████████████████████████▌            | 8279/9741 [00:13<00:02, 615.33it/s] 86%|███████████████████████████████████████████████████████████████████████            | 8341/9741 [00:13<00:02, 613.56it/s] 86%|███████████████████████████████████████████████████████████████████████▌           | 8403/9741 [00:14<00:02, 613.89it/s] 87%|████████████████████████████████████████████████████████████████████████▏          | 8465/9741 [00:14<00:02, 614.69it/s] 88%|████████████████████████████████████████████████████████████████████████▋          | 8527/9741 [00:14<00:01, 614.97it/s] 88%|█████████████████████████████████████████████████████████████████████████▏         | 8589/9741 [00:14<00:01, 604.83it/s] 89%|█████████████████████████████████████████████████████████████████████████▋         | 8651/9741 [00:14<00:01, 607.33it/s] 89%|██████████████████████████████████████████████████████████████████████████▏        | 8713/9741 [00:14<00:01, 609.36it/s] 90%|██████████████████████████████████████████████████████████████████████████▊        | 8774/9741 [00:14<00:01, 608.18it/s] 91%|███████████████████████████████████████████████████████████████████████████▎       | 8836/9741 [00:14<00:01, 610.69it/s] 91%|███████████████████████████████████████████████████████████████████████████▊       | 8898/9741 [00:14<00:01, 613.08it/s] 92%|████████████████████████████████████████████████████████████████████████████▎      | 8960/9741 [00:14<00:01, 614.26it/s] 93%|████████████████████████████████████████████████████████████████████████████▊      | 9022/9741 [00:15<00:01, 612.54it/s] 93%|█████████████████████████████████████████████████████████████████████████████▍     | 9084/9741 [00:15<00:01, 612.58it/s] 94%|█████████████████████████████████████████████████████████████████████████████▉     | 9146/9741 [00:15<00:00, 613.02it/s] 95%|██████████████████████████████████████████████████████████████████████████████▍    | 9208/9741 [00:15<00:00, 613.09it/s] 95%|██████████████████████████████████████████████████████████████████████████████▉    | 9270/9741 [00:15<00:00, 611.75it/s] 96%|███████████████████████████████████████████████████████████████████████████████▌   | 9332/9741 [00:15<00:00, 613.52it/s] 96%|████████████████████████████████████████████████████████████████████████████████   | 9394/9741 [00:15<00:00, 613.62it/s] 97%|████████████████████████████████████████████████████████████████████████████████▌  | 9456/9741 [00:15<00:00, 611.68it/s] 98%|█████████████████████████████████████████████████████████████████████████████████  | 9518/9741 [00:15<00:00, 611.92it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▋ | 9580/9741 [00:15<00:00, 613.64it/s] 99%|██████████████████████████████████████████████████████████████████████████████████▏| 9642/9741 [00:16<00:00, 614.47it/s]100%|██████████████████████████████████████████████████████████████████████████████████▋| 9704/9741 [00:16<00:00, 610.56it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:16<00:00, 601.39it/s]
Load End
Num instances: 1000
[2023-08-22 09:27:35,240] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 09:27:38,155] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 09:27:38,156] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 09:27:38,156] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 09:27:38,156] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 09:27:38,156] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 09:27:38,156] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 09:27:38,156] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 09:27:38,156] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 09:27:38,156] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 09:27:38,156] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 09:27:38,156] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 09:27:38,156] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f9613f5ea60>
[2023-08-22 09:27:38,156] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 09:27:38,156] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 09:27:38,156] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 09:27:38,156] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 09:27:38,156] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 09:27:38,156] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 09:27:38,156] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 09:27:38,156] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 09:27:38,156] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 09:27:38,156] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 09:27:38,156] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 09:27:38,156] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f9613f5e940>
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 09:27:38,157] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 09:27:38,157] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4375762939453125 seconds
Loading extension module utils...
Time to load utils op: 0.5047953128814697 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: For the nuts Adam paid 3 * $12 = $<<3*12=36>>36.
And for dried fruits Adam paid 2.5 * $8 = $<<2.5*8=20>>20.
So in total for his purchases Adam paid $36 + $20 = $<<36+20=56>>56.
So the final answer is 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: He spends 60/3=<<60/3=20>>20 minutes warming up
So he spends 60+20=<<60+20=80>>80 minutes at the gym per day
That means he spends 80*3=<<80*3=240>>240 minutes at the gym
So he spends 240/60=<<240/60=4>>4 hours at the gym a week
So the final answer is 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: The cost to fill a tank went up 200*.2=$<<200*.2=40>>40
So it cost 200+40=$<<200+40=240>>240 to fill the tank
That means he now pays 240*2=$<<240*2=480>>480
So the final answer is 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: If the total number of goals scored in the league that season against Barca is 300, the two players scored 20/100*300=<<300*20/100=60>>60 goals.
If the players scored an equal number of goals, each scored 60/2=<<60/2=30>>30 goals.
So the final answer is 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: He drinks 12 * 5 = <<12*5=60>>60 ounces of soda a day
So he drinks 60 + 64 = <<60+64=124>>124 ounces of liquid a day
So in total he drinks 124 * 7 = <<124*7=868>>868 ounces of liquid a week
So the final answer is 868

Input: Stella and Twinkle are filling up a truck with a capacity of 6000 stone blocks at the rate of 250 blocks per hour per person. They work for four hours and are then joined by 6 other people who also work at the same rate. How many hours did filling the truck take?
Output: Stella and Twinkle filled up the truck at the rate of 250 blocks per hour per person, a total of 2*250 = <<250*2=500>>500 blocks per hour for both.
After working for four hours, Stella and Twinkle had filled 4*500 = <<4*500=2000>>2000 blocks into the truck.
The number of blocks they had to put into the truck for it to be full is 6000-2000 = <<6000-2000=4000>>4000
When 6 more people joined Stella and Twinkle, a total of 2+6 = <<2+6=8>>8 people were filling the truck now.
Working at the rate of 250 blocks per person, the eight people filled the truck with 250*8 = <<250*8=2000>>2000 blocks in one hour.
If there were 4000 blocks that still needed to be put into the truck, the 8 people took 4000/2000 = <<4000/2000=2>>2 hours to fill the truck with the blocks.
The total time it took to fill up the tank is 4+2 = <<4+2=6>>6 hours.
So the final answer is 6

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o6-tgsm8k-s10-rTrue
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:39<32:07, 39.34s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:18<31:18, 39.14s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [01:56<30:14, 38.60s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [02:35<29:38, 38.66s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [03:13<28:50, 38.45s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [03:51<28:13, 38.50s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [04:30<27:42, 38.66s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [05:09<27:02, 38.63s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [05:47<26:17, 38.48s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [06:25<25:38, 38.47s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [07:04<25:02, 38.52s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [07:42<24:18, 38.39s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [08:20<23:35, 38.26s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [08:58<22:53, 38.15s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [09:36<22:15, 38.15s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [10:15<21:42, 38.32s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [10:54<21:08, 38.44s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [11:31<20:24, 38.26s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [12:09<19:42, 38.13s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [12:48<19:07, 38.24s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [13:26<18:33, 38.39s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [14:05<17:56, 38.45s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [14:43<17:17, 38.41s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [15:22<16:37, 38.37s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [16:00<15:58, 38.33s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [16:38<15:21, 38.39s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [17:17<14:45, 38.49s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [17:56<14:06, 38.46s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [18:34<13:28, 38.52s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [19:14<12:56, 38.81s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [19:54<12:23, 39.14s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [20:32<11:41, 38.95s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [21:12<11:07, 39.27s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [21:51<10:27, 39.20s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [22:30<09:47, 39.19s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [23:10<09:09, 39.22s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [23:48<08:25, 38.92s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [24:26<07:45, 38.75s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [25:05<07:07, 38.85s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [25:45<06:30, 39.05s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [26:24<05:50, 38.96s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [27:02<05:10, 38.86s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [27:42<04:33, 39.02s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [28:20<03:52, 38.82s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [28:58<03:13, 38.64s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [29:38<02:35, 38.87s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [30:16<01:56, 38.88s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [30:55<01:17, 38.81s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [31:34<00:38, 38.72s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [32:13<00:00, 38.85s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [32:13<00:00, 38.66s/it]
name: commonsenseqa | {'exact_match': 0.2, 'rougeL': 1.3067} | avg. gen lenth: 447.412
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o7-tgsm8k-s10-rTrue --seed 10 --max-prompt-length 2048 --rationales --num-out-domain 7
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 10:00:16,005] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o7-tgsm8k-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 7
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o7-tgsm8k-s10-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|▌                                                                                    | 58/9741 [00:00<00:16, 570.88it/s]  1%|█                                                                                   | 117/9741 [00:00<00:16, 579.08it/s]  2%|█▌                                                                                  | 175/9741 [00:00<00:16, 579.40it/s]  2%|██                                                                                  | 234/9741 [00:00<00:16, 582.31it/s]  3%|██▌                                                                                 | 293/9741 [00:00<00:16, 583.26it/s]  4%|███                                                                                 | 352/9741 [00:00<00:16, 582.97it/s]  4%|███▌                                                                                | 411/9741 [00:00<00:16, 582.76it/s]  5%|████                                                                                | 470/9741 [00:00<00:15, 583.70it/s]  5%|████▌                                                                               | 529/9741 [00:00<00:16, 574.27it/s]  6%|█████                                                                               | 588/9741 [00:01<00:15, 577.65it/s]  7%|█████▌                                                                              | 646/9741 [00:01<00:15, 577.66it/s]  7%|██████                                                                              | 706/9741 [00:01<00:15, 581.48it/s]  8%|██████▌                                                                             | 766/9741 [00:01<00:15, 584.67it/s]  8%|███████                                                                             | 826/9741 [00:01<00:15, 588.32it/s]  9%|███████▋                                                                            | 885/9741 [00:01<00:15, 587.61it/s] 10%|████████▏                                                                           | 945/9741 [00:01<00:14, 588.78it/s] 10%|████████▌                                                                          | 1005/9741 [00:01<00:14, 589.85it/s] 11%|█████████                                                                          | 1065/9741 [00:01<00:14, 590.88it/s] 12%|█████████▌                                                                         | 1125/9741 [00:01<00:14, 585.59it/s] 12%|██████████                                                                         | 1185/9741 [00:02<00:14, 586.96it/s] 13%|██████████▌                                                                        | 1244/9741 [00:02<00:14, 585.26it/s] 13%|███████████                                                                        | 1303/9741 [00:02<00:14, 585.25it/s] 14%|███████████▌                                                                       | 1362/9741 [00:02<00:14, 583.77it/s] 15%|████████████                                                                       | 1421/9741 [00:02<00:14, 583.55it/s] 15%|████████████▌                                                                      | 1480/9741 [00:02<00:14, 584.83it/s] 16%|█████████████                                                                      | 1539/9741 [00:02<00:14, 584.85it/s] 16%|█████████████▌                                                                     | 1598/9741 [00:02<00:13, 585.72it/s] 17%|██████████████                                                                     | 1657/9741 [00:02<00:13, 584.40it/s] 18%|██████████████▌                                                                    | 1716/9741 [00:02<00:13, 585.46it/s] 18%|███████████████                                                                    | 1775/9741 [00:03<00:14, 563.58it/s] 19%|███████████████▌                                                                   | 1832/9741 [00:03<00:14, 561.83it/s] 19%|████████████████                                                                   | 1889/9741 [00:03<00:13, 563.39it/s] 20%|████████████████▌                                                                  | 1947/9741 [00:03<00:13, 565.67it/s] 21%|█████████████████                                                                  | 2004/9741 [00:03<00:13, 566.38it/s] 21%|█████████████████▌                                                                 | 2062/9741 [00:03<00:13, 570.32it/s] 22%|██████████████████                                                                 | 2121/9741 [00:03<00:13, 574.18it/s] 22%|██████████████████▌                                                                | 2180/9741 [00:03<00:13, 578.30it/s] 23%|███████████████████                                                                | 2239/9741 [00:03<00:12, 579.65it/s] 24%|███████████████████▌                                                               | 2298/9741 [00:03<00:12, 581.40it/s] 24%|████████████████████                                                               | 2357/9741 [00:04<00:12, 582.49it/s] 25%|████████████████████▌                                                              | 2416/9741 [00:04<00:12, 580.81it/s] 25%|█████████████████████                                                              | 2475/9741 [00:04<00:12, 577.92it/s] 26%|█████████████████████▌                                                             | 2534/9741 [00:04<00:12, 579.65it/s] 27%|██████████████████████                                                             | 2592/9741 [00:04<00:12, 579.72it/s] 27%|██████████████████████▌                                                            | 2651/9741 [00:04<00:12, 579.85it/s] 28%|███████████████████████                                                            | 2709/9741 [00:04<00:12, 578.57it/s] 28%|███████████████████████▌                                                           | 2767/9741 [00:04<00:12, 578.53it/s] 29%|████████████████████████                                                           | 2825/9741 [00:04<00:11, 578.34it/s] 30%|████████████████████████▌                                                          | 2883/9741 [00:04<00:11, 578.22it/s] 30%|█████████████████████████                                                          | 2941/9741 [00:05<00:11, 575.28it/s] 31%|█████████████████████████▌                                                         | 3000/9741 [00:05<00:11, 578.18it/s] 31%|██████████████████████████                                                         | 3058/9741 [00:05<00:11, 577.69it/s] 32%|██████████████████████████▌                                                        | 3116/9741 [00:05<00:11, 576.71it/s] 33%|███████████████████████████                                                        | 3174/9741 [00:05<00:11, 576.93it/s] 33%|███████████████████████████▌                                                       | 3232/9741 [00:05<00:11, 574.52it/s] 34%|████████████████████████████                                                       | 3290/9741 [00:05<00:11, 576.09it/s] 34%|████████████████████████████▌                                                      | 3348/9741 [00:05<00:11, 574.94it/s] 35%|█████████████████████████████                                                      | 3406/9741 [00:05<00:10, 576.33it/s] 36%|█████████████████████████████▌                                                     | 3464/9741 [00:05<00:10, 577.38it/s] 36%|██████████████████████████████                                                     | 3522/9741 [00:06<00:10, 578.00it/s] 37%|██████████████████████████████▌                                                    | 3580/9741 [00:06<00:10, 568.71it/s] 37%|██████████████████████████████▉                                                    | 3638/9741 [00:06<00:10, 570.05it/s] 38%|███████████████████████████████▍                                                   | 3696/9741 [00:06<00:10, 572.97it/s] 39%|███████████████████████████████▉                                                   | 3754/9741 [00:06<00:10, 572.73it/s] 39%|████████████████████████████████▍                                                  | 3812/9741 [00:06<00:10, 570.43it/s] 40%|████████████████████████████████▉                                                  | 3870/9741 [00:06<00:10, 566.83it/s] 40%|█████████████████████████████████▍                                                 | 3928/9741 [00:06<00:10, 568.17it/s] 41%|█████████████████████████████████▉                                                 | 3986/9741 [00:06<00:10, 570.12it/s] 42%|██████████████████████████████████▍                                                | 4044/9741 [00:06<00:10, 569.00it/s] 42%|██████████████████████████████████▉                                                | 4102/9741 [00:07<00:09, 570.34it/s] 43%|███████████████████████████████████▍                                               | 4160/9741 [00:07<00:09, 568.65it/s] 43%|███████████████████████████████████▉                                               | 4217/9741 [00:07<00:09, 566.85it/s] 44%|████████████████████████████████████▍                                              | 4274/9741 [00:07<00:09, 563.70it/s] 44%|████████████████████████████████████▉                                              | 4331/9741 [00:07<00:09, 561.64it/s] 45%|█████████████████████████████████████▍                                             | 4388/9741 [00:07<00:09, 562.74it/s] 46%|█████████████████████████████████████▊                                             | 4445/9741 [00:07<00:09, 563.53it/s] 46%|██████████████████████████████████████▎                                            | 4502/9741 [00:07<00:09, 527.71it/s] 47%|██████████████████████████████████████▊                                            | 4560/9741 [00:07<00:09, 539.91it/s] 47%|███████████████████████████████████████▎                                           | 4618/9741 [00:08<00:09, 550.55it/s] 48%|███████████████████████████████████████▊                                           | 4675/9741 [00:08<00:09, 555.96it/s] 49%|████████████████████████████████████████▎                                          | 4731/9741 [00:08<00:12, 405.33it/s] 49%|████████████████████████████████████████▊                                          | 4789/9741 [00:08<00:11, 445.89it/s] 50%|█████████████████████████████████████████▎                                         | 4847/9741 [00:08<00:10, 478.82it/s] 50%|█████████████████████████████████████████▊                                         | 4905/9741 [00:08<00:09, 504.79it/s] 51%|██████████████████████████████████████████▎                                        | 4963/9741 [00:08<00:09, 524.27it/s] 52%|██████████████████████████████████████████▊                                        | 5020/9741 [00:08<00:08, 535.13it/s] 52%|███████████████████████████████████████████▎                                       | 5077/9741 [00:08<00:08, 543.00it/s] 53%|███████████████████████████████████████████▊                                       | 5135/9741 [00:09<00:08, 551.92it/s] 53%|████████████████████████████████████████████▏                                      | 5192/9741 [00:09<00:08, 556.84it/s] 54%|████████████████████████████████████████████▋                                      | 5250/9741 [00:09<00:07, 563.07it/s] 54%|█████████████████████████████████████████████▏                                     | 5308/9741 [00:09<00:07, 567.53it/s] 55%|█████████████████████████████████████████████▋                                     | 5366/9741 [00:09<00:07, 569.72it/s] 56%|██████████████████████████████████████████████▏                                    | 5424/9741 [00:09<00:07, 569.99it/s] 56%|██████████████████████████████████████████████▋                                    | 5482/9741 [00:09<00:07, 571.56it/s] 57%|███████████████████████████████████████████████▏                                   | 5540/9741 [00:09<00:07, 570.11it/s] 57%|███████████████████████████████████████████████▋                                   | 5598/9741 [00:09<00:07, 565.08it/s] 58%|████████████████████████████████████████████████▏                                  | 5655/9741 [00:09<00:07, 560.75it/s] 59%|████████████████████████████████████████████████▋                                  | 5712/9741 [00:10<00:07, 563.27it/s] 59%|█████████████████████████████████████████████████▏                                 | 5770/9741 [00:10<00:07, 565.39it/s] 60%|█████████████████████████████████████████████████▋                                 | 5827/9741 [00:10<00:06, 563.18it/s] 60%|██████████████████████████████████████████████████▏                                | 5884/9741 [00:10<00:06, 562.98it/s] 61%|██████████████████████████████████████████████████▌                                | 5941/9741 [00:10<00:06, 562.71it/s] 62%|███████████████████████████████████████████████████                                | 5998/9741 [00:10<00:06, 562.71it/s] 62%|███████████████████████████████████████████████████▌                               | 6055/9741 [00:10<00:06, 561.20it/s] 63%|████████████████████████████████████████████████████                               | 6112/9741 [00:10<00:06, 561.84it/s] 63%|████████████████████████████████████████████████████▌                              | 6169/9741 [00:10<00:06, 560.11it/s] 64%|█████████████████████████████████████████████████████                              | 6226/9741 [00:11<00:06, 560.78it/s] 65%|█████████████████████████████████████████████████████▌                             | 6283/9741 [00:11<00:06, 555.52it/s] 65%|██████████████████████████████████████████████████████                             | 6339/9741 [00:11<00:06, 556.71it/s] 66%|██████████████████████████████████████████████████████▍                            | 6396/9741 [00:11<00:05, 558.71it/s] 66%|██████████████████████████████████████████████████████▉                            | 6453/9741 [00:11<00:05, 560.07it/s] 67%|███████████████████████████████████████████████████████▍                           | 6510/9741 [00:11<00:05, 561.58it/s] 67%|███████████████████████████████████████████████████████▉                           | 6568/9741 [00:11<00:05, 564.72it/s] 68%|████████████████████████████████████████████████████████▍                          | 6626/9741 [00:11<00:05, 567.24it/s] 69%|████████████████████████████████████████████████████████▉                          | 6684/9741 [00:11<00:05, 570.06it/s] 69%|█████████████████████████████████████████████████████████▍                         | 6742/9741 [00:11<00:05, 570.01it/s] 70%|█████████████████████████████████████████████████████████▉                         | 6800/9741 [00:12<00:05, 572.12it/s] 70%|██████████████████████████████████████████████████████████▍                        | 6858/9741 [00:12<00:05, 573.11it/s] 71%|██████████████████████████████████████████████████████████▉                        | 6916/9741 [00:12<00:04, 571.56it/s] 72%|███████████████████████████████████████████████████████████▍                       | 6974/9741 [00:12<00:04, 560.74it/s] 72%|███████████████████████████████████████████████████████████▉                       | 7032/9741 [00:12<00:04, 565.56it/s] 73%|████████████████████████████████████████████████████████████▍                      | 7090/9741 [00:12<00:04, 569.25it/s] 73%|████████████████████████████████████████████████████████████▉                      | 7148/9741 [00:12<00:04, 571.44it/s] 74%|█████████████████████████████████████████████████████████████▍                     | 7206/9741 [00:12<00:04, 569.73it/s] 75%|█████████████████████████████████████████████████████████████▉                     | 7264/9741 [00:12<00:04, 571.47it/s] 75%|██████████████████████████████████████████████████████████████▍                    | 7322/9741 [00:12<00:04, 570.49it/s] 76%|██████████████████████████████████████████████████████████████▉                    | 7380/9741 [00:13<00:04, 571.86it/s] 76%|███████████████████████████████████████████████████████████████▍                   | 7438/9741 [00:13<00:04, 535.08it/s] 77%|███████████████████████████████████████████████████████████████▊                   | 7495/9741 [00:13<00:04, 542.58it/s] 78%|████████████████████████████████████████████████████████████████▎                  | 7552/9741 [00:13<00:03, 548.56it/s] 78%|████████████████████████████████████████████████████████████████▊                  | 7610/9741 [00:13<00:03, 555.41it/s] 79%|█████████████████████████████████████████████████████████████████▎                 | 7667/9741 [00:13<00:03, 557.67it/s] 79%|█████████████████████████████████████████████████████████████████▊                 | 7725/9741 [00:13<00:03, 561.43it/s] 80%|██████████████████████████████████████████████████████████████████▎                | 7783/9741 [00:13<00:03, 564.01it/s] 80%|██████████████████████████████████████████████████████████████████▊                | 7841/9741 [00:13<00:03, 566.13it/s] 81%|███████████████████████████████████████████████████████████████████▎               | 7898/9741 [00:13<00:03, 565.43it/s] 82%|███████████████████████████████████████████████████████████████████▊               | 7956/9741 [00:14<00:03, 568.38it/s] 82%|████████████████████████████████████████████████████████████████████▎              | 8014/9741 [00:14<00:03, 570.76it/s] 83%|████████████████████████████████████████████████████████████████████▊              | 8072/9741 [00:14<00:02, 572.13it/s] 83%|█████████████████████████████████████████████████████████████████████▎             | 8130/9741 [00:14<00:02, 568.06it/s] 84%|█████████████████████████████████████████████████████████████████████▊             | 8187/9741 [00:14<00:02, 563.63it/s] 85%|██████████████████████████████████████████████████████████████████████▎            | 8245/9741 [00:14<00:02, 566.30it/s] 85%|██████████████████████████████████████████████████████████████████████▋            | 8303/9741 [00:14<00:02, 568.13it/s] 86%|███████████████████████████████████████████████████████████████████████▏           | 8360/9741 [00:14<00:02, 566.57it/s] 86%|███████████████████████████████████████████████████████████████████████▋           | 8418/9741 [00:14<00:02, 567.94it/s] 87%|████████████████████████████████████████████████████████████████████████▏          | 8475/9741 [00:14<00:02, 553.30it/s] 88%|████████████████████████████████████████████████████████████████████████▋          | 8533/9741 [00:15<00:02, 560.61it/s] 88%|█████████████████████████████████████████████████████████████████████████▏         | 8591/9741 [00:15<00:02, 563.53it/s] 89%|█████████████████████████████████████████████████████████████████████████▋         | 8649/9741 [00:15<00:01, 566.99it/s] 89%|██████████████████████████████████████████████████████████████████████████▏        | 8707/9741 [00:15<00:01, 569.38it/s] 90%|██████████████████████████████████████████████████████████████████████████▋        | 8765/9741 [00:15<00:01, 571.15it/s] 91%|███████████████████████████████████████████████████████████████████████████▏       | 8823/9741 [00:15<00:01, 570.49it/s] 91%|███████████████████████████████████████████████████████████████████████████▋       | 8881/9741 [00:15<00:01, 572.47it/s] 92%|████████████████████████████████████████████████████████████████████████████▏      | 8939/9741 [00:15<00:01, 573.71it/s] 92%|████████████████████████████████████████████████████████████████████████████▋      | 8997/9741 [00:15<00:01, 572.17it/s] 93%|█████████████████████████████████████████████████████████████████████████████▏     | 9055/9741 [00:16<00:01, 573.21it/s] 94%|█████████████████████████████████████████████████████████████████████████████▋     | 9113/9741 [00:16<00:01, 574.49it/s] 94%|██████████████████████████████████████████████████████████████████████████████▏    | 9171/9741 [00:16<00:00, 574.46it/s] 95%|██████████████████████████████████████████████████████████████████████████████▋    | 9229/9741 [00:16<00:00, 571.62it/s] 95%|███████████████████████████████████████████████████████████████████████████████▏   | 9287/9741 [00:16<00:00, 571.74it/s] 96%|███████████████████████████████████████████████████████████████████████████████▋   | 9345/9741 [00:16<00:00, 569.89it/s] 97%|████████████████████████████████████████████████████████████████████████████████   | 9403/9741 [00:16<00:00, 569.91it/s] 97%|████████████████████████████████████████████████████████████████████████████████▌  | 9460/9741 [00:16<00:00, 567.66it/s] 98%|█████████████████████████████████████████████████████████████████████████████████  | 9517/9741 [00:16<00:00, 567.82it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▌ | 9574/9741 [00:16<00:00, 568.35it/s] 99%|██████████████████████████████████████████████████████████████████████████████████ | 9631/9741 [00:17<00:00, 567.22it/s] 99%|██████████████████████████████████████████████████████████████████████████████████▌| 9688/9741 [00:17<00:00, 566.10it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:17<00:00, 566.03it/s]
Load End
Num instances: 1000
[2023-08-22 10:00:44,826] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 10:00:47,617] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 10:00:47,618] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 10:00:47,618] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 10:00:47,618] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 10:00:47,618] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 10:00:47,618] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 10:00:47,618] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 10:00:47,618] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 10:00:47,618] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 10:00:47,618] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 10:00:47,618] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f222a63ca60>
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f222a63c940>
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 10:00:47,619] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 10:00:47,620] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 10:00:47,620] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 10:00:47,620] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 10:00:47,620] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.43664121627807617 seconds
Loading extension module utils...
Time to load utils op: 0.5048480033874512 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: For the nuts Adam paid 3 * $12 = $<<3*12=36>>36.
And for dried fruits Adam paid 2.5 * $8 = $<<2.5*8=20>>20.
So in total for his purchases Adam paid $36 + $20 = $<<36+20=56>>56.
So the final answer is 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: He spends 60/3=<<60/3=20>>20 minutes warming up
So he spends 60+20=<<60+20=80>>80 minutes at the gym per day
That means he spends 80*3=<<80*3=240>>240 minutes at the gym
So he spends 240/60=<<240/60=4>>4 hours at the gym a week
So the final answer is 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: The cost to fill a tank went up 200*.2=$<<200*.2=40>>40
So it cost 200+40=$<<200+40=240>>240 to fill the tank
That means he now pays 240*2=$<<240*2=480>>480
So the final answer is 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: If the total number of goals scored in the league that season against Barca is 300, the two players scored 20/100*300=<<300*20/100=60>>60 goals.
If the players scored an equal number of goals, each scored 60/2=<<60/2=30>>30 goals.
So the final answer is 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: He drinks 12 * 5 = <<12*5=60>>60 ounces of soda a day
So he drinks 60 + 64 = <<60+64=124>>124 ounces of liquid a day
So in total he drinks 124 * 7 = <<124*7=868>>868 ounces of liquid a week
So the final answer is 868

Input: Stella and Twinkle are filling up a truck with a capacity of 6000 stone blocks at the rate of 250 blocks per hour per person. They work for four hours and are then joined by 6 other people who also work at the same rate. How many hours did filling the truck take?
Output: Stella and Twinkle filled up the truck at the rate of 250 blocks per hour per person, a total of 2*250 = <<250*2=500>>500 blocks per hour for both.
After working for four hours, Stella and Twinkle had filled 4*500 = <<4*500=2000>>2000 blocks into the truck.
The number of blocks they had to put into the truck for it to be full is 6000-2000 = <<6000-2000=4000>>4000
When 6 more people joined Stella and Twinkle, a total of 2+6 = <<2+6=8>>8 people were filling the truck now.
Working at the rate of 250 blocks per person, the eight people filled the truck with 250*8 = <<250*8=2000>>2000 blocks in one hour.
If there were 4000 blocks that still needed to be put into the truck, the 8 people took 4000/2000 = <<4000/2000=2>>2 hours to fill the truck with the blocks.
The total time it took to fill up the tank is 4+2 = <<4+2=6>>6 hours.
So the final answer is 6

Input: Elijah drank 8.5 pints of coffee yesterday. Emilio drank 9.5 pints of water yesterday. How many cups of liquid did the two boys drink yesterday?
Output: Total drunk: 8.5 + 9.5 = <<8.5+9.5=18>>18 pints
18 pints * 2 = <<18*2=36>>36 cups
The two boys drank a total of 36 cups of liquid yesterday.
So the final answer is 36

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o7-tgsm8k-s10-rTrue
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:37<31:00, 37.97s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:14<29:50, 37.31s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [01:51<28:55, 36.93s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [02:28<28:15, 36.86s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [03:06<27:56, 37.26s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [03:42<27:06, 36.95s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [04:18<26:24, 36.84s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [04:55<25:46, 36.83s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [05:33<25:16, 36.99s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [06:09<24:35, 36.88s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [06:46<24:01, 36.97s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [07:23<23:21, 36.88s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [08:00<22:46, 36.92s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [08:38<22:17, 37.14s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [09:15<21:38, 37.11s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [09:51<20:55, 36.93s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [10:32<20:52, 37.97s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [11:09<20:10, 37.82s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [11:46<19:20, 37.43s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [12:23<18:40, 37.36s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [13:00<18:01, 37.29s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [13:37<17:24, 37.30s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [14:14<16:45, 37.26s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [14:52<16:10, 37.31s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [15:30<15:40, 37.62s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [16:09<15:08, 37.87s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [16:46<14:27, 37.71s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [17:23<13:46, 37.56s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [18:01<13:09, 37.60s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [18:39<12:31, 37.58s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [19:16<11:55, 37.66s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [19:56<11:27, 38.18s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [20:33<10:44, 37.93s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [21:10<10:01, 37.59s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [21:47<09:21, 37.46s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [22:25<08:45, 37.51s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [23:02<08:07, 37.49s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [23:39<07:29, 37.42s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [24:22<07:09, 39.01s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [25:05<06:40, 40.06s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [25:57<06:33, 43.71s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [26:38<05:44, 43.10s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [27:17<04:51, 41.63s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [27:56<04:05, 40.89s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [28:33<03:19, 39.88s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [29:11<02:36, 39.16s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [29:48<01:55, 38.64s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [30:26<01:16, 38.38s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [31:04<00:38, 38.24s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [31:42<00:00, 38.11s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [31:42<00:00, 38.05s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.4126} | avg. gen lenth: 451.674
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s10-rTrue --seed 10 --max-prompt-length 2048 --rationales --num-out-domain 8
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 10:32:39,319] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 8
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o8-tgsm8k-s10-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  0%|▎                                                                                    | 33/9741 [00:00<00:30, 323.21it/s]  1%|▌                                                                                    | 66/9741 [00:00<00:29, 325.93it/s]  1%|▊                                                                                   | 100/9741 [00:00<00:29, 328.16it/s]  1%|█▏                                                                                  | 134/9741 [00:00<00:29, 329.52it/s]  2%|█▍                                                                                  | 168/9741 [00:00<00:28, 330.36it/s]  2%|█▋                                                                                  | 202/9741 [00:00<00:28, 329.16it/s]  2%|██                                                                                  | 236/9741 [00:00<00:28, 329.88it/s]  3%|██▎                                                                                 | 269/9741 [00:00<00:29, 323.44it/s]  3%|██▌                                                                                 | 303/9741 [00:00<00:28, 326.09it/s]  3%|██▉                                                                                 | 336/9741 [00:01<00:30, 309.94it/s]  4%|███▏                                                                                | 370/9741 [00:01<00:29, 316.53it/s]  4%|███▍                                                                                | 403/9741 [00:01<00:29, 317.72it/s]  4%|███▊                                                                                | 437/9741 [00:01<00:28, 322.24it/s]  5%|████                                                                                | 471/9741 [00:01<00:28, 325.41it/s]  5%|████▎                                                                               | 505/9741 [00:01<00:28, 327.98it/s]  6%|████▋                                                                               | 539/9741 [00:01<00:27, 329.89it/s]  6%|████▉                                                                               | 573/9741 [00:01<00:29, 312.60it/s]  6%|█████▏                                                                              | 605/9741 [00:01<00:31, 289.05it/s]  7%|█████▍                                                                              | 635/9741 [00:02<00:31, 285.33it/s]  7%|█████▊                                                                              | 668/9741 [00:02<00:30, 297.55it/s]  7%|██████                                                                              | 702/9741 [00:02<00:29, 308.51it/s]  8%|██████▎                                                                             | 734/9741 [00:02<00:31, 288.04it/s]  8%|██████▌                                                                             | 764/9741 [00:02<00:31, 287.20it/s]  8%|██████▉                                                                             | 798/9741 [00:02<00:29, 299.70it/s]  9%|███████▏                                                                            | 832/9741 [00:02<00:28, 309.62it/s]  9%|███████▍                                                                            | 864/9741 [00:02<00:31, 285.30it/s]  9%|███████▋                                                                            | 894/9741 [00:02<00:31, 284.42it/s]  9%|███████▉                                                                            | 923/9741 [00:03<00:31, 282.31it/s] 10%|████████▎                                                                           | 957/9741 [00:03<00:29, 296.65it/s] 10%|████████▌                                                                           | 991/9741 [00:03<00:28, 307.87it/s] 11%|████████▋                                                                          | 1025/9741 [00:03<00:27, 316.35it/s] 11%|█████████                                                                          | 1059/9741 [00:03<00:26, 322.34it/s] 11%|█████████▎                                                                         | 1093/9741 [00:03<00:26, 324.90it/s] 12%|█████████▌                                                                         | 1127/9741 [00:03<00:26, 328.75it/s] 12%|█████████▉                                                                         | 1161/9741 [00:03<00:25, 331.55it/s] 12%|██████████▏                                                                        | 1195/9741 [00:03<00:25, 332.96it/s] 13%|██████████▍                                                                        | 1229/9741 [00:03<00:25, 333.46it/s] 13%|██████████▊                                                                        | 1263/9741 [00:04<00:25, 334.62it/s] 13%|███████████                                                                        | 1297/9741 [00:04<00:25, 334.83it/s] 14%|███████████▎                                                                       | 1331/9741 [00:04<00:25, 333.45it/s] 14%|███████████▋                                                                       | 1365/9741 [00:04<00:25, 334.08it/s] 14%|███████████▉                                                                       | 1399/9741 [00:04<00:24, 334.38it/s] 15%|████████████▏                                                                      | 1433/9741 [00:04<00:24, 334.34it/s] 15%|████████████▍                                                                      | 1467/9741 [00:04<00:24, 334.59it/s] 15%|████████████▊                                                                      | 1501/9741 [00:04<00:24, 334.56it/s] 16%|█████████████▏                                                                     | 1549/9741 [00:04<00:21, 377.20it/s] 16%|█████████████▌                                                                     | 1597/9741 [00:04<00:20, 406.30it/s] 17%|█████████████▉                                                                     | 1638/9741 [00:05<00:19, 405.49it/s] 17%|██████████████▎                                                                    | 1686/9741 [00:05<00:18, 425.27it/s] 18%|██████████████▊                                                                    | 1734/9741 [00:05<00:18, 439.49it/s] 18%|███████████████▏                                                                   | 1778/9741 [00:05<00:19, 404.04it/s] 19%|███████████████▌                                                                   | 1825/9741 [00:05<00:18, 422.10it/s] 19%|███████████████▉                                                                   | 1872/9741 [00:05<00:18, 434.62it/s] 20%|████████████████▎                                                                  | 1919/9741 [00:05<00:17, 444.79it/s] 20%|████████████████▊                                                                  | 1967/9741 [00:05<00:17, 452.77it/s] 21%|█████████████████▏                                                                 | 2014/9741 [00:05<00:16, 456.14it/s] 21%|█████████████████▌                                                                 | 2062/9741 [00:05<00:16, 460.66it/s] 22%|█████████████████▉                                                                 | 2110/9741 [00:06<00:16, 463.54it/s] 22%|██████████████████▍                                                                | 2157/9741 [00:06<00:16, 465.19it/s] 23%|██████████████████▊                                                                | 2204/9741 [00:06<00:16, 465.16it/s] 23%|███████████████████▏                                                               | 2251/9741 [00:06<00:16, 463.26it/s] 24%|███████████████████▌                                                               | 2299/9741 [00:06<00:15, 465.75it/s] 24%|███████████████████▉                                                               | 2346/9741 [00:06<00:15, 465.94it/s] 25%|████████████████████▍                                                              | 2393/9741 [00:06<00:15, 466.99it/s] 25%|████████████████████▊                                                              | 2440/9741 [00:06<00:15, 463.50it/s] 26%|█████████████████████▏                                                             | 2487/9741 [00:06<00:15, 460.59it/s] 26%|█████████████████████▌                                                             | 2534/9741 [00:06<00:15, 453.58it/s] 26%|█████████████████████▉                                                             | 2581/9741 [00:07<00:15, 457.30it/s] 27%|██████████████████████▍                                                            | 2628/9741 [00:07<00:15, 460.23it/s] 27%|██████████████████████▊                                                            | 2675/9741 [00:07<00:15, 459.89it/s] 28%|███████████████████████▏                                                           | 2722/9741 [00:07<00:15, 462.53it/s] 28%|███████████████████████▌                                                           | 2769/9741 [00:07<00:15, 464.10it/s] 29%|███████████████████████▉                                                           | 2816/9741 [00:07<00:14, 463.32it/s] 29%|████████████████████████▍                                                          | 2863/9741 [00:07<00:14, 462.15it/s] 30%|████████████████████████▊                                                          | 2910/9741 [00:07<00:14, 457.54it/s] 30%|█████████████████████████▏                                                         | 2956/9741 [00:07<00:14, 457.42it/s] 31%|█████████████████████████▌                                                         | 3002/9741 [00:08<00:14, 457.01it/s] 31%|█████████████████████████▉                                                         | 3048/9741 [00:08<00:14, 453.76it/s] 32%|██████████████████████████▎                                                        | 3094/9741 [00:08<00:14, 451.25it/s] 32%|██████████████████████████▊                                                        | 3140/9741 [00:08<00:14, 449.39it/s] 33%|███████████████████████████▏                                                       | 3186/9741 [00:08<00:14, 449.91it/s] 33%|███████████████████████████▌                                                       | 3232/9741 [00:08<00:14, 450.99it/s] 34%|███████████████████████████▉                                                       | 3278/9741 [00:08<00:14, 451.71it/s] 34%|████████████████████████████▎                                                      | 3324/9741 [00:08<00:14, 453.56it/s] 35%|████████████████████████████▋                                                      | 3370/9741 [00:08<00:14, 449.68it/s] 35%|█████████████████████████████                                                      | 3416/9741 [00:08<00:14, 451.07it/s] 36%|█████████████████████████████▍                                                     | 3462/9741 [00:09<00:13, 452.26it/s] 36%|█████████████████████████████▉                                                     | 3508/9741 [00:09<00:13, 451.86it/s] 36%|██████████████████████████████▎                                                    | 3554/9741 [00:09<00:13, 452.95it/s] 37%|██████████████████████████████▋                                                    | 3600/9741 [00:09<00:13, 452.90it/s] 37%|███████████████████████████████                                                    | 3647/9741 [00:09<00:13, 455.40it/s] 38%|███████████████████████████████▍                                                   | 3693/9741 [00:09<00:13, 451.02it/s] 38%|███████████████████████████████▊                                                   | 3740/9741 [00:09<00:13, 455.26it/s] 39%|████████████████████████████████▎                                                  | 3787/9741 [00:09<00:13, 457.27it/s] 39%|████████████████████████████████▋                                                  | 3833/9741 [00:09<00:12, 454.84it/s] 40%|█████████████████████████████████                                                  | 3880/9741 [00:09<00:12, 456.53it/s] 40%|█████████████████████████████████▍                                                 | 3926/9741 [00:10<00:12, 455.85it/s] 41%|█████████████████████████████████▊                                                 | 3973/9741 [00:10<00:12, 457.95it/s] 41%|██████████████████████████████████▏                                                | 4019/9741 [00:10<00:12, 457.19it/s] 42%|██████████████████████████████████▋                                                | 4065/9741 [00:10<00:12, 456.54it/s] 42%|███████████████████████████████████                                                | 4112/9741 [00:10<00:12, 458.83it/s] 43%|███████████████████████████████████▍                                               | 4158/9741 [00:10<00:12, 458.11it/s] 43%|███████████████████████████████████▊                                               | 4205/9741 [00:10<00:12, 460.67it/s] 44%|████████████████████████████████████▏                                              | 4252/9741 [00:10<00:11, 461.30it/s] 44%|████████████████████████████████████▋                                              | 4299/9741 [00:10<00:11, 459.65it/s] 45%|█████████████████████████████████████                                              | 4345/9741 [00:10<00:11, 458.59it/s] 45%|█████████████████████████████████████▍                                             | 4391/9741 [00:11<00:11, 458.27it/s] 46%|█████████████████████████████████████▊                                             | 4437/9741 [00:11<00:11, 458.68it/s] 46%|██████████████████████████████████████▏                                            | 4483/9741 [00:11<00:12, 418.94it/s] 46%|██████████████████████████████████████▌                                            | 4529/9741 [00:11<00:12, 429.60it/s] 47%|██████████████████████████████████████▉                                            | 4576/9741 [00:11<00:11, 439.16it/s] 47%|███████████████████████████████████████▍                                           | 4622/9741 [00:11<00:11, 444.12it/s] 48%|███████████████████████████████████████▊                                           | 4669/9741 [00:11<00:11, 449.33it/s] 48%|████████████████████████████████████████▏                                          | 4715/9741 [00:11<00:15, 317.78it/s] 49%|████████████████████████████████████████▌                                          | 4761/9741 [00:12<00:14, 349.54it/s] 49%|████████████████████████████████████████▉                                          | 4807/9741 [00:12<00:13, 375.79it/s] 50%|█████████████████████████████████████████▎                                         | 4853/9741 [00:12<00:12, 396.50it/s] 50%|█████████████████████████████████████████▋                                         | 4898/9741 [00:12<00:11, 410.42it/s] 51%|██████████████████████████████████████████▏                                        | 4944/9741 [00:12<00:11, 422.03it/s] 51%|██████████████████████████████████████████▌                                        | 4990/9741 [00:12<00:10, 432.38it/s] 52%|██████████████████████████████████████████▉                                        | 5036/9741 [00:12<00:10, 440.05it/s] 52%|███████████████████████████████████████████▎                                       | 5082/9741 [00:12<00:10, 445.83it/s] 53%|███████████████████████████████████████████▋                                       | 5128/9741 [00:12<00:10, 449.97it/s] 53%|████████████████████████████████████████████                                       | 5174/9741 [00:12<00:10, 449.92it/s] 54%|████████████████████████████████████████████▍                                      | 5221/9741 [00:13<00:09, 453.04it/s] 54%|████████████████████████████████████████████▉                                      | 5268/9741 [00:13<00:09, 455.39it/s] 55%|█████████████████████████████████████████████▎                                     | 5314/9741 [00:13<00:09, 455.85it/s] 55%|█████████████████████████████████████████████▋                                     | 5361/9741 [00:13<00:09, 457.43it/s] 56%|██████████████████████████████████████████████                                     | 5407/9741 [00:13<00:09, 456.78it/s] 56%|██████████████████████████████████████████████▍                                    | 5453/9741 [00:13<00:09, 457.22it/s] 56%|██████████████████████████████████████████████▊                                    | 5500/9741 [00:13<00:09, 458.13it/s] 57%|███████████████████████████████████████████████▎                                   | 5546/9741 [00:13<00:09, 457.64it/s] 57%|███████████████████████████████████████████████▋                                   | 5592/9741 [00:13<00:09, 458.04it/s] 58%|████████████████████████████████████████████████                                   | 5638/9741 [00:13<00:08, 456.22it/s] 58%|████████████████████████████████████████████████▍                                  | 5684/9741 [00:14<00:08, 457.27it/s] 59%|████████████████████████████████████████████████▊                                  | 5731/9741 [00:14<00:08, 458.78it/s] 59%|█████████████████████████████████████████████████▏                                 | 5777/9741 [00:14<00:08, 451.55it/s] 60%|█████████████████████████████████████████████████▌                                 | 5823/9741 [00:14<00:08, 450.16it/s] 60%|██████████████████████████████████████████████████                                 | 5870/9741 [00:14<00:08, 453.52it/s] 61%|██████████████████████████████████████████████████▍                                | 5916/9741 [00:14<00:08, 455.02it/s] 61%|██████████████████████████████████████████████████▊                                | 5962/9741 [00:14<00:08, 456.31it/s] 62%|███████████████████████████████████████████████████▏                               | 6008/9741 [00:14<00:08, 456.16it/s] 62%|███████████████████████████████████████████████████▌                               | 6054/9741 [00:14<00:08, 454.89it/s] 63%|███████████████████████████████████████████████████▉                               | 6100/9741 [00:14<00:08, 454.70it/s] 63%|████████████████████████████████████████████████████▎                              | 6146/9741 [00:15<00:07, 455.73it/s] 64%|████████████████████████████████████████████████████▊                              | 6192/9741 [00:15<00:07, 456.53it/s] 64%|█████████████████████████████████████████████████████▏                             | 6238/9741 [00:15<00:07, 456.58it/s] 65%|█████████████████████████████████████████████████████▌                             | 6284/9741 [00:15<00:07, 455.39it/s] 65%|█████████████████████████████████████████████████████▉                             | 6330/9741 [00:15<00:07, 455.52it/s] 65%|██████████████████████████████████████████████████████▎                            | 6376/9741 [00:15<00:07, 455.64it/s] 66%|██████████████████████████████████████████████████████▋                            | 6423/9741 [00:15<00:07, 457.52it/s] 66%|███████████████████████████████████████████████████████                            | 6469/9741 [00:15<00:07, 457.18it/s] 67%|███████████████████████████████████████████████████████▌                           | 6515/9741 [00:15<00:07, 454.61it/s] 67%|███████████████████████████████████████████████████████▉                           | 6561/9741 [00:15<00:06, 454.32it/s] 68%|████████████████████████████████████████████████████████▎                          | 6607/9741 [00:16<00:06, 451.38it/s] 68%|████████████████████████████████████████████████████████▋                          | 6653/9741 [00:16<00:06, 452.31it/s] 69%|█████████████████████████████████████████████████████████                          | 6700/9741 [00:16<00:06, 454.80it/s] 69%|█████████████████████████████████████████████████████████▍                         | 6746/9741 [00:16<00:06, 454.13it/s] 70%|█████████████████████████████████████████████████████████▊                         | 6792/9741 [00:16<00:06, 453.53it/s] 70%|██████████████████████████████████████████████████████████▎                        | 6838/9741 [00:16<00:06, 454.11it/s] 71%|██████████████████████████████████████████████████████████▋                        | 6884/9741 [00:16<00:06, 455.27it/s] 71%|███████████████████████████████████████████████████████████                        | 6930/9741 [00:16<00:06, 455.80it/s] 72%|███████████████████████████████████████████████████████████▍                       | 6976/9741 [00:16<00:06, 452.58it/s] 72%|███████████████████████████████████████████████████████████▊                       | 7022/9741 [00:17<00:06, 452.11it/s] 73%|████████████████████████████████████████████████████████████▏                      | 7068/9741 [00:17<00:05, 454.31it/s] 73%|████████████████████████████████████████████████████████████▌                      | 7115/9741 [00:17<00:05, 456.47it/s] 74%|█████████████████████████████████████████████████████████████                      | 7162/9741 [00:17<00:05, 457.78it/s] 74%|█████████████████████████████████████████████████████████████▍                     | 7208/9741 [00:17<00:05, 456.45it/s] 74%|█████████████████████████████████████████████████████████████▊                     | 7255/9741 [00:17<00:05, 457.99it/s] 75%|██████████████████████████████████████████████████████████████▏                    | 7302/9741 [00:17<00:05, 458.98it/s] 75%|██████████████████████████████████████████████████████████████▌                    | 7349/9741 [00:17<00:05, 460.91it/s] 76%|███████████████████████████████████████████████████████████████                    | 7396/9741 [00:17<00:05, 461.13it/s] 76%|███████████████████████████████████████████████████████████████▍                   | 7443/9741 [00:17<00:05, 427.55it/s] 77%|███████████████████████████████████████████████████████████████▊                   | 7489/9741 [00:18<00:05, 434.98it/s] 77%|████████████████████████████████████████████████████████████████▏                  | 7535/9741 [00:18<00:05, 441.07it/s] 78%|████████████████████████████████████████████████████████████████▌                  | 7581/9741 [00:18<00:04, 446.30it/s] 78%|████████████████████████████████████████████████████████████████▉                  | 7627/9741 [00:18<00:04, 449.53it/s] 79%|█████████████████████████████████████████████████████████████████▍                 | 7673/9741 [00:18<00:04, 450.62it/s] 79%|█████████████████████████████████████████████████████████████████▊                 | 7719/9741 [00:18<00:04, 446.91it/s] 80%|██████████████████████████████████████████████████████████████████▏                | 7765/9741 [00:18<00:04, 450.68it/s] 80%|██████████████████████████████████████████████████████████████████▌                | 7812/9741 [00:18<00:04, 453.81it/s] 81%|██████████████████████████████████████████████████████████████████▉                | 7858/9741 [00:18<00:04, 455.24it/s] 81%|███████████████████████████████████████████████████████████████████▎               | 7904/9741 [00:18<00:04, 452.95it/s] 82%|███████████████████████████████████████████████████████████████████▋               | 7950/9741 [00:19<00:03, 453.06it/s] 82%|████████████████████████████████████████████████████████████████████▏              | 7996/9741 [00:19<00:03, 452.47it/s] 83%|████████████████████████████████████████████████████████████████████▌              | 8042/9741 [00:19<00:03, 453.17it/s] 83%|████████████████████████████████████████████████████████████████████▉              | 8088/9741 [00:19<00:03, 454.01it/s] 84%|█████████████████████████████████████████████████████████████████████▎             | 8134/9741 [00:19<00:03, 453.66it/s] 84%|█████████████████████████████████████████████████████████████████████▋             | 8180/9741 [00:19<00:03, 455.35it/s] 84%|██████████████████████████████████████████████████████████████████████             | 8227/9741 [00:19<00:03, 456.95it/s] 85%|██████████████████████████████████████████████████████████████████████▍            | 8273/9741 [00:19<00:03, 457.18it/s] 85%|██████████████████████████████████████████████████████████████████████▉            | 8319/9741 [00:19<00:03, 455.67it/s] 86%|███████████████████████████████████████████████████████████████████████▎           | 8366/9741 [00:19<00:03, 457.11it/s] 86%|███████████████████████████████████████████████████████████████████████▋           | 8412/9741 [00:20<00:02, 457.03it/s] 87%|████████████████████████████████████████████████████████████████████████           | 8458/9741 [00:20<00:02, 454.48it/s] 87%|████████████████████████████████████████████████████████████████████████▍          | 8504/9741 [00:20<00:02, 451.88it/s] 88%|████████████████████████████████████████████████████████████████████████▊          | 8550/9741 [00:20<00:02, 451.12it/s] 88%|█████████████████████████████████████████████████████████████████████████▏         | 8596/9741 [00:20<00:02, 451.89it/s] 89%|█████████████████████████████████████████████████████████████████████████▋         | 8642/9741 [00:20<00:02, 451.79it/s] 89%|██████████████████████████████████████████████████████████████████████████         | 8688/9741 [00:20<00:02, 453.39it/s] 90%|██████████████████████████████████████████████████████████████████████████▍        | 8734/9741 [00:20<00:02, 454.69it/s] 90%|██████████████████████████████████████████████████████████████████████████▊        | 8780/9741 [00:20<00:02, 453.54it/s] 91%|███████████████████████████████████████████████████████████████████████████▏       | 8826/9741 [00:20<00:02, 449.74it/s] 91%|███████████████████████████████████████████████████████████████████████████▌       | 8872/9741 [00:21<00:01, 451.91it/s] 92%|███████████████████████████████████████████████████████████████████████████▉       | 8918/9741 [00:21<00:01, 453.63it/s] 92%|████████████████████████████████████████████████████████████████████████████▍      | 8964/9741 [00:21<00:01, 454.01it/s] 92%|████████████████████████████████████████████████████████████████████████████▊      | 9010/9741 [00:21<00:01, 452.97it/s] 93%|█████████████████████████████████████████████████████████████████████████████▏     | 9056/9741 [00:21<00:01, 453.71it/s] 93%|█████████████████████████████████████████████████████████████████████████████▌     | 9102/9741 [00:21<00:01, 454.77it/s] 94%|█████████████████████████████████████████████████████████████████████████████▉     | 9148/9741 [00:21<00:01, 455.02it/s] 94%|██████████████████████████████████████████████████████████████████████████████▎    | 9194/9741 [00:21<00:01, 455.58it/s] 95%|██████████████████████████████████████████████████████████████████████████████▋    | 9240/9741 [00:21<00:01, 454.21it/s] 95%|███████████████████████████████████████████████████████████████████████████████    | 9286/9741 [00:22<00:00, 455.61it/s] 96%|███████████████████████████████████████████████████████████████████████████████▌   | 9332/9741 [00:22<00:00, 455.84it/s] 96%|███████████████████████████████████████████████████████████████████████████████▉   | 9378/9741 [00:22<00:00, 456.30it/s] 97%|████████████████████████████████████████████████████████████████████████████████▎  | 9424/9741 [00:22<00:00, 454.79it/s] 97%|████████████████████████████████████████████████████████████████████████████████▋  | 9470/9741 [00:22<00:00, 450.44it/s] 98%|█████████████████████████████████████████████████████████████████████████████████  | 9516/9741 [00:22<00:00, 452.15it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▍ | 9562/9741 [00:22<00:00, 453.58it/s] 99%|█████████████████████████████████████████████████████████████████████████████████▊ | 9608/9741 [00:22<00:00, 455.26it/s] 99%|██████████████████████████████████████████████████████████████████████████████████▎| 9654/9741 [00:22<00:00, 455.94it/s]100%|██████████████████████████████████████████████████████████████████████████████████▋| 9700/9741 [00:22<00:00, 455.02it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:23<00:00, 423.34it/s]
Load End
Num instances: 1000
[2023-08-22 10:33:13,872] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 10:33:16,697] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 10:33:16,698] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 10:33:16,698] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 10:33:16,698] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 10:33:16,698] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 10:33:16,698] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fa68cf29a60>
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fa68cf29940>
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 10:33:16,699] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 10:33:16,700] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 10:33:16,700] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 10:33:16,700] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 10:33:16,700] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 10:33:16,700] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 10:33:16,700] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 10:33:16,700] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 10:33:16,700] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 10:33:16,700] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 10:33:16,700] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 10:33:16,700] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 10:33:16,700] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 10:33:16,700] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 10:33:16,700] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 10:33:16,700] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 10:33:16,700] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 10:33:16,700] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 10:33:16,700] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 10:33:16,700] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4308474063873291 seconds
Loading extension module utils...
Time to load utils op: 0.4048655033111572 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: For the nuts Adam paid 3 * $12 = $<<3*12=36>>36.
And for dried fruits Adam paid 2.5 * $8 = $<<2.5*8=20>>20.
So in total for his purchases Adam paid $36 + $20 = $<<36+20=56>>56.
So the final answer is 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: He spends 60/3=<<60/3=20>>20 minutes warming up
So he spends 60+20=<<60+20=80>>80 minutes at the gym per day
That means he spends 80*3=<<80*3=240>>240 minutes at the gym
So he spends 240/60=<<240/60=4>>4 hours at the gym a week
So the final answer is 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: The cost to fill a tank went up 200*.2=$<<200*.2=40>>40
So it cost 200+40=$<<200+40=240>>240 to fill the tank
That means he now pays 240*2=$<<240*2=480>>480
So the final answer is 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: If the total number of goals scored in the league that season against Barca is 300, the two players scored 20/100*300=<<300*20/100=60>>60 goals.
If the players scored an equal number of goals, each scored 60/2=<<60/2=30>>30 goals.
So the final answer is 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: He drinks 12 * 5 = <<12*5=60>>60 ounces of soda a day
So he drinks 60 + 64 = <<60+64=124>>124 ounces of liquid a day
So in total he drinks 124 * 7 = <<124*7=868>>868 ounces of liquid a week
So the final answer is 868

Input: Stella and Twinkle are filling up a truck with a capacity of 6000 stone blocks at the rate of 250 blocks per hour per person. They work for four hours and are then joined by 6 other people who also work at the same rate. How many hours did filling the truck take?
Output: Stella and Twinkle filled up the truck at the rate of 250 blocks per hour per person, a total of 2*250 = <<250*2=500>>500 blocks per hour for both.
After working for four hours, Stella and Twinkle had filled 4*500 = <<4*500=2000>>2000 blocks into the truck.
The number of blocks they had to put into the truck for it to be full is 6000-2000 = <<6000-2000=4000>>4000
When 6 more people joined Stella and Twinkle, a total of 2+6 = <<2+6=8>>8 people were filling the truck now.
Working at the rate of 250 blocks per person, the eight people filled the truck with 250*8 = <<250*8=2000>>2000 blocks in one hour.
If there were 4000 blocks that still needed to be put into the truck, the 8 people took 4000/2000 = <<4000/2000=2>>2 hours to fill the truck with the blocks.
The total time it took to fill up the tank is 4+2 = <<4+2=6>>6 hours.
So the final answer is 6

Input: Elijah drank 8.5 pints of coffee yesterday. Emilio drank 9.5 pints of water yesterday. How many cups of liquid did the two boys drink yesterday?
Output: Total drunk: 8.5 + 9.5 = <<8.5+9.5=18>>18 pints
18 pints * 2 = <<18*2=36>>36 cups
The two boys drank a total of 36 cups of liquid yesterday.
So the final answer is 36

Input: Doris works at the Widget Factory in the packing department. She puts 3 widgets in each carton, which are 4 inches wide, 4 inches long, and 5 inches tall. She then packs those cartons into a shipping box before sending it to the loading bay. The shipping boxes are 20 inches wide, 20 inches long, and 20 inches high. How many widgets get shipped in each shipping box?
Output: Each carton has an area of 4*4*5 = <<4*4*5=80>>80 square inches.
Each shipping box has an area of 20*20*20 = <<20*20*20=8000>>8000 square inches
The total number of cartons that will fit into each box is 8000/80 = <<8000/80=100>>100
Since there are 3 widgets in each carton, the total number of cartons in each box will be 3*100 = <<3*100=300>>300
So the final answer is 300

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o8-tgsm8k-s10-rTrue
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:35<28:43, 35.18s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:09<27:36, 34.52s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [01:43<26:54, 34.36s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [02:17<26:17, 34.30s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [02:51<25:41, 34.26s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [03:25<25:02, 34.15s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [04:00<24:39, 34.41s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [04:35<24:10, 34.54s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [05:11<23:55, 35.02s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [05:46<23:18, 34.97s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [06:24<23:22, 35.97s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [06:59<22:32, 35.59s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [07:33<21:44, 35.26s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [08:08<20:58, 34.97s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [08:43<20:22, 34.93s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [09:17<19:44, 34.83s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [09:51<19:03, 34.64s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [10:26<18:29, 34.67s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [11:00<17:50, 34.53s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [11:35<17:17, 34.57s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [12:10<16:44, 34.63s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [12:44<16:06, 34.51s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [13:19<15:33, 34.59s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [13:54<15:03, 34.77s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [14:30<14:42, 35.30s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [15:05<14:03, 35.15s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [15:40<13:24, 34.98s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [16:14<12:45, 34.81s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [16:49<12:12, 34.87s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [17:24<11:34, 34.75s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [17:58<10:58, 34.66s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [18:33<10:24, 34.67s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [19:07<09:49, 34.66s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [19:42<09:13, 34.61s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [20:17<08:41, 34.74s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [20:52<08:06, 34.77s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [21:27<07:34, 34.97s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [22:02<06:57, 34.76s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [22:36<06:21, 34.69s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [23:11<05:48, 34.83s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [23:46<05:14, 34.90s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [24:21<04:37, 34.74s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [24:56<04:03, 34.76s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [25:31<03:29, 34.83s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [26:05<02:53, 34.63s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [26:41<02:20, 35.18s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [27:17<01:46, 35.40s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [27:51<01:10, 35.09s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [28:26<00:34, 34.85s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [29:00<00:00, 34.76s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [29:00<00:00, 34.82s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.6484} | avg. gen lenth: 449.058
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o9-tgsm8k-s10-rTrue --seed 10 --max-prompt-length 2048 --rationales --num-out-domain 9
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 11:02:26,987] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o9-tgsm8k-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 9
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o9-tgsm8k-s10-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  0%|▎                                                                                    | 30/9741 [00:00<00:33, 293.92it/s]  1%|▌                                                                                    | 61/9741 [00:00<00:32, 298.65it/s]  1%|▊                                                                                    | 91/9741 [00:00<00:33, 291.78it/s]  1%|█                                                                                   | 122/9741 [00:00<00:32, 295.30it/s]  2%|█▎                                                                                  | 153/9741 [00:00<00:32, 297.61it/s]  2%|█▌                                                                                  | 183/9741 [00:00<00:32, 296.26it/s]  2%|█▊                                                                                  | 214/9741 [00:00<00:31, 297.83it/s]  3%|██                                                                                  | 245/9741 [00:00<00:31, 298.95it/s]  3%|██▍                                                                                 | 276/9741 [00:00<00:31, 300.03it/s]  3%|██▋                                                                                 | 307/9741 [00:01<00:31, 300.96it/s]  3%|██▉                                                                                 | 338/9741 [00:01<00:31, 301.01it/s]  4%|███▏                                                                                | 369/9741 [00:01<00:31, 300.62it/s]  4%|███▍                                                                                | 400/9741 [00:01<00:31, 299.35it/s]  4%|███▋                                                                                | 431/9741 [00:01<00:30, 300.51it/s]  5%|███▉                                                                                | 462/9741 [00:01<00:30, 300.55it/s]  5%|████▎                                                                               | 493/9741 [00:01<00:30, 301.00it/s]  5%|████▌                                                                               | 524/9741 [00:01<00:30, 300.69it/s]  6%|████▊                                                                               | 555/9741 [00:01<00:30, 300.88it/s]  6%|█████                                                                               | 586/9741 [00:01<00:30, 300.76it/s]  6%|█████▎                                                                              | 617/9741 [00:02<00:30, 300.61it/s]  7%|█████▌                                                                              | 648/9741 [00:02<00:30, 298.56it/s]  7%|█████▊                                                                              | 678/9741 [00:02<00:30, 298.68it/s]  7%|██████                                                                              | 708/9741 [00:02<00:30, 298.94it/s]  8%|██████▎                                                                             | 738/9741 [00:02<00:30, 299.00it/s]  8%|██████▌                                                                             | 768/9741 [00:02<00:30, 294.29it/s]  8%|██████▉                                                                             | 798/9741 [00:02<00:30, 295.69it/s]  9%|███████▏                                                                            | 834/9741 [00:02<00:28, 314.45it/s]  9%|███████▌                                                                            | 877/9741 [00:02<00:25, 348.68it/s]  9%|███████▉                                                                            | 921/9741 [00:02<00:23, 375.76it/s] 10%|████████▎                                                                           | 966/9741 [00:03<00:22, 395.95it/s] 10%|████████▌                                                                          | 1010/9741 [00:03<00:21, 408.31it/s] 11%|████████▉                                                                          | 1055/9741 [00:03<00:20, 418.48it/s] 11%|█████████▎                                                                         | 1099/9741 [00:03<00:20, 424.10it/s] 12%|█████████▋                                                                         | 1144/9741 [00:03<00:20, 429.17it/s] 12%|██████████▏                                                                        | 1189/9741 [00:03<00:19, 433.41it/s] 13%|██████████▌                                                                        | 1234/9741 [00:03<00:19, 436.12it/s] 13%|██████████▉                                                                        | 1278/9741 [00:03<00:19, 436.68it/s] 14%|███████████▎                                                                       | 1322/9741 [00:03<00:19, 435.32it/s] 14%|███████████▋                                                                       | 1366/9741 [00:03<00:19, 436.43it/s] 14%|████████████                                                                       | 1410/9741 [00:04<00:19, 437.34it/s] 15%|████████████▍                                                                      | 1455/9741 [00:04<00:18, 438.74it/s] 15%|████████████▊                                                                      | 1499/9741 [00:04<00:18, 437.92it/s] 16%|█████████████▏                                                                     | 1543/9741 [00:04<00:18, 436.65it/s] 16%|█████████████▌                                                                     | 1587/9741 [00:04<00:18, 436.68it/s] 17%|█████████████▉                                                                     | 1631/9741 [00:04<00:18, 437.60it/s] 17%|██████████████▎                                                                    | 1675/9741 [00:04<00:18, 438.09it/s] 18%|██████████████▋                                                                    | 1720/9741 [00:04<00:18, 439.20it/s] 18%|███████████████                                                                    | 1764/9741 [00:04<00:19, 418.32it/s] 19%|███████████████▍                                                                   | 1808/9741 [00:05<00:18, 423.84it/s] 19%|███████████████▊                                                                   | 1852/9741 [00:05<00:18, 426.86it/s] 19%|████████████████▏                                                                  | 1896/9741 [00:05<00:18, 428.50it/s] 20%|████████████████▌                                                                  | 1940/9741 [00:05<00:18, 429.65it/s] 20%|████████████████▉                                                                  | 1984/9741 [00:05<00:17, 431.26it/s] 21%|█████████████████▎                                                                 | 2028/9741 [00:05<00:17, 431.61it/s] 21%|█████████████████▋                                                                 | 2072/9741 [00:05<00:17, 427.41it/s] 22%|██████████████████                                                                 | 2116/9741 [00:05<00:17, 428.70it/s] 22%|██████████████████▍                                                                | 2160/9741 [00:05<00:17, 429.93it/s] 23%|██████████████████▊                                                                | 2204/9741 [00:05<00:17, 430.08it/s] 23%|███████████████████▏                                                               | 2248/9741 [00:06<00:17, 427.57it/s] 24%|███████████████████▌                                                               | 2292/9741 [00:06<00:17, 429.60it/s] 24%|███████████████████▉                                                               | 2336/9741 [00:06<00:17, 431.59it/s] 24%|████████████████████▎                                                              | 2380/9741 [00:06<00:16, 433.28it/s] 25%|████████████████████▋                                                              | 2424/9741 [00:06<00:16, 434.30it/s] 25%|█████████████████████                                                              | 2468/9741 [00:06<00:16, 432.00it/s] 26%|█████████████████████▍                                                             | 2512/9741 [00:06<00:16, 433.06it/s] 26%|█████████████████████▊                                                             | 2556/9741 [00:06<00:16, 433.36it/s] 27%|██████████████████████▏                                                            | 2600/9741 [00:06<00:16, 434.47it/s] 27%|██████████████████████▌                                                            | 2644/9741 [00:06<00:16, 434.74it/s] 28%|██████████████████████▉                                                            | 2688/9741 [00:07<00:16, 432.89it/s] 28%|███████████████████████▎                                                           | 2732/9741 [00:07<00:16, 433.28it/s] 28%|███████████████████████▋                                                           | 2776/9741 [00:07<00:16, 432.41it/s] 29%|████████████████████████                                                           | 2820/9741 [00:07<00:16, 431.09it/s] 29%|████████████████████████▍                                                          | 2864/9741 [00:07<00:15, 431.11it/s] 30%|████████████████████████▊                                                          | 2908/9741 [00:07<00:15, 429.72it/s] 30%|█████████████████████████▏                                                         | 2952/9741 [00:07<00:15, 429.96it/s] 31%|█████████████████████████▌                                                         | 2995/9741 [00:07<00:15, 429.89it/s] 31%|█████████████████████████▉                                                         | 3039/9741 [00:07<00:15, 430.42it/s] 32%|██████████████████████████▎                                                        | 3083/9741 [00:07<00:15, 430.46it/s] 32%|██████████████████████████▋                                                        | 3127/9741 [00:08<00:15, 428.50it/s] 33%|███████████████████████████                                                        | 3171/9741 [00:08<00:15, 428.98it/s] 33%|███████████████████████████▍                                                       | 3215/9741 [00:08<00:15, 430.20it/s] 33%|███████████████████████████▊                                                       | 3259/9741 [00:08<00:15, 429.31it/s] 34%|████████████████████████████▏                                                      | 3302/9741 [00:08<00:15, 427.31it/s] 34%|████████████████████████████▌                                                      | 3345/9741 [00:08<00:14, 427.46it/s] 35%|████████████████████████████▊                                                      | 3388/9741 [00:08<00:14, 426.15it/s] 35%|█████████████████████████████▏                                                     | 3431/9741 [00:08<00:14, 426.91it/s] 36%|█████████████████████████████▌                                                     | 3474/9741 [00:08<00:14, 426.73it/s] 36%|█████████████████████████████▉                                                     | 3517/9741 [00:08<00:14, 426.91it/s] 37%|██████████████████████████████▎                                                    | 3560/9741 [00:09<00:14, 424.96it/s] 37%|██████████████████████████████▋                                                    | 3603/9741 [00:09<00:14, 422.57it/s] 37%|███████████████████████████████                                                    | 3646/9741 [00:09<00:14, 424.54it/s] 38%|███████████████████████████████▍                                                   | 3689/9741 [00:09<00:14, 425.22it/s] 38%|███████████████████████████████▊                                                   | 3733/9741 [00:09<00:14, 427.16it/s] 39%|████████████████████████████████▏                                                  | 3776/9741 [00:09<00:13, 427.16it/s] 39%|████████████████████████████████▌                                                  | 3819/9741 [00:09<00:13, 423.77it/s] 40%|████████████████████████████████▉                                                  | 3862/9741 [00:09<00:13, 423.16it/s] 40%|█████████████████████████████████▎                                                 | 3905/9741 [00:09<00:13, 424.51it/s] 41%|█████████████████████████████████▋                                                 | 3948/9741 [00:09<00:13, 426.01it/s] 41%|██████████████████████████████████                                                 | 3991/9741 [00:10<00:13, 426.57it/s] 41%|██████████████████████████████████▎                                                | 4034/9741 [00:10<00:13, 425.41it/s] 42%|██████████████████████████████████▋                                                | 4077/9741 [00:10<00:13, 425.34it/s] 42%|███████████████████████████████████                                                | 4120/9741 [00:10<00:13, 424.83it/s] 43%|███████████████████████████████████▍                                               | 4163/9741 [00:10<00:13, 424.77it/s] 43%|███████████████████████████████████▊                                               | 4206/9741 [00:10<00:13, 424.56it/s] 44%|████████████████████████████████████▏                                              | 4249/9741 [00:10<00:12, 424.39it/s] 44%|████████████████████████████████████▌                                              | 4292/9741 [00:10<00:12, 421.64it/s] 45%|████████████████████████████████████▉                                              | 4335/9741 [00:10<00:12, 420.08it/s] 45%|█████████████████████████████████████▎                                             | 4378/9741 [00:11<00:12, 419.93it/s] 45%|█████████████████████████████████████▋                                             | 4421/9741 [00:11<00:12, 420.79it/s] 46%|██████████████████████████████████████                                             | 4464/9741 [00:11<00:12, 418.29it/s] 46%|██████████████████████████████████████▍                                            | 4506/9741 [00:11<00:13, 394.15it/s] 47%|██████████████████████████████████████▊                                            | 4548/9741 [00:11<00:12, 400.84it/s] 47%|███████████████████████████████████████                                            | 4590/9741 [00:11<00:12, 404.74it/s] 48%|███████████████████████████████████████▍                                           | 4633/9741 [00:11<00:12, 410.17it/s] 48%|███████████████████████████████████████▊                                           | 4676/9741 [00:11<00:12, 413.96it/s] 48%|████████████████████████████████████████▏                                          | 4718/9741 [00:11<00:15, 323.97it/s] 49%|████████████████████████████████████████▌                                          | 4761/9741 [00:12<00:14, 348.64it/s] 49%|████████████████████████████████████████▉                                          | 4802/9741 [00:12<00:13, 364.37it/s] 50%|█████████████████████████████████████████▎                                         | 4844/9741 [00:12<00:12, 377.76it/s] 50%|█████████████████████████████████████████▋                                         | 4886/9741 [00:12<00:12, 389.20it/s] 51%|█████████████████████████████████████████▉                                         | 4928/9741 [00:12<00:12, 395.61it/s] 51%|██████████████████████████████████████████▎                                        | 4970/9741 [00:12<00:11, 402.51it/s] 51%|██████████████████████████████████████████▋                                        | 5013/9741 [00:12<00:11, 409.07it/s] 52%|███████████████████████████████████████████                                        | 5055/9741 [00:12<00:11, 412.26it/s] 52%|███████████████████████████████████████████▍                                       | 5098/9741 [00:12<00:11, 415.83it/s] 53%|███████████████████████████████████████████▊                                       | 5140/9741 [00:12<00:11, 416.40it/s] 53%|████████████████████████████████████████████▏                                      | 5183/9741 [00:13<00:10, 418.39it/s] 54%|████████████████████████████████████████████▌                                      | 5226/9741 [00:13<00:10, 420.08it/s] 54%|████████████████████████████████████████████▉                                      | 5269/9741 [00:13<00:10, 418.03it/s] 55%|█████████████████████████████████████████████▎                                     | 5311/9741 [00:13<00:10, 414.13it/s] 55%|█████████████████████████████████████████████▌                                     | 5353/9741 [00:13<00:10, 414.08it/s] 55%|█████████████████████████████████████████████▉                                     | 5395/9741 [00:13<00:10, 414.12it/s] 56%|██████████████████████████████████████████████▎                                    | 5438/9741 [00:13<00:10, 416.63it/s] 56%|██████████████████████████████████████████████▋                                    | 5481/9741 [00:13<00:10, 418.13it/s] 57%|███████████████████████████████████████████████                                    | 5523/9741 [00:13<00:10, 412.99it/s] 57%|███████████████████████████████████████████████▍                                   | 5566/9741 [00:13<00:10, 415.32it/s] 58%|███████████████████████████████████████████████▊                                   | 5608/9741 [00:14<00:09, 413.84it/s] 58%|████████████████████████████████████████████████▏                                  | 5651/9741 [00:14<00:09, 415.90it/s] 58%|████████████████████████████████████████████████▌                                  | 5694/9741 [00:14<00:09, 417.68it/s] 59%|████████████████████████████████████████████████▉                                  | 5737/9741 [00:14<00:09, 418.76it/s] 59%|█████████████████████████████████████████████████▏                                 | 5779/9741 [00:14<00:09, 419.05it/s] 60%|█████████████████████████████████████████████████▌                                 | 5821/9741 [00:14<00:09, 417.31it/s] 60%|█████████████████████████████████████████████████▉                                 | 5863/9741 [00:14<00:09, 417.71it/s] 61%|██████████████████████████████████████████████████▎                                | 5906/9741 [00:14<00:09, 418.46it/s] 61%|██████████████████████████████████████████████████▋                                | 5949/9741 [00:14<00:09, 419.95it/s] 62%|███████████████████████████████████████████████████                                | 5992/9741 [00:14<00:08, 420.68it/s] 62%|███████████████████████████████████████████████████▍                               | 6035/9741 [00:15<00:08, 421.54it/s] 62%|███████████████████████████████████████████████████▊                               | 6078/9741 [00:15<00:08, 420.26it/s] 63%|████████████████████████████████████████████████████▏                              | 6121/9741 [00:15<00:08, 420.84it/s] 63%|████████████████████████████████████████████████████▌                              | 6164/9741 [00:15<00:08, 421.40it/s] 64%|████████████████████████████████████████████████████▉                              | 6207/9741 [00:15<00:08, 421.99it/s] 64%|█████████████████████████████████████████████████████▎                             | 6250/9741 [00:15<00:08, 420.90it/s] 65%|█████████████████████████████████████████████████████▌                             | 6293/9741 [00:15<00:08, 418.51it/s] 65%|█████████████████████████████████████████████████████▉                             | 6336/9741 [00:15<00:08, 419.74it/s] 65%|██████████████████████████████████████████████████████▎                            | 6379/9741 [00:15<00:07, 420.53it/s] 66%|██████████████████████████████████████████████████████▋                            | 6422/9741 [00:16<00:07, 421.46it/s] 66%|███████████████████████████████████████████████████████                            | 6465/9741 [00:16<00:07, 418.20it/s] 67%|███████████████████████████████████████████████████████▍                           | 6507/9741 [00:16<00:07, 417.16it/s] 67%|███████████████████████████████████████████████████████▊                           | 6550/9741 [00:16<00:07, 418.87it/s] 68%|████████████████████████████████████████████████████████▏                          | 6593/9741 [00:16<00:07, 419.79it/s] 68%|████████████████████████████████████████████████████████▌                          | 6636/9741 [00:16<00:07, 420.21it/s] 69%|████████████████████████████████████████████████████████▉                          | 6679/9741 [00:16<00:07, 416.92it/s] 69%|█████████████████████████████████████████████████████████▎                         | 6721/9741 [00:16<00:07, 414.43it/s] 69%|█████████████████████████████████████████████████████████▋                         | 6763/9741 [00:16<00:07, 412.28it/s] 70%|█████████████████████████████████████████████████████████▉                         | 6805/9741 [00:16<00:07, 412.35it/s] 70%|██████████████████████████████████████████████████████████▎                        | 6847/9741 [00:17<00:07, 411.67it/s] 71%|██████████████████████████████████████████████████████████▋                        | 6889/9741 [00:17<00:06, 411.80it/s] 71%|███████████████████████████████████████████████████████████                        | 6931/9741 [00:17<00:06, 411.66it/s] 72%|███████████████████████████████████████████████████████████▍                       | 6973/9741 [00:17<00:06, 409.97it/s] 72%|███████████████████████████████████████████████████████████▊                       | 7015/9741 [00:17<00:06, 410.27it/s] 72%|████████████████████████████████████████████████████████████▏                      | 7057/9741 [00:17<00:06, 410.72it/s] 73%|████████████████████████████████████████████████████████████▍                      | 7099/9741 [00:17<00:06, 411.02it/s] 73%|████████████████████████████████████████████████████████████▊                      | 7141/9741 [00:17<00:06, 410.64it/s] 74%|█████████████████████████████████████████████████████████████▏                     | 7183/9741 [00:17<00:06, 408.63it/s] 74%|█████████████████████████████████████████████████████████████▌                     | 7225/9741 [00:17<00:06, 409.65it/s] 75%|█████████████████████████████████████████████████████████████▉                     | 7267/9741 [00:18<00:06, 410.13it/s] 75%|██████████████████████████████████████████████████████████████▎                    | 7309/9741 [00:18<00:05, 410.58it/s] 75%|██████████████████████████████████████████████████████████████▋                    | 7351/9741 [00:18<00:05, 410.78it/s] 76%|██████████████████████████████████████████████████████████████▉                    | 7393/9741 [00:18<00:05, 411.11it/s] 76%|███████████████████████████████████████████████████████████████▎                   | 7435/9741 [00:18<00:06, 382.88it/s] 77%|███████████████████████████████████████████████████████████████▋                   | 7476/9741 [00:18<00:05, 390.47it/s] 77%|████████████████████████████████████████████████████████████████                   | 7518/9741 [00:18<00:05, 396.36it/s] 78%|████████████████████████████████████████████████████████████████▍                  | 7559/9741 [00:18<00:05, 399.91it/s] 78%|████████████████████████████████████████████████████████████████▊                  | 7600/9741 [00:18<00:05, 402.85it/s] 78%|█████████████████████████████████████████████████████████████████                  | 7641/9741 [00:19<00:05, 397.50it/s] 79%|█████████████████████████████████████████████████████████████████▍                 | 7683/9741 [00:19<00:05, 401.45it/s] 79%|█████████████████████████████████████████████████████████████████▊                 | 7725/9741 [00:19<00:04, 404.73it/s] 80%|██████████████████████████████████████████████████████████████████▏                | 7767/9741 [00:19<00:04, 406.88it/s] 80%|██████████████████████████████████████████████████████████████████▌                | 7809/9741 [00:19<00:04, 408.35it/s] 81%|██████████████████████████████████████████████████████████████████▉                | 7851/9741 [00:19<00:04, 409.05it/s] 81%|███████████████████████████████████████████████████████████████████▏               | 7892/9741 [00:19<00:04, 407.78it/s] 81%|███████████████████████████████████████████████████████████████████▌               | 7934/9741 [00:19<00:04, 409.57it/s] 82%|███████████████████████████████████████████████████████████████████▉               | 7976/9741 [00:19<00:04, 411.16it/s] 82%|████████████████████████████████████████████████████████████████████▎              | 8018/9741 [00:19<00:04, 412.21it/s] 83%|████████████████████████████████████████████████████████████████████▋              | 8060/9741 [00:20<00:04, 413.07it/s] 83%|█████████████████████████████████████████████████████████████████████              | 8102/9741 [00:20<00:03, 412.50it/s] 84%|█████████████████████████████████████████████████████████████████████▍             | 8144/9741 [00:20<00:03, 414.26it/s] 84%|█████████████████████████████████████████████████████████████████████▊             | 8186/9741 [00:20<00:03, 415.88it/s] 84%|██████████████████████████████████████████████████████████████████████             | 8228/9741 [00:20<00:03, 416.83it/s] 85%|██████████████████████████████████████████████████████████████████████▍            | 8270/9741 [00:20<00:03, 417.27it/s] 85%|██████████████████████████████████████████████████████████████████████▊            | 8313/9741 [00:20<00:03, 418.40it/s] 86%|███████████████████████████████████████████████████████████████████████▏           | 8355/9741 [00:20<00:03, 417.39it/s] 86%|███████████████████████████████████████████████████████████████████████▌           | 8398/9741 [00:20<00:03, 418.65it/s] 87%|███████████████████████████████████████████████████████████████████████▉           | 8440/9741 [00:20<00:03, 417.37it/s] 87%|████████████████████████████████████████████████████████████████████████▎          | 8482/9741 [00:21<00:03, 417.22it/s] 88%|████████████████████████████████████████████████████████████████████████▋          | 8524/9741 [00:21<00:02, 417.20it/s] 88%|████████████████████████████████████████████████████████████████████████▉          | 8566/9741 [00:21<00:02, 416.57it/s] 88%|█████████████████████████████████████████████████████████████████████████▎         | 8609/9741 [00:21<00:02, 418.42it/s] 89%|█████████████████████████████████████████████████████████████████████████▋         | 8652/9741 [00:21<00:02, 419.73it/s] 89%|██████████████████████████████████████████████████████████████████████████         | 8695/9741 [00:21<00:02, 420.81it/s] 90%|██████████████████████████████████████████████████████████████████████████▍        | 8738/9741 [00:21<00:02, 421.53it/s] 90%|██████████████████████████████████████████████████████████████████████████▊        | 8781/9741 [00:21<00:02, 420.09it/s] 91%|███████████████████████████████████████████████████████████████████████████▏       | 8824/9741 [00:21<00:02, 418.70it/s] 91%|███████████████████████████████████████████████████████████████████████████▌       | 8866/9741 [00:21<00:02, 418.26it/s] 91%|███████████████████████████████████████████████████████████████████████████▉       | 8908/9741 [00:22<00:01, 416.60it/s] 92%|████████████████████████████████████████████████████████████████████████████▎      | 8950/9741 [00:22<00:01, 416.20it/s] 92%|████████████████████████████████████████████████████████████████████████████▋      | 8993/9741 [00:22<00:01, 417.72it/s] 93%|████████████████████████████████████████████████████████████████████████████▉      | 9035/9741 [00:22<00:01, 416.45it/s] 93%|█████████████████████████████████████████████████████████████████████████████▎     | 9078/9741 [00:22<00:01, 417.60it/s] 94%|█████████████████████████████████████████████████████████████████████████████▋     | 9121/9741 [00:22<00:01, 418.43it/s] 94%|██████████████████████████████████████████████████████████████████████████████     | 9164/9741 [00:22<00:01, 418.92it/s] 95%|██████████████████████████████████████████████████████████████████████████████▍    | 9207/9741 [00:22<00:01, 419.73it/s] 95%|██████████████████████████████████████████████████████████████████████████████▊    | 9249/9741 [00:22<00:01, 417.82it/s] 95%|███████████████████████████████████████████████████████████████████████████████▏   | 9292/9741 [00:22<00:01, 418.79it/s] 96%|███████████████████████████████████████████████████████████████████████████████▌   | 9334/9741 [00:23<00:00, 418.92it/s] 96%|███████████████████████████████████████████████████████████████████████████████▉   | 9377/9741 [00:23<00:00, 419.31it/s] 97%|████████████████████████████████████████████████████████████████████████████████▎  | 9420/9741 [00:23<00:00, 419.78it/s] 97%|████████████████████████████████████████████████████████████████████████████████▌  | 9462/9741 [00:23<00:00, 417.78it/s] 98%|████████████████████████████████████████████████████████████████████████████████▉  | 9505/9741 [00:23<00:00, 418.64it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▎ | 9548/9741 [00:23<00:00, 419.30it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▋ | 9590/9741 [00:23<00:00, 419.40it/s] 99%|██████████████████████████████████████████████████████████████████████████████████ | 9632/9741 [00:23<00:00, 419.50it/s] 99%|██████████████████████████████████████████████████████████████████████████████████▍| 9675/9741 [00:23<00:00, 419.69it/s]100%|██████████████████████████████████████████████████████████████████████████████████▊| 9717/9741 [00:23<00:00, 417.80it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:24<00:00, 405.15it/s]
Load End
Num instances: 1000
[2023-08-22 11:03:02,759] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 11:03:05,595] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 11:03:05,595] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f7df074ea60>
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 11:03:05,596] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f7df074e940>
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 11:03:05,597] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 11:03:05,597] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4015357494354248 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: For the nuts Adam paid 3 * $12 = $<<3*12=36>>36.
And for dried fruits Adam paid 2.5 * $8 = $<<2.5*8=20>>20.
So in total for his purchases Adam paid $36 + $20 = $<<36+20=56>>56.
So the final answer is 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: He spends 60/3=<<60/3=20>>20 minutes warming up
So he spends 60+20=<<60+20=80>>80 minutes at the gym per day
That means he spends 80*3=<<80*3=240>>240 minutes at the gym
So he spends 240/60=<<240/60=4>>4 hours at the gym a week
So the final answer is 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: The cost to fill a tank went up 200*.2=$<<200*.2=40>>40
So it cost 200+40=$<<200+40=240>>240 to fill the tank
That means he now pays 240*2=$<<240*2=480>>480
So the final answer is 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: If the total number of goals scored in the league that season against Barca is 300, the two players scored 20/100*300=<<300*20/100=60>>60 goals.
If the players scored an equal number of goals, each scored 60/2=<<60/2=30>>30 goals.
So the final answer is 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: He drinks 12 * 5 = <<12*5=60>>60 ounces of soda a day
So he drinks 60 + 64 = <<60+64=124>>124 ounces of liquid a day
So in total he drinks 124 * 7 = <<124*7=868>>868 ounces of liquid a week
So the final answer is 868

Input: Stella and Twinkle are filling up a truck with a capacity of 6000 stone blocks at the rate of 250 blocks per hour per person. They work for four hours and are then joined by 6 other people who also work at the same rate. How many hours did filling the truck take?
Output: Stella and Twinkle filled up the truck at the rate of 250 blocks per hour per person, a total of 2*250 = <<250*2=500>>500 blocks per hour for both.
After working for four hours, Stella and Twinkle had filled 4*500 = <<4*500=2000>>2000 blocks into the truck.
The number of blocks they had to put into the truck for it to be full is 6000-2000 = <<6000-2000=4000>>4000
When 6 more people joined Stella and Twinkle, a total of 2+6 = <<2+6=8>>8 people were filling the truck now.
Working at the rate of 250 blocks per person, the eight people filled the truck with 250*8 = <<250*8=2000>>2000 blocks in one hour.
If there were 4000 blocks that still needed to be put into the truck, the 8 people took 4000/2000 = <<4000/2000=2>>2 hours to fill the truck with the blocks.
The total time it took to fill up the tank is 4+2 = <<4+2=6>>6 hours.
So the final answer is 6

Input: Elijah drank 8.5 pints of coffee yesterday. Emilio drank 9.5 pints of water yesterday. How many cups of liquid did the two boys drink yesterday?
Output: Total drunk: 8.5 + 9.5 = <<8.5+9.5=18>>18 pints
18 pints * 2 = <<18*2=36>>36 cups
The two boys drank a total of 36 cups of liquid yesterday.
So the final answer is 36

Input: Doris works at the Widget Factory in the packing department. She puts 3 widgets in each carton, which are 4 inches wide, 4 inches long, and 5 inches tall. She then packs those cartons into a shipping box before sending it to the loading bay. The shipping boxes are 20 inches wide, 20 inches long, and 20 inches high. How many widgets get shipped in each shipping box?
Output: Each carton has an area of 4*4*5 = <<4*4*5=80>>80 square inches.
Each shipping box has an area of 20*20*20 = <<20*20*20=8000>>8000 square inches
The total number of cartons that will fit into each box is 8000/80 = <<8000/80=100>>100
Since there are 3 widgets in each carton, the total number of cartons in each box will be 3*100 = <<3*100=300>>300
So the final answer is 300

Input: Queenie earns $150 a day as a part-time clerk. She earns an additional $5 per hour as overtime pay. How much will Queenie receive for working 5 days with 4 hours overtime?
Output: Queenie will earn $150 x 5 = $<<150*5=750>>750 for working 5 days.
She will receive an additional $5 x 4 = $<<5*4=20>>20 for overtime pay.
Hence, Queenie will receive a total of $750 + $20 = $<<750+20=770>>770.
So the final answer is 770

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o9-tgsm8k-s10-rTrue
Loading extension module utils...
Time to load utils op: 0.40478086471557617 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:34<28:12, 34.54s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:08<27:09, 33.95s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [01:42<26:43, 34.11s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [02:15<25:58, 33.88s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [02:49<25:17, 33.72s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [03:23<24:46, 33.79s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [03:56<24:07, 33.65s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [04:30<23:30, 33.58s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [05:04<23:05, 33.80s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [05:38<22:32, 33.81s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [06:11<21:56, 33.76s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [06:47<21:43, 34.30s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [07:21<21:02, 34.12s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [07:54<20:25, 34.04s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [08:28<19:45, 33.86s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [09:01<19:06, 33.73s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [09:35<18:31, 33.70s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [10:09<17:58, 33.69s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [10:42<17:23, 33.65s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [11:15<16:45, 33.53s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [11:49<16:13, 33.56s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [12:23<15:39, 33.54s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [12:56<15:07, 33.60s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [13:30<14:33, 33.59s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [14:03<13:58, 33.52s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [14:37<13:24, 33.52s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [15:10<12:50, 33.52s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [15:44<12:17, 33.54s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [16:17<11:43, 33.52s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [16:51<11:12, 33.64s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [17:25<10:39, 33.64s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [17:59<10:05, 33.64s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [18:32<09:31, 33.62s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [19:06<08:59, 33.70s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [19:40<08:25, 33.68s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [20:13<07:50, 33.64s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [20:46<07:16, 33.54s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [21:20<06:42, 33.56s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [21:54<06:09, 33.57s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [22:28<05:37, 33.75s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [23:01<05:02, 33.58s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [23:34<04:27, 33.45s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [24:07<03:53, 33.41s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [24:41<03:20, 33.47s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [25:14<02:47, 33.45s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [25:48<02:13, 33.34s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [26:21<01:40, 33.35s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [26:54<01:06, 33.29s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [27:28<00:33, 33.48s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [28:01<00:00, 33.31s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [28:01<00:00, 33.63s/it]
name: commonsenseqa | {'exact_match': 0.2, 'rougeL': 1.7828} | avg. gen lenth: 439.742
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 2048 --num-out-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 11:31:15,579] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 1
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o1-tgsm8k-s10-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  3%|██▍                                                                                | 283/9741 [00:00<00:03, 2828.30it/s]  6%|████▉                                                                              | 582/9741 [00:00<00:03, 2916.98it/s]  9%|███████▌                                                                           | 890/9741 [00:00<00:02, 2988.71it/s] 12%|██████████                                                                        | 1202/9741 [00:00<00:02, 3038.51it/s] 16%|████████████▋                                                                     | 1511/9741 [00:00<00:02, 3054.88it/s] 19%|███████████████▎                                                                  | 1821/9741 [00:00<00:02, 3068.81it/s] 22%|█████████████████▉                                                                | 2128/9741 [00:00<00:02, 3068.15it/s] 25%|████████████████████▌                                                             | 2439/9741 [00:00<00:02, 3081.37it/s] 28%|███████████████████████▏                                                          | 2749/9741 [00:00<00:02, 3084.46it/s] 31%|█████████████████████████▋                                                        | 3058/9741 [00:01<00:02, 3020.80it/s] 35%|████████████████████████████▍                                                     | 3372/9741 [00:01<00:02, 3054.25it/s] 38%|███████████████████████████████                                                   | 3684/9741 [00:01<00:01, 3072.84it/s] 42%|██████████████████████████████████▋                                               | 4126/9741 [00:01<00:01, 3476.67it/s] 47%|██████████████████████████████████████▌                                           | 4586/9741 [00:01<00:01, 3811.77it/s] 51%|█████████████████████████████████████████▊                                        | 4968/9741 [00:01<00:01, 3205.59it/s] 56%|█████████████████████████████████████████████▊                                    | 5448/9741 [00:01<00:01, 3627.35it/s] 61%|█████████████████████████████████████████████████▉                                | 5935/9741 [00:01<00:00, 3966.55it/s] 66%|██████████████████████████████████████████████████████                            | 6418/9741 [00:01<00:00, 4207.68it/s] 71%|██████████████████████████████████████████████████████████                        | 6891/9741 [00:01<00:00, 4356.60it/s] 76%|██████████████████████████████████████████████████████████████                    | 7368/9741 [00:02<00:00, 4474.18it/s] 81%|██████████████████████████████████████████████████████████████████                | 7843/9741 [00:02<00:00, 4554.69it/s] 85%|██████████████████████████████████████████████████████████████████████            | 8328/9741 [00:02<00:00, 4641.13it/s] 90%|██████████████████████████████████████████████████████████████████████████▏       | 8813/9741 [00:02<00:00, 4702.74it/s] 95%|██████████████████████████████████████████████████████████████████████████████▎   | 9301/9741 [00:02<00:00, 4753.42it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:02<00:00, 3799.05it/s]
Load End
Num instances: 1000
[2023-08-22 11:31:29,023] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 11:31:33,496] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 11:31:33,497] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 11:31:33,497] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 11:31:33,497] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 11:31:33,497] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 11:31:33,497] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fd9f1130a60>
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fd9f1130940>
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 11:31:33,498] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 11:31:33,499] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 11:31:33,499] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 11:31:33,499] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 11:31:33,499] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 11:31:33,499] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 11:31:33,499] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 11:31:33,499] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 11:31:33,499] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 11:31:33,499] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 11:31:33,499] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 11:31:33,499] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 11:31:33,499] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 11:31:33,499] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.3773977756500244 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: 56

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o1-tgsm8k-s10-rFalse
Loading extension module utils...
Time to load utils op: 0.40543508529663086 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [01:07<55:21, 67.79s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [02:15<54:18, 67.90s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [03:24<53:39, 68.50s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [04:30<51:39, 67.38s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [05:36<50:14, 66.98s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [06:43<49:05, 66.93s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [07:50<48:01, 67.02s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [08:59<47:16, 67.54s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [10:07<46:11, 67.60s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [11:14<44:53, 67.35s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [12:21<43:52, 67.51s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [13:27<42:22, 66.90s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [14:35<41:31, 67.33s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [15:42<40:16, 67.12s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [16:49<39:03, 66.95s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [17:55<37:54, 66.90s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [19:03<36:53, 67.07s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [20:09<35:40, 66.89s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [21:17<34:40, 67.12s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [22:24<33:31, 67.05s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [23:30<32:19, 66.87s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [24:38<31:22, 67.22s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [25:45<30:14, 67.19s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [26:53<29:11, 67.35s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [28:01<28:11, 67.65s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [29:08<26:53, 67.24s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [30:16<25:56, 67.68s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [31:22<24:35, 67.05s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [32:30<23:36, 67.47s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [33:35<22:12, 66.62s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [34:42<21:04, 66.56s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [35:50<20:09, 67.17s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [36:59<19:12, 67.80s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [38:06<18:01, 67.58s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [39:12<16:46, 67.10s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [40:19<15:36, 66.87s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [41:26<14:31, 67.04s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [42:32<13:19, 66.66s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [43:41<12:20, 67.32s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [44:52<11:25, 68.53s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [46:00<10:14, 68.26s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [47:08<09:05, 68.24s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [48:16<07:57, 68.22s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [49:24<06:47, 67.99s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [50:30<05:36, 67.38s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [51:38<04:31, 67.76s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [52:46<03:23, 67.84s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [53:53<02:14, 67.39s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [54:58<01:06, 66.71s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [56:03<00:00, 66.37s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [56:03<00:00, 67.28s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 0.8626} | avg. gen lenth: 323.242
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 2048 --num-out-domain 2
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date![nltk_data]   Package punkt is already up-to-date!

using world size: 2
[2023-08-22 12:27:45,403] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 2
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o2-tgsm8k-s10-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  2%|█▋                                                                                 | 199/9741 [00:00<00:04, 1988.82it/s]  4%|███▌                                                                               | 411/9741 [00:00<00:04, 2064.42it/s]  6%|█████▎                                                                             | 625/9741 [00:00<00:04, 2094.77it/s]  9%|███████▏                                                                           | 842/9741 [00:00<00:04, 2121.65it/s] 11%|████████▉                                                                         | 1059/9741 [00:00<00:04, 2138.53it/s] 13%|██████████▋                                                                       | 1275/9741 [00:00<00:03, 2145.65it/s] 15%|████████████▌                                                                     | 1490/9741 [00:00<00:03, 2146.76it/s] 18%|██████████████▎                                                                   | 1707/9741 [00:00<00:03, 2153.06it/s] 20%|████████████████▏                                                                 | 1923/9741 [00:00<00:03, 2141.35it/s] 22%|█████████████████▉                                                                | 2138/9741 [00:01<00:03, 2092.45it/s] 24%|███████████████████▊                                                              | 2354/9741 [00:01<00:03, 2112.15it/s] 26%|█████████████████████▋                                                            | 2572/9741 [00:01<00:03, 2129.98it/s] 29%|███████████████████████▍                                                          | 2787/9741 [00:01<00:03, 2135.30it/s] 31%|█████████████████████████▎                                                        | 3006/9741 [00:01<00:03, 2150.77it/s] 34%|███████████████████████████▋                                                      | 3290/9741 [00:01<00:02, 2355.15it/s] 37%|██████████████████████████████▍                                                   | 3623/9741 [00:01<00:02, 2646.15it/s] 41%|█████████████████████████████████▎                                                | 3956/9741 [00:01<00:02, 2849.19it/s] 44%|████████████████████████████████████▏                                             | 4294/9741 [00:01<00:01, 3007.51it/s] 47%|██████████████████████████████████████▊                                           | 4617/9741 [00:01<00:01, 3072.26it/s] 51%|█████████████████████████████████████████▍                                        | 4925/9741 [00:02<00:01, 2411.84it/s] 54%|████████████████████████████████████████████▎                                     | 5261/9741 [00:02<00:01, 2650.11it/s] 57%|███████████████████████████████████████████████                                   | 5594/9741 [00:02<00:01, 2826.45it/s] 61%|█████████████████████████████████████████████████▉                                | 5929/9741 [00:02<00:01, 2968.18it/s] 64%|████████████████████████████████████████████████████▋                             | 6262/9741 [00:02<00:01, 3069.73it/s] 68%|███████████████████████████████████████████████████████▌                          | 6598/9741 [00:02<00:00, 3152.16it/s] 71%|██████████████████████████████████████████████████████████▍                       | 6935/9741 [00:02<00:00, 3215.20it/s] 75%|█████████████████████████████████████████████████████████████▏                    | 7274/9741 [00:02<00:00, 3266.40it/s] 78%|████████████████████████████████████████████████████████████████                  | 7605/9741 [00:02<00:00, 3265.39it/s] 82%|██████████████████████████████████████████████████████████████████▊               | 7939/9741 [00:03<00:00, 3286.76it/s] 85%|█████████████████████████████████████████████████████████████████████▋            | 8274/9741 [00:03<00:00, 3302.74it/s] 88%|████████████████████████████████████████████████████████████████████████▍         | 8609/9741 [00:03<00:00, 3315.20it/s] 92%|███████████████████████████████████████████████████████████████████████████▎      | 8942/9741 [00:03<00:00, 3277.81it/s] 95%|██████████████████████████████████████████████████████████████████████████████    | 9279/9741 [00:03<00:00, 3303.47it/s] 99%|████████████████████████████████████████████████████████████████████████████████▉ | 9611/9741 [00:03<00:00, 3306.23it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:03<00:00, 2741.35it/s]
Load End
Num instances: 1000
[2023-08-22 12:27:59,958] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 12:28:02,748] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 12:28:02,749] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 12:28:02,749] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 12:28:02,749] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 12:28:02,749] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 12:28:02,749] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fdc7ef0fa60>
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fdc7ef0f940>
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 12:28:02,750] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 12:28:02,751] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 12:28:02,751] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 12:28:02,751] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 12:28:02,751] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 12:28:02,751] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 12:28:02,751] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 12:28:02,751] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 12:28:02,751] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 12:28:02,751] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 12:28:02,751] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 12:28:02,751] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 12:28:02,751] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 12:28:02,751] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 12:28:02,751] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 12:28:02,751] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 12:28:02,751] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.40239739418029785 seconds
Loading extension module utils...
Time to load utils op: 0.40424060821533203 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: 4

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o2-tgsm8k-s10-rFalse
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [01:06<54:01, 66.15s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [02:11<52:33, 65.71s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [03:17<51:29, 65.74s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [04:21<49:54, 65.10s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [05:28<49:22, 65.84s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [06:35<48:30, 66.15s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [07:40<47:11, 65.86s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [08:44<45:36, 65.16s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [09:49<44:34, 65.22s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [10:56<43:45, 65.63s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [12:01<42:38, 65.61s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [13:07<41:33, 65.62s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [14:15<40:51, 66.25s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [15:20<39:39, 66.09s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [16:25<38:23, 65.82s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [17:30<37:09, 65.57s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [18:35<35:54, 65.29s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [19:38<34:29, 64.66s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [20:43<33:22, 64.59s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [21:47<32:12, 64.42s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [22:52<31:13, 64.61s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [23:57<30:10, 64.67s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [25:01<29:04, 64.61s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [26:05<27:51, 64.29s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [27:09<26:45, 64.23s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [28:13<25:42, 64.27s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [29:18<24:40, 64.38s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [30:24<23:46, 64.83s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [31:30<22:51, 65.30s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [32:36<21:47, 65.38s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [33:42<20:48, 65.70s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [34:48<19:42, 65.71s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [35:53<18:34, 65.57s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [36:56<17:14, 64.67s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [38:01<16:11, 64.78s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [39:05<15:06, 64.75s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [40:11<14:06, 65.10s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [41:17<13:02, 65.18s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [42:20<11:51, 64.71s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [43:28<10:57, 65.71s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [44:35<09:54, 66.04s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [45:40<08:45, 65.64s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [46:45<07:39, 65.63s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [47:51<06:33, 65.62s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [48:57<05:28, 65.72s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [50:00<04:20, 65.02s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [51:07<03:16, 65.58s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [52:12<02:10, 65.39s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [53:16<01:04, 64.88s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [54:21<00:00, 64.94s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [54:21<00:00, 65.23s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.4464} | avg. gen lenth: 301.416
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o3-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 2048 --num-out-domain 3
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 13:22:35,156] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o3-tgsm8k-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 3
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o3-tgsm8k-s10-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  2%|█▍                                                                                 | 163/9741 [00:00<00:05, 1622.61it/s]  3%|██▊                                                                                | 333/9741 [00:00<00:05, 1662.28it/s]  5%|████▎                                                                              | 505/9741 [00:00<00:05, 1687.72it/s]  7%|█████▊                                                                             | 678/9741 [00:00<00:05, 1700.47it/s]  9%|███████▎                                                                           | 853/9741 [00:00<00:05, 1714.47it/s] 11%|████████▋                                                                         | 1029/9741 [00:00<00:05, 1727.31it/s] 12%|██████████▏                                                                       | 1204/9741 [00:00<00:04, 1733.76it/s] 14%|███████████▌                                                                      | 1378/9741 [00:00<00:04, 1734.63it/s] 16%|█████████████                                                                     | 1552/9741 [00:00<00:04, 1695.86it/s] 18%|██████████████▌                                                                   | 1725/9741 [00:01<00:04, 1703.18it/s] 19%|███████████████▉                                                                  | 1896/9741 [00:01<00:04, 1692.95it/s] 21%|█████████████████▍                                                                | 2070/9741 [00:01<00:04, 1705.08it/s] 23%|███████████████████                                                               | 2267/9741 [00:01<00:04, 1784.31it/s] 26%|█████████████████████▎                                                            | 2531/9741 [00:01<00:03, 2040.41it/s] 29%|███████████████████████▍                                                          | 2783/9741 [00:01<00:03, 2182.17it/s] 31%|█████████████████████████▌                                                        | 3043/9741 [00:01<00:02, 2305.77it/s] 34%|███████████████████████████▌                                                      | 3278/9741 [00:01<00:02, 2316.15it/s] 36%|█████████████████████████████▌                                                    | 3510/9741 [00:01<00:02, 2308.95it/s] 38%|███████████████████████████████▌                                                  | 3742/9741 [00:02<00:03, 1836.82it/s] 40%|█████████████████████████████████▏                                                | 3941/9741 [00:02<00:03, 1807.27it/s] 42%|██████████████████████████████████▊                                               | 4133/9741 [00:02<00:03, 1788.85it/s] 44%|████████████████████████████████████▎                                             | 4320/9741 [00:02<00:03, 1776.30it/s] 46%|█████████████████████████████████████▉                                            | 4503/9741 [00:02<00:03, 1745.95it/s] 48%|███████████████████████████████████████▍                                          | 4681/9741 [00:02<00:02, 1739.64it/s] 50%|████████████████████████████████████████▉                                         | 4858/9741 [00:02<00:03, 1310.06it/s] 52%|██████████████████████████████████████████▎                                       | 5032/9741 [00:02<00:03, 1408.47it/s] 53%|███████████████████████████████████████████▊                                      | 5207/9741 [00:02<00:03, 1491.82it/s] 55%|█████████████████████████████████████████████▎                                    | 5381/9741 [00:03<00:02, 1555.65it/s] 57%|██████████████████████████████████████████████▊                                   | 5557/9741 [00:03<00:02, 1610.05it/s] 59%|████████████████████████████████████████████████▎                                 | 5733/9741 [00:03<00:02, 1649.42it/s] 61%|█████████████████████████████████████████████████▋                                | 5909/9741 [00:03<00:02, 1678.66it/s] 62%|███████████████████████████████████████████████████▏                              | 6081/9741 [00:03<00:02, 1669.14it/s] 64%|████████████████████████████████████████████████████▋                             | 6256/9741 [00:03<00:02, 1689.94it/s] 66%|██████████████████████████████████████████████████████▏                           | 6432/9741 [00:03<00:01, 1708.37it/s] 68%|███████████████████████████████████████████████████████▌                          | 6606/9741 [00:03<00:01, 1717.35it/s] 70%|█████████████████████████████████████████████████████████                         | 6784/9741 [00:03<00:01, 1734.67it/s] 72%|███████████████████████████████████████████████████████████▍                      | 7055/9741 [00:03<00:01, 2023.43it/s] 75%|█████████████████████████████████████████████████████████████▋                    | 7324/9741 [00:04<00:01, 2219.60it/s] 78%|███████████████████████████████████████████████████████████████▊                  | 7579/9741 [00:04<00:00, 2317.09it/s] 80%|█████████████████████████████████████████████████████████████████▊                | 7812/9741 [00:04<00:00, 2318.51it/s] 83%|████████████████████████████████████████████████████████████████████              | 8084/9741 [00:04<00:00, 2435.97it/s] 86%|██████████████████████████████████████████████████████████████████████▎           | 8356/9741 [00:04<00:00, 2520.82it/s] 88%|████████████████████████████████████████████████████████████████████████▌         | 8615/9741 [00:04<00:00, 2540.94it/s] 91%|██████████████████████████████████████████████████████████████████████████▊       | 8882/9741 [00:04<00:00, 2577.07it/s] 94%|████████████████████████████████████████████████████████████████████████████▉     | 9144/9741 [00:04<00:00, 2588.84it/s] 97%|███████████████████████████████████████████████████████████████████████████████▏  | 9403/9741 [00:04<00:00, 2547.38it/s] 99%|█████████████████████████████████████████████████████████████████████████████████▎| 9658/9741 [00:04<00:00, 2465.99it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:05<00:00, 1938.23it/s]
Load End
Num instances: 1000
[2023-08-22 13:22:51,300] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 13:22:54,006] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 13:22:54,006] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f3442d56a60>
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 13:22:54,007] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f3442d56940>
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 13:22:54,008] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 13:22:54,008] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.39937400817871094 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: 480

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o3-tgsm8k-s10-rFalse
Loading extension module utils...
Time to load utils op: 0.3043084144592285 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [01:01<50:32, 61.90s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [02:05<50:15, 62.81s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [03:06<48:44, 62.22s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [04:07<47:14, 61.62s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [05:11<46:46, 62.38s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [06:13<45:38, 62.24s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [07:14<44:26, 62.01s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [08:14<42:59, 61.41s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [09:17<42:13, 61.80s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [10:18<41:02, 61.55s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [11:23<40:36, 62.47s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [12:24<39:19, 62.09s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [13:28<38:40, 62.71s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [14:31<37:42, 62.86s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [15:33<36:24, 62.42s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [16:33<35:06, 61.96s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [17:38<34:29, 62.71s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [18:39<33:13, 62.31s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [19:41<32:07, 62.18s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [20:44<31:12, 62.43s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [21:44<29:50, 61.74s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [22:47<28:53, 61.91s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [23:48<27:48, 61.81s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [24:49<26:39, 61.50s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [25:51<25:44, 61.79s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [26:55<24:58, 62.46s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [27:59<24:03, 62.78s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [29:00<22:49, 62.24s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [30:03<21:53, 62.52s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [31:05<20:44, 62.23s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [32:07<19:40, 62.14s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [33:10<18:46, 62.61s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [34:14<17:47, 62.81s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [35:14<16:35, 62.19s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [36:19<15:42, 62.82s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [37:22<14:40, 62.86s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [38:26<13:42, 63.23s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [39:27<12:33, 62.75s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [40:28<11:24, 62.24s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [41:34<10:31, 63.12s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [42:35<09:24, 62.74s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [43:38<08:20, 62.59s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [44:39<07:15, 62.18s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [45:40<06:11, 61.98s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [46:43<05:10, 62.05s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [47:44<04:07, 61.94s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [48:47<03:06, 62.21s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [49:51<02:05, 62.67s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [50:55<01:02, 62.98s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [51:57<00:00, 62.83s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [51:57<00:00, 62.35s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.3134} | avg. gen lenth: 331.384
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o4-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 2048 --num-out-domain 4
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 14:15:04,725] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o4-tgsm8k-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 4
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o4-tgsm8k-s10-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|█                                                                                  | 122/9741 [00:00<00:07, 1219.16it/s]  3%|██▏                                                                                | 250/9741 [00:00<00:07, 1249.87it/s]  4%|███▏                                                                               | 380/9741 [00:00<00:07, 1269.64it/s]  5%|████▎                                                                              | 510/9741 [00:00<00:07, 1278.38it/s]  7%|█████▍                                                                             | 641/9741 [00:00<00:07, 1286.97it/s]  8%|██████▌                                                                            | 773/9741 [00:00<00:06, 1296.20it/s]  9%|███████▋                                                                           | 904/9741 [00:00<00:06, 1300.29it/s] 11%|████████▋                                                                         | 1037/9741 [00:00<00:06, 1307.62it/s] 12%|█████████▊                                                                        | 1168/9741 [00:00<00:06, 1287.35it/s] 13%|██████████▉                                                                       | 1299/9741 [00:01<00:06, 1293.25it/s] 15%|████████████                                                                      | 1429/9741 [00:01<00:06, 1293.30it/s] 16%|█████████████▏                                                                    | 1560/9741 [00:01<00:06, 1297.58it/s] 17%|██████████████▏                                                                   | 1692/9741 [00:01<00:06, 1301.47it/s] 19%|███████████████▎                                                                  | 1823/9741 [00:01<00:06, 1283.02it/s] 20%|████████████████▍                                                                 | 1953/9741 [00:01<00:06, 1287.56it/s] 21%|█████████████████▌                                                                | 2084/9741 [00:01<00:05, 1291.88it/s] 23%|██████████████████▋                                                               | 2216/9741 [00:01<00:05, 1297.31it/s] 24%|███████████████████▊                                                              | 2348/9741 [00:01<00:05, 1302.63it/s] 26%|█████████████████████▍                                                            | 2547/9741 [00:01<00:04, 1506.11it/s] 28%|███████████████████████                                                           | 2746/9741 [00:02<00:04, 1649.19it/s] 30%|████████████████████████▊                                                         | 2946/9741 [00:02<00:03, 1752.81it/s] 32%|██████████████████████████▍                                                       | 3146/9741 [00:02<00:03, 1824.47it/s] 34%|████████████████████████████▏                                                     | 3347/9741 [00:02<00:03, 1878.93it/s] 36%|█████████████████████████████▊                                                    | 3546/9741 [00:02<00:03, 1911.36it/s] 38%|███████████████████████████████▌                                                  | 3746/9741 [00:02<00:03, 1935.85it/s] 41%|█████████████████████████████████▏                                                | 3946/9741 [00:02<00:02, 1952.36it/s] 43%|██████████████████████████████████▉                                               | 4145/9741 [00:02<00:02, 1962.87it/s] 45%|████████████████████████████████████▌                                             | 4345/9741 [00:02<00:02, 1971.97it/s] 47%|██████████████████████████████████████▏                                           | 4543/9741 [00:02<00:02, 1949.02it/s] 49%|███████████████████████████████████████▉                                          | 4738/9741 [00:03<00:02, 1681.23it/s] 51%|█████████████████████████████████████████▌                                        | 4932/9741 [00:03<00:02, 1742.68it/s] 53%|███████████████████████████████████████████▏                                      | 5129/9741 [00:03<00:02, 1802.67it/s] 55%|████████████████████████████████████████████▊                                     | 5329/9741 [00:03<00:02, 1856.70it/s] 57%|██████████████████████████████████████████████▌                                   | 5529/9741 [00:03<00:02, 1896.27it/s] 59%|████████████████████████████████████████████████▏                                 | 5728/9741 [00:03<00:02, 1921.36it/s] 61%|█████████████████████████████████████████████████▉                                | 5927/9741 [00:03<00:01, 1940.93it/s] 63%|███████████████████████████████████████████████████▌                              | 6126/9741 [00:03<00:01, 1954.88it/s] 65%|█████████████████████████████████████████████████████▏                            | 6324/9741 [00:03<00:01, 1961.32it/s] 67%|██████████████████████████████████████████████████████▉                           | 6524/9741 [00:03<00:01, 1970.02it/s] 69%|████████████████████████████████████████████████████████▌                         | 6724/9741 [00:04<00:01, 1976.74it/s] 71%|██████████████████████████████████████████████████████████▎                       | 6924/9741 [00:04<00:01, 1982.59it/s] 73%|███████████████████████████████████████████████████████████▉                      | 7124/9741 [00:04<00:01, 1986.61it/s] 75%|█████████████████████████████████████████████████████████████▋                    | 7323/9741 [00:04<00:01, 1985.10it/s] 77%|███████████████████████████████████████████████████████████████▎                  | 7522/9741 [00:04<00:01, 1952.87it/s] 79%|████████████████████████████████████████████████████████████████▉                 | 7718/9741 [00:04<00:01, 1945.99it/s] 81%|██████████████████████████████████████████████████████████████████▋               | 7918/9741 [00:04<00:00, 1961.22it/s] 83%|████████████████████████████████████████████████████████████████████▎             | 8116/9741 [00:04<00:00, 1965.06it/s] 85%|█████████████████████████████████████████████████████████████████████▉            | 8313/9741 [00:04<00:00, 1946.76it/s] 87%|███████████████████████████████████████████████████████████████████████▌          | 8508/9741 [00:04<00:00, 1946.72it/s] 89%|█████████████████████████████████████████████████████████████████████████▎        | 8704/9741 [00:05<00:00, 1948.88it/s] 91%|██████████████████████████████████████████████████████████████████████████▉       | 8900/9741 [00:05<00:00, 1950.79it/s] 93%|████████████████████████████████████████████████████████████████████████████▌     | 9097/9741 [00:05<00:00, 1955.63it/s] 95%|██████████████████████████████████████████████████████████████████████████████▏   | 9295/9741 [00:05<00:00, 1960.49it/s] 97%|███████████████████████████████████████████████████████████████████████████████▉  | 9492/9741 [00:05<00:00, 1962.82it/s] 99%|█████████████████████████████████████████████████████████████████████████████████▌| 9689/9741 [00:05<00:00, 1959.94it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:05<00:00, 1731.95it/s]
Load End
Num instances: 1000
[2023-08-22 14:15:21,310] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 14:15:24,123] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 14:15:24,124] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 14:15:24,124] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 14:15:24,124] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 14:15:24,124] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 14:15:24,124] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 14:15:24,124] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 14:15:24,124] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 14:15:24,124] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fdf37ec0a60>
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fdf37ec0940>
[2023-08-22 14:15:24,125] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 14:15:24,126] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 14:15:24,126] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 14:15:24,126] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 14:15:24,126] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 14:15:24,126] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 14:15:24,126] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 14:15:24,126] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 14:15:24,126] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 14:15:24,126] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 14:15:24,126] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 14:15:24,126] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 14:15:24,126] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 14:15:24,126] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 14:15:24,126] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 14:15:24,126] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 14:15:24,126] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 14:15:24,126] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 14:15:24,126] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 14:15:24,126] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 14:15:24,126] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 14:15:24,126] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 14:15:24,126] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.39810657501220703 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: 30

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o4-tgsm8k-s10-rFalse
Loading extension module utils...
Time to load utils op: 0.4047830104827881 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [01:00<49:13, 60.27s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [02:00<47:59, 59.99s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:58<46:23, 59.22s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:56<44:56, 58.62s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [04:54<43:50, 58.45s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [05:52<42:45, 58.31s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [06:52<42:08, 58.80s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [07:50<41:06, 58.72s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [08:50<40:21, 59.06s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [09:49<39:24, 59.11s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [10:48<38:19, 58.95s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [11:46<37:12, 58.74s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [12:47<36:35, 59.33s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [13:47<35:41, 59.49s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [14:47<34:47, 59.64s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [15:47<33:57, 59.93s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [16:47<33:01, 60.04s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [17:46<31:50, 59.70s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [18:45<30:41, 59.41s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [19:42<29:22, 58.74s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [20:41<28:19, 58.61s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [21:41<27:40, 59.30s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [22:40<26:31, 58.94s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [23:40<25:40, 59.24s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [24:39<24:44, 59.39s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [25:37<23:34, 58.96s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [26:35<22:30, 58.73s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [27:35<21:39, 59.05s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [28:34<20:36, 58.87s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [29:33<19:38, 58.91s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [30:30<18:33, 58.59s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [31:30<17:37, 58.73s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [32:28<16:39, 58.79s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [33:26<15:33, 58.36s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [34:25<14:39, 58.63s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [35:22<13:35, 58.22s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [36:22<12:41, 58.58s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [37:21<11:44, 58.72s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [38:19<10:45, 58.65s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [39:19<09:50, 59.05s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [40:18<08:50, 58.96s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [41:17<07:51, 58.93s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [42:15<06:50, 58.58s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [43:12<05:49, 58.19s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [44:10<04:50, 58.20s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [45:07<03:51, 57.94s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [46:07<02:54, 58.32s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [47:05<01:56, 58.33s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [48:05<00:58, 58.70s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [49:02<00:00, 58.28s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [49:02<00:00, 58.85s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.2087} | avg. gen lenth: 374.124
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o5-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 2048 --num-out-domain 5
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 15:04:33,994] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o5-tgsm8k-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 5
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o5-tgsm8k-s10-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|▉                                                                                  | 113/9741 [00:00<00:08, 1124.29it/s]  2%|█▉                                                                                 | 230/9741 [00:00<00:08, 1148.69it/s]  4%|██▉                                                                                | 349/9741 [00:00<00:08, 1163.94it/s]  5%|███▉                                                                               | 468/9741 [00:00<00:07, 1173.94it/s]  6%|█████                                                                              | 589/9741 [00:00<00:07, 1184.27it/s]  7%|██████                                                                             | 709/9741 [00:00<00:07, 1187.20it/s]  9%|███████                                                                            | 829/9741 [00:00<00:07, 1190.56it/s] 10%|████████                                                                           | 949/9741 [00:00<00:07, 1193.12it/s] 11%|████████▉                                                                         | 1069/9741 [00:00<00:07, 1172.95it/s] 12%|█████████▉                                                                        | 1187/9741 [00:01<00:07, 1174.22it/s] 13%|███████████                                                                       | 1307/9741 [00:01<00:07, 1179.94it/s] 15%|████████████                                                                      | 1427/9741 [00:01<00:07, 1185.59it/s] 16%|█████████████                                                                     | 1547/9741 [00:01<00:06, 1189.17it/s] 17%|██████████████                                                                    | 1668/9741 [00:01<00:06, 1193.10it/s] 18%|███████████████                                                                   | 1788/9741 [00:01<00:06, 1178.69it/s] 20%|████████████████                                                                  | 1908/9741 [00:01<00:06, 1184.35it/s] 21%|█████████████████                                                                 | 2028/9741 [00:01<00:06, 1186.25it/s] 22%|██████████████████                                                                | 2148/9741 [00:01<00:06, 1187.39it/s] 23%|███████████████████                                                               | 2267/9741 [00:01<00:06, 1187.65it/s] 25%|████████████████████                                                              | 2387/9741 [00:02<00:06, 1191.24it/s] 26%|█████████████████████▎                                                            | 2532/9741 [00:02<00:05, 1267.91it/s] 28%|██████████████████████▊                                                           | 2715/9741 [00:02<00:04, 1434.39it/s] 30%|████████████████████████▍                                                         | 2897/9741 [00:02<00:04, 1548.30it/s] 32%|█████████████████████████▉                                                        | 3080/9741 [00:02<00:04, 1630.88it/s] 33%|███████████████████████████▍                                                      | 3262/9741 [00:02<00:03, 1687.39it/s] 35%|████████████████████████████▉                                                     | 3444/9741 [00:02<00:03, 1724.53it/s] 37%|██████████████████████████████▌                                                   | 3625/9741 [00:02<00:03, 1749.28it/s] 39%|████████████████████████████████                                                  | 3806/9741 [00:02<00:03, 1767.38it/s] 41%|█████████████████████████████████▌                                                | 3989/9741 [00:02<00:03, 1785.76it/s] 43%|███████████████████████████████████                                               | 4171/9741 [00:03<00:03, 1793.62it/s] 45%|████████████████████████████████████▋                                             | 4353/9741 [00:03<00:02, 1800.93it/s] 47%|██████████████████████████████████████▏                                           | 4534/9741 [00:03<00:02, 1755.49it/s] 48%|███████████████████████████████████████▋                                          | 4710/9741 [00:03<00:03, 1339.67it/s] 50%|█████████████████████████████████████████▏                                        | 4890/9741 [00:03<00:03, 1449.47it/s] 52%|██████████████████████████████████████████▋                                       | 5071/9741 [00:03<00:03, 1541.27it/s] 54%|████████████████████████████████████████████▏                                     | 5253/9741 [00:03<00:02, 1613.99it/s] 56%|█████████████████████████████████████████████▋                                    | 5433/9741 [00:03<00:02, 1665.11it/s] 58%|███████████████████████████████████████████████▎                                  | 5615/9741 [00:03<00:02, 1707.53it/s] 60%|████████████████████████████████████████████████▊                                 | 5798/9741 [00:04<00:02, 1741.13it/s] 61%|██████████████████████████████████████████████████▎                               | 5981/9741 [00:04<00:02, 1764.56it/s] 63%|███████████████████████████████████████████████████▊                              | 6162/9741 [00:04<00:02, 1776.79it/s] 65%|█████████████████████████████████████████████████████▍                            | 6342/9741 [00:04<00:01, 1780.88it/s] 67%|██████████████████████████████████████████████████████▉                           | 6522/9741 [00:04<00:01, 1783.52it/s] 69%|████████████████████████████████████████████████████████▍                         | 6702/9741 [00:04<00:01, 1787.38it/s] 71%|█████████████████████████████████████████████████████████▉                        | 6882/9741 [00:04<00:01, 1790.64it/s] 72%|███████████████████████████████████████████████████████████▍                      | 7062/9741 [00:04<00:01, 1792.01it/s] 74%|████████████████████████████████████████████████████████████▉                     | 7242/9741 [00:04<00:01, 1794.35it/s] 76%|██████████████████████████████████████████████████████████████▍                   | 7422/9741 [00:04<00:01, 1726.44it/s] 78%|███████████████████████████████████████████████████████████████▉                  | 7600/9741 [00:05<00:01, 1741.63it/s] 80%|█████████████████████████████████████████████████████████████████▍                | 7778/9741 [00:05<00:01, 1752.61it/s] 82%|██████████████████████████████████████████████████████████████████▉               | 7957/9741 [00:05<00:01, 1762.63it/s] 84%|████████████████████████████████████████████████████████████████████▍             | 8136/9741 [00:05<00:00, 1768.48it/s] 85%|██████████████████████████████████████████████████████████████████████            | 8316/9741 [00:05<00:00, 1775.98it/s] 87%|███████████████████████████████████████████████████████████████████████▌          | 8494/9741 [00:05<00:00, 1774.38it/s] 89%|█████████████████████████████████████████████████████████████████████████         | 8672/9741 [00:05<00:00, 1765.18it/s] 91%|██████████████████████████████████████████████████████████████████████████▍       | 8849/9741 [00:05<00:00, 1766.12it/s] 93%|███████████████████████████████████████████████████████████████████████████▉      | 9026/9741 [00:05<00:00, 1766.13it/s] 94%|█████████████████████████████████████████████████████████████████████████████▍    | 9204/9741 [00:05<00:00, 1767.78it/s] 96%|██████████████████████████████████████████████████████████████████████████████▉   | 9381/9741 [00:06<00:00, 1767.57it/s] 98%|████████████████████████████████████████████████████████████████████████████████▍ | 9558/9741 [00:06<00:00, 1766.00it/s]100%|█████████████████████████████████████████████████████████████████████████████████▉| 9736/9741 [00:06<00:00, 1767.76it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:06<00:00, 1555.63it/s]
Load End
Num instances: 1000
[2023-08-22 15:04:51,180] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 15:04:53,889] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 15:04:53,890] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 15:04:53,891] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 15:04:53,891] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 15:04:53,891] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 15:04:53,891] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 15:04:53,891] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 15:04:53,891] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 15:04:53,891] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 15:04:53,891] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 15:04:53,891] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 15:04:53,891] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f5f5dd36a60>
[2023-08-22 15:04:53,891] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 15:04:53,891] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 15:04:53,891] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 15:04:53,892] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 15:04:53,892] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 15:04:53,892] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 15:04:53,892] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 15:04:53,892] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 15:04:53,892] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 15:04:53,892] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 15:04:53,892] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 15:04:53,892] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 15:04:53,892] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 15:04:53,892] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 15:04:53,892] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 15:04:53,892] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 15:04:53,892] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 15:04:53,892] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 15:04:53,892] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 15:04:53,892] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 15:04:53,892] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 15:04:53,892] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 15:04:53,892] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 15:04:53,892] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 15:04:53,892] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 15:04:53,892] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 15:04:53,892] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 15:04:53,892] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 15:04:53,892] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 15:04:53,892] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 15:04:53,892] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 15:04:53,892] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 15:04:53,893] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f5f5dd36940>
[2023-08-22 15:04:53,893] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 15:04:53,893] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 15:04:53,893] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 15:04:53,893] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 15:04:53,893] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 15:04:53,893] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 15:04:53,893] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 15:04:53,893] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 15:04:53,893] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 15:04:53,893] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 15:04:53,893] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 15:04:53,893] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 15:04:53,893] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 15:04:53,893] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 15:04:53,893] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 15:04:53,893] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 15:04:53,893] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 15:04:53,893] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 15:04:53,893] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 15:04:53,893] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 15:04:53,893] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 15:04:53,893] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 15:04:53,893] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.40970420837402344 seconds
Loading extension module utils...
Time to load utils op: 0.5047035217285156 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: 868

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o5-tgsm8k-s10-rFalse
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:58<47:59, 58.77s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:56<46:23, 57.98s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:54<45:42, 58.35s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:51<44:04, 57.48s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [04:49<43:13, 57.63s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [05:45<42:02, 57.32s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [06:42<40:59, 57.20s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [07:39<39:53, 56.98s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [08:35<38:51, 56.85s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [09:32<37:58, 56.96s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [10:30<37:11, 57.23s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [11:27<36:05, 56.99s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [12:27<35:45, 57.98s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [13:25<34:43, 57.88s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [14:21<33:30, 57.44s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [15:19<32:38, 57.60s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [16:17<31:47, 57.79s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [17:15<30:52, 57.88s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [18:12<29:46, 57.62s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [19:12<29:07, 58.23s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [20:08<27:49, 57.56s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [21:07<26:59, 57.84s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [22:03<25:53, 57.55s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [23:00<24:51, 57.38s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [23:58<23:53, 57.36s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [24:55<22:53, 57.23s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [25:51<21:52, 57.06s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [26:49<20:59, 57.23s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [27:47<20:08, 57.56s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [28:46<19:15, 57.78s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [29:42<18:07, 57.25s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [30:38<17:08, 57.13s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [31:37<16:16, 57.46s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [32:33<15:16, 57.25s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [33:31<14:20, 57.38s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [34:29<13:24, 57.45s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [35:27<12:28, 57.56s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [36:23<11:25, 57.11s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [37:18<10:24, 56.75s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [38:17<09:32, 57.24s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [39:15<08:37, 57.54s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [40:13<07:41, 57.74s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [41:11<06:44, 57.73s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [42:07<05:43, 57.28s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [43:03<04:44, 56.92s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [44:00<03:47, 56.83s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [45:00<02:53, 57.69s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [45:57<01:55, 57.69s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [46:54<00:57, 57.50s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [47:51<00:00, 57.12s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [47:51<00:00, 57.42s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 0.9958} | avg. gen lenth: 399.072
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 2048 --num-out-domain 6
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 15:52:53,211] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 6
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o6-tgsm8k-s10-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|▊                                                                                    | 97/9741 [00:00<00:09, 964.94it/s]  2%|█▋                                                                                  | 197/9741 [00:00<00:09, 983.74it/s]  3%|██▌                                                                                | 300/9741 [00:00<00:09, 1001.46it/s]  4%|███▍                                                                               | 403/9741 [00:00<00:09, 1010.14it/s]  5%|████▎                                                                              | 507/9741 [00:00<00:09, 1019.65it/s]  6%|█████▏                                                                             | 611/9741 [00:00<00:08, 1025.98it/s]  7%|██████                                                                             | 715/9741 [00:00<00:08, 1029.15it/s]  8%|██████▉                                                                            | 820/9741 [00:00<00:08, 1032.85it/s]  9%|███████▊                                                                           | 924/9741 [00:00<00:08, 1014.99it/s] 11%|████████▋                                                                         | 1026/9741 [00:01<00:08, 1015.50it/s] 12%|█████████▌                                                                        | 1129/9741 [00:01<00:08, 1019.24it/s] 13%|██████████▎                                                                       | 1232/9741 [00:01<00:08, 1021.44it/s] 14%|███████████▏                                                                      | 1336/9741 [00:01<00:08, 1024.17it/s] 15%|████████████                                                                      | 1439/9741 [00:01<00:08, 1025.08it/s] 16%|████████████▉                                                                     | 1542/9741 [00:01<00:07, 1026.45it/s] 17%|█████████████▊                                                                    | 1646/9741 [00:01<00:07, 1028.27it/s] 18%|██████████████▋                                                                   | 1750/9741 [00:01<00:07, 1030.49it/s] 19%|███████████████▌                                                                  | 1854/9741 [00:01<00:07, 1007.77it/s] 20%|████████████████▍                                                                 | 1956/9741 [00:01<00:07, 1011.32it/s] 21%|█████████████████▎                                                                | 2059/9741 [00:02<00:07, 1014.42it/s] 22%|██████████████████▏                                                               | 2162/9741 [00:02<00:07, 1016.46it/s] 23%|███████████████████                                                               | 2266/9741 [00:02<00:07, 1020.74it/s] 24%|███████████████████▉                                                              | 2369/9741 [00:02<00:07, 1022.23it/s] 25%|████████████████████▊                                                             | 2472/9741 [00:02<00:07, 1023.98it/s] 26%|█████████████████████▋                                                            | 2576/9741 [00:02<00:06, 1026.07it/s] 28%|██████████████████████▌                                                           | 2679/9741 [00:02<00:06, 1024.39it/s] 29%|███████████████████████▍                                                          | 2782/9741 [00:02<00:06, 1023.59it/s] 30%|████████████████████████▋                                                         | 2931/9741 [00:02<00:05, 1160.66it/s] 32%|█████████████████████████▉                                                        | 3087/9741 [00:02<00:05, 1278.56it/s] 33%|███████████████████████████▎                                                      | 3244/9741 [00:03<00:04, 1364.84it/s] 35%|████████████████████████████▋                                                     | 3401/9741 [00:03<00:04, 1423.92it/s] 36%|█████████████████████████████▉                                                    | 3553/9741 [00:03<00:04, 1449.69it/s] 38%|███████████████████████████████▏                                                  | 3706/9741 [00:03<00:04, 1472.58it/s] 40%|████████████████████████████████▌                                                 | 3861/9741 [00:03<00:03, 1495.20it/s] 41%|█████████████████████████████████▊                                                | 4017/9741 [00:03<00:03, 1513.45it/s] 43%|███████████████████████████████████                                               | 4172/9741 [00:03<00:03, 1522.68it/s] 44%|████████████████████████████████████▍                                             | 4328/9741 [00:03<00:03, 1531.36it/s] 46%|█████████████████████████████████████▋                                            | 4483/9741 [00:03<00:03, 1497.81it/s] 48%|███████████████████████████████████████                                           | 4639/9741 [00:03<00:03, 1515.29it/s] 49%|████████████████████████████████████████▎                                         | 4791/9741 [00:04<00:03, 1295.86it/s] 51%|█████████████████████████████████████████▋                                        | 4946/9741 [00:04<00:03, 1362.11it/s] 52%|██████████████████████████████████████████▉                                       | 5102/9741 [00:04<00:03, 1414.85it/s] 54%|████████████████████████████████████████████▎                                     | 5257/9741 [00:04<00:03, 1451.33it/s] 56%|█████████████████████████████████████████████▌                                    | 5411/9741 [00:04<00:02, 1475.20it/s] 57%|██████████████████████████████████████████████▊                                   | 5566/9741 [00:04<00:02, 1496.19it/s] 59%|████████████████████████████████████████████████▏                                 | 5722/9741 [00:04<00:02, 1513.31it/s] 60%|█████████████████████████████████████████████████▍                                | 5878/9741 [00:04<00:02, 1526.67it/s] 62%|██████████████████████████████████████████████████▊                               | 6034/9741 [00:04<00:02, 1533.96it/s] 64%|████████████████████████████████████████████████████                              | 6188/9741 [00:05<00:02, 1510.77it/s] 65%|█████████████████████████████████████████████████████▍                            | 6342/9741 [00:05<00:02, 1518.69it/s] 67%|██████████████████████████████████████████████████████▋                           | 6497/9741 [00:05<00:02, 1525.54it/s] 68%|███████████████████████████████████████████████████████▉                          | 6651/9741 [00:05<00:02, 1529.06it/s] 70%|█████████████████████████████████████████████████████████▎                        | 6807/9741 [00:05<00:01, 1536.13it/s] 71%|██████████████████████████████████████████████████████████▌                       | 6962/9741 [00:05<00:01, 1539.96it/s] 73%|███████████████████████████████████████████████████████████▉                      | 7117/9741 [00:05<00:01, 1542.82it/s] 75%|█████████████████████████████████████████████████████████████▏                    | 7272/9741 [00:05<00:01, 1542.43it/s] 76%|██████████████████████████████████████████████████████████████▌                   | 7427/9741 [00:05<00:01, 1503.66it/s] 78%|███████████████████████████████████████████████████████████████▊                  | 7581/9741 [00:05<00:01, 1512.69it/s] 79%|█████████████████████████████████████████████████████████████████                 | 7735/9741 [00:06<00:01, 1517.99it/s] 81%|██████████████████████████████████████████████████████████████████▍               | 7889/9741 [00:06<00:01, 1523.47it/s] 83%|███████████████████████████████████████████████████████████████████▋              | 8044/9741 [00:06<00:01, 1530.65it/s] 84%|█████████████████████████████████████████████████████████████████████             | 8199/9741 [00:06<00:01, 1534.88it/s] 86%|██████████████████████████████████████████████████████████████████████▎           | 8354/9741 [00:06<00:00, 1537.36it/s] 87%|███████████████████████████████████████████████████████████████████████▋          | 8509/9741 [00:06<00:00, 1541.00it/s] 89%|████████████████████████████████████████████████████████████████████████▉         | 8664/9741 [00:06<00:00, 1537.92it/s] 91%|██████████████████████████████████████████████████████████████████████████▏       | 8818/9741 [00:06<00:00, 1536.99it/s] 92%|███████████████████████████████████████████████████████████████████████████▌      | 8973/9741 [00:06<00:00, 1539.17it/s] 94%|████████████████████████████████████████████████████████████████████████████▊     | 9127/9741 [00:06<00:00, 1534.86it/s] 95%|██████████████████████████████████████████████████████████████████████████████▏   | 9281/9741 [00:07<00:00, 1534.34it/s] 97%|███████████████████████████████████████████████████████████████████████████████▍  | 9435/9741 [00:07<00:00, 1518.47it/s] 98%|████████████████████████████████████████████████████████████████████████████████▋ | 9587/9741 [00:07<00:00, 1514.94it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:07<00:00, 1519.75it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:07<00:00, 1329.13it/s]
Load End
Num instances: 1000
[2023-08-22 15:53:11,455] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 15:53:14,699] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 15:53:14,700] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 15:53:14,701] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 15:53:14,701] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 15:53:14,701] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 15:53:14,701] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 15:53:14,701] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 15:53:14,701] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fcbf740ba60>
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 15:53:14,702] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 15:53:14,703] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 15:53:14,703] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 15:53:14,703] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 15:53:14,703] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 15:53:14,703] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fcbf740b940>
[2023-08-22 15:53:14,703] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 15:53:14,703] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 15:53:14,703] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 15:53:14,703] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 15:53:14,703] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 15:53:14,703] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 15:53:14,703] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 15:53:14,703] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 15:53:14,703] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 15:53:14,703] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 15:53:14,703] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 15:53:14,703] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 15:53:14,703] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 15:53:14,703] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 15:53:14,703] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 15:53:14,703] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 15:53:14,703] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 15:53:14,703] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 15:53:14,703] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 15:53:14,703] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 15:53:14,703] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 15:53:14,703] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 15:53:14,703] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4182145595550537 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: 868

Input: Stella and Twinkle are filling up a truck with a capacity of 6000 stone blocks at the rate of 250 blocks per hour per person. They work for four hours and are then joined by 6 other people who also work at the same rate. How many hours did filling the truck take?
Output: 6

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o6-tgsm8k-s10-rFalse
Loading extension module utils...
Time to load utils op: 0.5049667358398438 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:56<46:18, 56.70s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:51<44:33, 55.69s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:45<43:07, 55.06s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:39<41:48, 54.54s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [04:33<40:48, 54.42s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [05:27<39:46, 54.25s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [06:23<39:08, 54.62s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [07:16<37:55, 54.19s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [08:11<37:06, 54.31s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [09:06<36:25, 54.63s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [10:01<35:34, 54.72s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [10:55<34:37, 54.68s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [11:51<33:58, 55.09s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [12:45<32:45, 54.60s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [13:40<31:55, 54.73s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [14:34<30:58, 54.65s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [15:30<30:08, 54.81s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [16:24<29:06, 54.57s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [17:19<28:17, 54.75s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [18:13<27:16, 54.56s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [19:07<26:21, 54.53s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [20:03<25:33, 54.75s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [21:00<25:01, 55.63s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [21:54<23:53, 55.15s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [22:43<22:10, 53.22s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [23:38<21:29, 53.72s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [24:32<20:37, 53.81s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [25:26<19:45, 53.89s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [26:22<19:02, 54.38s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [27:16<18:07, 54.40s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [28:11<17:19, 54.71s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [29:06<16:24, 54.67s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [30:02<15:37, 55.15s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [30:57<14:40, 55.05s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [31:51<13:41, 54.76s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [32:46<12:47, 54.83s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [33:41<11:52, 54.78s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [34:36<10:58, 54.91s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [35:31<10:02, 54.79s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [36:25<09:07, 54.79s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [37:21<08:14, 54.89s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [38:16<07:21, 55.15s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [39:11<06:25, 55.08s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [40:07<05:31, 55.17s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [41:02<04:36, 55.26s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [41:56<03:39, 54.99s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [42:52<02:45, 55.14s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [43:46<01:49, 54.91s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [44:42<00:55, 55.09s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [45:37<00:00, 55.10s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [45:37<00:00, 54.75s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 0.8463} | avg. gen lenth: 405.002
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o7-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 2048 --num-out-domain 7
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 16:39:02,499] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o7-tgsm8k-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 7
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o7-tgsm8k-s10-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|▋                                                                                    | 85/9741 [00:00<00:11, 841.82it/s]  2%|█▌                                                                                  | 174/9741 [00:00<00:11, 866.17it/s]  3%|██▎                                                                                 | 264/9741 [00:00<00:10, 878.12it/s]  4%|███                                                                                 | 354/9741 [00:00<00:10, 884.41it/s]  5%|███▊                                                                                | 444/9741 [00:00<00:10, 888.03it/s]  5%|████▌                                                                               | 535/9741 [00:00<00:10, 894.10it/s]  6%|█████▍                                                                              | 625/9741 [00:00<00:10, 895.20it/s]  7%|██████▏                                                                             | 717/9741 [00:00<00:10, 900.23it/s]  8%|██████▉                                                                             | 808/9741 [00:00<00:10, 880.77it/s]  9%|███████▋                                                                            | 898/9741 [00:01<00:09, 884.81it/s] 10%|████████▌                                                                           | 989/9741 [00:01<00:09, 890.03it/s] 11%|█████████▏                                                                         | 1080/9741 [00:01<00:09, 894.49it/s] 12%|█████████▉                                                                         | 1171/9741 [00:01<00:09, 896.94it/s] 13%|██████████▊                                                                        | 1262/9741 [00:01<00:09, 899.39it/s] 14%|███████████▌                                                                       | 1352/9741 [00:01<00:09, 898.65it/s] 15%|████████████▎                                                                      | 1442/9741 [00:01<00:09, 898.02it/s] 16%|█████████████                                                                      | 1532/9741 [00:01<00:09, 895.67it/s] 17%|█████████████▊                                                                     | 1623/9741 [00:01<00:09, 897.11it/s] 18%|██████████████▌                                                                    | 1713/9741 [00:01<00:08, 897.41it/s] 19%|███████████████▎                                                                   | 1803/9741 [00:02<00:08, 883.37it/s] 20%|████████████████▎                                                                 | 1939/9741 [00:02<00:07, 1022.59it/s] 21%|█████████████████▍                                                                | 2072/9741 [00:02<00:06, 1113.73it/s] 23%|██████████████████▌                                                               | 2208/9741 [00:02<00:06, 1185.91it/s] 24%|███████████████████▋                                                              | 2343/9741 [00:02<00:05, 1233.35it/s] 25%|████████████████████▊                                                             | 2478/9741 [00:02<00:05, 1266.61it/s] 27%|██████████████████████                                                            | 2614/9741 [00:02<00:05, 1292.87it/s] 28%|███████████████████████▏                                                          | 2748/9741 [00:02<00:05, 1304.70it/s] 30%|████████████████████████▎                                                         | 2882/9741 [00:02<00:05, 1315.00it/s] 31%|█████████████████████████▍                                                        | 3017/9741 [00:02<00:05, 1323.62it/s] 32%|██████████████████████████▌                                                       | 3151/9741 [00:03<00:04, 1326.36it/s] 34%|███████████████████████████▋                                                      | 3287/9741 [00:03<00:04, 1334.04it/s] 35%|████████████████████████████▊                                                     | 3421/9741 [00:03<00:04, 1319.20it/s] 36%|█████████████████████████████▉                                                    | 3555/9741 [00:03<00:04, 1324.41it/s] 38%|███████████████████████████████                                                   | 3689/9741 [00:03<00:04, 1327.29it/s] 39%|████████████████████████████████▏                                                 | 3823/9741 [00:03<00:04, 1329.80it/s] 41%|█████████████████████████████████▎                                                | 3958/9741 [00:03<00:04, 1333.44it/s] 42%|██████████████████████████████████▍                                               | 4092/9741 [00:03<00:04, 1330.31it/s] 43%|███████████████████████████████████▌                                              | 4226/9741 [00:03<00:04, 1330.27it/s] 45%|████████████████████████████████████▋                                             | 4360/9741 [00:03<00:04, 1332.13it/s] 46%|█████████████████████████████████████▊                                            | 4494/9741 [00:04<00:04, 1298.06it/s] 48%|██████████████████████████████████████▉                                           | 4627/9741 [00:04<00:03, 1306.75it/s] 49%|████████████████████████████████████████▌                                          | 4758/9741 [00:04<00:04, 998.44it/s] 50%|█████████████████████████████████████████▏                                        | 4892/9741 [00:04<00:04, 1080.57it/s] 52%|██████████████████████████████████████████▎                                       | 5025/9741 [00:04<00:04, 1143.97it/s] 53%|███████████████████████████████████████████▍                                      | 5158/9741 [00:04<00:03, 1192.97it/s] 54%|████████████████████████████████████████████▌                                     | 5291/9741 [00:04<00:03, 1229.05it/s] 56%|█████████████████████████████████████████████▌                                    | 5419/9741 [00:04<00:03, 1234.45it/s] 57%|██████████████████████████████████████████████▋                                   | 5552/9741 [00:04<00:03, 1259.89it/s] 58%|███████████████████████████████████████████████▊                                  | 5684/9741 [00:05<00:03, 1275.30it/s] 60%|████████████████████████████████████████████████▉                                 | 5817/9741 [00:05<00:03, 1290.26it/s] 61%|██████████████████████████████████████████████████                                | 5949/9741 [00:05<00:02, 1298.22it/s] 62%|███████████████████████████████████████████████████▏                              | 6081/9741 [00:05<00:02, 1303.81it/s] 64%|████████████████████████████████████████████████████▎                             | 6213/9741 [00:05<00:02, 1308.55it/s] 65%|█████████████████████████████████████████████████████▍                            | 6345/9741 [00:05<00:02, 1309.54it/s] 66%|██████████████████████████████████████████████████████▌                           | 6477/9741 [00:05<00:02, 1310.73it/s] 68%|███████████████████████████████████████████████████████▋                          | 6609/9741 [00:05<00:02, 1307.75it/s] 69%|████████████████████████████████████████████████████████▋                         | 6740/9741 [00:05<00:02, 1307.12it/s] 71%|█████████████████████████████████████████████████████████▊                        | 6871/9741 [00:05<00:02, 1307.61it/s] 72%|██████████████████████████████████████████████████████████▉                       | 7002/9741 [00:06<00:02, 1304.58it/s] 73%|████████████████████████████████████████████████████████████                      | 7134/9741 [00:06<00:01, 1308.65it/s] 75%|█████████████████████████████████████████████████████████████▏                    | 7265/9741 [00:06<00:01, 1303.46it/s] 76%|██████████████████████████████████████████████████████████████▎                   | 7397/9741 [00:06<00:01, 1305.51it/s] 77%|███████████████████████████████████████████████████████████████▎                  | 7528/9741 [00:06<00:01, 1275.32it/s] 79%|████████████████████████████████████████████████████████████████▍                 | 7658/9741 [00:06<00:01, 1280.70it/s] 80%|█████████████████████████████████████████████████████████████████▌                | 7789/9741 [00:06<00:01, 1288.76it/s] 81%|██████████████████████████████████████████████████████████████████▋               | 7920/9741 [00:06<00:01, 1294.57it/s] 83%|███████████████████████████████████████████████████████████████████▊              | 8051/9741 [00:06<00:01, 1297.48it/s] 84%|████████████████████████████████████████████████████████████████████▊             | 8181/9741 [00:06<00:01, 1297.70it/s] 85%|█████████████████████████████████████████████████████████████████████▉            | 8311/9741 [00:07<00:01, 1264.84it/s] 87%|███████████████████████████████████████████████████████████████████████           | 8439/9741 [00:07<00:01, 1268.29it/s] 88%|████████████████████████████████████████████████████████████████████████▏         | 8569/9741 [00:07<00:00, 1274.99it/s] 89%|█████████████████████████████████████████████████████████████████████████▏        | 8698/9741 [00:07<00:00, 1278.39it/s] 91%|██████████████████████████████████████████████████████████████████████████▎       | 8828/9741 [00:07<00:00, 1282.78it/s] 92%|███████████████████████████████████████████████████████████████████████████▍      | 8959/9741 [00:07<00:00, 1290.42it/s] 93%|████████████████████████████████████████████████████████████████████████████▌     | 9089/9741 [00:07<00:00, 1288.20it/s] 95%|█████████████████████████████████████████████████████████████████████████████▌    | 9219/9741 [00:07<00:00, 1291.52it/s] 96%|██████████████████████████████████████████████████████████████████████████████▋   | 9349/9741 [00:07<00:00, 1291.59it/s] 97%|███████████████████████████████████████████████████████████████████████████████▊  | 9479/9741 [00:07<00:00, 1290.68it/s] 99%|████████████████████████████████████████████████████████████████████████████████▉ | 9609/9741 [00:08<00:00, 1288.15it/s]100%|█████████████████████████████████████████████████████████████████████████████████▉| 9738/9741 [00:08<00:00, 1285.62it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:08<00:00, 1188.86it/s]
Load End
Num instances: 1000
[2023-08-22 16:39:21,832] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 16:39:24,685] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 16:39:24,685] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 16:39:24,685] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 16:39:24,685] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 16:39:24,685] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 16:39:24,685] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f719fa95a60>
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f719fa95940>
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 16:39:24,686] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 16:39:24,687] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 16:39:24,687] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 16:39:24,687] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 16:39:24,687] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 16:39:24,687] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 16:39:24,687] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 16:39:24,687] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 16:39:24,687] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 16:39:24,687] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 16:39:24,687] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 16:39:24,687] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 16:39:24,687] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4777810573577881 seconds
Loading extension module utils...
Time to load utils op: 0.5048506259918213 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: 868

Input: Stella and Twinkle are filling up a truck with a capacity of 6000 stone blocks at the rate of 250 blocks per hour per person. They work for four hours and are then joined by 6 other people who also work at the same rate. How many hours did filling the truck take?
Output: 6

Input: Elijah drank 8.5 pints of coffee yesterday. Emilio drank 9.5 pints of water yesterday. How many cups of liquid did the two boys drink yesterday?
Output: 36

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o7-tgsm8k-s10-rFalse
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:54<44:21, 54.32s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:49<43:47, 54.75s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:42<42:16, 53.96s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:34<40:56, 53.40s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [04:28<40:00, 53.35s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [05:21<39:05, 53.31s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [06:14<38:15, 53.38s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [07:07<37:11, 53.12s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [08:01<36:28, 53.39s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [08:54<35:28, 53.22s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [09:47<34:36, 53.23s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [10:40<33:35, 53.05s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [11:34<32:51, 53.29s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [12:27<32:02, 53.41s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [13:19<30:55, 53.01s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [14:12<30:00, 52.95s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [15:04<28:57, 52.65s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [15:56<27:55, 52.37s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [16:50<27:18, 52.87s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [17:43<26:32, 53.07s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [18:37<25:42, 53.19s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [19:30<24:47, 53.13s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [20:24<24:00, 53.35s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [21:17<23:09, 53.43s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [22:13<22:31, 54.08s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [23:07<21:37, 54.07s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [24:01<20:45, 54.14s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [24:54<19:38, 53.57s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [25:48<18:51, 53.90s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [26:41<17:53, 53.67s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [27:34<16:55, 53.47s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [28:28<16:02, 53.48s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [29:22<15:10, 53.58s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [30:15<14:16, 53.56s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [31:08<13:21, 53.43s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [32:01<12:24, 53.17s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [32:55<11:33, 53.37s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [33:48<10:39, 53.29s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [34:42<09:48, 53.49s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [35:36<08:56, 53.63s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [36:29<08:02, 53.58s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [37:23<07:09, 53.64s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [38:15<06:12, 53.23s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [39:09<05:19, 53.28s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [40:03<04:27, 53.48s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [40:55<03:32, 53.19s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [41:49<02:40, 53.51s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [42:42<01:46, 53.10s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [43:36<00:53, 53.40s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [44:29<00:00, 53.48s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [44:29<00:00, 53.40s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 0.9585} | avg. gen lenth: 411.444
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 2048 --num-out-domain 8
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 17:24:06,651] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 8
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o8-tgsm8k-s10-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|▋                                                                                    | 72/9741 [00:00<00:13, 717.43it/s]  2%|█▎                                                                                  | 147/9741 [00:00<00:13, 732.92it/s]  2%|█▉                                                                                  | 222/9741 [00:00<00:12, 740.56it/s]  3%|██▌                                                                                 | 298/9741 [00:00<00:12, 746.31it/s]  4%|███▏                                                                                | 374/9741 [00:00<00:12, 750.94it/s]  5%|███▉                                                                                | 450/9741 [00:00<00:12, 753.73it/s]  5%|████▌                                                                               | 527/9741 [00:00<00:12, 756.11it/s]  6%|█████▏                                                                              | 603/9741 [00:00<00:12, 757.12it/s]  7%|█████▊                                                                              | 679/9741 [00:00<00:12, 735.79it/s]  8%|██████▌                                                                             | 755/9741 [00:01<00:12, 741.22it/s]  9%|███████▏                                                                            | 832/9741 [00:01<00:11, 747.10it/s]  9%|███████▊                                                                            | 908/9741 [00:01<00:11, 750.69it/s] 10%|████████▋                                                                          | 1020/9741 [00:01<00:10, 860.22it/s] 12%|█████████▋                                                                         | 1135/9741 [00:01<00:09, 946.49it/s] 13%|██████████▌                                                                       | 1250/9741 [00:01<00:08, 1005.16it/s] 14%|███████████▍                                                                      | 1364/9741 [00:01<00:08, 1044.64it/s] 15%|████████████▍                                                                     | 1479/9741 [00:01<00:07, 1074.98it/s] 16%|█████████████▍                                                                    | 1593/9741 [00:01<00:07, 1093.92it/s] 18%|██████████████▎                                                                   | 1707/9741 [00:01<00:07, 1107.37it/s] 19%|███████████████▎                                                                  | 1818/9741 [00:02<00:07, 1098.49it/s] 20%|████████████████▎                                                                 | 1932/9741 [00:02<00:07, 1110.54it/s] 21%|█████████████████▏                                                                | 2046/9741 [00:02<00:06, 1117.25it/s] 22%|██████████████████▏                                                               | 2160/9741 [00:02<00:06, 1122.50it/s] 23%|███████████████████▏                                                              | 2273/9741 [00:02<00:06, 1124.33it/s] 25%|████████████████████                                                              | 2387/9741 [00:02<00:06, 1128.65it/s] 26%|█████████████████████                                                             | 2501/9741 [00:02<00:06, 1129.32it/s] 27%|██████████████████████                                                            | 2616/9741 [00:02<00:06, 1133.17it/s] 28%|██████████████████████▉                                                           | 2730/9741 [00:02<00:06, 1131.15it/s] 29%|███████████████████████▉                                                          | 2844/9741 [00:02<00:06, 1130.93it/s] 30%|████████████████████████▉                                                         | 2958/9741 [00:03<00:06, 1128.55it/s] 32%|█████████████████████████▊                                                        | 3071/9741 [00:03<00:05, 1121.43it/s] 33%|██████████████████████████▊                                                       | 3184/9741 [00:03<00:05, 1105.99it/s] 34%|███████████████████████████▊                                                      | 3297/9741 [00:03<00:05, 1112.67it/s] 35%|████████████████████████████▋                                                     | 3409/9741 [00:03<00:05, 1114.52it/s] 36%|█████████████████████████████▋                                                    | 3521/9741 [00:03<00:05, 1116.12it/s] 37%|██████████████████████████████▌                                                   | 3634/9741 [00:03<00:05, 1118.26it/s] 38%|███████████████████████████████▌                                                  | 3747/9741 [00:03<00:05, 1119.92it/s] 40%|████████████████████████████████▍                                                 | 3860/9741 [00:03<00:05, 1119.68it/s] 41%|█████████████████████████████████▍                                                | 3973/9741 [00:03<00:05, 1121.17it/s] 42%|██████████████████████████████████▍                                               | 4086/9741 [00:04<00:05, 1121.09it/s] 43%|███████████████████████████████████▎                                              | 4199/9741 [00:04<00:04, 1121.58it/s] 44%|████████████████████████████████████▎                                             | 4312/9741 [00:04<00:04, 1120.72it/s] 45%|█████████████████████████████████████▏                                            | 4425/9741 [00:04<00:04, 1120.55it/s] 47%|██████████████████████████████████████▏                                           | 4538/9741 [00:04<00:04, 1085.68it/s] 48%|███████████████████████████████████████▏                                          | 4651/9741 [00:04<00:04, 1095.82it/s] 49%|████████████████████████████████████████▌                                          | 4761/9741 [00:04<00:05, 836.38it/s] 50%|█████████████████████████████████████████▍                                         | 4867/9741 [00:04<00:05, 889.01it/s] 51%|██████████████████████████████████████████▍                                        | 4978/9741 [00:04<00:05, 944.36it/s] 52%|███████████████████████████████████████████▎                                       | 5090/9741 [00:05<00:04, 990.86it/s] 53%|███████████████████████████████████████████▊                                      | 5201/9741 [00:05<00:04, 1022.53it/s] 55%|████████████████████████████████████████████▋                                     | 5313/9741 [00:05<00:04, 1048.08it/s] 56%|█████████████████████████████████████████████▋                                    | 5424/9741 [00:05<00:04, 1063.85it/s] 57%|██████████████████████████████████████████████▌                                   | 5536/9741 [00:05<00:03, 1079.30it/s] 58%|███████████████████████████████████████████████▌                                  | 5647/9741 [00:05<00:03, 1086.60it/s] 59%|████████████████████████████████████████████████▍                                 | 5760/9741 [00:05<00:03, 1096.62it/s] 60%|█████████████████████████████████████████████████▍                                | 5871/9741 [00:05<00:03, 1098.99it/s] 61%|██████████████████████████████████████████████████▎                               | 5983/9741 [00:05<00:03, 1102.91it/s] 63%|███████████████████████████████████████████████████▎                              | 6094/9741 [00:05<00:03, 1097.88it/s] 64%|████████████████████████████████████████████████████▏                             | 6205/9741 [00:06<00:03, 1094.87it/s] 65%|█████████████████████████████████████████████████████▏                            | 6315/9741 [00:06<00:03, 1090.51it/s] 66%|██████████████████████████████████████████████████████                            | 6425/9741 [00:06<00:03, 1090.56it/s] 67%|███████████████████████████████████████████████████████                           | 6535/9741 [00:06<00:02, 1087.19it/s] 68%|███████████████████████████████████████████████████████▉                          | 6645/9741 [00:06<00:02, 1088.26it/s] 69%|████████████████████████████████████████████████████████▊                         | 6756/9741 [00:06<00:02, 1092.02it/s] 70%|█████████████████████████████████████████████████████████▊                        | 6867/9741 [00:06<00:02, 1096.44it/s] 72%|██████████████████████████████████████████████████████████▋                       | 6977/9741 [00:06<00:02, 1097.19it/s] 73%|███████████████████████████████████████████████████████████▋                      | 7089/9741 [00:06<00:02, 1101.39it/s] 74%|████████████████████████████████████████████████████████████▌                     | 7200/9741 [00:06<00:02, 1102.88it/s] 75%|█████████████████████████████████████████████████████████████▌                    | 7311/9741 [00:07<00:02, 1089.12it/s] 76%|██████████████████████████████████████████████████████████████▍                   | 7420/9741 [00:07<00:02, 1052.76it/s] 77%|███████████████████████████████████████████████████████████████▍                  | 7530/9741 [00:07<00:02, 1065.24it/s] 78%|████████████████████████████████████████████████████████████████▎                 | 7640/9741 [00:07<00:01, 1073.37it/s] 80%|█████████████████████████████████████████████████████████████████▏                | 7751/9741 [00:07<00:01, 1082.56it/s] 81%|██████████████████████████████████████████████████████████████████▏               | 7861/9741 [00:07<00:01, 1087.51it/s] 82%|███████████████████████████████████████████████████████████████████               | 7972/9741 [00:07<00:01, 1091.31it/s] 83%|████████████████████████████████████████████████████████████████████              | 8083/9741 [00:07<00:01, 1094.13it/s] 84%|████████████████████████████████████████████████████████████████████▉             | 8194/9741 [00:07<00:01, 1096.29it/s] 85%|█████████████████████████████████████████████████████████████████████▉            | 8304/9741 [00:07<00:01, 1095.05it/s] 86%|██████████████████████████████████████████████████████████████████████▊           | 8414/9741 [00:08<00:01, 1093.52it/s] 88%|███████████████████████████████████████████████████████████████████████▊          | 8524/9741 [00:08<00:01, 1095.20it/s] 89%|████████████████████████████████████████████████████████████████████████▋         | 8634/9741 [00:08<00:01, 1093.98it/s] 90%|█████████████████████████████████████████████████████████████████████████▌        | 8745/9741 [00:08<00:00, 1096.57it/s] 91%|██████████████████████████████████████████████████████████████████████████▌       | 8855/9741 [00:08<00:00, 1096.16it/s] 92%|███████████████████████████████████████████████████████████████████████████▍      | 8966/9741 [00:08<00:00, 1099.14it/s] 93%|████████████████████████████████████████████████████████████████████████████▍     | 9076/9741 [00:08<00:00, 1097.78it/s] 94%|█████████████████████████████████████████████████████████████████████████████▎    | 9187/9741 [00:08<00:00, 1098.56it/s] 95%|██████████████████████████████████████████████████████████████████████████████▎   | 9297/9741 [00:08<00:00, 1097.70it/s] 97%|███████████████████████████████████████████████████████████████████████████████▏  | 9408/9741 [00:09<00:00, 1100.15it/s] 98%|████████████████████████████████████████████████████████████████████████████████▏ | 9519/9741 [00:09<00:00, 1098.38it/s] 99%|█████████████████████████████████████████████████████████████████████████████████ | 9629/9741 [00:09<00:00, 1098.41it/s]100%|█████████████████████████████████████████████████████████████████████████████████▉| 9739/9741 [00:09<00:00, 1095.03it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:09<00:00, 1046.33it/s]
Load End
Num instances: 1000
[2023-08-22 17:24:27,145] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 17:24:30,114] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 17:24:30,115] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 17:24:30,115] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 17:24:30,115] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 17:24:30,115] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 17:24:30,115] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 17:24:30,115] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 17:24:30,115] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fa5b7fd9a60>
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fa5b7fd9940>
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 17:24:30,116] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 17:24:30,117] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 17:24:30,117] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 17:24:30,117] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 17:24:30,117] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.6439151763916016 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: 868

Input: Stella and Twinkle are filling up a truck with a capacity of 6000 stone blocks at the rate of 250 blocks per hour per person. They work for four hours and are then joined by 6 other people who also work at the same rate. How many hours did filling the truck take?
Output: 6

Input: Elijah drank 8.5 pints of coffee yesterday. Emilio drank 9.5 pints of water yesterday. How many cups of liquid did the two boys drink yesterday?
Output: 36

Input: Doris works at the Widget Factory in the packing department. She puts 3 widgets in each carton, which are 4 inches wide, 4 inches long, and 5 inches tall. She then packs those cartons into a shipping box before sending it to the loading bay. The shipping boxes are 20 inches wide, 20 inches long, and 20 inches high. How many widgets get shipped in each shipping box?
Output: 300

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o8-tgsm8k-s10-rFalse
Loading extension module utils...
Time to load utils op: 0.6048867702484131 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:53<43:56, 53.82s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:46<42:30, 53.13s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:37<40:44, 52.01s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:27<39:18, 51.28s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [04:18<38:26, 51.26s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [05:09<37:24, 51.02s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [06:00<36:38, 51.13s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [06:52<35:55, 51.32s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [07:43<35:09, 51.45s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [08:35<34:19, 51.49s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [09:26<33:24, 51.39s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [10:18<32:32, 51.39s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [11:09<31:39, 51.34s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [12:00<30:47, 51.31s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [12:52<30:07, 51.65s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [13:44<29:12, 51.56s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [14:35<28:21, 51.57s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [15:25<27:14, 51.08s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [16:16<26:23, 51.07s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [17:07<25:27, 50.92s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [17:58<24:36, 50.93s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [18:49<23:47, 50.98s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [19:40<22:59, 51.10s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [20:31<22:09, 51.12s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [21:23<21:18, 51.14s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [22:15<20:33, 51.39s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [23:06<19:38, 51.23s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [23:57<18:49, 51.34s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [24:50<18:09, 51.86s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [25:42<17:13, 51.70s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [26:33<16:19, 51.55s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [27:23<15:21, 51.20s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [28:13<14:25, 50.93s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [29:04<13:33, 50.86s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [29:54<12:39, 50.65s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [30:45<11:50, 50.75s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [31:36<10:58, 50.63s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [32:26<10:07, 50.66s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [33:17<09:17, 50.64s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [34:08<08:27, 50.78s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [35:02<07:44, 51.60s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [35:53<06:51, 51.44s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [36:43<05:57, 51.09s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [37:33<05:05, 50.90s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [38:23<04:12, 50.60s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [39:13<03:21, 50.43s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [40:05<02:32, 50.89s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [40:56<01:41, 50.82s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [41:48<00:51, 51.27s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [42:40<00:00, 51.52s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [42:40<00:00, 51.22s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.1335} | avg. gen lenth: 414.778
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o9-tgsm8k-s10-rFalse --seed 10 --max-prompt-length 2048 --num-out-domain 9
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date![nltk_data]   Package punkt is already up-to-date!

using world size: 2
[2023-08-22 18:07:20,642] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o9-tgsm8k-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 9
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o9-tgsm8k-s10-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|▌                                                                                    | 66/9741 [00:00<00:14, 656.70it/s]  1%|█▏                                                                                  | 136/9741 [00:00<00:14, 677.69it/s]  2%|█▊                                                                                  | 205/9741 [00:00<00:14, 680.02it/s]  3%|██▎                                                                                 | 275/9741 [00:00<00:13, 686.24it/s]  4%|██▉                                                                                 | 345/9741 [00:00<00:13, 690.61it/s]  4%|███▌                                                                                | 415/9741 [00:00<00:13, 691.94it/s]  5%|████▏                                                                               | 486/9741 [00:00<00:13, 694.90it/s]  6%|████▊                                                                               | 557/9741 [00:00<00:13, 697.41it/s]  6%|█████▍                                                                              | 627/9741 [00:00<00:13, 682.39it/s]  7%|██████                                                                              | 698/9741 [00:01<00:13, 689.20it/s]  8%|██████▌                                                                             | 768/9741 [00:01<00:12, 691.94it/s]  9%|███████▏                                                                            | 839/9741 [00:01<00:12, 695.57it/s]  9%|███████▊                                                                            | 909/9741 [00:01<00:12, 696.65it/s] 10%|████████▍                                                                           | 980/9741 [00:01<00:12, 699.19it/s] 11%|████████▉                                                                          | 1051/9741 [00:01<00:12, 702.15it/s] 12%|█████████▌                                                                         | 1122/9741 [00:01<00:12, 703.27it/s] 12%|██████████▏                                                                        | 1193/9741 [00:01<00:12, 703.86it/s] 13%|██████████▊                                                                        | 1264/9741 [00:01<00:12, 702.67it/s] 14%|███████████▍                                                                       | 1335/9741 [00:01<00:12, 699.83it/s] 14%|███████████▉                                                                       | 1405/9741 [00:02<00:11, 699.58it/s] 15%|████████████▌                                                                      | 1476/9741 [00:02<00:11, 701.06it/s] 16%|█████████████▏                                                                     | 1547/9741 [00:02<00:11, 701.34it/s] 17%|█████████████▊                                                                     | 1618/9741 [00:02<00:11, 701.69it/s] 17%|██████████████▍                                                                    | 1689/9741 [00:02<00:11, 702.27it/s] 18%|██████████████▉                                                                    | 1760/9741 [00:02<00:11, 686.48it/s] 19%|███████████████▌                                                                   | 1831/9741 [00:02<00:11, 690.92it/s] 20%|████████████████▎                                                                  | 1918/9741 [00:02<00:10, 743.14it/s] 21%|█████████████████▏                                                                 | 2023/9741 [00:02<00:09, 832.06it/s] 22%|██████████████████▏                                                                | 2128/9741 [00:02<00:08, 894.79it/s] 23%|███████████████████                                                                | 2233/9741 [00:03<00:07, 938.67it/s] 24%|███████████████████▉                                                               | 2339/9741 [00:03<00:07, 972.59it/s] 25%|████████████████████▊                                                              | 2440/9741 [00:03<00:07, 980.36it/s] 26%|█████████████████████▋                                                             | 2544/9741 [00:03<00:07, 997.89it/s] 27%|██████████████████████▎                                                           | 2649/9741 [00:03<00:07, 1012.78it/s] 28%|███████████████████████▏                                                          | 2752/9741 [00:03<00:06, 1017.86it/s] 29%|████████████████████████                                                          | 2857/9741 [00:03<00:06, 1025.23it/s] 30%|████████████████████████▉                                                         | 2961/9741 [00:03<00:06, 1029.29it/s] 31%|█████████████████████████▊                                                        | 3066/9741 [00:03<00:06, 1033.26it/s] 33%|██████████████████████████▋                                                       | 3170/9741 [00:03<00:06, 1030.48it/s] 34%|███████████████████████████▌                                                      | 3275/9741 [00:04<00:06, 1034.63it/s] 35%|████████████████████████████▍                                                     | 3379/9741 [00:04<00:06, 1034.74it/s] 36%|█████████████████████████████▎                                                    | 3483/9741 [00:04<00:06, 1035.17it/s] 37%|██████████████████████████████▏                                                   | 3587/9741 [00:04<00:05, 1031.60it/s] 38%|███████████████████████████████                                                   | 3691/9741 [00:04<00:05, 1033.89it/s] 39%|███████████████████████████████▉                                                  | 3796/9741 [00:04<00:05, 1036.11it/s] 40%|████████████████████████████████▊                                                 | 3900/9741 [00:04<00:05, 1033.34it/s] 41%|█████████████████████████████████▋                                                | 4004/9741 [00:04<00:05, 1034.48it/s] 42%|██████████████████████████████████▌                                               | 4108/9741 [00:04<00:05, 1033.41it/s] 43%|███████████████████████████████████▍                                              | 4212/9741 [00:04<00:05, 1021.17it/s] 44%|████████████████████████████████████▎                                             | 4315/9741 [00:05<00:05, 1022.69it/s] 45%|█████████████████████████████████████▏                                            | 4419/9741 [00:05<00:05, 1027.24it/s] 46%|██████████████████████████████████████▌                                            | 4522/9741 [00:05<00:05, 986.95it/s] 47%|███████████████████████████████████████▍                                           | 4625/9741 [00:05<00:05, 999.32it/s] 49%|████████████████████████████████████████▎                                          | 4726/9741 [00:05<00:05, 839.69it/s] 50%|█████████████████████████████████████████▏                                         | 4829/9741 [00:05<00:05, 888.96it/s] 51%|██████████████████████████████████████████                                         | 4932/9741 [00:05<00:05, 925.55it/s] 52%|██████████████████████████████████████████▉                                        | 5035/9741 [00:05<00:04, 954.56it/s] 53%|███████████████████████████████████████████▊                                       | 5139/9741 [00:05<00:04, 976.82it/s] 54%|████████████████████████████████████████████▋                                      | 5242/9741 [00:06<00:04, 989.88it/s] 55%|█████████████████████████████████████████████                                     | 5346/9741 [00:06<00:04, 1001.78it/s] 56%|█████████████████████████████████████████████▊                                    | 5449/9741 [00:06<00:04, 1008.45it/s] 57%|██████████████████████████████████████████████▋                                   | 5552/9741 [00:06<00:04, 1014.72it/s] 58%|███████████████████████████████████████████████▌                                  | 5654/9741 [00:06<00:04, 1015.88it/s] 59%|████████████████████████████████████████████████▍                                 | 5757/9741 [00:06<00:03, 1019.63it/s] 60%|█████████████████████████████████████████████████▎                                | 5860/9741 [00:06<00:03, 1020.71it/s] 61%|██████████████████████████████████████████████████▏                               | 5963/9741 [00:06<00:03, 1022.62it/s] 62%|███████████████████████████████████████████████████                               | 6066/9741 [00:06<00:03, 1021.67it/s] 63%|███████████████████████████████████████████████████▉                              | 6169/9741 [00:06<00:03, 1018.89it/s] 64%|████████████████████████████████████████████████████▊                             | 6271/9741 [00:07<00:03, 1016.99it/s] 65%|██████████████████████████████████████████████████████▎                            | 6373/9741 [00:07<00:03, 999.87it/s] 66%|██████████████████████████████████████████████████████▌                           | 6475/9741 [00:07<00:03, 1004.86it/s] 68%|███████████████████████████████████████████████████████▎                          | 6577/9741 [00:07<00:03, 1008.77it/s] 69%|████████████████████████████████████████████████████████▏                         | 6681/9741 [00:07<00:03, 1015.28it/s] 70%|█████████████████████████████████████████████████████████                         | 6784/9741 [00:07<00:02, 1018.75it/s] 71%|█████████████████████████████████████████████████████████▉                        | 6887/9741 [00:07<00:02, 1021.15it/s] 72%|██████████████████████████████████████████████████████████▊                       | 6990/9741 [00:07<00:02, 1019.60it/s] 73%|███████████████████████████████████████████████████████████▋                      | 7093/9741 [00:07<00:02, 1020.99it/s] 74%|████████████████████████████████████████████████████████████▌                     | 7196/9741 [00:07<00:02, 1021.14it/s] 75%|█████████████████████████████████████████████████████████████▍                    | 7299/9741 [00:08<00:02, 1022.08it/s] 76%|██████████████████████████████████████████████████████████████▎                   | 7403/9741 [00:08<00:02, 1024.43it/s] 77%|███████████████████████████████████████████████████████████████▉                   | 7506/9741 [00:08<00:02, 986.01it/s] 78%|████████████████████████████████████████████████████████████████▊                  | 7608/9741 [00:08<00:02, 995.26it/s] 79%|████████████████████████████████████████████████████████████████▉                 | 7710/9741 [00:08<00:02, 1000.06it/s] 80%|█████████████████████████████████████████████████████████████████▊                | 7813/9741 [00:08<00:01, 1006.51it/s] 81%|██████████████████████████████████████████████████████████████████▋               | 7915/9741 [00:08<00:01, 1009.32it/s] 82%|███████████████████████████████████████████████████████████████████▍              | 8018/9741 [00:08<00:01, 1012.85it/s] 83%|████████████████████████████████████████████████████████████████████▎             | 8120/9741 [00:08<00:01, 1012.65it/s] 84%|█████████████████████████████████████████████████████████████████████▏            | 8222/9741 [00:08<00:01, 1014.02it/s] 85%|██████████████████████████████████████████████████████████████████████            | 8324/9741 [00:09<00:01, 1012.12it/s] 87%|██████████████████████████████████████████████████████████████████████▉           | 8426/9741 [00:09<00:01, 1014.01it/s] 88%|███████████████████████████████████████████████████████████████████████▊          | 8528/9741 [00:09<00:01, 1014.21it/s] 89%|████████████████████████████████████████████████████████████████████████▋         | 8630/9741 [00:09<00:01, 1010.61it/s] 90%|█████████████████████████████████████████████████████████████████████████▌        | 8732/9741 [00:09<00:00, 1012.42it/s] 91%|██████████████████████████████████████████████████████████████████████████▎       | 8834/9741 [00:09<00:00, 1010.13it/s] 92%|███████████████████████████████████████████████████████████████████████████▏      | 8936/9741 [00:09<00:00, 1011.06it/s] 93%|████████████████████████████████████████████████████████████████████████████      | 9038/9741 [00:09<00:00, 1008.75it/s] 94%|████████████████████████████████████████████████████████████████████████████▉     | 9140/9741 [00:09<00:00, 1010.45it/s] 95%|█████████████████████████████████████████████████████████████████████████████▊    | 9242/9741 [00:09<00:00, 1009.54it/s] 96%|██████████████████████████████████████████████████████████████████████████████▋   | 9344/9741 [00:10<00:00, 1010.27it/s] 97%|███████████████████████████████████████████████████████████████████████████████▌  | 9446/9741 [00:10<00:00, 1008.10it/s] 98%|████████████████████████████████████████████████████████████████████████████████▎ | 9547/9741 [00:10<00:00, 1004.34it/s] 99%|█████████████████████████████████████████████████████████████████████████████████▏| 9648/9741 [00:10<00:00, 1003.91it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:10<00:00, 929.29it/s]
Load End
Num instances: 1000
[2023-08-22 18:07:42,265] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 18:07:45,021] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 18:07:45,021] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 18:07:45,021] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f5be77e0a60>
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f5be77e0940>
[2023-08-22 18:07:45,022] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 18:07:45,023] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 18:07:45,023] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 18:07:45,023] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 18:07:45,023] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 18:07:45,023] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 18:07:45,023] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 18:07:45,023] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 18:07:45,023] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 18:07:45,023] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 18:07:45,023] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 18:07:45,023] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 18:07:45,023] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 18:07:45,023] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 18:07:45,023] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 18:07:45,023] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 18:07:45,023] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 18:07:45,023] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 18:07:45,023] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 18:07:45,023] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 18:07:45,023] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 18:07:45,023] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 18:07:45,023] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.43081021308898926 seconds
Loading extension module utils...
Time to load utils op: 0.5047924518585205 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Adam bought 3 kilograms of nuts and 2.5 kilograms of dried fruits at a store. One kilogram of nuts costs $12 and one kilogram of dried fruit costs $8. How much did his purchases cost?
Output: 56

Input: Johns goes to the gym 3 times a week.  He spends 1 hour each day lifting weight. Additionally, he also spends a third of his weightlifting time warming up and doing cardio each day.  How many hours does he spend at the gym a week?
Output: 4

Input: James has to refuel his plane.  It used to cost $200 to refill the tank.  He got an extra tank to double fuel capacity.  Fuel prices also went up by 20%.  How much does he pay now for fuel?
Output: 480

Input: The number of goals scored in a game against Barca by exactly two players last season accounts for 20% of all goals scored in the league. If the players scored an equal number of goals, and the total number of goals scored in the league against Barca that season is 300, calculate the number of goals each of the two players scored.
Output: 30

Input: Every day Tom drinks 5 12-oz cans of soda plus 64 ounces of water. How many ounces of fluid does he drink a week?
Output: 868

Input: Stella and Twinkle are filling up a truck with a capacity of 6000 stone blocks at the rate of 250 blocks per hour per person. They work for four hours and are then joined by 6 other people who also work at the same rate. How many hours did filling the truck take?
Output: 6

Input: Elijah drank 8.5 pints of coffee yesterday. Emilio drank 9.5 pints of water yesterday. How many cups of liquid did the two boys drink yesterday?
Output: 36

Input: Doris works at the Widget Factory in the packing department. She puts 3 widgets in each carton, which are 4 inches wide, 4 inches long, and 5 inches tall. She then packs those cartons into a shipping box before sending it to the loading bay. The shipping boxes are 20 inches wide, 20 inches long, and 20 inches high. How many widgets get shipped in each shipping box?
Output: 300

Input: Queenie earns $150 a day as a part-time clerk. She earns an additional $5 per hour as overtime pay. How much will Queenie receive for working 5 days with 4 hours overtime?
Output: 770

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o9-tgsm8k-s10-rFalse
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:49<40:27, 49.55s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:39<39:35, 49.49s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:28<38:46, 49.50s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:16<37:35, 49.03s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [04:05<36:45, 49.00s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [04:54<35:48, 48.84s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [05:43<34:58, 48.80s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [06:31<34:01, 48.61s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [07:19<33:11, 48.58s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [08:09<32:42, 49.05s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [08:59<32:00, 49.25s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [09:47<31:00, 48.95s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [10:37<30:24, 49.30s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [11:27<29:33, 49.27s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [12:15<28:36, 49.04s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [13:04<27:49, 49.10s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [13:53<26:55, 48.96s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [14:42<26:06, 48.95s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [15:31<25:20, 49.04s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [16:19<24:22, 48.74s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [17:07<23:25, 48.46s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [17:55<22:33, 48.35s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [18:43<21:41, 48.20s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [19:32<20:57, 48.35s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [20:22<20:20, 48.83s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [21:10<19:30, 48.77s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [21:59<18:41, 48.75s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [22:49<18:01, 49.14s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [23:38<17:11, 49.13s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [24:27<16:23, 49.17s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [25:16<15:31, 49.05s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [26:04<14:37, 48.77s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [26:53<13:49, 48.81s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [27:42<13:00, 48.78s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [28:32<12:16, 49.09s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [29:22<11:31, 49.39s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [30:11<10:41, 49.35s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [31:00<09:51, 49.33s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [31:49<08:59, 49.08s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [32:38<08:10, 49.05s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [33:28<07:25, 49.50s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [34:17<06:33, 49.14s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [35:06<05:43, 49.13s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [35:54<04:53, 48.99s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [36:43<04:04, 48.91s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [37:32<03:15, 48.93s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [38:23<02:28, 49.46s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [39:11<01:38, 49.04s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [40:02<00:49, 49.64s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [40:50<00:00, 49.29s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [40:50<00:00, 49.02s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 0.8929} | avg. gen lenth: 435.486
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s20-rTrue --seed 20 --max-prompt-length 2048 --rationales --num-out-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 18:48:54,672] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s20-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 1
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o1-tgsm8k-s20-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  2%|█▌                                                                                 | 187/9741 [00:00<00:05, 1862.86it/s]  4%|███▎                                                                               | 385/9741 [00:00<00:04, 1928.54it/s]  6%|████▉                                                                              | 582/9741 [00:00<00:04, 1947.33it/s]  8%|██████▋                                                                            | 781/9741 [00:00<00:04, 1961.61it/s] 10%|████████▎                                                                          | 981/9741 [00:00<00:04, 1974.23it/s] 12%|█████████▉                                                                        | 1182/9741 [00:00<00:04, 1986.34it/s] 14%|███████████▋                                                                      | 1381/9741 [00:00<00:04, 1987.14it/s] 16%|█████████████▎                                                                    | 1581/9741 [00:00<00:04, 1988.42it/s] 18%|██████████████▉                                                                   | 1780/9741 [00:00<00:04, 1932.56it/s] 20%|████████████████▋                                                                 | 1980/9741 [00:01<00:03, 1951.19it/s] 22%|██████████████████▎                                                               | 2179/9741 [00:01<00:03, 1961.72it/s] 24%|████████████████████                                                              | 2381/9741 [00:01<00:03, 1977.77it/s] 27%|█████████████████████▊                                                            | 2584/9741 [00:01<00:03, 1991.42it/s] 29%|███████████████████████▍                                                          | 2785/9741 [00:01<00:03, 1996.03it/s] 31%|█████████████████████████▏                                                        | 2988/9741 [00:01<00:03, 2005.24it/s] 33%|██████████████████████████▊                                                       | 3190/9741 [00:01<00:03, 2007.70it/s] 35%|████████████████████████████▌                                                     | 3392/9741 [00:01<00:03, 2009.70it/s] 37%|██████████████████████████████▎                                                   | 3594/9741 [00:01<00:03, 2007.36it/s] 39%|███████████████████████████████▉                                                  | 3795/9741 [00:01<00:02, 2007.78it/s] 41%|█████████████████████████████████▋                                                | 3996/9741 [00:02<00:02, 2005.19it/s] 43%|███████████████████████████████████▎                                              | 4197/9741 [00:02<00:02, 2006.04it/s] 45%|█████████████████████████████████████                                             | 4400/9741 [00:02<00:02, 2010.37it/s] 47%|██████████████████████████████████████▋                                           | 4602/9741 [00:02<00:02, 1988.28it/s] 49%|████████████████████████████████████████▍                                         | 4801/9741 [00:02<00:02, 1869.25it/s] 52%|███████████████████████████████████████████                                       | 5109/9741 [00:02<00:02, 2212.45it/s] 56%|█████████████████████████████████████████████▌                                    | 5416/9741 [00:02<00:01, 2458.77it/s] 59%|████████████████████████████████████████████████▏                                 | 5727/9741 [00:02<00:01, 2648.14it/s] 62%|██████████████████████████████████████████████████▊                               | 6039/9741 [00:02<00:01, 2786.51it/s] 65%|█████████████████████████████████████████████████████▍                            | 6349/9741 [00:02<00:01, 2877.41it/s] 68%|████████████████████████████████████████████████████████                          | 6660/9741 [00:03<00:01, 2945.52it/s] 72%|██████████████████████████████████████████████████████████▋                       | 6972/9741 [00:03<00:00, 2997.10it/s] 75%|█████████████████████████████████████████████████████████████▏                    | 7273/9741 [00:03<00:00, 2989.80it/s] 78%|███████████████████████████████████████████████████████████████▋                  | 7573/9741 [00:03<00:00, 2956.41it/s] 81%|██████████████████████████████████████████████████████████████████▎               | 7874/9741 [00:03<00:00, 2972.09it/s] 84%|████████████████████████████████████████████████████████████████████▊             | 8181/9741 [00:03<00:00, 2998.81it/s] 87%|███████████████████████████████████████████████████████████████████████▍          | 8491/9741 [00:03<00:00, 3028.38it/s] 90%|██████████████████████████████████████████████████████████████████████████        | 8800/9741 [00:03<00:00, 3046.11it/s] 94%|████████████████████████████████████████████████████████████████████████████▋     | 9113/9741 [00:03<00:00, 3068.52it/s] 97%|███████████████████████████████████████████████████████████████████████████████▎  | 9425/9741 [00:03<00:00, 3083.05it/s]100%|█████████████████████████████████████████████████████████████████████████████████▉| 9735/9741 [00:04<00:00, 3085.54it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:04<00:00, 2404.75it/s]
Load End
Num instances: 1000
[2023-08-22 18:49:10,040] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 18:49:13,347] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 18:49:13,347] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f64a1d31a60>
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 18:49:13,348] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 18:49:13,349] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 18:49:13,349] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 18:49:13,349] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 18:49:13,349] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f64a1d31940>
[2023-08-22 18:49:13,349] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 18:49:13,349] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 18:49:13,349] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 18:49:13,349] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 18:49:13,349] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 18:49:13,349] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 18:49:13,349] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 18:49:13,349] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 18:49:13,349] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 18:49:13,349] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 18:49:13,349] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 18:49:13,349] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 18:49:13,349] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 18:49:13,349] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 18:49:13,349] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 18:49:13,349] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 18:49:13,349] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 18:49:13,349] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 18:49:13,349] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 18:49:13,349] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 18:49:13,349] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 18:49:13,349] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 18:49:13,349] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.412280797958374 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: Let x = the total number of candies Corey has.
x + 8 = the total number of candies Tapanga has.
The equation for the total number of candies is x + (x + 8) = 66
Combining like terms, we get 2x + 8 = 66
Subtracting 8 from both sides, we get 2x = 58
Dividing both sides by 2, we get x = <<29=29>>29, so Corey has 29 candies.
So the final answer is 29

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o1-tgsm8k-s20-rTrue
Loading extension module utils...
Time to load utils op: 0.5065360069274902 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [01:04<52:50, 64.71s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [02:12<53:19, 66.65s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [03:14<50:28, 64.43s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [04:14<47:59, 62.59s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [05:15<46:34, 62.09s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [06:16<45:15, 61.71s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [07:18<44:16, 61.79s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [08:21<43:29, 62.12s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [09:23<42:27, 62.13s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [10:26<41:31, 62.29s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [11:26<40:07, 61.73s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [12:28<39:08, 61.80s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [13:29<38:01, 61.65s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [14:32<37:08, 61.89s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [15:32<35:45, 61.31s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [16:34<34:59, 61.76s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [17:36<33:54, 61.66s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [18:37<32:51, 61.59s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [19:39<31:50, 61.62s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [20:42<30:58, 61.95s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [21:43<29:51, 61.77s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [22:43<28:34, 61.23s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [23:47<27:51, 61.91s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [24:47<26:34, 61.32s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [25:48<25:32, 61.30s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [26:51<24:42, 61.78s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [27:53<23:44, 61.92s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [28:55<22:45, 62.06s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [29:58<21:46, 62.20s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [31:01<20:46, 62.35s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [32:01<19:36, 61.90s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [33:05<18:43, 62.39s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [34:06<17:35, 62.07s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [35:07<16:24, 61.56s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [36:10<15:30, 62.02s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [37:11<14:23, 61.71s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [38:13<13:23, 61.83s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [39:14<12:21, 61.76s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [40:18<11:24, 62.24s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [41:19<10:19, 61.90s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [42:22<09:21, 62.34s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [43:25<08:19, 62.44s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [44:29<07:21, 63.09s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [45:31<06:15, 62.61s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [46:34<05:14, 62.83s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [47:38<04:11, 62.99s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [48:39<03:07, 62.60s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [49:41<02:04, 62.18s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [50:42<01:01, 61.87s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [51:43<00:00, 61.72s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [51:43<00:00, 62.07s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.3952} | avg. gen lenth: 386.696
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s20-rTrue --seed 20 --max-prompt-length 2048 --rationales --num-out-domain 2
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 19:41:19,221] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s20-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 2
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o2-tgsm8k-s20-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  2%|█▎                                                                                 | 151/9741 [00:00<00:06, 1500.77it/s]  3%|██▌                                                                                | 307/9741 [00:00<00:06, 1534.66it/s]  5%|███▉                                                                               | 464/9741 [00:00<00:05, 1548.97it/s]  6%|█████▎                                                                             | 621/9741 [00:00<00:05, 1553.26it/s]  8%|██████▋                                                                            | 781/9741 [00:00<00:05, 1566.95it/s] 10%|████████                                                                           | 941/9741 [00:00<00:05, 1576.33it/s] 11%|█████████▎                                                                        | 1102/9741 [00:00<00:05, 1584.47it/s] 13%|██████████▋                                                                       | 1263/9741 [00:00<00:05, 1590.46it/s] 15%|███████████▉                                                                      | 1423/9741 [00:00<00:05, 1589.74it/s] 16%|█████████████▎                                                                    | 1582/9741 [00:01<00:05, 1549.06it/s] 18%|██████████████▋                                                                   | 1740/9741 [00:01<00:05, 1557.21it/s] 19%|███████████████▉                                                                  | 1896/9741 [00:01<00:05, 1530.50it/s] 21%|█████████████████▎                                                                | 2053/9741 [00:01<00:04, 1542.13it/s] 23%|██████████████████▌                                                               | 2210/9741 [00:01<00:04, 1549.40it/s] 24%|███████████████████▉                                                              | 2367/9741 [00:01<00:04, 1554.32it/s] 26%|█████████████████████▎                                                            | 2525/9741 [00:01<00:04, 1559.70it/s] 28%|██████████████████████▌                                                           | 2682/9741 [00:01<00:04, 1558.29it/s] 29%|███████████████████████▉                                                          | 2839/9741 [00:01<00:04, 1560.88it/s] 31%|█████████████████████████▏                                                        | 2996/9741 [00:01<00:04, 1563.34it/s] 32%|██████████████████████████▌                                                       | 3153/9741 [00:02<00:04, 1557.68it/s] 34%|███████████████████████████▊                                                      | 3311/9741 [00:02<00:04, 1563.69it/s] 36%|█████████████████████████████▏                                                    | 3468/9741 [00:02<00:04, 1561.40it/s] 37%|██████████████████████████████▌                                                   | 3625/9741 [00:02<00:03, 1562.10it/s] 39%|███████████████████████████████▊                                                  | 3782/9741 [00:02<00:03, 1561.08it/s] 40%|█████████████████████████████████▏                                                | 3939/9741 [00:02<00:03, 1560.45it/s] 42%|██████████████████████████████████▍                                               | 4096/9741 [00:02<00:03, 1560.06it/s] 44%|███████████████████████████████████▊                                              | 4254/9741 [00:02<00:03, 1563.60it/s] 45%|█████████████████████████████████████▏                                            | 4411/9741 [00:02<00:03, 1562.43it/s] 47%|██████████████████████████████████████▍                                           | 4568/9741 [00:02<00:03, 1530.88it/s] 48%|███████████████████████████████████████▋                                          | 4722/9741 [00:03<00:04, 1181.31it/s] 50%|█████████████████████████████████████████                                         | 4874/9741 [00:03<00:03, 1259.47it/s] 52%|██████████████████████████████████████████▎                                       | 5027/9741 [00:03<00:03, 1327.79it/s] 53%|███████████████████████████████████████████▌                                      | 5181/9741 [00:03<00:03, 1384.53it/s] 55%|████████████████████████████████████████████▉                                     | 5334/9741 [00:03<00:03, 1424.79it/s] 56%|██████████████████████████████████████████████▏                                   | 5489/9741 [00:03<00:02, 1458.15it/s] 58%|███████████████████████████████████████████████▌                                  | 5645/9741 [00:03<00:02, 1486.78it/s] 60%|████████████████████████████████████████████████▊                                 | 5803/9741 [00:03<00:02, 1513.91it/s] 61%|██████████████████████████████████████████████████▏                               | 5958/9741 [00:03<00:02, 1524.48it/s] 63%|███████████████████████████████████████████████████▍                              | 6112/9741 [00:04<00:02, 1500.24it/s] 64%|████████████████████████████████████████████████████▋                             | 6265/9741 [00:04<00:02, 1507.32it/s] 66%|██████████████████████████████████████████████████████                            | 6423/9741 [00:04<00:02, 1528.33it/s] 68%|███████████████████████████████████████████████████████▍                          | 6579/9741 [00:04<00:02, 1537.13it/s] 69%|████████████████████████████████████████████████████████▋                         | 6734/9741 [00:04<00:01, 1536.35it/s] 71%|██████████████████████████████████████████████████████████                        | 6890/9741 [00:04<00:01, 1542.60it/s] 72%|███████████████████████████████████████████████████████████▎                      | 7045/9741 [00:04<00:01, 1543.28it/s] 74%|████████████████████████████████████████████████████████████▋                     | 7202/9741 [00:04<00:01, 1549.87it/s] 76%|█████████████████████████████████████████████████████████████▉                    | 7360/9741 [00:04<00:01, 1556.46it/s] 77%|███████████████████████████████████████████████████████████████▎                  | 7516/9741 [00:04<00:01, 1504.75it/s] 79%|████████████████████████████████████████████████████████████████▌                 | 7670/9741 [00:05<00:01, 1513.74it/s] 80%|█████████████████████████████████████████████████████████████████▊                | 7825/9741 [00:05<00:01, 1522.83it/s] 82%|███████████████████████████████████████████████████████████████████▏              | 7980/9741 [00:05<00:01, 1530.13it/s] 84%|████████████████████████████████████████████████████████████████████▍             | 8134/9741 [00:05<00:01, 1532.35it/s] 85%|█████████████████████████████████████████████████████████████████████▊            | 8291/9741 [00:05<00:00, 1541.69it/s] 87%|███████████████████████████████████████████████████████████████████████           | 8446/9741 [00:05<00:00, 1543.75it/s] 88%|████████████████████████████████████████████████████████████████████████▍         | 8601/9741 [00:05<00:00, 1540.33it/s] 90%|█████████████████████████████████████████████████████████████████████████▋        | 8757/9741 [00:05<00:00, 1544.97it/s] 91%|███████████████████████████████████████████████████████████████████████████       | 8912/9741 [00:05<00:00, 1546.08it/s] 93%|████████████████████████████████████████████████████████████████████████████▎     | 9067/9741 [00:05<00:00, 1546.22it/s] 95%|█████████████████████████████████████████████████████████████████████████████▋    | 9223/9741 [00:06<00:00, 1548.73it/s] 96%|██████████████████████████████████████████████████████████████████████████████▉   | 9378/9741 [00:06<00:00, 1546.60it/s] 98%|████████████████████████████████████████████████████████████████████████████████▏ | 9533/9741 [00:06<00:00, 1544.11it/s] 99%|█████████████████████████████████████████████████████████████████████████████████▌| 9688/9741 [00:06<00:00, 1542.66it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:06<00:00, 1521.83it/s]
Load End
Num instances: 1000
[2023-08-22 19:41:36,812] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 19:41:39,868] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 19:41:39,868] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7ff1a0a51a60>
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 19:41:39,869] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7ff1a0a51940>
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 19:41:39,870] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 19:41:39,870] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4891626834869385 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: Let x = the total number of candies Corey has.
x + 8 = the total number of candies Tapanga has.
The equation for the total number of candies is x + (x + 8) = 66
Combining like terms, we get 2x + 8 = 66
Subtracting 8 from both sides, we get 2x = 58
Dividing both sides by 2, we get x = <<29=29>>29, so Corey has 29 candies.
So the final answer is 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: At 5 cents a minute, calling his father cost Freddy 5* 45 = <<5*45=225>>225 cents.
At 25 cents a minute, calling his brother cost Freddy 25 * 31 = <<25*31=775>>775 cents.
Adding the cost of calling his father and brother, we find that Freddy paid a total of 225 + 775 = <<225+775=1000>>1000 cents.
Since each dollar has 100 cents, Freddy paid 1000 / 100 = <<1000/100=10>>10 dollars
So the final answer is 10

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o2-tgsm8k-s20-rTrue
Loading extension module utils...
Time to load utils op: 0.5045218467712402 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:54<44:34, 54.57s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:48<43:28, 54.35s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:43<42:35, 54.37s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:37<41:37, 54.29s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [04:31<40:36, 54.14s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [05:25<39:46, 54.24s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [06:20<38:59, 54.41s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [07:14<37:58, 54.25s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [08:07<36:54, 54.02s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [09:02<36:10, 54.26s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [09:58<35:30, 54.63s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [10:51<34:27, 54.41s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [11:48<33:52, 54.93s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [12:43<32:57, 54.94s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [13:37<31:54, 54.69s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [14:31<30:59, 54.70s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [15:25<29:58, 54.51s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [16:20<29:04, 54.52s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [17:15<28:12, 54.58s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [18:09<27:14, 54.50s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [19:03<26:13, 54.27s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [19:58<25:28, 54.57s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [20:53<24:38, 54.76s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [21:47<23:37, 54.51s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [22:41<22:38, 54.32s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [23:37<21:55, 54.83s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [24:30<20:49, 54.31s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [25:24<19:53, 54.24s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [26:19<19:04, 54.51s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [27:13<18:05, 54.27s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [28:07<17:10, 54.25s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [29:02<16:17, 54.32s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [29:56<15:21, 54.21s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [30:50<14:26, 54.16s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [31:45<13:37, 54.49s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [32:39<12:42, 54.48s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [33:33<11:46, 54.34s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [34:29<10:55, 54.65s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [35:24<10:01, 54.71s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [36:17<09:02, 54.24s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [37:11<08:08, 54.31s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [38:05<07:12, 54.00s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [38:59<06:19, 54.22s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [39:53<05:24, 54.08s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [40:48<04:31, 54.24s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [41:44<03:39, 54.87s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [42:38<02:43, 54.51s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [43:32<01:48, 54.50s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [44:26<00:54, 54.26s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [45:20<00:00, 54.31s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [45:20<00:00, 54.42s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.1746} | avg. gen lenth: 430.068
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o3-tgsm8k-s20-rTrue --seed 20 --max-prompt-length 2048 --rationales --num-out-domain 3
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 20:27:08,141] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o3-tgsm8k-s20-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 3
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o3-tgsm8k-s20-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|▋                                                                                    | 75/9741 [00:00<00:13, 740.65it/s]  2%|█▎                                                                                  | 152/9741 [00:00<00:12, 755.80it/s]  2%|█▉                                                                                  | 229/9741 [00:00<00:12, 760.41it/s]  3%|██▋                                                                                 | 307/9741 [00:00<00:12, 767.69it/s]  4%|███▎                                                                                | 385/9741 [00:00<00:12, 771.25it/s]  5%|███▉                                                                                | 463/9741 [00:00<00:11, 774.13it/s]  6%|████▋                                                                               | 542/9741 [00:00<00:11, 777.43it/s]  6%|█████▎                                                                              | 621/9741 [00:00<00:11, 780.46it/s]  7%|██████                                                                              | 700/9741 [00:00<00:11, 759.39it/s]  8%|██████▋                                                                             | 779/9741 [00:01<00:11, 766.32it/s]  9%|███████▍                                                                            | 858/9741 [00:01<00:11, 771.43it/s] 10%|████████                                                                            | 937/9741 [00:01<00:11, 774.89it/s] 10%|████████▋                                                                          | 1016/9741 [00:01<00:11, 778.72it/s] 11%|█████████▎                                                                         | 1098/9741 [00:01<00:10, 790.98it/s] 12%|██████████▎                                                                        | 1212/9741 [00:01<00:09, 893.87it/s] 14%|███████████▎                                                                       | 1328/9741 [00:01<00:08, 972.08it/s] 15%|████████████▏                                                                     | 1446/9741 [00:01<00:08, 1032.31it/s] 16%|█████████████▏                                                                    | 1564/9741 [00:01<00:07, 1074.59it/s] 17%|██████████████▏                                                                   | 1681/9741 [00:01<00:07, 1100.32it/s] 18%|███████████████                                                                   | 1792/9741 [00:02<00:07, 1097.79it/s] 20%|████████████████                                                                  | 1909/9741 [00:02<00:07, 1118.79it/s] 21%|█████████████████                                                                 | 2026/9741 [00:02<00:06, 1132.53it/s] 22%|██████████████████                                                                | 2143/9741 [00:02<00:06, 1143.02it/s] 23%|███████████████████                                                               | 2260/9741 [00:02<00:06, 1148.09it/s] 24%|███████████████████▉                                                              | 2375/9741 [00:02<00:06, 1146.08it/s] 26%|████████████████████▉                                                             | 2491/9741 [00:02<00:06, 1148.93it/s] 27%|█████████████████████▉                                                            | 2609/9741 [00:02<00:06, 1155.64it/s] 28%|██████████████████████▉                                                           | 2725/9741 [00:02<00:06, 1156.08it/s] 29%|███████████████████████▉                                                          | 2842/9741 [00:02<00:05, 1157.56it/s] 30%|████████████████████████▉                                                         | 2958/9741 [00:03<00:05, 1158.17it/s] 32%|█████████████████████████▉                                                        | 3075/9741 [00:03<00:05, 1160.08it/s] 33%|██████████████████████████▊                                                       | 3192/9741 [00:03<00:05, 1140.28it/s] 34%|███████████████████████████▊                                                      | 3309/9741 [00:03<00:05, 1147.92it/s] 35%|████████████████████████████▊                                                     | 3425/9741 [00:03<00:05, 1149.46it/s] 36%|█████████████████████████████▊                                                    | 3540/9741 [00:03<00:05, 1108.26it/s] 38%|██████████████████████████████▊                                                   | 3656/9741 [00:03<00:05, 1121.85it/s] 39%|███████████████████████████████▊                                                  | 3774/9741 [00:03<00:05, 1136.08it/s] 40%|████████████████████████████████▊                                                 | 3891/9741 [00:03<00:05, 1144.66it/s] 41%|█████████████████████████████████▋                                                | 4009/9741 [00:03<00:04, 1153.33it/s] 42%|██████████████████████████████████▋                                               | 4126/9741 [00:04<00:04, 1156.25it/s] 44%|███████████████████████████████████▋                                              | 4244/9741 [00:04<00:04, 1160.91it/s] 45%|████████████████████████████████████▋                                             | 4361/9741 [00:04<00:04, 1161.26it/s] 46%|█████████████████████████████████████▋                                            | 4479/9741 [00:04<00:04, 1164.07it/s] 47%|██████████████████████████████████████▋                                           | 4596/9741 [00:04<00:04, 1128.29it/s] 48%|████████████████████████████████████████▏                                          | 4710/9741 [00:04<00:05, 865.05it/s] 49%|█████████████████████████████████████████                                          | 4819/9741 [00:04<00:05, 918.84it/s] 51%|██████████████████████████████████████████                                         | 4933/9741 [00:04<00:04, 974.55it/s] 52%|██████████████████████████████████████████▌                                       | 5049/9741 [00:04<00:04, 1024.03it/s] 53%|███████████████████████████████████████████▍                                      | 5165/9741 [00:05<00:04, 1059.55it/s] 54%|████████████████████████████████████████████▍                                     | 5282/9741 [00:05<00:04, 1088.22it/s] 55%|█████████████████████████████████████████████▍                                    | 5397/9741 [00:05<00:03, 1103.28it/s] 57%|██████████████████████████████████████████████▍                                   | 5514/9741 [00:05<00:03, 1120.76it/s] 58%|███████████████████████████████████████████████▍                                  | 5630/9741 [00:05<00:03, 1130.74it/s] 59%|████████████████████████████████████████████████▍                                 | 5747/9741 [00:05<00:03, 1139.40it/s] 60%|█████████████████████████████████████████████████▎                                | 5862/9741 [00:05<00:03, 1142.24it/s] 61%|██████████████████████████████████████████████████▎                               | 5979/9741 [00:05<00:03, 1148.80it/s] 63%|███████████████████████████████████████████████████▎                              | 6095/9741 [00:05<00:03, 1148.38it/s] 64%|████████████████████████████████████████████████████▎                             | 6211/9741 [00:05<00:03, 1150.66it/s] 65%|█████████████████████████████████████████████████████▎                            | 6327/9741 [00:06<00:02, 1146.59it/s] 66%|██████████████████████████████████████████████████████▏                           | 6442/9741 [00:06<00:02, 1145.40it/s] 67%|███████████████████████████████████████████████████████▏                          | 6557/9741 [00:06<00:02, 1145.47it/s] 68%|████████████████████████████████████████████████████████▏                         | 6672/9741 [00:06<00:02, 1146.61it/s] 70%|█████████████████████████████████████████████████████████▏                        | 6787/9741 [00:06<00:02, 1147.09it/s] 71%|██████████████████████████████████████████████████████████                        | 6903/9741 [00:06<00:02, 1148.47it/s] 72%|███████████████████████████████████████████████████████████                       | 7018/9741 [00:06<00:02, 1148.67it/s] 73%|████████████████████████████████████████████████████████████                      | 7134/9741 [00:06<00:02, 1150.78it/s] 74%|█████████████████████████████████████████████████████████████                     | 7250/9741 [00:06<00:02, 1147.87it/s] 76%|██████████████████████████████████████████████████████████████                    | 7366/9741 [00:06<00:02, 1150.04it/s] 77%|██████████████████████████████████████████████████████████████▉                   | 7482/9741 [00:07<00:02, 1121.13it/s] 78%|███████████████████████████████████████████████████████████████▉                  | 7597/9741 [00:07<00:01, 1128.04it/s] 79%|████████████████████████████████████████████████████████████████▉                 | 7710/9741 [00:07<00:01, 1127.02it/s] 80%|█████████████████████████████████████████████████████████████████▊                | 7825/9741 [00:07<00:01, 1132.54it/s] 82%|██████████████████████████████████████████████████████████████████▊               | 7940/9741 [00:07<00:01, 1134.83it/s] 83%|███████████████████████████████████████████████████████████████████▊              | 8055/9741 [00:07<00:01, 1136.38it/s] 84%|████████████████████████████████████████████████████████████████████▊             | 8169/9741 [00:07<00:01, 1136.81it/s] 85%|█████████████████████████████████████████████████████████████████████▋            | 8284/9741 [00:07<00:01, 1138.45it/s] 86%|██████████████████████████████████████████████████████████████████████▋           | 8398/9741 [00:07<00:01, 1136.98it/s] 87%|███████████████████████████████████████████████████████████████████████▋          | 8513/9741 [00:07<00:01, 1139.62it/s] 89%|████████████████████████████████████████████████████████████████████████▌         | 8627/9741 [00:08<00:00, 1135.86it/s] 90%|█████████████████████████████████████████████████████████████████████████▌        | 8741/9741 [00:08<00:00, 1121.11it/s] 91%|██████████████████████████████████████████████████████████████████████████▌       | 8854/9741 [00:08<00:00, 1120.88it/s] 92%|███████████████████████████████████████████████████████████████████████████▌      | 8969/9741 [00:08<00:00, 1127.47it/s] 93%|████████████████████████████████████████████████████████████████████████████▍     | 9083/9741 [00:08<00:00, 1128.28it/s] 94%|█████████████████████████████████████████████████████████████████████████████▍    | 9197/9741 [00:08<00:00, 1131.20it/s] 96%|██████████████████████████████████████████████████████████████████████████████▍   | 9311/9741 [00:08<00:00, 1131.67it/s] 97%|███████████████████████████████████████████████████████████████████████████████▎  | 9425/9741 [00:08<00:00, 1133.25it/s] 98%|████████████████████████████████████████████████████████████████████████████████▎ | 9539/9741 [00:08<00:00, 1131.97it/s] 99%|█████████████████████████████████████████████████████████████████████████████████▎| 9653/9741 [00:09<00:00, 1132.91it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:09<00:00, 1072.09it/s]
Load End
Num instances: 1000
[2023-08-22 20:27:28,518] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 20:27:31,665] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 20:27:31,665] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f9df186ca60>
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 20:27:31,666] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f9df186c940>
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 20:27:31,667] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 20:27:31,667] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.49079132080078125 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
Loading extension module utils...
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: Let x = the total number of candies Corey has.
x + 8 = the total number of candies Tapanga has.
The equation for the total number of candies is x + (x + 8) = 66
Combining like terms, we get 2x + 8 = 66
Subtracting 8 from both sides, we get 2x = 58
Dividing both sides by 2, we get x = <<29=29>>29, so Corey has 29 candies.
So the final answer is 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: At 5 cents a minute, calling his father cost Freddy 5* 45 = <<5*45=225>>225 cents.
At 25 cents a minute, calling his brother cost Freddy 25 * 31 = <<25*31=775>>775 cents.
Adding the cost of calling his father and brother, we find that Freddy paid a total of 225 + 775 = <<225+775=1000>>1000 cents.
Since each dollar has 100 cents, Freddy paid 1000 / 100 = <<1000/100=10>>10 dollars
So the final answer is 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 8 hours * 3 = <<8*3=24>>24 hours
5.5 * 2 = <<5.5*2=11>>11 hours
24 + 11 = <<24+11=35>>35 hours
35/7 = <<35/7=5>>5 hours
Lawrence would work 5 hours each of the 7 days in a week.
So the final answer is 5

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o3-tgsm8k-s20-rTrue
Time to load utils op: 0.5049588680267334 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:50<41:02, 50.25s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:41<40:32, 50.68s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:31<39:29, 50.41s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:22<38:45, 50.56s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [04:12<37:46, 50.36s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [05:01<36:44, 50.11s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [05:52<36:09, 50.46s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [06:42<35:11, 50.28s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [07:33<34:30, 50.49s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [08:24<33:39, 50.49s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [09:14<32:51, 50.55s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [10:05<32:00, 50.54s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [10:57<31:22, 50.87s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [11:48<30:41, 51.16s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [12:39<29:45, 51.00s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [13:29<28:38, 50.54s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [14:19<27:48, 50.56s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [15:09<26:49, 50.30s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [15:59<25:54, 50.16s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [16:49<25:03, 50.11s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [17:39<24:14, 50.15s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [18:29<23:22, 50.09s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [19:20<22:39, 50.34s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [20:10<21:44, 50.18s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [20:59<20:51, 50.05s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [21:50<20:02, 50.12s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [22:39<19:08, 49.94s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [23:29<18:17, 49.90s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [24:18<17:24, 49.74s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [25:09<16:41, 50.09s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [25:59<15:51, 50.07s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [26:51<15:08, 50.45s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [27:41<14:18, 50.48s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [28:32<13:28, 50.51s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [29:21<12:32, 50.16s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [30:11<11:42, 50.19s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [31:02<10:52, 50.23s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [31:53<10:08, 50.68s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [32:44<09:15, 50.53s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [33:33<08:23, 50.35s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [34:23<07:31, 50.15s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [35:13<06:40, 50.08s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [36:02<05:48, 49.83s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [36:51<04:57, 49.58s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [37:40<04:07, 49.42s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [38:31<03:19, 49.86s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [39:21<02:29, 49.94s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [40:12<01:40, 50.06s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [41:02<00:50, 50.03s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [41:51<00:00, 49.82s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [41:51<00:00, 50.23s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.3172} | avg. gen lenth: 428.552
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o4-tgsm8k-s20-rTrue --seed 20 --max-prompt-length 2048 --rationales --num-out-domain 4
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 21:09:37,166] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o4-tgsm8k-s20-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 4
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o4-tgsm8k-s20-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|▌                                                                                    | 63/9741 [00:00<00:15, 623.35it/s]  1%|█                                                                                   | 128/9741 [00:00<00:15, 637.76it/s]  2%|█▋                                                                                  | 193/9741 [00:00<00:14, 640.47it/s]  3%|██▏                                                                                 | 259/9741 [00:00<00:14, 647.55it/s]  3%|██▊                                                                                 | 326/9741 [00:00<00:14, 652.66it/s]  4%|███▍                                                                                | 393/9741 [00:00<00:14, 655.79it/s]  5%|███▉                                                                                | 459/9741 [00:00<00:14, 655.68it/s]  5%|████▌                                                                               | 525/9741 [00:00<00:14, 656.02it/s]  6%|█████                                                                               | 591/9741 [00:00<00:14, 642.70it/s]  7%|█████▋                                                                              | 656/9741 [00:01<00:14, 643.19it/s]  7%|██████▏                                                                             | 722/9741 [00:01<00:13, 647.28it/s]  8%|███████                                                                             | 819/9741 [00:01<00:12, 743.32it/s]  9%|███████▉                                                                            | 918/9741 [00:01<00:10, 815.54it/s] 10%|████████▋                                                                          | 1018/9741 [00:01<00:10, 868.89it/s] 11%|█████████▌                                                                         | 1117/9741 [00:01<00:09, 904.60it/s] 12%|██████████▎                                                                        | 1216/9741 [00:01<00:09, 927.55it/s] 13%|███████████▏                                                                       | 1315/9741 [00:01<00:08, 944.39it/s] 15%|████████████                                                                       | 1414/9741 [00:01<00:08, 955.30it/s] 16%|████████████▉                                                                      | 1512/9741 [00:01<00:08, 961.63it/s] 17%|█████████████▋                                                                     | 1611/9741 [00:02<00:08, 967.41it/s] 18%|██████████████▌                                                                    | 1711/9741 [00:02<00:08, 975.59it/s] 19%|███████████████▍                                                                   | 1809/9741 [00:02<00:08, 958.07it/s] 20%|████████████████▎                                                                  | 1908/9741 [00:02<00:08, 966.26it/s] 21%|█████████████████                                                                  | 2006/9741 [00:02<00:07, 968.81it/s] 22%|█████████████████▉                                                                 | 2104/9741 [00:02<00:07, 972.11it/s] 23%|██████████████████▊                                                                | 2202/9741 [00:02<00:07, 973.18it/s] 24%|███████████████████▌                                                               | 2300/9741 [00:02<00:07, 973.79it/s] 25%|████████████████████▍                                                              | 2399/9741 [00:02<00:07, 976.45it/s] 26%|█████████████████████▎                                                             | 2497/9741 [00:02<00:07, 974.18it/s] 27%|██████████████████████                                                             | 2596/9741 [00:03<00:07, 976.65it/s] 28%|██████████████████████▉                                                            | 2694/9741 [00:03<00:07, 976.05it/s] 29%|███████████████████████▊                                                           | 2792/9741 [00:03<00:07, 963.28it/s] 30%|████████████████████████▌                                                          | 2890/9741 [00:03<00:07, 967.39it/s] 31%|█████████████████████████▍                                                         | 2988/9741 [00:03<00:06, 968.65it/s] 32%|██████████████████████████▎                                                        | 3086/9741 [00:03<00:06, 970.14it/s] 33%|███████████████████████████▏                                                       | 3184/9741 [00:03<00:06, 971.01it/s] 34%|███████████████████████████▉                                                       | 3283/9741 [00:03<00:06, 974.49it/s] 35%|████████████████████████████▊                                                      | 3381/9741 [00:03<00:06, 970.60it/s] 36%|█████████████████████████████▋                                                     | 3479/9741 [00:03<00:06, 971.78it/s] 37%|██████████████████████████████▍                                                    | 3577/9741 [00:04<00:06, 970.31it/s] 38%|███████████████████████████████▎                                                   | 3675/9741 [00:04<00:06, 971.57it/s] 39%|████████████████████████████████▏                                                  | 3773/9741 [00:04<00:06, 971.34it/s] 40%|████████████████████████████████▉                                                  | 3871/9741 [00:04<00:06, 969.17it/s] 41%|█████████████████████████████████▊                                                 | 3968/9741 [00:04<00:05, 968.45it/s] 42%|██████████████████████████████████▋                                                | 4065/9741 [00:04<00:05, 965.23it/s] 43%|███████████████████████████████████▍                                               | 4162/9741 [00:04<00:05, 966.01it/s] 44%|████████████████████████████████████▎                                              | 4259/9741 [00:04<00:05, 967.02it/s] 45%|█████████████████████████████████████                                              | 4356/9741 [00:04<00:05, 956.85it/s] 46%|█████████████████████████████████████▉                                             | 4453/9741 [00:04<00:05, 958.22it/s] 47%|██████████████████████████████████████▊                                            | 4549/9741 [00:05<00:05, 911.41it/s] 48%|███████████████████████████████████████▌                                           | 4646/9741 [00:05<00:05, 927.52it/s] 49%|████████████████████████████████████████▍                                          | 4740/9741 [00:05<00:06, 772.43it/s] 50%|█████████████████████████████████████████▏                                         | 4837/9741 [00:05<00:05, 820.97it/s] 51%|██████████████████████████████████████████                                         | 4933/9741 [00:05<00:05, 857.15it/s] 52%|██████████████████████████████████████████▊                                        | 5031/9741 [00:05<00:05, 888.74it/s] 53%|███████████████████████████████████████████▋                                       | 5129/9741 [00:05<00:05, 912.61it/s] 54%|████████████████████████████████████████████▌                                      | 5226/9741 [00:05<00:04, 927.45it/s] 55%|█████████████████████████████████████████████▎                                     | 5323/9741 [00:05<00:04, 938.65it/s] 56%|██████████████████████████████████████████████▏                                    | 5419/9741 [00:06<00:04, 942.33it/s] 57%|███████████████████████████████████████████████                                    | 5516/9741 [00:06<00:04, 947.72it/s] 58%|███████████████████████████████████████████████▊                                   | 5612/9741 [00:06<00:04, 950.58it/s] 59%|████████████████████████████████████████████████▋                                  | 5708/9741 [00:06<00:04, 952.06it/s] 60%|█████████████████████████████████████████████████▍                                 | 5805/9741 [00:06<00:04, 955.71it/s] 61%|██████████████████████████████████████████████████▎                                | 5901/9741 [00:06<00:04, 953.61it/s] 62%|███████████████████████████████████████████████████                                | 5998/9741 [00:06<00:03, 958.06it/s] 63%|███████████████████████████████████████████████████▉                               | 6094/9741 [00:06<00:03, 957.65it/s] 64%|████████████████████████████████████████████████████▊                              | 6191/9741 [00:06<00:03, 960.26it/s] 65%|█████████████████████████████████████████████████████▌                             | 6288/9741 [00:06<00:03, 958.40it/s] 66%|██████████████████████████████████████████████████████▍                            | 6385/9741 [00:07<00:03, 959.64it/s] 67%|███████████████████████████████████████████████████████▏                           | 6482/9741 [00:07<00:03, 959.96it/s] 68%|████████████████████████████████████████████████████████                           | 6579/9741 [00:07<00:03, 956.47it/s] 69%|████████████████████████████████████████████████████████▉                          | 6675/9741 [00:07<00:03, 955.34it/s] 70%|█████████████████████████████████████████████████████████▋                         | 6771/9741 [00:07<00:03, 955.17it/s] 70%|██████████████████████████████████████████████████████████▌                        | 6867/9741 [00:07<00:03, 956.09it/s] 71%|███████████████████████████████████████████████████████████▎                       | 6963/9741 [00:07<00:02, 953.76it/s] 72%|████████████████████████████████████████████████████████████▏                      | 7059/9741 [00:07<00:02, 955.49it/s] 73%|████████████████████████████████████████████████████████████▉                      | 7155/9741 [00:07<00:02, 954.40it/s] 74%|█████████████████████████████████████████████████████████████▊                     | 7251/9741 [00:07<00:02, 947.04it/s] 75%|██████████████████████████████████████████████████████████████▌                    | 7346/9741 [00:08<00:02, 944.51it/s] 76%|███████████████████████████████████████████████████████████████▍                   | 7441/9741 [00:08<00:02, 914.40it/s] 77%|████████████████████████████████████████████████████████████████▏                  | 7536/9741 [00:08<00:02, 923.27it/s] 78%|█████████████████████████████████████████████████████████████████                  | 7631/9741 [00:08<00:02, 930.41it/s] 79%|█████████████████████████████████████████████████████████████████▊                 | 7726/9741 [00:08<00:02, 933.46it/s] 80%|██████████████████████████████████████████████████████████████████▋                | 7822/9741 [00:08<00:02, 939.08it/s] 81%|███████████████████████████████████████████████████████████████████▍               | 7917/9741 [00:08<00:01, 941.57it/s] 82%|████████████████████████████████████████████████████████████████████▎              | 8012/9741 [00:08<00:01, 928.14it/s] 83%|█████████████████████████████████████████████████████████████████████              | 8106/9741 [00:08<00:01, 929.63it/s] 84%|█████████████████████████████████████████████████████████████████████▉             | 8201/9741 [00:08<00:01, 935.09it/s] 85%|██████████████████████████████████████████████████████████████████████▋            | 8297/9741 [00:09<00:01, 939.65it/s] 86%|███████████████████████████████████████████████████████████████████████▌           | 8392/9741 [00:09<00:01, 940.53it/s] 87%|████████████████████████████████████████████████████████████████████████▎          | 8487/9741 [00:09<00:01, 942.62it/s] 88%|█████████████████████████████████████████████████████████████████████████          | 8582/9741 [00:09<00:01, 941.18it/s] 89%|█████████████████████████████████████████████████████████████████████████▉         | 8678/9741 [00:09<00:01, 944.38it/s] 90%|██████████████████████████████████████████████████████████████████████████▊        | 8774/9741 [00:09<00:01, 946.75it/s] 91%|███████████████████████████████████████████████████████████████████████████▌       | 8870/9741 [00:09<00:00, 949.36it/s] 92%|████████████████████████████████████████████████████████████████████████████▍      | 8966/9741 [00:09<00:00, 949.86it/s] 93%|█████████████████████████████████████████████████████████████████████████████▏     | 9061/9741 [00:09<00:00, 948.34it/s] 94%|██████████████████████████████████████████████████████████████████████████████     | 9157/9741 [00:09<00:00, 949.38it/s] 95%|██████████████████████████████████████████████████████████████████████████████▊    | 9253/9741 [00:10<00:00, 950.18it/s] 96%|███████████████████████████████████████████████████████████████████████████████▋   | 9349/9741 [00:10<00:00, 951.90it/s] 97%|████████████████████████████████████████████████████████████████████████████████▍  | 9445/9741 [00:10<00:00, 952.06it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▎ | 9541/9741 [00:10<00:00, 947.87it/s] 99%|██████████████████████████████████████████████████████████████████████████████████ | 9637/9741 [00:10<00:00, 950.02it/s]100%|██████████████████████████████████████████████████████████████████████████████████▉| 9733/9741 [00:10<00:00, 947.66it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:10<00:00, 917.99it/s]
Load End
Num instances: 1000
[2023-08-22 21:09:58,782] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 21:10:01,660] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 21:10:01,660] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 21:10:01,660] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 21:10:01,660] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 21:10:01,660] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f87d6932a60>
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f87d6932940>
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 21:10:01,661] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 21:10:01,662] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 21:10:01,662] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 21:10:01,662] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 21:10:01,662] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 21:10:01,662] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 21:10:01,662] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 21:10:01,662] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 21:10:01,662] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 21:10:01,662] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 21:10:01,662] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 21:10:01,662] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 21:10:01,662] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 21:10:01,662] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 21:10:01,662] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 21:10:01,662] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 21:10:01,662] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 21:10:01,662] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 21:10:01,662] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 21:10:01,662] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 21:10:01,662] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.42970991134643555 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: Let x = the total number of candies Corey has.
x + 8 = the total number of candies Tapanga has.
The equation for the total number of candies is x + (x + 8) = 66
Combining like terms, we get 2x + 8 = 66
Subtracting 8 from both sides, we get 2x = 58
Dividing both sides by 2, we get x = <<29=29>>29, so Corey has 29 candies.
So the final answer is 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: At 5 cents a minute, calling his father cost Freddy 5* 45 = <<5*45=225>>225 cents.
At 25 cents a minute, calling his brother cost Freddy 25 * 31 = <<25*31=775>>775 cents.
Adding the cost of calling his father and brother, we find that Freddy paid a total of 225 + 775 = <<225+775=1000>>1000 cents.
Since each dollar has 100 cents, Freddy paid 1000 / 100 = <<1000/100=10>>10 dollars
So the final answer is 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 8 hours * 3 = <<8*3=24>>24 hours
5.5 * 2 = <<5.5*2=11>>11 hours
24 + 11 = <<24+11=35>>35 hours
35/7 = <<35/7=5>>5 hours
Lawrence would work 5 hours each of the 7 days in a week.
So the final answer is 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: We look first for the total number of books that were sold: 60 + 10 + 20 + 44 + 66 = <<60+10+20+44+66=200>>200 books.
So the total number of books that were not sold is: 800 – 200 = <<800-200=600>>600 books.
So the final answer is 600

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o4-tgsm8k-s20-rTrue
Loading extension module utils...
Time to load utils op: 0.40462517738342285 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:47<38:56, 47.69s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:34<37:41, 47.12s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:20<36:42, 46.86s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:07<35:46, 46.65s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [03:54<35:06, 46.82s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [04:41<34:27, 47.00s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [05:29<33:45, 47.10s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [06:15<32:49, 46.90s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [07:01<31:53, 46.66s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [07:47<31:01, 46.54s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [08:35<30:22, 46.72s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [09:23<29:49, 47.09s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [10:09<28:52, 46.83s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [10:55<28:02, 46.74s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [11:42<27:15, 46.73s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [12:29<26:29, 46.74s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [13:15<25:40, 46.69s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [14:02<24:51, 46.59s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [14:49<24:06, 46.67s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [15:35<23:22, 46.75s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [16:22<22:34, 46.71s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [17:09<21:52, 46.86s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [17:57<21:11, 47.09s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [18:44<20:24, 47.09s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [19:32<19:41, 47.27s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [20:18<18:48, 47.03s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [21:07<18:10, 47.42s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [21:53<17:16, 47.12s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [22:41<16:35, 47.39s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [23:28<15:47, 47.38s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [24:15<14:55, 47.16s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [25:02<14:08, 47.15s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [25:49<13:21, 47.15s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [26:36<12:30, 46.93s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [27:23<11:47, 47.14s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [28:10<10:58, 47.03s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [28:56<10:08, 46.83s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [29:43<09:19, 46.64s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [30:30<08:35, 46.84s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [31:17<07:48, 46.86s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [32:03<07:00, 46.77s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [32:50<06:13, 46.68s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [33:38<05:29, 47.11s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [34:25<04:42, 47.05s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [35:12<03:55, 47.07s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [35:59<03:07, 46.98s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [36:46<02:20, 46.93s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [37:33<01:34, 47.21s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [38:20<00:47, 47.02s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [39:07<00:00, 46.93s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [39:07<00:00, 46.94s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.0628} | avg. gen lenth: 450.236
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o5-tgsm8k-s20-rTrue --seed 20 --max-prompt-length 2048 --rationales --num-out-domain 5
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 21:49:15,939] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o5-tgsm8k-s20-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 5
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o5-tgsm8k-s20-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|▍                                                                                    | 49/9741 [00:00<00:20, 482.33it/s]  1%|▊                                                                                    | 99/9741 [00:00<00:19, 490.45it/s]  2%|█▎                                                                                  | 149/9741 [00:00<00:19, 494.74it/s]  2%|█▋                                                                                  | 199/9741 [00:00<00:19, 495.36it/s]  3%|██▏                                                                                 | 249/9741 [00:00<00:19, 496.37it/s]  3%|██▌                                                                                 | 300/9741 [00:00<00:18, 498.92it/s]  4%|███                                                                                 | 351/9741 [00:00<00:18, 500.02it/s]  4%|███▍                                                                                | 402/9741 [00:00<00:19, 489.61it/s]  5%|███▉                                                                                | 452/9741 [00:00<00:18, 492.13it/s]  5%|████▎                                                                               | 503/9741 [00:01<00:18, 495.39it/s]  6%|████▊                                                                               | 554/9741 [00:01<00:18, 498.40it/s]  6%|█████▏                                                                              | 605/9741 [00:01<00:18, 501.45it/s]  7%|█████▋                                                                              | 656/9741 [00:01<00:18, 502.08it/s]  7%|██████                                                                              | 707/9741 [00:01<00:17, 504.16it/s]  8%|██████▋                                                                             | 774/9741 [00:01<00:16, 553.76it/s]  9%|███████▎                                                                            | 851/9741 [00:01<00:14, 615.01it/s] 10%|███████▉                                                                            | 927/9741 [00:01<00:13, 657.50it/s] 10%|████████▌                                                                          | 1003/9741 [00:01<00:12, 686.59it/s] 11%|█████████▏                                                                         | 1079/9741 [00:01<00:12, 707.56it/s] 12%|█████████▊                                                                         | 1156/9741 [00:02<00:11, 723.74it/s] 13%|██████████▍                                                                        | 1232/9741 [00:02<00:11, 732.07it/s] 13%|███████████▏                                                                       | 1308/9741 [00:02<00:11, 738.60it/s] 14%|███████████▊                                                                       | 1384/9741 [00:02<00:11, 743.07it/s] 15%|████████████▍                                                                      | 1460/9741 [00:02<00:11, 745.79it/s] 16%|█████████████                                                                      | 1535/9741 [00:02<00:11, 745.30it/s] 17%|█████████████▋                                                                     | 1611/9741 [00:02<00:10, 746.97it/s] 17%|██████████████▎                                                                    | 1687/9741 [00:02<00:10, 749.19it/s] 18%|███████████████                                                                    | 1762/9741 [00:02<00:10, 729.11it/s] 19%|███████████████▋                                                                   | 1837/9741 [00:02<00:10, 735.01it/s] 20%|████████████████▎                                                                  | 1913/9741 [00:03<00:10, 740.22it/s] 20%|████████████████▉                                                                  | 1988/9741 [00:03<00:10, 729.47it/s] 21%|█████████████████▌                                                                 | 2063/9741 [00:03<00:10, 734.12it/s] 22%|██████████████████▏                                                                | 2138/9741 [00:03<00:10, 737.05it/s] 23%|██████████████████▊                                                                | 2213/9741 [00:03<00:10, 737.63it/s] 23%|███████████████████▍                                                               | 2288/9741 [00:03<00:10, 739.97it/s] 24%|████████████████████▏                                                              | 2363/9741 [00:03<00:09, 742.00it/s] 25%|████████████████████▊                                                              | 2439/9741 [00:03<00:09, 746.85it/s] 26%|█████████████████████▍                                                             | 2514/9741 [00:03<00:09, 744.90it/s] 27%|██████████████████████                                                             | 2590/9741 [00:03<00:09, 747.49it/s] 27%|██████████████████████▋                                                            | 2665/9741 [00:04<00:09, 744.75it/s] 28%|███████████████████████▎                                                           | 2740/9741 [00:04<00:09, 739.89it/s] 29%|███████████████████████▉                                                           | 2814/9741 [00:04<00:09, 739.16it/s] 30%|████████████████████████▌                                                          | 2889/9741 [00:04<00:09, 739.71it/s] 30%|█████████████████████████▏                                                         | 2963/9741 [00:04<00:09, 735.80it/s] 31%|█████████████████████████▉                                                         | 3038/9741 [00:04<00:09, 738.14it/s] 32%|██████████████████████████▌                                                        | 3112/9741 [00:04<00:08, 737.62it/s] 33%|███████████████████████████▏                                                       | 3186/9741 [00:04<00:08, 734.80it/s] 33%|███████████████████████████▊                                                       | 3260/9741 [00:04<00:08, 735.10it/s] 34%|████████████████████████████▍                                                      | 3334/9741 [00:04<00:08, 734.13it/s] 35%|█████████████████████████████                                                      | 3408/9741 [00:05<00:08, 732.31it/s] 36%|█████████████████████████████▋                                                     | 3482/9741 [00:05<00:08, 731.66it/s] 37%|██████████████████████████████▎                                                    | 3556/9741 [00:05<00:08, 731.51it/s] 37%|██████████████████████████████▉                                                    | 3630/9741 [00:05<00:08, 729.10it/s] 38%|███████████████████████████████▌                                                   | 3703/9741 [00:05<00:08, 729.23it/s] 39%|████████████████████████████████▏                                                  | 3776/9741 [00:05<00:08, 725.20it/s] 40%|████████████████████████████████▊                                                  | 3849/9741 [00:05<00:08, 723.69it/s] 40%|█████████████████████████████████▍                                                 | 3922/9741 [00:05<00:08, 725.29it/s] 41%|██████████████████████████████████                                                 | 3996/9741 [00:05<00:07, 727.14it/s] 42%|██████████████████████████████████▋                                                | 4069/9741 [00:05<00:07, 725.46it/s] 43%|███████████████████████████████████▎                                               | 4142/9741 [00:06<00:07, 723.77it/s] 43%|███████████████████████████████████▉                                               | 4215/9741 [00:06<00:07, 708.88it/s] 44%|████████████████████████████████████▌                                              | 4286/9741 [00:06<00:07, 708.82it/s] 45%|█████████████████████████████████████▏                                             | 4359/9741 [00:06<00:07, 712.79it/s] 45%|█████████████████████████████████████▊                                             | 4432/9741 [00:06<00:07, 716.11it/s] 46%|██████████████████████████████████████▍                                            | 4504/9741 [00:06<00:07, 672.44it/s] 47%|██████████████████████████████████████▉                                            | 4576/9741 [00:06<00:07, 685.75it/s] 48%|███████████████████████████████████████▌                                           | 4648/9741 [00:06<00:07, 694.25it/s] 48%|████████████████████████████████████████▏                                          | 4718/9741 [00:06<00:08, 564.24it/s] 49%|████████████████████████████████████████▊                                          | 4791/9741 [00:07<00:08, 605.10it/s] 50%|█████████████████████████████████████████▍                                         | 4864/9741 [00:07<00:07, 636.83it/s] 51%|██████████████████████████████████████████                                         | 4936/9741 [00:07<00:07, 658.39it/s] 51%|██████████████████████████████████████████▋                                        | 5009/9741 [00:07<00:06, 676.83it/s] 52%|███████████████████████████████████████████▎                                       | 5082/9741 [00:07<00:06, 690.93it/s] 53%|███████████████████████████████████████████▉                                       | 5154/9741 [00:07<00:06, 698.91it/s] 54%|████████████████████████████████████████████▌                                      | 5227/9741 [00:07<00:06, 705.63it/s] 54%|█████████████████████████████████████████████▏                                     | 5299/9741 [00:07<00:06, 705.57it/s] 55%|█████████████████████████████████████████████▊                                     | 5371/9741 [00:07<00:06, 705.23it/s] 56%|██████████████████████████████████████████████▍                                    | 5443/9741 [00:08<00:06, 708.14it/s] 57%|██████████████████████████████████████████████▉                                    | 5515/9741 [00:08<00:05, 710.27it/s] 57%|███████████████████████████████████████████████▌                                   | 5587/9741 [00:08<00:05, 712.92it/s] 58%|████████████████████████████████████████████████▏                                  | 5659/9741 [00:08<00:05, 712.49it/s] 59%|████████████████████████████████████████████████▊                                  | 5731/9741 [00:08<00:05, 713.52it/s] 60%|█████████████████████████████████████████████████▍                                 | 5803/9741 [00:08<00:05, 714.02it/s] 60%|██████████████████████████████████████████████████                                 | 5875/9741 [00:08<00:05, 711.30it/s] 61%|██████████████████████████████████████████████████▋                                | 5947/9741 [00:08<00:05, 712.72it/s] 62%|███████████████████████████████████████████████████▎                               | 6019/9741 [00:08<00:05, 714.14it/s] 63%|███████████████████████████████████████████████████▉                               | 6091/9741 [00:08<00:05, 712.77it/s] 63%|████████████████████████████████████████████████████▌                              | 6163/9741 [00:09<00:05, 714.02it/s] 64%|█████████████████████████████████████████████████████▏                             | 6235/9741 [00:09<00:04, 713.98it/s] 65%|█████████████████████████████████████████████████████▋                             | 6307/9741 [00:09<00:04, 712.06it/s] 65%|██████████████████████████████████████████████████████▎                            | 6379/9741 [00:09<00:04, 712.82it/s] 66%|██████████████████████████████████████████████████████▉                            | 6451/9741 [00:09<00:04, 712.39it/s] 67%|███████████████████████████████████████████████████████▌                           | 6523/9741 [00:09<00:04, 711.33it/s] 68%|████████████████████████████████████████████████████████▏                          | 6596/9741 [00:09<00:04, 716.72it/s] 68%|████████████████████████████████████████████████████████▊                          | 6669/9741 [00:09<00:04, 719.05it/s] 69%|█████████████████████████████████████████████████████████▍                         | 6741/9741 [00:09<00:04, 716.40it/s] 70%|██████████████████████████████████████████████████████████                         | 6813/9741 [00:09<00:04, 716.70it/s] 71%|██████████████████████████████████████████████████████████▋                        | 6885/9741 [00:10<00:03, 715.83it/s] 71%|███████████████████████████████████████████████████████████▎                       | 6957/9741 [00:10<00:03, 713.73it/s] 72%|███████████████████████████████████████████████████████████▉                       | 7029/9741 [00:10<00:03, 714.55it/s] 73%|████████████████████████████████████████████████████████████▌                      | 7101/9741 [00:10<00:03, 715.44it/s] 74%|█████████████████████████████████████████████████████████████                      | 7173/9741 [00:10<00:03, 715.35it/s] 74%|█████████████████████████████████████████████████████████████▋                     | 7245/9741 [00:10<00:03, 713.29it/s] 75%|██████████████████████████████████████████████████████████████▎                    | 7317/9741 [00:10<00:03, 713.77it/s] 76%|██████████████████████████████████████████████████████████████▉                    | 7389/9741 [00:10<00:03, 715.07it/s] 77%|███████████████████████████████████████████████████████████████▌                   | 7461/9741 [00:10<00:03, 686.58it/s] 77%|████████████████████████████████████████████████████████████████▏                  | 7533/9741 [00:10<00:03, 693.82it/s] 78%|████████████████████████████████████████████████████████████████▊                  | 7605/9741 [00:11<00:03, 700.10it/s] 79%|█████████████████████████████████████████████████████████████████▍                 | 7676/9741 [00:11<00:02, 701.35it/s] 80%|██████████████████████████████████████████████████████████████████                 | 7748/9741 [00:11<00:02, 705.92it/s] 80%|██████████████████████████████████████████████████████████████████▋                | 7820/9741 [00:11<00:02, 707.55it/s] 81%|███████████████████████████████████████████████████████████████████▏               | 7891/9741 [00:11<00:02, 706.00it/s] 82%|███████████████████████████████████████████████████████████████████▊               | 7963/9741 [00:11<00:02, 707.97it/s] 82%|████████████████████████████████████████████████████████████████████▍              | 8035/9741 [00:11<00:02, 709.56it/s] 83%|█████████████████████████████████████████████████████████████████████              | 8106/9741 [00:11<00:02, 709.17it/s] 84%|█████████████████████████████████████████████████████████████████████▋             | 8178/9741 [00:11<00:02, 710.28it/s] 85%|██████████████████████████████████████████████████████████████████████▎            | 8250/9741 [00:11<00:02, 687.49it/s] 85%|██████████████████████████████████████████████████████████████████████▉            | 8319/9741 [00:12<00:02, 673.93it/s] 86%|███████████████████████████████████████████████████████████████████████▍           | 8387/9741 [00:12<00:02, 667.47it/s] 87%|████████████████████████████████████████████████████████████████████████           | 8454/9741 [00:12<00:01, 663.54it/s] 88%|████████████████████████████████████████████████████████████████████████▋          | 8525/9741 [00:12<00:01, 676.63it/s] 88%|█████████████████████████████████████████████████████████████████████████▏         | 8593/9741 [00:12<00:01, 659.41it/s] 89%|█████████████████████████████████████████████████████████████████████████▊         | 8664/9741 [00:12<00:01, 672.42it/s] 90%|██████████████████████████████████████████████████████████████████████████▍        | 8735/9741 [00:12<00:01, 682.78it/s] 90%|███████████████████████████████████████████████████████████████████████████        | 8804/9741 [00:12<00:01, 679.34it/s] 91%|███████████████████████████████████████████████████████████████████████████▌       | 8874/9741 [00:12<00:01, 684.32it/s] 92%|████████████████████████████████████████████████████████████████████████████▏      | 8944/9741 [00:12<00:01, 687.07it/s] 93%|████████████████████████████████████████████████████████████████████████████▊      | 9013/9741 [00:13<00:01, 682.27it/s] 93%|█████████████████████████████████████████████████████████████████████████████▍     | 9082/9741 [00:13<00:00, 684.35it/s] 94%|█████████████████████████████████████████████████████████████████████████████▉     | 9152/9741 [00:13<00:00, 688.90it/s] 95%|██████████████████████████████████████████████████████████████████████████████▌    | 9222/9741 [00:13<00:00, 691.91it/s] 95%|███████████████████████████████████████████████████████████████████████████████▏   | 9292/9741 [00:13<00:00, 694.12it/s] 96%|███████████████████████████████████████████████████████████████████████████████▊   | 9364/9741 [00:13<00:00, 698.78it/s] 97%|████████████████████████████████████████████████████████████████████████████████▍  | 9435/9741 [00:13<00:00, 700.92it/s] 98%|████████████████████████████████████████████████████████████████████████████████▉  | 9506/9741 [00:13<00:00, 700.32it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▌ | 9577/9741 [00:13<00:00, 703.05it/s] 99%|██████████████████████████████████████████████████████████████████████████████████▏| 9648/9741 [00:14<00:00, 673.49it/s]100%|██████████████████████████████████████████████████████████████████████████████████▊| 9716/9741 [00:14<00:00, 656.98it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:14<00:00, 687.94it/s]
Load End
Num instances: 1000
[2023-08-22 21:49:41,294] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 21:49:44,809] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 21:49:44,810] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 21:49:44,810] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 21:49:44,810] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 21:49:44,810] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 21:49:44,810] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 21:49:44,810] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 21:49:44,810] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fa696f53a60>
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fa696f53940>
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 21:49:44,811] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 21:49:44,812] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 21:49:44,812] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 21:49:44,812] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 21:49:44,812] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 21:49:44,812] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Loading extension module utils...
Time to load utils op: 0.4072396755218506 seconds
Time to load utils op: 0.40455102920532227 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: Let x = the total number of candies Corey has.
x + 8 = the total number of candies Tapanga has.
The equation for the total number of candies is x + (x + 8) = 66
Combining like terms, we get 2x + 8 = 66
Subtracting 8 from both sides, we get 2x = 58
Dividing both sides by 2, we get x = <<29=29>>29, so Corey has 29 candies.
So the final answer is 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: At 5 cents a minute, calling his father cost Freddy 5* 45 = <<5*45=225>>225 cents.
At 25 cents a minute, calling his brother cost Freddy 25 * 31 = <<25*31=775>>775 cents.
Adding the cost of calling his father and brother, we find that Freddy paid a total of 225 + 775 = <<225+775=1000>>1000 cents.
Since each dollar has 100 cents, Freddy paid 1000 / 100 = <<1000/100=10>>10 dollars
So the final answer is 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 8 hours * 3 = <<8*3=24>>24 hours
5.5 * 2 = <<5.5*2=11>>11 hours
24 + 11 = <<24+11=35>>35 hours
35/7 = <<35/7=5>>5 hours
Lawrence would work 5 hours each of the 7 days in a week.
So the final answer is 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: We look first for the total number of books that were sold: 60 + 10 + 20 + 44 + 66 = <<60+10+20+44+66=200>>200 books.
So the total number of books that were not sold is: 800 – 200 = <<800-200=600>>600 books.
So the final answer is 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: Michael sold 2 large birdhouses for $22 each, so he made 2*$22= $<<2*22=44>>44 from large birdhouse sales.
Michael also sold 2 medium birdhouses for $16 each, so he made 2*$16= $<<2*16=32>>32 from medium birdhouse sales.
Michael sold 3 small birdhouses for $7 each, so he made 3*7=$<<3*7=21>>21 from small birdhouse sales.
Since Michael made $44 from large birdhouse sales, $32 from medium birdhouse sales, and $21 for small birdhouse sales, he made $44+$32+$21= $<<44+32+21=97>>97 total this week.
So the final answer is 97

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o5-tgsm8k-s20-rTrue
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:41<33:33, 41.09s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:23<33:36, 42.01s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:04<32:28, 41.46s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [02:46<31:47, 41.46s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [03:27<31:11, 41.58s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [04:08<30:09, 41.13s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [04:48<29:20, 40.94s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [05:29<28:42, 41.01s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [06:10<28:01, 41.02s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [06:51<27:16, 40.92s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [07:32<26:34, 40.89s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [08:12<25:50, 40.81s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [08:53<25:11, 40.84s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [09:34<24:27, 40.77s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [10:14<23:41, 40.63s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [10:55<23:05, 40.74s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [11:36<22:27, 40.82s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [12:17<21:48, 40.89s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [12:58<21:03, 40.74s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [13:39<20:24, 40.80s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [14:19<19:42, 40.78s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [15:00<18:57, 40.63s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [15:40<18:16, 40.60s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [16:21<17:35, 40.59s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [17:02<16:56, 40.65s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [17:42<16:13, 40.55s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [18:23<15:37, 40.75s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [19:03<14:53, 40.63s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [19:44<14:15, 40.75s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [20:25<13:36, 40.81s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [21:06<12:56, 40.88s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [21:48<12:18, 41.02s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [22:29<11:37, 41.01s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [23:11<11:01, 41.33s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [23:52<10:17, 41.19s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [24:33<09:35, 41.08s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [25:13<08:51, 40.88s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [25:54<08:12, 41.06s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [26:36<07:32, 41.18s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [27:17<06:52, 41.21s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [27:58<06:09, 41.10s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [28:39<05:29, 41.17s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [29:21<04:49, 41.31s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [30:02<04:06, 41.09s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [30:44<03:27, 41.47s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [31:25<02:45, 41.37s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [32:07<02:04, 41.42s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [32:48<01:22, 41.28s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [33:29<00:41, 41.25s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [34:10<00:00, 41.39s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [34:10<00:00, 41.02s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.0626} | avg. gen lenth: 438.366
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s20-rTrue --seed 20 --max-prompt-length 2048 --rationales --num-out-domain 6
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 22:24:14,184] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s20-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 6
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o6-tgsm8k-s20-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  0%|▎                                                                                    | 40/9741 [00:00<00:24, 390.87it/s]  1%|▋                                                                                    | 80/9741 [00:00<00:24, 395.94it/s]  1%|█                                                                                   | 121/9741 [00:00<00:24, 398.65it/s]  2%|█▍                                                                                  | 162/9741 [00:00<00:23, 401.72it/s]  2%|█▊                                                                                  | 203/9741 [00:00<00:23, 401.28it/s]  3%|██                                                                                  | 244/9741 [00:00<00:24, 381.83it/s]  3%|██▍                                                                                 | 285/9741 [00:00<00:24, 389.67it/s]  3%|██▊                                                                                 | 325/9741 [00:00<00:24, 378.42it/s]  4%|███▏                                                                                | 365/9741 [00:00<00:24, 384.74it/s]  4%|███▍                                                                                | 405/9741 [00:01<00:24, 386.63it/s]  5%|███▊                                                                                | 446/9741 [00:01<00:23, 391.66it/s]  5%|████▏                                                                               | 487/9741 [00:01<00:23, 395.45it/s]  5%|████▌                                                                               | 528/9741 [00:01<00:23, 398.28it/s]  6%|████▉                                                                               | 569/9741 [00:01<00:22, 400.32it/s]  6%|█████▎                                                                              | 610/9741 [00:01<00:22, 401.80it/s]  7%|█████▌                                                                              | 651/9741 [00:01<00:22, 401.78it/s]  7%|█████▉                                                                              | 693/9741 [00:01<00:22, 404.71it/s]  8%|██████▎                                                                             | 734/9741 [00:01<00:22, 403.75it/s]  8%|██████▋                                                                             | 775/9741 [00:01<00:22, 405.39it/s]  8%|███████                                                                             | 816/9741 [00:02<00:21, 406.51it/s]  9%|███████▍                                                                            | 857/9741 [00:02<00:21, 405.17it/s]  9%|███████▋                                                                            | 898/9741 [00:02<00:21, 406.19it/s] 10%|████████                                                                            | 939/9741 [00:02<00:21, 406.18it/s] 10%|████████▍                                                                           | 980/9741 [00:02<00:21, 406.55it/s] 11%|████████▋                                                                          | 1024/9741 [00:02<00:20, 416.18it/s] 11%|█████████▏                                                                         | 1085/9741 [00:02<00:18, 472.26it/s] 12%|█████████▊                                                                         | 1146/9741 [00:02<00:16, 513.32it/s] 12%|██████████▎                                                                        | 1207/9741 [00:02<00:15, 541.54it/s] 13%|██████████▊                                                                        | 1268/9741 [00:02<00:15, 561.13it/s] 14%|███████████▎                                                                       | 1329/9741 [00:03<00:14, 572.97it/s] 14%|███████████▊                                                                       | 1390/9741 [00:03<00:14, 582.94it/s] 15%|████████████▎                                                                      | 1451/9741 [00:03<00:14, 589.31it/s] 16%|████████████▉                                                                      | 1512/9741 [00:03<00:13, 593.29it/s] 16%|█████████████▍                                                                     | 1572/9741 [00:03<00:13, 595.02it/s] 17%|█████████████▉                                                                     | 1633/9741 [00:03<00:13, 597.43it/s] 17%|██████████████▍                                                                    | 1694/9741 [00:03<00:13, 598.89it/s] 18%|██████████████▉                                                                    | 1754/9741 [00:03<00:13, 598.01it/s] 19%|███████████████▍                                                                   | 1814/9741 [00:03<00:13, 573.20it/s] 19%|███████████████▉                                                                   | 1874/9741 [00:03<00:13, 580.07it/s] 20%|████████████████▍                                                                  | 1934/9741 [00:04<00:13, 585.66it/s] 20%|████████████████▉                                                                  | 1993/9741 [00:04<00:13, 586.93it/s] 21%|█████████████████▍                                                                 | 2053/9741 [00:04<00:13, 589.58it/s] 22%|██████████████████                                                                 | 2113/9741 [00:04<00:12, 590.91it/s] 22%|██████████████████▌                                                                | 2173/9741 [00:04<00:12, 591.85it/s] 23%|███████████████████                                                                | 2233/9741 [00:04<00:12, 589.34it/s] 24%|███████████████████▌                                                               | 2292/9741 [00:04<00:12, 588.81it/s] 24%|████████████████████                                                               | 2351/9741 [00:04<00:12, 588.86it/s] 25%|████████████████████▌                                                              | 2411/9741 [00:04<00:12, 590.28it/s] 25%|█████████████████████                                                              | 2471/9741 [00:04<00:12, 588.30it/s] 26%|█████████████████████▌                                                             | 2531/9741 [00:05<00:12, 588.95it/s] 27%|██████████████████████                                                             | 2591/9741 [00:05<00:12, 590.16it/s] 27%|██████████████████████▌                                                            | 2651/9741 [00:05<00:12, 589.75it/s] 28%|███████████████████████                                                            | 2710/9741 [00:05<00:11, 587.18it/s] 28%|███████████████████████▌                                                           | 2769/9741 [00:05<00:11, 586.84it/s] 29%|████████████████████████                                                           | 2828/9741 [00:05<00:11, 587.73it/s] 30%|████████████████████████▌                                                          | 2887/9741 [00:05<00:11, 580.14it/s] 30%|█████████████████████████                                                          | 2946/9741 [00:05<00:11, 577.81it/s] 31%|█████████████████████████▌                                                         | 3005/9741 [00:05<00:11, 580.20it/s] 31%|██████████████████████████                                                         | 3064/9741 [00:06<00:11, 581.34it/s] 32%|██████████████████████████▌                                                        | 3123/9741 [00:06<00:11, 580.79it/s] 33%|███████████████████████████                                                        | 3182/9741 [00:06<00:11, 582.72it/s] 33%|███████████████████████████▌                                                       | 3241/9741 [00:06<00:11, 584.37it/s] 34%|████████████████████████████                                                       | 3300/9741 [00:06<00:11, 585.11it/s] 34%|████████████████████████████▌                                                      | 3359/9741 [00:06<00:10, 582.76it/s] 35%|█████████████████████████████                                                      | 3418/9741 [00:06<00:10, 583.79it/s] 36%|█████████████████████████████▋                                                     | 3477/9741 [00:06<00:10, 583.83it/s] 36%|██████████████████████████████▏                                                    | 3536/9741 [00:06<00:10, 582.90it/s] 37%|██████████████████████████████▋                                                    | 3595/9741 [00:06<00:10, 580.78it/s] 38%|███████████████████████████████▏                                                   | 3654/9741 [00:07<00:10, 579.66it/s] 38%|███████████████████████████████▋                                                   | 3713/9741 [00:07<00:10, 580.30it/s] 39%|████████████████████████████████▏                                                  | 3772/9741 [00:07<00:10, 580.72it/s] 39%|████████████████████████████████▋                                                  | 3831/9741 [00:07<00:10, 578.75it/s] 40%|█████████████████████████████████▏                                                 | 3890/9741 [00:07<00:10, 579.45it/s] 41%|█████████████████████████████████▋                                                 | 3948/9741 [00:07<00:09, 579.60it/s] 41%|██████████████████████████████████▏                                                | 4006/9741 [00:07<00:09, 579.41it/s] 42%|██████████████████████████████████▋                                                | 4064/9741 [00:07<00:09, 577.36it/s] 42%|███████████████████████████████████                                                | 4122/9741 [00:07<00:09, 576.79it/s] 43%|███████████████████████████████████▌                                               | 4180/9741 [00:07<00:09, 576.94it/s] 44%|████████████████████████████████████                                               | 4238/9741 [00:08<00:09, 576.31it/s] 44%|████████████████████████████████████▌                                              | 4296/9741 [00:08<00:09, 574.83it/s] 45%|█████████████████████████████████████                                              | 4354/9741 [00:08<00:09, 575.25it/s] 45%|█████████████████████████████████████▌                                             | 4412/9741 [00:08<00:09, 575.22it/s] 46%|██████████████████████████████████████                                             | 4470/9741 [00:08<00:09, 575.80it/s] 46%|██████████████████████████████████████▌                                            | 4528/9741 [00:08<00:09, 542.47it/s] 47%|███████████████████████████████████████                                            | 4586/9741 [00:08<00:09, 551.25it/s] 48%|███████████████████████████████████████▌                                           | 4642/9741 [00:08<00:09, 550.03it/s] 48%|████████████████████████████████████████                                           | 4700/9741 [00:08<00:09, 556.49it/s] 49%|████████████████████████████████████████▌                                          | 4756/9741 [00:09<00:11, 417.87it/s] 49%|█████████████████████████████████████████                                          | 4814/9741 [00:09<00:10, 454.78it/s] 50%|█████████████████████████████████████████▌                                         | 4872/9741 [00:09<00:10, 484.47it/s] 51%|█████████████████████████████████████████▉                                         | 4929/9741 [00:09<00:09, 506.27it/s] 51%|██████████████████████████████████████████▍                                        | 4987/9741 [00:09<00:09, 524.02it/s] 52%|██████████████████████████████████████████▉                                        | 5045/9741 [00:09<00:08, 537.33it/s] 52%|███████████████████████████████████████████▍                                       | 5103/9741 [00:09<00:08, 547.31it/s] 53%|███████████████████████████████████████████▉                                       | 5160/9741 [00:09<00:08, 551.68it/s] 54%|████████████████████████████████████████████▍                                      | 5217/9741 [00:09<00:08, 556.87it/s] 54%|████████████████████████████████████████████▉                                      | 5274/9741 [00:09<00:07, 560.54it/s] 55%|█████████████████████████████████████████████▍                                     | 5332/9741 [00:10<00:07, 563.78it/s] 55%|█████████████████████████████████████████████▉                                     | 5389/9741 [00:10<00:07, 563.00it/s] 56%|██████████████████████████████████████████████▍                                    | 5447/9741 [00:10<00:07, 565.22it/s] 57%|██████████████████████████████████████████████▉                                    | 5504/9741 [00:10<00:07, 566.01it/s] 57%|███████████████████████████████████████████████▍                                   | 5562/9741 [00:10<00:07, 567.28it/s] 58%|███████████████████████████████████████████████▉                                   | 5619/9741 [00:10<00:07, 564.98it/s] 58%|████████████████████████████████████████████████▎                                  | 5677/9741 [00:10<00:07, 567.07it/s] 59%|████████████████████████████████████████████████▊                                  | 5734/9741 [00:10<00:07, 567.87it/s] 59%|█████████████████████████████████████████████████▎                                 | 5792/9741 [00:10<00:06, 568.78it/s] 60%|█████████████████████████████████████████████████▊                                 | 5849/9741 [00:11<00:06, 565.82it/s] 61%|██████████████████████████████████████████████████▎                                | 5906/9741 [00:11<00:06, 566.73it/s] 61%|██████████████████████████████████████████████████▊                                | 5964/9741 [00:11<00:06, 568.15it/s] 62%|███████████████████████████████████████████████████▎                               | 6022/9741 [00:11<00:06, 568.92it/s] 62%|███████████████████████████████████████████████████▊                               | 6079/9741 [00:11<00:06, 567.47it/s] 63%|████████████████████████████████████████████████████▎                              | 6136/9741 [00:11<00:06, 568.01it/s] 64%|████████████████████████████████████████████████████▊                              | 6193/9741 [00:11<00:06, 568.47it/s] 64%|█████████████████████████████████████████████████████▎                             | 6250/9741 [00:11<00:06, 567.75it/s] 65%|█████████████████████████████████████████████████████▋                             | 6307/9741 [00:11<00:06, 566.38it/s] 65%|██████████████████████████████████████████████████████▏                            | 6364/9741 [00:11<00:05, 566.76it/s] 66%|██████████████████████████████████████████████████████▋                            | 6421/9741 [00:12<00:05, 566.36it/s] 67%|███████████████████████████████████████████████████████▏                           | 6478/9741 [00:12<00:05, 562.50it/s] 67%|███████████████████████████████████████████████████████▋                           | 6535/9741 [00:12<00:05, 561.36it/s] 68%|████████████████████████████████████████████████████████▏                          | 6592/9741 [00:12<00:05, 562.94it/s] 68%|████████████████████████████████████████████████████████▋                          | 6650/9741 [00:12<00:05, 565.11it/s] 69%|█████████████████████████████████████████████████████████▏                         | 6707/9741 [00:12<00:05, 565.78it/s] 69%|█████████████████████████████████████████████████████████▋                         | 6764/9741 [00:12<00:05, 564.87it/s] 70%|██████████████████████████████████████████████████████████                         | 6821/9741 [00:12<00:05, 566.02it/s] 71%|██████████████████████████████████████████████████████████▌                        | 6878/9741 [00:12<00:05, 566.57it/s] 71%|███████████████████████████████████████████████████████████                        | 6935/9741 [00:12<00:04, 565.58it/s] 72%|███████████████████████████████████████████████████████████▌                       | 6992/9741 [00:13<00:04, 564.22it/s] 72%|████████████████████████████████████████████████████████████                       | 7049/9741 [00:13<00:04, 565.01it/s] 73%|████████████████████████████████████████████████████████████▌                      | 7106/9741 [00:13<00:04, 566.18it/s] 74%|█████████████████████████████████████████████████████████████                      | 7163/9741 [00:13<00:04, 566.32it/s] 74%|█████████████████████████████████████████████████████████████▌                     | 7220/9741 [00:13<00:04, 564.16it/s] 75%|██████████████████████████████████████████████████████████████                     | 7278/9741 [00:13<00:04, 565.94it/s] 75%|██████████████████████████████████████████████████████████████▌                    | 7336/9741 [00:13<00:04, 567.29it/s] 76%|██████████████████████████████████████████████████████████████▉                    | 7393/9741 [00:13<00:04, 567.98it/s] 76%|███████████████████████████████████████████████████████████████▍                   | 7450/9741 [00:13<00:04, 541.39it/s] 77%|███████████████████████████████████████████████████████████████▉                   | 7507/9741 [00:13<00:04, 549.19it/s] 78%|████████████████████████████████████████████████████████████████▍                  | 7564/9741 [00:14<00:03, 554.12it/s] 78%|████████████████████████████████████████████████████████████████▉                  | 7621/9741 [00:14<00:03, 558.19it/s] 79%|█████████████████████████████████████████████████████████████████▍                 | 7677/9741 [00:14<00:03, 558.61it/s] 79%|█████████████████████████████████████████████████████████████████▉                 | 7733/9741 [00:14<00:03, 552.03it/s] 80%|██████████████████████████████████████████████████████████████████▍                | 7790/9741 [00:14<00:03, 556.32it/s] 81%|██████████████████████████████████████████████████████████████████▊                | 7847/9741 [00:14<00:03, 560.22it/s] 81%|███████████████████████████████████████████████████████████████████▎               | 7904/9741 [00:14<00:03, 560.38it/s] 82%|███████████████████████████████████████████████████████████████████▊               | 7961/9741 [00:14<00:03, 563.09it/s] 82%|████████████████████████████████████████████████████████████████████▎              | 8018/9741 [00:14<00:03, 563.76it/s] 83%|████████████████████████████████████████████████████████████████████▊              | 8075/9741 [00:14<00:02, 564.02it/s] 83%|█████████████████████████████████████████████████████████████████████▎             | 8132/9741 [00:15<00:02, 563.81it/s] 84%|█████████████████████████████████████████████████████████████████████▊             | 8189/9741 [00:15<00:02, 565.33it/s] 85%|██████████████████████████████████████████████████████████████████████▎            | 8247/9741 [00:15<00:02, 566.80it/s] 85%|██████████████████████████████████████████████████████████████████████▊            | 8304/9741 [00:15<00:02, 566.90it/s] 86%|███████████████████████████████████████████████████████████████████████▏           | 8361/9741 [00:15<00:02, 565.77it/s] 86%|███████████████████████████████████████████████████████████████████████▋           | 8418/9741 [00:15<00:02, 566.57it/s] 87%|████████████████████████████████████████████████████████████████████████▏          | 8475/9741 [00:15<00:02, 566.45it/s] 88%|████████████████████████████████████████████████████████████████████████▋          | 8533/9741 [00:15<00:02, 567.66it/s] 88%|█████████████████████████████████████████████████████████████████████████▏         | 8590/9741 [00:15<00:02, 566.13it/s] 89%|█████████████████████████████████████████████████████████████████████████▋         | 8647/9741 [00:15<00:01, 566.02it/s] 89%|██████████████████████████████████████████████████████████████████████████▏        | 8704/9741 [00:16<00:01, 566.57it/s] 90%|██████████████████████████████████████████████████████████████████████████▋        | 8761/9741 [00:16<00:01, 567.33it/s] 91%|███████████████████████████████████████████████████████████████████████████▏       | 8818/9741 [00:16<00:01, 563.64it/s] 91%|███████████████████████████████████████████████████████████████████████████▌       | 8875/9741 [00:16<00:01, 564.02it/s] 92%|████████████████████████████████████████████████████████████████████████████       | 8932/9741 [00:16<00:01, 565.22it/s] 92%|████████████████████████████████████████████████████████████████████████████▌      | 8989/9741 [00:16<00:01, 560.40it/s] 93%|█████████████████████████████████████████████████████████████████████████████      | 9046/9741 [00:16<00:01, 557.97it/s] 93%|█████████████████████████████████████████████████████████████████████████████▌     | 9103/9741 [00:16<00:01, 560.54it/s] 94%|██████████████████████████████████████████████████████████████████████████████     | 9160/9741 [00:16<00:01, 562.82it/s] 95%|██████████████████████████████████████████████████████████████████████████████▌    | 9217/9741 [00:16<00:00, 564.49it/s] 95%|███████████████████████████████████████████████████████████████████████████████    | 9274/9741 [00:17<00:00, 563.30it/s] 96%|███████████████████████████████████████████████████████████████████████████████▌   | 9331/9741 [00:17<00:00, 564.45it/s] 96%|███████████████████████████████████████████████████████████████████████████████▉   | 9388/9741 [00:17<00:00, 565.50it/s] 97%|████████████████████████████████████████████████████████████████████████████████▍  | 9445/9741 [00:17<00:00, 566.43it/s] 98%|████████████████████████████████████████████████████████████████████████████████▉  | 9502/9741 [00:17<00:00, 564.55it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▍ | 9559/9741 [00:17<00:00, 565.72it/s] 99%|█████████████████████████████████████████████████████████████████████████████████▉ | 9616/9741 [00:17<00:00, 565.40it/s] 99%|██████████████████████████████████████████████████████████████████████████████████▍| 9673/9741 [00:17<00:00, 564.33it/s]100%|██████████████████████████████████████████████████████████████████████████████████▉| 9730/9741 [00:17<00:00, 562.55it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:17<00:00, 543.98it/s]
Load End
Num instances: 1000
[2023-08-22 22:24:43,408] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 22:24:46,167] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 22:24:46,167] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 22:24:46,167] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 22:24:46,167] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 22:24:46,167] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 22:24:46,167] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f7fe2019a60>
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f7fe2019940>
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 22:24:46,168] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 22:24:46,169] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 22:24:46,169] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 22:24:46,169] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 22:24:46,169] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 22:24:46,169] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 22:24:46,169] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 22:24:46,169] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 22:24:46,169] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 22:24:46,169] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 22:24:46,169] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 22:24:46,169] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 22:24:46,169] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 22:24:46,169] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 22:24:46,169] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 22:24:46,169] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 22:24:46,169] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 22:24:46,169] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.41705822944641113 seconds
Loading extension module utils...
Time to load utils op: 0.40450525283813477 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: Let x = the total number of candies Corey has.
x + 8 = the total number of candies Tapanga has.
The equation for the total number of candies is x + (x + 8) = 66
Combining like terms, we get 2x + 8 = 66
Subtracting 8 from both sides, we get 2x = 58
Dividing both sides by 2, we get x = <<29=29>>29, so Corey has 29 candies.
So the final answer is 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: At 5 cents a minute, calling his father cost Freddy 5* 45 = <<5*45=225>>225 cents.
At 25 cents a minute, calling his brother cost Freddy 25 * 31 = <<25*31=775>>775 cents.
Adding the cost of calling his father and brother, we find that Freddy paid a total of 225 + 775 = <<225+775=1000>>1000 cents.
Since each dollar has 100 cents, Freddy paid 1000 / 100 = <<1000/100=10>>10 dollars
So the final answer is 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 8 hours * 3 = <<8*3=24>>24 hours
5.5 * 2 = <<5.5*2=11>>11 hours
24 + 11 = <<24+11=35>>35 hours
35/7 = <<35/7=5>>5 hours
Lawrence would work 5 hours each of the 7 days in a week.
So the final answer is 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: We look first for the total number of books that were sold: 60 + 10 + 20 + 44 + 66 = <<60+10+20+44+66=200>>200 books.
So the total number of books that were not sold is: 800 – 200 = <<800-200=600>>600 books.
So the final answer is 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: Michael sold 2 large birdhouses for $22 each, so he made 2*$22= $<<2*22=44>>44 from large birdhouse sales.
Michael also sold 2 medium birdhouses for $16 each, so he made 2*$16= $<<2*16=32>>32 from medium birdhouse sales.
Michael sold 3 small birdhouses for $7 each, so he made 3*7=$<<3*7=21>>21 from small birdhouse sales.
Since Michael made $44 from large birdhouse sales, $32 from medium birdhouse sales, and $21 for small birdhouse sales, he made $44+$32+$21= $<<44+32+21=97>>97 total this week.
So the final answer is 97

Input: Nalani had two female dogs that were expecting and after a month gave birth to 10 puppies each. She then sold 3/4 of the puppies after they came of age, each at $200. Calculate the total amount of money she received from the sale of the puppies.
Output: If the two expectant dogs gave birth to 10 puppies each, the total number of puppies Nalani had is 10+10= <<10+10=20>>20
When they came of age, Nalani sold 3/4 of the dogs, a total of 3/4*20 = <<3/4*20=15>>15 dogs.
If each dog sold for $200, Nalani received 15*200 = $<<15*200=3000>>3000 from the sale of the dogs.
So the final answer is 3000

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o6-tgsm8k-s20-rTrue
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:39<32:11, 39.42s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:17<30:51, 38.56s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [01:54<29:51, 38.11s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [02:32<29:03, 37.91s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [03:10<28:20, 37.80s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [03:48<27:49, 37.95s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [04:26<27:16, 38.06s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [05:04<26:31, 37.89s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [05:42<26:03, 38.14s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [06:20<25:21, 38.03s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [06:58<24:40, 37.96s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [07:36<24:01, 37.93s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [08:14<23:31, 38.14s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [08:53<22:57, 38.25s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [09:30<22:09, 37.99s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [10:08<21:29, 37.94s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [10:46<20:53, 37.99s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [11:24<20:14, 37.94s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [12:02<19:31, 37.80s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [12:39<18:54, 37.83s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [13:17<18:13, 37.70s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [13:55<17:41, 37.90s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [14:33<17:03, 37.90s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [15:11<16:28, 38.01s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [15:49<15:47, 37.88s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [16:27<15:10, 37.96s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [17:05<14:31, 37.89s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [17:43<13:56, 38.00s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [18:21<13:16, 37.94s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [18:59<12:37, 37.86s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [19:36<11:56, 37.71s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [20:14<11:18, 37.71s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [20:52<10:45, 37.96s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [21:30<10:06, 37.90s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [22:09<09:33, 38.24s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [22:47<08:55, 38.26s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [23:25<08:15, 38.11s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [24:03<07:35, 37.93s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [24:41<06:57, 37.93s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [25:19<06:20, 38.09s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [25:58<05:44, 38.23s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [26:35<05:04, 38.07s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [27:13<04:26, 38.01s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [27:51<03:48, 38.02s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [28:29<03:09, 37.91s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [29:07<02:31, 37.91s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [29:45<01:53, 37.89s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [30:23<01:16, 38.09s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [31:01<00:38, 38.03s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [31:38<00:00, 37.85s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [31:38<00:00, 37.98s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.2724} | avg. gen lenth: 439.142
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o7-tgsm8k-s20-rTrue --seed 20 --max-prompt-length 2048 --rationales --num-out-domain 7
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 22:56:32,153] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o7-tgsm8k-s20-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 7
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o7-tgsm8k-s20-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  0%|▎                                                                                    | 36/9741 [00:00<00:27, 350.62it/s]  1%|▋                                                                                    | 72/9741 [00:00<00:27, 355.01it/s]  1%|▉                                                                                   | 109/9741 [00:00<00:26, 357.57it/s]  1%|█▎                                                                                  | 145/9741 [00:00<00:26, 357.60it/s]  2%|█▌                                                                                  | 181/9741 [00:00<00:26, 354.92it/s]  2%|█▊                                                                                  | 217/9741 [00:00<00:26, 356.14it/s]  3%|██▏                                                                                 | 253/9741 [00:00<00:26, 356.79it/s]  3%|██▌                                                                                 | 290/9741 [00:00<00:26, 358.30it/s]  3%|██▊                                                                                 | 327/9741 [00:00<00:26, 359.49it/s]  4%|███▏                                                                                | 364/9741 [00:01<00:26, 360.37it/s]  4%|███▍                                                                                | 401/9741 [00:01<00:25, 359.66it/s]  4%|███▊                                                                                | 437/9741 [00:01<00:26, 353.89it/s]  5%|████                                                                                | 473/9741 [00:01<00:26, 355.64it/s]  5%|████▍                                                                               | 510/9741 [00:01<00:25, 357.13it/s]  6%|████▋                                                                               | 546/9741 [00:01<00:25, 357.27it/s]  6%|█████                                                                               | 582/9741 [00:01<00:25, 357.43it/s]  6%|█████▎                                                                              | 618/9741 [00:01<00:25, 358.09it/s]  7%|█████▋                                                                              | 654/9741 [00:01<00:25, 356.93it/s]  7%|█████▉                                                                              | 690/9741 [00:01<00:25, 357.03it/s]  7%|██████▎                                                                             | 726/9741 [00:02<00:25, 357.76it/s]  8%|██████▌                                                                             | 763/9741 [00:02<00:25, 359.00it/s]  8%|██████▉                                                                             | 799/9741 [00:02<00:25, 356.35it/s]  9%|███████▏                                                                            | 835/9741 [00:02<00:24, 356.80it/s]  9%|███████▌                                                                            | 871/9741 [00:02<00:24, 355.83it/s]  9%|███████▊                                                                            | 908/9741 [00:02<00:24, 357.86it/s] 10%|████████▏                                                                           | 945/9741 [00:02<00:24, 359.58it/s] 10%|████████▍                                                                           | 982/9741 [00:02<00:24, 360.11it/s] 10%|████████▋                                                                          | 1019/9741 [00:02<00:24, 360.48it/s] 11%|████████▉                                                                          | 1056/9741 [00:02<00:24, 360.53it/s] 11%|█████████▎                                                                         | 1093/9741 [00:03<00:24, 358.92it/s] 12%|█████████▋                                                                         | 1130/9741 [00:03<00:23, 360.05it/s] 12%|█████████▉                                                                         | 1167/9741 [00:03<00:23, 360.81it/s] 12%|██████████▎                                                                        | 1204/9741 [00:03<00:23, 362.17it/s] 13%|██████████▌                                                                        | 1241/9741 [00:03<00:23, 362.79it/s] 13%|██████████▉                                                                        | 1278/9741 [00:03<00:23, 363.44it/s] 13%|███████████▏                                                                       | 1315/9741 [00:03<00:23, 362.06it/s] 14%|███████████▌                                                                       | 1357/9741 [00:03<00:22, 377.38it/s] 14%|████████████                                                                       | 1411/9741 [00:03<00:19, 424.72it/s] 15%|████████████▍                                                                      | 1465/9741 [00:03<00:18, 457.45it/s] 16%|████████████▉                                                                      | 1519/9741 [00:04<00:17, 480.91it/s] 16%|█████████████▍                                                                     | 1573/9741 [00:04<00:16, 496.40it/s] 17%|█████████████▊                                                                     | 1627/9741 [00:04<00:15, 507.88it/s] 17%|██████████████▎                                                                    | 1681/9741 [00:04<00:15, 516.72it/s] 18%|██████████████▊                                                                    | 1735/9741 [00:04<00:15, 523.30it/s] 18%|███████████████▏                                                                   | 1788/9741 [00:04<00:15, 505.15it/s] 19%|███████████████▋                                                                   | 1842/9741 [00:04<00:15, 512.86it/s] 19%|████████████████▏                                                                  | 1894/9741 [00:04<00:15, 512.52it/s] 20%|████████████████▌                                                                  | 1947/9741 [00:04<00:15, 516.89it/s] 21%|█████████████████                                                                  | 1999/9741 [00:04<00:14, 517.53it/s] 21%|█████████████████▍                                                                 | 2053/9741 [00:05<00:14, 521.74it/s] 22%|█████████████████▉                                                                 | 2107/9741 [00:05<00:14, 524.69it/s] 22%|██████████████████▍                                                                | 2161/9741 [00:05<00:14, 527.06it/s] 23%|██████████████████▊                                                                | 2214/9741 [00:05<00:14, 526.62it/s] 23%|███████████████████▎                                                               | 2268/9741 [00:05<00:14, 527.87it/s] 24%|███████████████████▊                                                               | 2322/9741 [00:05<00:14, 528.79it/s] 24%|████████████████████▏                                                              | 2376/9741 [00:05<00:13, 530.16it/s] 25%|████████████████████▋                                                              | 2430/9741 [00:05<00:13, 531.35it/s] 26%|█████████████████████▏                                                             | 2484/9741 [00:05<00:13, 529.06it/s] 26%|█████████████████████▋                                                             | 2538/9741 [00:06<00:13, 529.70it/s] 27%|██████████████████████                                                             | 2591/9741 [00:06<00:13, 528.85it/s] 27%|██████████████████████▌                                                            | 2644/9741 [00:06<00:13, 527.52it/s] 28%|██████████████████████▉                                                            | 2697/9741 [00:06<00:13, 525.39it/s] 28%|███████████████████████▍                                                           | 2750/9741 [00:06<00:13, 525.81it/s] 29%|███████████████████████▉                                                           | 2803/9741 [00:06<00:13, 525.83it/s] 29%|████████████████████████▎                                                          | 2856/9741 [00:06<00:13, 525.43it/s] 30%|████████████████████████▊                                                          | 2909/9741 [00:06<00:13, 523.19it/s] 30%|█████████████████████████▏                                                         | 2962/9741 [00:06<00:12, 523.12it/s] 31%|█████████████████████████▋                                                         | 3015/9741 [00:06<00:12, 524.45it/s] 31%|██████████████████████████▏                                                        | 3068/9741 [00:07<00:12, 523.62it/s] 32%|██████████████████████████▌                                                        | 3121/9741 [00:07<00:12, 521.31it/s] 33%|███████████████████████████                                                        | 3174/9741 [00:07<00:12, 521.74it/s] 33%|███████████████████████████▍                                                       | 3227/9741 [00:07<00:12, 522.25it/s] 34%|███████████████████████████▉                                                       | 3280/9741 [00:07<00:12, 522.61it/s] 34%|████████████████████████████▍                                                      | 3333/9741 [00:07<00:12, 522.74it/s] 35%|████████████████████████████▊                                                      | 3386/9741 [00:07<00:12, 521.33it/s] 35%|█████████████████████████████▎                                                     | 3439/9741 [00:07<00:12, 522.34it/s] 36%|█████████████████████████████▊                                                     | 3492/9741 [00:07<00:12, 516.09it/s] 36%|██████████████████████████████▏                                                    | 3545/9741 [00:07<00:11, 517.57it/s] 37%|██████████████████████████████▋                                                    | 3597/9741 [00:08<00:11, 515.21it/s] 37%|███████████████████████████████                                                    | 3649/9741 [00:08<00:11, 516.56it/s] 38%|███████████████████████████████▌                                                   | 3701/9741 [00:08<00:11, 517.27it/s] 39%|███████████████████████████████▉                                                   | 3754/9741 [00:08<00:11, 518.24it/s] 39%|████████████████████████████████▍                                                  | 3806/9741 [00:08<00:11, 515.92it/s] 40%|████████████████████████████████▊                                                  | 3858/9741 [00:08<00:11, 516.84it/s] 40%|█████████████████████████████████▎                                                 | 3910/9741 [00:08<00:11, 516.55it/s] 41%|█████████████████████████████████▊                                                 | 3962/9741 [00:08<00:11, 516.57it/s] 41%|██████████████████████████████████▏                                                | 4014/9741 [00:08<00:11, 516.25it/s] 42%|██████████████████████████████████▋                                                | 4066/9741 [00:08<00:11, 513.99it/s] 42%|███████████████████████████████████                                                | 4118/9741 [00:09<00:10, 514.35it/s] 43%|███████████████████████████████████▌                                               | 4170/9741 [00:09<00:10, 514.60it/s] 43%|███████████████████████████████████▉                                               | 4222/9741 [00:09<00:10, 514.70it/s] 44%|████████████████████████████████████▍                                              | 4274/9741 [00:09<00:10, 514.12it/s] 44%|████████████████████████████████████▊                                              | 4327/9741 [00:09<00:10, 516.10it/s] 45%|█████████████████████████████████████▎                                             | 4379/9741 [00:09<00:10, 516.57it/s] 45%|█████████████████████████████████████▊                                             | 4431/9741 [00:09<00:10, 516.87it/s] 46%|██████████████████████████████████████▏                                            | 4483/9741 [00:09<00:10, 487.62it/s] 47%|██████████████████████████████████████▋                                            | 4535/9741 [00:09<00:10, 495.56it/s] 47%|███████████████████████████████████████                                            | 4588/9741 [00:09<00:10, 502.85it/s] 48%|███████████████████████████████████████▌                                           | 4640/9741 [00:10<00:10, 507.20it/s] 48%|███████████████████████████████████████▉                                           | 4692/9741 [00:10<00:09, 510.31it/s] 49%|████████████████████████████████████████▍                                          | 4744/9741 [00:10<00:13, 373.06it/s] 49%|████████████████████████████████████████▊                                          | 4796/9741 [00:10<00:12, 406.75it/s] 50%|█████████████████████████████████████████▎                                         | 4848/9741 [00:10<00:11, 433.73it/s] 50%|█████████████████████████████████████████▊                                         | 4900/9741 [00:10<00:10, 455.52it/s] 51%|██████████████████████████████████████████▏                                        | 4951/9741 [00:10<00:10, 470.25it/s] 51%|██████████████████████████████████████████▋                                        | 5003/9741 [00:10<00:09, 483.32it/s] 52%|███████████████████████████████████████████                                        | 5055/9741 [00:11<00:09, 493.20it/s] 52%|███████████████████████████████████████████▌                                       | 5107/9741 [00:11<00:09, 500.19it/s] 53%|███████████████████████████████████████████▉                                       | 5158/9741 [00:11<00:09, 502.66it/s] 53%|████████████████████████████████████████████▍                                      | 5210/9741 [00:11<00:08, 506.60it/s] 54%|████████████████████████████████████████████▊                                      | 5262/9741 [00:11<00:08, 508.22it/s] 55%|█████████████████████████████████████████████▎                                     | 5314/9741 [00:11<00:08, 508.98it/s] 55%|█████████████████████████████████████████████▋                                     | 5366/9741 [00:11<00:08, 508.17it/s] 56%|██████████████████████████████████████████████▏                                    | 5418/9741 [00:11<00:08, 509.84it/s] 56%|██████████████████████████████████████████████▌                                    | 5470/9741 [00:11<00:08, 511.11it/s] 57%|███████████████████████████████████████████████                                    | 5522/9741 [00:11<00:08, 511.76it/s] 57%|███████████████████████████████████████████████▍                                   | 5574/9741 [00:12<00:08, 512.41it/s] 58%|███████████████████████████████████████████████▉                                   | 5626/9741 [00:12<00:08, 509.74it/s] 58%|████████████████████████████████████████████████▍                                  | 5678/9741 [00:12<00:07, 510.72it/s] 59%|████████████████████████████████████████████████▊                                  | 5730/9741 [00:12<00:07, 511.83it/s] 59%|█████████████████████████████████████████████████▎                                 | 5782/9741 [00:12<00:07, 512.56it/s] 60%|█████████████████████████████████████████████████▋                                 | 5834/9741 [00:12<00:07, 510.44it/s] 60%|██████████████████████████████████████████████████▏                                | 5886/9741 [00:12<00:07, 511.24it/s] 61%|██████████████████████████████████████████████████▌                                | 5938/9741 [00:12<00:07, 512.18it/s] 61%|███████████████████████████████████████████████████                                | 5990/9741 [00:12<00:07, 513.39it/s] 62%|███████████████████████████████████████████████████▍                               | 6042/9741 [00:12<00:07, 510.10it/s] 63%|███████████████████████████████████████████████████▉                               | 6094/9741 [00:13<00:07, 509.18it/s] 63%|████████████████████████████████████████████████████▎                              | 6146/9741 [00:13<00:07, 510.88it/s] 64%|████████████████████████████████████████████████████▊                              | 6198/9741 [00:13<00:06, 512.56it/s] 64%|█████████████████████████████████████████████████████▎                             | 6250/9741 [00:13<00:06, 513.38it/s] 65%|█████████████████████████████████████████████████████▋                             | 6302/9741 [00:13<00:06, 511.52it/s] 65%|██████████████████████████████████████████████████████▏                            | 6354/9741 [00:13<00:06, 512.95it/s] 66%|██████████████████████████████████████████████████████▌                            | 6406/9741 [00:13<00:06, 513.73it/s] 66%|███████████████████████████████████████████████████████                            | 6458/9741 [00:13<00:06, 513.96it/s] 67%|███████████████████████████████████████████████████████▍                           | 6510/9741 [00:13<00:06, 511.77it/s] 67%|███████████████████████████████████████████████████████▉                           | 6562/9741 [00:13<00:06, 512.94it/s] 68%|████████████████████████████████████████████████████████▎                          | 6614/9741 [00:14<00:06, 513.83it/s] 68%|████████████████████████████████████████████████████████▊                          | 6666/9741 [00:14<00:05, 513.48it/s] 69%|█████████████████████████████████████████████████████████▏                         | 6718/9741 [00:14<00:05, 512.29it/s] 70%|█████████████████████████████████████████████████████████▋                         | 6770/9741 [00:14<00:05, 510.70it/s] 70%|██████████████████████████████████████████████████████████▏                        | 6822/9741 [00:14<00:05, 511.51it/s] 71%|██████████████████████████████████████████████████████████▌                        | 6874/9741 [00:14<00:05, 511.94it/s] 71%|███████████████████████████████████████████████████████████                        | 6926/9741 [00:14<00:05, 512.52it/s] 72%|███████████████████████████████████████████████████████████▍                       | 6978/9741 [00:14<00:05, 511.53it/s] 72%|███████████████████████████████████████████████████████████▉                       | 7030/9741 [00:14<00:05, 512.81it/s] 73%|████████████████████████████████████████████████████████████▎                      | 7082/9741 [00:14<00:05, 513.82it/s] 73%|████████████████████████████████████████████████████████████▊                      | 7134/9741 [00:15<00:05, 514.47it/s] 74%|█████████████████████████████████████████████████████████████▏                     | 7186/9741 [00:15<00:05, 504.89it/s] 74%|█████████████████████████████████████████████████████████████▋                     | 7238/9741 [00:15<00:04, 507.75it/s] 75%|██████████████████████████████████████████████████████████████                     | 7290/9741 [00:15<00:04, 509.98it/s] 75%|██████████████████████████████████████████████████████████████▌                    | 7342/9741 [00:15<00:04, 512.06it/s] 76%|███████████████████████████████████████████████████████████████                    | 7394/9741 [00:15<00:04, 513.54it/s] 76%|███████████████████████████████████████████████████████████████▍                   | 7446/9741 [00:15<00:04, 488.22it/s] 77%|███████████████████████████████████████████████████████████████▉                   | 7498/9741 [00:15<00:04, 495.53it/s] 77%|████████████████████████████████████████████████████████████████▎                  | 7549/9741 [00:15<00:04, 499.60it/s] 78%|████████████████████████████████████████████████████████████████▊                  | 7601/9741 [00:16<00:04, 503.87it/s] 79%|█████████████████████████████████████████████████████████████████▏                 | 7652/9741 [00:16<00:04, 504.71it/s] 79%|█████████████████████████████████████████████████████████████████▋                 | 7704/9741 [00:16<00:04, 507.61it/s] 80%|██████████████████████████████████████████████████████████████████                 | 7756/9741 [00:16<00:03, 509.81it/s] 80%|██████████████████████████████████████████████████████████████████▌                | 7808/9741 [00:16<00:03, 511.44it/s] 81%|██████████████████████████████████████████████████████████████████▉                | 7860/9741 [00:16<00:03, 512.48it/s] 81%|███████████████████████████████████████████████████████████████████▍               | 7912/9741 [00:16<00:03, 510.99it/s] 82%|███████████████████████████████████████████████████████████████████▊               | 7964/9741 [00:16<00:03, 512.09it/s] 82%|████████████████████████████████████████████████████████████████████▎              | 8016/9741 [00:16<00:03, 513.45it/s] 83%|████████████████████████████████████████████████████████████████████▋              | 8068/9741 [00:16<00:03, 513.60it/s] 83%|█████████████████████████████████████████████████████████████████████▏             | 8120/9741 [00:17<00:03, 512.19it/s] 84%|█████████████████████████████████████████████████████████████████████▋             | 8172/9741 [00:17<00:03, 512.55it/s] 84%|██████████████████████████████████████████████████████████████████████             | 8224/9741 [00:17<00:02, 514.38it/s] 85%|██████████████████████████████████████████████████████████████████████▌            | 8276/9741 [00:17<00:02, 511.21it/s] 85%|██████████████████████████████████████████████████████████████████████▉            | 8328/9741 [00:17<00:02, 508.47it/s] 86%|███████████████████████████████████████████████████████████████████████▍           | 8380/9741 [00:17<00:02, 510.40it/s] 87%|███████████████████████████████████████████████████████████████████████▊           | 8432/9741 [00:17<00:02, 510.88it/s] 87%|████████████████████████████████████████████████████████████████████████▎          | 8484/9741 [00:17<00:02, 511.21it/s] 88%|████████████████████████████████████████████████████████████████████████▋          | 8536/9741 [00:17<00:02, 511.78it/s] 88%|█████████████████████████████████████████████████████████████████████████▏         | 8588/9741 [00:17<00:02, 509.92it/s] 89%|█████████████████████████████████████████████████████████████████████████▌         | 8639/9741 [00:18<00:02, 509.23it/s] 89%|██████████████████████████████████████████████████████████████████████████         | 8691/9741 [00:18<00:02, 510.07it/s] 90%|██████████████████████████████████████████████████████████████████████████▍        | 8743/9741 [00:18<00:01, 511.16it/s] 90%|██████████████████████████████████████████████████████████████████████████▉        | 8795/9741 [00:18<00:01, 509.28it/s] 91%|███████████████████████████████████████████████████████████████████████████▍       | 8847/9741 [00:18<00:01, 510.56it/s] 91%|███████████████████████████████████████████████████████████████████████████▊       | 8899/9741 [00:18<00:01, 511.79it/s] 92%|████████████████████████████████████████████████████████████████████████████▎      | 8951/9741 [00:18<00:01, 511.92it/s] 92%|████████████████████████████████████████████████████████████████████████████▋      | 9003/9741 [00:18<00:01, 510.07it/s] 93%|█████████████████████████████████████████████████████████████████████████████▏     | 9055/9741 [00:18<00:01, 510.92it/s] 93%|█████████████████████████████████████████████████████████████████████████████▌     | 9107/9741 [00:18<00:01, 512.19it/s] 94%|██████████████████████████████████████████████████████████████████████████████     | 9159/9741 [00:19<00:01, 512.99it/s] 95%|██████████████████████████████████████████████████████████████████████████████▍    | 9211/9741 [00:19<00:01, 513.21it/s] 95%|██████████████████████████████████████████████████████████████████████████████▉    | 9263/9741 [00:19<00:00, 511.73it/s] 96%|███████████████████████████████████████████████████████████████████████████████▎   | 9315/9741 [00:19<00:00, 512.91it/s] 96%|███████████████████████████████████████████████████████████████████████████████▊   | 9367/9741 [00:19<00:00, 513.06it/s] 97%|████████████████████████████████████████████████████████████████████████████████▎  | 9419/9741 [00:19<00:00, 513.31it/s] 97%|████████████████████████████████████████████████████████████████████████████████▋  | 9471/9741 [00:19<00:00, 511.17it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▏ | 9523/9741 [00:19<00:00, 512.65it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▌ | 9575/9741 [00:19<00:00, 513.70it/s] 99%|██████████████████████████████████████████████████████████████████████████████████ | 9627/9741 [00:19<00:00, 514.37it/s] 99%|██████████████████████████████████████████████████████████████████████████████████▍| 9679/9741 [00:20<00:00, 512.82it/s]100%|██████████████████████████████████████████████████████████████████████████████████▉| 9731/9741 [00:20<00:00, 513.35it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:20<00:00, 482.72it/s]
Load End
Num instances: 1000
[2023-08-22 22:57:03,976] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 22:57:06,635] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 22:57:06,635] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 22:57:06,635] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 22:57:06,635] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 22:57:06,635] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 22:57:06,635] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f519fd25a60>
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f519fd25940>
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 22:57:06,636] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 22:57:06,637] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 22:57:06,637] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 22:57:06,637] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 22:57:06,637] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 22:57:06,637] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 22:57:06,637] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 22:57:06,637] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 22:57:06,637] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 22:57:06,637] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 22:57:06,637] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 22:57:06,637] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 22:57:06,637] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4504387378692627 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: Let x = the total number of candies Corey has.
x + 8 = the total number of candies Tapanga has.
The equation for the total number of candies is x + (x + 8) = 66
Combining like terms, we get 2x + 8 = 66
Subtracting 8 from both sides, we get 2x = 58
Dividing both sides by 2, we get x = <<29=29>>29, so Corey has 29 candies.
So the final answer is 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: At 5 cents a minute, calling his father cost Freddy 5* 45 = <<5*45=225>>225 cents.
At 25 cents a minute, calling his brother cost Freddy 25 * 31 = <<25*31=775>>775 cents.
Adding the cost of calling his father and brother, we find that Freddy paid a total of 225 + 775 = <<225+775=1000>>1000 cents.
Since each dollar has 100 cents, Freddy paid 1000 / 100 = <<1000/100=10>>10 dollars
So the final answer is 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 8 hours * 3 = <<8*3=24>>24 hours
5.5 * 2 = <<5.5*2=11>>11 hours
24 + 11 = <<24+11=35>>35 hours
35/7 = <<35/7=5>>5 hours
Lawrence would work 5 hours each of the 7 days in a week.
So the final answer is 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: We look first for the total number of books that were sold: 60 + 10 + 20 + 44 + 66 = <<60+10+20+44+66=200>>200 books.
So the total number of books that were not sold is: 800 – 200 = <<800-200=600>>600 books.
So the final answer is 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: Michael sold 2 large birdhouses for $22 each, so he made 2*$22= $<<2*22=44>>44 from large birdhouse sales.
Michael also sold 2 medium birdhouses for $16 each, so he made 2*$16= $<<2*16=32>>32 from medium birdhouse sales.
Michael sold 3 small birdhouses for $7 each, so he made 3*7=$<<3*7=21>>21 from small birdhouse sales.
Since Michael made $44 from large birdhouse sales, $32 from medium birdhouse sales, and $21 for small birdhouse sales, he made $44+$32+$21= $<<44+32+21=97>>97 total this week.
So the final answer is 97

Input: Nalani had two female dogs that were expecting and after a month gave birth to 10 puppies each. She then sold 3/4 of the puppies after they came of age, each at $200. Calculate the total amount of money she received from the sale of the puppies.
Output: If the two expectant dogs gave birth to 10 puppies each, the total number of puppies Nalani had is 10+10= <<10+10=20>>20
When they came of age, Nalani sold 3/4 of the dogs, a total of 3/4*20 = <<3/4*20=15>>15 dogs.
If each dog sold for $200, Nalani received 15*200 = $<<15*200=3000>>3000 from the sale of the dogs.
So the final answer is 3000

Input: Boris has 24 books and he donates a fourth of his books to the library. Cameron has 30 books and he donates a third of his books to the library. After donating their books, how many books in total do Boris and Cameron have together?
Output: Boris donates 24 / 4 = <<24/4=6>>6 books
Then Boris has a total of 24 - 6 = <<24-6=18>>18 books
Cameron donates 30 / 3 = <<30/3=10>>10 books
Then Cameron has a total of 30 - 10 = <<30-10=20>>20 books
Altogether, Boris and Cameron have 18 + 20 = <<18+20=38>>38 books
So the final answer is 38

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o7-tgsm8k-s20-rTrue
Loading extension module utils...
Time to load utils op: 0.5049645900726318 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:35<29:23, 36.00s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:11<28:26, 35.56s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [01:46<27:44, 35.41s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [02:21<27:02, 35.28s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [02:57<26:32, 35.40s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [03:31<25:46, 35.14s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [04:07<25:16, 35.27s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [04:42<24:37, 35.17s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [05:18<24:09, 35.36s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [05:52<23:26, 35.17s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [06:28<22:55, 35.27s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [07:03<22:18, 35.23s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [07:38<21:37, 35.07s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [08:12<20:59, 34.98s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [08:47<20:23, 34.96s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [09:23<19:55, 35.16s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [09:58<19:15, 35.02s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [10:32<18:37, 34.92s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [11:08<18:06, 35.03s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [11:43<17:34, 35.16s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [12:18<16:59, 35.17s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [12:53<16:23, 35.14s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [13:28<15:46, 35.06s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [14:03<15:08, 34.95s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [14:38<14:36, 35.05s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [15:14<14:04, 35.18s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [15:49<13:31, 35.29s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [16:24<12:52, 35.12s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [17:00<12:21, 35.31s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [17:35<11:44, 35.24s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [18:10<11:08, 35.18s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [18:45<10:33, 35.18s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [19:20<09:58, 35.19s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [19:56<09:24, 35.30s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [20:31<08:50, 35.33s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [21:06<08:13, 35.28s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [21:42<07:38, 35.28s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [22:17<07:04, 35.38s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [22:53<06:31, 35.57s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [23:28<05:54, 35.43s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [24:03<05:17, 35.24s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [24:38<04:41, 35.19s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [25:14<04:07, 35.31s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [25:49<03:31, 35.32s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [26:24<02:56, 35.25s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [27:01<02:22, 35.56s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [27:35<01:46, 35.34s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [28:10<01:10, 35.13s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [28:45<00:35, 35.18s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [29:21<00:00, 35.28s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [29:21<00:00, 35.23s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 0.9726} | avg. gen lenth: 449.472
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s20-rTrue --seed 20 --max-prompt-length 2048 --rationales --num-out-domain 8
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 23:26:50,727] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s20-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 8
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o8-tgsm8k-s20-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  0%|▎                                                                                    | 32/9741 [00:00<00:30, 318.81it/s]  1%|▌                                                                                    | 65/9741 [00:00<00:30, 321.01it/s]  1%|▊                                                                                    | 98/9741 [00:00<00:29, 322.83it/s]  1%|█▏                                                                                  | 131/9741 [00:00<00:29, 324.22it/s]  2%|█▍                                                                                  | 164/9741 [00:00<00:29, 324.72it/s]  2%|█▋                                                                                  | 197/9741 [00:00<00:29, 323.02it/s]  2%|█▉                                                                                  | 230/9741 [00:00<00:29, 324.12it/s]  3%|██▎                                                                                 | 263/9741 [00:00<00:29, 319.76it/s]  3%|██▌                                                                                 | 296/9741 [00:00<00:29, 321.51it/s]  3%|██▊                                                                                 | 329/9741 [00:01<00:29, 323.33it/s]  4%|███                                                                                 | 362/9741 [00:01<00:28, 324.80it/s]  4%|███▍                                                                                | 396/9741 [00:01<00:28, 326.44it/s]  4%|███▋                                                                                | 429/9741 [00:01<00:28, 325.31it/s]  5%|███▉                                                                                | 462/9741 [00:01<00:28, 326.36it/s]  5%|████▎                                                                               | 495/9741 [00:01<00:28, 326.53it/s]  5%|████▌                                                                               | 528/9741 [00:01<00:28, 326.66it/s]  6%|████▊                                                                               | 563/9741 [00:01<00:27, 331.73it/s]  6%|█████▎                                                                              | 612/9741 [00:01<00:24, 377.30it/s]  7%|█████▋                                                                              | 661/9741 [00:01<00:22, 408.41it/s]  7%|██████                                                                              | 710/9741 [00:02<00:20, 432.52it/s]  8%|██████▌                                                                             | 759/9741 [00:02<00:20, 449.06it/s]  8%|██████▉                                                                             | 808/9741 [00:02<00:19, 460.72it/s]  9%|███████▍                                                                            | 856/9741 [00:02<00:19, 466.39it/s]  9%|███████▊                                                                            | 905/9741 [00:02<00:18, 470.91it/s] 10%|████████▏                                                                           | 954/9741 [00:02<00:18, 475.82it/s] 10%|████████▌                                                                          | 1004/9741 [00:02<00:18, 480.15it/s] 11%|████████▉                                                                          | 1054/9741 [00:02<00:17, 483.61it/s] 11%|█████████▍                                                                         | 1103/9741 [00:02<00:17, 483.94it/s] 12%|█████████▊                                                                         | 1153/9741 [00:02<00:17, 486.36it/s] 12%|██████████▏                                                                        | 1202/9741 [00:03<00:17, 487.41it/s] 13%|██████████▋                                                                        | 1251/9741 [00:03<00:17, 482.55it/s] 13%|███████████                                                                        | 1300/9741 [00:03<00:17, 484.37it/s] 14%|███████████▍                                                                       | 1349/9741 [00:03<00:17, 482.39it/s] 14%|███████████▉                                                                       | 1398/9741 [00:03<00:17, 482.92it/s] 15%|████████████▎                                                                      | 1447/9741 [00:03<00:17, 483.67it/s] 15%|████████████▋                                                                      | 1496/9741 [00:03<00:17, 484.86it/s] 16%|█████████████▏                                                                     | 1545/9741 [00:03<00:16, 483.94it/s] 16%|█████████████▌                                                                     | 1594/9741 [00:03<00:16, 484.26it/s] 17%|█████████████▉                                                                     | 1643/9741 [00:03<00:16, 483.98it/s] 17%|██████████████▍                                                                    | 1692/9741 [00:04<00:16, 483.86it/s] 18%|██████████████▊                                                                    | 1741/9741 [00:04<00:16, 484.71it/s] 18%|███████████████▎                                                                   | 1790/9741 [00:04<00:17, 460.89it/s] 19%|███████████████▋                                                                   | 1839/9741 [00:04<00:16, 467.48it/s] 19%|████████████████                                                                   | 1887/9741 [00:04<00:16, 470.99it/s] 20%|████████████████▍                                                                  | 1936/9741 [00:04<00:16, 474.71it/s] 20%|████████████████▉                                                                  | 1985/9741 [00:04<00:16, 477.17it/s] 21%|█████████████████▎                                                                 | 2033/9741 [00:04<00:16, 476.33it/s] 21%|█████████████████▋                                                                 | 2081/9741 [00:04<00:16, 476.59it/s] 22%|██████████████████▏                                                                | 2130/9741 [00:04<00:15, 477.84it/s] 22%|██████████████████▌                                                                | 2179/9741 [00:05<00:15, 479.39it/s] 23%|██████████████████▉                                                                | 2227/9741 [00:05<00:15, 478.51it/s] 23%|███████████████████▍                                                               | 2276/9741 [00:05<00:15, 479.40it/s] 24%|███████████████████▊                                                               | 2324/9741 [00:05<00:15, 478.26it/s] 24%|████████████████████▏                                                              | 2372/9741 [00:05<00:15, 478.43it/s] 25%|████████████████████▌                                                              | 2420/9741 [00:05<00:15, 478.24it/s] 25%|█████████████████████                                                              | 2468/9741 [00:05<00:15, 475.29it/s] 26%|█████████████████████▍                                                             | 2516/9741 [00:05<00:15, 475.51it/s] 26%|█████████████████████▊                                                             | 2564/9741 [00:05<00:15, 475.93it/s] 27%|██████████████████████▎                                                            | 2612/9741 [00:05<00:15, 474.99it/s] 27%|██████████████████████▋                                                            | 2660/9741 [00:06<00:15, 469.44it/s] 28%|███████████████████████                                                            | 2707/9741 [00:06<00:15, 467.18it/s] 28%|███████████████████████▍                                                           | 2755/9741 [00:06<00:14, 469.45it/s] 29%|███████████████████████▉                                                           | 2803/9741 [00:06<00:14, 470.51it/s] 29%|████████████████████████▎                                                          | 2851/9741 [00:06<00:14, 471.70it/s] 30%|████████████████████████▋                                                          | 2899/9741 [00:06<00:14, 470.19it/s] 30%|█████████████████████████                                                          | 2947/9741 [00:06<00:14, 471.48it/s] 31%|█████████████████████████▌                                                         | 2995/9741 [00:06<00:14, 472.75it/s] 31%|█████████████████████████▉                                                         | 3043/9741 [00:06<00:14, 472.76it/s] 32%|██████████████████████████▎                                                        | 3091/9741 [00:07<00:14, 471.70it/s] 32%|██████████████████████████▋                                                        | 3139/9741 [00:07<00:14, 468.88it/s] 33%|███████████████████████████▏                                                       | 3187/9741 [00:07<00:13, 469.62it/s] 33%|███████████████████████████▌                                                       | 3235/9741 [00:07<00:13, 470.17it/s] 34%|███████████████████████████▉                                                       | 3283/9741 [00:07<00:13, 468.99it/s] 34%|████████████████████████████▎                                                      | 3330/9741 [00:07<00:13, 469.07it/s] 35%|████████████████████████████▊                                                      | 3377/9741 [00:07<00:13, 467.12it/s] 35%|█████████████████████████████▏                                                     | 3424/9741 [00:07<00:13, 467.95it/s] 36%|█████████████████████████████▌                                                     | 3471/9741 [00:07<00:13, 465.72it/s] 36%|█████████████████████████████▉                                                     | 3518/9741 [00:07<00:13, 466.27it/s] 37%|██████████████████████████████▍                                                    | 3565/9741 [00:08<00:13, 466.55it/s] 37%|██████████████████████████████▊                                                    | 3612/9741 [00:08<00:13, 464.23it/s] 38%|███████████████████████████████▏                                                   | 3659/9741 [00:08<00:13, 464.61it/s] 38%|███████████████████████████████▌                                                   | 3706/9741 [00:08<00:13, 463.30it/s] 39%|███████████████████████████████▉                                                   | 3753/9741 [00:08<00:12, 463.31it/s] 39%|████████████████████████████████▍                                                  | 3800/9741 [00:08<00:12, 463.62it/s] 39%|████████████████████████████████▊                                                  | 3847/9741 [00:08<00:12, 461.63it/s] 40%|█████████████████████████████████▏                                                 | 3894/9741 [00:08<00:12, 461.72it/s] 40%|█████████████████████████████████▌                                                 | 3941/9741 [00:08<00:12, 462.24it/s] 41%|█████████████████████████████████▉                                                 | 3988/9741 [00:08<00:12, 462.76it/s] 41%|██████████████████████████████████▍                                                | 4035/9741 [00:09<00:12, 460.55it/s] 42%|██████████████████████████████████▊                                                | 4082/9741 [00:09<00:12, 461.48it/s] 42%|███████████████████████████████████▏                                               | 4129/9741 [00:09<00:12, 461.55it/s] 43%|███████████████████████████████████▌                                               | 4176/9741 [00:09<00:12, 462.12it/s] 43%|███████████████████████████████████▉                                               | 4223/9741 [00:09<00:11, 462.70it/s] 44%|████████████████████████████████████▍                                              | 4270/9741 [00:09<00:11, 461.61it/s] 44%|████████████████████████████████████▊                                              | 4317/9741 [00:09<00:11, 463.04it/s] 45%|█████████████████████████████████████▏                                             | 4364/9741 [00:09<00:11, 463.89it/s] 45%|█████████████████████████████████████▌                                             | 4411/9741 [00:09<00:11, 464.11it/s] 46%|█████████████████████████████████████▉                                             | 4458/9741 [00:09<00:11, 463.95it/s] 46%|██████████████████████████████████████▍                                            | 4505/9741 [00:10<00:12, 433.18it/s] 47%|██████████████████████████████████████▊                                            | 4552/9741 [00:10<00:11, 442.36it/s] 47%|███████████████████████████████████████▏                                           | 4599/9741 [00:10<00:11, 449.38it/s] 48%|███████████████████████████████████████▌                                           | 4646/9741 [00:10<00:11, 454.26it/s] 48%|███████████████████████████████████████▉                                           | 4693/9741 [00:10<00:11, 457.62it/s] 49%|████████████████████████████████████████▍                                          | 4739/9741 [00:10<00:14, 354.29it/s] 49%|████████████████████████████████████████▊                                          | 4786/9741 [00:10<00:12, 381.48it/s] 50%|█████████████████████████████████████████▏                                         | 4833/9741 [00:10<00:12, 403.07it/s] 50%|█████████████████████████████████████████▌                                         | 4880/9741 [00:10<00:11, 419.65it/s] 51%|█████████████████████████████████████████▉                                         | 4926/9741 [00:11<00:11, 430.39it/s] 51%|██████████████████████████████████████████▎                                        | 4973/9741 [00:11<00:10, 440.24it/s] 52%|██████████████████████████████████████████▊                                        | 5020/9741 [00:11<00:10, 446.75it/s] 52%|███████████████████████████████████████████▏                                       | 5067/9741 [00:11<00:10, 451.98it/s] 52%|███████████████████████████████████████████▌                                       | 5114/9741 [00:11<00:10, 455.38it/s] 53%|███████████████████████████████████████████▉                                       | 5160/9741 [00:11<00:10, 455.69it/s] 53%|████████████████████████████████████████████▎                                      | 5207/9741 [00:11<00:09, 457.92it/s] 54%|████████████████████████████████████████████▊                                      | 5254/9741 [00:11<00:09, 458.88it/s] 54%|█████████████████████████████████████████████▏                                     | 5301/9741 [00:11<00:09, 460.13it/s] 55%|█████████████████████████████████████████████▌                                     | 5348/9741 [00:12<00:09, 460.77it/s] 55%|█████████████████████████████████████████████▉                                     | 5395/9741 [00:12<00:09, 459.33it/s] 56%|██████████████████████████████████████████████▎                                    | 5441/9741 [00:12<00:09, 454.33it/s] 56%|██████████████████████████████████████████████▊                                    | 5488/9741 [00:12<00:09, 456.13it/s] 57%|███████████████████████████████████████████████▏                                   | 5535/9741 [00:12<00:09, 457.67it/s] 57%|███████████████████████████████████████████████▌                                   | 5581/9741 [00:12<00:09, 458.15it/s] 58%|███████████████████████████████████████████████▉                                   | 5627/9741 [00:12<00:09, 455.99it/s] 58%|████████████████████████████████████████████████▎                                  | 5673/9741 [00:12<00:08, 456.46it/s] 59%|████████████████████████████████████████████████▋                                  | 5719/9741 [00:12<00:08, 456.39it/s] 59%|█████████████████████████████████████████████████                                  | 5765/9741 [00:12<00:08, 454.00it/s] 60%|█████████████████████████████████████████████████▌                                 | 5811/9741 [00:13<00:08, 453.27it/s] 60%|█████████████████████████████████████████████████▉                                 | 5857/9741 [00:13<00:08, 451.70it/s] 61%|██████████████████████████████████████████████████▎                                | 5903/9741 [00:13<00:08, 453.51it/s] 61%|██████████████████████████████████████████████████▋                                | 5949/9741 [00:13<00:08, 454.81it/s] 62%|███████████████████████████████████████████████████                                | 5995/9741 [00:13<00:08, 455.37it/s] 62%|███████████████████████████████████████████████████▍                               | 6041/9741 [00:13<00:08, 456.19it/s] 62%|███████████████████████████████████████████████████▊                               | 6087/9741 [00:13<00:08, 454.65it/s] 63%|████████████████████████████████████████████████████▎                              | 6133/9741 [00:13<00:07, 455.81it/s] 63%|████████████████████████████████████████████████████▋                              | 6179/9741 [00:13<00:07, 456.63it/s] 64%|█████████████████████████████████████████████████████                              | 6225/9741 [00:13<00:07, 456.86it/s] 64%|█████████████████████████████████████████████████████▍                             | 6271/9741 [00:14<00:07, 456.75it/s] 65%|█████████████████████████████████████████████████████▊                             | 6317/9741 [00:14<00:07, 453.95it/s] 65%|██████████████████████████████████████████████████████▏                            | 6363/9741 [00:14<00:07, 453.10it/s] 66%|██████████████████████████████████████████████████████▌                            | 6409/9741 [00:14<00:07, 454.88it/s] 66%|███████████████████████████████████████████████████████                            | 6455/9741 [00:14<00:07, 450.71it/s] 67%|███████████████████████████████████████████████████████▍                           | 6501/9741 [00:14<00:07, 449.20it/s] 67%|███████████████████████████████████████████████████████▊                           | 6547/9741 [00:14<00:07, 450.78it/s] 68%|████████████████████████████████████████████████████████▏                          | 6593/9741 [00:14<00:06, 452.46it/s] 68%|████████████████████████████████████████████████████████▌                          | 6639/9741 [00:14<00:06, 453.38it/s] 69%|████████████████████████████████████████████████████████▉                          | 6686/9741 [00:14<00:06, 455.36it/s] 69%|█████████████████████████████████████████████████████████▎                         | 6732/9741 [00:15<00:06, 455.66it/s] 70%|█████████████████████████████████████████████████████████▊                         | 6779/9741 [00:15<00:06, 457.46it/s] 70%|██████████████████████████████████████████████████████████▏                        | 6825/9741 [00:15<00:06, 455.32it/s] 71%|██████████████████████████████████████████████████████████▌                        | 6871/9741 [00:15<00:06, 453.97it/s] 71%|██████████████████████████████████████████████████████████▉                        | 6917/9741 [00:15<00:06, 452.28it/s] 71%|███████████████████████████████████████████████████████████▎                       | 6963/9741 [00:15<00:06, 449.53it/s] 72%|███████████████████████████████████████████████████████████▋                       | 7009/9741 [00:15<00:06, 449.75it/s] 72%|████████████████████████████████████████████████████████████                       | 7055/9741 [00:15<00:05, 450.10it/s] 73%|████████████████████████████████████████████████████████████▌                      | 7101/9741 [00:15<00:05, 450.43it/s] 73%|████████████████████████████████████████████████████████████▉                      | 7147/9741 [00:15<00:05, 450.30it/s] 74%|█████████████████████████████████████████████████████████████▎                     | 7193/9741 [00:16<00:05, 448.09it/s] 74%|█████████████████████████████████████████████████████████████▋                     | 7239/9741 [00:16<00:05, 450.69it/s] 75%|██████████████████████████████████████████████████████████████                     | 7285/9741 [00:16<00:05, 453.08it/s] 75%|██████████████████████████████████████████████████████████████▍                    | 7332/9741 [00:16<00:05, 455.62it/s] 76%|██████████████████████████████████████████████████████████████▊                    | 7379/9741 [00:16<00:05, 458.07it/s] 76%|███████████████████████████████████████████████████████████████▎                   | 7425/9741 [00:16<00:05, 421.16it/s] 77%|███████████████████████████████████████████████████████████████▋                   | 7471/9741 [00:16<00:05, 431.17it/s] 77%|████████████████████████████████████████████████████████████████                   | 7517/9741 [00:16<00:05, 438.79it/s] 78%|████████████████████████████████████████████████████████████████▍                  | 7564/9741 [00:16<00:04, 445.14it/s] 78%|████████████████████████████████████████████████████████████████▊                  | 7611/9741 [00:17<00:04, 449.82it/s] 79%|█████████████████████████████████████████████████████████████████▏                 | 7657/9741 [00:17<00:04, 451.27it/s] 79%|█████████████████████████████████████████████████████████████████▋                 | 7704/9741 [00:17<00:04, 454.53it/s] 80%|██████████████████████████████████████████████████████████████████                 | 7751/9741 [00:17<00:04, 456.60it/s] 80%|██████████████████████████████████████████████████████████████████▍                | 7798/9741 [00:17<00:04, 457.64it/s] 81%|██████████████████████████████████████████████████████████████████▊                | 7845/9741 [00:17<00:04, 458.76it/s] 81%|███████████████████████████████████████████████████████████████████▏               | 7891/9741 [00:17<00:04, 457.50it/s] 81%|███████████████████████████████████████████████████████████████████▋               | 7938/9741 [00:17<00:03, 458.81it/s] 82%|████████████████████████████████████████████████████████████████████               | 7985/9741 [00:17<00:03, 459.67it/s] 82%|████████████████████████████████████████████████████████████████████▍              | 8032/9741 [00:17<00:03, 460.18it/s] 83%|████████████████████████████████████████████████████████████████████▊              | 8079/9741 [00:18<00:03, 460.57it/s] 83%|█████████████████████████████████████████████████████████████████████▏             | 8126/9741 [00:18<00:03, 458.75it/s] 84%|█████████████████████████████████████████████████████████████████████▋             | 8173/9741 [00:18<00:03, 459.39it/s] 84%|██████████████████████████████████████████████████████████████████████             | 8220/9741 [00:18<00:03, 460.04it/s] 85%|██████████████████████████████████████████████████████████████████████▍            | 8267/9741 [00:18<00:03, 458.84it/s] 85%|██████████████████████████████████████████████████████████████████████▊            | 8314/9741 [00:18<00:03, 460.31it/s] 86%|███████████████████████████████████████████████████████████████████████▏           | 8361/9741 [00:18<00:03, 459.35it/s] 86%|███████████████████████████████████████████████████████████████████████▋           | 8408/9741 [00:18<00:02, 460.73it/s] 87%|████████████████████████████████████████████████████████████████████████           | 8455/9741 [00:18<00:02, 462.06it/s] 87%|████████████████████████████████████████████████████████████████████████▍          | 8502/9741 [00:18<00:02, 462.95it/s] 88%|████████████████████████████████████████████████████████████████████████▊          | 8549/9741 [00:19<00:02, 461.07it/s] 88%|█████████████████████████████████████████████████████████████████████████▏         | 8596/9741 [00:19<00:02, 456.53it/s] 89%|█████████████████████████████████████████████████████████████████████████▋         | 8643/9741 [00:19<00:02, 458.90it/s] 89%|██████████████████████████████████████████████████████████████████████████         | 8690/9741 [00:19<00:02, 460.82it/s] 90%|██████████████████████████████████████████████████████████████████████████▍        | 8737/9741 [00:19<00:02, 455.98it/s] 90%|██████████████████████████████████████████████████████████████████████████▊        | 8783/9741 [00:19<00:02, 454.93it/s] 91%|███████████████████████████████████████████████████████████████████████████▏       | 8830/9741 [00:19<00:01, 456.89it/s] 91%|███████████████████████████████████████████████████████████████████████████▋       | 8877/9741 [00:19<00:01, 458.49it/s] 92%|████████████████████████████████████████████████████████████████████████████       | 8924/9741 [00:19<00:01, 459.10it/s] 92%|████████████████████████████████████████████████████████████████████████████▍      | 8971/9741 [00:19<00:01, 460.05it/s] 93%|████████████████████████████████████████████████████████████████████████████▊      | 9018/9741 [00:20<00:01, 457.58it/s] 93%|█████████████████████████████████████████████████████████████████████████████▏     | 9065/9741 [00:20<00:01, 459.03it/s] 94%|█████████████████████████████████████████████████████████████████████████████▋     | 9112/9741 [00:20<00:01, 460.11it/s] 94%|██████████████████████████████████████████████████████████████████████████████     | 9159/9741 [00:20<00:01, 460.98it/s] 95%|██████████████████████████████████████████████████████████████████████████████▍    | 9206/9741 [00:20<00:01, 461.76it/s] 95%|██████████████████████████████████████████████████████████████████████████████▊    | 9253/9741 [00:20<00:01, 460.50it/s] 95%|███████████████████████████████████████████████████████████████████████████████▏   | 9300/9741 [00:20<00:00, 460.83it/s] 96%|███████████████████████████████████████████████████████████████████████████████▋   | 9347/9741 [00:20<00:00, 461.45it/s] 96%|████████████████████████████████████████████████████████████████████████████████   | 9394/9741 [00:20<00:00, 461.86it/s] 97%|████████████████████████████████████████████████████████████████████████████████▍  | 9441/9741 [00:20<00:00, 462.41it/s] 97%|████████████████████████████████████████████████████████████████████████████████▊  | 9488/9741 [00:21<00:00, 459.79it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▏ | 9534/9741 [00:21<00:00, 459.72it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▋ | 9580/9741 [00:21<00:00, 459.66it/s] 99%|██████████████████████████████████████████████████████████████████████████████████ | 9626/9741 [00:21<00:00, 459.67it/s] 99%|██████████████████████████████████████████████████████████████████████████████████▍| 9673/9741 [00:21<00:00, 459.90it/s]100%|██████████████████████████████████████████████████████████████████████████████████▊| 9719/9741 [00:21<00:00, 457.29it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:21<00:00, 449.90it/s]
Load End
Num instances: 1000
[2023-08-22 23:27:24,171] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 23:27:26,731] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 23:27:26,732] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 23:27:26,732] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 23:27:26,732] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 23:27:26,732] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 23:27:26,732] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f31e4cdca60>
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f31e4cdc940>
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 23:27:26,733] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 23:27:26,734] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 23:27:26,734] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 23:27:26,734] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 23:27:26,734] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 23:27:26,734] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 23:27:26,734] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 23:27:26,734] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 23:27:26,734] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 23:27:26,734] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4284169673919678 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: Let x = the total number of candies Corey has.
x + 8 = the total number of candies Tapanga has.
The equation for the total number of candies is x + (x + 8) = 66
Combining like terms, we get 2x + 8 = 66
Subtracting 8 from both sides, we get 2x = 58
Dividing both sides by 2, we get x = <<29=29>>29, so Corey has 29 candies.
So the final answer is 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: At 5 cents a minute, calling his father cost Freddy 5* 45 = <<5*45=225>>225 cents.
At 25 cents a minute, calling his brother cost Freddy 25 * 31 = <<25*31=775>>775 cents.
Adding the cost of calling his father and brother, we find that Freddy paid a total of 225 + 775 = <<225+775=1000>>1000 cents.
Since each dollar has 100 cents, Freddy paid 1000 / 100 = <<1000/100=10>>10 dollars
So the final answer is 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 8 hours * 3 = <<8*3=24>>24 hours
5.5 * 2 = <<5.5*2=11>>11 hours
24 + 11 = <<24+11=35>>35 hours
35/7 = <<35/7=5>>5 hours
Lawrence would work 5 hours each of the 7 days in a week.
So the final answer is 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: We look first for the total number of books that were sold: 60 + 10 + 20 + 44 + 66 = <<60+10+20+44+66=200>>200 books.
So the total number of books that were not sold is: 800 – 200 = <<800-200=600>>600 books.
So the final answer is 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: Michael sold 2 large birdhouses for $22 each, so he made 2*$22= $<<2*22=44>>44 from large birdhouse sales.
Michael also sold 2 medium birdhouses for $16 each, so he made 2*$16= $<<2*16=32>>32 from medium birdhouse sales.
Michael sold 3 small birdhouses for $7 each, so he made 3*7=$<<3*7=21>>21 from small birdhouse sales.
Since Michael made $44 from large birdhouse sales, $32 from medium birdhouse sales, and $21 for small birdhouse sales, he made $44+$32+$21= $<<44+32+21=97>>97 total this week.
So the final answer is 97

Input: Nalani had two female dogs that were expecting and after a month gave birth to 10 puppies each. She then sold 3/4 of the puppies after they came of age, each at $200. Calculate the total amount of money she received from the sale of the puppies.
Output: If the two expectant dogs gave birth to 10 puppies each, the total number of puppies Nalani had is 10+10= <<10+10=20>>20
When they came of age, Nalani sold 3/4 of the dogs, a total of 3/4*20 = <<3/4*20=15>>15 dogs.
If each dog sold for $200, Nalani received 15*200 = $<<15*200=3000>>3000 from the sale of the dogs.
So the final answer is 3000

Input: Boris has 24 books and he donates a fourth of his books to the library. Cameron has 30 books and he donates a third of his books to the library. After donating their books, how many books in total do Boris and Cameron have together?
Output: Boris donates 24 / 4 = <<24/4=6>>6 books
Then Boris has a total of 24 - 6 = <<24-6=18>>18 books
Cameron donates 30 / 3 = <<30/3=10>>10 books
Then Cameron has a total of 30 - 10 = <<30-10=20>>20 books
Altogether, Boris and Cameron have 18 + 20 = <<18+20=38>>38 books
So the final answer is 38

Input: There are 3 boxes of cereal. One box holds 14 ounces of cereal. Another box holds half the amount of the first box and 5 ounces less than the third box. How much cereal is there in all 3 cereal boxes?
Output: First = <<14=14>>14 oz
Second = (1/2) * 14 = <<(1/2)*14=7>>7 oz
Third = 7 + 5 = <<7+5=12>>12 oz
14 + 7 + 12 = <<14+7+12=33>>33 oz
There are 33 ounces of cereal in those 3 boxes.
So the final answer is 33

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o8-tgsm8k-s20-rTrue
Loading extension module utils...
Time to load utils op: 0.5047738552093506 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:34<28:12, 34.54s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:08<27:29, 34.36s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [01:42<26:34, 33.93s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [02:15<25:53, 33.77s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [02:49<25:20, 33.78s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [03:23<24:46, 33.77s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [03:56<24:06, 33.65s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [04:30<23:36, 33.73s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [05:04<22:59, 33.64s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [05:37<22:23, 33.59s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [06:10<21:46, 33.49s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [06:45<21:21, 33.73s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [07:18<20:46, 33.70s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [07:52<20:10, 33.61s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [08:25<19:32, 33.50s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [08:58<18:58, 33.48s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [09:32<18:28, 33.58s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [10:05<17:51, 33.47s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [10:39<17:22, 33.62s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [11:13<16:51, 33.71s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [11:47<16:16, 33.67s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [12:21<15:43, 33.71s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [12:54<15:09, 33.67s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [13:28<14:34, 33.64s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [14:01<14:00, 33.63s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [14:35<13:29, 33.73s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [15:09<12:55, 33.73s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [15:43<12:20, 33.67s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [16:16<11:46, 33.63s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [16:50<11:12, 33.63s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [17:23<10:38, 33.62s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [17:57<10:03, 33.55s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [18:30<09:29, 33.53s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [19:04<08:57, 33.60s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [19:38<08:25, 33.70s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [20:12<07:52, 33.77s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [20:46<07:18, 33.76s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [21:19<06:45, 33.77s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [21:53<06:10, 33.67s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [22:26<05:36, 33.68s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [23:01<05:04, 33.81s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [23:34<04:30, 33.81s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [24:08<03:56, 33.76s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [24:42<03:22, 33.71s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [25:16<02:49, 33.83s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [25:49<02:15, 33.79s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [26:23<01:41, 33.69s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [26:56<01:07, 33.58s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [27:29<00:33, 33.50s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [28:03<00:00, 33.47s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [28:03<00:00, 33.67s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.0799} | avg. gen lenth: 447.128
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o9-tgsm8k-s20-rTrue --seed 20 --max-prompt-length 2048 --rationales --num-out-domain 9
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 23:55:58,838] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o9-tgsm8k-s20-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 9
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o9-tgsm8k-s20-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  0%|▎                                                                                    | 29/9741 [00:00<00:33, 289.80it/s]  1%|▌                                                                                    | 59/9741 [00:00<00:33, 293.15it/s]  1%|▊                                                                                    | 89/9741 [00:00<00:32, 293.17it/s]  1%|█                                                                                   | 119/9741 [00:00<00:32, 293.48it/s]  2%|█▎                                                                                  | 149/9741 [00:00<00:32, 293.06it/s]  2%|█▌                                                                                  | 179/9741 [00:00<00:32, 292.14it/s]  2%|█▊                                                                                  | 209/9741 [00:00<00:33, 288.32it/s]  2%|██                                                                                  | 239/9741 [00:00<00:32, 290.35it/s]  3%|██▎                                                                                 | 269/9741 [00:00<00:32, 291.26it/s]  3%|██▌                                                                                 | 299/9741 [00:01<00:32, 291.97it/s]  3%|██▊                                                                                 | 329/9741 [00:01<00:31, 294.29it/s]  4%|███▏                                                                                | 373/9741 [00:01<00:27, 337.21it/s]  4%|███▌                                                                                | 416/9741 [00:01<00:25, 364.59it/s]  5%|███▉                                                                                | 460/9741 [00:01<00:24, 386.27it/s]  5%|████▎                                                                               | 504/9741 [00:01<00:22, 402.12it/s]  6%|████▋                                                                               | 548/9741 [00:01<00:22, 411.75it/s]  6%|█████                                                                               | 591/9741 [00:01<00:21, 416.26it/s]  6%|█████▍                                                                              | 633/9741 [00:01<00:21, 417.25it/s]  7%|█████▊                                                                              | 677/9741 [00:01<00:21, 421.53it/s]  7%|██████▏                                                                             | 721/9741 [00:02<00:21, 424.80it/s]  8%|██████▌                                                                             | 765/9741 [00:02<00:21, 426.40it/s]  8%|██████▉                                                                             | 809/9741 [00:02<00:20, 427.65it/s]  9%|███████▎                                                                            | 852/9741 [00:02<00:20, 427.02it/s]  9%|███████▋                                                                            | 895/9741 [00:02<00:20, 426.87it/s] 10%|████████                                                                            | 938/9741 [00:02<00:20, 427.77it/s] 10%|████████▍                                                                           | 981/9741 [00:02<00:20, 426.80it/s] 11%|████████▋                                                                          | 1025/9741 [00:02<00:20, 428.17it/s] 11%|█████████                                                                          | 1069/9741 [00:02<00:20, 429.07it/s] 11%|█████████▍                                                                         | 1112/9741 [00:02<00:20, 425.35it/s] 12%|█████████▊                                                                         | 1155/9741 [00:03<00:20, 421.65it/s] 12%|██████████▏                                                                        | 1198/9741 [00:03<00:20, 424.00it/s] 13%|██████████▌                                                                        | 1241/9741 [00:03<00:19, 425.20it/s] 13%|██████████▉                                                                        | 1284/9741 [00:03<00:19, 425.66it/s] 14%|███████████▎                                                                       | 1327/9741 [00:03<00:19, 423.79it/s] 14%|███████████▋                                                                       | 1371/9741 [00:03<00:19, 425.83it/s] 15%|████████████                                                                       | 1415/9741 [00:03<00:19, 427.58it/s] 15%|████████████▍                                                                      | 1458/9741 [00:03<00:19, 428.11it/s] 15%|████████████▊                                                                      | 1501/9741 [00:03<00:19, 428.34it/s] 16%|█████████████▏                                                                     | 1544/9741 [00:03<00:19, 427.09it/s] 16%|█████████████▌                                                                     | 1587/9741 [00:04<00:19, 427.40it/s] 17%|█████████████▉                                                                     | 1630/9741 [00:04<00:18, 427.94it/s] 17%|██████████████▎                                                                    | 1674/9741 [00:04<00:18, 428.82it/s] 18%|██████████████▋                                                                    | 1717/9741 [00:04<00:18, 427.41it/s] 18%|██████████████▉                                                                    | 1760/9741 [00:04<00:19, 402.99it/s] 19%|███████████████▎                                                                   | 1803/9741 [00:04<00:19, 410.22it/s] 19%|███████████████▋                                                                   | 1845/9741 [00:04<00:19, 400.46it/s] 19%|████████████████                                                                   | 1888/9741 [00:04<00:19, 408.86it/s] 20%|████████████████▍                                                                  | 1931/9741 [00:04<00:18, 414.79it/s] 20%|████████████████▊                                                                  | 1975/9741 [00:05<00:18, 419.32it/s] 21%|█████████████████▏                                                                 | 2018/9741 [00:05<00:18, 420.71it/s] 21%|█████████████████▌                                                                 | 2061/9741 [00:05<00:18, 423.07it/s] 22%|█████████████████▉                                                                 | 2104/9741 [00:05<00:17, 424.35it/s] 22%|██████████████████▎                                                                | 2147/9741 [00:05<00:17, 425.34it/s] 22%|██████████████████▋                                                                | 2190/9741 [00:05<00:17, 426.30it/s] 23%|███████████████████                                                                | 2233/9741 [00:05<00:17, 424.66it/s] 23%|███████████████████▍                                                               | 2276/9741 [00:05<00:17, 425.56it/s] 24%|███████████████████▊                                                               | 2319/9741 [00:05<00:17, 425.46it/s] 24%|████████████████████▏                                                              | 2362/9741 [00:05<00:17, 425.16it/s] 25%|████████████████████▍                                                              | 2405/9741 [00:06<00:17, 417.98it/s] 25%|████████████████████▊                                                              | 2447/9741 [00:06<00:17, 416.83it/s] 26%|█████████████████████▏                                                             | 2490/9741 [00:06<00:17, 418.44it/s] 26%|█████████████████████▌                                                             | 2533/9741 [00:06<00:17, 419.64it/s] 26%|█████████████████████▉                                                             | 2575/9741 [00:06<00:17, 419.74it/s] 27%|██████████████████████▎                                                            | 2617/9741 [00:06<00:16, 419.79it/s] 27%|██████████████████████▋                                                            | 2660/9741 [00:06<00:16, 419.91it/s] 28%|███████████████████████                                                            | 2702/9741 [00:06<00:16, 418.00it/s] 28%|███████████████████████▍                                                           | 2745/9741 [00:06<00:16, 418.70it/s] 29%|███████████████████████▊                                                           | 2788/9741 [00:06<00:16, 419.14it/s] 29%|████████████████████████                                                           | 2831/9741 [00:07<00:16, 419.97it/s] 30%|████████████████████████▍                                                          | 2874/9741 [00:07<00:16, 420.63it/s] 30%|████████████████████████▊                                                          | 2917/9741 [00:07<00:16, 418.61it/s] 30%|█████████████████████████▏                                                         | 2959/9741 [00:07<00:16, 418.08it/s] 31%|█████████████████████████▌                                                         | 3001/9741 [00:07<00:16, 418.62it/s] 31%|█████████████████████████▉                                                         | 3043/9741 [00:07<00:15, 418.72it/s] 32%|██████████████████████████▎                                                        | 3085/9741 [00:07<00:15, 418.53it/s] 32%|██████████████████████████▋                                                        | 3127/9741 [00:07<00:16, 410.72it/s] 33%|███████████████████████████                                                        | 3169/9741 [00:07<00:15, 412.78it/s] 33%|███████████████████████████▎                                                       | 3211/9741 [00:07<00:15, 414.74it/s] 33%|███████████████████████████▋                                                       | 3253/9741 [00:08<00:15, 416.06it/s] 34%|████████████████████████████                                                       | 3295/9741 [00:08<00:15, 415.72it/s] 34%|████████████████████████████▍                                                      | 3337/9741 [00:08<00:15, 415.01it/s] 35%|████████████████████████████▊                                                      | 3379/9741 [00:08<00:15, 413.03it/s] 35%|█████████████████████████████▏                                                     | 3421/9741 [00:08<00:15, 414.31it/s] 36%|█████████████████████████████▌                                                     | 3463/9741 [00:08<00:15, 415.01it/s] 36%|█████████████████████████████▊                                                     | 3505/9741 [00:08<00:15, 415.05it/s] 36%|██████████████████████████████▏                                                    | 3547/9741 [00:08<00:14, 415.68it/s] 37%|██████████████████████████████▌                                                    | 3589/9741 [00:08<00:14, 413.64it/s] 37%|██████████████████████████████▉                                                    | 3631/9741 [00:08<00:14, 414.31it/s] 38%|███████████████████████████████▎                                                   | 3673/9741 [00:09<00:14, 414.04it/s] 38%|███████████████████████████████▋                                                   | 3715/9741 [00:09<00:14, 413.91it/s] 39%|████████████████████████████████                                                   | 3757/9741 [00:09<00:14, 413.78it/s] 39%|████████████████████████████████▎                                                  | 3799/9741 [00:09<00:14, 413.35it/s] 39%|████████████████████████████████▋                                                  | 3841/9741 [00:09<00:14, 410.83it/s] 40%|█████████████████████████████████                                                  | 3883/9741 [00:09<00:14, 411.14it/s] 40%|█████████████████████████████████▍                                                 | 3925/9741 [00:09<00:14, 411.40it/s] 41%|█████████████████████████████████▊                                                 | 3967/9741 [00:09<00:14, 411.18it/s] 41%|██████████████████████████████████▏                                                | 4009/9741 [00:09<00:13, 411.07it/s] 42%|██████████████████████████████████▌                                                | 4051/9741 [00:09<00:13, 408.70it/s] 42%|██████████████████████████████████▉                                                | 4093/9741 [00:10<00:13, 410.16it/s] 42%|███████████████████████████████████▏                                               | 4135/9741 [00:10<00:13, 410.84it/s] 43%|███████████████████████████████████▌                                               | 4177/9741 [00:10<00:13, 410.78it/s] 43%|███████████████████████████████████▉                                               | 4219/9741 [00:10<00:13, 410.20it/s] 44%|████████████████████████████████████▎                                              | 4261/9741 [00:10<00:13, 409.00it/s] 44%|████████████████████████████████████▋                                              | 4302/9741 [00:10<00:13, 407.80it/s] 45%|█████████████████████████████████████                                              | 4344/9741 [00:10<00:13, 409.67it/s] 45%|█████████████████████████████████████▎                                             | 4386/9741 [00:10<00:13, 411.34it/s] 45%|█████████████████████████████████████▋                                             | 4428/9741 [00:10<00:12, 412.26it/s] 46%|██████████████████████████████████████                                             | 4470/9741 [00:11<00:12, 412.84it/s] 46%|██████████████████████████████████████▍                                            | 4512/9741 [00:11<00:13, 381.14it/s] 47%|██████████████████████████████████████▊                                            | 4554/9741 [00:11<00:13, 390.40it/s] 47%|███████████████████████████████████████▏                                           | 4596/9741 [00:11<00:12, 397.51it/s] 48%|███████████████████████████████████████▌                                           | 4638/9741 [00:11<00:12, 402.87it/s] 48%|███████████████████████████████████████▉                                           | 4680/9741 [00:11<00:12, 406.09it/s] 48%|████████████████████████████████████████▏                                          | 4721/9741 [00:11<00:15, 316.72it/s] 49%|████████████████████████████████████████▌                                          | 4763/9741 [00:11<00:14, 341.12it/s] 49%|████████████████████████████████████████▉                                          | 4805/9741 [00:11<00:13, 360.67it/s] 50%|█████████████████████████████████████████▎                                         | 4847/9741 [00:12<00:13, 375.99it/s] 50%|█████████████████████████████████████████▋                                         | 4887/9741 [00:12<00:12, 381.68it/s] 51%|█████████████████████████████████████████▉                                         | 4928/9741 [00:12<00:12, 388.61it/s] 51%|██████████████████████████████████████████▎                                        | 4970/9741 [00:12<00:12, 395.64it/s] 51%|██████████████████████████████████████████▋                                        | 5012/9741 [00:12<00:11, 400.06it/s] 52%|███████████████████████████████████████████                                        | 5053/9741 [00:12<00:11, 402.81it/s] 52%|███████████████████████████████████████████▍                                       | 5094/9741 [00:12<00:11, 404.81it/s] 53%|███████████████████████████████████████████▊                                       | 5135/9741 [00:12<00:11, 406.16it/s] 53%|████████████████████████████████████████████                                       | 5176/9741 [00:12<00:11, 405.49it/s] 54%|████████████████████████████████████████████▍                                      | 5218/9741 [00:12<00:11, 407.09it/s] 54%|████████████████████████████████████████████▊                                      | 5259/9741 [00:13<00:11, 407.43it/s] 54%|█████████████████████████████████████████████▏                                     | 5300/9741 [00:13<00:10, 407.97it/s] 55%|█████████████████████████████████████████████▌                                     | 5341/9741 [00:13<00:10, 408.24it/s] 55%|█████████████████████████████████████████████▊                                     | 5382/9741 [00:13<00:10, 407.22it/s] 56%|██████████████████████████████████████████████▏                                    | 5423/9741 [00:13<00:10, 407.96it/s] 56%|██████████████████████████████████████████████▌                                    | 5465/9741 [00:13<00:10, 408.74it/s] 57%|██████████████████████████████████████████████▉                                    | 5507/9741 [00:13<00:10, 409.19it/s] 57%|███████████████████████████████████████████████▎                                   | 5549/9741 [00:13<00:10, 409.98it/s] 57%|███████████████████████████████████████████████▋                                   | 5591/9741 [00:13<00:10, 409.92it/s] 58%|███████████████████████████████████████████████▉                                   | 5632/9741 [00:13<00:10, 407.90it/s] 58%|████████████████████████████████████████████████▎                                  | 5674/9741 [00:14<00:09, 408.64it/s] 59%|████████████████████████████████████████████████▋                                  | 5716/9741 [00:14<00:09, 409.27it/s] 59%|█████████████████████████████████████████████████                                  | 5758/9741 [00:14<00:09, 409.91it/s] 60%|█████████████████████████████████████████████████▍                                 | 5799/9741 [00:14<00:09, 404.84it/s] 60%|█████████████████████████████████████████████████▊                                 | 5840/9741 [00:14<00:09, 402.58it/s] 60%|██████████████████████████████████████████████████                                 | 5882/9741 [00:14<00:09, 405.05it/s] 61%|██████████████████████████████████████████████████▍                                | 5923/9741 [00:14<00:09, 405.96it/s] 61%|██████████████████████████████████████████████████▊                                | 5964/9741 [00:14<00:09, 406.42it/s] 62%|███████████████████████████████████████████████████▏                               | 6005/9741 [00:14<00:09, 406.58it/s] 62%|███████████████████████████████████████████████████▌                               | 6046/9741 [00:14<00:09, 407.23it/s] 62%|███████████████████████████████████████████████████▊                               | 6087/9741 [00:15<00:09, 405.72it/s] 63%|████████████████████████████████████████████████████▏                              | 6128/9741 [00:15<00:08, 406.80it/s] 63%|████████████████████████████████████████████████████▌                              | 6170/9741 [00:15<00:08, 407.77it/s] 64%|████████████████████████████████████████████████████▉                              | 6212/9741 [00:15<00:08, 408.62it/s] 64%|█████████████████████████████████████████████████████▎                             | 6253/9741 [00:15<00:08, 408.63it/s] 65%|█████████████████████████████████████████████████████▋                             | 6294/9741 [00:15<00:08, 407.08it/s] 65%|█████████████████████████████████████████████████████▉                             | 6335/9741 [00:15<00:08, 407.65it/s] 65%|██████████████████████████████████████████████████████▎                            | 6377/9741 [00:15<00:08, 408.54it/s] 66%|██████████████████████████████████████████████████████▋                            | 6419/9741 [00:15<00:08, 409.43it/s] 66%|███████████████████████████████████████████████████████                            | 6461/9741 [00:15<00:08, 409.80it/s] 67%|███████████████████████████████████████████████████████▍                           | 6502/9741 [00:16<00:07, 407.65it/s] 67%|███████████████████████████████████████████████████████▊                           | 6543/9741 [00:16<00:07, 407.95it/s] 68%|████████████████████████████████████████████████████████                           | 6584/9741 [00:16<00:07, 407.75it/s] 68%|████████████████████████████████████████████████████████▍                          | 6625/9741 [00:16<00:07, 407.66it/s] 68%|████████████████████████████████████████████████████████▊                          | 6666/9741 [00:16<00:07, 407.25it/s] 69%|█████████████████████████████████████████████████████████▏                         | 6707/9741 [00:16<00:07, 406.59it/s] 69%|█████████████████████████████████████████████████████████▍                         | 6748/9741 [00:16<00:07, 405.92it/s] 70%|█████████████████████████████████████████████████████████▊                         | 6790/9741 [00:16<00:07, 407.45it/s] 70%|██████████████████████████████████████████████████████████▏                        | 6832/9741 [00:16<00:07, 408.35it/s] 71%|██████████████████████████████████████████████████████████▌                        | 6874/9741 [00:17<00:07, 408.90it/s] 71%|██████████████████████████████████████████████████████████▉                        | 6915/9741 [00:17<00:06, 409.10it/s] 71%|███████████████████████████████████████████████████████████▎                       | 6956/9741 [00:17<00:06, 407.63it/s] 72%|███████████████████████████████████████████████████████████▌                       | 6997/9741 [00:17<00:06, 408.15it/s] 72%|███████████████████████████████████████████████████████████▉                       | 7039/9741 [00:17<00:06, 408.77it/s] 73%|████████████████████████████████████████████████████████████▎                      | 7081/9741 [00:17<00:06, 409.43it/s] 73%|████████████████████████████████████████████████████████████▋                      | 7123/9741 [00:17<00:06, 410.01it/s] 74%|█████████████████████████████████████████████████████████████                      | 7165/9741 [00:17<00:06, 410.12it/s] 74%|█████████████████████████████████████████████████████████████▍                     | 7207/9741 [00:17<00:06, 408.01it/s] 74%|█████████████████████████████████████████████████████████████▊                     | 7249/9741 [00:17<00:06, 408.85it/s] 75%|██████████████████████████████████████████████████████████████                     | 7291/9741 [00:18<00:05, 409.36it/s] 75%|██████████████████████████████████████████████████████████████▍                    | 7333/9741 [00:18<00:05, 409.80it/s] 76%|██████████████████████████████████████████████████████████████▊                    | 7375/9741 [00:18<00:05, 410.11it/s] 76%|███████████████████████████████████████████████████████████████▏                   | 7417/9741 [00:18<00:06, 379.40it/s] 77%|███████████████████████████████████████████████████████████████▌                   | 7458/9741 [00:18<00:05, 387.53it/s] 77%|███████████████████████████████████████████████████████████████▉                   | 7499/9741 [00:18<00:05, 393.25it/s] 77%|████████████████████████████████████████████████████████████████▏                  | 7540/9741 [00:18<00:05, 397.78it/s] 78%|████████████████████████████████████████████████████████████████▌                  | 7582/9741 [00:18<00:05, 401.47it/s] 78%|████████████████████████████████████████████████████████████████▉                  | 7624/9741 [00:18<00:05, 404.26it/s] 79%|█████████████████████████████████████████████████████████████████▎                 | 7665/9741 [00:18<00:05, 403.78it/s] 79%|█████████████████████████████████████████████████████████████████▋                 | 7706/9741 [00:19<00:05, 405.53it/s] 80%|██████████████████████████████████████████████████████████████████                 | 7748/9741 [00:19<00:04, 407.08it/s] 80%|██████████████████████████████████████████████████████████████████▎                | 7789/9741 [00:19<00:04, 407.85it/s] 80%|██████████████████████████████████████████████████████████████████▋                | 7830/9741 [00:19<00:04, 404.38it/s] 81%|███████████████████████████████████████████████████████████████████                | 7871/9741 [00:19<00:04, 403.25it/s] 81%|███████████████████████████████████████████████████████████████████▍               | 7913/9741 [00:19<00:04, 405.54it/s] 82%|███████████████████████████████████████████████████████████████████▊               | 7955/9741 [00:19<00:04, 406.95it/s] 82%|████████████████████████████████████████████████████████████████████▏              | 7996/9741 [00:19<00:04, 407.71it/s] 83%|████████████████████████████████████████████████████████████████████▍              | 8037/9741 [00:19<00:04, 408.17it/s] 83%|████████████████████████████████████████████████████████████████████▊              | 8078/9741 [00:19<00:04, 408.32it/s] 83%|█████████████████████████████████████████████████████████████████████▏             | 8119/9741 [00:20<00:04, 405.27it/s] 84%|█████████████████████████████████████████████████████████████████████▌             | 8161/9741 [00:20<00:03, 406.96it/s] 84%|█████████████████████████████████████████████████████████████████████▉             | 8203/9741 [00:20<00:03, 408.29it/s] 85%|██████████████████████████████████████████████████████████████████████▎            | 8245/9741 [00:20<00:03, 409.51it/s] 85%|██████████████████████████████████████████████████████████████████████▌            | 8287/9741 [00:20<00:03, 409.81it/s] 85%|██████████████████████████████████████████████████████████████████████▉            | 8328/9741 [00:20<00:03, 406.57it/s] 86%|███████████████████████████████████████████████████████████████████████▎           | 8370/9741 [00:20<00:03, 407.70it/s] 86%|███████████████████████████████████████████████████████████████████████▋           | 8412/9741 [00:20<00:03, 408.69it/s] 87%|████████████████████████████████████████████████████████████████████████           | 8454/9741 [00:20<00:03, 409.27it/s] 87%|████████████████████████████████████████████████████████████████████████▍          | 8495/9741 [00:21<00:03, 409.04it/s] 88%|████████████████████████████████████████████████████████████████████████▋          | 8536/9741 [00:21<00:02, 408.76it/s] 88%|█████████████████████████████████████████████████████████████████████████          | 8577/9741 [00:21<00:02, 406.81it/s] 88%|█████████████████████████████████████████████████████████████████████████▍         | 8618/9741 [00:21<00:02, 407.07it/s] 89%|█████████████████████████████████████████████████████████████████████████▊         | 8659/9741 [00:21<00:02, 407.66it/s] 89%|██████████████████████████████████████████████████████████████████████████▏        | 8700/9741 [00:21<00:02, 408.20it/s] 90%|██████████████████████████████████████████████████████████████████████████▍        | 8741/9741 [00:21<00:02, 408.16it/s] 90%|██████████████████████████████████████████████████████████████████████████▊        | 8782/9741 [00:21<00:02, 406.23it/s] 91%|███████████████████████████████████████████████████████████████████████████▏       | 8823/9741 [00:21<00:02, 407.09it/s] 91%|███████████████████████████████████████████████████████████████████████████▌       | 8864/9741 [00:21<00:02, 407.25it/s] 91%|███████████████████████████████████████████████████████████████████████████▉       | 8905/9741 [00:22<00:02, 407.63it/s] 92%|████████████████████████████████████████████████████████████████████████████▏      | 8946/9741 [00:22<00:01, 408.26it/s] 92%|████████████████████████████████████████████████████████████████████████████▌      | 8987/9741 [00:22<00:01, 408.54it/s] 93%|████████████████████████████████████████████████████████████████████████████▉      | 9028/9741 [00:22<00:01, 402.28it/s] 93%|█████████████████████████████████████████████████████████████████████████████▎     | 9069/9741 [00:22<00:01, 403.14it/s] 94%|█████████████████████████████████████████████████████████████████████████████▌     | 9110/9741 [00:22<00:01, 403.84it/s] 94%|█████████████████████████████████████████████████████████████████████████████▉     | 9151/9741 [00:22<00:01, 404.57it/s] 94%|██████████████████████████████████████████████████████████████████████████████▎    | 9192/9741 [00:22<00:01, 405.33it/s] 95%|██████████████████████████████████████████████████████████████████████████████▋    | 9233/9741 [00:22<00:01, 403.34it/s] 95%|███████████████████████████████████████████████████████████████████████████████    | 9274/9741 [00:22<00:01, 404.42it/s] 96%|███████████████████████████████████████████████████████████████████████████████▎   | 9315/9741 [00:23<00:01, 404.98it/s] 96%|███████████████████████████████████████████████████████████████████████████████▋   | 9356/9741 [00:23<00:00, 405.38it/s] 96%|████████████████████████████████████████████████████████████████████████████████   | 9397/9741 [00:23<00:00, 406.13it/s] 97%|████████████████████████████████████████████████████████████████████████████████▍  | 9438/9741 [00:23<00:00, 406.22it/s] 97%|████████████████████████████████████████████████████████████████████████████████▊  | 9479/9741 [00:23<00:00, 404.24it/s] 98%|█████████████████████████████████████████████████████████████████████████████████  | 9520/9741 [00:23<00:00, 405.18it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▍ | 9561/9741 [00:23<00:00, 406.23it/s] 99%|█████████████████████████████████████████████████████████████████████████████████▊ | 9602/9741 [00:23<00:00, 407.33it/s] 99%|██████████████████████████████████████████████████████████████████████████████████▏| 9644/9741 [00:23<00:00, 408.44it/s] 99%|██████████████████████████████████████████████████████████████████████████████████▌| 9685/9741 [00:23<00:00, 406.92it/s]100%|██████████████████████████████████████████████████████████████████████████████████▊| 9726/9741 [00:24<00:00, 407.83it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:24<00:00, 404.67it/s]
Load End
Num instances: 1000
[2023-08-22 23:56:34,259] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 23:56:37,577] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 23:56:37,578] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 23:56:37,578] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 23:56:37,578] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 23:56:37,578] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 23:56:37,578] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 23:56:37,578] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 23:56:37,578] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 23:56:37,578] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 23:56:37,578] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 23:56:37,578] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 23:56:37,578] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f2d3aa20a60>
[2023-08-22 23:56:37,578] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 23:56:37,578] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 23:56:37,578] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 23:56:37,578] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f2d3aa20940>
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 23:56:37,579] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 23:56:37,580] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4573788642883301 seconds
Loading extension module utils...
Time to load utils op: 0.5047411918640137 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: Let x = the total number of candies Corey has.
x + 8 = the total number of candies Tapanga has.
The equation for the total number of candies is x + (x + 8) = 66
Combining like terms, we get 2x + 8 = 66
Subtracting 8 from both sides, we get 2x = 58
Dividing both sides by 2, we get x = <<29=29>>29, so Corey has 29 candies.
So the final answer is 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: At 5 cents a minute, calling his father cost Freddy 5* 45 = <<5*45=225>>225 cents.
At 25 cents a minute, calling his brother cost Freddy 25 * 31 = <<25*31=775>>775 cents.
Adding the cost of calling his father and brother, we find that Freddy paid a total of 225 + 775 = <<225+775=1000>>1000 cents.
Since each dollar has 100 cents, Freddy paid 1000 / 100 = <<1000/100=10>>10 dollars
So the final answer is 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 8 hours * 3 = <<8*3=24>>24 hours
5.5 * 2 = <<5.5*2=11>>11 hours
24 + 11 = <<24+11=35>>35 hours
35/7 = <<35/7=5>>5 hours
Lawrence would work 5 hours each of the 7 days in a week.
So the final answer is 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: We look first for the total number of books that were sold: 60 + 10 + 20 + 44 + 66 = <<60+10+20+44+66=200>>200 books.
So the total number of books that were not sold is: 800 – 200 = <<800-200=600>>600 books.
So the final answer is 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: Michael sold 2 large birdhouses for $22 each, so he made 2*$22= $<<2*22=44>>44 from large birdhouse sales.
Michael also sold 2 medium birdhouses for $16 each, so he made 2*$16= $<<2*16=32>>32 from medium birdhouse sales.
Michael sold 3 small birdhouses for $7 each, so he made 3*7=$<<3*7=21>>21 from small birdhouse sales.
Since Michael made $44 from large birdhouse sales, $32 from medium birdhouse sales, and $21 for small birdhouse sales, he made $44+$32+$21= $<<44+32+21=97>>97 total this week.
So the final answer is 97

Input: Nalani had two female dogs that were expecting and after a month gave birth to 10 puppies each. She then sold 3/4 of the puppies after they came of age, each at $200. Calculate the total amount of money she received from the sale of the puppies.
Output: If the two expectant dogs gave birth to 10 puppies each, the total number of puppies Nalani had is 10+10= <<10+10=20>>20
When they came of age, Nalani sold 3/4 of the dogs, a total of 3/4*20 = <<3/4*20=15>>15 dogs.
If each dog sold for $200, Nalani received 15*200 = $<<15*200=3000>>3000 from the sale of the dogs.
So the final answer is 3000

Input: Boris has 24 books and he donates a fourth of his books to the library. Cameron has 30 books and he donates a third of his books to the library. After donating their books, how many books in total do Boris and Cameron have together?
Output: Boris donates 24 / 4 = <<24/4=6>>6 books
Then Boris has a total of 24 - 6 = <<24-6=18>>18 books
Cameron donates 30 / 3 = <<30/3=10>>10 books
Then Cameron has a total of 30 - 10 = <<30-10=20>>20 books
Altogether, Boris and Cameron have 18 + 20 = <<18+20=38>>38 books
So the final answer is 38

Input: There are 3 boxes of cereal. One box holds 14 ounces of cereal. Another box holds half the amount of the first box and 5 ounces less than the third box. How much cereal is there in all 3 cereal boxes?
Output: First = <<14=14>>14 oz
Second = (1/2) * 14 = <<(1/2)*14=7>>7 oz
Third = 7 + 5 = <<7+5=12>>12 oz
14 + 7 + 12 = <<14+7+12=33>>33 oz
There are 33 ounces of cereal in those 3 boxes.
So the final answer is 33

Input: A jug needs 40 cups of water to be full. A custodian at Truman Elementary School has to fill water jugs for 200 students, who drink 10 cups of water in a day. How many water jugs will the custodian fill with cups of water to provide the students with all the water they need in a day?
Output: Since each student needs 10 cups of water per day and there are 200 students, the custodian has to provide 200*10 = <<200*10=2000>>2000 cups of water.
A jug of water needs 40 cups to be full, so 2000 cups of water will fill 2000/40 = <<2000/40=50>>50 jugs
So the final answer is 50

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o9-tgsm8k-s20-rTrue
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 126, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 123, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 107, in evaluate_main
    query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 89, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2484, in sample
    outputs = self(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/models/opt/modeling_opt.py", line 983, in forward
    outputs = self.model.decoder(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/models/opt/modeling_opt.py", line 749, in forward
    layer_outputs = decoder_layer(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/models/opt/modeling_opt.py", line 399, in forward
    hidden_states = self.fc1(hidden_states)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasGemmEx( handle, opa, opb, m, n, k, &falpha, a, CUDA_R_16F, lda, b, CUDA_R_16F, ldb, &fbeta, c, CUDA_R_16F, ldc, CUDA_R_32F, CUBLAS_GEMM_DFALT_TENSOR_OP)`
terminate called after throwing an instance of 'c10::CUDAError'
  what():  CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Exception raised from create_event_internal at ../c10/cuda/CUDACachingAllocator.cpp:1387 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x3e (0x7f1aa22d720e in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x23a21 (0x7f1a9ab35a21 in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #2: c10::cuda::CUDACachingAllocator::raw_delete(void*) + 0x257 (0x7f1a9ab3a9a7 in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x463338 (0x7f1a86af4338 in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #4: c10::TensorImpl::release_resources() + 0x175 (0x7f1aa22be7a5 in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #5: <unknown function> + 0x35f355 (0x7f1a869f0355 in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #6: <unknown function> + 0x678d38 (0x7f1a86d09d38 in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: THPVariable_subclass_dealloc(_object*) + 0x2b5 (0x7f1a86d0a0e5 in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #8: /home/ylu130/.conda/envs/distllm/bin/python() [0x4e4277]
frame #9: /home/ylu130/.conda/envs/distllm/bin/python() [0x4d9998]
frame #10: _PyModule_ClearDict + 0xe9 (0x55b3b9 in /home/ylu130/.conda/envs/distllm/bin/python)
frame #11: /home/ylu130/.conda/envs/distllm/bin/python() [0x5c263b]
frame #12: Py_FinalizeEx + 0x179 (0x5c10d9 in /home/ylu130/.conda/envs/distllm/bin/python)
frame #13: Py_RunMain + 0x110 (0x5b4210 in /home/ylu130/.conda/envs/distllm/bin/python)
frame #14: Py_BytesMain + 0x39 (0x587a39 in /home/ylu130/.conda/envs/distllm/bin/python)
frame #15: <unknown function> + 0x29d90 (0x7f1aa2c32d90 in /lib/x86_64-linux-gnu/libc.so.6)
frame #16: __libc_start_main + 0x80 (0x7f1aa2c32e40 in /lib/x86_64-linux-gnu/libc.so.6)
frame #17: /home/ylu130/.conda/envs/distllm/bin/python() [0x5878ee]

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:33<?, ?it/s]
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 126, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 123, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 107, in evaluate_main
    query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 89, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2484, in sample
    outputs = self(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/models/opt/modeling_opt.py", line 983, in forward
    outputs = self.model.decoder(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/models/opt/modeling_opt.py", line 749, in forward
    layer_outputs = decoder_layer(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/models/opt/modeling_opt.py", line 376, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/models/opt/modeling_opt.py", line 301, in forward
    attn_output = torch.bmm(attn_probs, value_states)
RuntimeError: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasGemmStridedBatchedExFix( handle, opa, opb, m, n, k, (void*)(&falpha), a, CUDA_R_16F, lda, stridea, b, CUDA_R_16F, ldb, strideb, (void*)(&fbeta), c, CUDA_R_16F, ldc, stridec, num_batches, CUDA_R_32F, CUBLAS_GEMM_DEFAULT_TENSOR_OP)`
terminate called after throwing an instance of 'c10::CUDAError'
  what():  CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Exception raised from create_event_internal at ../c10/cuda/CUDACachingAllocator.cpp:1387 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x3e (0x7f2de229320e in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x23a21 (0x7f2ddab35a21 in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #2: c10::cuda::CUDACachingAllocator::raw_delete(void*) + 0x257 (0x7f2ddab3a9a7 in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x463338 (0x7f2dc6af4338 in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #4: c10::TensorImpl::release_resources() + 0x175 (0x7f2de227a7a5 in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #5: <unknown function> + 0x35f355 (0x7f2dc69f0355 in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #6: <unknown function> + 0x678d38 (0x7f2dc6d09d38 in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: THPVariable_subclass_dealloc(_object*) + 0x2b5 (0x7f2dc6d0a0e5 in /home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #8: /home/ylu130/.conda/envs/distllm/bin/python() [0x4e4277]
frame #9: /home/ylu130/.conda/envs/distllm/bin/python() [0x4d9998]
frame #10: _PyModule_ClearDict + 0xe9 (0x55b3b9 in /home/ylu130/.conda/envs/distllm/bin/python)
frame #11: /home/ylu130/.conda/envs/distllm/bin/python() [0x5c263b]
frame #12: Py_FinalizeEx + 0x179 (0x5c10d9 in /home/ylu130/.conda/envs/distllm/bin/python)
frame #13: Py_RunMain + 0x110 (0x5b4210 in /home/ylu130/.conda/envs/distllm/bin/python)
frame #14: Py_BytesMain + 0x39 (0x587a39 in /home/ylu130/.conda/envs/distllm/bin/python)
frame #15: <unknown function> + 0x29d90 (0x7f2de2beed90 in /lib/x86_64-linux-gnu/libc.so.6)
frame #16: __libc_start_main + 0x80 (0x7f2de2beee40 in /lib/x86_64-linux-gnu/libc.so.6)
frame #17: /home/ylu130/.conda/envs/distllm/bin/python() [0x5878ee]

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: -6) local_rank: 0 (pid: 3938445) of binary: /home/ylu130/.conda/envs/distllm/bin/python
Traceback (most recent call last):
  File "/home/ylu130/.conda/envs/distllm/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/run.py", line 761, in main
    run(args)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/ylu130/workspace/in-context-generalization/inference.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-08-22_23:57:16
  host      : ia1.wse.jhu.edu
  rank      : 1 (local_rank: 1)
  exitcode  : -6 (pid: 3938446)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 3938446
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-08-22_23:57:16
  host      : ia1.wse.jhu.edu
  rank      : 0 (local_rank: 0)
  exitcode  : -6 (pid: 3938445)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 3938445
============================================================
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 2048 --num-out-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-22 23:57:20,055] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 1
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o1-tgsm8k-s20-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  3%|██▋                                                                                | 314/9741 [00:00<00:03, 3135.46it/s]  7%|█████▍                                                                             | 643/9741 [00:00<00:02, 3223.84it/s] 10%|████████▎                                                                          | 981/9741 [00:00<00:02, 3294.62it/s] 14%|███████████                                                                       | 1320/9741 [00:00<00:02, 3328.71it/s] 17%|█████████████▉                                                                    | 1662/9741 [00:00<00:02, 3358.56it/s] 21%|████████████████▊                                                                 | 1998/9741 [00:00<00:02, 3352.56it/s] 24%|███████████████████▋                                                              | 2338/9741 [00:00<00:02, 3365.86it/s] 28%|██████████████████████▌                                                           | 2681/9741 [00:00<00:02, 3384.45it/s] 31%|█████████████████████████▍                                                        | 3024/9741 [00:00<00:01, 3395.89it/s] 35%|████████████████████████████▎                                                     | 3364/9741 [00:01<00:01, 3340.08it/s] 38%|███████████████████████████████▏                                                  | 3702/9741 [00:01<00:01, 3349.41it/s] 42%|██████████████████████████████████                                                | 4049/9741 [00:01<00:01, 3382.89it/s] 45%|█████████████████████████████████████                                             | 4397/9741 [00:01<00:01, 3409.22it/s] 49%|███████████████████████████████████████▉                                          | 4739/9741 [00:01<00:01, 2561.72it/s] 52%|██████████████████████████████████████████▊                                       | 5084/9741 [00:01<00:01, 2778.00it/s] 56%|█████████████████████████████████████████████▋                                    | 5431/9741 [00:01<00:01, 2954.89it/s] 59%|████████████████████████████████████████████████▋                                 | 5782/9741 [00:01<00:01, 3102.75it/s] 63%|███████████████████████████████████████████████████▌                              | 6131/9741 [00:01<00:01, 3209.52it/s] 67%|██████████████████████████████████████████████████████▌                           | 6479/9741 [00:02<00:00, 3284.04it/s] 70%|█████████████████████████████████████████████████████████▍                        | 6826/9741 [00:02<00:00, 3336.66it/s] 74%|████████████████████████████████████████████████████████████▍                     | 7181/9741 [00:02<00:00, 3398.37it/s] 77%|███████████████████████████████████████████████████████████████▎                  | 7526/9741 [00:02<00:00, 3405.11it/s] 81%|██████████████████████████████████████████████████████████████████▎               | 7877/9741 [00:02<00:00, 3435.27it/s] 85%|█████████████████████████████████████████████████████████████████████▎            | 8232/9741 [00:02<00:00, 3468.39it/s] 90%|█████████████████████████████████████████████████████████████████████████▋        | 8749/9741 [00:02<00:00, 3973.50it/s] 95%|██████████████████████████████████████████████████████████████████████████████▏   | 9282/9741 [00:02<00:00, 4376.58it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:02<00:00, 3470.34it/s]
Load End
Num instances: 1000
[2023-08-22 23:57:34,577] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-22 23:57:37,298] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-22 23:57:37,298] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-22 23:57:37,298] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-22 23:57:37,298] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-22 23:57:37,298] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-22 23:57:37,298] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f01a3aeea60>
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f01a3aee940>
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-22 23:57:37,299] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-22 23:57:37,300] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-22 23:57:37,300] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-22 23:57:37,300] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-22 23:57:37,300] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-22 23:57:37,300] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-22 23:57:37,300] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-22 23:57:37,300] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-22 23:57:37,300] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-22 23:57:37,300] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-22 23:57:37,300] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-22 23:57:37,300] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-22 23:57:37,300] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-22 23:57:37,300] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-22 23:57:37,300] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-22 23:57:37,300] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-22 23:57:37,300] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.43851399421691895 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: 29

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o1-tgsm8k-s20-rFalse
Loading extension module utils...
Time to load utils op: 0.5050914287567139 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [01:06<53:55, 66.04s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [02:13<53:18, 66.63s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [03:20<52:38, 67.20s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [04:27<51:19, 66.96s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [05:34<50:15, 67.01s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [06:42<49:14, 67.15s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [07:48<48:00, 66.98s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [08:57<47:11, 67.43s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [10:03<45:52, 67.14s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [11:13<45:18, 67.96s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [12:21<44:12, 68.01s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [13:27<42:45, 67.51s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [14:33<41:15, 66.90s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [15:40<40:10, 66.95s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [16:48<39:10, 67.16s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [17:54<37:59, 67.03s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [19:01<36:46, 66.87s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [20:09<35:51, 67.24s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [21:17<34:55, 67.61s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [22:25<33:49, 67.64s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [23:32<32:33, 67.35s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [24:41<31:37, 67.79s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [25:48<30:27, 67.70s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [26:57<29:27, 67.99s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [28:04<28:15, 67.81s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [29:11<27:03, 67.66s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [30:21<26:10, 68.28s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [31:30<25:03, 68.33s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [32:39<24:02, 68.69s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [33:48<22:53, 68.68s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [34:54<21:32, 68.03s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [36:00<20:14, 67.46s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [37:07<19:02, 67.19s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [38:13<17:50, 66.90s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [39:21<16:45, 67.06s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [40:27<15:35, 66.85s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [41:36<14:35, 67.35s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [42:42<13:24, 67.05s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [43:50<12:22, 67.46s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [44:59<11:17, 67.76s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [46:08<10:13, 68.18s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [47:15<09:01, 67.74s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [48:22<07:52, 67.49s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [49:28<06:43, 67.24s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [50:35<05:34, 66.99s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [51:42<04:28, 67.09s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [52:47<03:19, 66.55s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [53:57<02:14, 67.37s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [55:05<01:07, 67.63s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [56:12<00:00, 67.44s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [56:12<00:00, 67.45s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.4379} | avg. gen lenth: 301.704
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 2048 --num-out-domain 2
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-23 00:54:09,871] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 2
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o2-tgsm8k-s20-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  2%|█▌                                                                                 | 186/9741 [00:00<00:05, 1855.35it/s]  4%|███▎                                                                               | 383/9741 [00:00<00:04, 1921.58it/s]  6%|████▉                                                                              | 583/9741 [00:00<00:04, 1953.33it/s]  8%|██████▋                                                                            | 784/9741 [00:00<00:04, 1971.42it/s] 10%|████████▍                                                                          | 985/9741 [00:00<00:04, 1983.15it/s] 12%|█████████▉                                                                        | 1187/9741 [00:00<00:04, 1994.53it/s] 14%|███████████▋                                                                      | 1388/9741 [00:00<00:04, 1998.82it/s] 16%|█████████████▍                                                                    | 1591/9741 [00:00<00:04, 2006.28it/s] 18%|███████████████                                                                   | 1792/9741 [00:00<00:03, 1990.31it/s] 20%|████████████████▊                                                                 | 1992/9741 [00:01<00:03, 1953.51it/s] 23%|██████████████████▍                                                               | 2192/9741 [00:01<00:03, 1967.09it/s] 25%|████████████████████▏                                                             | 2395/9741 [00:01<00:03, 1984.82it/s] 27%|█████████████████████▊                                                            | 2597/9741 [00:01<00:03, 1993.41it/s] 29%|███████████████████████▌                                                          | 2797/9741 [00:01<00:03, 1994.03it/s] 31%|█████████████████████████▏                                                        | 2999/9741 [00:01<00:03, 2001.36it/s] 33%|██████████████████████████▉                                                       | 3202/9741 [00:01<00:03, 2009.46it/s] 35%|████████████████████████████▋                                                     | 3405/9741 [00:01<00:03, 2015.10it/s] 38%|██████████████████████████████▊                                                   | 3656/9741 [00:01<00:02, 2163.16it/s] 41%|█████████████████████████████████▍                                                | 3965/9741 [00:01<00:02, 2441.02it/s] 44%|███████████████████████████████████▉                                              | 4275/9741 [00:02<00:02, 2637.49it/s] 47%|██████████████████████████████████████▌                                           | 4574/9741 [00:02<00:01, 2742.21it/s] 50%|████████████████████████████████████████▊                                         | 4849/9741 [00:02<00:02, 2438.81it/s] 53%|███████████████████████████████████████████▍                                      | 5159/9741 [00:02<00:01, 2620.24it/s] 56%|██████████████████████████████████████████████                                    | 5471/9741 [00:02<00:01, 2759.30it/s] 59%|████████████████████████████████████████████████▋                                 | 5784/9741 [00:02<00:01, 2864.55it/s] 63%|███████████████████████████████████████████████████▎                              | 6098/9741 [00:02<00:01, 2944.60it/s] 66%|█████████████████████████████████████████████████████▉                            | 6410/9741 [00:02<00:01, 2995.01it/s] 69%|████████████████████████████████████████████████████████▌                         | 6725/9741 [00:02<00:00, 3038.45it/s] 72%|███████████████████████████████████████████████████████████▎                      | 7040/9741 [00:02<00:00, 3068.77it/s] 76%|█████████████████████████████████████████████████████████████▉                    | 7357/9741 [00:03<00:00, 3096.51it/s] 79%|████████████████████████████████████████████████████████████████▌                 | 7668/9741 [00:03<00:00, 3068.93it/s] 82%|███████████████████████████████████████████████████████████████████▏              | 7976/9741 [00:03<00:00, 3052.60it/s] 85%|█████████████████████████████████████████████████████████████████████▊            | 8289/9741 [00:03<00:00, 3075.44it/s] 88%|████████████████████████████████████████████████████████████████████████▍         | 8602/9741 [00:03<00:00, 3089.14it/s] 92%|███████████████████████████████████████████████████████████████████████████       | 8915/9741 [00:03<00:00, 3100.40it/s] 95%|█████████████████████████████████████████████████████████████████████████████▋    | 9230/9741 [00:03<00:00, 3113.98it/s] 98%|████████████████████████████████████████████████████████████████████████████████▎ | 9545/9741 [00:03<00:00, 3124.53it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:03<00:00, 2546.44it/s]
Load End
Num instances: 1000
[2023-08-23 00:54:24,730] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-23 00:54:27,762] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-23 00:54:27,762] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f0d54ecea60>
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-23 00:54:27,763] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f0d54ece940>
[2023-08-23 00:54:27,764] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-23 00:54:27,764] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-23 00:54:27,764] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-23 00:54:27,764] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-23 00:54:27,764] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-23 00:54:27,764] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-23 00:54:27,764] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-23 00:54:27,764] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-23 00:54:27,764] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-23 00:54:27,764] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-23 00:54:27,764] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-23 00:54:27,764] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-23 00:54:27,764] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-23 00:54:27,764] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-23 00:54:27,764] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-23 00:54:27,764] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-23 00:54:27,764] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-23 00:54:27,764] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-23 00:54:27,764] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-23 00:54:27,764] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-23 00:54:27,764] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-23 00:54:27,764] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-23 00:54:27,764] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4125347137451172 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: 10

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o2-tgsm8k-s20-rFalse
Loading extension module utils...
Time to load utils op: 0.3043818473815918 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [01:03<51:50, 63.48s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [02:06<50:34, 63.22s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [03:09<49:23, 63.06s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [04:12<48:12, 62.89s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [05:13<46:52, 62.49s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [06:16<45:59, 62.71s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [07:18<44:38, 62.28s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [08:21<43:43, 62.46s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [09:23<42:34, 62.30s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [10:26<41:40, 62.52s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [11:28<40:33, 62.41s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [12:31<39:45, 62.76s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [13:36<38:59, 63.24s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [14:39<37:56, 63.23s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [15:42<36:56, 63.33s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [16:46<35:58, 63.48s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [17:49<34:43, 63.13s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [18:52<33:41, 63.18s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [19:55<32:33, 63.02s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [20:59<31:46, 63.55s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [22:01<30:29, 63.09s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [23:06<29:38, 63.50s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [24:09<28:34, 63.49s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [25:12<27:25, 63.31s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [26:16<26:23, 63.33s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [27:18<25:14, 63.12s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [28:23<24:25, 63.71s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [29:28<23:29, 64.05s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [30:31<22:15, 63.58s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [31:33<21:03, 63.16s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [32:35<19:52, 62.77s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [33:35<18:36, 62.02s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [34:39<17:43, 62.53s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [35:40<16:35, 62.20s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [36:43<15:35, 62.35s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [37:44<14:29, 62.11s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [38:49<13:38, 62.99s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [39:52<12:33, 62.78s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [40:55<11:33, 63.04s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [41:58<10:28, 62.86s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [43:01<09:26, 62.94s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [44:03<08:22, 62.82s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [45:06<07:19, 62.75s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [46:08<06:14, 62.47s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [47:11<05:12, 62.59s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [48:13<04:09, 62.38s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [49:14<03:06, 62.08s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [50:17<02:04, 62.30s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [51:20<01:02, 62.58s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [52:22<00:00, 62.41s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [52:22<00:00, 62.85s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.4294} | avg. gen lenth: 353.012
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o3-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 2048 --num-out-domain 3
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-23 01:46:59,489] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o3-tgsm8k-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 3
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o3-tgsm8k-s20-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  2%|█▎                                                                                 | 149/9741 [00:00<00:06, 1488.31it/s]  3%|██▌                                                                                | 304/9741 [00:00<00:06, 1524.00it/s]  5%|███▉                                                                               | 461/9741 [00:00<00:06, 1544.55it/s]  6%|█████▎                                                                             | 620/9741 [00:00<00:05, 1558.54it/s]  8%|██████▋                                                                            | 779/9741 [00:00<00:05, 1568.58it/s] 10%|███████▉                                                                           | 938/9741 [00:00<00:05, 1575.79it/s] 11%|█████████▎                                                                        | 1099/9741 [00:00<00:05, 1584.20it/s] 13%|██████████▌                                                                       | 1259/9741 [00:00<00:05, 1587.90it/s] 15%|███████████▉                                                                      | 1418/9741 [00:00<00:05, 1561.87it/s] 16%|█████████████▎                                                                    | 1575/9741 [00:01<00:05, 1563.44it/s] 18%|██████████████▌                                                                   | 1735/9741 [00:01<00:05, 1573.63it/s] 19%|███████████████▉                                                                  | 1893/9741 [00:01<00:05, 1551.90it/s] 21%|█████████████████▎                                                                | 2051/9741 [00:01<00:04, 1559.39it/s] 23%|██████████████████▌                                                               | 2211/9741 [00:01<00:04, 1569.33it/s] 24%|███████████████████▉                                                              | 2371/9741 [00:01<00:04, 1577.05it/s] 26%|█████████████████████▎                                                            | 2538/9741 [00:01<00:04, 1603.63it/s] 29%|███████████████████████▍                                                          | 2782/9741 [00:01<00:03, 1852.11it/s] 31%|█████████████████████████▍                                                        | 3027/9741 [00:01<00:03, 2030.61it/s] 34%|███████████████████████████▌                                                      | 3273/9741 [00:01<00:02, 2157.16it/s] 36%|█████████████████████████████▌                                                    | 3518/9741 [00:02<00:02, 2243.32it/s] 39%|███████████████████████████████▋                                                  | 3764/9741 [00:02<00:02, 2307.42it/s] 41%|█████████████████████████████████▋                                                | 4009/9741 [00:02<00:02, 2349.38it/s] 44%|███████████████████████████████████▊                                              | 4254/9741 [00:02<00:02, 2379.45it/s] 46%|█████████████████████████████████████▊                                            | 4492/9741 [00:02<00:02, 2369.74it/s] 49%|███████████████████████████████████████▊                                          | 4730/9741 [00:02<00:02, 2064.35it/s] 51%|█████████████████████████████████████████▊                                        | 4974/9741 [00:02<00:02, 2164.61it/s] 54%|███████████████████████████████████████████▉                                      | 5219/9741 [00:02<00:02, 2242.72it/s] 56%|█████████████████████████████████████████████▉                                    | 5464/9741 [00:02<00:01, 2299.36it/s] 59%|████████████████████████████████████████████████                                  | 5709/9741 [00:02<00:01, 2340.97it/s] 61%|██████████████████████████████████████████████████▏                               | 5955/9741 [00:03<00:01, 2374.72it/s] 64%|████████████████████████████████████████████████████▏                             | 6202/9741 [00:03<00:01, 2400.40it/s] 66%|██████████████████████████████████████████████████████▏                           | 6444/9741 [00:03<00:01, 2379.82it/s] 69%|████████████████████████████████████████████████████████▎                         | 6688/9741 [00:03<00:01, 2397.15it/s] 71%|██████████████████████████████████████████████████████████▎                       | 6934/9741 [00:03<00:01, 2414.00it/s] 74%|████████████████████████████████████████████████████████████▍                     | 7180/9741 [00:03<00:01, 2426.11it/s] 76%|██████████████████████████████████████████████████████████████▍                   | 7423/9741 [00:03<00:00, 2398.72it/s] 79%|████████████████████████████████████████████████████████████████▌                 | 7668/9741 [00:03<00:00, 2413.41it/s] 81%|██████████████████████████████████████████████████████████████████▋               | 7915/9741 [00:03<00:00, 2427.58it/s] 84%|████████████████████████████████████████████████████████████████████▋             | 8162/9741 [00:03<00:00, 2439.17it/s] 86%|██████████████████████████████████████████████████████████████████████▊           | 8408/9741 [00:04<00:00, 2443.88it/s] 89%|████████████████████████████████████████████████████████████████████████▊         | 8654/9741 [00:04<00:00, 2447.93it/s] 91%|██████████████████████████████████████████████████████████████████████████▉       | 8901/9741 [00:04<00:00, 2453.18it/s] 94%|████████████████████████████████████████████████████████████████████████████▉     | 9147/9741 [00:04<00:00, 2452.09it/s] 96%|███████████████████████████████████████████████████████████████████████████████   | 9393/9741 [00:04<00:00, 2454.14it/s] 99%|█████████████████████████████████████████████████████████████████████████████████▏| 9639/9741 [00:04<00:00, 2451.01it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:04<00:00, 2107.92it/s]
Load End
Num instances: 1000
[2023-08-23 01:47:15,104] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-23 01:47:17,890] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-23 01:47:17,890] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-23 01:47:17,890] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-23 01:47:17,890] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-23 01:47:17,890] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-23 01:47:17,890] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fe92dffda60>
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fe92dffd940>
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-23 01:47:17,891] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-23 01:47:17,892] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-23 01:47:17,892] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-23 01:47:17,892] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-23 01:47:17,892] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-23 01:47:17,892] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-23 01:47:17,892] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-23 01:47:17,892] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-23 01:47:17,892] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-23 01:47:17,892] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-23 01:47:17,892] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-23 01:47:17,892] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-23 01:47:17,892] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-23 01:47:17,892] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-23 01:47:17,892] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-23 01:47:17,892] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-23 01:47:17,892] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-23 01:47:17,892] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-23 01:47:17,892] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.41814327239990234 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 5

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o3-tgsm8k-s20-rFalse
Loading extension module utils...
Time to load utils op: 0.5048766136169434 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [01:02<51:22, 62.92s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [02:05<50:16, 62.84s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [03:05<48:12, 61.54s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [04:05<46:46, 61.02s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [05:05<45:16, 60.36s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [06:04<44:02, 60.06s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [07:04<43:04, 60.10s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [08:06<42:24, 60.59s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [09:06<41:21, 60.52s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [10:08<40:40, 61.00s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [11:10<39:45, 61.17s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [12:10<38:36, 60.97s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [13:10<37:21, 60.59s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [14:12<36:37, 61.04s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [15:13<35:34, 61.00s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [16:14<34:33, 60.97s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [17:15<33:34, 61.05s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [18:16<32:26, 60.82s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [19:15<31:17, 60.56s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [20:17<30:21, 60.71s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [21:18<29:26, 60.93s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [22:18<28:20, 60.74s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [23:19<27:20, 60.76s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [24:22<26:34, 61.34s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [25:22<25:27, 61.12s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [26:23<24:23, 60.97s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [27:24<23:24, 61.05s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [28:29<22:44, 62.04s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [29:32<21:51, 62.45s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [30:33<20:41, 62.06s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [31:36<19:42, 62.23s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [32:37<18:33, 61.88s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [33:39<17:33, 61.97s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [34:38<16:18, 61.17s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [35:41<15:22, 61.47s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [36:41<14:14, 61.04s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [37:43<13:17, 61.36s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [38:46<12:23, 61.95s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [39:47<11:19, 61.80s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [40:47<10:12, 61.24s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [41:49<09:11, 61.24s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [42:49<08:07, 60.98s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [43:49<07:05, 60.81s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [44:50<06:03, 60.66s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [45:50<05:03, 60.66s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [46:52<04:04, 61.04s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [47:54<03:03, 61.21s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [48:55<02:02, 61.17s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [49:58<01:01, 61.74s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [50:58<00:00, 61.06s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [50:58<00:00, 61.16s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.4404} | avg. gen lenth: 357.05
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o4-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 2048 --num-out-domain 4
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-23 02:38:23,942] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o4-tgsm8k-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 4
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o4-tgsm8k-s20-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  2%|█▋                                                                                 | 195/9741 [00:00<00:04, 1943.00it/s]  4%|███▍                                                                               | 402/9741 [00:00<00:04, 2012.37it/s]  6%|█████▏                                                                             | 611/9741 [00:00<00:04, 2046.60it/s]  8%|██████▉                                                                            | 821/9741 [00:00<00:04, 2067.01it/s] 11%|████████▋                                                                         | 1031/9741 [00:00<00:04, 2075.80it/s] 13%|██████████▍                                                                       | 1242/9741 [00:00<00:04, 2085.06it/s] 15%|████████████▏                                                                     | 1453/9741 [00:00<00:03, 2091.22it/s] 17%|█████████████▉                                                                    | 1663/9741 [00:00<00:03, 2093.39it/s] 19%|███████████████▊                                                                  | 1873/9741 [00:00<00:03, 2078.98it/s] 21%|█████████████████▌                                                                | 2081/9741 [00:01<00:03, 2038.79it/s] 24%|███████████████████▎                                                              | 2290/9741 [00:01<00:03, 2052.95it/s] 26%|█████████████████████                                                             | 2500/9741 [00:01<00:03, 2065.70it/s] 28%|██████████████████████▊                                                           | 2707/9741 [00:01<00:03, 2006.45it/s] 30%|████████████████████████▌                                                         | 2916/9741 [00:01<00:03, 2029.22it/s] 32%|██████████████████████████▎                                                       | 3126/9741 [00:01<00:03, 2049.85it/s] 34%|████████████████████████████                                                      | 3337/9741 [00:01<00:03, 2066.81it/s] 36%|█████████████████████████████▊                                                    | 3548/9741 [00:01<00:02, 2078.45it/s] 39%|███████████████████████████████▋                                                  | 3759/9741 [00:01<00:02, 2087.23it/s] 41%|█████████████████████████████████▍                                                | 3971/9741 [00:01<00:02, 2096.66it/s] 43%|███████████████████████████████████▏                                              | 4181/9741 [00:02<00:02, 2093.29it/s] 45%|████████████████████████████████████▉                                             | 4391/9741 [00:02<00:02, 2093.67it/s] 47%|██████████████████████████████████████▋                                           | 4601/9741 [00:02<00:02, 2070.02it/s] 49%|████████████████████████████████████████▍                                         | 4809/9741 [00:02<00:03, 1602.63it/s] 52%|██████████████████████████████████████████▏                                       | 5018/9741 [00:02<00:02, 1722.26it/s] 54%|████████████████████████████████████████████                                      | 5228/9741 [00:02<00:02, 1819.69it/s] 56%|█████████████████████████████████████████████▊                                    | 5437/9741 [00:02<00:02, 1892.31it/s] 58%|███████████████████████████████████████████████▌                                  | 5646/9741 [00:02<00:02, 1947.24it/s] 60%|█████████████████████████████████████████████████▎                                | 5858/9741 [00:02<00:01, 1995.01it/s] 62%|███████████████████████████████████████████████████                               | 6069/9741 [00:03<00:01, 2025.99it/s] 64%|████████████████████████████████████████████████████▊                             | 6278/9741 [00:03<00:01, 2042.66it/s] 67%|██████████████████████████████████████████████████████▌                           | 6488/9741 [00:03<00:01, 2057.90it/s] 69%|████████████████████████████████████████████████████████▎                         | 6696/9741 [00:03<00:01, 2017.00it/s] 71%|██████████████████████████████████████████████████████████▏                       | 6905/9741 [00:03<00:01, 2036.29it/s] 73%|███████████████████████████████████████████████████████████▉                      | 7115/9741 [00:03<00:01, 2052.51it/s] 75%|█████████████████████████████████████████████████████████████▋                    | 7326/9741 [00:03<00:01, 2067.79it/s] 77%|███████████████████████████████████████████████████████████████▍                  | 7534/9741 [00:03<00:01, 2036.77it/s] 79%|█████████████████████████████████████████████████████████████████▏                | 7744/9741 [00:03<00:00, 2052.60it/s] 82%|██████████████████████████████████████████████████████████████████▉               | 7953/9741 [00:03<00:00, 2061.46it/s] 84%|████████████████████████████████████████████████████████████████████▋             | 8163/9741 [00:04<00:00, 2072.44it/s] 86%|██████████████████████████████████████████████████████████████████████▍           | 8372/9741 [00:04<00:00, 2076.87it/s] 88%|████████████████████████████████████████████████████████████████████████▏         | 8580/9741 [00:04<00:00, 2077.75it/s] 90%|█████████████████████████████████████████████████████████████████████████▉        | 8788/9741 [00:04<00:00, 2073.42it/s] 92%|███████████████████████████████████████████████████████████████████████████▋      | 8998/9741 [00:04<00:00, 2078.75it/s] 95%|█████████████████████████████████████████████████████████████████████████████▍    | 9206/9741 [00:04<00:00, 2059.26it/s] 97%|███████████████████████████████████████████████████████████████████████████████▏  | 9412/9741 [00:04<00:00, 1964.05it/s] 99%|████████████████████████████████████████████████████████████████████████████████▉ | 9614/9741 [00:04<00:00, 1980.04it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:04<00:00, 2018.09it/s]
Load End
Num instances: 1000
[2023-08-23 02:38:40,742] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-23 02:38:43,955] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-23 02:38:43,956] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-23 02:38:43,956] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-23 02:38:43,956] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-23 02:38:43,956] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-23 02:38:43,956] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-23 02:38:43,956] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-23 02:38:43,956] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-23 02:38:43,956] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-23 02:38:43,956] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-23 02:38:43,956] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-23 02:38:43,956] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fc01d479a60>
[2023-08-23 02:38:43,956] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-23 02:38:43,956] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fc01d479940>
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-23 02:38:43,957] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-23 02:38:43,958] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-23 02:38:43,958] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4753994941711426 seconds
Loading extension module utils...
Time to load utils op: 0.5048220157623291 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: 600

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o4-tgsm8k-s20-rFalse
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:59<48:41, 59.62s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:58<47:27, 59.32s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:59<47:03, 60.08s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [04:00<46:10, 60.24s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [05:01<45:35, 60.78s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [06:01<44:21, 60.49s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [06:59<42:43, 59.61s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [07:57<41:21, 59.09s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [08:58<40:45, 59.64s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [10:00<40:17, 60.43s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [11:00<39:05, 60.14s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [11:58<37:49, 59.71s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [12:59<36:59, 59.99s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [13:59<35:55, 59.87s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [14:59<34:57, 59.94s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [15:57<33:36, 59.31s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [16:55<32:27, 59.01s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [17:53<31:16, 58.65s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [18:52<30:21, 58.75s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [19:51<29:26, 58.88s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [20:51<28:42, 59.40s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [21:51<27:46, 59.51s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [22:49<26:34, 59.04s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [23:49<25:39, 59.22s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [24:48<24:41, 59.25s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [25:49<23:50, 59.61s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [26:48<22:51, 59.63s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [27:49<21:56, 59.86s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [28:48<20:54, 59.74s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [29:47<19:50, 59.54s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [30:46<18:47, 59.33s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [31:45<17:44, 59.14s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [32:43<16:42, 58.96s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [33:41<15:36, 58.51s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [34:39<14:35, 58.37s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [35:39<13:44, 58.89s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [36:37<12:42, 58.63s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [37:38<11:53, 59.47s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [38:37<10:52, 59.35s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [39:36<09:51, 59.20s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [40:35<08:50, 58.94s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [41:34<07:53, 59.23s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [42:36<06:58, 59.83s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [43:35<05:58, 59.79s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [44:34<04:56, 59.34s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [45:33<03:56, 59.18s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [46:31<02:57, 59.03s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [47:34<02:00, 60.05s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [48:35<01:00, 60.34s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [49:33<00:00, 59.81s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [49:33<00:00, 59.47s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.1891} | avg. gen lenth: 376.84
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o5-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 2048 --num-out-domain 5
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-23 03:28:28,365] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o5-tgsm8k-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 5
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o5-tgsm8k-s20-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|▉                                                                                  | 107/9741 [00:00<00:09, 1064.18it/s]  2%|█▊                                                                                 | 218/9741 [00:00<00:08, 1087.04it/s]  3%|██▊                                                                                | 331/9741 [00:00<00:08, 1105.51it/s]  5%|███▊                                                                               | 444/9741 [00:00<00:08, 1114.07it/s]  6%|████▊                                                                              | 559/9741 [00:00<00:08, 1123.44it/s]  7%|█████▋                                                                             | 673/9741 [00:00<00:08, 1125.99it/s]  8%|██████▋                                                                            | 788/9741 [00:00<00:07, 1130.92it/s]  9%|███████▋                                                                           | 903/9741 [00:00<00:07, 1134.07it/s] 10%|████████▌                                                                         | 1017/9741 [00:00<00:07, 1118.24it/s] 12%|█████████▌                                                                        | 1130/9741 [00:01<00:07, 1121.36it/s] 13%|██████████▍                                                                       | 1244/9741 [00:01<00:07, 1125.64it/s] 14%|███████████▍                                                                      | 1358/9741 [00:01<00:07, 1128.33it/s] 15%|████████████▍                                                                     | 1472/9741 [00:01<00:07, 1131.69it/s] 16%|█████████████▌                                                                    | 1605/9741 [00:01<00:06, 1190.81it/s] 18%|██████████████▉                                                                   | 1771/9741 [00:01<00:05, 1331.45it/s] 20%|████████████████▎                                                                 | 1945/9741 [00:01<00:05, 1451.96it/s] 22%|█████████████████▊                                                                | 2118/9741 [00:01<00:04, 1532.86it/s] 24%|███████████████████▎                                                              | 2292/9741 [00:01<00:04, 1593.56it/s] 25%|████████████████████▊                                                             | 2465/9741 [00:01<00:04, 1632.83it/s] 27%|██████████████████████▏                                                           | 2639/9741 [00:02<00:04, 1664.27it/s] 29%|███████████████████████▋                                                          | 2812/9741 [00:02<00:04, 1681.90it/s] 31%|█████████████████████████▏                                                        | 2986/9741 [00:02<00:03, 1697.48it/s] 32%|██████████████████████████▌                                                       | 3159/9741 [00:02<00:03, 1706.16it/s] 34%|████████████████████████████                                                      | 3333/9741 [00:02<00:03, 1715.20it/s] 36%|█████████████████████████████▌                                                    | 3506/9741 [00:02<00:03, 1717.51it/s] 38%|██████████████████████████████▉                                                   | 3679/9741 [00:02<00:03, 1718.96it/s] 40%|████████████████████████████████▍                                                 | 3851/9741 [00:02<00:03, 1718.15it/s] 41%|█████████████████████████████████▊                                                | 4024/9741 [00:02<00:03, 1719.40it/s] 43%|███████████████████████████████████▎                                              | 4196/9741 [00:02<00:03, 1719.45it/s] 45%|████████████████████████████████████▊                                             | 4369/9741 [00:03<00:03, 1719.98it/s] 47%|██████████████████████████████████████▏                                           | 4541/9741 [00:03<00:03, 1695.11it/s] 48%|███████████████████████████████████████▋                                          | 4711/9741 [00:03<00:03, 1427.49it/s] 50%|█████████████████████████████████████████                                         | 4882/9741 [00:03<00:03, 1501.26it/s] 52%|██████████████████████████████████████████▌                                       | 5055/9741 [00:03<00:03, 1561.60it/s] 54%|████████████████████████████████████████████                                      | 5227/9741 [00:03<00:02, 1604.95it/s] 55%|█████████████████████████████████████████████▍                                    | 5399/9741 [00:03<00:02, 1636.89it/s] 57%|██████████████████████████████████████████████▉                                   | 5572/9741 [00:03<00:02, 1662.09it/s] 59%|████████████████████████████████████████████████▎                                 | 5744/9741 [00:03<00:02, 1676.81it/s] 61%|█████████████████████████████████████████████████▊                                | 5915/9741 [00:03<00:02, 1685.62it/s] 62%|███████████████████████████████████████████████████▏                              | 6087/9741 [00:04<00:02, 1695.64it/s] 64%|████████████████████████████████████████████████████▋                             | 6260/9741 [00:04<00:02, 1704.21it/s] 66%|██████████████████████████████████████████████████████▏                           | 6432/9741 [00:04<00:01, 1708.23it/s] 68%|███████████████████████████████████████████████████████▌                          | 6604/9741 [00:04<00:01, 1708.98it/s] 70%|█████████████████████████████████████████████████████████                         | 6777/9741 [00:04<00:01, 1712.92it/s] 71%|██████████████████████████████████████████████████████████▌                       | 6950/9741 [00:04<00:01, 1716.55it/s] 73%|███████████████████████████████████████████████████████████▉                      | 7122/9741 [00:04<00:01, 1714.04it/s] 75%|█████████████████████████████████████████████████████████████▍                    | 7294/9741 [00:04<00:01, 1714.72it/s] 77%|██████████████████████████████████████████████████████████████▊                   | 7466/9741 [00:04<00:01, 1667.03it/s] 78%|████████████████████████████████████████████████████████████████▎                 | 7634/9741 [00:05<00:01, 1667.19it/s] 80%|█████████████████████████████████████████████████████████████████▋                | 7804/9741 [00:05<00:01, 1675.60it/s] 82%|███████████████████████████████████████████████████████████████████▏              | 7975/9741 [00:05<00:01, 1684.69it/s] 84%|████████████████████████████████████████████████████████████████████▌             | 8146/9741 [00:05<00:00, 1691.21it/s] 85%|██████████████████████████████████████████████████████████████████████            | 8317/9741 [00:05<00:00, 1696.63it/s] 87%|███████████████████████████████████████████████████████████████████████▍          | 8488/9741 [00:05<00:00, 1698.65it/s] 89%|████████████████████████████████████████████████████████████████████████▉         | 8658/9741 [00:05<00:00, 1697.79it/s] 91%|██████████████████████████████████████████████████████████████████████████▎       | 8829/9741 [00:05<00:00, 1700.80it/s] 92%|███████████████████████████████████████████████████████████████████████████▊      | 9000/9741 [00:05<00:00, 1700.14it/s] 94%|█████████████████████████████████████████████████████████████████████████████▏    | 9171/9741 [00:05<00:00, 1702.93it/s] 96%|██████████████████████████████████████████████████████████████████████████████▋   | 9342/9741 [00:06<00:00, 1703.48it/s] 98%|████████████████████████████████████████████████████████████████████████████████  | 9513/9741 [00:06<00:00, 1697.46it/s] 99%|█████████████████████████████████████████████████████████████████████████████████▌| 9683/9741 [00:06<00:00, 1694.11it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:06<00:00, 1561.18it/s]
Load End
Num instances: 1000
[2023-08-23 03:28:45,522] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-23 03:28:48,352] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-23 03:28:48,353] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-23 03:28:48,353] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-23 03:28:48,353] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-23 03:28:48,353] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-23 03:28:48,353] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fe654346a60>
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fe654346940>
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-23 03:28:48,354] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-23 03:28:48,355] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-23 03:28:48,355] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-23 03:28:48,355] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-23 03:28:48,355] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-23 03:28:48,355] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-23 03:28:48,355] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-23 03:28:48,355] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-23 03:28:48,355] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.3906586170196533 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Loading extension module utils...
Time to load utils op: 0.20357298851013184 seconds
Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: 97

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o5-tgsm8k-s20-rFalse
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:57<47:12, 57.80s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:53<45:20, 56.68s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:49<44:02, 56.23s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:45<43:05, 56.20s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [04:40<41:43, 55.64s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [05:37<41:12, 56.18s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [06:34<40:30, 56.51s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [07:29<39:09, 55.95s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [08:25<38:19, 56.09s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [09:23<37:48, 56.71s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [10:19<36:43, 56.49s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [11:16<35:45, 56.46s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [12:11<34:40, 56.24s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [13:08<33:45, 56.27s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [14:05<32:57, 56.49s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [15:01<31:56, 56.37s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [15:58<31:04, 56.49s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [16:54<30:05, 56.41s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [17:51<29:11, 56.51s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [18:49<28:28, 56.96s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [19:45<27:30, 56.90s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [20:45<26:53, 57.62s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [21:41<25:41, 57.11s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [22:38<24:47, 57.20s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [23:34<23:40, 56.80s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [24:30<22:41, 56.73s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [25:27<21:45, 56.75s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [26:25<20:57, 57.18s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [27:22<19:55, 56.92s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [28:17<18:48, 56.43s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [29:13<17:47, 56.20s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [30:11<17:01, 56.74s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [31:08<16:07, 56.91s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [32:03<15:02, 56.39s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [32:59<14:03, 56.25s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [33:56<13:10, 56.50s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [34:52<12:11, 56.28s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [35:48<11:13, 56.11s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [36:43<10:16, 56.02s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [37:39<09:17, 55.73s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [38:35<08:23, 56.00s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [39:30<07:26, 55.77s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [40:27<06:32, 56.12s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [41:25<05:39, 56.62s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [42:22<04:43, 56.75s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [43:21<03:49, 57.33s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [44:19<02:52, 57.49s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [45:16<01:54, 57.38s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [46:12<00:57, 57.15s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [47:08<00:00, 56.72s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [47:08<00:00, 56.57s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.3687} | avg. gen lenth: 373.57
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 2048 --num-out-domain 6
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-23 04:16:07,657] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 6
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o6-tgsm8k-s20-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|█▏                                                                                 | 142/9741 [00:00<00:06, 1416.45it/s]  3%|██▍                                                                                | 288/9741 [00:00<00:06, 1437.17it/s]  4%|███▋                                                                               | 436/9741 [00:00<00:06, 1453.16it/s]  6%|████▉                                                                              | 584/9741 [00:00<00:06, 1460.16it/s]  8%|██████▏                                                                            | 733/9741 [00:00<00:06, 1468.35it/s]  9%|███████▌                                                                           | 883/9741 [00:00<00:06, 1476.33it/s] 11%|████████▋                                                                         | 1034/9741 [00:00<00:05, 1484.55it/s] 12%|█████████▉                                                                        | 1184/9741 [00:00<00:05, 1489.03it/s] 14%|███████████▏                                                                      | 1333/9741 [00:00<00:05, 1460.62it/s] 15%|████████████▍                                                                     | 1481/9741 [00:01<00:05, 1465.92it/s] 17%|█████████████▋                                                                    | 1629/9741 [00:01<00:05, 1469.14it/s] 18%|██████████████▉                                                                   | 1776/9741 [00:01<00:05, 1449.57it/s] 20%|████████████████▏                                                                 | 1925/9741 [00:01<00:05, 1458.85it/s] 21%|█████████████████▍                                                                | 2073/9741 [00:01<00:05, 1462.87it/s] 23%|██████████████████▋                                                               | 2222/9741 [00:01<00:05, 1468.27it/s] 24%|███████████████████▉                                                              | 2371/9741 [00:01<00:05, 1473.30it/s] 26%|█████████████████████▏                                                            | 2520/9741 [00:01<00:04, 1476.78it/s] 27%|██████████████████████▍                                                           | 2668/9741 [00:01<00:04, 1477.66it/s] 29%|███████████████████████▋                                                          | 2816/9741 [00:01<00:04, 1470.96it/s] 30%|████████████████████████▉                                                         | 2964/9741 [00:02<00:04, 1463.49it/s] 32%|██████████████████████████▏                                                       | 3114/9741 [00:02<00:04, 1472.01it/s] 33%|███████████████████████████▍                                                      | 3263/9741 [00:02<00:04, 1474.93it/s] 35%|████████████████████████████▋                                                     | 3411/9741 [00:02<00:04, 1476.03it/s] 37%|█████████████████████████████▉                                                    | 3559/9741 [00:02<00:04, 1476.53it/s] 38%|███████████████████████████████▏                                                  | 3707/9741 [00:02<00:04, 1476.85it/s] 40%|████████████████████████████████▍                                                 | 3855/9741 [00:02<00:03, 1477.70it/s] 41%|█████████████████████████████████▋                                                | 4003/9741 [00:02<00:03, 1478.35it/s] 43%|██████████████████████████████████▉                                               | 4151/9741 [00:02<00:03, 1476.52it/s] 44%|████████████████████████████████████▏                                             | 4299/9741 [00:02<00:03, 1476.25it/s] 46%|█████████████████████████████████████▍                                            | 4448/9741 [00:03<00:03, 1479.07it/s] 47%|██████████████████████████████████████▋                                           | 4596/9741 [00:03<00:03, 1450.45it/s] 49%|███████████████████████████████████████▉                                          | 4742/9741 [00:03<00:04, 1101.07it/s] 50%|█████████████████████████████████████████▏                                        | 4888/9741 [00:03<00:04, 1186.91it/s] 52%|██████████████████████████████████████████▍                                       | 5035/9741 [00:03<00:03, 1257.68it/s] 53%|███████████████████████████████████████████▌                                      | 5182/9741 [00:03<00:03, 1313.14it/s] 55%|████████████████████████████████████████████▊                                     | 5328/9741 [00:03<00:03, 1353.57it/s] 56%|██████████████████████████████████████████████                                    | 5474/9741 [00:03<00:03, 1382.71it/s] 58%|███████████████████████████████████████████████▎                                  | 5621/9741 [00:03<00:02, 1406.53it/s] 59%|████████████████████████████████████████████████▌                                 | 5769/9741 [00:04<00:02, 1426.99it/s] 61%|█████████████████████████████████████████████████▊                                | 5916/9741 [00:04<00:02, 1436.75it/s] 62%|███████████████████████████████████████████████████                               | 6063/9741 [00:04<00:02, 1444.55it/s] 64%|████████████████████████████████████████████████████▎                             | 6210/9741 [00:04<00:02, 1451.85it/s] 65%|█████████████████████████████████████████████████████▌                            | 6356/9741 [00:04<00:02, 1448.79it/s] 67%|██████████████████████████████████████████████████████▋                           | 6502/9741 [00:04<00:02, 1449.01it/s] 68%|███████████████████████████████████████████████████████▉                          | 6648/9741 [00:04<00:02, 1451.16it/s] 70%|█████████████████████████████████████████████████████████▏                        | 6794/9741 [00:04<00:02, 1453.56it/s] 71%|██████████████████████████████████████████████████████████▍                       | 6941/9741 [00:04<00:01, 1456.79it/s] 73%|███████████████████████████████████████████████████████████▋                      | 7087/9741 [00:04<00:01, 1435.99it/s] 74%|████████████████████████████████████████████████████████████▊                     | 7231/9741 [00:05<00:01, 1436.89it/s] 76%|██████████████████████████████████████████████████████████████                    | 7378/9741 [00:05<00:01, 1444.26it/s] 77%|███████████████████████████████████████████████████████████████▎                  | 7523/9741 [00:05<00:01, 1402.12it/s] 79%|████████████████████████████████████████████████████████████████▌                 | 7668/9741 [00:05<00:01, 1414.29it/s] 80%|█████████████████████████████████████████████████████████████████▊                | 7814/9741 [00:05<00:01, 1426.72it/s] 82%|███████████████████████████████████████████████████████████████████               | 7960/9741 [00:05<00:01, 1435.45it/s] 83%|████████████████████████████████████████████████████████████████████▏             | 8105/9741 [00:05<00:01, 1437.64it/s] 85%|█████████████████████████████████████████████████████████████████████▍            | 8250/9741 [00:05<00:01, 1441.12it/s] 86%|██████████████████████████████████████████████████████████████████████▋           | 8395/9741 [00:05<00:00, 1440.10it/s] 88%|███████████████████████████████████████████████████████████████████████▉          | 8542/9741 [00:05<00:00, 1447.76it/s] 89%|█████████████████████████████████████████████████████████████████████████▏        | 8687/9741 [00:06<00:00, 1445.68it/s] 91%|██████████████████████████████████████████████████████████████████████████▎       | 8832/9741 [00:06<00:00, 1443.24it/s] 92%|███████████████████████████████████████████████████████████████████████████▌      | 8977/9741 [00:06<00:00, 1444.77it/s] 94%|████████████████████████████████████████████████████████████████████████████▊     | 9122/9741 [00:06<00:00, 1446.20it/s] 95%|██████████████████████████████████████████████████████████████████████████████    | 9268/9741 [00:06<00:00, 1449.59it/s] 97%|███████████████████████████████████████████████████████████████████████████████▎  | 9415/9741 [00:06<00:00, 1454.13it/s] 98%|████████████████████████████████████████████████████████████████████████████████▍ | 9561/9741 [00:06<00:00, 1450.86it/s]100%|█████████████████████████████████████████████████████████████████████████████████▋| 9707/9741 [00:06<00:00, 1446.01it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:06<00:00, 1433.99it/s]
Load End
Num instances: 1000
[2023-08-23 04:16:25,512] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-23 04:16:28,124] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-23 04:16:28,125] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-23 04:16:28,126] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-23 04:16:28,126] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-23 04:16:28,126] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-23 04:16:28,126] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-23 04:16:28,126] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-23 04:16:28,126] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-23 04:16:28,126] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-23 04:16:28,126] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-23 04:16:28,126] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-23 04:16:28,126] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fa4408a6a60>
[2023-08-23 04:16:28,126] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-23 04:16:28,126] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-23 04:16:28,126] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-23 04:16:28,126] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-23 04:16:28,126] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-23 04:16:28,126] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fa4408a6940>
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-23 04:16:28,127] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-23 04:16:28,128] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-23 04:16:28,128] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-23 04:16:28,128] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-23 04:16:28,128] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-23 04:16:28,128] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-23 04:16:28,128] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-23 04:16:28,128] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-23 04:16:28,128] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-23 04:16:28,128] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-23 04:16:28,128] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-23 04:16:28,128] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-23 04:16:28,128] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-23 04:16:28,128] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-23 04:16:28,128] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-23 04:16:28,128] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-23 04:16:28,128] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-23 04:16:28,128] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-23 04:16:28,128] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-23 04:16:28,128] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-23 04:16:28,128] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4105501174926758 seconds
Loading extension module utils...
Time to load utils op: 0.4046182632446289 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: 97

Input: Nalani had two female dogs that were expecting and after a month gave birth to 10 puppies each. She then sold 3/4 of the puppies after they came of age, each at $200. Calculate the total amount of money she received from the sale of the puppies.
Output: 3000

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o6-tgsm8k-s20-rFalse
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:53<43:57, 53.82s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:48<43:14, 54.06s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:42<42:23, 54.12s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:36<41:40, 54.36s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [04:30<40:25, 53.90s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [05:23<39:27, 53.82s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [06:18<38:49, 54.16s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [07:11<37:43, 53.89s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [08:06<37:01, 54.19s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [09:01<36:08, 54.22s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [09:55<35:12, 54.15s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [10:50<34:36, 54.64s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [11:44<33:30, 54.35s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [12:41<33:01, 55.05s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [13:36<32:09, 55.12s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [14:30<31:02, 54.78s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [15:24<30:03, 54.64s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [16:18<29:00, 54.40s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [17:13<28:08, 54.47s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [18:07<27:17, 54.57s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [19:02<26:21, 54.52s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [19:58<25:36, 54.89s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [20:51<24:27, 54.34s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [21:44<23:23, 53.99s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [22:37<22:23, 53.75s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [23:31<21:28, 53.70s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [24:25<20:36, 53.78s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [25:20<19:53, 54.25s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [26:14<18:59, 54.26s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [27:08<18:02, 54.13s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [28:01<17:02, 53.83s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [28:54<16:05, 53.65s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [29:49<15:15, 53.87s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [30:42<14:19, 53.73s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [31:35<13:23, 53.57s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [32:29<12:28, 53.48s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [33:23<11:37, 53.65s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [34:18<10:49, 54.12s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [35:12<09:54, 54.01s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [36:07<09:04, 54.48s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [37:02<08:10, 54.45s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [37:55<07:13, 54.14s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [38:51<06:22, 54.63s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [39:44<05:25, 54.28s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [40:39<04:31, 54.28s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [41:33<03:36, 54.21s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [42:27<02:42, 54.11s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [43:21<01:48, 54.15s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [44:14<00:53, 53.90s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [45:07<00:00, 53.56s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [45:07<00:00, 54.15s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 0.9835} | avg. gen lenth: 398.958
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o7-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 2048 --num-out-domain 7
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-23 05:01:46,834] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o7-tgsm8k-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 7
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o7-tgsm8k-s20-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|▋                                                                                    | 80/9741 [00:00<00:12, 791.40it/s]  2%|█▍                                                                                  | 163/9741 [00:00<00:11, 811.67it/s]  3%|██                                                                                  | 245/9741 [00:00<00:11, 815.42it/s]  3%|██▊                                                                                 | 329/9741 [00:00<00:11, 823.32it/s]  4%|███▌                                                                                | 412/9741 [00:00<00:11, 825.56it/s]  5%|████▎                                                                               | 496/9741 [00:00<00:11, 830.28it/s]  6%|█████                                                                               | 580/9741 [00:00<00:11, 832.59it/s]  7%|█████▋                                                                              | 664/9741 [00:00<00:11, 810.92it/s]  8%|██████▍                                                                             | 747/9741 [00:00<00:11, 816.62it/s]  9%|███████▏                                                                            | 831/9741 [00:01<00:10, 823.63it/s]  9%|███████▉                                                                            | 915/9741 [00:01<00:10, 826.41it/s] 10%|████████▌                                                                           | 999/9741 [00:01<00:10, 829.96it/s] 11%|█████████▎                                                                         | 1093/9741 [00:01<00:10, 862.58it/s] 13%|██████████▍                                                                        | 1220/9741 [00:01<00:08, 983.95it/s] 14%|███████████▎                                                                      | 1346/9741 [00:01<00:07, 1066.63it/s] 15%|████████████▍                                                                     | 1472/9741 [00:01<00:07, 1122.42it/s] 16%|█████████████▍                                                                    | 1598/9741 [00:01<00:06, 1163.46it/s] 18%|██████████████▌                                                                   | 1724/9741 [00:01<00:06, 1191.79it/s] 19%|███████████████▌                                                                  | 1844/9741 [00:01<00:06, 1188.41it/s] 20%|████████████████▌                                                                 | 1971/9741 [00:02<00:06, 1210.12it/s] 22%|█████████████████▋                                                                | 2096/9741 [00:02<00:06, 1220.54it/s] 23%|██████████████████▋                                                               | 2221/9741 [00:02<00:06, 1228.92it/s] 24%|███████████████████▊                                                              | 2348/9741 [00:02<00:05, 1238.60it/s] 25%|████████████████████▊                                                             | 2474/9741 [00:02<00:05, 1243.42it/s] 27%|█████████████████████▉                                                            | 2601/9741 [00:02<00:05, 1248.84it/s] 28%|██████████████████████▉                                                           | 2727/9741 [00:02<00:05, 1249.69it/s] 29%|████████████████████████                                                          | 2853/9741 [00:02<00:05, 1251.86it/s] 31%|█████████████████████████                                                         | 2979/9741 [00:02<00:05, 1252.19it/s] 32%|██████████████████████████▏                                                       | 3105/9741 [00:02<00:05, 1252.39it/s] 33%|███████████████████████████▏                                                      | 3231/9741 [00:03<00:05, 1249.42it/s] 34%|████████████████████████████▎                                                     | 3356/9741 [00:03<00:05, 1229.42it/s] 36%|█████████████████████████████▎                                                    | 3481/9741 [00:03<00:05, 1234.77it/s] 37%|██████████████████████████████▎                                                   | 3605/9741 [00:03<00:04, 1234.18it/s] 38%|███████████████████████████████▍                                                  | 3731/9741 [00:03<00:04, 1239.52it/s] 40%|████████████████████████████████▍                                                 | 3856/9741 [00:03<00:04, 1240.82it/s] 41%|█████████████████████████████████▌                                                | 3981/9741 [00:03<00:04, 1241.33it/s] 42%|██████████████████████████████████▌                                               | 4106/9741 [00:03<00:04, 1242.33it/s] 43%|███████████████████████████████████▌                                              | 4231/9741 [00:03<00:04, 1242.53it/s] 45%|████████████████████████████████████▋                                             | 4356/9741 [00:03<00:04, 1242.58it/s] 46%|█████████████████████████████████████▋                                            | 4481/9741 [00:04<00:04, 1242.53it/s] 47%|██████████████████████████████████████▊                                           | 4606/9741 [00:04<00:04, 1202.86it/s] 49%|████████████████████████████████████████▎                                          | 4727/9741 [00:04<00:05, 932.28it/s] 50%|████████████████████████████████████████▊                                         | 4850/9741 [00:04<00:04, 1003.77it/s] 51%|█████████████████████████████████████████▊                                        | 4974/9741 [00:04<00:04, 1062.62it/s] 52%|██████████████████████████████████████████▉                                       | 5099/9741 [00:04<00:04, 1111.55it/s] 54%|███████████████████████████████████████████▉                                      | 5223/9741 [00:04<00:03, 1145.77it/s] 55%|████████████████████████████████████████████▉                                     | 5342/9741 [00:04<00:03, 1150.15it/s] 56%|██████████████████████████████████████████████                                    | 5465/9741 [00:04<00:03, 1172.46it/s] 57%|███████████████████████████████████████████████                                   | 5590/9741 [00:05<00:03, 1192.21it/s] 59%|████████████████████████████████████████████████                                  | 5714/9741 [00:05<00:03, 1204.20it/s] 60%|█████████████████████████████████████████████████▏                                | 5836/9741 [00:05<00:03, 1207.79it/s] 61%|██████████████████████████████████████████████████▏                               | 5961/9741 [00:05<00:03, 1218.01it/s] 62%|███████████████████████████████████████████████████▏                              | 6085/9741 [00:05<00:02, 1221.66it/s] 64%|████████████████████████████████████████████████████▎                             | 6209/9741 [00:05<00:02, 1225.47it/s] 65%|█████████████████████████████████████████████████████▎                            | 6332/9741 [00:05<00:02, 1223.06it/s] 66%|██████████████████████████████████████████████████████▎                           | 6456/9741 [00:05<00:02, 1226.36it/s] 68%|███████████████████████████████████████████████████████▍                          | 6579/9741 [00:05<00:02, 1225.89it/s] 69%|████████████████████████████████████████████████████████▍                         | 6702/9741 [00:05<00:02, 1226.93it/s] 70%|█████████████████████████████████████████████████████████▍                        | 6825/9741 [00:06<00:02, 1227.80it/s] 71%|██████████████████████████████████████████████████████████▍                       | 6949/9741 [00:06<00:02, 1228.78it/s] 73%|███████████████████████████████████████████████████████████▌                      | 7072/9741 [00:06<00:02, 1226.25it/s] 74%|████████████████████████████████████████████████████████████▌                     | 7195/9741 [00:06<00:02, 1223.88it/s] 75%|█████████████████████████████████████████████████████████████▌                    | 7318/9741 [00:06<00:01, 1224.48it/s] 76%|██████████████████████████████████████████████████████████████▋                   | 7441/9741 [00:06<00:01, 1196.13it/s] 78%|███████████████████████████████████████████████████████████████▋                  | 7564/9741 [00:06<00:01, 1203.49it/s] 79%|████████████████████████████████████████████████████████████████▋                 | 7686/9741 [00:06<00:01, 1206.95it/s] 80%|█████████████████████████████████████████████████████████████████▋                | 7809/9741 [00:06<00:01, 1213.61it/s] 81%|██████████████████████████████████████████████████████████████████▊               | 7931/9741 [00:06<00:01, 1194.89it/s] 83%|███████████████████████████████████████████████████████████████████▊              | 8051/9741 [00:07<00:01, 1186.56it/s] 84%|████████████████████████████████████████████████████████████████████▊             | 8170/9741 [00:07<00:01, 1186.44it/s] 85%|█████████████████████████████████████████████████████████████████████▊            | 8292/9741 [00:07<00:01, 1194.24it/s] 86%|██████████████████████████████████████████████████████████████████████▊           | 8413/9741 [00:07<00:01, 1197.71it/s] 88%|███████████████████████████████████████████████████████████████████████▊          | 8535/9741 [00:07<00:01, 1202.40it/s] 89%|████████████████████████████████████████████████████████████████████████▊         | 8656/9741 [00:07<00:00, 1203.45it/s] 90%|█████████████████████████████████████████████████████████████████████████▉        | 8777/9741 [00:07<00:00, 1204.47it/s] 91%|██████████████████████████████████████████████████████████████████████████▉       | 8899/9741 [00:07<00:00, 1206.56it/s] 93%|███████████████████████████████████████████████████████████████████████████▉      | 9021/9741 [00:07<00:00, 1207.82it/s] 94%|████████████████████████████████████████████████████████████████████████████▉     | 9143/9741 [00:07<00:00, 1209.71it/s] 95%|█████████████████████████████████████████████████████████████████████████████▉    | 9264/9741 [00:08<00:00, 1207.53it/s] 96%|███████████████████████████████████████████████████████████████████████████████   | 9385/9741 [00:08<00:00, 1204.53it/s] 98%|████████████████████████████████████████████████████████████████████████████████  | 9506/9741 [00:08<00:00, 1201.78it/s] 99%|█████████████████████████████████████████████████████████████████████████████████ | 9627/9741 [00:08<00:00, 1204.21it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:08<00:00, 1148.87it/s]
Load End
Num instances: 1000
[2023-08-23 05:02:06,458] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-23 05:02:11,010] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-23 05:02:11,010] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f173d894a60>
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-23 05:02:11,011] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-23 05:02:11,012] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-23 05:02:11,012] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-23 05:02:11,012] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-23 05:02:11,012] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-23 05:02:11,012] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f173d894940>
[2023-08-23 05:02:11,012] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-23 05:02:11,012] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-23 05:02:11,012] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-23 05:02:11,012] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-23 05:02:11,012] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-23 05:02:11,012] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-23 05:02:11,012] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-23 05:02:11,012] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-23 05:02:11,012] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-23 05:02:11,012] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-23 05:02:11,012] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-23 05:02:11,012] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-23 05:02:11,012] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-23 05:02:11,012] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-23 05:02:11,012] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-23 05:02:11,012] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-23 05:02:11,012] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-23 05:02:11,012] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-23 05:02:11,012] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-23 05:02:11,012] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-23 05:02:11,012] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-23 05:02:11,012] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-23 05:02:11,012] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.46766018867492676 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: 97

Input: Nalani had two female dogs that were expecting and after a month gave birth to 10 puppies each. She then sold 3/4 of the puppies after they came of age, each at $200. Calculate the total amount of money she received from the sale of the puppies.
Output: 3000

Input: Boris has 24 books and he donates a fourth of his books to the library. Cameron has 30 books and he donates a third of his books to the library. After donating their books, how many books in total do Boris and Cameron have together?
Output: 38

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o7-tgsm8k-s20-rFalse
Loading extension module utils...
Time to load utils op: 0.5049927234649658 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:52<43:11, 52.89s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:44<41:38, 52.05s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:36<40:51, 52.17s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:30<40:27, 52.77s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [04:22<39:20, 52.45s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [05:14<38:27, 52.43s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [06:05<37:16, 52.02s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [06:57<36:21, 51.94s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [07:50<35:36, 52.10s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [08:43<34:58, 52.45s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [09:35<33:58, 52.27s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [10:28<33:22, 52.70s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [11:21<32:30, 52.71s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [12:15<31:49, 53.04s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [13:06<30:41, 52.61s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [13:58<29:38, 52.30s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [14:51<28:51, 52.47s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [15:42<27:50, 52.19s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [16:35<26:59, 52.23s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [17:28<26:16, 52.55s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [18:20<25:21, 52.48s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [19:15<24:45, 53.07s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [20:06<23:38, 52.54s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [20:59<22:45, 52.51s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [21:50<21:45, 52.24s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [22:43<21:00, 52.53s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [23:36<20:05, 52.42s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [24:31<19:32, 53.28s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [25:22<18:27, 52.75s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [26:15<17:32, 52.64s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [27:07<16:37, 52.51s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [27:59<15:40, 52.27s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [28:52<14:52, 52.50s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [29:43<13:53, 52.07s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [30:35<13:01, 52.10s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [31:28<12:11, 52.29s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [32:20<11:21, 52.46s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [33:13<10:28, 52.40s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [34:07<09:41, 52.82s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [34:59<08:45, 52.58s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [35:52<07:54, 52.73s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [36:43<06:59, 52.38s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [37:35<06:06, 52.31s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [38:27<05:13, 52.23s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [39:19<04:20, 52.11s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [40:12<03:29, 52.34s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [41:04<02:36, 52.26s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [41:57<01:44, 52.48s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [42:49<00:52, 52.26s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [43:40<00:00, 52.02s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [43:40<00:00, 52.42s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.1306} | avg. gen lenth: 397.404
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 2048 --num-out-domain 8
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-23 05:46:00,373] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 8
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o8-tgsm8k-s20-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|▋                                                                                    | 73/9741 [00:00<00:13, 726.72it/s]  2%|█▎                                                                                  | 149/9741 [00:00<00:12, 744.69it/s]  2%|█▉                                                                                  | 224/9741 [00:00<00:13, 725.42it/s]  3%|██▌                                                                                 | 300/9741 [00:00<00:12, 735.69it/s]  4%|███▏                                                                                | 376/9741 [00:00<00:12, 743.23it/s]  5%|███▉                                                                                | 451/9741 [00:00<00:12, 744.77it/s]  5%|████▌                                                                               | 527/9741 [00:00<00:12, 748.92it/s]  6%|█████▏                                                                              | 603/9741 [00:00<00:12, 752.36it/s]  7%|█████▊                                                                              | 679/9741 [00:00<00:12, 753.97it/s]  8%|██████▌                                                                             | 756/9741 [00:01<00:11, 757.07it/s]  9%|███████▏                                                                            | 833/9741 [00:01<00:11, 759.34it/s]  9%|███████▊                                                                            | 910/9741 [00:01<00:11, 759.86it/s] 10%|████████▌                                                                           | 986/9741 [00:01<00:11, 759.39it/s] 11%|█████████                                                                          | 1063/9741 [00:01<00:11, 760.50it/s] 12%|█████████▋                                                                         | 1140/9741 [00:01<00:11, 760.87it/s] 12%|██████████▎                                                                        | 1217/9741 [00:01<00:11, 760.26it/s] 13%|███████████                                                                        | 1294/9741 [00:01<00:11, 760.58it/s] 14%|███████████▋                                                                       | 1371/9741 [00:01<00:11, 759.20it/s] 15%|████████████▎                                                                      | 1448/9741 [00:01<00:10, 759.76it/s] 16%|████████████▉                                                                      | 1525/9741 [00:02<00:10, 760.38it/s] 16%|█████████████▋                                                                     | 1602/9741 [00:02<00:10, 760.26it/s] 17%|██████████████▎                                                                    | 1679/9741 [00:02<00:10, 761.16it/s] 18%|██████████████▉                                                                    | 1756/9741 [00:02<00:10, 761.23it/s] 19%|███████████████▌                                                                   | 1833/9741 [00:02<00:10, 744.52it/s] 20%|████████████████▎                                                                  | 1910/9741 [00:02<00:10, 749.60it/s] 20%|████████████████▉                                                                  | 1986/9741 [00:02<00:10, 738.85it/s] 21%|█████████████████▌                                                                 | 2066/9741 [00:02<00:10, 756.65it/s] 22%|██████████████████▌                                                                | 2180/9741 [00:02<00:08, 869.28it/s] 24%|███████████████████▌                                                               | 2294/9741 [00:02<00:07, 947.97it/s] 25%|████████████████████▎                                                             | 2409/9741 [00:03<00:07, 1006.56it/s] 26%|█████████████████████▏                                                            | 2523/9741 [00:03<00:06, 1045.11it/s] 27%|██████████████████████▏                                                           | 2638/9741 [00:03<00:06, 1074.15it/s] 28%|███████████████████████▏                                                          | 2752/9741 [00:03<00:06, 1092.46it/s] 29%|████████████████████████▏                                                         | 2867/9741 [00:03<00:06, 1108.10it/s] 31%|█████████████████████████                                                         | 2981/9741 [00:03<00:06, 1115.79it/s] 32%|██████████████████████████                                                        | 3096/9741 [00:03<00:05, 1123.48it/s] 33%|███████████████████████████                                                       | 3210/9741 [00:03<00:05, 1127.31it/s] 34%|███████████████████████████▉                                                      | 3324/9741 [00:03<00:05, 1130.92it/s] 35%|████████████████████████████▉                                                     | 3438/9741 [00:03<00:05, 1129.81it/s] 36%|█████████████████████████████▉                                                    | 3552/9741 [00:04<00:05, 1131.36it/s] 38%|██████████████████████████████▊                                                   | 3666/9741 [00:04<00:05, 1130.49it/s] 39%|███████████████████████████████▊                                                  | 3781/9741 [00:04<00:05, 1133.33it/s] 40%|████████████████████████████████▊                                                 | 3895/9741 [00:04<00:05, 1117.38it/s] 41%|█████████████████████████████████▋                                                | 4009/9741 [00:04<00:05, 1122.16it/s] 42%|██████████████████████████████████▋                                               | 4123/9741 [00:04<00:04, 1124.92it/s] 43%|███████████████████████████████████▋                                              | 4237/9741 [00:04<00:04, 1127.16it/s] 45%|████████████████████████████████████▌                                             | 4350/9741 [00:04<00:04, 1126.74it/s] 46%|█████████████████████████████████████▌                                            | 4463/9741 [00:04<00:04, 1126.89it/s] 47%|██████████████████████████████████████▌                                           | 4576/9741 [00:04<00:04, 1090.72it/s] 48%|███████████████████████████████████████▍                                          | 4689/9741 [00:05<00:04, 1102.12it/s] 49%|████████████████████████████████████████▉                                          | 4800/9741 [00:05<00:05, 854.83it/s] 50%|█████████████████████████████████████████▊                                         | 4913/9741 [00:05<00:05, 920.78it/s] 52%|██████████████████████████████████████████▊                                        | 5027/9741 [00:05<00:04, 975.54it/s] 53%|███████████████████████████████████████████▎                                      | 5140/9741 [00:05<00:04, 1015.74it/s] 54%|████████████████████████████████████████████▏                                     | 5253/9741 [00:05<00:04, 1046.98it/s] 55%|█████████████████████████████████████████████▏                                    | 5366/9741 [00:05<00:04, 1069.40it/s] 56%|██████████████████████████████████████████████                                    | 5479/9741 [00:05<00:03, 1084.85it/s] 57%|███████████████████████████████████████████████                                   | 5591/9741 [00:05<00:03, 1094.57it/s] 59%|████████████████████████████████████████████████                                  | 5704/9741 [00:06<00:03, 1102.39it/s] 60%|████████████████████████████████████████████████▉                                 | 5817/9741 [00:06<00:03, 1108.93it/s] 61%|█████████████████████████████████████████████████▉                                | 5929/9741 [00:06<00:03, 1110.95it/s] 62%|██████████████████████████████████████████████████▊                               | 6042/9741 [00:06<00:03, 1114.88it/s] 63%|███████████████████████████████████████████████████▊                              | 6154/9741 [00:06<00:03, 1100.44it/s] 64%|████████████████████████████████████████████████████▋                             | 6266/9741 [00:06<00:03, 1104.81it/s] 65%|█████████████████████████████████████████████████████▋                            | 6377/9741 [00:06<00:03, 1104.40it/s] 67%|██████████████████████████████████████████████████████▌                           | 6489/9741 [00:06<00:02, 1108.46it/s] 68%|███████████████████████████████████████████████████████▌                          | 6600/9741 [00:06<00:02, 1107.24it/s] 69%|████████████████████████████████████████████████████████▌                         | 6712/9741 [00:06<00:02, 1109.86it/s] 70%|█████████████████████████████████████████████████████████▍                        | 6824/9741 [00:07<00:02, 1110.73it/s] 71%|██████████████████████████████████████████████████████████▍                       | 6936/9741 [00:07<00:02, 1112.99it/s] 72%|███████████████████████████████████████████████████████████▎                      | 7048/9741 [00:07<00:02, 1113.86it/s] 74%|████████████████████████████████████████████████████████████▎                     | 7161/9741 [00:07<00:02, 1117.73it/s] 75%|█████████████████████████████████████████████████████████████▏                    | 7273/9741 [00:07<00:02, 1116.99it/s] 76%|██████████████████████████████████████████████████████████████▏                   | 7386/9741 [00:07<00:02, 1118.14it/s] 77%|███████████████████████████████████████████████████████████████                   | 7498/9741 [00:07<00:02, 1083.40it/s] 78%|████████████████████████████████████████████████████████████████                  | 7609/9741 [00:07<00:01, 1089.78it/s] 79%|████████████████████████████████████████████████████████████████▉                 | 7721/9741 [00:07<00:01, 1096.22it/s] 80%|█████████████████████████████████████████████████████████████████▉                | 7833/9741 [00:07<00:01, 1100.83it/s] 82%|██████████████████████████████████████████████████████████████████▊               | 7944/9741 [00:08<00:01, 1100.79it/s] 83%|███████████████████████████████████████████████████████████████████▊              | 8055/9741 [00:08<00:01, 1103.06it/s] 84%|████████████████████████████████████████████████████████████████████▋             | 8166/9741 [00:08<00:01, 1099.53it/s] 85%|█████████████████████████████████████████████████████████████████████▋            | 8278/9741 [00:08<00:01, 1104.77it/s] 86%|██████████████████████████████████████████████████████████████████████▌           | 8389/9741 [00:08<00:01, 1104.18it/s] 87%|███████████████████████████████████████████████████████████████████████▌          | 8501/9741 [00:08<00:01, 1108.60it/s] 88%|████████████████████████████████████████████████████████████████████████▍         | 8612/9741 [00:08<00:01, 1106.37it/s] 90%|█████████████████████████████████████████████████████████████████████████▍        | 8724/9741 [00:08<00:00, 1109.37it/s] 91%|██████████████████████████████████████████████████████████████████████████▎       | 8835/9741 [00:08<00:00, 1108.20it/s] 92%|███████████████████████████████████████████████████████████████████████████▎      | 8948/9741 [00:09<00:00, 1112.18it/s] 93%|████████████████████████████████████████████████████████████████████████████▎     | 9060/9741 [00:09<00:00, 1112.36it/s] 94%|█████████████████████████████████████████████████████████████████████████████▏    | 9173/9741 [00:09<00:00, 1114.89it/s] 95%|██████████████████████████████████████████████████████████████████████████████▏   | 9285/9741 [00:09<00:00, 1110.99it/s] 96%|███████████████████████████████████████████████████████████████████████████████   | 9397/9741 [00:09<00:00, 1110.83it/s] 98%|████████████████████████████████████████████████████████████████████████████████  | 9509/9741 [00:09<00:00, 1108.87it/s] 99%|████████████████████████████████████████████████████████████████████████████████▉ | 9621/9741 [00:09<00:00, 1109.74it/s]100%|█████████████████████████████████████████████████████████████████████████████████▉| 9732/9741 [00:09<00:00, 1105.34it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:09<00:00, 1002.37it/s]
Load End
Num instances: 1000
[2023-08-23 05:46:21,609] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-23 05:46:24,461] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-23 05:46:24,461] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-23 05:46:24,461] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-23 05:46:24,461] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-23 05:46:24,461] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-23 05:46:24,461] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f051e946a60>
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f051e946940>
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-23 05:46:24,462] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-23 05:46:24,463] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-23 05:46:24,463] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-23 05:46:24,463] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-23 05:46:24,463] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-23 05:46:24,463] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-23 05:46:24,463] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-23 05:46:24,463] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-23 05:46:24,463] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-23 05:46:24,463] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-23 05:46:24,463] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-23 05:46:24,463] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-23 05:46:24,463] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-23 05:46:24,463] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-23 05:46:24,463] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-23 05:46:24,463] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-23 05:46:24,463] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-23 05:46:24,463] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4332761764526367 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: 97

Input: Nalani had two female dogs that were expecting and after a month gave birth to 10 puppies each. She then sold 3/4 of the puppies after they came of age, each at $200. Calculate the total amount of money she received from the sale of the puppies.
Output: 3000

Input: Boris has 24 books and he donates a fourth of his books to the library. Cameron has 30 books and he donates a third of his books to the library. After donating their books, how many books in total do Boris and Cameron have together?
Output: 38

Input: There are 3 boxes of cereal. One box holds 14 ounces of cereal. Another box holds half the amount of the first box and 5 ounces less than the third box. How much cereal is there in all 3 cereal boxes?
Output: 33

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o8-tgsm8k-s20-rFalse
Loading extension module utils...
Time to load utils op: 0.5053627490997314 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:51<41:55, 51.33s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:41<40:43, 50.91s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:31<39:26, 50.36s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:22<38:46, 50.58s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [04:12<37:44, 50.32s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [05:01<36:37, 49.95s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [05:51<35:42, 49.83s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [06:40<34:39, 49.52s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [07:30<33:56, 49.66s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [08:20<33:15, 49.89s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [09:10<32:28, 49.97s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [10:00<31:42, 50.07s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [10:51<30:59, 50.24s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [11:41<30:10, 50.29s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [12:32<29:23, 50.37s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [13:24<28:50, 50.90s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [14:15<27:58, 50.87s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [15:04<26:53, 50.41s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [15:54<25:52, 50.09s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [16:44<25:07, 50.26s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [17:34<24:09, 49.97s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [18:25<23:31, 50.42s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [19:16<22:44, 50.55s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [20:06<21:53, 50.51s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [20:56<20:55, 50.24s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [21:46<20:06, 50.25s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [22:35<19:08, 49.95s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [23:27<18:31, 50.52s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [24:18<17:44, 50.71s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [25:09<16:55, 50.79s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [26:00<16:06, 50.85s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [26:51<15:11, 50.62s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [27:40<14:16, 50.38s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [28:29<13:19, 49.94s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [29:19<12:29, 49.95s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [30:10<11:43, 50.23s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [31:00<10:53, 50.27s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [31:52<10:09, 50.78s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [32:42<09:13, 50.31s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [33:32<08:21, 50.18s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [34:21<07:30, 50.06s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [35:11<06:40, 50.10s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [36:02<05:51, 50.23s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [36:53<05:02, 50.38s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [37:43<04:11, 50.29s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [38:33<03:20, 50.15s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [39:23<02:31, 50.34s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [40:14<01:40, 50.46s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [41:04<00:50, 50.19s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [41:54<00:00, 50.33s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [41:54<00:00, 50.30s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.1534} | avg. gen lenth: 404.162
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o9-tgsm8k-s20-rFalse --seed 20 --max-prompt-length 2048 --num-out-domain 9
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date![nltk_data]   Package punkt is already up-to-date!

using world size: 2
[2023-08-23 06:28:29,793] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o9-tgsm8k-s20-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 9
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o9-tgsm8k-s20-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|▌                                                                                    | 65/9741 [00:00<00:15, 640.96it/s]  1%|█▏                                                                                  | 133/9741 [00:00<00:14, 658.49it/s]  2%|█▋                                                                                  | 201/9741 [00:00<00:14, 663.83it/s]  3%|██▎                                                                                 | 269/9741 [00:00<00:14, 669.44it/s]  3%|██▉                                                                                 | 338/9741 [00:00<00:13, 674.56it/s]  4%|███▌                                                                                | 406/9741 [00:00<00:13, 675.85it/s]  5%|████                                                                                | 475/9741 [00:00<00:13, 679.92it/s]  6%|████▋                                                                               | 544/9741 [00:00<00:13, 682.82it/s]  6%|█████▎                                                                              | 613/9741 [00:00<00:13, 666.99it/s]  7%|█████▊                                                                              | 681/9741 [00:01<00:13, 668.52it/s]  8%|██████▍                                                                             | 750/9741 [00:01<00:13, 674.16it/s]  9%|███████▎                                                                            | 846/9741 [00:01<00:11, 759.97it/s] 10%|████████▏                                                                           | 949/9741 [00:01<00:10, 840.78it/s] 11%|████████▉                                                                          | 1054/9741 [00:01<00:09, 901.09it/s] 12%|█████████▊                                                                         | 1158/9741 [00:01<00:09, 941.60it/s] 13%|██████████▊                                                                        | 1262/9741 [00:01<00:08, 969.68it/s] 14%|███████████▋                                                                       | 1366/9741 [00:01<00:08, 987.97it/s] 15%|████████████▌                                                                      | 1469/9741 [00:01<00:08, 999.54it/s] 16%|█████████████▏                                                                    | 1572/9741 [00:01<00:08, 1008.02it/s] 17%|██████████████                                                                    | 1676/9741 [00:02<00:07, 1017.47it/s] 18%|██████████████▉                                                                   | 1778/9741 [00:02<00:07, 1004.75it/s] 19%|███████████████▊                                                                  | 1882/9741 [00:02<00:07, 1013.65it/s] 20%|████████████████▋                                                                 | 1986/9741 [00:02<00:07, 1017.32it/s] 21%|█████████████████▌                                                                | 2089/9741 [00:02<00:07, 1020.58it/s] 23%|██████████████████▍                                                               | 2193/9741 [00:02<00:07, 1025.40it/s] 24%|███████████████████▎                                                              | 2296/9741 [00:02<00:07, 1026.65it/s] 25%|████████████████████▏                                                             | 2400/9741 [00:02<00:07, 1029.72it/s] 26%|█████████████████████                                                             | 2503/9741 [00:02<00:07, 1028.41it/s] 27%|█████████████████████▉                                                            | 2607/9741 [00:02<00:06, 1029.89it/s] 28%|██████████████████████▊                                                           | 2710/9741 [00:03<00:06, 1027.90it/s] 29%|███████████████████████▋                                                          | 2813/9741 [00:03<00:06, 1026.91it/s] 30%|████████████████████████▌                                                         | 2917/9741 [00:03<00:06, 1027.94it/s] 31%|█████████████████████████▍                                                        | 3021/9741 [00:03<00:06, 1029.55it/s] 32%|██████████████████████████▎                                                       | 3124/9741 [00:03<00:06, 1028.99it/s] 33%|███████████████████████████▏                                                      | 3228/9741 [00:03<00:06, 1029.75it/s] 34%|████████████████████████████                                                      | 3331/9741 [00:03<00:06, 1028.76it/s] 35%|████████████████████████████▉                                                     | 3434/9741 [00:03<00:06, 1027.27it/s] 36%|█████████████████████████████▊                                                    | 3537/9741 [00:03<00:06, 1026.34it/s] 37%|██████████████████████████████▋                                                   | 3640/9741 [00:03<00:05, 1022.55it/s] 38%|███████████████████████████████▌                                                  | 3743/9741 [00:04<00:05, 1024.71it/s] 39%|████████████████████████████████▍                                                 | 3846/9741 [00:04<00:05, 1023.50it/s] 41%|█████████████████████████████████▎                                                | 3950/9741 [00:04<00:05, 1025.35it/s] 42%|██████████████████████████████████                                                | 4053/9741 [00:04<00:05, 1024.67it/s] 43%|██████████████████████████████████▉                                               | 4156/9741 [00:04<00:05, 1023.81it/s] 44%|███████████████████████████████████▊                                              | 4259/9741 [00:04<00:05, 1020.24it/s] 45%|████████████████████████████████████▋                                             | 4362/9741 [00:04<00:05, 1022.02it/s] 46%|█████████████████████████████████████▌                                            | 4465/9741 [00:04<00:05, 1023.85it/s] 47%|██████████████████████████████████████▉                                            | 4568/9741 [00:04<00:05, 996.81it/s] 48%|███████████████████████████████████████▎                                          | 4671/9741 [00:04<00:05, 1003.93it/s] 49%|████████████████████████████████████████▋                                          | 4772/9741 [00:05<00:06, 777.58it/s] 50%|█████████████████████████████████████████▌                                         | 4874/9741 [00:05<00:05, 836.30it/s] 51%|██████████████████████████████████████████▍                                        | 4976/9741 [00:05<00:05, 882.83it/s] 52%|███████████████████████████████████████████▎                                       | 5079/9741 [00:05<00:05, 920.50it/s] 53%|████████████████████████████████████████████▏                                      | 5181/9741 [00:05<00:04, 946.97it/s] 54%|█████████████████████████████████████████████                                      | 5283/9741 [00:05<00:04, 967.59it/s] 55%|█████████████████████████████████████████████▊                                     | 5383/9741 [00:05<00:04, 965.10it/s] 56%|██████████████████████████████████████████████▋                                    | 5485/9741 [00:05<00:04, 978.90it/s] 57%|███████████████████████████████████████████████▌                                   | 5587/9741 [00:05<00:04, 989.29it/s] 58%|████████████████████████████████████████████████▍                                  | 5688/9741 [00:06<00:04, 995.36it/s] 59%|████████████████████████████████████████████████▋                                 | 5790/9741 [00:06<00:03, 1001.76it/s] 60%|█████████████████████████████████████████████████▌                                | 5892/9741 [00:06<00:03, 1004.83it/s] 62%|██████████████████████████████████████████████████▍                               | 5995/9741 [00:06<00:03, 1009.44it/s] 63%|███████████████████████████████████████████████████▎                              | 6097/9741 [00:06<00:03, 1010.68it/s] 64%|████████████████████████████████████████████████████▏                             | 6199/9741 [00:06<00:03, 1012.49it/s] 65%|█████████████████████████████████████████████████████                             | 6301/9741 [00:06<00:03, 1010.19it/s] 66%|█████████████████████████████████████████████████████▉                            | 6403/9741 [00:06<00:03, 1009.81it/s] 67%|██████████████████████████████████████████████████████▊                           | 6505/9741 [00:06<00:03, 1009.24it/s] 68%|███████████████████████████████████████████████████████▌                          | 6606/9741 [00:06<00:03, 1008.94it/s] 69%|████████████████████████████████████████████████████████▍                         | 6708/9741 [00:07<00:03, 1009.76it/s] 70%|█████████████████████████████████████████████████████████▎                        | 6810/9741 [00:07<00:02, 1010.12it/s] 71%|██████████████████████████████████████████████████████████▏                       | 6912/9741 [00:07<00:02, 1011.91it/s] 72%|███████████████████████████████████████████████████████████                       | 7014/9741 [00:07<00:02, 1010.70it/s] 73%|███████████████████████████████████████████████████████████▉                      | 7116/9741 [00:07<00:02, 1012.28it/s] 74%|████████████████████████████████████████████████████████████▊                     | 7218/9741 [00:07<00:02, 1011.07it/s] 75%|█████████████████████████████████████████████████████████████▌                    | 7320/9741 [00:07<00:02, 1010.93it/s] 76%|███████████████████████████████████████████████████████████████▏                   | 7422/9741 [00:07<00:02, 982.19it/s] 77%|████████████████████████████████████████████████████████████████                   | 7523/9741 [00:07<00:02, 990.06it/s] 78%|████████████████████████████████████████████████████████████████▉                  | 7625/9741 [00:07<00:02, 996.36it/s] 79%|█████████████████████████████████████████████████████████████████▊                 | 7726/9741 [00:08<00:02, 997.70it/s] 80%|█████████████████████████████████████████████████████████████████▉                | 7827/9741 [00:08<00:01, 1000.97it/s] 81%|██████████████████████████████████████████████████████████████████▋               | 7928/9741 [00:08<00:01, 1002.47it/s] 82%|███████████████████████████████████████████████████████████████████▌              | 8029/9741 [00:08<00:01, 1003.59it/s] 83%|████████████████████████████████████████████████████████████████████▍             | 8130/9741 [00:08<00:01, 1004.88it/s] 85%|█████████████████████████████████████████████████████████████████████▎            | 8232/9741 [00:08<00:01, 1006.48it/s] 86%|██████████████████████████████████████████████████████████████████████▏           | 8333/9741 [00:08<00:01, 1004.34it/s] 87%|███████████████████████████████████████████████████████████████████████▊           | 8434/9741 [00:08<00:01, 989.58it/s] 88%|████████████████████████████████████████████████████████████████████████▋          | 8535/9741 [00:08<00:01, 993.80it/s] 89%|█████████████████████████████████████████████████████████████████████████▌         | 8635/9741 [00:08<00:01, 993.40it/s] 90%|██████████████████████████████████████████████████████████████████████████▍        | 8736/9741 [00:09<00:01, 996.65it/s] 91%|███████████████████████████████████████████████████████████████████████████▎       | 8836/9741 [00:09<00:00, 993.18it/s] 92%|████████████████████████████████████████████████████████████████████████████▏      | 8938/9741 [00:09<00:00, 998.53it/s] 93%|█████████████████████████████████████████████████████████████████████████████      | 9038/9741 [00:09<00:00, 998.46it/s] 94%|████████████████████████████████████████████████████████████████████████████▉     | 9139/9741 [00:09<00:00, 1000.16it/s] 95%|██████████████████████████████████████████████████████████████████████████████▋    | 9240/9741 [00:09<00:00, 997.84it/s] 96%|██████████████████████████████████████████████████████████████████████████████▋   | 9341/9741 [00:09<00:00, 1000.06it/s] 97%|███████████████████████████████████████████████████████████████████████████████▍  | 9442/9741 [00:09<00:00, 1000.89it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▎ | 9543/9741 [00:09<00:00, 998.57it/s] 99%|██████████████████████████████████████████████████████████████████████████████████▏| 9644/9741 [00:10<00:00, 999.53it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:10<00:00, 964.35it/s]
Load End
Num instances: 1000
[2023-08-23 06:28:50,978] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-23 06:28:54,138] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-23 06:28:54,139] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-23 06:28:54,139] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-23 06:28:54,139] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-23 06:28:54,139] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-23 06:28:54,139] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-23 06:28:54,139] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-23 06:28:54,139] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f05f98f2a60>
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f05f98f2940>
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-23 06:28:54,140] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-23 06:28:54,141] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-23 06:28:54,141] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-23 06:28:54,141] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-23 06:28:54,141] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.43708324432373047 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Tapanga and Corey have 66 candies together. However, Tapanga has 8 more candies than Corey. How many candies does Corey have?
Output: 29

Input: Freddy is calling his family on New Year's Eve. He calls his dad, who lives in the same city as him, and they talk for 45 minutes. Then he calls his brother, who lives on the other side of the world, and they talk for 31 minutes. Local calls cost 5 cents a minute, while international calls cost 25 cents a minute. How many dollars did Freddy spend calling his family on New Year's Eve?
Output: 10

Input: Lawrence worked 8 hours each day on Monday, Tuesday and Friday. He worked 5.5 hours on both Wednesday and Thursday. How many hours would Lawrence work each day if he worked the same number of hours each day?
Output: 5

Input: Ali had a stock of 800 books in his Room. He sold 60 on Monday, 10 on Tuesday, 20 on Wednesday, 44 on Thursday and 66 on Friday. How many books were not sold?
Output: 600

Input: Michael makes birdhouses to sell at craft shows. He charges $22 for each large birdhouse, $16 for each medium birdhouse, and $7 for each small birdhouse. This week, he sold 2 large birdhouses, 2 medium birdhouses, and 3 small birdhouses. How much money, in dollars, did he make this week?
Output: 97

Input: Nalani had two female dogs that were expecting and after a month gave birth to 10 puppies each. She then sold 3/4 of the puppies after they came of age, each at $200. Calculate the total amount of money she received from the sale of the puppies.
Output: 3000

Input: Boris has 24 books and he donates a fourth of his books to the library. Cameron has 30 books and he donates a third of his books to the library. After donating their books, how many books in total do Boris and Cameron have together?
Output: 38

Input: There are 3 boxes of cereal. One box holds 14 ounces of cereal. Another box holds half the amount of the first box and 5 ounces less than the third box. How much cereal is there in all 3 cereal boxes?
Output: 33

Input: A jug needs 40 cups of water to be full. A custodian at Truman Elementary School has to fill water jugs for 200 students, who drink 10 cups of water in a day. How many water jugs will the custodian fill with cups of water to provide the students with all the water they need in a day?
Output: 50

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o9-tgsm8k-s20-rFalse
Loading extension module utils...
Time to load utils op: 0.5032861232757568 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:47<39:00, 47.76s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:35<38:20, 47.93s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:23<37:19, 47.65s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:10<36:29, 47.60s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [03:57<35:37, 47.50s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [04:45<34:47, 47.43s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [05:33<34:10, 47.69s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [06:21<33:22, 47.68s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [07:10<32:57, 48.24s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [07:59<32:19, 48.50s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [08:47<31:23, 48.29s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [09:35<30:34, 48.27s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [10:24<29:48, 48.33s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [11:13<29:13, 48.71s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [12:02<28:20, 48.57s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [12:49<27:22, 48.32s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [13:38<26:42, 48.55s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [14:28<26:00, 48.78s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [15:17<25:14, 48.87s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [16:05<24:22, 48.75s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [16:55<23:44, 49.11s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [17:45<23:04, 49.43s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [18:33<22:02, 48.97s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [19:21<21:00, 48.50s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [20:08<20:06, 48.26s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [20:57<19:23, 48.46s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [21:44<18:25, 48.07s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [22:35<17:54, 48.83s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [23:23<17:02, 48.68s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [24:11<16:05, 48.26s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [24:58<15:10, 47.94s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [25:45<14:18, 47.71s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [26:34<13:36, 48.05s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [27:23<12:52, 48.25s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [28:11<12:03, 48.22s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [28:58<11:11, 47.96s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [29:47<10:28, 48.34s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [30:36<09:40, 48.37s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [31:25<08:55, 48.68s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [32:13<08:05, 48.55s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [33:02<07:16, 48.48s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [33:49<06:24, 48.10s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [34:38<05:38, 48.36s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [35:26<04:50, 48.34s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [36:14<04:00, 48.11s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [37:02<03:13, 48.26s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [37:50<02:24, 48.07s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [38:38<01:36, 48.09s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [39:27<00:48, 48.26s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [40:14<00:00, 48.07s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [40:14<00:00, 48.30s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 0.8431} | avg. gen lenth: 416.702
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s30-rTrue --seed 30 --max-prompt-length 2048 --rationales --num-out-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-23 07:09:18,663] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s30-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 1
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o1-tgsm8k-s30-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  2%|█▋                                                                                 | 200/9741 [00:00<00:04, 1993.52it/s]  4%|███▍                                                                               | 410/9741 [00:00<00:04, 2053.61it/s]  6%|█████▎                                                                             | 623/9741 [00:00<00:04, 2085.05it/s]  9%|███████                                                                            | 836/9741 [00:00<00:04, 2099.71it/s] 11%|████████▊                                                                         | 1050/9741 [00:00<00:04, 2114.12it/s] 13%|██████████▋                                                                       | 1266/9741 [00:00<00:03, 2126.73it/s] 15%|████████████▍                                                                     | 1481/9741 [00:00<00:03, 2133.29it/s] 17%|██████████████▎                                                                   | 1698/9741 [00:00<00:03, 2143.18it/s] 20%|████████████████                                                                  | 1913/9741 [00:00<00:03, 2086.63it/s] 22%|█████████████████▊                                                                | 2122/9741 [00:01<00:03, 2085.57it/s] 24%|███████████████████▋                                                              | 2337/9741 [00:01<00:03, 2103.49it/s] 26%|█████████████████████▍                                                            | 2553/9741 [00:01<00:03, 2118.06it/s] 28%|███████████████████████▎                                                          | 2768/9741 [00:01<00:03, 2125.27it/s] 31%|█████████████████████████                                                         | 2982/9741 [00:01<00:03, 2129.19it/s] 33%|██████████████████████████▉                                                       | 3199/9741 [00:01<00:03, 2138.43it/s] 35%|█████████████████████████████                                                     | 3445/9741 [00:01<00:02, 2233.44it/s] 39%|███████████████████████████████▊                                                  | 3772/9741 [00:01<00:02, 2542.60it/s] 42%|██████████████████████████████████▌                                               | 4103/9741 [00:01<00:02, 2771.05it/s] 45%|█████████████████████████████████████▎                                            | 4431/9741 [00:01<00:01, 2921.47it/s] 48%|███████████████████████████████████████▊                                          | 4724/9741 [00:02<00:02, 2315.21it/s] 52%|██████████████████████████████████████████▌                                       | 5055/9741 [00:02<00:01, 2566.03it/s] 55%|█████████████████████████████████████████████▎                                    | 5381/9741 [00:02<00:01, 2749.82it/s] 59%|████████████████████████████████████████████████                                  | 5714/9741 [00:02<00:01, 2908.48it/s] 62%|██████████████████████████████████████████████████▉                               | 6049/9741 [00:02<00:01, 3031.15it/s] 65%|█████████████████████████████████████████████████████▋                            | 6380/9741 [00:02<00:01, 3108.95it/s] 69%|████████████████████████████████████████████████████████▍                         | 6710/9741 [00:02<00:00, 3162.48it/s] 72%|███████████████████████████████████████████████████████████▎                      | 7047/9741 [00:02<00:00, 3221.30it/s] 76%|██████████████████████████████████████████████████████████████▏                   | 7384/9741 [00:02<00:00, 3262.95it/s] 79%|████████████████████████████████████████████████████████████████▉                 | 7713/9741 [00:03<00:00, 3246.49it/s] 83%|███████████████████████████████████████████████████████████████████▋              | 8047/9741 [00:03<00:00, 3273.55it/s] 86%|██████████████████████████████████████████████████████████████████████▌           | 8376/9741 [00:03<00:00, 3260.29it/s] 89%|█████████████████████████████████████████████████████████████████████████▎        | 8703/9741 [00:03<00:00, 3247.34it/s] 93%|████████████████████████████████████████████████████████████████████████████      | 9029/9741 [00:03<00:00, 3230.55it/s] 96%|██████████████████████████████████████████████████████████████████████████████▊   | 9364/9741 [00:03<00:00, 3263.47it/s]100%|█████████████████████████████████████████████████████████████████████████████████▋| 9698/9741 [00:03<00:00, 3284.26it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:03<00:00, 2687.27it/s]
Load End
Num instances: 1000
[2023-08-23 07:09:33,198] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-23 07:09:36,622] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-23 07:09:36,622] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-23 07:09:36,623] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-23 07:09:36,623] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-23 07:09:36,623] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-23 07:09:36,623] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-23 07:09:36,623] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-23 07:09:36,623] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-23 07:09:36,623] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-23 07:09:36,623] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-23 07:09:36,623] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-23 07:09:36,623] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f45ce81da60>
[2023-08-23 07:09:36,623] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-23 07:09:36,623] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-23 07:09:36,623] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-23 07:09:36,623] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-23 07:09:36,623] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-23 07:09:36,623] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f45ce81d940>
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-23 07:09:36,624] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-23 07:09:36,624] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.43097376823425293 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: The car-rental agency charges $30/day for a car, or $190 for the first week for a rental that lasts an entire week or longer. Jennie rented a car for 11 days. How much, in dollars, did she pay for the rental?
Output: The first 7 days were $190.
There were 11-7=<<11-7=4>>4 days left.
The additional 4 days were 4*30=<<4*30=120>>120.
And 190+120=<<190+120=310>>310.
So the final answer is 310

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o1-tgsm8k-s30-rTrue
Loading extension module utils...
Time to load utils op: 0.3042922019958496 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [01:05<53:11, 65.13s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [02:08<51:20, 64.17s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [03:10<49:16, 62.90s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [04:11<47:44, 62.27s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [05:13<46:45, 62.35s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [06:16<45:51, 62.53s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [07:20<45:02, 62.85s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [08:22<43:57, 62.79s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [09:26<42:59, 62.91s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [10:30<42:17, 63.45s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [11:33<41:11, 63.36s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [12:37<40:10, 63.44s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [13:39<38:47, 62.92s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [14:42<37:48, 63.01s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [15:48<37:15, 63.86s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [16:50<35:55, 63.41s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [17:53<34:52, 63.40s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [18:59<34:07, 63.98s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [20:04<33:11, 64.24s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [21:07<32:00, 64.01s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [22:11<30:51, 63.86s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [23:14<29:42, 63.65s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [24:19<28:52, 64.16s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [25:22<27:39, 63.84s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [26:26<26:36, 63.87s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [27:31<25:37, 64.07s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [28:35<24:35, 64.14s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [29:38<23:24, 63.84s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [30:42<22:18, 63.72s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [31:46<21:19, 63.95s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [32:48<20:05, 63.43s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [33:54<19:11, 63.99s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [34:56<17:58, 63.43s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [35:58<16:49, 63.12s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [37:03<15:52, 63.52s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [38:06<14:49, 63.53s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [39:12<13:54, 64.19s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [40:16<12:50, 64.19s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [41:19<11:42, 63.82s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [42:23<10:39, 63.94s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [43:29<09:40, 64.54s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [44:32<08:33, 64.14s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [45:38<07:31, 64.51s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [46:42<06:26, 64.46s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [47:45<05:19, 63.96s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [48:50<04:17, 64.28s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [49:54<03:13, 64.35s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [50:58<02:07, 63.98s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [52:01<01:03, 63.92s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [53:05<00:00, 63.98s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [53:05<00:00, 63.72s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 2.0675} | avg. gen lenth: 337.552
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s30-rTrue --seed 30 --max-prompt-length 2048 --rationales --num-out-domain 2
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-23 08:02:53,296] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s30-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 2
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o2-tgsm8k-s30-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|▊                                                                                    | 99/9741 [00:00<00:09, 989.66it/s]  2%|█▋                                                                                 | 202/9741 [00:00<00:09, 1013.16it/s]  3%|██▌                                                                                | 308/9741 [00:00<00:09, 1031.90it/s]  4%|███▌                                                                               | 413/9741 [00:00<00:08, 1038.81it/s]  5%|████▍                                                                              | 520/9741 [00:00<00:08, 1046.99it/s]  6%|█████▎                                                                             | 626/9741 [00:00<00:08, 1049.67it/s]  8%|██████▏                                                                            | 733/9741 [00:00<00:08, 1055.43it/s]  9%|███████▏                                                                           | 841/9741 [00:00<00:08, 1061.35it/s] 10%|████████                                                                           | 948/9741 [00:00<00:08, 1034.93it/s] 11%|████████▊                                                                         | 1054/9741 [00:01<00:08, 1041.91it/s] 12%|█████████▊                                                                        | 1161/9741 [00:01<00:08, 1047.81it/s] 13%|██████████▋                                                                       | 1267/9741 [00:01<00:08, 1049.87it/s] 14%|███████████▌                                                                      | 1373/9741 [00:01<00:07, 1051.78it/s] 15%|████████████▍                                                                     | 1480/9741 [00:01<00:07, 1054.72it/s] 16%|█████████████▎                                                                    | 1586/9741 [00:01<00:07, 1055.70it/s] 17%|██████████████▎                                                                   | 1693/9741 [00:01<00:07, 1058.53it/s] 18%|███████████████▏                                                                  | 1799/9741 [00:01<00:07, 1040.67it/s] 20%|████████████████                                                                  | 1905/9741 [00:01<00:07, 1046.23it/s] 21%|████████████████▉                                                                 | 2010/9741 [00:01<00:07, 1044.31it/s] 22%|█████████████████▊                                                                | 2116/9741 [00:02<00:07, 1046.73it/s] 23%|██████████████████▋                                                               | 2222/9741 [00:02<00:07, 1048.35it/s] 24%|████████████████████                                                              | 2376/9741 [00:02<00:06, 1192.75it/s] 26%|█████████████████████▎                                                            | 2537/9741 [00:02<00:05, 1314.70it/s] 28%|██████████████████████▋                                                           | 2697/9741 [00:02<00:05, 1399.50it/s] 29%|████████████████████████                                                          | 2858/9741 [00:02<00:04, 1459.65it/s] 31%|█████████████████████████▍                                                        | 3019/9741 [00:02<00:04, 1502.37it/s] 33%|██████████████████████████▊                                                       | 3179/9741 [00:02<00:04, 1531.38it/s] 34%|████████████████████████████                                                      | 3340/9741 [00:02<00:04, 1554.83it/s] 36%|█████████████████████████████▍                                                    | 3500/9741 [00:02<00:03, 1567.17it/s] 38%|██████████████████████████████▊                                                   | 3660/9741 [00:03<00:03, 1575.91it/s] 39%|████████████████████████████████▏                                                 | 3820/9741 [00:03<00:03, 1580.47it/s] 41%|█████████████████████████████████▍                                                | 3979/9741 [00:03<00:03, 1567.76it/s] 42%|██████████████████████████████████▊                                               | 4139/9741 [00:03<00:03, 1574.58it/s] 44%|████████████████████████████████████▏                                             | 4298/9741 [00:03<00:03, 1576.21it/s] 46%|█████████████████████████████████████▌                                            | 4456/9741 [00:03<00:03, 1575.59it/s] 47%|██████████████████████████████████████▊                                           | 4614/9741 [00:03<00:03, 1536.70it/s] 49%|████████████████████████████████████████▏                                         | 4768/9741 [00:03<00:04, 1181.63it/s] 51%|█████████████████████████████████████████▍                                        | 4926/9741 [00:03<00:03, 1278.09it/s] 52%|██████████████████████████████████████████▊                                       | 5086/9741 [00:04<00:03, 1360.77it/s] 54%|████████████████████████████████████████████▏                                     | 5246/9741 [00:04<00:03, 1423.14it/s] 55%|█████████████████████████████████████████████▍                                    | 5405/9741 [00:04<00:02, 1468.88it/s] 57%|██████████████████████████████████████████████▊                                   | 5566/9741 [00:04<00:02, 1507.40it/s] 59%|████████████████████████████████████████████████▏                                 | 5726/9741 [00:04<00:02, 1532.80it/s] 60%|█████████████████████████████████████████████████▌                                | 5886/9741 [00:04<00:02, 1551.58it/s] 62%|██████████████████████████████████████████████████▉                               | 6046/9741 [00:04<00:02, 1565.76it/s] 64%|████████████████████████████████████████████████████▏                             | 6205/9741 [00:04<00:02, 1572.38it/s] 65%|█████████████████████████████████████████████████████▌                            | 6364/9741 [00:04<00:02, 1575.05it/s] 67%|██████████████████████████████████████████████████████▉                           | 6523/9741 [00:04<00:02, 1548.07it/s] 69%|████████████████████████████████████████████████████████▏                         | 6680/9741 [00:05<00:01, 1553.86it/s] 70%|█████████████████████████████████████████████████████████▌                        | 6839/9741 [00:05<00:01, 1563.54it/s] 72%|██████████████████████████████████████████████████████████▉                       | 6997/9741 [00:05<00:01, 1566.26it/s] 73%|████████████████████████████████████████████████████████████▏                     | 7156/9741 [00:05<00:01, 1571.86it/s] 75%|█████████████████████████████████████████████████████████████▌                    | 7314/9741 [00:05<00:01, 1569.72it/s] 77%|██████████████████████████████████████████████████████████████▉                   | 7472/9741 [00:05<00:01, 1533.20it/s] 78%|████████████████████████████████████████████████████████████████▏                 | 7631/9741 [00:05<00:01, 1547.09it/s] 80%|█████████████████████████████████████████████████████████████████▌                | 7789/9741 [00:05<00:01, 1556.41it/s] 82%|██████████████████████████████████████████████████████████████████▉               | 7947/9741 [00:05<00:01, 1562.89it/s] 83%|████████████████████████████████████████████████████████████████████▏             | 8104/9741 [00:05<00:01, 1564.98it/s] 85%|█████████████████████████████████████████████████████████████████████▌            | 8262/9741 [00:06<00:00, 1569.27it/s] 86%|██████████████████████████████████████████████████████████████████████▊           | 8419/9741 [00:06<00:00, 1568.61it/s] 88%|████████████████████████████████████████████████████████████████████████▏         | 8576/9741 [00:06<00:00, 1567.61it/s] 90%|█████████████████████████████████████████████████████████████████████████▌        | 8734/9741 [00:06<00:00, 1569.85it/s] 91%|██████████████████████████████████████████████████████████████████████████▊       | 8892/9741 [00:06<00:00, 1565.71it/s] 93%|████████████████████████████████████████████████████████████████████████████▏     | 9049/9741 [00:06<00:00, 1565.03it/s] 95%|█████████████████████████████████████████████████████████████████████████████▍    | 9206/9741 [00:06<00:00, 1565.54it/s] 96%|██████████████████████████████████████████████████████████████████████████████▊   | 9363/9741 [00:06<00:00, 1566.00it/s] 98%|████████████████████████████████████████████████████████████████████████████████▏ | 9520/9741 [00:06<00:00, 1562.47it/s] 99%|█████████████████████████████████████████████████████████████████████████████████▍| 9677/9741 [00:06<00:00, 1563.80it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:07<00:00, 1389.54it/s]
Load End
Num instances: 1000
[2023-08-23 08:03:11,232] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-23 08:03:14,206] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-23 08:03:14,207] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-23 08:03:14,207] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-23 08:03:14,207] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-23 08:03:14,207] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-23 08:03:14,207] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-23 08:03:14,207] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-23 08:03:14,207] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-23 08:03:14,207] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-23 08:03:14,207] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-23 08:03:14,207] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-23 08:03:14,207] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fd36c98ca60>
[2023-08-23 08:03:14,207] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-23 08:03:14,207] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-23 08:03:14,207] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-23 08:03:14,207] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fd36c98c940>
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-23 08:03:14,208] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-23 08:03:14,208] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4252045154571533 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
Loading extension module utils...
### Instruction:Answer the following multiple choice question.

Input: The car-rental agency charges $30/day for a car, or $190 for the first week for a rental that lasts an entire week or longer. Jennie rented a car for 11 days. How much, in dollars, did she pay for the rental?
Output: The first 7 days were $190.
There were 11-7=<<11-7=4>>4 days left.
The additional 4 days were 4*30=<<4*30=120>>120.
And 190+120=<<190+120=310>>310.
So the final answer is 310

Input: A hurricane is approaching the southern coast of Texas, and a rancher is planning to move 400 head of cattle 60 miles to higher ground to protect them from possible inland flooding that might occur.  His animal transport truck holds 20 head of cattle.  Traveling at 60 miles per hour, what is the total driving time, in hours, it will take to transport all of his cattle to higher ground?
Output: Given the limited capacity of his transport vehicle (20 head of cattle), the 400 head of cattle will require 400/20=<<400/20=20>>20 trips using his transport vehicle.
Traveling to the site at 60 mph for 60 miles it will take 60/60=<<60/60=1>>1 hour to travel one-way.
Since each trip requires driving to and returning from the relocation site, each complete round trip will take 2*1=<<2*1=2>>2 hours.
Thus, 20 complete trips will take 20*2=<<20*2=40>>40 hours of driving time.
So the final answer is 40

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o2-tgsm8k-s30-rTrue
Time to load utils op: 0.30440640449523926 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:54<44:34, 54.58s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:47<42:56, 53.67s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:41<42:16, 53.96s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:37<41:43, 54.42s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [04:31<40:56, 54.59s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [05:24<39:33, 53.95s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [06:18<38:37, 53.90s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [07:12<37:45, 53.93s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [08:06<36:48, 53.87s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [09:01<36:14, 54.36s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [09:54<35:04, 53.96s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [10:48<34:12, 54.02s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [11:43<33:27, 54.26s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [12:37<32:32, 54.24s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [13:32<31:38, 54.25s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [14:25<30:39, 54.09s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [15:18<29:32, 53.70s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [16:14<28:57, 54.29s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [17:09<28:08, 54.47s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [18:03<27:17, 54.57s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [18:56<26:06, 54.02s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [19:50<25:10, 53.96s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [20:45<24:28, 54.41s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [21:41<23:42, 54.72s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [22:37<22:57, 55.09s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [23:31<21:54, 54.75s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [24:26<20:59, 54.75s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [25:19<19:52, 54.20s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [26:13<18:58, 54.22s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [27:07<18:04, 54.24s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [28:01<17:10, 54.25s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [28:56<16:17, 54.30s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [29:49<15:18, 54.05s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [30:44<14:27, 54.21s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [31:37<13:28, 53.91s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [32:30<12:29, 53.52s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [33:24<11:39, 53.81s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [34:19<10:49, 54.14s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [35:13<09:53, 53.97s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [36:08<09:03, 54.37s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [37:02<08:08, 54.28s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [37:56<07:13, 54.22s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [38:49<06:16, 53.78s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [39:43<05:23, 53.94s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [40:37<04:30, 54.03s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [41:31<03:35, 53.97s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [42:26<02:42, 54.23s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [43:19<01:47, 53.95s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [44:14<00:54, 54.04s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [45:08<00:00, 54.17s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [45:08<00:00, 54.17s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.6446} | avg. gen lenth: 416.612
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o3-tgsm8k-s30-rTrue --seed 30 --max-prompt-length 2048 --rationales --num-out-domain 3
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-23 08:48:57,451] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o3-tgsm8k-s30-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 3
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o3-tgsm8k-s30-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|▌                                                                                    | 71/9741 [00:00<00:13, 704.67it/s]  1%|█▎                                                                                  | 145/9741 [00:00<00:13, 720.32it/s]  2%|█▉                                                                                  | 219/9741 [00:00<00:13, 727.53it/s]  3%|██▌                                                                                 | 294/9741 [00:00<00:12, 735.34it/s]  4%|███▏                                                                                | 370/9741 [00:00<00:12, 740.78it/s]  5%|███▊                                                                                | 445/9741 [00:00<00:12, 743.27it/s]  5%|████▍                                                                               | 520/9741 [00:00<00:12, 744.54it/s]  6%|█████▏                                                                              | 595/9741 [00:00<00:12, 745.24it/s]  7%|█████▊                                                                              | 670/9741 [00:00<00:12, 724.21it/s]  8%|██████▍                                                                             | 745/9741 [00:01<00:12, 730.54it/s]  8%|███████                                                                             | 820/9741 [00:01<00:12, 735.97it/s]  9%|███████▋                                                                            | 894/9741 [00:01<00:12, 698.54it/s] 10%|████████▎                                                                           | 969/9741 [00:01<00:12, 711.30it/s] 11%|████████▉                                                                          | 1044/9741 [00:01<00:12, 722.47it/s] 11%|█████████▌                                                                         | 1119/9741 [00:01<00:11, 728.59it/s] 12%|██████████▏                                                                        | 1194/9741 [00:01<00:11, 732.55it/s] 13%|██████████▊                                                                        | 1269/9741 [00:01<00:11, 735.42it/s] 14%|███████████▍                                                                       | 1343/9741 [00:01<00:11, 731.61it/s] 15%|████████████                                                                       | 1417/9741 [00:02<00:13, 597.62it/s] 15%|████████████▌                                                                      | 1481/9741 [00:02<00:15, 526.84it/s] 16%|█████████████                                                                      | 1538/9741 [00:02<00:16, 489.31it/s] 16%|█████████████▌                                                                     | 1590/9741 [00:02<00:18, 439.52it/s] 17%|█████████████▉                                                                     | 1640/9741 [00:02<00:17, 452.61it/s] 17%|██████████████▍                                                                    | 1688/9741 [00:02<00:17, 453.00it/s] 18%|██████████████▊                                                                    | 1736/9741 [00:02<00:17, 458.41it/s] 18%|███████████████▏                                                                   | 1783/9741 [00:02<00:18, 425.45it/s] 19%|███████████████▌                                                                   | 1833/9741 [00:03<00:17, 440.88it/s] 19%|████████████████                                                                   | 1884/9741 [00:03<00:17, 459.20it/s] 20%|████████████████▍                                                                  | 1931/9741 [00:03<00:17, 458.67it/s] 20%|████████████████▉                                                                  | 1982/9741 [00:03<00:16, 472.18it/s] 21%|█████████████████▎                                                                 | 2030/9741 [00:03<00:16, 465.78it/s] 21%|█████████████████▋                                                                 | 2077/9741 [00:03<00:16, 465.40it/s] 22%|██████████████████                                                                 | 2127/9741 [00:03<00:16, 475.39it/s] 22%|██████████████████▌                                                                | 2175/9741 [00:03<00:15, 474.87it/s] 23%|██████████████████▉                                                                | 2223/9741 [00:03<00:15, 474.83it/s] 23%|███████████████████▍                                                               | 2275/9741 [00:03<00:15, 486.34it/s] 24%|███████████████████▊                                                               | 2326/9741 [00:04<00:15, 493.06it/s] 24%|████████████████████▏                                                              | 2376/9741 [00:04<00:15, 481.95it/s] 25%|████████████████████▋                                                              | 2429/9741 [00:04<00:14, 495.36it/s] 25%|█████████████████████                                                              | 2479/9741 [00:04<00:15, 482.66it/s] 26%|█████████████████████▌                                                             | 2529/9741 [00:04<00:14, 487.04it/s] 26%|█████████████████████▉                                                             | 2581/9741 [00:04<00:14, 496.55it/s] 27%|██████████████████████▍                                                            | 2631/9741 [00:04<00:14, 479.54it/s] 28%|██████████████████████▉                                                            | 2691/9741 [00:04<00:13, 513.27it/s] 28%|███████████████████████▌                                                           | 2765/9741 [00:04<00:12, 578.73it/s] 29%|████████████████████████                                                           | 2824/9741 [00:04<00:11, 576.55it/s] 30%|████████████████████████▋                                                          | 2891/9741 [00:05<00:11, 601.80it/s] 30%|█████████████████████████▏                                                         | 2962/9741 [00:05<00:10, 631.11it/s] 31%|█████████████████████████▊                                                         | 3035/9741 [00:05<00:10, 660.03it/s] 32%|██████████████████████████▍                                                        | 3108/9741 [00:05<00:09, 679.54it/s] 33%|███████████████████████████                                                        | 3181/9741 [00:05<00:09, 692.38it/s] 33%|███████████████████████████▋                                                       | 3255/9741 [00:05<00:09, 705.12it/s] 34%|████████████████████████████▎                                                      | 3329/9741 [00:05<00:08, 713.77it/s] 35%|████████████████████████████▉                                                      | 3402/9741 [00:05<00:08, 718.45it/s] 36%|█████████████████████████████▌                                                     | 3474/9741 [00:05<00:08, 701.98it/s] 36%|██████████████████████████████▏                                                    | 3547/9741 [00:05<00:08, 707.50it/s] 37%|██████████████████████████████▊                                                    | 3619/9741 [00:06<00:08, 709.23it/s] 38%|███████████████████████████████▍                                                   | 3692/9741 [00:06<00:08, 714.93it/s] 39%|████████████████████████████████                                                   | 3765/9741 [00:06<00:08, 718.81it/s] 39%|████████████████████████████████▋                                                  | 3837/9741 [00:06<00:08, 718.85it/s] 40%|█████████████████████████████████▎                                                 | 3910/9741 [00:06<00:08, 721.37it/s] 41%|█████████████████████████████████▉                                                 | 3983/9741 [00:06<00:07, 722.12it/s] 42%|██████████████████████████████████▌                                                | 4056/9741 [00:06<00:07, 722.68it/s] 42%|███████████████████████████████████▏                                               | 4129/9741 [00:06<00:07, 723.92it/s] 43%|███████████████████████████████████▊                                               | 4202/9741 [00:06<00:07, 723.23it/s] 44%|████████████████████████████████████▍                                              | 4275/9741 [00:06<00:07, 706.00it/s] 45%|█████████████████████████████████████                                              | 4348/9741 [00:07<00:07, 710.80it/s] 45%|█████████████████████████████████████▋                                             | 4421/9741 [00:07<00:07, 714.64it/s] 46%|██████████████████████████████████████▎                                            | 4493/9741 [00:07<00:07, 672.62it/s] 47%|██████████████████████████████████████▉                                            | 4566/9741 [00:07<00:07, 687.99it/s] 48%|███████████████████████████████████████▌                                           | 4639/9741 [00:07<00:07, 699.56it/s] 48%|████████████████████████████████████████▏                                          | 4710/9741 [00:07<00:09, 536.81it/s] 49%|████████████████████████████████████████▊                                          | 4783/9741 [00:07<00:08, 582.04it/s] 50%|█████████████████████████████████████████▍                                         | 4856/9741 [00:07<00:07, 619.26it/s] 51%|█████████████████████████████████████████▉                                         | 4928/9741 [00:08<00:07, 644.45it/s] 51%|██████████████████████████████████████████▌                                        | 5001/9741 [00:08<00:07, 667.55it/s] 52%|███████████████████████████████████████████▏                                       | 5075/9741 [00:08<00:06, 685.41it/s] 53%|███████████████████████████████████████████▊                                       | 5148/9741 [00:08<00:06, 696.19it/s] 54%|████████████████████████████████████████████▍                                      | 5221/9741 [00:08<00:06, 704.62it/s] 54%|█████████████████████████████████████████████                                      | 5294/9741 [00:08<00:06, 710.57it/s] 55%|█████████████████████████████████████████████▋                                     | 5367/9741 [00:08<00:06, 712.47it/s] 56%|██████████████████████████████████████████████▎                                    | 5440/9741 [00:08<00:06, 716.80it/s] 57%|██████████████████████████████████████████████▉                                    | 5513/9741 [00:08<00:05, 719.66it/s] 57%|███████████████████████████████████████████████▌                                   | 5586/9741 [00:08<00:05, 721.86it/s] 58%|████████████████████████████████████████████████▏                                  | 5659/9741 [00:09<00:05, 722.08it/s] 59%|████████████████████████████████████████████████▊                                  | 5733/9741 [00:09<00:05, 724.42it/s] 60%|█████████████████████████████████████████████████▍                                 | 5807/9741 [00:09<00:05, 726.99it/s] 60%|██████████████████████████████████████████████████                                 | 5880/9741 [00:09<00:05, 727.32it/s] 61%|██████████████████████████████████████████████████▋                                | 5954/9741 [00:09<00:05, 729.66it/s] 62%|███████████████████████████████████████████████████▎                               | 6027/9741 [00:09<00:05, 713.37it/s] 63%|███████████████████████████████████████████████████▉                               | 6100/9741 [00:09<00:05, 716.34it/s] 63%|████████████████████████████████████████████████████▌                              | 6174/9741 [00:09<00:04, 720.41it/s] 64%|█████████████████████████████████████████████████████▏                             | 6248/9741 [00:09<00:04, 723.33it/s] 65%|█████████████████████████████████████████████████████▊                             | 6321/9741 [00:09<00:04, 722.58it/s] 66%|██████████████████████████████████████████████████████▍                            | 6394/9741 [00:10<00:04, 724.39it/s] 66%|███████████████████████████████████████████████████████                            | 6467/9741 [00:10<00:04, 725.20it/s] 67%|███████████████████████████████████████████████████████▋                           | 6540/9741 [00:10<00:04, 723.02it/s] 68%|████████████████████████████████████████████████████████▎                          | 6615/9741 [00:10<00:04, 729.90it/s] 69%|█████████████████████████████████████████████████████████▎                         | 6723/9741 [00:10<00:03, 832.41it/s] 70%|██████████████████████████████████████████████████████████▏                        | 6830/9741 [00:10<00:03, 902.18it/s] 71%|███████████████████████████████████████████████████████████                        | 6936/9741 [00:10<00:02, 948.42it/s] 72%|███████████████████████████████████████████████████████████▉                       | 7041/9741 [00:10<00:02, 978.00it/s] 73%|████████████████████████████████████████████████████████████▏                     | 7147/9741 [00:10<00:02, 1001.18it/s] 74%|█████████████████████████████████████████████████████████████                     | 7252/9741 [00:10<00:02, 1014.78it/s] 76%|█████████████████████████████████████████████████████████████▉                    | 7359/9741 [00:11<00:02, 1029.78it/s] 77%|██████████████████████████████████████████████████████████████▊                   | 7462/9741 [00:11<00:02, 1004.50it/s] 78%|███████████████████████████████████████████████████████████████▋                  | 7569/9741 [00:11<00:02, 1023.09it/s] 79%|████████████████████████████████████████████████████████████████▌                 | 7674/9741 [00:11<00:02, 1029.97it/s] 80%|█████████████████████████████████████████████████████████████████▌                | 7781/9741 [00:11<00:01, 1040.36it/s] 81%|██████████████████████████████████████████████████████████████████▍               | 7886/9741 [00:11<00:01, 1041.67it/s] 82%|███████████████████████████████████████████████████████████████████▎              | 7994/9741 [00:11<00:01, 1050.77it/s] 83%|████████████████████████████████████████████████████████████████████▏             | 8100/9741 [00:11<00:01, 1053.22it/s] 84%|█████████████████████████████████████████████████████████████████████             | 8207/9741 [00:11<00:01, 1055.88it/s] 85%|█████████████████████████████████████████████████████████████████████▉            | 8314/9741 [00:11<00:01, 1058.34it/s] 86%|██████████████████████████████████████████████████████████████████████▉           | 8420/9741 [00:12<00:01, 1051.37it/s] 88%|███████████████████████████████████████████████████████████████████████▊          | 8527/9741 [00:12<00:01, 1055.84it/s] 89%|████████████████████████████████████████████████████████████████████████▋         | 8634/9741 [00:12<00:01, 1058.04it/s] 90%|█████████████████████████████████████████████████████████████████████████▌        | 8740/9741 [00:12<00:00, 1057.60it/s] 91%|██████████████████████████████████████████████████████████████████████████▍       | 8846/9741 [00:12<00:00, 1056.80it/s] 92%|███████████████████████████████████████████████████████████████████████████▍      | 8954/9741 [00:12<00:00, 1061.53it/s] 93%|████████████████████████████████████████████████████████████████████████████▎     | 9061/9741 [00:12<00:00, 1062.36it/s] 94%|█████████████████████████████████████████████████████████████████████████████▏    | 9169/9741 [00:12<00:00, 1065.86it/s] 95%|██████████████████████████████████████████████████████████████████████████████    | 9276/9741 [00:12<00:00, 1064.46it/s] 96%|██████████████████████████████████████████████████████████████████████████████▉   | 9384/9741 [00:12<00:00, 1066.91it/s] 97%|███████████████████████████████████████████████████████████████████████████████▉  | 9491/9741 [00:13<00:00, 1062.96it/s] 99%|████████████████████████████████████████████████████████████████████████████████▊ | 9598/9741 [00:13<00:00, 1059.94it/s]100%|█████████████████████████████████████████████████████████████████████████████████▋| 9705/9741 [00:13<00:00, 1060.66it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:13<00:00, 731.35it/s]
Load End
Num instances: 1000
[2023-08-23 08:49:22,170] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-23 08:49:24,997] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-23 08:49:24,998] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-23 08:49:24,998] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-23 08:49:24,998] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-23 08:49:24,998] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-23 08:49:24,998] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fcbd515ea60>
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fcbd515e940>
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-23 08:49:24,999] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-23 08:49:25,000] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-23 08:49:25,000] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-23 08:49:25,000] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-23 08:49:25,000] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-23 08:49:25,000] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-23 08:49:25,000] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-23 08:49:25,000] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-23 08:49:25,000] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-23 08:49:25,000] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-23 08:49:25,000] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4604666233062744 seconds
Loading extension module utils...
Time to load utils op: 0.5049171447753906 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: The car-rental agency charges $30/day for a car, or $190 for the first week for a rental that lasts an entire week or longer. Jennie rented a car for 11 days. How much, in dollars, did she pay for the rental?
Output: The first 7 days were $190.
There were 11-7=<<11-7=4>>4 days left.
The additional 4 days were 4*30=<<4*30=120>>120.
And 190+120=<<190+120=310>>310.
So the final answer is 310

Input: A hurricane is approaching the southern coast of Texas, and a rancher is planning to move 400 head of cattle 60 miles to higher ground to protect them from possible inland flooding that might occur.  His animal transport truck holds 20 head of cattle.  Traveling at 60 miles per hour, what is the total driving time, in hours, it will take to transport all of his cattle to higher ground?
Output: Given the limited capacity of his transport vehicle (20 head of cattle), the 400 head of cattle will require 400/20=<<400/20=20>>20 trips using his transport vehicle.
Traveling to the site at 60 mph for 60 miles it will take 60/60=<<60/60=1>>1 hour to travel one-way.
Since each trip requires driving to and returning from the relocation site, each complete round trip will take 2*1=<<2*1=2>>2 hours.
Thus, 20 complete trips will take 20*2=<<20*2=40>>40 hours of driving time.
So the final answer is 40

Input: Jason has a carriage house that he rents out.  He’s charging $50.00 per day or $500.00 for 14 days.  Eric wants to rent the house for 20 days.  How much will it cost him?
Output: He wants to rent for 20 days and there is a deal if you rent for 14 days so that leaves 20-14 = <<20-14=6>>6 individual days
Each individual day is $50.00 and he will have 6 individual days for a total of 50*6 = $<<50*6=300.00>>300.00
14 days costs $500.00 and 6 days costs $300.00 for a total of 500+300 = $800.00
So the final answer is 800

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o3-tgsm8k-s30-rTrue
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:50<41:03, 50.28s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:39<39:37, 49.52s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:27<38:14, 48.83s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:16<37:34, 49.02s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [04:06<37:06, 49.48s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [04:56<36:15, 49.44s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [05:44<35:13, 49.16s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [06:33<34:17, 48.98s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [07:21<33:22, 48.85s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [08:10<32:34, 48.87s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [09:00<31:50, 48.98s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [09:51<31:25, 49.63s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [10:40<30:29, 49.44s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [11:28<29:30, 49.18s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [12:19<28:51, 49.48s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [13:08<28:03, 49.50s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [13:56<26:57, 49.01s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [14:46<26:19, 49.37s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [15:37<25:44, 49.82s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [16:26<24:49, 49.66s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [17:15<23:50, 49.32s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [18:04<22:55, 49.13s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [18:53<22:09, 49.23s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [19:42<21:20, 49.23s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [20:31<20:29, 49.20s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [21:19<19:32, 48.83s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [22:09<18:48, 49.08s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [22:58<18:01, 49.15s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [23:47<17:11, 49.11s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [24:37<16:23, 49.17s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [25:25<15:28, 48.89s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [26:15<14:44, 49.13s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [27:03<13:53, 49.03s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [27:53<13:06, 49.13s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [28:42<12:15, 49.04s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [29:31<11:26, 49.03s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [30:19<10:36, 48.93s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [31:08<09:45, 48.78s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [31:56<08:53, 48.53s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [32:44<08:05, 48.51s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [33:35<07:24, 49.35s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [34:23<06:30, 48.86s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [35:12<05:42, 48.99s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [36:02<04:54, 49.10s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [36:52<04:06, 49.35s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [37:40<03:16, 49.02s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [38:29<02:27, 49.12s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [39:18<01:37, 48.99s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [40:07<00:49, 49.05s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [40:55<00:00, 48.71s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [40:55<00:00, 49.11s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.6229} | avg. gen lenth: 417.158
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o4-tgsm8k-s30-rTrue --seed 30 --max-prompt-length 2048 --rationales --num-out-domain 4
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-23 09:30:51,262] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o4-tgsm8k-s30-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 4
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o4-tgsm8k-s30-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|▌                                                                                    | 61/9741 [00:00<00:16, 603.29it/s]  1%|█                                                                                   | 124/9741 [00:00<00:15, 617.62it/s]  2%|█▌                                                                                  | 187/9741 [00:00<00:15, 620.06it/s]  3%|██▏                                                                                 | 250/9741 [00:00<00:15, 623.10it/s]  3%|██▋                                                                                 | 314/9741 [00:00<00:15, 628.37it/s]  4%|███▎                                                                                | 378/9741 [00:00<00:14, 631.59it/s]  5%|███▊                                                                                | 442/9741 [00:00<00:14, 632.43it/s]  5%|████▎                                                                               | 506/9741 [00:00<00:14, 634.82it/s]  6%|████▉                                                                               | 570/9741 [00:00<00:14, 623.58it/s]  6%|█████▍                                                                              | 633/9741 [00:01<00:14, 624.52it/s]  7%|██████                                                                              | 698/9741 [00:01<00:14, 629.97it/s]  8%|██████▌                                                                             | 762/9741 [00:01<00:14, 632.07it/s]  8%|███████▏                                                                            | 827/9741 [00:01<00:14, 635.91it/s]  9%|███████▋                                                                            | 891/9741 [00:01<00:13, 635.74it/s] 10%|████████▏                                                                           | 956/9741 [00:01<00:13, 637.83it/s] 10%|████████▋                                                                          | 1021/9741 [00:01<00:13, 638.90it/s] 11%|█████████▏                                                                         | 1085/9741 [00:01<00:13, 638.65it/s] 12%|█████████▊                                                                         | 1150/9741 [00:01<00:13, 640.09it/s] 12%|██████████▎                                                                        | 1215/9741 [00:01<00:13, 637.39it/s] 13%|███████████▏                                                                       | 1310/9741 [00:02<00:11, 729.94it/s] 14%|███████████▉                                                                       | 1406/9741 [00:02<00:10, 796.46it/s] 15%|████████████▊                                                                      | 1502/9741 [00:02<00:09, 843.88it/s] 16%|█████████████▌                                                                     | 1597/9741 [00:02<00:09, 874.48it/s] 17%|██████████████▍                                                                    | 1693/9741 [00:02<00:08, 898.69it/s] 18%|███████████████▏                                                                   | 1783/9741 [00:02<00:08, 893.65it/s] 19%|████████████████                                                                   | 1878/9741 [00:02<00:08, 910.00it/s] 20%|████████████████▊                                                                  | 1973/9741 [00:02<00:08, 920.96it/s] 21%|█████████████████▌                                                                 | 2067/9741 [00:02<00:08, 926.52it/s] 22%|██████████████████▍                                                                | 2161/9741 [00:02<00:08, 930.37it/s] 23%|███████████████████▏                                                               | 2255/9741 [00:03<00:08, 931.25it/s] 24%|████████████████████                                                               | 2350/9741 [00:03<00:07, 934.70it/s] 25%|████████████████████▊                                                              | 2444/9741 [00:03<00:07, 921.65it/s] 26%|█████████████████████▋                                                             | 2538/9741 [00:03<00:07, 925.85it/s] 27%|██████████████████████▍                                                            | 2633/9741 [00:03<00:07, 930.22it/s] 28%|███████████████████████▏                                                           | 2727/9741 [00:03<00:07, 931.01it/s] 29%|████████████████████████                                                           | 2821/9741 [00:03<00:07, 931.66it/s] 30%|████████████████████████▊                                                          | 2915/9741 [00:03<00:07, 932.36it/s] 31%|█████████████████████████▋                                                         | 3010/9741 [00:03<00:07, 935.44it/s] 32%|██████████████████████████▍                                                        | 3104/9741 [00:03<00:07, 934.03it/s] 33%|███████████████████████████▏                                                       | 3198/9741 [00:04<00:07, 931.75it/s] 34%|████████████████████████████                                                       | 3292/9741 [00:04<00:06, 932.72it/s] 35%|████████████████████████████▊                                                      | 3386/9741 [00:04<00:06, 931.08it/s] 36%|█████████████████████████████▋                                                     | 3480/9741 [00:04<00:06, 933.16it/s] 37%|██████████████████████████████▍                                                    | 3574/9741 [00:04<00:06, 930.79it/s] 38%|███████████████████████████████▎                                                   | 3668/9741 [00:04<00:06, 927.20it/s] 39%|████████████████████████████████                                                   | 3762/9741 [00:04<00:06, 929.40it/s] 40%|████████████████████████████████▊                                                  | 3855/9741 [00:04<00:06, 929.11it/s] 41%|█████████████████████████████████▋                                                 | 3949/9741 [00:04<00:06, 929.96it/s] 41%|██████████████████████████████████▍                                                | 4042/9741 [00:04<00:06, 910.96it/s] 42%|███████████████████████████████████▏                                               | 4135/9741 [00:05<00:06, 913.92it/s] 43%|████████████████████████████████████                                               | 4228/9741 [00:05<00:06, 916.89it/s] 44%|████████████████████████████████████▊                                              | 4320/9741 [00:05<00:05, 916.43it/s] 45%|█████████████████████████████████████▌                                             | 4413/9741 [00:05<00:05, 918.40it/s] 46%|██████████████████████████████████████▍                                            | 4505/9741 [00:05<00:05, 874.34it/s] 47%|███████████████████████████████████████▏                                           | 4597/9741 [00:05<00:05, 887.42it/s] 48%|███████████████████████████████████████▉                                           | 4689/9741 [00:05<00:05, 894.14it/s] 49%|████████████████████████████████████████▋                                          | 4779/9741 [00:05<00:06, 741.13it/s] 50%|█████████████████████████████████████████▌                                         | 4872/9741 [00:05<00:06, 787.68it/s] 51%|██████████████████████████████████████████▎                                        | 4964/9741 [00:06<00:05, 822.14it/s] 52%|███████████████████████████████████████████                                        | 5057/9741 [00:06<00:05, 849.68it/s] 53%|███████████████████████████████████████████▊                                       | 5149/9741 [00:06<00:05, 868.25it/s] 54%|████████████████████████████████████████████▋                                      | 5242/9741 [00:06<00:05, 883.54it/s] 55%|█████████████████████████████████████████████▍                                     | 5334/9741 [00:06<00:04, 892.29it/s] 56%|██████████████████████████████████████████████▏                                    | 5426/9741 [00:06<00:04, 897.91it/s] 57%|███████████████████████████████████████████████                                    | 5518/9741 [00:06<00:04, 902.55it/s] 58%|███████████████████████████████████████████████▊                                   | 5610/9741 [00:06<00:04, 906.59it/s] 59%|████████████████████████████████████████████████▌                                  | 5703/9741 [00:06<00:04, 913.18it/s] 59%|█████████████████████████████████████████████████▍                                 | 5795/9741 [00:06<00:04, 914.43it/s] 60%|██████████████████████████████████████████████████▏                                | 5887/9741 [00:07<00:04, 912.72it/s] 61%|██████████████████████████████████████████████████▉                                | 5980/9741 [00:07<00:04, 915.24it/s] 62%|███████████████████████████████████████████████████▋                               | 6072/9741 [00:07<00:04, 916.30it/s] 63%|████████████████████████████████████████████████████▌                              | 6165/9741 [00:07<00:03, 918.91it/s] 64%|█████████████████████████████████████████████████████▎                             | 6257/9741 [00:07<00:03, 918.31it/s] 65%|██████████████████████████████████████████████████████                             | 6349/9741 [00:07<00:03, 915.51it/s] 66%|██████████████████████████████████████████████████████▉                            | 6441/9741 [00:07<00:03, 915.16it/s] 67%|███████████████████████████████████████████████████████▋                           | 6533/9741 [00:07<00:03, 912.68it/s] 68%|████████████████████████████████████████████████████████▍                          | 6625/9741 [00:07<00:03, 913.03it/s] 69%|█████████████████████████████████████████████████████████▏                         | 6717/9741 [00:07<00:03, 914.79it/s] 70%|██████████████████████████████████████████████████████████                         | 6809/9741 [00:08<00:03, 912.23it/s] 71%|██████████████████████████████████████████████████████████▊                        | 6901/9741 [00:08<00:03, 910.67it/s] 72%|███████████████████████████████████████████████████████████▌                       | 6993/9741 [00:08<00:03, 905.68it/s] 73%|████████████████████████████████████████████████████████████▎                      | 7084/9741 [00:08<00:02, 903.07it/s] 74%|█████████████████████████████████████████████████████████████▏                     | 7175/9741 [00:08<00:02, 899.94it/s] 75%|█████████████████████████████████████████████████████████████▉                     | 7265/9741 [00:08<00:02, 896.49it/s] 76%|██████████████████████████████████████████████████████████████▋                    | 7355/9741 [00:08<00:02, 896.68it/s] 76%|███████████████████████████████████████████████████████████████▍                   | 7445/9741 [00:08<00:02, 854.16it/s] 77%|████████████████████████████████████████████████████████████████▏                  | 7535/9741 [00:08<00:02, 865.03it/s] 78%|████████████████████████████████████████████████████████████████▉                  | 7626/9741 [00:08<00:02, 877.29it/s] 79%|█████████████████████████████████████████████████████████████████▋                 | 7716/9741 [00:09<00:02, 882.74it/s] 80%|██████████████████████████████████████████████████████████████████▌                | 7808/9741 [00:09<00:02, 890.81it/s] 81%|███████████████████████████████████████████████████████████████████▎               | 7900/9741 [00:09<00:02, 896.81it/s] 82%|████████████████████████████████████████████████████████████████████               | 7992/9741 [00:09<00:01, 903.32it/s] 83%|████████████████████████████████████████████████████████████████████▉              | 8084/9741 [00:09<00:01, 906.89it/s] 84%|█████████████████████████████████████████████████████████████████████▋             | 8176/9741 [00:09<00:01, 907.95it/s] 85%|██████████████████████████████████████████████████████████████████████▍            | 8268/9741 [00:09<00:01, 910.47it/s] 86%|███████████████████████████████████████████████████████████████████████▏           | 8360/9741 [00:09<00:01, 909.85it/s] 87%|████████████████████████████████████████████████████████████████████████           | 8452/9741 [00:09<00:01, 910.60it/s] 88%|████████████████████████████████████████████████████████████████████████▊          | 8544/9741 [00:09<00:01, 911.55it/s] 89%|█████████████████████████████████████████████████████████████████████████▌         | 8636/9741 [00:10<00:01, 905.85it/s] 90%|██████████████████████████████████████████████████████████████████████████▎        | 8727/9741 [00:10<00:01, 904.13it/s] 91%|███████████████████████████████████████████████████████████████████████████▏       | 8818/9741 [00:10<00:01, 902.06it/s] 91%|███████████████████████████████████████████████████████████████████████████▉       | 8909/9741 [00:10<00:00, 903.35it/s] 92%|████████████████████████████████████████████████████████████████████████████▋      | 9000/9741 [00:10<00:00, 900.30it/s] 93%|█████████████████████████████████████████████████████████████████████████████▍     | 9091/9741 [00:10<00:00, 901.93it/s] 94%|██████████████████████████████████████████████████████████████████████████████▏    | 9182/9741 [00:10<00:00, 903.17it/s] 95%|███████████████████████████████████████████████████████████████████████████████    | 9273/9741 [00:10<00:00, 902.34it/s] 96%|███████████████████████████████████████████████████████████████████████████████▊   | 9364/9741 [00:10<00:00, 902.68it/s] 97%|████████████████████████████████████████████████████████████████████████████████▌  | 9455/9741 [00:11<00:00, 901.21it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▎ | 9546/9741 [00:11<00:00, 901.69it/s] 99%|██████████████████████████████████████████████████████████████████████████████████ | 9637/9741 [00:11<00:00, 901.30it/s]100%|██████████████████████████████████████████████████████████████████████████████████▉| 9728/9741 [00:11<00:00, 898.19it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:11<00:00, 859.81it/s]
Load End
Num instances: 1000
[2023-08-23 09:31:13,996] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-23 09:31:16,894] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-23 09:31:16,895] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-23 09:31:16,895] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-23 09:31:16,895] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-23 09:31:16,895] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-23 09:31:16,895] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-23 09:31:16,895] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-23 09:31:16,895] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-23 09:31:16,895] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-23 09:31:16,895] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-23 09:31:16,895] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-23 09:31:16,895] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f8ef8761a60>
[2023-08-23 09:31:16,895] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-23 09:31:16,895] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-23 09:31:16,895] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-23 09:31:16,895] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-23 09:31:16,895] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-23 09:31:16,895] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-23 09:31:16,895] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-23 09:31:16,895] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-23 09:31:16,895] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-23 09:31:16,895] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-23 09:31:16,895] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-23 09:31:16,895] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-23 09:31:16,895] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-23 09:31:16,895] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-23 09:31:16,895] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-23 09:31:16,895] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-23 09:31:16,895] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-23 09:31:16,895] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-23 09:31:16,895] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f8ef8761940>
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-23 09:31:16,896] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-23 09:31:16,896] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.43782711029052734 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: The car-rental agency charges $30/day for a car, or $190 for the first week for a rental that lasts an entire week or longer. Jennie rented a car for 11 days. How much, in dollars, did she pay for the rental?
Output: The first 7 days were $190.
There were 11-7=<<11-7=4>>4 days left.
The additional 4 days were 4*30=<<4*30=120>>120.
And 190+120=<<190+120=310>>310.
So the final answer is 310

Input: A hurricane is approaching the southern coast of Texas, and a rancher is planning to move 400 head of cattle 60 miles to higher ground to protect them from possible inland flooding that might occur.  His animal transport truck holds 20 head of cattle.  Traveling at 60 miles per hour, what is the total driving time, in hours, it will take to transport all of his cattle to higher ground?
Output: Given the limited capacity of his transport vehicle (20 head of cattle), the 400 head of cattle will require 400/20=<<400/20=20>>20 trips using his transport vehicle.
Traveling to the site at 60 mph for 60 miles it will take 60/60=<<60/60=1>>1 hour to travel one-way.
Since each trip requires driving to and returning from the relocation site, each complete round trip will take 2*1=<<2*1=2>>2 hours.
Thus, 20 complete trips will take 20*2=<<20*2=40>>40 hours of driving time.
So the final answer is 40

Input: Jason has a carriage house that he rents out.  He’s charging $50.00 per day or $500.00 for 14 days.  Eric wants to rent the house for 20 days.  How much will it cost him?
Output: He wants to rent for 20 days and there is a deal if you rent for 14 days so that leaves 20-14 = <<20-14=6>>6 individual days
Each individual day is $50.00 and he will have 6 individual days for a total of 50*6 = $<<50*6=300.00>>300.00
14 days costs $500.00 and 6 days costs $300.00 for a total of 500+300 = $800.00
So the final answer is 800

Input: Melissa works on a poultry farm. She drives to town twice each month to buy supplies. If it takes her 3 hours to drive to town and back, how many hours does Melissa spend driving in a year?
Output: Melissa spends 2x3=<<2*3=6>>6 hours driving each month.
Since there are 12 months in a year, she spends 6x12=<<6*12=72>>72 hours driving each year.
So the final answer is 72

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o4-tgsm8k-s30-rTrue
Loading extension module utils...
Time to load utils op: 0.5048091411590576 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:46<38:01, 46.55s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:34<37:44, 47.18s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:19<36:25, 46.49s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [03:06<35:33, 46.38s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [03:53<35:05, 46.78s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [04:39<34:10, 46.61s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [05:26<33:27, 46.69s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [06:13<32:49, 46.88s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [07:00<31:53, 46.68s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [07:45<30:54, 46.36s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [08:31<30:02, 46.22s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [09:17<29:16, 46.21s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [10:05<28:42, 46.54s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [10:51<27:47, 46.32s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [11:38<27:13, 46.67s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [12:25<26:25, 46.64s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [13:11<25:34, 46.49s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [13:57<24:44, 46.39s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [14:43<23:57, 46.39s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [15:30<23:12, 46.42s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [16:16<22:21, 46.26s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [17:02<21:32, 46.15s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [17:48<20:47, 46.21s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [18:35<20:09, 46.51s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [19:23<19:29, 46.78s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [20:11<18:51, 47.16s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [20:58<18:07, 47.29s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [21:45<17:14, 47.04s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [22:31<16:20, 46.71s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [23:18<15:37, 46.89s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [24:04<14:45, 46.61s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [24:51<14:00, 46.67s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [25:38<13:15, 46.80s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [26:25<12:29, 46.86s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [27:11<11:39, 46.61s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [27:57<10:49, 46.43s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [28:47<10:18, 47.60s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [29:33<09:26, 47.23s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [30:19<08:35, 46.86s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [31:07<07:50, 47.06s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [31:53<07:00, 46.77s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [32:39<06:12, 46.55s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [33:26<05:27, 46.73s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [34:13<04:39, 46.67s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [35:00<03:53, 46.72s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [35:46<03:06, 46.72s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [36:34<02:20, 46.95s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [37:22<01:34, 47.30s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [38:09<00:47, 47.09s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [38:55<00:00, 47.01s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [38:55<00:00, 46.72s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.4786} | avg. gen lenth: 425.716
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o5-tgsm8k-s30-rTrue --seed 30 --max-prompt-length 2048 --rationales --num-out-domain 5
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-23 10:10:20,022] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o5-tgsm8k-s30-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 5
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o5-tgsm8k-s30-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  1%|▍                                                                                    | 51/9741 [00:00<00:19, 509.36it/s]  1%|▉                                                                                   | 104/9741 [00:00<00:18, 518.71it/s]  2%|█▎                                                                                  | 157/9741 [00:00<00:18, 521.75it/s]  2%|█▊                                                                                  | 210/9741 [00:00<00:18, 521.93it/s]  3%|██▎                                                                                 | 263/9741 [00:00<00:18, 524.52it/s]  3%|██▋                                                                                 | 317/9741 [00:00<00:17, 527.73it/s]  4%|███▏                                                                                | 371/9741 [00:00<00:17, 531.58it/s]  4%|███▋                                                                                | 425/9741 [00:00<00:17, 517.83it/s]  5%|████                                                                                | 478/9741 [00:00<00:17, 520.79it/s]  5%|████▌                                                                               | 531/9741 [00:01<00:17, 523.12it/s]  6%|█████                                                                               | 584/9741 [00:01<00:17, 524.26it/s]  7%|█████▍                                                                              | 637/9741 [00:01<00:17, 523.94it/s]  7%|██████                                                                              | 710/9741 [00:01<00:15, 584.52it/s]  8%|██████▊                                                                             | 790/9741 [00:01<00:13, 646.89it/s]  9%|███████▍                                                                            | 869/9741 [00:01<00:12, 687.04it/s] 10%|████████▏                                                                           | 948/9741 [00:01<00:12, 716.41it/s] 11%|████████▊                                                                          | 1027/9741 [00:01<00:11, 737.79it/s] 11%|█████████▍                                                                         | 1105/9741 [00:01<00:11, 748.30it/s] 12%|██████████                                                                         | 1184/9741 [00:01<00:11, 760.72it/s] 13%|██████████▊                                                                        | 1263/9741 [00:02<00:11, 767.56it/s] 14%|███████████▍                                                                       | 1341/9741 [00:02<00:10, 771.00it/s] 15%|████████████                                                                       | 1420/9741 [00:02<00:10, 774.63it/s] 15%|████████████▊                                                                      | 1499/9741 [00:02<00:10, 777.49it/s] 16%|█████████████▍                                                                     | 1577/9741 [00:02<00:10, 778.12it/s] 17%|██████████████                                                                     | 1656/9741 [00:02<00:10, 780.13it/s] 18%|██████████████▊                                                                    | 1735/9741 [00:02<00:10, 781.95it/s] 19%|███████████████▍                                                                   | 1814/9741 [00:02<00:10, 762.12it/s] 19%|████████████████▏                                                                  | 1893/9741 [00:02<00:10, 768.09it/s] 20%|████████████████▊                                                                  | 1972/9741 [00:02<00:10, 771.67it/s] 21%|█████████████████▍                                                                 | 2050/9741 [00:03<00:09, 773.40it/s] 22%|██████████████████▏                                                                | 2128/9741 [00:03<00:09, 765.67it/s] 23%|██████████████████▊                                                                | 2206/9741 [00:03<00:09, 769.62it/s] 23%|███████████████████▍                                                               | 2284/9741 [00:03<00:09, 770.35it/s] 24%|████████████████████▏                                                              | 2362/9741 [00:03<00:09, 772.64it/s] 25%|████████████████████▊                                                              | 2440/9741 [00:03<00:09, 772.68it/s] 26%|█████████████████████▍                                                             | 2518/9741 [00:03<00:09, 774.44it/s] 27%|██████████████████████                                                             | 2596/9741 [00:03<00:09, 775.95it/s] 27%|██████████████████████▊                                                            | 2674/9741 [00:03<00:09, 773.72it/s] 28%|███████████████████████▍                                                           | 2752/9741 [00:03<00:09, 772.50it/s] 29%|████████████████████████                                                           | 2830/9741 [00:04<00:08, 772.68it/s] 30%|████████████████████████▊                                                          | 2908/9741 [00:04<00:08, 771.34it/s] 31%|█████████████████████████▍                                                         | 2986/9741 [00:04<00:08, 772.30it/s] 31%|██████████████████████████                                                         | 3064/9741 [00:04<00:08, 773.35it/s] 32%|██████████████████████████▊                                                        | 3142/9741 [00:04<00:08, 770.70it/s] 33%|███████████████████████████▍                                                       | 3220/9741 [00:04<00:08, 772.15it/s] 34%|████████████████████████████                                                       | 3298/9741 [00:04<00:08, 772.61it/s] 35%|████████████████████████████▊                                                      | 3376/9741 [00:04<00:08, 770.38it/s] 35%|█████████████████████████████▍                                                     | 3454/9741 [00:04<00:08, 770.74it/s] 36%|██████████████████████████████                                                     | 3532/9741 [00:04<00:08, 769.89it/s] 37%|██████████████████████████████▊                                                    | 3609/9741 [00:05<00:07, 768.35it/s] 38%|███████████████████████████████▍                                                   | 3686/9741 [00:05<00:07, 768.73it/s] 39%|████████████████████████████████                                                   | 3764/9741 [00:05<00:07, 770.37it/s] 39%|████████████████████████████████▋                                                  | 3842/9741 [00:05<00:07, 768.31it/s] 40%|█████████████████████████████████▍                                                 | 3920/9741 [00:05<00:07, 770.11it/s] 41%|██████████████████████████████████                                                 | 3998/9741 [00:05<00:07, 770.18it/s] 42%|██████████████████████████████████▋                                                | 4076/9741 [00:05<00:07, 767.67it/s] 43%|███████████████████████████████████▍                                               | 4153/9741 [00:05<00:07, 766.89it/s] 43%|████████████████████████████████████                                               | 4230/9741 [00:05<00:07, 766.34it/s] 44%|████████████████████████████████████▋                                              | 4307/9741 [00:05<00:07, 765.12it/s] 45%|█████████████████████████████████████▎                                             | 4384/9741 [00:06<00:07, 765.13it/s] 46%|██████████████████████████████████████                                             | 4461/9741 [00:06<00:07, 753.57it/s] 47%|██████████████████████████████████████▋                                            | 4537/9741 [00:06<00:07, 709.98it/s] 47%|███████████████████████████████████████▎                                           | 4614/9741 [00:06<00:07, 725.35it/s] 48%|███████████████████████████████████████▉                                           | 4691/9741 [00:06<00:06, 737.19it/s] 49%|████████████████████████████████████████▌                                          | 4766/9741 [00:06<00:08, 558.75it/s] 50%|█████████████████████████████████████████▎                                         | 4843/9741 [00:06<00:08, 607.86it/s] 50%|█████████████████████████████████████████▉                                         | 4919/9741 [00:06<00:07, 646.18it/s] 51%|██████████████████████████████████████████▌                                        | 4996/9741 [00:07<00:07, 677.77it/s] 52%|███████████████████████████████████████████▏                                       | 5072/9741 [00:07<00:06, 700.09it/s] 53%|███████████████████████████████████████████▊                                       | 5148/9741 [00:07<00:06, 716.51it/s] 54%|████████████████████████████████████████████▌                                      | 5225/9741 [00:07<00:06, 730.53it/s] 54%|█████████████████████████████████████████████▏                                     | 5302/9741 [00:07<00:06, 739.30it/s] 55%|█████████████████████████████████████████████▊                                     | 5378/9741 [00:07<00:05, 741.81it/s] 56%|██████████████████████████████████████████████▍                                    | 5454/9741 [00:07<00:05, 745.24it/s] 57%|███████████████████████████████████████████████                                    | 5530/9741 [00:07<00:05, 747.64it/s] 58%|███████████████████████████████████████████████▊                                   | 5606/9741 [00:07<00:05, 742.92it/s] 58%|████████████████████████████████████████████████▍                                  | 5681/9741 [00:07<00:05, 744.59it/s] 59%|█████████████████████████████████████████████████                                  | 5757/9741 [00:08<00:05, 746.21it/s] 60%|█████████████████████████████████████████████████▋                                 | 5832/9741 [00:08<00:05, 745.51it/s] 61%|██████████████████████████████████████████████████▎                                | 5908/9741 [00:08<00:05, 747.68it/s] 61%|██████████████████████████████████████████████████▉                                | 5984/9741 [00:08<00:05, 750.38it/s] 62%|███████████████████████████████████████████████████▋                               | 6060/9741 [00:08<00:04, 751.25it/s] 63%|████████████████████████████████████████████████████▎                              | 6136/9741 [00:08<00:04, 753.75it/s] 64%|████████████████████████████████████████████████████▉                              | 6212/9741 [00:08<00:04, 755.57it/s] 65%|█████████████████████████████████████████████████████▌                             | 6288/9741 [00:08<00:04, 754.13it/s] 65%|██████████████████████████████████████████████████████▏                            | 6364/9741 [00:08<00:04, 754.77it/s] 66%|██████████████████████████████████████████████████████▊                            | 6440/9741 [00:08<00:04, 755.79it/s] 67%|███████████████████████████████████████████████████████▌                           | 6516/9741 [00:09<00:04, 754.05it/s] 68%|████████████████████████████████████████████████████████▏                          | 6592/9741 [00:09<00:04, 755.11it/s] 68%|████████████████████████████████████████████████████████▊                          | 6668/9741 [00:09<00:04, 756.02it/s] 69%|█████████████████████████████████████████████████████████▍                         | 6744/9741 [00:09<00:03, 753.08it/s] 70%|██████████████████████████████████████████████████████████                         | 6820/9741 [00:09<00:03, 753.94it/s] 71%|██████████████████████████████████████████████████████████▊                        | 6896/9741 [00:09<00:03, 753.85it/s] 72%|███████████████████████████████████████████████████████████▍                       | 6972/9741 [00:09<00:03, 751.31it/s] 72%|████████████████████████████████████████████████████████████                       | 7048/9741 [00:09<00:03, 752.09it/s] 73%|████████████████████████████████████████████████████████████▋                      | 7124/9741 [00:09<00:03, 752.21it/s] 74%|█████████████████████████████████████████████████████████████▎                     | 7200/9741 [00:09<00:03, 751.25it/s] 75%|█████████████████████████████████████████████████████████████▉                     | 7276/9741 [00:10<00:03, 750.84it/s] 75%|██████████████████████████████████████████████████████████████▋                    | 7352/9741 [00:10<00:03, 750.96it/s] 76%|███████████████████████████████████████████████████████████████▎                   | 7428/9741 [00:10<00:03, 725.06it/s] 77%|███████████████████████████████████████████████████████████████▉                   | 7504/9741 [00:10<00:03, 732.47it/s] 78%|████████████████████████████████████████████████████████████████▌                  | 7580/9741 [00:10<00:02, 738.53it/s] 79%|█████████████████████████████████████████████████████████████████▏                 | 7655/9741 [00:10<00:02, 740.94it/s] 79%|█████████████████████████████████████████████████████████████████▊                 | 7731/9741 [00:10<00:02, 744.79it/s] 80%|██████████████████████████████████████████████████████████████████▌                | 7807/9741 [00:10<00:02, 746.56it/s] 81%|███████████████████████████████████████████████████████████████████▏               | 7882/9741 [00:10<00:02, 745.95it/s] 82%|███████████████████████████████████████████████████████████████████▊               | 7957/9741 [00:10<00:02, 747.00it/s] 82%|████████████████████████████████████████████████████████████████████▍              | 8032/9741 [00:11<00:02, 747.25it/s] 83%|█████████████████████████████████████████████████████████████████████              | 8107/9741 [00:11<00:02, 746.56it/s] 84%|█████████████████████████████████████████████████████████████████████▋             | 8184/9741 [00:11<00:02, 751.51it/s] 85%|██████████████████████████████████████████████████████████████████████▍            | 8260/9741 [00:11<00:01, 753.51it/s] 86%|███████████████████████████████████████████████████████████████████████            | 8336/9741 [00:11<00:01, 751.72it/s] 86%|███████████████████████████████████████████████████████████████████████▋           | 8412/9741 [00:11<00:01, 753.25it/s] 87%|████████████████████████████████████████████████████████████████████████▎          | 8488/9741 [00:11<00:01, 752.78it/s] 88%|████████████████████████████████████████████████████████████████████████▉          | 8564/9741 [00:11<00:01, 750.11it/s] 89%|█████████████████████████████████████████████████████████████████████████▌         | 8640/9741 [00:11<00:01, 749.38it/s] 89%|██████████████████████████████████████████████████████████████████████████▎        | 8716/9741 [00:11<00:01, 750.75it/s] 90%|██████████████████████████████████████████████████████████████████████████▉        | 8792/9741 [00:12<00:01, 749.01it/s] 91%|███████████████████████████████████████████████████████████████████████████▌       | 8868/9741 [00:12<00:01, 749.75it/s] 92%|████████████████████████████████████████████████████████████████████████████▏      | 8943/9741 [00:12<00:01, 733.82it/s] 93%|████████████████████████████████████████████████████████████████████████████▊      | 9017/9741 [00:12<00:00, 735.60it/s] 93%|█████████████████████████████████████████████████████████████████████████████▍     | 9093/9741 [00:12<00:00, 740.14it/s] 94%|██████████████████████████████████████████████████████████████████████████████▏    | 9169/9741 [00:12<00:00, 743.46it/s] 95%|██████████████████████████████████████████████████████████████████████████████▊    | 9244/9741 [00:12<00:00, 744.44it/s] 96%|███████████████████████████████████████████████████████████████████████████████▍   | 9320/9741 [00:12<00:00, 746.05it/s] 96%|████████████████████████████████████████████████████████████████████████████████   | 9395/9741 [00:12<00:00, 746.62it/s] 97%|████████████████████████████████████████████████████████████████████████████████▋  | 9470/9741 [00:12<00:00, 744.59it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▎ | 9545/9741 [00:13<00:00, 745.08it/s] 99%|█████████████████████████████████████████████████████████████████████████████████▉ | 9621/9741 [00:13<00:00, 746.75it/s]100%|██████████████████████████████████████████████████████████████████████████████████▌| 9696/9741 [00:13<00:00, 745.66it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:13<00:00, 729.65it/s]
Load End
Num instances: 1000
[2023-08-23 10:10:44,634] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-23 10:10:47,402] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-23 10:10:47,402] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f9e17618a60>
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-23 10:10:47,403] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f9e17618940>
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-23 10:10:47,404] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-23 10:10:47,404] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4672393798828125 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: The car-rental agency charges $30/day for a car, or $190 for the first week for a rental that lasts an entire week or longer. Jennie rented a car for 11 days. How much, in dollars, did she pay for the rental?
Output: The first 7 days were $190.
There were 11-7=<<11-7=4>>4 days left.
The additional 4 days were 4*30=<<4*30=120>>120.
And 190+120=<<190+120=310>>310.
So the final answer is 310

Input: A hurricane is approaching the southern coast of Texas, and a rancher is planning to move 400 head of cattle 60 miles to higher ground to protect them from possible inland flooding that might occur.  His animal transport truck holds 20 head of cattle.  Traveling at 60 miles per hour, what is the total driving time, in hours, it will take to transport all of his cattle to higher ground?
Output: Given the limited capacity of his transport vehicle (20 head of cattle), the 400 head of cattle will require 400/20=<<400/20=20>>20 trips using his transport vehicle.
Traveling to the site at 60 mph for 60 miles it will take 60/60=<<60/60=1>>1 hour to travel one-way.
Since each trip requires driving to and returning from the relocation site, each complete round trip will take 2*1=<<2*1=2>>2 hours.
Thus, 20 complete trips will take 20*2=<<20*2=40>>40 hours of driving time.
So the final answer is 40

Input: Jason has a carriage house that he rents out.  He’s charging $50.00 per day or $500.00 for 14 days.  Eric wants to rent the house for 20 days.  How much will it cost him?
Output: He wants to rent for 20 days and there is a deal if you rent for 14 days so that leaves 20-14 = <<20-14=6>>6 individual days
Each individual day is $50.00 and he will have 6 individual days for a total of 50*6 = $<<50*6=300.00>>300.00
14 days costs $500.00 and 6 days costs $300.00 for a total of 500+300 = $800.00
So the final answer is 800

Input: Melissa works on a poultry farm. She drives to town twice each month to buy supplies. If it takes her 3 hours to drive to town and back, how many hours does Melissa spend driving in a year?
Output: Melissa spends 2x3=<<2*3=6>>6 hours driving each month.
Since there are 12 months in a year, she spends 6x12=<<6*12=72>>72 hours driving each year.
So the final answer is 72

Input: The ratio of boys to girls in a family is 5:7. The total number of children in the family is 180. If the boys are given $3900 to share, how much money does each boy receive?
Output: The total ratio representing the number of children in the family is 5+7 = <<5+7=12>>12
From the total ratio of children in the family, 5/12 represent the number of boys, meaning that the number of boys in the family is 5/12*180 = <<5/12*180=75>>75
If the boys are given $3900 to share, each boy receives $3900/75 = $<<3900/75=52>>52
So the final answer is 52

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o5-tgsm8k-s30-rTrue
Loading extension module utils...
Time to load utils op: 0.504777193069458 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:44<36:10, 44.29s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:26<34:31, 43.15s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [02:09<33:43, 43.06s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [02:51<32:45, 42.72s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [03:34<31:57, 42.61s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [04:16<31:11, 42.53s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [04:58<30:23, 42.41s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [05:41<29:43, 42.47s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [06:24<29:05, 42.58s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [07:06<28:15, 42.39s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [07:48<27:28, 42.26s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [08:29<26:40, 42.11s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [09:12<26:07, 42.36s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [09:54<25:15, 42.11s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [10:36<24:33, 42.09s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [11:18<23:49, 42.04s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [12:00<23:08, 42.07s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [12:42<22:25, 42.05s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [13:25<21:49, 42.24s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [14:07<21:06, 42.23s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [14:48<20:18, 42.03s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [15:31<19:45, 42.32s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [16:13<18:58, 42.17s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [16:56<18:19, 42.29s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [17:39<17:41, 42.46s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [18:22<17:01, 42.58s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [19:04<16:16, 42.44s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [19:46<15:32, 42.37s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [20:27<14:43, 42.08s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [21:10<14:03, 42.17s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [21:51<13:19, 42.06s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [22:33<12:34, 41.92s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [23:16<12:00, 42.36s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [23:58<11:15, 42.22s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [24:40<10:32, 42.17s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [25:23<09:51, 42.26s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [26:06<09:11, 42.43s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [26:48<08:28, 42.39s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [27:30<07:45, 42.35s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [28:13<07:03, 42.36s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [28:55<06:22, 42.51s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [29:38<05:39, 42.40s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [30:20<04:57, 42.47s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [31:03<04:15, 42.58s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [31:46<03:32, 42.56s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [32:28<02:49, 42.41s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [33:10<02:06, 42.28s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [33:52<01:24, 42.33s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [34:34<00:42, 42.18s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [35:16<00:00, 42.21s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [35:16<00:00, 42.33s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.2903} | avg. gen lenth: 434.286
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s30-rTrue --seed 30 --max-prompt-length 2048 --rationales --num-out-domain 6
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-23 10:46:33,585] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o6-tgsm8k-s30-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 6
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o6-tgsm8k-s30-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  0%|▍                                                                                    | 45/9741 [00:00<00:21, 443.05it/s]  1%|▊                                                                                    | 91/9741 [00:00<00:21, 448.20it/s]  1%|█▏                                                                                  | 137/9741 [00:00<00:21, 452.10it/s]  2%|█▌                                                                                  | 183/9741 [00:00<00:21, 452.81it/s]  2%|█▉                                                                                  | 230/9741 [00:00<00:20, 455.80it/s]  3%|██▍                                                                                 | 276/9741 [00:00<00:20, 456.96it/s]  3%|██▊                                                                                 | 323/9741 [00:00<00:20, 458.85it/s]  4%|███▏                                                                                | 369/9741 [00:00<00:20, 449.22it/s]  4%|███▌                                                                                | 414/9741 [00:00<00:20, 447.94it/s]  5%|███▉                                                                                | 461/9741 [00:01<00:20, 452.82it/s]  5%|████▍                                                                               | 508/9741 [00:01<00:20, 456.16it/s]  6%|████▊                                                                               | 555/9741 [00:01<00:20, 457.87it/s]  6%|█████▏                                                                              | 602/9741 [00:01<00:19, 460.80it/s]  7%|█████▌                                                                              | 649/9741 [00:01<00:19, 462.71it/s]  7%|██████                                                                              | 697/9741 [00:01<00:19, 466.65it/s]  8%|██████▍                                                                             | 745/9741 [00:01<00:19, 468.79it/s]  8%|██████▊                                                                             | 793/9741 [00:01<00:19, 470.22it/s]  9%|███████▎                                                                            | 841/9741 [00:01<00:18, 468.91it/s]  9%|███████▋                                                                            | 888/9741 [00:01<00:18, 466.31it/s] 10%|████████▏                                                                           | 945/9741 [00:02<00:17, 496.95it/s] 10%|████████▋                                                                          | 1015/9741 [00:02<00:15, 555.43it/s] 11%|█████████▏                                                                         | 1083/9741 [00:02<00:14, 592.43it/s] 12%|█████████▊                                                                         | 1153/9741 [00:02<00:13, 623.70it/s] 13%|██████████▍                                                                        | 1220/9741 [00:02<00:13, 636.46it/s] 13%|██████████▉                                                                        | 1284/9741 [00:02<00:13, 624.90it/s] 14%|███████████▍                                                                       | 1348/9741 [00:02<00:13, 627.18it/s] 15%|████████████                                                                       | 1416/9741 [00:02<00:12, 642.08it/s] 15%|████████████▋                                                                      | 1485/9741 [00:02<00:12, 654.56it/s] 16%|█████████████▏                                                                     | 1553/9741 [00:02<00:12, 661.25it/s] 17%|█████████████▊                                                                     | 1620/9741 [00:03<00:12, 646.08it/s] 17%|██████████████▎                                                                    | 1685/9741 [00:03<00:12, 645.66it/s] 18%|██████████████▉                                                                    | 1753/9741 [00:03<00:12, 655.66it/s] 19%|███████████████▍                                                                   | 1819/9741 [00:03<00:12, 619.47it/s] 19%|████████████████                                                                   | 1887/9741 [00:03<00:12, 634.19it/s] 20%|████████████████▋                                                                  | 1955/9741 [00:03<00:12, 644.99it/s] 21%|█████████████████▏                                                                 | 2021/9741 [00:03<00:11, 646.87it/s] 21%|█████████████████▊                                                                 | 2088/9741 [00:03<00:11, 651.24it/s] 22%|██████████████████▎                                                                | 2156/9741 [00:03<00:11, 658.56it/s] 23%|██████████████████▉                                                                | 2224/9741 [00:03<00:11, 662.10it/s] 24%|███████████████████▌                                                               | 2292/9741 [00:04<00:11, 665.62it/s] 24%|████████████████████                                                               | 2359/9741 [00:04<00:11, 666.56it/s] 25%|████████████████████▋                                                              | 2427/9741 [00:04<00:10, 669.30it/s] 26%|█████████████████████▎                                                             | 2494/9741 [00:04<00:10, 668.26it/s] 26%|█████████████████████▊                                                             | 2561/9741 [00:04<00:10, 667.64it/s] 27%|██████████████████████▍                                                            | 2628/9741 [00:04<00:11, 616.99it/s] 28%|██████████████████████▉                                                            | 2691/9741 [00:04<00:12, 544.44it/s] 28%|███████████████████████▍                                                           | 2756/9741 [00:04<00:12, 571.69it/s] 29%|███████████████████████▉                                                           | 2815/9741 [00:04<00:12, 552.74it/s] 29%|████████████████████████▍                                                          | 2872/9741 [00:05<00:12, 547.65it/s] 30%|█████████████████████████                                                          | 2937/9741 [00:05<00:11, 574.55it/s] 31%|█████████████████████████▌                                                         | 3004/9741 [00:05<00:11, 600.11it/s] 32%|██████████████████████████▏                                                        | 3071/9741 [00:05<00:10, 617.50it/s] 32%|██████████████████████████▋                                                        | 3138/9741 [00:05<00:10, 629.98it/s] 33%|███████████████████████████▎                                                       | 3205/9741 [00:05<00:10, 641.26it/s] 34%|███████████████████████████▉                                                       | 3272/9741 [00:05<00:09, 648.36it/s] 34%|████████████████████████████▍                                                      | 3338/9741 [00:05<00:09, 651.60it/s] 35%|█████████████████████████████                                                      | 3404/9741 [00:05<00:09, 651.80it/s] 36%|█████████████████████████████▌                                                     | 3470/9741 [00:05<00:09, 648.59it/s] 36%|██████████████████████████████                                                     | 3535/9741 [00:06<00:09, 640.44it/s] 37%|██████████████████████████████▋                                                    | 3600/9741 [00:06<00:09, 641.42it/s] 38%|███████████████████████████████▏                                                   | 3667/9741 [00:06<00:09, 647.79it/s] 38%|███████████████████████████████▊                                                   | 3733/9741 [00:06<00:09, 651.17it/s] 39%|████████████████████████████████▎                                                  | 3799/9741 [00:06<00:09, 652.04it/s] 40%|████████████████████████████████▉                                                  | 3865/9741 [00:06<00:09, 650.95it/s] 40%|█████████████████████████████████▍                                                 | 3931/9741 [00:06<00:08, 651.80it/s] 41%|██████████████████████████████████                                                 | 3997/9741 [00:06<00:08, 652.15it/s] 42%|██████████████████████████████████▌                                                | 4063/9741 [00:06<00:08, 651.09it/s] 42%|███████████████████████████████████▏                                               | 4129/9741 [00:07<00:08, 651.37it/s] 43%|███████████████████████████████████▋                                               | 4195/9741 [00:07<00:08, 651.49it/s] 44%|████████████████████████████████████▎                                              | 4261/9741 [00:07<00:08, 653.21it/s] 44%|████████████████████████████████████▉                                              | 4328/9741 [00:07<00:08, 656.61it/s] 45%|█████████████████████████████████████▍                                             | 4395/9741 [00:07<00:08, 658.66it/s] 46%|██████████████████████████████████████                                             | 4462/9741 [00:07<00:08, 659.39it/s] 46%|██████████████████████████████████████▌                                            | 4528/9741 [00:07<00:08, 620.11it/s] 47%|███████████████████████████████████████▏                                           | 4595/9741 [00:07<00:08, 632.21it/s] 48%|███████████████████████████████████████▋                                           | 4659/9741 [00:07<00:08, 634.05it/s] 48%|████████████████████████████████████████▏                                          | 4723/9741 [00:08<00:09, 509.75it/s] 49%|████████████████████████████████████████▊                                          | 4788/9741 [00:08<00:09, 544.79it/s] 50%|█████████████████████████████████████████▎                                         | 4853/9741 [00:08<00:08, 572.09it/s] 50%|█████████████████████████████████████████▉                                         | 4918/9741 [00:08<00:08, 591.67it/s] 51%|██████████████████████████████████████████▍                                        | 4983/9741 [00:08<00:07, 607.80it/s] 52%|███████████████████████████████████████████                                        | 5048/9741 [00:08<00:07, 618.02it/s] 52%|███████████████████████████████████████████▌                                       | 5113/9741 [00:08<00:07, 624.59it/s] 53%|████████████████████████████████████████████                                       | 5177/9741 [00:08<00:07, 627.18it/s] 54%|████████████████████████████████████████████▋                                      | 5241/9741 [00:08<00:07, 629.62it/s] 54%|█████████████████████████████████████████████▏                                     | 5305/9741 [00:08<00:07, 631.00it/s] 55%|█████████████████████████████████████████████▋                                     | 5369/9741 [00:09<00:06, 629.70it/s] 56%|██████████████████████████████████████████████▎                                    | 5433/9741 [00:09<00:06, 631.48it/s] 56%|██████████████████████████████████████████████▊                                    | 5499/9741 [00:09<00:06, 638.18it/s] 57%|███████████████████████████████████████████████▍                                   | 5565/9741 [00:09<00:06, 643.09it/s] 58%|███████████████████████████████████████████████▉                                   | 5630/9741 [00:09<00:06, 644.57it/s] 58%|████████████████████████████████████████████████▌                                  | 5696/9741 [00:09<00:06, 647.61it/s] 59%|█████████████████████████████████████████████████                                  | 5762/9741 [00:09<00:06, 649.33it/s] 60%|█████████████████████████████████████████████████▋                                 | 5827/9741 [00:09<00:06, 648.41it/s] 60%|██████████████████████████████████████████████████▏                                | 5893/9741 [00:09<00:05, 649.18it/s] 61%|██████████████████████████████████████████████████▊                                | 5958/9741 [00:09<00:05, 646.53it/s] 62%|███████████████████████████████████████████████████▎                               | 6023/9741 [00:10<00:05, 643.84it/s] 62%|███████████████████████████████████████████████████▊                               | 6088/9741 [00:10<00:05, 640.98it/s] 63%|████████████████████████████████████████████████████▍                              | 6153/9741 [00:10<00:05, 640.74it/s] 64%|████████████████████████████████████████████████████▉                              | 6218/9741 [00:10<00:05, 641.10it/s] 65%|█████████████████████████████████████████████████████▌                             | 6283/9741 [00:10<00:05, 640.33it/s] 65%|██████████████████████████████████████████████████████                             | 6348/9741 [00:10<00:05, 641.92it/s] 66%|██████████████████████████████████████████████████████▋                            | 6413/9741 [00:10<00:05, 643.15it/s] 67%|███████████████████████████████████████████████████████▏                           | 6478/9741 [00:10<00:05, 643.10it/s] 67%|███████████████████████████████████████████████████████▊                           | 6543/9741 [00:10<00:05, 639.43it/s] 68%|████████████████████████████████████████████████████████▎                          | 6607/9741 [00:10<00:04, 639.18it/s] 68%|████████████████████████████████████████████████████████▊                          | 6672/9741 [00:11<00:04, 639.79it/s] 69%|█████████████████████████████████████████████████████████▍                         | 6736/9741 [00:11<00:04, 638.51it/s] 70%|█████████████████████████████████████████████████████████▉                         | 6800/9741 [00:11<00:04, 638.62it/s] 70%|██████████████████████████████████████████████████████████▍                        | 6865/9741 [00:11<00:04, 641.01it/s] 71%|███████████████████████████████████████████████████████████                        | 6930/9741 [00:11<00:04, 642.66it/s] 72%|███████████████████████████████████████████████████████████▌                       | 6995/9741 [00:11<00:04, 642.09it/s] 72%|████████████████████████████████████████████████████████████▏                      | 7060/9741 [00:11<00:04, 643.71it/s] 73%|████████████████████████████████████████████████████████████▋                      | 7125/9741 [00:11<00:04, 644.66it/s] 74%|█████████████████████████████████████████████████████████████▎                     | 7190/9741 [00:11<00:03, 643.15it/s] 74%|█████████████████████████████████████████████████████████████▊                     | 7255/9741 [00:11<00:03, 644.29it/s] 75%|██████████████████████████████████████████████████████████████▎                    | 7320/9741 [00:12<00:03, 645.40it/s] 76%|██████████████████████████████████████████████████████████████▉                    | 7385/9741 [00:12<00:03, 646.39it/s] 76%|███████████████████████████████████████████████████████████████▍                   | 7450/9741 [00:12<00:03, 596.46it/s] 77%|████████████████████████████████████████████████████████████████                   | 7514/9741 [00:12<00:03, 607.89it/s] 78%|████████████████████████████████████████████████████████████████▌                  | 7578/9741 [00:12<00:03, 616.87it/s] 78%|█████████████████████████████████████████████████████████████████                  | 7642/9741 [00:12<00:03, 623.38it/s] 79%|█████████████████████████████████████████████████████████████████▋                 | 7707/9741 [00:12<00:03, 628.38it/s] 80%|██████████████████████████████████████████████████████████████████▏                | 7771/9741 [00:12<00:03, 631.75it/s] 80%|██████████████████████████████████████████████████████████████████▊                | 7836/9741 [00:12<00:03, 634.56it/s] 81%|███████████████████████████████████████████████████████████████████▎               | 7901/9741 [00:12<00:02, 638.48it/s] 82%|███████████████████████████████████████████████████████████████████▉               | 7967/9741 [00:13<00:02, 643.90it/s] 82%|████████████████████████████████████████████████████████████████████▍              | 8033/9741 [00:13<00:02, 646.69it/s] 83%|█████████████████████████████████████████████████████████████████████              | 8098/9741 [00:13<00:02, 647.58it/s] 84%|█████████████████████████████████████████████████████████████████████▌             | 8164/9741 [00:13<00:02, 650.20it/s] 84%|██████████████████████████████████████████████████████████████████████▏            | 8230/9741 [00:13<00:02, 652.01it/s] 85%|██████████████████████████████████████████████████████████████████████▋            | 8296/9741 [00:13<00:02, 652.84it/s] 86%|███████████████████████████████████████████████████████████████████████▏           | 8362/9741 [00:13<00:02, 651.59it/s] 87%|███████████████████████████████████████████████████████████████████████▊           | 8428/9741 [00:13<00:02, 650.91it/s] 87%|████████████████████████████████████████████████████████████████████████▎          | 8494/9741 [00:13<00:01, 648.13it/s] 88%|████████████████████████████████████████████████████████████████████████▉          | 8559/9741 [00:14<00:01, 643.95it/s] 89%|█████████████████████████████████████████████████████████████████████████▍         | 8624/9741 [00:14<00:01, 642.54it/s] 89%|██████████████████████████████████████████████████████████████████████████         | 8689/9741 [00:14<00:01, 642.59it/s] 90%|██████████████████████████████████████████████████████████████████████████▌        | 8754/9741 [00:14<00:01, 643.41it/s] 91%|███████████████████████████████████████████████████████████████████████████▏       | 8819/9741 [00:14<00:01, 635.29it/s] 91%|███████████████████████████████████████████████████████████████████████████▋       | 8884/9741 [00:14<00:01, 637.57it/s] 92%|████████████████████████████████████████████████████████████████████████████▎      | 8949/9741 [00:14<00:01, 640.13it/s] 93%|████████████████████████████████████████████████████████████████████████████▊      | 9014/9741 [00:14<00:01, 638.86it/s] 93%|█████████████████████████████████████████████████████████████████████████████▎     | 9079/9741 [00:14<00:01, 640.09it/s] 94%|█████████████████████████████████████████████████████████████████████████████▉     | 9144/9741 [00:14<00:00, 641.11it/s] 95%|██████████████████████████████████████████████████████████████████████████████▍    | 9209/9741 [00:15<00:00, 642.04it/s] 95%|███████████████████████████████████████████████████████████████████████████████    | 9274/9741 [00:15<00:00, 640.87it/s] 96%|███████████████████████████████████████████████████████████████████████████████▌   | 9339/9741 [00:15<00:00, 641.28it/s] 97%|████████████████████████████████████████████████████████████████████████████████▏  | 9404/9741 [00:15<00:00, 641.69it/s] 97%|████████████████████████████████████████████████████████████████████████████████▋  | 9469/9741 [00:15<00:00, 640.03it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▏ | 9534/9741 [00:15<00:00, 639.76it/s] 99%|█████████████████████████████████████████████████████████████████████████████████▊ | 9598/9741 [00:15<00:00, 638.75it/s] 99%|██████████████████████████████████████████████████████████████████████████████████▎| 9663/9741 [00:15<00:00, 641.22it/s]100%|██████████████████████████████████████████████████████████████████████████████████▉| 9728/9741 [00:15<00:00, 638.69it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:15<00:00, 614.42it/s]
Load End
Num instances: 1000
[2023-08-23 10:47:00,961] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-23 10:47:03,699] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-23 10:47:03,699] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-23 10:47:03,699] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-23 10:47:03,699] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-23 10:47:03,699] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-23 10:47:03,699] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f164af86a60>
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f164af86940>
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-23 10:47:03,700] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-23 10:47:03,701] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-23 10:47:03,701] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-23 10:47:03,701] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-23 10:47:03,701] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-23 10:47:03,701] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-23 10:47:03,701] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-23 10:47:03,701] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-23 10:47:03,701] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-23 10:47:03,701] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-23 10:47:03,701] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-23 10:47:03,701] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-23 10:47:03,701] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-23 10:47:03,701] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-23 10:47:03,701] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-23 10:47:03,701] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-23 10:47:03,701] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Loading extension module utils...
Time to load utils op: 0.43701934814453125 seconds
Time to load utils op: 0.4045708179473877 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: The car-rental agency charges $30/day for a car, or $190 for the first week for a rental that lasts an entire week or longer. Jennie rented a car for 11 days. How much, in dollars, did she pay for the rental?
Output: The first 7 days were $190.
There were 11-7=<<11-7=4>>4 days left.
The additional 4 days were 4*30=<<4*30=120>>120.
And 190+120=<<190+120=310>>310.
So the final answer is 310

Input: A hurricane is approaching the southern coast of Texas, and a rancher is planning to move 400 head of cattle 60 miles to higher ground to protect them from possible inland flooding that might occur.  His animal transport truck holds 20 head of cattle.  Traveling at 60 miles per hour, what is the total driving time, in hours, it will take to transport all of his cattle to higher ground?
Output: Given the limited capacity of his transport vehicle (20 head of cattle), the 400 head of cattle will require 400/20=<<400/20=20>>20 trips using his transport vehicle.
Traveling to the site at 60 mph for 60 miles it will take 60/60=<<60/60=1>>1 hour to travel one-way.
Since each trip requires driving to and returning from the relocation site, each complete round trip will take 2*1=<<2*1=2>>2 hours.
Thus, 20 complete trips will take 20*2=<<20*2=40>>40 hours of driving time.
So the final answer is 40

Input: Jason has a carriage house that he rents out.  He’s charging $50.00 per day or $500.00 for 14 days.  Eric wants to rent the house for 20 days.  How much will it cost him?
Output: He wants to rent for 20 days and there is a deal if you rent for 14 days so that leaves 20-14 = <<20-14=6>>6 individual days
Each individual day is $50.00 and he will have 6 individual days for a total of 50*6 = $<<50*6=300.00>>300.00
14 days costs $500.00 and 6 days costs $300.00 for a total of 500+300 = $800.00
So the final answer is 800

Input: Melissa works on a poultry farm. She drives to town twice each month to buy supplies. If it takes her 3 hours to drive to town and back, how many hours does Melissa spend driving in a year?
Output: Melissa spends 2x3=<<2*3=6>>6 hours driving each month.
Since there are 12 months in a year, she spends 6x12=<<6*12=72>>72 hours driving each year.
So the final answer is 72

Input: The ratio of boys to girls in a family is 5:7. The total number of children in the family is 180. If the boys are given $3900 to share, how much money does each boy receive?
Output: The total ratio representing the number of children in the family is 5+7 = <<5+7=12>>12
From the total ratio of children in the family, 5/12 represent the number of boys, meaning that the number of boys in the family is 5/12*180 = <<5/12*180=75>>75
If the boys are given $3900 to share, each boy receives $3900/75 = $<<3900/75=52>>52
So the final answer is 52

Input: Josephine receives a bill from the hospital for 5000$.  50 percent of the bill is for medication.  25 percent of the remaining bill is for overnight stays, and 175$ is for food.  The rest of the bill is for the ambulance ride.  How much did the ambulance ride cost?
Output: Medication:5000(.50)=2500
Overnight Stays:2500(.25)=625
2500-625=<<2500-625=1875>>1875
Food:1875-175=<<1875-175=1700>>1700$
Ambulance ride:1700$
So the final answer is 1700

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o6-tgsm8k-s30-rTrue
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:39<32:20, 39.60s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:20<32:09, 40.20s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [01:59<31:18, 39.96s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [02:39<30:34, 39.89s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [03:20<30:02, 40.06s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [04:00<29:24, 40.09s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [04:39<28:39, 39.99s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [05:19<27:53, 39.85s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [05:59<27:14, 39.88s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [06:38<26:30, 39.76s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [07:18<25:50, 39.75s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [07:58<25:13, 39.83s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [08:39<24:40, 40.03s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [09:18<23:55, 39.87s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [09:58<23:15, 39.87s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [10:39<22:44, 40.14s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [11:19<22:03, 40.10s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [11:59<21:21, 40.04s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [12:39<20:39, 39.99s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [13:18<19:56, 39.89s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [13:58<19:13, 39.79s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [14:38<18:35, 39.84s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [15:18<17:59, 39.98s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [15:58<17:15, 39.82s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [16:37<16:30, 39.64s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [17:16<15:51, 39.64s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [17:56<15:11, 39.64s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [18:36<14:31, 39.63s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [19:16<13:55, 39.80s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [19:55<13:13, 39.68s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [20:34<12:31, 39.54s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [21:15<11:55, 39.75s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [21:55<11:18, 39.93s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [22:34<10:35, 39.71s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [23:14<09:54, 39.62s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [23:54<09:17, 39.85s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [24:34<08:37, 39.84s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [25:14<07:59, 39.99s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [25:55<07:21, 40.17s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [26:35<06:40, 40.07s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [27:14<05:58, 39.82s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [27:54<05:19, 39.88s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [28:34<04:40, 40.06s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [29:14<03:59, 39.98s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [29:54<03:19, 39.87s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [30:34<02:39, 39.92s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [31:14<01:59, 39.89s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [31:54<01:19, 39.93s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [32:33<00:39, 39.77s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [33:12<00:00, 39.67s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [33:12<00:00, 39.86s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.8926} | avg. gen lenth: 438.136
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o7-tgsm8k-s30-rTrue --seed 30 --max-prompt-length 2048 --rationales --num-out-domain 7
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-23 11:20:27,041] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o7-tgsm8k-s30-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 7
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o7-tgsm8k-s30-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                               | 0/9741 [00:00<?, ?it/s]  0%|▎                                                                                    | 38/9741 [00:00<00:25, 378.08it/s]  1%|▋                                                                                    | 77/9741 [00:00<00:25, 383.64it/s]  1%|█                                                                                   | 116/9741 [00:00<00:24, 385.07it/s]  2%|█▎                                                                                  | 156/9741 [00:00<00:24, 387.38it/s]  2%|█▋                                                                                  | 195/9741 [00:00<00:24, 388.25it/s]  2%|██                                                                                  | 235/9741 [00:00<00:24, 390.91it/s]  3%|██▎                                                                                 | 275/9741 [00:00<00:24, 392.09it/s]  3%|██▋                                                                                 | 315/9741 [00:00<00:24, 383.71it/s]  4%|███                                                                                 | 355/9741 [00:00<00:24, 386.70it/s]  4%|███▍                                                                                | 395/9741 [00:01<00:24, 388.70it/s]  4%|███▋                                                                                | 434/9741 [00:01<00:24, 387.52it/s]  5%|████                                                                                | 474/9741 [00:01<00:23, 389.39it/s]  5%|████▍                                                                               | 514/9741 [00:01<00:23, 391.03it/s]  6%|████▊                                                                               | 554/9741 [00:01<00:23, 392.53it/s]  6%|█████                                                                               | 594/9741 [00:01<00:23, 393.53it/s]  7%|█████▍                                                                              | 634/9741 [00:01<00:23, 392.90it/s]  7%|█████▊                                                                              | 674/9741 [00:01<00:23, 391.76it/s]  7%|██████▏                                                                             | 723/9741 [00:01<00:21, 419.17it/s]  8%|██████▊                                                                             | 783/9741 [00:01<00:19, 471.21it/s]  9%|███████▎                                                                            | 843/9741 [00:02<00:17, 507.30it/s]  9%|███████▊                                                                            | 902/9741 [00:02<00:16, 530.36it/s] 10%|████████▎                                                                           | 962/9741 [00:02<00:15, 549.35it/s] 10%|████████▋                                                                          | 1022/9741 [00:02<00:15, 562.70it/s] 11%|█████████▏                                                                         | 1081/9741 [00:02<00:15, 569.20it/s] 12%|█████████▋                                                                         | 1141/9741 [00:02<00:14, 576.38it/s] 12%|██████████▏                                                                        | 1201/9741 [00:02<00:14, 581.46it/s] 13%|██████████▋                                                                        | 1260/9741 [00:02<00:14, 583.92it/s] 14%|███████████▏                                                                       | 1319/9741 [00:02<00:14, 583.81it/s] 14%|███████████▊                                                                       | 1379/9741 [00:02<00:14, 585.75it/s] 15%|████████████▎                                                                      | 1438/9741 [00:03<00:14, 586.58it/s] 15%|████████████▊                                                                      | 1497/9741 [00:03<00:14, 587.14it/s] 16%|█████████████▎                                                                     | 1556/9741 [00:03<00:13, 584.87it/s] 17%|█████████████▊                                                                     | 1615/9741 [00:03<00:13, 584.50it/s] 17%|██████████████▎                                                                    | 1674/9741 [00:03<00:13, 585.98it/s] 18%|██████████████▊                                                                    | 1733/9741 [00:03<00:13, 585.54it/s] 18%|███████████████▎                                                                   | 1792/9741 [00:03<00:14, 563.83it/s] 19%|███████████████▊                                                                   | 1851/9741 [00:03<00:13, 569.06it/s] 20%|████████████████▎                                                                  | 1910/9741 [00:03<00:13, 572.89it/s] 20%|████████████████▊                                                                  | 1969/9741 [00:03<00:13, 575.40it/s] 21%|█████████████████▎                                                                 | 2027/9741 [00:04<00:13, 573.86it/s] 21%|█████████████████▊                                                                 | 2085/9741 [00:04<00:13, 574.75it/s] 22%|██████████████████▎                                                                | 2144/9741 [00:04<00:13, 576.51it/s] 23%|██████████████████▊                                                                | 2202/9741 [00:04<00:13, 575.65it/s] 23%|███████████████████▎                                                               | 2260/9741 [00:04<00:13, 573.88it/s] 24%|███████████████████▊                                                               | 2318/9741 [00:04<00:12, 574.06it/s] 24%|████████████████████▏                                                              | 2376/9741 [00:04<00:12, 572.38it/s] 25%|████████████████████▋                                                              | 2434/9741 [00:04<00:12, 573.29it/s] 26%|█████████████████████▏                                                             | 2492/9741 [00:04<00:12, 571.62it/s] 26%|█████████████████████▋                                                             | 2550/9741 [00:04<00:12, 572.79it/s] 27%|██████████████████████▏                                                            | 2608/9741 [00:05<00:12, 573.69it/s] 27%|██████████████████████▋                                                            | 2666/9741 [00:05<00:12, 574.05it/s] 28%|███████████████████████▏                                                           | 2724/9741 [00:05<00:12, 571.42it/s] 29%|███████████████████████▋                                                           | 2782/9741 [00:05<00:12, 571.10it/s] 29%|████████████████████████▏                                                          | 2840/9741 [00:05<00:12, 571.60it/s] 30%|████████████████████████▋                                                          | 2898/9741 [00:05<00:12, 566.84it/s] 30%|█████████████████████████▏                                                         | 2955/9741 [00:05<00:12, 559.64it/s] 31%|█████████████████████████▋                                                         | 3013/9741 [00:05<00:11, 563.16it/s] 32%|██████████████████████████▏                                                        | 3070/9741 [00:05<00:11, 564.59it/s] 32%|██████████████████████████▋                                                        | 3127/9741 [00:05<00:11, 564.07it/s] 33%|███████████████████████████▏                                                       | 3185/9741 [00:06<00:11, 566.63it/s] 33%|███████████████████████████▋                                                       | 3243/9741 [00:06<00:11, 568.48it/s] 34%|████████████████████████████                                                       | 3300/9741 [00:06<00:11, 568.56it/s] 34%|████████████████████████████▌                                                      | 3357/9741 [00:06<00:11, 566.92it/s] 35%|█████████████████████████████                                                      | 3415/9741 [00:06<00:11, 567.96it/s] 36%|█████████████████████████████▌                                                     | 3472/9741 [00:06<00:11, 568.26it/s] 36%|██████████████████████████████                                                     | 3529/9741 [00:06<00:10, 568.30it/s] 37%|██████████████████████████████▌                                                    | 3586/9741 [00:06<00:10, 566.32it/s] 37%|███████████████████████████████                                                    | 3643/9741 [00:06<00:10, 566.91it/s] 38%|███████████████████████████████▌                                                   | 3700/9741 [00:07<00:10, 564.17it/s] 39%|████████████████████████████████                                                   | 3757/9741 [00:07<00:10, 564.23it/s] 39%|████████████████████████████████▍                                                  | 3814/9741 [00:07<00:10, 561.61it/s] 40%|████████████████████████████████▉                                                  | 3871/9741 [00:07<00:10, 563.02it/s] 40%|█████████████████████████████████▍                                                 | 3928/9741 [00:07<00:10, 563.99it/s] 41%|█████████████████████████████████▉                                                 | 3985/9741 [00:07<00:10, 564.05it/s] 41%|██████████████████████████████████▍                                                | 4042/9741 [00:07<00:10, 562.03it/s] 42%|██████████████████████████████████▉                                                | 4099/9741 [00:07<00:10, 563.14it/s] 43%|███████████████████████████████████▍                                               | 4156/9741 [00:07<00:09, 563.28it/s] 43%|███████████████████████████████████▉                                               | 4213/9741 [00:07<00:09, 562.56it/s] 44%|████████████████████████████████████▍                                              | 4270/9741 [00:08<00:09, 560.85it/s] 44%|████████████████████████████████████▊                                              | 4327/9741 [00:08<00:09, 562.34it/s] 45%|█████████████████████████████████████▎                                             | 4384/9741 [00:08<00:09, 562.32it/s] 46%|█████████████████████████████████████▊                                             | 4441/9741 [00:08<00:09, 562.38it/s] 46%|██████████████████████████████████████▎                                            | 4498/9741 [00:08<00:09, 528.88it/s] 47%|██████████████████████████████████████▊                                            | 4554/9741 [00:08<00:09, 537.73it/s] 47%|███████████████████████████████████████▎                                           | 4609/9741 [00:08<00:09, 536.94it/s] 48%|███████████████████████████████████████▋                                           | 4665/9741 [00:08<00:09, 542.72it/s] 48%|████████████████████████████████████████▏                                          | 4720/9741 [00:08<00:12, 386.63it/s] 49%|████████████████████████████████████████▋                                          | 4775/9741 [00:09<00:11, 423.79it/s] 50%|█████████████████████████████████████████▏                                         | 4830/9741 [00:09<00:10, 454.60it/s] 50%|█████████████████████████████████████████▌                                         | 4885/9741 [00:09<00:10, 478.80it/s] 51%|██████████████████████████████████████████                                         | 4940/9741 [00:09<00:09, 496.22it/s] 51%|██████████████████████████████████████████▌                                        | 4995/9741 [00:09<00:09, 510.45it/s] 52%|███████████████████████████████████████████                                        | 5051/9741 [00:09<00:08, 522.02it/s] 52%|███████████████████████████████████████████▌                                       | 5106/9741 [00:09<00:08, 528.54it/s] 53%|███████████████████████████████████████████▉                                       | 5161/9741 [00:09<00:08, 532.34it/s] 54%|████████████████████████████████████████████▍                                      | 5216/9741 [00:09<00:08, 536.39it/s] 54%|████████████████████████████████████████████▉                                      | 5272/9741 [00:10<00:08, 540.56it/s] 55%|█████████████████████████████████████████████▍                                     | 5328/9741 [00:10<00:08, 544.73it/s] 55%|█████████████████████████████████████████████▊                                     | 5383/9741 [00:10<00:08, 544.04it/s] 56%|██████████████████████████████████████████████▎                                    | 5439/9741 [00:10<00:07, 546.20it/s] 56%|██████████████████████████████████████████████▊                                    | 5495/9741 [00:10<00:07, 547.39it/s] 57%|███████████████████████████████████████████████▎                                   | 5551/9741 [00:10<00:07, 549.04it/s] 58%|███████████████████████████████████████████████▊                                   | 5606/9741 [00:10<00:07, 546.60it/s] 58%|████████████████████████████████████████████████▏                                  | 5661/9741 [00:10<00:07, 547.53it/s] 59%|████████████████████████████████████████████████▋                                  | 5717/9741 [00:10<00:07, 549.02it/s] 59%|█████████████████████████████████████████████████▏                                 | 5773/9741 [00:10<00:07, 549.73it/s] 60%|█████████████████████████████████████████████████▋                                 | 5828/9741 [00:11<00:07, 547.46it/s] 60%|██████████████████████████████████████████████████▏                                | 5884/9741 [00:11<00:07, 548.19it/s] 61%|██████████████████████████████████████████████████▌                                | 5940/9741 [00:11<00:06, 549.49it/s] 62%|███████████████████████████████████████████████████                                | 5996/9741 [00:11<00:06, 551.85it/s] 62%|███████████████████████████████████████████████████▌                               | 6052/9741 [00:11<00:06, 550.99it/s] 63%|████████████████████████████████████████████████████                               | 6108/9741 [00:11<00:06, 551.70it/s] 63%|████████████████████████████████████████████████████▌                              | 6164/9741 [00:11<00:06, 552.26it/s] 64%|████████████████████████████████████████████████████▉                              | 6220/9741 [00:11<00:06, 552.06it/s] 64%|█████████████████████████████████████████████████████▍                             | 6276/9741 [00:11<00:06, 549.96it/s] 65%|█████████████████████████████████████████████████████▉                             | 6332/9741 [00:11<00:06, 551.57it/s] 66%|██████████████████████████████████████████████████████▍                            | 6388/9741 [00:12<00:06, 548.33it/s] 66%|██████████████████████████████████████████████████████▉                            | 6444/9741 [00:12<00:05, 549.95it/s] 67%|███████████████████████████████████████████████████████▍                           | 6500/9741 [00:12<00:05, 549.47it/s] 67%|███████████████████████████████████████████████████████▊                           | 6555/9741 [00:12<00:05, 549.52it/s] 68%|████████████████████████████████████████████████████████▎                          | 6611/9741 [00:12<00:05, 550.64it/s] 68%|████████████████████████████████████████████████████████▊                          | 6667/9741 [00:12<00:05, 551.62it/s] 69%|█████████████████████████████████████████████████████████▎                         | 6723/9741 [00:12<00:05, 551.91it/s] 70%|█████████████████████████████████████████████████████████▊                         | 6779/9741 [00:12<00:05, 550.98it/s] 70%|██████████████████████████████████████████████████████████▏                        | 6835/9741 [00:12<00:05, 551.76it/s] 71%|██████████████████████████████████████████████████████████▋                        | 6891/9741 [00:12<00:05, 552.86it/s] 71%|███████████████████████████████████████████████████████████▏                       | 6947/9741 [00:13<00:05, 554.04it/s] 72%|███████████████████████████████████████████████████████████▋                       | 7003/9741 [00:13<00:04, 551.97it/s] 72%|████████████████████████████████████████████████████████████▏                      | 7059/9741 [00:13<00:04, 552.46it/s] 73%|████████████████████████████████████████████████████████████▌                      | 7115/9741 [00:13<00:04, 553.62it/s] 74%|█████████████████████████████████████████████████████████████                      | 7171/9741 [00:13<00:04, 554.64it/s] 74%|█████████████████████████████████████████████████████████████▌                     | 7227/9741 [00:13<00:04, 552.18it/s] 75%|██████████████████████████████████████████████████████████████                     | 7283/9741 [00:13<00:04, 551.65it/s] 75%|██████████████████████████████████████████████████████████████▌                    | 7339/9741 [00:13<00:04, 553.17it/s] 76%|███████████████████████████████████████████████████████████████                    | 7395/9741 [00:13<00:04, 554.66it/s] 76%|███████████████████████████████████████████████████████████████▍                   | 7451/9741 [00:13<00:04, 528.79it/s] 77%|███████████████████████████████████████████████████████████████▉                   | 7506/9741 [00:14<00:04, 534.20it/s] 78%|████████████████████████████████████████████████████████████████▍                  | 7561/9741 [00:14<00:04, 537.52it/s] 78%|████████████████████████████████████████████████████████████████▉                  | 7615/9741 [00:14<00:04, 529.80it/s] 79%|█████████████████████████████████████████████████████████████████▎                 | 7669/9741 [00:14<00:03, 531.44it/s] 79%|█████████████████████████████████████████████████████████████████▊                 | 7724/9741 [00:14<00:03, 534.51it/s] 80%|██████████████████████████████████████████████████████████████████▎                | 7779/9741 [00:14<00:03, 537.77it/s] 80%|██████████████████████████████████████████████████████████████████▊                | 7834/9741 [00:14<00:03, 540.08it/s] 81%|███████████████████████████████████████████████████████████████████▏               | 7889/9741 [00:14<00:03, 525.83it/s] 82%|███████████████████████████████████████████████████████████████████▋               | 7944/9741 [00:14<00:03, 530.90it/s] 82%|████████████████████████████████████████████████████████████████████▏              | 7999/9741 [00:14<00:03, 535.87it/s] 83%|████████████████████████████████████████████████████████████████████▋              | 8054/9741 [00:15<00:03, 539.16it/s] 83%|█████████████████████████████████████████████████████████████████████              | 8109/9741 [00:15<00:03, 540.30it/s] 84%|█████████████████████████████████████████████████████████████████████▌             | 8164/9741 [00:15<00:02, 541.33it/s] 84%|██████████████████████████████████████████████████████████████████████             | 8219/9741 [00:15<00:02, 543.30it/s] 85%|██████████████████████████████████████████████████████████████████████▌            | 8274/9741 [00:15<00:02, 544.75it/s] 86%|██████████████████████████████████████████████████████████████████████▉            | 8329/9741 [00:15<00:02, 543.71it/s] 86%|███████████████████████████████████████████████████████████████████████▍           | 8384/9741 [00:15<00:02, 542.21it/s] 87%|███████████████████████████████████████████████████████████████████████▉           | 8439/9741 [00:15<00:02, 543.71it/s] 87%|████████████████████████████████████████████████████████████████████████▎          | 8494/9741 [00:15<00:02, 544.74it/s] 88%|████████████████████████████████████████████████████████████████████████▊          | 8549/9741 [00:16<00:02, 543.69it/s] 88%|█████████████████████████████████████████████████████████████████████████▎         | 8605/9741 [00:16<00:02, 546.37it/s] 89%|█████████████████████████████████████████████████████████████████████████▊         | 8660/9741 [00:16<00:01, 546.60it/s] 89%|██████████████████████████████████████████████████████████████████████████▎        | 8716/9741 [00:16<00:01, 549.75it/s] 90%|██████████████████████████████████████████████████████████████████████████▋        | 8771/9741 [00:16<00:01, 549.78it/s] 91%|███████████████████████████████████████████████████████████████████████████▏       | 8826/9741 [00:16<00:01, 545.16it/s] 91%|███████████████████████████████████████████████████████████████████████████▋       | 8881/9741 [00:16<00:01, 546.37it/s] 92%|████████████████████████████████████████████████████████████████████████████▏      | 8937/9741 [00:16<00:01, 548.49it/s] 92%|████████████████████████████████████████████████████████████████████████████▋      | 8993/9741 [00:16<00:01, 550.21it/s] 93%|█████████████████████████████████████████████████████████████████████████████      | 9049/9741 [00:16<00:01, 549.24it/s] 93%|█████████████████████████████████████████████████████████████████████████████▌     | 9104/9741 [00:17<00:01, 548.95it/s] 94%|██████████████████████████████████████████████████████████████████████████████     | 9160/9741 [00:17<00:01, 549.92it/s] 95%|██████████████████████████████████████████████████████████████████████████████▌    | 9216/9741 [00:17<00:00, 550.95it/s] 95%|███████████████████████████████████████████████████████████████████████████████    | 9272/9741 [00:17<00:00, 550.10it/s] 96%|███████████████████████████████████████████████████████████████████████████████▍   | 9328/9741 [00:17<00:00, 549.58it/s] 96%|███████████████████████████████████████████████████████████████████████████████▉   | 9384/9741 [00:17<00:00, 549.92it/s] 97%|████████████████████████████████████████████████████████████████████████████████▍  | 9440/9741 [00:17<00:00, 550.88it/s] 97%|████████████████████████████████████████████████████████████████████████████████▉  | 9496/9741 [00:17<00:00, 548.48it/s] 98%|█████████████████████████████████████████████████████████████████████████████████▍ | 9551/9741 [00:17<00:00, 547.32it/s] 99%|█████████████████████████████████████████████████████████████████████████████████▊ | 9606/9741 [00:17<00:00, 546.70it/s] 99%|██████████████████████████████████████████████████████████████████████████████████▎| 9662/9741 [00:18<00:00, 549.68it/s]100%|██████████████████████████████████████████████████████████████████████████████████▊| 9718/9741 [00:18<00:00, 550.29it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:18<00:00, 536.02it/s]
Load End
Num instances: 1000
[2023-08-23 11:20:56,251] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-23 11:20:59,964] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-23 11:20:59,964] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fe0e5771a60>
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-23 11:20:59,965] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-23 11:20:59,966] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-23 11:20:59,966] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-23 11:20:59,966] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-23 11:20:59,966] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fe0e5771940>
[2023-08-23 11:20:59,966] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-23 11:20:59,966] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-23 11:20:59,966] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-23 11:20:59,966] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-23 11:20:59,966] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-23 11:20:59,966] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-23 11:20:59,966] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-23 11:20:59,966] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-23 11:20:59,966] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-23 11:20:59,966] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-23 11:20:59,966] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-23 11:20:59,966] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-23 11:20:59,966] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-23 11:20:59,966] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-23 11:20:59,966] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-23 11:20:59,966] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-23 11:20:59,966] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-23 11:20:59,966] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-23 11:20:59,966] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-23 11:20:59,966] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-23 11:20:59,966] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-23 11:20:59,966] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-23 11:20:59,966] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4429483413696289 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                      | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: The car-rental agency charges $30/day for a car, or $190 for the first week for a rental that lasts an entire week or longer. Jennie rented a car for 11 days. How much, in dollars, did she pay for the rental?
Output: The first 7 days were $190.
There were 11-7=<<11-7=4>>4 days left.
The additional 4 days were 4*30=<<4*30=120>>120.
And 190+120=<<190+120=310>>310.
So the final answer is 310

Input: A hurricane is approaching the southern coast of Texas, and a rancher is planning to move 400 head of cattle 60 miles to higher ground to protect them from possible inland flooding that might occur.  His animal transport truck holds 20 head of cattle.  Traveling at 60 miles per hour, what is the total driving time, in hours, it will take to transport all of his cattle to higher ground?
Output: Given the limited capacity of his transport vehicle (20 head of cattle), the 400 head of cattle will require 400/20=<<400/20=20>>20 trips using his transport vehicle.
Traveling to the site at 60 mph for 60 miles it will take 60/60=<<60/60=1>>1 hour to travel one-way.
Since each trip requires driving to and returning from the relocation site, each complete round trip will take 2*1=<<2*1=2>>2 hours.
Thus, 20 complete trips will take 20*2=<<20*2=40>>40 hours of driving time.
So the final answer is 40

Input: Jason has a carriage house that he rents out.  He’s charging $50.00 per day or $500.00 for 14 days.  Eric wants to rent the house for 20 days.  How much will it cost him?
Output: He wants to rent for 20 days and there is a deal if you rent for 14 days so that leaves 20-14 = <<20-14=6>>6 individual days
Each individual day is $50.00 and he will have 6 individual days for a total of 50*6 = $<<50*6=300.00>>300.00
14 days costs $500.00 and 6 days costs $300.00 for a total of 500+300 = $800.00
So the final answer is 800

Input: Melissa works on a poultry farm. She drives to town twice each month to buy supplies. If it takes her 3 hours to drive to town and back, how many hours does Melissa spend driving in a year?
Output: Melissa spends 2x3=<<2*3=6>>6 hours driving each month.
Since there are 12 months in a year, she spends 6x12=<<6*12=72>>72 hours driving each year.
So the final answer is 72

Input: The ratio of boys to girls in a family is 5:7. The total number of children in the family is 180. If the boys are given $3900 to share, how much money does each boy receive?
Output: The total ratio representing the number of children in the family is 5+7 = <<5+7=12>>12
From the total ratio of children in the family, 5/12 represent the number of boys, meaning that the number of boys in the family is 5/12*180 = <<5/12*180=75>>75
If the boys are given $3900 to share, each boy receives $3900/75 = $<<3900/75=52>>52
So the final answer is 52

Input: Josephine receives a bill from the hospital for 5000$.  50 percent of the bill is for medication.  25 percent of the remaining bill is for overnight stays, and 175$ is for food.  The rest of the bill is for the ambulance ride.  How much did the ambulance ride cost?
Output: Medication:5000(.50)=2500
Overnight Stays:2500(.25)=625
2500-625=<<2500-625=1875>>1875
Food:1875-175=<<1875-175=1700>>1700$
Ambulance ride:1700$
So the final answer is 1700

Input: It was time for Kelly to harvest her carrots that she had planted in three different beds.  In the first bed she pulled out 55 carrots.  In the second bed she pulled out 101 carrots and in the third bed she pulled out 78 carrots.  She found that 6 carrots weighed one pound.  How many pounds of carrots did Kelly harvest?
Output: She pulled out 55 + 101 + 78 = <<55+101+78=234>>234
6 carrots weigh one pound so 234/6 = <<234/6=39>>39 pounds of carrots
So the final answer is 39

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o7-tgsm8k-s30-rTrue
Loading extension module utils...
Time to load utils op: 0.3045005798339844 seconds
Evaluating commonsenseqa :   2%|█▏                                                            | 1/50 [00:38<31:29, 38.56s/it]Evaluating commonsenseqa :   4%|██▍                                                           | 2/50 [01:17<30:48, 38.50s/it]Evaluating commonsenseqa :   6%|███▋                                                          | 3/50 [01:55<30:06, 38.43s/it]Evaluating commonsenseqa :   8%|████▉                                                         | 4/50 [02:32<29:04, 37.92s/it]Evaluating commonsenseqa :  10%|██████▏                                                       | 5/50 [03:10<28:21, 37.81s/it]Evaluating commonsenseqa :  12%|███████▍                                                      | 6/50 [03:48<27:46, 37.88s/it]Evaluating commonsenseqa :  14%|████████▋                                                     | 7/50 [04:25<26:59, 37.66s/it]Evaluating commonsenseqa :  16%|█████████▉                                                    | 8/50 [05:02<26:16, 37.52s/it]Evaluating commonsenseqa :  18%|███████████▏                                                  | 9/50 [05:39<25:30, 37.32s/it]Evaluating commonsenseqa :  20%|████████████▏                                                | 10/50 [06:16<24:52, 37.30s/it]Evaluating commonsenseqa :  22%|█████████████▍                                               | 11/50 [06:53<24:11, 37.22s/it]Evaluating commonsenseqa :  24%|██████████████▋                                              | 12/50 [07:31<23:36, 37.27s/it]Evaluating commonsenseqa :  26%|███████████████▊                                             | 13/50 [08:08<22:58, 37.25s/it]Evaluating commonsenseqa :  28%|█████████████████                                            | 14/50 [08:45<22:19, 37.22s/it]Evaluating commonsenseqa :  30%|██████████████████▎                                          | 15/50 [09:22<21:42, 37.23s/it]Evaluating commonsenseqa :  32%|███████████████████▌                                         | 16/50 [09:59<21:02, 37.14s/it]Evaluating commonsenseqa :  34%|████████████████████▋                                        | 17/50 [10:37<20:36, 37.47s/it]Evaluating commonsenseqa :  36%|█████████████████████▉                                       | 18/50 [11:15<19:59, 37.48s/it]Evaluating commonsenseqa :  38%|███████████████████████▏                                     | 19/50 [11:52<19:21, 37.46s/it]Evaluating commonsenseqa :  40%|████████████████████████▍                                    | 20/50 [12:30<18:45, 37.53s/it]Evaluating commonsenseqa :  42%|█████████████████████████▌                                   | 21/50 [13:07<18:02, 37.32s/it]Evaluating commonsenseqa :  44%|██████████████████████████▊                                  | 22/50 [13:44<17:23, 37.27s/it]Evaluating commonsenseqa :  46%|████████████████████████████                                 | 23/50 [14:21<16:44, 37.19s/it]Evaluating commonsenseqa :  48%|█████████████████████████████▎                               | 24/50 [14:58<16:07, 37.20s/it]Evaluating commonsenseqa :  50%|██████████████████████████████▌                              | 25/50 [15:35<15:27, 37.12s/it]Evaluating commonsenseqa :  52%|███████████████████████████████▋                             | 26/50 [16:12<14:50, 37.09s/it]Evaluating commonsenseqa :  54%|████████████████████████████████▉                            | 27/50 [16:49<14:11, 37.02s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████▏                          | 28/50 [17:26<13:34, 37.01s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████▍                         | 29/50 [18:03<12:56, 36.96s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████▌                        | 30/50 [18:40<12:23, 37.16s/it]Evaluating commonsenseqa :  62%|█████████████████████████████████████▊                       | 31/50 [19:17<11:44, 37.07s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████████                      | 32/50 [19:54<11:07, 37.06s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████████▎                    | 33/50 [20:32<10:32, 37.19s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████████▍                   | 34/50 [21:09<09:56, 37.31s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████████▋                  | 35/50 [21:47<09:20, 37.38s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████████▉                 | 36/50 [22:24<08:41, 37.22s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████████████▏               | 37/50 [23:02<08:06, 37.44s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████████████▎              | 38/50 [23:40<07:30, 37.55s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████████████▌             | 39/50 [24:17<06:53, 37.59s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████▊            | 40/50 [24:55<06:15, 37.55s/it]Evaluating commonsenseqa :  82%|██████████████████████████████████████████████████           | 41/50 [25:32<05:35, 37.32s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████▏         | 42/50 [26:08<04:57, 37.21s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████▍        | 43/50 [26:46<04:20, 37.23s/it]Evaluating commonsenseqa :  88%|█████████████████████████████████████████████████████▋       | 44/50 [27:23<03:42, 37.12s/it]Evaluating commonsenseqa :  90%|██████████████████████████████████████████████████████▉      | 45/50 [28:00<03:05, 37.05s/it]Evaluating commonsenseqa :  92%|████████████████████████████████████████████████████████     | 46/50 [28:37<02:29, 37.30s/it]Evaluating commonsenseqa :  94%|█████████████████████████████████████████████████████████▎   | 47/50 [29:15<01:51, 37.29s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████▌  | 48/50 [29:52<01:14, 37.36s/it]Evaluating commonsenseqa :  98%|███████████████████████████████████████████████████████████▊ | 49/50 [30:29<00:37, 37.30s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [31:06<00:00, 37.15s/it]Evaluating commonsenseqa : 100%|█████████████████████████████████████████████████████████████| 50/50 [31:06<00:00, 37.33s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.9082} | avg. gen lenth: 434.142
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s30-rTrue --seed 30 --max-prompt-length 2048 --rationales --num-out-domain 8
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-23 11:52:25,385] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o8-tgsm8k-s30-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 8
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o8-tgsm8k-s30-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                         | 0/9741 [00:00<?, ?it/s]  0%|▎                                                                              | 33/9741 [00:00<00:29, 327.08it/s]  1%|▌                                                                              | 67/9741 [00:00<00:29, 330.31it/s]  1%|▊                                                                             | 101/9741 [00:00<00:28, 332.69it/s]  1%|█                                                                             | 135/9741 [00:00<00:28, 332.96it/s]  2%|█▎                                                                            | 169/9741 [00:00<00:28, 333.20it/s]  2%|█▋                                                                            | 203/9741 [00:00<00:28, 332.00it/s]  2%|█▉                                                                            | 237/9741 [00:00<00:29, 327.13it/s]  3%|██▏                                                                           | 271/9741 [00:00<00:28, 329.20it/s]  3%|██▍                                                                           | 305/9741 [00:00<00:28, 329.93it/s]  3%|██▋                                                                           | 339/9741 [00:01<00:28, 330.57it/s]  4%|██▉                                                                           | 373/9741 [00:01<00:28, 331.89it/s]  4%|███▎                                                                          | 407/9741 [00:01<00:28, 330.72it/s]  5%|███▌                                                                          | 441/9741 [00:01<00:28, 331.64it/s]  5%|███▊                                                                          | 475/9741 [00:01<00:27, 332.50it/s]  5%|████                                                                          | 509/9741 [00:01<00:27, 333.79it/s]  6%|████▍                                                                         | 550/9741 [00:01<00:25, 355.58it/s]  6%|████▊                                                                         | 598/9741 [00:01<00:23, 392.52it/s]  7%|█████▏                                                                        | 647/9741 [00:01<00:21, 419.51it/s]  7%|█████▌                                                                        | 697/9741 [00:01<00:20, 443.33it/s]  8%|█████▉                                                                        | 747/9741 [00:02<00:19, 459.42it/s]  8%|██████▍                                                                       | 797/9741 [00:02<00:18, 471.46it/s]  9%|██████▊                                                                       | 847/9741 [00:02<00:18, 479.32it/s]  9%|███████▏                                                                      | 896/9741 [00:02<00:18, 481.71it/s] 10%|███████▌                                                                      | 946/9741 [00:02<00:18, 486.85it/s] 10%|███████▉                                                                      | 997/9741 [00:02<00:17, 492.02it/s] 11%|████████▎                                                                    | 1048/9741 [00:02<00:17, 495.56it/s] 11%|████████▋                                                                    | 1098/9741 [00:02<00:17, 494.65it/s] 12%|█████████                                                                    | 1148/9741 [00:02<00:17, 496.21it/s] 12%|█████████▍                                                                   | 1198/9741 [00:02<00:17, 496.83it/s] 13%|█████████▊                                                                   | 1248/9741 [00:03<00:17, 497.06it/s] 13%|██████████▎                                                                  | 1298/9741 [00:03<00:16, 496.92it/s] 14%|██████████▋                                                                  | 1348/9741 [00:03<00:16, 495.36it/s] 14%|███████████                                                                  | 1398/9741 [00:03<00:16, 496.73it/s] 15%|███████████▍                                                                 | 1448/9741 [00:03<00:16, 497.53it/s] 15%|███████████▊                                                                 | 1498/9741 [00:03<00:16, 497.59it/s] 16%|████████████▏                                                                | 1548/9741 [00:03<00:16, 495.38it/s] 16%|████████████▋                                                                | 1598/9741 [00:03<00:16, 495.45it/s] 17%|█████████████                                                                | 1648/9741 [00:03<00:16, 496.03it/s] 17%|█████████████▍                                                               | 1698/9741 [00:03<00:16, 496.39it/s] 18%|█████████████▊                                                               | 1748/9741 [00:04<00:16, 496.55it/s] 18%|██████████████▏                                                              | 1798/9741 [00:04<00:16, 476.92it/s] 19%|██████████████▌                                                              | 1848/9741 [00:04<00:16, 481.28it/s] 19%|███████████████                                                              | 1898/9741 [00:04<00:16, 483.87it/s] 20%|███████████████▍                                                             | 1947/9741 [00:04<00:16, 482.55it/s] 20%|███████████████▊                                                             | 1996/9741 [00:04<00:16, 480.53it/s] 21%|████████████████▏                                                            | 2045/9741 [00:04<00:15, 482.68it/s] 22%|████████████████▌                                                            | 2095/9741 [00:04<00:15, 485.11it/s] 22%|████████████████▉                                                            | 2145/9741 [00:04<00:15, 486.76it/s] 23%|█████████████████▎                                                           | 2195/9741 [00:04<00:15, 488.58it/s] 23%|█████████████████▋                                                           | 2244/9741 [00:05<00:15, 487.16it/s] 24%|██████████████████▏                                                          | 2293/9741 [00:05<00:15, 487.42it/s] 24%|██████████████████▌                                                          | 2342/9741 [00:05<00:15, 486.67it/s] 25%|██████████████████▉                                                          | 2391/9741 [00:05<00:15, 486.13it/s] 25%|███████████████████▎                                                         | 2440/9741 [00:05<00:15, 483.38it/s] 26%|███████████████████▋                                                         | 2489/9741 [00:05<00:15, 483.36it/s] 26%|████████████████████                                                         | 2538/9741 [00:05<00:15, 476.79it/s] 27%|████████████████████▍                                                        | 2587/9741 [00:05<00:14, 478.60it/s] 27%|████████████████████▊                                                        | 2635/9741 [00:05<00:14, 478.43it/s] 28%|█████████████████████▏                                                       | 2683/9741 [00:05<00:14, 474.97it/s] 28%|█████████████████████▌                                                       | 2731/9741 [00:06<00:14, 474.93it/s] 29%|█████████████████████▉                                                       | 2779/9741 [00:06<00:14, 473.73it/s] 29%|██████████████████████▎                                                      | 2827/9741 [00:06<00:14, 473.14it/s] 30%|██████████████████████▋                                                      | 2876/9741 [00:06<00:14, 475.45it/s] 30%|███████████████████████                                                      | 2924/9741 [00:06<00:14, 475.87it/s] 31%|███████████████████████▌                                                     | 2973/9741 [00:06<00:14, 477.69it/s] 31%|███████████████████████▉                                                     | 3022/9741 [00:06<00:14, 479.34it/s] 32%|████████████████████████▎                                                    | 3071/9741 [00:06<00:13, 479.97it/s] 32%|████████████████████████▋                                                    | 3120/9741 [00:06<00:13, 480.84it/s] 33%|█████████████████████████                                                    | 3169/9741 [00:07<00:13, 476.28it/s] 33%|█████████████████████████▍                                                   | 3217/9741 [00:07<00:13, 477.27it/s] 34%|█████████████████████████▊                                                   | 3266/9741 [00:07<00:13, 478.19it/s] 34%|██████████████████████████▏                                                  | 3314/9741 [00:07<00:13, 478.13it/s] 35%|██████████████████████████▌                                                  | 3362/9741 [00:07<00:13, 474.69it/s] 35%|██████████████████████████▉                                                  | 3410/9741 [00:07<00:13, 474.23it/s] 35%|███████████████████████████▎                                                 | 3458/9741 [00:07<00:13, 473.96it/s] 36%|███████████████████████████▋                                                 | 3506/9741 [00:07<00:13, 473.39it/s] 36%|████████████████████████████                                                 | 3554/9741 [00:07<00:13, 472.74it/s] 37%|████████████████████████████▍                                                | 3602/9741 [00:07<00:13, 469.93it/s] 37%|████████████████████████████▊                                                | 3650/9741 [00:08<00:12, 470.47it/s] 38%|█████████████████████████████▏                                               | 3698/9741 [00:08<00:12, 471.06it/s] 38%|█████████████████████████████▌                                               | 3746/9741 [00:08<00:12, 471.63it/s] 39%|█████████████████████████████▉                                               | 3794/9741 [00:08<00:12, 472.12it/s] 39%|██████████████████████████████▎                                              | 3842/9741 [00:08<00:12, 471.16it/s] 40%|██████████████████████████████▋                                              | 3890/9741 [00:08<00:12, 472.90it/s] 40%|███████████████████████████████▏                                             | 3938/9741 [00:08<00:12, 467.88it/s] 41%|███████████████████████████████▌                                             | 3986/9741 [00:08<00:12, 469.49it/s] 41%|███████████████████████████████▉                                             | 4033/9741 [00:08<00:12, 469.43it/s] 42%|████████████████████████████████▎                                            | 4081/9741 [00:08<00:11, 471.96it/s] 42%|████████████████████████████████▋                                            | 4129/9741 [00:09<00:11, 473.31it/s] 43%|█████████████████████████████████                                            | 4177/9741 [00:09<00:11, 473.33it/s] 43%|█████████████████████████████████▍                                           | 4225/9741 [00:09<00:11, 473.61it/s] 44%|█████████████████████████████████▊                                           | 4273/9741 [00:09<00:11, 472.39it/s] 44%|██████████████████████████████████▏                                          | 4321/9741 [00:09<00:11, 473.35it/s] 45%|██████████████████████████████████▌                                          | 4369/9741 [00:09<00:11, 473.07it/s] 45%|██████████████████████████████████▉                                          | 4417/9741 [00:09<00:11, 472.68it/s] 46%|███████████████████████████████████▎                                         | 4465/9741 [00:09<00:11, 472.67it/s] 46%|███████████████████████████████████▋                                         | 4513/9741 [00:09<00:11, 441.20it/s] 47%|████████████████████████████████████                                         | 4561/9741 [00:09<00:11, 449.61it/s] 47%|████████████████████████████████████▍                                        | 4608/9741 [00:10<00:11, 454.87it/s] 48%|████████████████████████████████████▊                                        | 4656/9741 [00:10<00:11, 460.18it/s] 48%|█████████████████████████████████████▏                                       | 4703/9741 [00:10<00:10, 462.95it/s] 49%|█████████████████████████████████████▌                                       | 4750/9741 [00:10<00:14, 333.77it/s] 49%|█████████████████████████████████████▉                                       | 4798/9741 [00:10<00:13, 366.10it/s] 50%|██████████████████████████████████████▎                                      | 4846/9741 [00:10<00:12, 392.65it/s] 50%|██████████████████████████████████████▋                                      | 4893/9741 [00:10<00:11, 412.51it/s] 51%|███████████████████████████████████████                                      | 4940/9741 [00:10<00:11, 425.82it/s] 51%|███████████████████████████████████████▍                                     | 4987/9741 [00:11<00:10, 437.90it/s] 52%|███████████████████████████████████████▊                                     | 5035/9741 [00:11<00:10, 447.29it/s] 52%|████████████████████████████████████████▏                                    | 5082/9741 [00:11<00:10, 453.52it/s] 53%|████████████████████████████████████████▌                                    | 5129/9741 [00:11<00:10, 457.80it/s] 53%|████████████████████████████████████████▉                                    | 5176/9741 [00:11<00:09, 458.81it/s] 54%|█████████████████████████████████████████▎                                   | 5223/9741 [00:11<00:09, 461.19it/s] 54%|█████████████████████████████████████████▋                                   | 5270/9741 [00:11<00:09, 461.43it/s] 55%|██████████████████████████████████████████                                   | 5317/9741 [00:11<00:09, 460.54it/s] 55%|██████████████████████████████████████████▍                                  | 5364/9741 [00:11<00:09, 459.95it/s] 56%|██████████████████████████████████████████▊                                  | 5411/9741 [00:11<00:09, 458.16it/s] 56%|███████████████████████████████████████████▏                                 | 5457/9741 [00:12<00:09, 452.91it/s] 56%|███████████████████████████████████████████▍                                 | 5503/9741 [00:12<00:09, 454.55it/s] 57%|███████████████████████████████████████████▊                                 | 5549/9741 [00:12<00:09, 455.83it/s] 57%|████████████████████████████████████████████▏                                | 5595/9741 [00:12<00:09, 454.63it/s] 58%|████████████████████████████████████████████▌                                | 5641/9741 [00:12<00:08, 456.19it/s] 58%|████████████████████████████████████████████▉                                | 5687/9741 [00:12<00:08, 457.00it/s] 59%|█████████████████████████████████████████████▎                               | 5733/9741 [00:12<00:08, 457.42it/s] 59%|█████████████████████████████████████████████▋                               | 5779/9741 [00:12<00:08, 457.65it/s] 60%|██████████████████████████████████████████████                               | 5825/9741 [00:12<00:08, 456.15it/s] 60%|██████████████████████████████████████████████▍                              | 5871/9741 [00:12<00:08, 457.23it/s] 61%|██████████████████████████████████████████████▊                              | 5918/9741 [00:13<00:08, 458.58it/s] 61%|███████████████████████████████████████████████▏                             | 5965/9741 [00:13<00:08, 461.96it/s] 62%|███████████████████████████████████████████████▌                             | 6013/9741 [00:13<00:08, 464.43it/s] 62%|███████████████████████████████████████████████▉                             | 6060/9741 [00:13<00:07, 463.90it/s] 63%|████████████████████████████████████████████████▎                            | 6107/9741 [00:13<00:07, 465.48it/s] 63%|████████████████████████████████████████████████▋                            | 6154/9741 [00:13<00:07, 466.26it/s] 64%|█████████████████████████████████████████████████                            | 6201/9741 [00:13<00:07, 467.12it/s] 64%|█████████████████████████████████████████████████▍                           | 6248/9741 [00:13<00:07, 467.39it/s] 65%|█████████████████████████████████████████████████▊                           | 6295/9741 [00:13<00:07, 466.15it/s] 65%|██████████████████████████████████████████████████▏                          | 6342/9741 [00:13<00:07, 466.55it/s] 66%|██████████████████████████████████████████████████▌                          | 6390/9741 [00:14<00:07, 467.89it/s] 66%|██████████████████████████████████████████████████▉                          | 6438/9741 [00:14<00:07, 468.62it/s] 67%|███████████████████████████████████████████████████▎                         | 6485/9741 [00:14<00:06, 468.91it/s] 67%|███████████████████████████████████████████████████▋                         | 6532/9741 [00:14<00:06, 465.97it/s] 68%|████████████████████████████████████████████████████                         | 6579/9741 [00:14<00:06, 467.07it/s] 68%|████████████████████████████████████████████████████▍                        | 6626/9741 [00:14<00:06, 467.62it/s] 69%|████████████████████████████████████████████████████▊                        | 6674/9741 [00:14<00:06, 468.54it/s] 69%|█████████████████████████████████████████████████████▏                       | 6721/9741 [00:14<00:06, 468.24it/s] 69%|█████████████████████████████████████████████████████▍                       | 6768/9741 [00:14<00:06, 467.07it/s] 70%|█████████████████████████████████████████████████████▊                       | 6815/9741 [00:14<00:06, 467.92it/s] 70%|██████████████████████████████████████████████████████▎                      | 6863/9741 [00:15<00:06, 469.10it/s] 71%|██████████████████████████████████████████████████████▌                      | 6910/9741 [00:15<00:06, 469.18it/s] 71%|██████████████████████████████████████████████████████▉                      | 6957/9741 [00:15<00:05, 467.06it/s] 72%|███████████████████████████████████████████████████████▎                     | 7004/9741 [00:15<00:05, 467.50it/s] 72%|███████████████████████████████████████████████████████▋                     | 7052/9741 [00:15<00:05, 468.59it/s] 73%|████████████████████████████████████████████████████████                     | 7099/9741 [00:15<00:05, 468.67it/s] 73%|████████████████████████████████████████████████████████▍                    | 7146/9741 [00:15<00:05, 468.93it/s] 74%|████████████████████████████████████████████████████████▊                    | 7193/9741 [00:15<00:05, 466.83it/s] 74%|█████████████████████████████████████████████████████████▏                   | 7240/9741 [00:15<00:05, 467.68it/s] 75%|█████████████████████████████████████████████████████████▌                   | 7287/9741 [00:15<00:05, 461.49it/s] 75%|█████████████████████████████████████████████████████████▉                   | 7334/9741 [00:16<00:05, 463.16it/s] 76%|██████████████████████████████████████████████████████████▎                  | 7381/9741 [00:16<00:05, 465.08it/s] 76%|██████████████████████████████████████████████████████████▋                  | 7428/9741 [00:16<00:05, 437.19it/s] 77%|███████████████████████████████████████████████████████████                  | 7475/9741 [00:16<00:05, 445.68it/s] 77%|███████████████████████████████████████████████████████████▍                 | 7522/9741 [00:16<00:04, 450.73it/s] 78%|███████████████████████████████████████████████████████████▊                 | 7569/9741 [00:16<00:04, 455.15it/s] 78%|████████████████████████████████████████████████████████████▏                | 7616/9741 [00:16<00:04, 458.83it/s] 79%|████████████████████████████████████████████████████████████▌                | 7663/9741 [00:16<00:04, 459.63it/s] 79%|████████████████████████████████████████████████████████████▉                | 7710/9741 [00:16<00:04, 461.55it/s] 80%|█████████████████████████████████████████████████████████████▎               | 7757/9741 [00:17<00:04, 462.96it/s] 80%|█████████████████████████████████████████████████████████████▋               | 7804/9741 [00:17<00:04, 464.29it/s] 81%|██████████████████████████████████████████████████████████████               | 7851/9741 [00:17<00:04, 465.76it/s] 81%|██████████████████████████████████████████████████████████████▍              | 7898/9741 [00:17<00:03, 463.94it/s] 82%|██████████████████████████████████████████████████████████████▊              | 7945/9741 [00:17<00:03, 464.77it/s] 82%|███████████████████████████████████████████████████████████████▏             | 7992/9741 [00:17<00:03, 465.37it/s] 83%|███████████████████████████████████████████████████████████████▌             | 8039/9741 [00:17<00:03, 466.24it/s] 83%|███████████████████████████████████████████████████████████████▉             | 8086/9741 [00:17<00:03, 464.91it/s] 83%|████████████████████████████████████████████████████████████████▎            | 8133/9741 [00:17<00:03, 462.70it/s] 84%|████████████████████████████████████████████████████████████████▋            | 8180/9741 [00:17<00:03, 463.49it/s] 84%|█████████████████████████████████████████████████████████████████            | 8227/9741 [00:18<00:03, 464.09it/s] 85%|█████████████████████████████████████████████████████████████████▍           | 8274/9741 [00:18<00:03, 460.44it/s] 85%|█████████████████████████████████████████████████████████████████▊           | 8321/9741 [00:18<00:03, 456.88it/s] 86%|██████████████████████████████████████████████████████████████████▏          | 8368/9741 [00:18<00:02, 458.93it/s] 86%|██████████████████████████████████████████████████████████████████▌          | 8415/9741 [00:18<00:02, 460.92it/s] 87%|██████████████████████████████████████████████████████████████████▉          | 8462/9741 [00:18<00:02, 461.89it/s] 87%|███████████████████████████████████████████████████████████████████▎         | 8509/9741 [00:18<00:02, 462.31it/s] 88%|███████████████████████████████████████████████████████████████████▋         | 8556/9741 [00:18<00:02, 460.99it/s] 88%|████████████████████████████████████████████████████████████████████         | 8603/9741 [00:18<00:02, 462.72it/s] 89%|████████████████████████████████████████████████████████████████████▍        | 8650/9741 [00:18<00:02, 463.90it/s] 89%|████████████████████████████████████████████████████████████████████▋        | 8697/9741 [00:19<00:02, 465.27it/s] 90%|█████████████████████████████████████████████████████████████████████        | 8744/9741 [00:19<00:02, 466.57it/s] 90%|█████████████████████████████████████████████████████████████████████▍       | 8791/9741 [00:19<00:02, 464.66it/s] 91%|█████████████████████████████████████████████████████████████████████▊       | 8838/9741 [00:19<00:01, 465.33it/s] 91%|██████████████████████████████████████████████████████████████████████▏      | 8885/9741 [00:19<00:01, 466.01it/s] 92%|██████████████████████████████████████████████████████████████████████▌      | 8932/9741 [00:19<00:01, 466.92it/s] 92%|██████████████████████████████████████████████████████████████████████▉      | 8979/9741 [00:19<00:01, 467.80it/s] 93%|███████████████████████████████████████████████████████████████████████▎     | 9026/9741 [00:19<00:01, 466.41it/s] 93%|███████████████████████████████████████████████████████████████████████▋     | 9073/9741 [00:19<00:01, 466.34it/s] 94%|████████████████████████████████████████████████████████████████████████     | 9120/9741 [00:19<00:01, 467.23it/s] 94%|████████████████████████████████████████████████████████████████████████▍    | 9167/9741 [00:20<00:01, 467.42it/s] 95%|████████████████████████████████████████████████████████████████████████▊    | 9214/9741 [00:20<00:01, 468.08it/s] 95%|█████████████████████████████████████████████████████████████████████████▏   | 9261/9741 [00:20<00:01, 465.76it/s] 96%|█████████████████████████████████████████████████████████████████████████▌   | 9308/9741 [00:20<00:00, 465.52it/s] 96%|█████████████████████████████████████████████████████████████████████████▉   | 9355/9741 [00:20<00:00, 465.98it/s] 97%|██████████████████████████████████████████████████████████████████████████▎  | 9403/9741 [00:20<00:00, 467.22it/s] 97%|██████████████████████████████████████████████████████████████████████████▋  | 9450/9741 [00:20<00:00, 465.12it/s] 97%|███████████████████████████████████████████████████████████████████████████  | 9497/9741 [00:20<00:00, 465.38it/s] 98%|███████████████████████████████████████████████████████████████████████████▍ | 9544/9741 [00:20<00:00, 464.74it/s] 98%|███████████████████████████████████████████████████████████████████████████▊ | 9591/9741 [00:20<00:00, 465.69it/s] 99%|████████████████████████████████████████████████████████████████████████████▏| 9638/9741 [00:21<00:00, 465.95it/s] 99%|████████████████████████████████████████████████████████████████████████████▌| 9685/9741 [00:21<00:00, 464.32it/s]100%|████████████████████████████████████████████████████████████████████████████▉| 9732/9741 [00:21<00:00, 465.17it/s]100%|█████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:21<00:00, 457.59it/s]
Load End
Num instances: 1000
[2023-08-23 11:52:57,955] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-23 11:53:00,630] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-23 11:53:00,631] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-23 11:53:00,631] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-23 11:53:00,631] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-23 11:53:00,631] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-23 11:53:00,631] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-23 11:53:00,631] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-23 11:53:00,631] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-23 11:53:00,631] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-23 11:53:00,631] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-23 11:53:00,631] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-23 11:53:00,631] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f8817d32a60>
[2023-08-23 11:53:00,631] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-23 11:53:00,631] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-23 11:53:00,631] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-23 11:53:00,631] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-23 11:53:00,631] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-23 11:53:00,631] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-23 11:53:00,631] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-23 11:53:00,631] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-23 11:53:00,631] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-23 11:53:00,631] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-23 11:53:00,631] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f8817d32940>
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-23 11:53:00,632] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-23 11:53:00,632] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.5239036083221436 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: The car-rental agency charges $30/day for a car, or $190 for the first week for a rental that lasts an entire week or longer. Jennie rented a car for 11 days. How much, in dollars, did she pay for the rental?
Output: The first 7 days were $190.
There were 11-7=<<11-7=4>>4 days left.
The additional 4 days were 4*30=<<4*30=120>>120.
And 190+120=<<190+120=310>>310.
So the final answer is 310

Input: A hurricane is approaching the southern coast of Texas, and a rancher is planning to move 400 head of cattle 60 miles to higher ground to protect them from possible inland flooding that might occur.  His animal transport truck holds 20 head of cattle.  Traveling at 60 miles per hour, what is the total driving time, in hours, it will take to transport all of his cattle to higher ground?
Output: Given the limited capacity of his transport vehicle (20 head of cattle), the 400 head of cattle will require 400/20=<<400/20=20>>20 trips using his transport vehicle.
Traveling to the site at 60 mph for 60 miles it will take 60/60=<<60/60=1>>1 hour to travel one-way.
Since each trip requires driving to and returning from the relocation site, each complete round trip will take 2*1=<<2*1=2>>2 hours.
Thus, 20 complete trips will take 20*2=<<20*2=40>>40 hours of driving time.
So the final answer is 40

Input: Jason has a carriage house that he rents out.  He’s charging $50.00 per day or $500.00 for 14 days.  Eric wants to rent the house for 20 days.  How much will it cost him?
Output: He wants to rent for 20 days and there is a deal if you rent for 14 days so that leaves 20-14 = <<20-14=6>>6 individual days
Each individual day is $50.00 and he will have 6 individual days for a total of 50*6 = $<<50*6=300.00>>300.00
14 days costs $500.00 and 6 days costs $300.00 for a total of 500+300 = $800.00
So the final answer is 800

Input: Melissa works on a poultry farm. She drives to town twice each month to buy supplies. If it takes her 3 hours to drive to town and back, how many hours does Melissa spend driving in a year?
Output: Melissa spends 2x3=<<2*3=6>>6 hours driving each month.
Since there are 12 months in a year, she spends 6x12=<<6*12=72>>72 hours driving each year.
So the final answer is 72

Input: The ratio of boys to girls in a family is 5:7. The total number of children in the family is 180. If the boys are given $3900 to share, how much money does each boy receive?
Output: The total ratio representing the number of children in the family is 5+7 = <<5+7=12>>12
From the total ratio of children in the family, 5/12 represent the number of boys, meaning that the number of boys in the family is 5/12*180 = <<5/12*180=75>>75
If the boys are given $3900 to share, each boy receives $3900/75 = $<<3900/75=52>>52
So the final answer is 52

Input: Josephine receives a bill from the hospital for 5000$.  50 percent of the bill is for medication.  25 percent of the remaining bill is for overnight stays, and 175$ is for food.  The rest of the bill is for the ambulance ride.  How much did the ambulance ride cost?
Output: Medication:5000(.50)=2500
Overnight Stays:2500(.25)=625
2500-625=<<2500-625=1875>>1875
Food:1875-175=<<1875-175=1700>>1700$
Ambulance ride:1700$
So the final answer is 1700

Input: It was time for Kelly to harvest her carrots that she had planted in three different beds.  In the first bed she pulled out 55 carrots.  In the second bed she pulled out 101 carrots and in the third bed she pulled out 78 carrots.  She found that 6 carrots weighed one pound.  How many pounds of carrots did Kelly harvest?
Output: She pulled out 55 + 101 + 78 = <<55+101+78=234>>234
6 carrots weigh one pound so 234/6 = <<234/6=39>>39 pounds of carrots
So the final answer is 39

Input: Iris’ family is planning a surprise birthday party for her. The party will include her 3 uncles and 4 aunts who have a son and daughter each as well as her brother and mother. In total, how many people are coming to Iris’ birthday party?
Output: Each of her aunts and uncles have a family unit of 1 son + 1 daughter + 1 aunt/uncle = <<1+1+1=3>>3 people.
Iris has a total of 3 uncles + 4 aunts = <<3+4=7>>7 aunts or uncles in these family units.
So among her aunts, uncles, and cousins, there will be 7 family units * 3 people in each family unit = <<7*3=21>>21 people.
Including her mother and brother, there will be a total of 21 people + 1 mother + 1 brother = <<21+1+1=23>>23 people coming to her party.
So the final answer is 23

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o8-tgsm8k-s30-rTrue
Loading extension module utils...
Time to load utils op: 0.40479564666748047 seconds
Evaluating commonsenseqa :   2%|█                                                       | 1/50 [00:36<29:25, 36.03s/it]Evaluating commonsenseqa :   4%|██▏                                                     | 2/50 [01:10<28:13, 35.27s/it]Evaluating commonsenseqa :   6%|███▎                                                    | 3/50 [01:45<27:26, 35.03s/it]Evaluating commonsenseqa :   8%|████▍                                                   | 4/50 [02:20<26:42, 34.83s/it]Evaluating commonsenseqa :  10%|█████▌                                                  | 5/50 [02:55<26:13, 34.97s/it]Evaluating commonsenseqa :  12%|██████▋                                                 | 6/50 [03:29<25:33, 34.84s/it]Evaluating commonsenseqa :  14%|███████▊                                                | 7/50 [04:04<24:54, 34.75s/it]Evaluating commonsenseqa :  16%|████████▉                                               | 8/50 [04:39<24:18, 34.74s/it]Evaluating commonsenseqa :  18%|██████████                                              | 9/50 [05:13<23:35, 34.52s/it]Evaluating commonsenseqa :  20%|███████████                                            | 10/50 [05:47<23:02, 34.57s/it]Evaluating commonsenseqa :  22%|████████████                                           | 11/50 [06:21<22:15, 34.23s/it]Evaluating commonsenseqa :  24%|█████████████▏                                         | 12/50 [06:54<21:27, 33.89s/it]Evaluating commonsenseqa :  26%|██████████████▎                                        | 13/50 [07:27<20:46, 33.69s/it]Evaluating commonsenseqa :  28%|███████████████▍                                       | 14/50 [08:01<20:09, 33.61s/it]Evaluating commonsenseqa :  30%|████████████████▌                                      | 15/50 [08:34<19:32, 33.50s/it]Evaluating commonsenseqa :  32%|█████████████████▌                                     | 16/50 [09:07<18:57, 33.46s/it]Evaluating commonsenseqa :  34%|██████████████████▋                                    | 17/50 [09:40<18:22, 33.40s/it]Evaluating commonsenseqa :  36%|███████████████████▊                                   | 18/50 [10:14<17:45, 33.30s/it]Evaluating commonsenseqa :  38%|████████████████████▉                                  | 19/50 [10:47<17:10, 33.24s/it]Evaluating commonsenseqa :  40%|██████████████████████                                 | 20/50 [11:20<16:39, 33.32s/it]Evaluating commonsenseqa :  42%|███████████████████████                                | 21/50 [11:54<16:09, 33.44s/it]Evaluating commonsenseqa :  44%|████████████████████████▏                              | 22/50 [12:27<15:35, 33.42s/it]Evaluating commonsenseqa :  46%|█████████████████████████▎                             | 23/50 [13:01<15:07, 33.63s/it]Evaluating commonsenseqa :  48%|██████████████████████████▍                            | 24/50 [13:34<14:30, 33.48s/it]Evaluating commonsenseqa :  50%|███████████████████████████▌                           | 25/50 [14:08<13:57, 33.50s/it]Evaluating commonsenseqa :  52%|████████████████████████████▌                          | 26/50 [14:42<13:30, 33.75s/it]Evaluating commonsenseqa :  54%|█████████████████████████████▋                         | 27/50 [15:15<12:51, 33.52s/it]Evaluating commonsenseqa :  56%|██████████████████████████████▊                        | 28/50 [15:48<12:13, 33.33s/it]Evaluating commonsenseqa :  58%|███████████████████████████████▉                       | 29/50 [16:21<11:38, 33.27s/it]Evaluating commonsenseqa :  60%|█████████████████████████████████                      | 30/50 [16:55<11:08, 33.43s/it]Evaluating commonsenseqa :  62%|██████████████████████████████████                     | 31/50 [17:29<10:38, 33.63s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████▏                   | 32/50 [18:02<10:03, 33.51s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████▎                  | 33/50 [18:36<09:29, 33.53s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████▍                 | 34/50 [19:09<08:55, 33.46s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████▌                | 35/50 [19:42<08:20, 33.36s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████▌               | 36/50 [20:15<07:45, 33.25s/it]Evaluating commonsenseqa :  74%|████████████████████████████████████████▋              | 37/50 [20:49<07:12, 33.26s/it]Evaluating commonsenseqa :  76%|█████████████████████████████████████████▊             | 38/50 [21:22<06:40, 33.36s/it]Evaluating commonsenseqa :  78%|██████████████████████████████████████████▉            | 39/50 [21:56<06:06, 33.35s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████           | 40/50 [22:29<05:34, 33.43s/it]Evaluating commonsenseqa :  82%|█████████████████████████████████████████████          | 41/50 [23:03<05:00, 33.38s/it]Evaluating commonsenseqa :  84%|██████████████████████████████████████████████▏        | 42/50 [23:36<04:27, 33.39s/it]Evaluating commonsenseqa :  86%|███████████████████████████████████████████████▎       | 43/50 [24:10<03:54, 33.45s/it]Evaluating commonsenseqa :  88%|████████████████████████████████████████████████▍      | 44/50 [24:43<03:20, 33.41s/it]Evaluating commonsenseqa :  90%|█████████████████████████████████████████████████▌     | 45/50 [25:16<02:46, 33.38s/it]Evaluating commonsenseqa :  92%|██████████████████████████████████████████████████▌    | 46/50 [25:50<02:14, 33.61s/it]Evaluating commonsenseqa :  94%|███████████████████████████████████████████████████▋   | 47/50 [26:24<01:41, 33.70s/it]Evaluating commonsenseqa :  96%|████████████████████████████████████████████████████▊  | 48/50 [26:58<01:07, 33.61s/it]Evaluating commonsenseqa :  98%|█████████████████████████████████████████████████████▉ | 49/50 [27:31<00:33, 33.52s/it]Evaluating commonsenseqa : 100%|███████████████████████████████████████████████████████| 50/50 [28:04<00:00, 33.51s/it]Evaluating commonsenseqa : 100%|███████████████████████████████████████████████████████| 50/50 [28:04<00:00, 33.70s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.5549} | avg. gen lenth: 450.094
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o9-tgsm8k-s30-rTrue --seed 30 --max-prompt-length 2048 --rationales --num-out-domain 9
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-23 12:21:23,398] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o9-tgsm8k-s30-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 9
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o9-tgsm8k-s30-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                         | 0/9741 [00:00<?, ?it/s]  0%|▎                                                                              | 31/9741 [00:00<00:32, 302.50it/s]  1%|▌                                                                              | 63/9741 [00:00<00:31, 306.94it/s]  1%|▊                                                                              | 94/9741 [00:00<00:31, 307.47it/s]  1%|█                                                                             | 125/9741 [00:00<00:31, 308.43it/s]  2%|█▎                                                                            | 157/9741 [00:00<00:30, 309.31it/s]  2%|█▌                                                                            | 188/9741 [00:00<00:30, 308.46it/s]  2%|█▊                                                                            | 220/9741 [00:00<00:30, 309.92it/s]  3%|██                                                                            | 251/9741 [00:00<00:31, 303.28it/s]  3%|██▎                                                                           | 282/9741 [00:00<00:31, 304.99it/s]  3%|██▌                                                                           | 314/9741 [00:01<00:30, 306.67it/s]  4%|██▊                                                                           | 345/9741 [00:01<00:30, 307.52it/s]  4%|███                                                                           | 377/9741 [00:01<00:30, 308.65it/s]  4%|███▎                                                                          | 408/9741 [00:01<00:30, 307.61it/s]  5%|███▌                                                                          | 440/9741 [00:01<00:30, 308.77it/s]  5%|███▊                                                                          | 472/9741 [00:01<00:29, 309.51it/s]  5%|████                                                                          | 504/9741 [00:01<00:29, 310.14it/s]  6%|████▎                                                                         | 536/9741 [00:01<00:29, 310.21it/s]  6%|████▌                                                                         | 571/9741 [00:01<00:28, 320.80it/s]  6%|████▉                                                                         | 617/9741 [00:01<00:25, 361.25it/s]  7%|█████▎                                                                        | 663/9741 [00:02<00:23, 388.81it/s]  7%|█████▋                                                                        | 710/9741 [00:02<00:22, 410.28it/s]  8%|██████                                                                        | 757/9741 [00:02<00:21, 425.47it/s]  8%|██████▍                                                                       | 803/9741 [00:02<00:20, 434.76it/s]  9%|██████▊                                                                       | 849/9741 [00:02<00:20, 442.09it/s]  9%|███████▏                                                                      | 895/9741 [00:02<00:19, 446.91it/s] 10%|███████▌                                                                      | 941/9741 [00:02<00:19, 449.61it/s] 10%|███████▉                                                                      | 987/9741 [00:02<00:19, 451.27it/s] 11%|████████▏                                                                    | 1033/9741 [00:02<00:19, 452.78it/s] 11%|████████▌                                                                    | 1079/9741 [00:02<00:19, 451.77it/s] 12%|████████▉                                                                    | 1125/9741 [00:03<00:19, 452.63it/s] 12%|█████████▎                                                                   | 1171/9741 [00:03<00:19, 447.28it/s] 12%|█████████▌                                                                   | 1217/9741 [00:03<00:18, 450.23it/s] 13%|█████████▉                                                                   | 1264/9741 [00:03<00:18, 453.56it/s] 13%|██████████▎                                                                  | 1310/9741 [00:03<00:18, 453.54it/s] 14%|██████████▋                                                                  | 1356/9741 [00:03<00:18, 454.94it/s] 14%|███████████                                                                  | 1402/9741 [00:03<00:18, 454.93it/s] 15%|███████████▍                                                                 | 1448/9741 [00:03<00:18, 454.58it/s] 15%|███████████▊                                                                 | 1494/9741 [00:03<00:18, 454.01it/s] 16%|████████████▏                                                                | 1540/9741 [00:03<00:18, 452.38it/s] 16%|████████████▌                                                                | 1586/9741 [00:04<00:18, 452.56it/s] 17%|████████████▉                                                                | 1632/9741 [00:04<00:17, 452.66it/s] 17%|█████████████▎                                                               | 1678/9741 [00:04<00:17, 452.64it/s] 18%|█████████████▋                                                               | 1724/9741 [00:04<00:17, 451.53it/s] 18%|█████████████▉                                                               | 1770/9741 [00:04<00:18, 427.22it/s] 19%|██████████████▎                                                              | 1816/9741 [00:04<00:18, 434.35it/s] 19%|██████████████▋                                                              | 1861/9741 [00:04<00:17, 438.78it/s] 20%|███████████████                                                              | 1906/9741 [00:04<00:17, 441.59it/s] 20%|███████████████▍                                                             | 1952/9741 [00:04<00:17, 444.64it/s] 21%|███████████████▊                                                             | 1997/9741 [00:05<00:17, 445.10it/s] 21%|████████████████▏                                                            | 2043/9741 [00:05<00:17, 446.73it/s] 21%|████████████████▌                                                            | 2088/9741 [00:05<00:17, 447.67it/s] 22%|████████████████▊                                                            | 2133/9741 [00:05<00:16, 447.57it/s] 22%|█████████████████▏                                                           | 2178/9741 [00:05<00:16, 447.64it/s] 23%|█████████████████▌                                                           | 2223/9741 [00:05<00:16, 446.19it/s] 23%|█████████████████▉                                                           | 2268/9741 [00:05<00:16, 446.43it/s] 24%|██████████████████▎                                                          | 2313/9741 [00:05<00:16, 446.66it/s] 24%|██████████████████▋                                                          | 2358/9741 [00:05<00:16, 446.86it/s] 25%|██████████████████▉                                                          | 2403/9741 [00:05<00:16, 446.69it/s] 25%|███████████████████▎                                                         | 2448/9741 [00:06<00:16, 445.09it/s] 26%|███████████████████▋                                                         | 2493/9741 [00:06<00:16, 438.01it/s] 26%|████████████████████                                                         | 2538/9741 [00:06<00:16, 440.40it/s] 27%|████████████████████▍                                                        | 2583/9741 [00:06<00:16, 441.99it/s] 27%|████████████████████▊                                                        | 2628/9741 [00:06<00:16, 442.83it/s] 27%|█████████████████████▏                                                       | 2673/9741 [00:06<00:16, 441.37it/s] 28%|█████████████████████▍                                                       | 2718/9741 [00:06<00:15, 441.89it/s] 28%|█████████████████████▊                                                       | 2763/9741 [00:06<00:15, 441.87it/s] 29%|██████████████████████▏                                                      | 2808/9741 [00:06<00:15, 442.51it/s] 29%|██████████████████████▌                                                      | 2853/9741 [00:06<00:15, 442.64it/s] 30%|██████████████████████▉                                                      | 2898/9741 [00:07<00:15, 441.83it/s] 30%|███████████████████████▎                                                     | 2943/9741 [00:07<00:15, 443.00it/s] 31%|███████████████████████▌                                                     | 2988/9741 [00:07<00:15, 443.49it/s] 31%|███████████████████████▉                                                     | 3033/9741 [00:07<00:15, 443.88it/s] 32%|████████████████████████▎                                                    | 3078/9741 [00:07<00:15, 443.18it/s] 32%|████████████████████████▋                                                    | 3123/9741 [00:07<00:15, 440.54it/s] 33%|█████████████████████████                                                    | 3168/9741 [00:07<00:14, 439.25it/s] 33%|█████████████████████████▍                                                   | 3212/9741 [00:07<00:14, 439.32it/s] 33%|█████████████████████████▋                                                   | 3256/9741 [00:07<00:14, 437.67it/s] 34%|██████████████████████████                                                   | 3300/9741 [00:07<00:14, 438.25it/s] 34%|██████████████████████████▍                                                  | 3344/9741 [00:08<00:14, 438.65it/s] 35%|██████████████████████████▊                                                  | 3388/9741 [00:08<00:14, 438.03it/s] 35%|███████████████████████████▏                                                 | 3433/9741 [00:08<00:14, 439.12it/s] 36%|███████████████████████████▍                                                 | 3478/9741 [00:08<00:14, 439.48it/s] 36%|███████████████████████████▊                                                 | 3522/9741 [00:08<00:14, 439.18it/s] 37%|████████████████████████████▏                                                | 3566/9741 [00:08<00:14, 438.93it/s] 37%|████████████████████████████▌                                                | 3610/9741 [00:08<00:14, 436.71it/s] 38%|████████████████████████████▉                                                | 3654/9741 [00:08<00:13, 436.91it/s] 38%|█████████████████████████████▏                                               | 3698/9741 [00:08<00:13, 436.82it/s] 38%|█████████████████████████████▌                                               | 3742/9741 [00:08<00:13, 436.46it/s] 39%|█████████████████████████████▉                                               | 3786/9741 [00:09<00:13, 436.71it/s] 39%|██████████████████████████████▎                                              | 3830/9741 [00:09<00:13, 434.66it/s] 40%|██████████████████████████████▌                                              | 3874/9741 [00:09<00:13, 435.59it/s] 40%|██████████████████████████████▉                                              | 3918/9741 [00:09<00:13, 436.62it/s] 41%|███████████████████████████████▎                                             | 3962/9741 [00:09<00:13, 436.92it/s] 41%|███████████████████████████████▋                                             | 4006/9741 [00:09<00:13, 437.33it/s] 42%|████████████████████████████████                                             | 4050/9741 [00:09<00:13, 435.04it/s] 42%|████████████████████████████████▎                                            | 4094/9741 [00:09<00:12, 435.20it/s] 42%|████████████████████████████████▋                                            | 4138/9741 [00:09<00:12, 435.04it/s] 43%|█████████████████████████████████                                            | 4182/9741 [00:09<00:12, 435.48it/s] 43%|█████████████████████████████████▍                                           | 4226/9741 [00:10<00:12, 435.18it/s] 44%|█████████████████████████████████▊                                           | 4270/9741 [00:10<00:12, 434.11it/s] 44%|██████████████████████████████████                                           | 4314/9741 [00:10<00:12, 435.25it/s] 45%|██████████████████████████████████▍                                          | 4358/9741 [00:10<00:12, 435.69it/s] 45%|██████████████████████████████████▊                                          | 4402/9741 [00:10<00:12, 436.09it/s] 46%|███████████████████████████████████▏                                         | 4446/9741 [00:10<00:12, 436.05it/s] 46%|███████████████████████████████████▍                                         | 4490/9741 [00:10<00:12, 406.47it/s] 47%|███████████████████████████████████▊                                         | 4533/9741 [00:10<00:12, 413.05it/s] 47%|████████████████████████████████████▏                                        | 4577/9741 [00:10<00:12, 418.75it/s] 47%|████████████████████████████████████▌                                        | 4621/9741 [00:11<00:12, 422.72it/s] 48%|████████████████████████████████████▉                                        | 4665/9741 [00:11<00:11, 425.44it/s] 48%|█████████████████████████████████████▏                                       | 4708/9741 [00:11<00:11, 426.00it/s] 49%|█████████████████████████████████████▌                                       | 4751/9741 [00:11<00:16, 305.30it/s] 49%|█████████████████████████████████████▉                                       | 4794/9741 [00:11<00:14, 332.59it/s] 50%|██████████████████████████████████████▏                                      | 4837/9741 [00:11<00:13, 355.08it/s] 50%|██████████████████████████████████████▌                                      | 4881/9741 [00:11<00:12, 375.55it/s] 51%|██████████████████████████████████████▉                                      | 4924/9741 [00:11<00:12, 389.66it/s] 51%|███████████████████████████████████████▎                                     | 4968/9741 [00:11<00:11, 401.45it/s] 51%|███████████████████████████████████████▌                                     | 5012/9741 [00:12<00:11, 410.00it/s] 52%|███████████████████████████████████████▉                                     | 5056/9741 [00:12<00:11, 416.49it/s] 52%|████████████████████████████████████████▎                                    | 5099/9741 [00:12<00:11, 415.09it/s] 53%|████████████████████████████████████████▋                                    | 5142/9741 [00:12<00:10, 418.73it/s] 53%|████████████████████████████████████████▉                                    | 5186/9741 [00:12<00:10, 422.99it/s] 54%|█████████████████████████████████████████▎                                   | 5230/9741 [00:12<00:10, 425.40it/s] 54%|█████████████████████████████████████████▋                                   | 5273/9741 [00:12<00:10, 426.01it/s] 55%|██████████████████████████████████████████                                   | 5317/9741 [00:12<00:10, 427.58it/s] 55%|██████████████████████████████████████████▍                                  | 5361/9741 [00:12<00:10, 429.43it/s] 55%|██████████████████████████████████████████▋                                  | 5405/9741 [00:12<00:10, 429.10it/s] 56%|███████████████████████████████████████████                                  | 5449/9741 [00:13<00:09, 430.32it/s] 56%|███████████████████████████████████████████▍                                 | 5493/9741 [00:13<00:09, 429.74it/s] 57%|███████████████████████████████████████████▊                                 | 5536/9741 [00:13<00:09, 428.96it/s] 57%|████████████████████████████████████████████                                 | 5579/9741 [00:13<00:09, 429.08it/s] 58%|████████████████████████████████████████████▍                                | 5622/9741 [00:13<00:09, 427.23it/s] 58%|████████████████████████████████████████████▊                                | 5665/9741 [00:13<00:09, 427.55it/s] 59%|█████████████████████████████████████████████▏                               | 5709/9741 [00:13<00:09, 428.42it/s] 59%|█████████████████████████████████████████████▍                               | 5752/9741 [00:13<00:09, 428.39it/s] 59%|█████████████████████████████████████████████▊                               | 5795/9741 [00:13<00:09, 428.80it/s] 60%|██████████████████████████████████████████████▏                              | 5838/9741 [00:13<00:09, 427.07it/s] 60%|██████████████████████████████████████████████▍                              | 5882/9741 [00:14<00:09, 428.63it/s] 61%|██████████████████████████████████████████████▊                              | 5926/9741 [00:14<00:08, 429.50it/s] 61%|███████████████████████████████████████████████▏                             | 5969/9741 [00:14<00:08, 429.64it/s] 62%|███████████████████████████████████████████████▌                             | 6012/9741 [00:14<00:08, 424.38it/s] 62%|███████████████████████████████████████████████▊                             | 6055/9741 [00:14<00:08, 423.39it/s] 63%|████████████████████████████████████████████████▏                            | 6099/9741 [00:14<00:08, 426.25it/s] 63%|████████████████████████████████████████████████▌                            | 6143/9741 [00:14<00:08, 428.24it/s] 64%|████████████████████████████████████████████████▉                            | 6187/9741 [00:14<00:08, 430.43it/s] 64%|█████████████████████████████████████████████████▎                           | 6231/9741 [00:14<00:08, 431.25it/s] 64%|█████████████████████████████████████████████████▌                           | 6275/9741 [00:14<00:08, 430.25it/s] 65%|█████████████████████████████████████████████████▉                           | 6319/9741 [00:15<00:07, 431.29it/s] 65%|██████████████████████████████████████████████████▎                          | 6363/9741 [00:15<00:07, 431.87it/s] 66%|██████████████████████████████████████████████████▋                          | 6407/9741 [00:15<00:07, 432.27it/s] 66%|██████████████████████████████████████████████████▉                          | 6451/9741 [00:15<00:07, 432.74it/s] 67%|███████████████████████████████████████████████████▎                         | 6495/9741 [00:15<00:07, 432.44it/s] 67%|███████████████████████████████████████████████████▋                         | 6539/9741 [00:15<00:07, 430.85it/s] 68%|████████████████████████████████████████████████████                         | 6583/9741 [00:15<00:07, 431.67it/s] 68%|████████████████████████████████████████████████████▍                        | 6627/9741 [00:15<00:07, 432.33it/s] 68%|████████████████████████████████████████████████████▋                        | 6671/9741 [00:15<00:07, 432.09it/s] 69%|█████████████████████████████████████████████████████                        | 6715/9741 [00:16<00:07, 431.75it/s] 69%|█████████████████████████████████████████████████████▍                       | 6759/9741 [00:16<00:06, 430.48it/s] 70%|█████████████████████████████████████████████████████▊                       | 6803/9741 [00:16<00:06, 430.89it/s] 70%|██████████████████████████████████████████████████████                       | 6847/9741 [00:16<00:06, 431.18it/s] 71%|██████████████████████████████████████████████████████▍                      | 6891/9741 [00:16<00:06, 431.40it/s] 71%|██████████████████████████████████████████████████████▊                      | 6935/9741 [00:16<00:06, 431.38it/s] 72%|███████████████████████████████████████████████████████▏                     | 6979/9741 [00:16<00:06, 427.72it/s] 72%|███████████████████████████████████████████████████████▌                     | 7022/9741 [00:16<00:06, 426.76it/s] 73%|███████████████████████████████████████████████████████▊                     | 7065/9741 [00:16<00:06, 427.11it/s] 73%|████████████████████████████████████████████████████████▏                    | 7108/9741 [00:16<00:06, 426.65it/s] 73%|████████████████████████████████████████████████████████▌                    | 7151/9741 [00:17<00:06, 426.51it/s] 74%|████████████████████████████████████████████████████████▊                    | 7194/9741 [00:17<00:05, 425.12it/s] 74%|█████████████████████████████████████████████████████████▏                   | 7237/9741 [00:17<00:05, 425.36it/s] 75%|█████████████████████████████████████████████████████████▌                   | 7280/9741 [00:17<00:05, 425.61it/s] 75%|█████████████████████████████████████████████████████████▉                   | 7323/9741 [00:17<00:05, 425.77it/s] 76%|██████████████████████████████████████████████████████████▏                  | 7366/9741 [00:17<00:05, 425.86it/s] 76%|██████████████████████████████████████████████████████████▌                  | 7409/9741 [00:17<00:05, 395.08it/s] 77%|██████████████████████████████████████████████████████████▉                  | 7452/9741 [00:17<00:05, 403.40it/s] 77%|███████████████████████████████████████████████████████████▎                 | 7496/9741 [00:17<00:05, 411.30it/s] 77%|███████████████████████████████████████████████████████████▌                 | 7539/9741 [00:17<00:05, 416.45it/s] 78%|███████████████████████████████████████████████████████████▉                 | 7583/9741 [00:18<00:05, 420.71it/s] 78%|████████████████████████████████████████████████████████████▎                | 7627/9741 [00:18<00:04, 424.08it/s] 79%|████████████████████████████████████████████████████████████▋                | 7670/9741 [00:18<00:04, 424.69it/s] 79%|████████████████████████████████████████████████████████████▉                | 7714/9741 [00:18<00:04, 428.04it/s] 80%|█████████████████████████████████████████████████████████████▎               | 7758/9741 [00:18<00:04, 430.24it/s] 80%|█████████████████████████████████████████████████████████████▋               | 7802/9741 [00:18<00:04, 431.42it/s] 81%|██████████████████████████████████████████████████████████████               | 7846/9741 [00:18<00:04, 432.44it/s] 81%|██████████████████████████████████████████████████████████████▎              | 7890/9741 [00:18<00:04, 430.57it/s] 81%|██████████████████████████████████████████████████████████████▋              | 7934/9741 [00:18<00:04, 430.91it/s] 82%|███████████████████████████████████████████████████████████████              | 7978/9741 [00:18<00:04, 430.43it/s] 82%|███████████████████████████████████████████████████████████████▍             | 8022/9741 [00:19<00:03, 429.91it/s] 83%|███████████████████████████████████████████████████████████████▊             | 8065/9741 [00:19<00:03, 429.84it/s] 83%|████████████████████████████████████████████████████████████████             | 8108/9741 [00:19<00:03, 429.14it/s] 84%|████████████████████████████████████████████████████████████████▍            | 8152/9741 [00:19<00:03, 430.69it/s] 84%|████████████████████████████████████████████████████████████████▊            | 8196/9741 [00:19<00:03, 426.00it/s] 85%|█████████████████████████████████████████████████████████████████▏           | 8240/9741 [00:19<00:03, 428.01it/s] 85%|█████████████████████████████████████████████████████████████████▍           | 8284/9741 [00:19<00:03, 429.12it/s] 85%|█████████████████████████████████████████████████████████████████▊           | 8327/9741 [00:19<00:03, 428.24it/s] 86%|██████████████████████████████████████████████████████████████████▏          | 8371/9741 [00:19<00:03, 429.68it/s] 86%|██████████████████████████████████████████████████████████████████▌          | 8415/9741 [00:20<00:03, 429.81it/s] 87%|██████████████████████████████████████████████████████████████████▊          | 8458/9741 [00:20<00:02, 429.54it/s] 87%|███████████████████████████████████████████████████████████████████▏         | 8501/9741 [00:20<00:02, 429.31it/s] 88%|███████████████████████████████████████████████████████████████████▌         | 8544/9741 [00:20<00:02, 427.74it/s] 88%|███████████████████████████████████████████████████████████████████▉         | 8588/9741 [00:20<00:02, 428.88it/s] 89%|████████████████████████████████████████████████████████████████████▏        | 8632/9741 [00:20<00:02, 429.37it/s] 89%|████████████████████████████████████████████████████████████████████▌        | 8676/9741 [00:20<00:02, 430.19it/s] 90%|████████████████████████████████████████████████████████████████████▉        | 8720/9741 [00:20<00:02, 431.23it/s] 90%|█████████████████████████████████████████████████████████████████████▎       | 8764/9741 [00:20<00:02, 427.41it/s] 90%|█████████████████████████████████████████████████████████████████████▌       | 8807/9741 [00:20<00:02, 427.05it/s] 91%|█████████████████████████████████████████████████████████████████████▉       | 8851/9741 [00:21<00:02, 428.82it/s] 91%|██████████████████████████████████████████████████████████████████████▎      | 8895/9741 [00:21<00:01, 430.33it/s] 92%|██████████████████████████████████████████████████████████████████████▋      | 8939/9741 [00:21<00:01, 431.36it/s] 92%|███████████████████████████████████████████████████████████████████████      | 8983/9741 [00:21<00:01, 431.86it/s] 93%|███████████████████████████████████████████████████████████████████████▎     | 9027/9741 [00:21<00:01, 430.70it/s] 93%|███████████████████████████████████████████████████████████████████████▋     | 9071/9741 [00:21<00:01, 431.69it/s] 94%|████████████████████████████████████████████████████████████████████████     | 9115/9741 [00:21<00:01, 432.22it/s] 94%|████████████████████████████████████████████████████████████████████████▍    | 9159/9741 [00:21<00:01, 432.84it/s] 94%|████████████████████████████████████████████████████████████████████████▋    | 9203/9741 [00:21<00:01, 433.38it/s] 95%|█████████████████████████████████████████████████████████████████████████    | 9247/9741 [00:21<00:01, 432.18it/s] 95%|█████████████████████████████████████████████████████████████████████████▍   | 9291/9741 [00:22<00:01, 432.64it/s] 96%|█████████████████████████████████████████████████████████████████████████▊   | 9335/9741 [00:22<00:00, 432.61it/s] 96%|██████████████████████████████████████████████████████████████████████████▏  | 9379/9741 [00:22<00:00, 432.72it/s] 97%|██████████████████████████████████████████████████████████████████████████▍  | 9423/9741 [00:22<00:00, 427.91it/s] 97%|██████████████████████████████████████████████████████████████████████████▊  | 9466/9741 [00:22<00:00, 425.48it/s] 98%|███████████████████████████████████████████████████████████████████████████▏ | 9509/9741 [00:22<00:00, 426.27it/s] 98%|███████████████████████████████████████████████████████████████████████████▌ | 9552/9741 [00:22<00:00, 426.61it/s] 99%|███████████████████████████████████████████████████████████████████████████▊ | 9595/9741 [00:22<00:00, 427.00it/s] 99%|████████████████████████████████████████████████████████████████████████████▏| 9639/9741 [00:22<00:00, 428.82it/s] 99%|████████████████████████████████████████████████████████████████████████████▌| 9682/9741 [00:22<00:00, 427.92it/s]100%|████████████████████████████████████████████████████████████████████████████▉| 9726/9741 [00:23<00:00, 429.32it/s]100%|█████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:23<00:00, 421.81it/s]
Load End
Num instances: 1000
[2023-08-23 12:21:57,787] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-23 12:22:00,537] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-23 12:22:00,538] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-23 12:22:00,538] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-23 12:22:00,538] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-23 12:22:00,538] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-23 12:22:00,538] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f4b99b08a60>
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f4b99b08940>
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-23 12:22:00,539] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-23 12:22:00,540] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-23 12:22:00,540] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-23 12:22:00,540] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-23 12:22:00,540] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-23 12:22:00,540] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4416217803955078 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: The car-rental agency charges $30/day for a car, or $190 for the first week for a rental that lasts an entire week or longer. Jennie rented a car for 11 days. How much, in dollars, did she pay for the rental?
Output: The first 7 days were $190.
There were 11-7=<<11-7=4>>4 days left.
The additional 4 days were 4*30=<<4*30=120>>120.
And 190+120=<<190+120=310>>310.
So the final answer is 310

Input: A hurricane is approaching the southern coast of Texas, and a rancher is planning to move 400 head of cattle 60 miles to higher ground to protect them from possible inland flooding that might occur.  His animal transport truck holds 20 head of cattle.  Traveling at 60 miles per hour, what is the total driving time, in hours, it will take to transport all of his cattle to higher ground?
Output: Given the limited capacity of his transport vehicle (20 head of cattle), the 400 head of cattle will require 400/20=<<400/20=20>>20 trips using his transport vehicle.
Traveling to the site at 60 mph for 60 miles it will take 60/60=<<60/60=1>>1 hour to travel one-way.
Since each trip requires driving to and returning from the relocation site, each complete round trip will take 2*1=<<2*1=2>>2 hours.
Thus, 20 complete trips will take 20*2=<<20*2=40>>40 hours of driving time.
So the final answer is 40

Input: Jason has a carriage house that he rents out.  He’s charging $50.00 per day or $500.00 for 14 days.  Eric wants to rent the house for 20 days.  How much will it cost him?
Output: He wants to rent for 20 days and there is a deal if you rent for 14 days so that leaves 20-14 = <<20-14=6>>6 individual days
Each individual day is $50.00 and he will have 6 individual days for a total of 50*6 = $<<50*6=300.00>>300.00
14 days costs $500.00 and 6 days costs $300.00 for a total of 500+300 = $800.00
So the final answer is 800

Input: Melissa works on a poultry farm. She drives to town twice each month to buy supplies. If it takes her 3 hours to drive to town and back, how many hours does Melissa spend driving in a year?
Output: Melissa spends 2x3=<<2*3=6>>6 hours driving each month.
Since there are 12 months in a year, she spends 6x12=<<6*12=72>>72 hours driving each year.
So the final answer is 72

Input: The ratio of boys to girls in a family is 5:7. The total number of children in the family is 180. If the boys are given $3900 to share, how much money does each boy receive?
Output: The total ratio representing the number of children in the family is 5+7 = <<5+7=12>>12
From the total ratio of children in the family, 5/12 represent the number of boys, meaning that the number of boys in the family is 5/12*180 = <<5/12*180=75>>75
If the boys are given $3900 to share, each boy receives $3900/75 = $<<3900/75=52>>52
So the final answer is 52

Input: Josephine receives a bill from the hospital for 5000$.  50 percent of the bill is for medication.  25 percent of the remaining bill is for overnight stays, and 175$ is for food.  The rest of the bill is for the ambulance ride.  How much did the ambulance ride cost?
Output: Medication:5000(.50)=2500
Overnight Stays:2500(.25)=625
2500-625=<<2500-625=1875>>1875
Food:1875-175=<<1875-175=1700>>1700$
Ambulance ride:1700$
So the final answer is 1700

Input: It was time for Kelly to harvest her carrots that she had planted in three different beds.  In the first bed she pulled out 55 carrots.  In the second bed she pulled out 101 carrots and in the third bed she pulled out 78 carrots.  She found that 6 carrots weighed one pound.  How many pounds of carrots did Kelly harvest?
Output: She pulled out 55 + 101 + 78 = <<55+101+78=234>>234
6 carrots weigh one pound so 234/6 = <<234/6=39>>39 pounds of carrots
So the final answer is 39

Input: Iris’ family is planning a surprise birthday party for her. The party will include her 3 uncles and 4 aunts who have a son and daughter each as well as her brother and mother. In total, how many people are coming to Iris’ birthday party?
Output: Each of her aunts and uncles have a family unit of 1 son + 1 daughter + 1 aunt/uncle = <<1+1+1=3>>3 people.
Iris has a total of 3 uncles + 4 aunts = <<3+4=7>>7 aunts or uncles in these family units.
So among her aunts, uncles, and cousins, there will be 7 family units * 3 people in each family unit = <<7*3=21>>21 people.
Including her mother and brother, there will be a total of 21 people + 1 mother + 1 brother = <<21+1+1=23>>23 people coming to her party.
So the final answer is 23

Input: Lyra bought a pair of shoes at a 20% discount.  If she paid $480, how much was the original price of the pair of shoes?
Output: Lyra only paid $480 for the pair of shoes which is only 100% - 20% = 80% of the original price.
So let x be the original price.
Then 0.8x = $480
Thus x = $480 / 0.8 = $<<480/0.8=600>>600
So the final answer is 600

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o9-tgsm8k-s30-rTrue
Loading extension module utils...
Time to load utils op: 0.40456151962280273 seconds
Evaluating commonsenseqa :   2%|█                                                       | 1/50 [00:33<27:06, 33.19s/it]Evaluating commonsenseqa :   4%|██▏                                                     | 2/50 [01:05<26:00, 32.52s/it]Evaluating commonsenseqa :   6%|███▎                                                    | 3/50 [01:37<25:16, 32.28s/it]Evaluating commonsenseqa :   8%|████▍                                                   | 4/50 [02:09<24:50, 32.41s/it]Evaluating commonsenseqa :  10%|█████▌                                                  | 5/50 [02:42<24:23, 32.52s/it]Evaluating commonsenseqa :  12%|██████▋                                                 | 6/50 [03:15<23:54, 32.61s/it]Evaluating commonsenseqa :  14%|███████▊                                                | 7/50 [03:47<23:14, 32.44s/it]Evaluating commonsenseqa :  16%|████████▉                                               | 8/50 [04:19<22:40, 32.39s/it]Evaluating commonsenseqa :  18%|██████████                                              | 9/50 [04:51<22:03, 32.29s/it]Evaluating commonsenseqa :  20%|███████████                                            | 10/50 [05:23<21:29, 32.25s/it]Evaluating commonsenseqa :  22%|████████████                                           | 11/50 [05:56<21:00, 32.33s/it]Evaluating commonsenseqa :  24%|█████████████▏                                         | 12/50 [06:28<20:25, 32.24s/it]Evaluating commonsenseqa :  26%|██████████████▎                                        | 13/50 [07:00<19:48, 32.13s/it]Evaluating commonsenseqa :  28%|███████████████▍                                       | 14/50 [07:32<19:13, 32.05s/it]Evaluating commonsenseqa :  30%|████████████████▌                                      | 15/50 [08:04<18:47, 32.21s/it]Evaluating commonsenseqa :  32%|█████████████████▌                                     | 16/50 [08:36<18:11, 32.09s/it]Evaluating commonsenseqa :  34%|██████████████████▋                                    | 17/50 [09:08<17:39, 32.11s/it]Evaluating commonsenseqa :  36%|███████████████████▊                                   | 18/50 [09:40<17:05, 32.03s/it]Evaluating commonsenseqa :  38%|████████████████████▉                                  | 19/50 [10:12<16:34, 32.09s/it]Evaluating commonsenseqa :  40%|██████████████████████                                 | 20/50 [10:45<16:03, 32.13s/it]Evaluating commonsenseqa :  42%|███████████████████████                                | 21/50 [11:17<15:32, 32.16s/it]Evaluating commonsenseqa :  44%|████████████████████████▏                              | 22/50 [11:49<14:58, 32.08s/it]Evaluating commonsenseqa :  46%|█████████████████████████▎                             | 23/50 [12:21<14:31, 32.29s/it]Evaluating commonsenseqa :  48%|██████████████████████████▍                            | 24/50 [12:53<13:55, 32.15s/it]Evaluating commonsenseqa :  50%|███████████████████████████▌                           | 25/50 [13:26<13:25, 32.20s/it]Evaluating commonsenseqa :  52%|████████████████████████████▌                          | 26/50 [13:58<12:55, 32.32s/it]Evaluating commonsenseqa :  54%|█████████████████████████████▋                         | 27/50 [14:31<12:25, 32.43s/it]Evaluating commonsenseqa :  56%|██████████████████████████████▊                        | 28/50 [15:03<11:51, 32.35s/it]Evaluating commonsenseqa :  58%|███████████████████████████████▉                       | 29/50 [15:35<11:16, 32.20s/it]Evaluating commonsenseqa :  60%|█████████████████████████████████                      | 30/50 [16:07<10:45, 32.30s/it]Evaluating commonsenseqa :  62%|██████████████████████████████████                     | 31/50 [16:39<10:11, 32.20s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████▏                   | 32/50 [17:11<09:38, 32.12s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████▎                  | 33/50 [17:44<09:07, 32.22s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████▍                 | 34/50 [18:17<08:38, 32.39s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████▌                | 35/50 [18:49<08:06, 32.42s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████▌               | 36/50 [19:21<07:32, 32.31s/it]Evaluating commonsenseqa :  74%|████████████████████████████████████████▋              | 37/50 [19:54<07:00, 32.35s/it]Evaluating commonsenseqa :  76%|█████████████████████████████████████████▊             | 38/50 [20:26<06:27, 32.32s/it]Evaluating commonsenseqa :  78%|██████████████████████████████████████████▉            | 39/50 [20:58<05:56, 32.42s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████           | 40/50 [21:30<05:22, 32.29s/it]Evaluating commonsenseqa :  82%|█████████████████████████████████████████████          | 41/50 [22:04<04:53, 32.62s/it]Evaluating commonsenseqa :  84%|██████████████████████████████████████████████▏        | 42/50 [22:37<04:21, 32.65s/it]Evaluating commonsenseqa :  86%|███████████████████████████████████████████████▎       | 43/50 [23:13<03:55, 33.68s/it]Evaluating commonsenseqa :  88%|████████████████████████████████████████████████▍      | 44/50 [23:45<03:20, 33.37s/it]Evaluating commonsenseqa :  90%|█████████████████████████████████████████████████▌     | 45/50 [24:17<02:45, 33.02s/it]Evaluating commonsenseqa :  92%|██████████████████████████████████████████████████▌    | 46/50 [24:50<02:10, 32.75s/it]Evaluating commonsenseqa :  94%|███████████████████████████████████████████████████▋   | 47/50 [25:22<01:38, 32.68s/it]Evaluating commonsenseqa :  96%|████████████████████████████████████████████████████▊  | 48/50 [25:54<01:05, 32.56s/it]Evaluating commonsenseqa :  98%|█████████████████████████████████████████████████████▉ | 49/50 [26:27<00:32, 32.45s/it]Evaluating commonsenseqa : 100%|███████████████████████████████████████████████████████| 50/50 [26:59<00:00, 32.32s/it]Evaluating commonsenseqa : 100%|███████████████████████████████████████████████████████| 50/50 [26:59<00:00, 32.38s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.4843} | avg. gen lenth: 431.418
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s30-rFalse --seed 30 --max-prompt-length 2048 --num-out-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-23 12:49:11,447] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s30-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 1
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o1-tgsm8k-s30-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                         | 0/9741 [00:00<?, ?it/s]  3%|██▏                                                                          | 270/9741 [00:00<00:03, 2691.39it/s]  6%|████▍                                                                        | 555/9741 [00:00<00:03, 2780.71it/s]  9%|██████▋                                                                      | 844/9741 [00:00<00:03, 2828.61it/s] 12%|████████▊                                                                   | 1137/9741 [00:00<00:03, 2865.50it/s] 15%|███████████▏                                                                | 1427/9741 [00:00<00:02, 2875.63it/s] 18%|█████████████▍                                                              | 1721/9741 [00:00<00:02, 2897.07it/s] 21%|███████████████▋                                                            | 2011/9741 [00:00<00:02, 2892.80it/s] 24%|█████████████████▉                                                          | 2304/9741 [00:00<00:02, 2902.27it/s] 27%|████████████████████▎                                                       | 2600/9741 [00:00<00:02, 2917.81it/s] 30%|██████████████████████▌                                                     | 2892/9741 [00:01<00:02, 2854.09it/s] 33%|████████████████████████▊                                                   | 3185/9741 [00:01<00:02, 2874.60it/s] 36%|███████████████████████████▏                                                | 3480/9741 [00:01<00:02, 2894.96it/s] 39%|█████████████████████████████▍                                              | 3774/9741 [00:01<00:02, 2905.87it/s] 42%|███████████████████████████████▋                                            | 4069/9741 [00:01<00:01, 2916.29it/s] 45%|██████████████████████████████████                                          | 4364/9741 [00:01<00:01, 2925.67it/s] 48%|████████████████████████████████████▎                                       | 4657/9741 [00:01<00:01, 2909.17it/s] 51%|██████████████████████████████████████▌                                     | 4948/9741 [00:01<00:02, 2214.29it/s] 54%|████████████████████████████████████████▉                                   | 5243/9741 [00:01<00:01, 2393.35it/s] 58%|███████████████████████████████████████████▉                                | 5635/9741 [00:02<00:01, 2787.64it/s] 63%|███████████████████████████████████████████████▌                            | 6090/9741 [00:02<00:01, 3263.32it/s] 67%|███████████████████████████████████████████████████                         | 6546/9741 [00:02<00:00, 3623.37it/s] 72%|██████████████████████████████████████████████████████▋                     | 7006/9741 [00:02<00:00, 3900.75it/s] 77%|██████████████████████████████████████████████████████████▏                 | 7461/9741 [00:02<00:00, 4086.80it/s] 81%|█████████████████████████████████████████████████████████████▊              | 7921/9741 [00:02<00:00, 4235.53it/s] 86%|█████████████████████████████████████████████████████████████████▍          | 8382/9741 [00:02<00:00, 4344.97it/s] 91%|████████████████████████████████████████████████████████████████████▉       | 8839/9741 [00:02<00:00, 4410.84it/s] 95%|████████████████████████████████████████████████████████████████████████▌   | 9299/9741 [00:02<00:00, 4465.37it/s]100%|████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:02<00:00, 3340.41it/s]
Load End
Num instances: 1000
[2023-08-23 12:49:25,438] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-23 12:49:28,215] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-23 12:49:28,217] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-23 12:49:28,219] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-23 12:49:28,220] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-23 12:49:28,220] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-23 12:49:28,220] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-23 12:49:28,220] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-23 12:49:28,220] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-23 12:49:28,220] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-23 12:49:28,220] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-23 12:49:28,220] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-23 12:49:28,220] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f78b37d3a60>
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f78b37d3940>
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-23 12:49:28,221] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-23 12:49:28,222] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-23 12:49:28,222] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-23 12:49:28,222] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-23 12:49:28,222] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-23 12:49:28,222] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-23 12:49:28,222] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-23 12:49:28,222] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-23 12:49:28,222] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-23 12:49:28,222] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-23 12:49:28,222] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-23 12:49:28,222] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-23 12:49:28,222] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-23 12:49:28,222] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-23 12:49:28,222] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-23 12:49:28,222] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-23 12:49:28,222] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-23 12:49:28,222] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-23 12:49:28,222] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-23 12:49:28,222] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-23 12:49:28,222] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.47377991676330566 seconds
Loading extension module utils...
Time to load utils op: 0.50518798828125 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: The car-rental agency charges $30/day for a car, or $190 for the first week for a rental that lasts an entire week or longer. Jennie rented a car for 11 days. How much, in dollars, did she pay for the rental?
Output: 310

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o1-tgsm8k-s30-rFalse
Evaluating commonsenseqa :   2%|█                                                       | 1/50 [01:05<53:19, 65.29s/it]Evaluating commonsenseqa :   4%|██▏                                                     | 2/50 [02:10<52:17, 65.37s/it]Evaluating commonsenseqa :   6%|███▎                                                    | 3/50 [03:16<51:21, 65.56s/it]Evaluating commonsenseqa :   8%|████▍                                                   | 4/50 [04:23<50:34, 65.97s/it]Evaluating commonsenseqa :  10%|█████▌                                                  | 5/50 [05:31<50:08, 66.86s/it]Evaluating commonsenseqa :  12%|██████▋                                                 | 6/50 [06:35<48:19, 65.91s/it]Evaluating commonsenseqa :  14%|███████▊                                                | 7/50 [07:41<47:13, 65.89s/it]Evaluating commonsenseqa :  16%|████████▉                                               | 8/50 [08:47<46:04, 65.83s/it]Evaluating commonsenseqa :  18%|██████████                                              | 9/50 [09:51<44:36, 65.29s/it]Evaluating commonsenseqa :  20%|███████████                                            | 10/50 [10:57<43:43, 65.60s/it]Evaluating commonsenseqa :  22%|████████████                                           | 11/50 [12:02<42:30, 65.40s/it]Evaluating commonsenseqa :  24%|█████████████▏                                         | 12/50 [13:09<41:39, 65.78s/it]Evaluating commonsenseqa :  26%|██████████████▎                                        | 13/50 [14:14<40:26, 65.59s/it]Evaluating commonsenseqa :  28%|███████████████▍                                       | 14/50 [15:17<38:59, 64.98s/it]Evaluating commonsenseqa :  30%|████████████████▌                                      | 15/50 [16:24<38:11, 65.48s/it]Evaluating commonsenseqa :  32%|█████████████████▌                                     | 16/50 [17:31<37:19, 65.87s/it]Evaluating commonsenseqa :  34%|██████████████████▋                                    | 17/50 [18:38<36:23, 66.16s/it]Evaluating commonsenseqa :  36%|███████████████████▊                                   | 18/50 [19:43<35:12, 66.03s/it]Evaluating commonsenseqa :  38%|████████████████████▉                                  | 19/50 [20:49<33:59, 65.79s/it]Evaluating commonsenseqa :  40%|██████████████████████                                 | 20/50 [21:54<32:51, 65.71s/it]Evaluating commonsenseqa :  42%|███████████████████████                                | 21/50 [22:59<31:35, 65.37s/it]Evaluating commonsenseqa :  44%|████████████████████████▏                              | 22/50 [24:04<30:30, 65.38s/it]Evaluating commonsenseqa :  46%|█████████████████████████▎                             | 23/50 [25:11<29:35, 65.77s/it]Evaluating commonsenseqa :  48%|██████████████████████████▍                            | 24/50 [26:17<28:31, 65.81s/it]Evaluating commonsenseqa :  50%|███████████████████████████▌                           | 25/50 [27:21<27:16, 65.47s/it]Evaluating commonsenseqa :  52%|████████████████████████████▌                          | 26/50 [28:29<26:26, 66.12s/it]Evaluating commonsenseqa :  54%|█████████████████████████████▋                         | 27/50 [29:36<25:26, 66.37s/it]Evaluating commonsenseqa :  56%|██████████████████████████████▊                        | 28/50 [30:42<24:20, 66.40s/it]Evaluating commonsenseqa :  58%|███████████████████████████████▉                       | 29/50 [31:48<23:10, 66.22s/it]Evaluating commonsenseqa :  60%|█████████████████████████████████                      | 30/50 [32:56<22:11, 66.59s/it]Evaluating commonsenseqa :  62%|██████████████████████████████████                     | 31/50 [34:04<21:14, 67.10s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████▏                   | 32/50 [35:11<20:09, 67.20s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████▎                  | 33/50 [36:16<18:49, 66.44s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████▍                 | 34/50 [37:21<17:37, 66.06s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████▌                | 35/50 [38:28<16:32, 66.16s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████▌               | 36/50 [39:33<15:25, 66.07s/it]Evaluating commonsenseqa :  74%|████████████████████████████████████████▋              | 37/50 [40:39<14:17, 65.94s/it]Evaluating commonsenseqa :  76%|█████████████████████████████████████████▊             | 38/50 [41:46<13:13, 66.14s/it]Evaluating commonsenseqa :  78%|██████████████████████████████████████████▉            | 39/50 [42:51<12:04, 65.84s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████           | 40/50 [43:58<11:02, 66.26s/it]Evaluating commonsenseqa :  82%|█████████████████████████████████████████████          | 41/50 [45:02<09:51, 65.70s/it]Evaluating commonsenseqa :  84%|██████████████████████████████████████████████▏        | 42/50 [46:07<08:42, 65.34s/it]Evaluating commonsenseqa :  86%|███████████████████████████████████████████████▎       | 43/50 [47:11<07:35, 65.08s/it]Evaluating commonsenseqa :  88%|████████████████████████████████████████████████▍      | 44/50 [48:17<06:31, 65.20s/it]Evaluating commonsenseqa :  90%|█████████████████████████████████████████████████▌     | 45/50 [49:23<05:27, 65.52s/it]Evaluating commonsenseqa :  92%|██████████████████████████████████████████████████▌    | 46/50 [50:29<04:22, 65.65s/it]Evaluating commonsenseqa :  94%|███████████████████████████████████████████████████▋   | 47/50 [51:36<03:18, 66.03s/it]Evaluating commonsenseqa :  96%|████████████████████████████████████████████████████▊  | 48/50 [52:43<02:12, 66.16s/it]Evaluating commonsenseqa :  98%|█████████████████████████████████████████████████████▉ | 49/50 [53:49<01:06, 66.13s/it]Evaluating commonsenseqa : 100%|███████████████████████████████████████████████████████| 50/50 [54:53<00:00, 65.71s/it]Evaluating commonsenseqa : 100%|███████████████████████████████████████████████████████| 50/50 [54:53<00:00, 65.88s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.0659} | avg. gen lenth: 325.92
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s30-rFalse --seed 30 --max-prompt-length 2048 --num-out-domain 2
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-23 13:44:41,135] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s30-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 2
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o2-tgsm8k-s30-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                         | 0/9741 [00:00<?, ?it/s]  2%|█▎                                                                           | 173/9741 [00:00<00:05, 1727.74it/s]  4%|██▊                                                                          | 353/9741 [00:00<00:05, 1769.12it/s]  6%|████▏                                                                        | 536/9741 [00:00<00:05, 1793.66it/s]  7%|█████▋                                                                       | 719/9741 [00:00<00:04, 1806.51it/s]  9%|███████▏                                                                     | 904/9741 [00:00<00:04, 1818.12it/s] 11%|████████▌                                                                   | 1090/9741 [00:00<00:04, 1830.18it/s] 13%|█████████▉                                                                  | 1276/9741 [00:00<00:04, 1836.53it/s] 15%|███████████▍                                                                | 1460/9741 [00:00<00:04, 1836.31it/s] 17%|████████████▊                                                               | 1645/9741 [00:00<00:04, 1840.50it/s] 19%|██████████████▎                                                             | 1830/9741 [00:01<00:04, 1772.22it/s] 21%|███████████████▋                                                            | 2012/9741 [00:01<00:04, 1785.78it/s] 23%|█████████████████▏                                                          | 2196/9741 [00:01<00:04, 1801.15it/s] 24%|██████████████████▌                                                         | 2382/9741 [00:01<00:04, 1816.44it/s] 26%|████████████████████                                                        | 2567/9741 [00:01<00:03, 1823.88it/s] 28%|█████████████████████▍                                                      | 2751/9741 [00:01<00:03, 1826.09it/s] 30%|██████████████████████▉                                                     | 2936/9741 [00:01<00:03, 1832.33it/s] 32%|████████████████████████▎                                                   | 3121/9741 [00:01<00:03, 1836.58it/s] 34%|█████████████████████████▊                                                  | 3309/9741 [00:01<00:03, 1847.07it/s] 37%|███████████████████████████▉                                                | 3576/9741 [00:01<00:02, 2092.61it/s] 40%|██████████████████████████████                                              | 3860/9741 [00:02<00:02, 2314.18it/s] 43%|████████████████████████████████▎                                           | 4144/9741 [00:02<00:02, 2469.37it/s] 45%|██████████████████████████████████▌                                         | 4428/9741 [00:02<00:02, 2578.11it/s] 48%|████████████████████████████████████▋                                       | 4701/9741 [00:02<00:01, 2621.76it/s] 51%|██████████████████████████████████████▋                                     | 4964/9741 [00:02<00:02, 2046.47it/s] 54%|████████████████████████████████████████▉                                   | 5252/9741 [00:02<00:01, 2253.34it/s] 57%|███████████████████████████████████████████▏                                | 5539/9741 [00:02<00:01, 2415.15it/s] 60%|█████████████████████████████████████████████▍                              | 5829/9741 [00:02<00:01, 2546.08it/s] 63%|███████████████████████████████████████████████▊                            | 6121/9741 [00:02<00:01, 2650.53it/s] 66%|██████████████████████████████████████████████████                          | 6412/9741 [00:03<00:01, 2722.97it/s] 69%|████████████████████████████████████████████████████▎                       | 6702/9741 [00:03<00:01, 2773.39it/s] 72%|██████████████████████████████████████████████████████▌                     | 6995/9741 [00:03<00:00, 2816.47it/s] 75%|████████████████████████████████████████████████████████▊                   | 7281/9741 [00:03<00:00, 2798.70it/s] 78%|███████████████████████████████████████████████████████████                 | 7564/9741 [00:03<00:00, 2778.56it/s] 81%|█████████████████████████████████████████████████████████████▎              | 7853/9741 [00:03<00:00, 2810.72it/s] 84%|███████████████████████████████████████████████████████████████▌            | 8143/9741 [00:03<00:00, 2835.19it/s] 87%|█████████████████████████████████████████████████████████████████▊          | 8433/9741 [00:03<00:00, 2852.25it/s] 90%|████████████████████████████████████████████████████████████████████        | 8721/9741 [00:03<00:00, 2858.76it/s] 92%|██████████████████████████████████████████████████████████████████████▎     | 9009/9741 [00:03<00:00, 2863.50it/s] 95%|████████████████████████████████████████████████████████████████████████▌   | 9298/9741 [00:04<00:00, 2871.01it/s] 98%|██████████████████████████████████████████████████████████████████████████▊ | 9586/9741 [00:04<00:00, 2869.85it/s]100%|████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:04<00:00, 2331.40it/s]
Load End
Num instances: 1000
[2023-08-23 13:44:56,235] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-23 13:44:59,169] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-23 13:44:59,169] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-23 13:44:59,169] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-23 13:44:59,169] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-23 13:44:59,169] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-23 13:44:59,169] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f6a6d67fa60>
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f6a6d67f940>
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-23 13:44:59,170] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-23 13:44:59,171] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-23 13:44:59,171] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-23 13:44:59,171] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-23 13:44:59,171] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-23 13:44:59,171] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-23 13:44:59,171] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-23 13:44:59,171] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-23 13:44:59,171] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-23 13:44:59,171] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-23 13:44:59,171] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-23 13:44:59,171] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-23 13:44:59,171] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-23 13:44:59,171] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.42670345306396484 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: The car-rental agency charges $30/day for a car, or $190 for the first week for a rental that lasts an entire week or longer. Jennie rented a car for 11 days. How much, in dollars, did she pay for the rental?
Output: 310

Input: A hurricane is approaching the southern coast of Texas, and a rancher is planning to move 400 head of cattle 60 miles to higher ground to protect them from possible inland flooding that might occur.  His animal transport truck holds 20 head of cattle.  Traveling at 60 miles per hour, what is the total driving time, in hours, it will take to transport all of his cattle to higher ground?
Output: 40

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o2-tgsm8k-s30-rFalse
Loading extension module utils...
Time to load utils op: 0.3079090118408203 seconds
Evaluating commonsenseqa :   2%|█                                                       | 1/50 [01:01<49:52, 61.08s/it]Evaluating commonsenseqa :   4%|██▏                                                     | 2/50 [02:01<48:43, 60.91s/it]Evaluating commonsenseqa :   6%|███▎                                                    | 3/50 [03:04<48:12, 61.55s/it]Evaluating commonsenseqa :   8%|████▍                                                   | 4/50 [04:06<47:16, 61.66s/it]Evaluating commonsenseqa :  10%|█████▌                                                  | 5/50 [05:09<46:41, 62.27s/it]Evaluating commonsenseqa :  12%|██████▋                                                 | 6/50 [06:11<45:38, 62.24s/it]Evaluating commonsenseqa :  14%|███████▊                                                | 7/50 [07:12<44:17, 61.80s/it]Evaluating commonsenseqa :  16%|████████▉                                               | 8/50 [08:14<43:13, 61.74s/it]Evaluating commonsenseqa :  18%|██████████                                              | 9/50 [09:15<42:12, 61.77s/it]Evaluating commonsenseqa :  20%|███████████                                            | 10/50 [10:18<41:19, 61.98s/it]Evaluating commonsenseqa :  22%|████████████                                           | 11/50 [11:20<40:23, 62.14s/it]Evaluating commonsenseqa :  24%|█████████████▏                                         | 12/50 [12:23<39:29, 62.35s/it]Evaluating commonsenseqa :  26%|██████████████▎                                        | 13/50 [13:24<38:08, 61.85s/it]Evaluating commonsenseqa :  28%|███████████████▍                                       | 14/50 [14:26<37:12, 62.02s/it]Evaluating commonsenseqa :  30%|████████████████▌                                      | 15/50 [15:31<36:37, 62.80s/it]Evaluating commonsenseqa :  32%|█████████████████▌                                     | 16/50 [16:33<35:32, 62.71s/it]Evaluating commonsenseqa :  34%|██████████████████▋                                    | 17/50 [17:39<34:53, 63.44s/it]Evaluating commonsenseqa :  36%|███████████████████▊                                   | 18/50 [18:41<33:45, 63.29s/it]Evaluating commonsenseqa :  38%|████████████████████▉                                  | 19/50 [19:44<32:31, 62.96s/it]Evaluating commonsenseqa :  40%|██████████████████████                                 | 20/50 [20:46<31:25, 62.86s/it]Evaluating commonsenseqa :  42%|███████████████████████                                | 21/50 [21:46<29:55, 61.90s/it]Evaluating commonsenseqa :  44%|████████████████████████▏                              | 22/50 [22:47<28:44, 61.60s/it]Evaluating commonsenseqa :  46%|█████████████████████████▎                             | 23/50 [23:50<27:56, 62.11s/it]Evaluating commonsenseqa :  48%|██████████████████████████▍                            | 24/50 [24:53<26:58, 62.27s/it]Evaluating commonsenseqa :  50%|███████████████████████████▌                           | 25/50 [25:56<26:01, 62.44s/it]Evaluating commonsenseqa :  52%|████████████████████████████▌                          | 26/50 [26:58<25:00, 62.50s/it]Evaluating commonsenseqa :  54%|█████████████████████████████▋                         | 27/50 [27:59<23:48, 62.11s/it]Evaluating commonsenseqa :  56%|██████████████████████████████▊                        | 28/50 [29:02<22:48, 62.19s/it]Evaluating commonsenseqa :  58%|███████████████████████████████▉                       | 29/50 [30:06<21:55, 62.64s/it]Evaluating commonsenseqa :  60%|█████████████████████████████████                      | 30/50 [31:10<21:01, 63.08s/it]Evaluating commonsenseqa :  62%|██████████████████████████████████                     | 31/50 [32:12<19:56, 62.96s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████▏                   | 32/50 [33:15<18:51, 62.88s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████▎                  | 33/50 [34:17<17:46, 62.74s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████▍                 | 34/50 [35:19<16:39, 62.49s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████▌                | 35/50 [36:22<15:35, 62.39s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████▌               | 36/50 [37:25<14:39, 62.83s/it]Evaluating commonsenseqa :  74%|████████████████████████████████████████▋              | 37/50 [38:27<13:33, 62.54s/it]Evaluating commonsenseqa :  76%|█████████████████████████████████████████▊             | 38/50 [39:30<12:31, 62.61s/it]Evaluating commonsenseqa :  78%|██████████████████████████████████████████▉            | 39/50 [40:32<11:27, 62.51s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████           | 40/50 [41:33<10:18, 61.84s/it]Evaluating commonsenseqa :  82%|█████████████████████████████████████████████          | 41/50 [42:34<09:16, 61.80s/it]Evaluating commonsenseqa :  84%|██████████████████████████████████████████████▏        | 42/50 [43:38<08:17, 62.25s/it]Evaluating commonsenseqa :  86%|███████████████████████████████████████████████▎       | 43/50 [44:40<07:16, 62.32s/it]Evaluating commonsenseqa :  88%|████████████████████████████████████████████████▍      | 44/50 [45:43<06:14, 62.48s/it]Evaluating commonsenseqa :  90%|█████████████████████████████████████████████████▌     | 45/50 [46:43<05:09, 61.88s/it]Evaluating commonsenseqa :  92%|██████████████████████████████████████████████████▌    | 46/50 [47:48<04:11, 62.82s/it]Evaluating commonsenseqa :  94%|███████████████████████████████████████████████████▋   | 47/50 [48:50<03:07, 62.38s/it]Evaluating commonsenseqa :  96%|████████████████████████████████████████████████████▊  | 48/50 [49:52<02:04, 62.36s/it]Evaluating commonsenseqa :  98%|█████████████████████████████████████████████████████▉ | 49/50 [50:54<01:02, 62.23s/it]Evaluating commonsenseqa : 100%|███████████████████████████████████████████████████████| 50/50 [51:57<00:00, 62.54s/it]Evaluating commonsenseqa : 100%|███████████████████████████████████████████████████████| 50/50 [51:57<00:00, 62.35s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.2478} | avg. gen lenth: 356.16
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o3-tgsm8k-s30-rFalse --seed 30 --max-prompt-length 2048 --num-out-domain 3
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-23 14:37:05,697] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o3-tgsm8k-s30-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 3
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o3-tgsm8k-s30-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                         | 0/9741 [00:00<?, ?it/s]  1%|█                                                                            | 138/9741 [00:00<00:06, 1377.82it/s]  3%|██▏                                                                          | 283/9741 [00:00<00:06, 1416.78it/s]  4%|███▍                                                                         | 429/9741 [00:00<00:06, 1434.10it/s]  6%|████▌                                                                        | 576/9741 [00:00<00:06, 1445.78it/s]  7%|█████▋                                                                       | 723/9741 [00:00<00:06, 1452.97it/s]  9%|██████▉                                                                      | 871/9741 [00:00<00:06, 1460.70it/s] 10%|███████▉                                                                    | 1019/9741 [00:00<00:05, 1465.82it/s] 12%|█████████                                                                   | 1167/9741 [00:00<00:05, 1469.87it/s] 13%|██████████▎                                                                 | 1314/9741 [00:00<00:05, 1443.28it/s] 15%|███████████▍                                                                | 1459/9741 [00:01<00:05, 1445.11it/s] 16%|████████████▌                                                               | 1605/9741 [00:01<00:05, 1449.31it/s] 18%|█████████████▋                                                              | 1754/9741 [00:01<00:05, 1459.67it/s] 20%|██████████████▊                                                             | 1901/9741 [00:01<00:05, 1441.71it/s] 21%|███████████████▉                                                            | 2048/9741 [00:01<00:05, 1447.29it/s] 23%|█████████████████▏                                                          | 2195/9741 [00:01<00:05, 1453.04it/s] 24%|██████████████████▎                                                         | 2342/9741 [00:01<00:05, 1456.44it/s] 26%|███████████████████▍                                                        | 2490/9741 [00:01<00:04, 1461.70it/s] 27%|████████████████████▌                                                       | 2638/9741 [00:01<00:04, 1464.95it/s] 29%|█████████████████████▋                                                      | 2785/9741 [00:01<00:04, 1462.20it/s] 30%|██████████████████████▉                                                     | 2932/9741 [00:02<00:04, 1463.64it/s] 32%|████████████████████████                                                    | 3084/9741 [00:02<00:04, 1479.37it/s] 34%|█████████████████████████▊                                                  | 3308/9741 [00:02<00:03, 1705.45it/s] 36%|███████████████████████████▌                                                | 3531/9741 [00:02<00:03, 1860.20it/s] 39%|█████████████████████████████▎                                              | 3755/9741 [00:02<00:03, 1972.41it/s] 41%|███████████████████████████████                                             | 3979/9741 [00:02<00:02, 2051.04it/s] 43%|████████████████████████████████▊                                           | 4203/9741 [00:02<00:02, 2105.76it/s] 45%|██████████████████████████████████▌                                         | 4427/9741 [00:02<00:02, 2145.18it/s] 48%|████████████████████████████████████▏                                       | 4642/9741 [00:02<00:02, 2144.97it/s] 50%|█████████████████████████████████████▉                                      | 4857/9741 [00:02<00:02, 1860.53it/s] 52%|███████████████████████████████████████▋                                    | 5080/9741 [00:03<00:02, 1959.25it/s] 54%|█████████████████████████████████████████▎                                  | 5303/9741 [00:03<00:02, 2033.73it/s] 57%|███████████████████████████████████████████                                 | 5513/9741 [00:03<00:02, 2052.42it/s] 59%|████████████████████████████████████████████▋                               | 5730/9741 [00:03<00:01, 2086.20it/s] 61%|██████████████████████████████████████████████▍                             | 5954/9741 [00:03<00:01, 2131.05it/s] 63%|████████████████████████████████████████████████▏                           | 6178/9741 [00:03<00:01, 2163.11it/s] 66%|█████████████████████████████████████████████████▉                          | 6401/9741 [00:03<00:01, 2182.38it/s] 68%|███████████████████████████████████████████████████▋                        | 6624/9741 [00:03<00:01, 2194.40it/s] 70%|█████████████████████████████████████████████████████▍                      | 6848/9741 [00:03<00:01, 2207.02it/s] 73%|███████████████████████████████████████████████████████▏                    | 7072/9741 [00:03<00:01, 2215.06it/s] 75%|████████████████████████████████████████████████████████▉                   | 7295/9741 [00:04<00:01, 2218.74it/s] 77%|██████████████████████████████████████████████████████████▋                 | 7518/9741 [00:04<00:01, 2189.09it/s] 79%|████████████████████████████████████████████████████████████▍               | 7739/9741 [00:04<00:00, 2193.19it/s] 82%|██████████████████████████████████████████████████████████████              | 7960/9741 [00:04<00:00, 2196.07it/s] 84%|███████████████████████████████████████████████████████████████▊            | 8180/9741 [00:04<00:00, 2173.13it/s] 86%|█████████████████████████████████████████████████████████████████▌          | 8401/9741 [00:04<00:00, 2183.73it/s] 89%|███████████████████████████████████████████████████████████████████▎        | 8622/9741 [00:04<00:00, 2190.26it/s] 91%|████████████████████████████████████████████████████████████████████▉       | 8842/9741 [00:04<00:00, 2181.12it/s] 93%|██████████████████████████████████████████████████████████████████████▋     | 9061/9741 [00:04<00:00, 2162.09it/s] 95%|████████████████████████████████████████████████████████████████████████▍   | 9278/9741 [00:04<00:00, 2115.45it/s] 97%|██████████████████████████████████████████████████████████████████████████  | 9495/9741 [00:05<00:00, 2131.14it/s]100%|███████████████████████████████████████████████████████████████████████████▊| 9714/9741 [00:05<00:00, 2145.78it/s]100%|████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:05<00:00, 1870.54it/s]
Load End
Num instances: 1000
[2023-08-23 14:37:22,168] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-23 14:37:25,196] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-23 14:37:25,196] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-23 14:37:25,196] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-23 14:37:25,196] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-23 14:37:25,196] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-23 14:37:25,196] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fc6915aaa60>
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fc6915aa940>
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-23 14:37:25,197] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-23 14:37:25,198] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-23 14:37:25,198] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-23 14:37:25,198] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-23 14:37:25,198] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-23 14:37:25,198] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-23 14:37:25,198] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-23 14:37:25,198] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-23 14:37:25,198] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4810318946838379 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: The car-rental agency charges $30/day for a car, or $190 for the first week for a rental that lasts an entire week or longer. Jennie rented a car for 11 days. How much, in dollars, did she pay for the rental?
Output: 310

Input: A hurricane is approaching the southern coast of Texas, and a rancher is planning to move 400 head of cattle 60 miles to higher ground to protect them from possible inland flooding that might occur.  His animal transport truck holds 20 head of cattle.  Traveling at 60 miles per hour, what is the total driving time, in hours, it will take to transport all of his cattle to higher ground?
Output: 40

Input: Jason has a carriage house that he rents out.  He’s charging $50.00 per day or $500.00 for 14 days.  Eric wants to rent the house for 20 days.  How much will it cost him?
Output: 800

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o3-tgsm8k-s30-rFalse
Loading extension module utils...
Time to load utils op: 0.404634952545166 seconds
Evaluating commonsenseqa :   2%|█                                                       | 1/50 [01:01<50:04, 61.31s/it]Evaluating commonsenseqa :   4%|██▏                                                     | 2/50 [02:01<48:35, 60.75s/it]Evaluating commonsenseqa :   6%|███▎                                                    | 3/50 [03:02<47:37, 60.80s/it]Evaluating commonsenseqa :   8%|████▍                                                   | 4/50 [04:03<46:39, 60.86s/it]Evaluating commonsenseqa :  10%|█████▌                                                  | 5/50 [05:05<46:01, 61.36s/it]Evaluating commonsenseqa :  12%|██████▋                                                 | 6/50 [06:06<44:53, 61.23s/it]Evaluating commonsenseqa :  14%|███████▊                                                | 7/50 [07:06<43:26, 60.63s/it]Evaluating commonsenseqa :  16%|████████▉                                               | 8/50 [08:06<42:19, 60.47s/it]Evaluating commonsenseqa :  18%|██████████                                              | 9/50 [09:06<41:22, 60.54s/it]Evaluating commonsenseqa :  20%|███████████                                            | 10/50 [10:10<40:53, 61.33s/it]Evaluating commonsenseqa :  22%|████████████                                           | 11/50 [11:11<39:57, 61.49s/it]Evaluating commonsenseqa :  24%|█████████████▏                                         | 12/50 [12:12<38:46, 61.22s/it]Evaluating commonsenseqa :  26%|██████████████▎                                        | 13/50 [13:12<37:26, 60.72s/it]Evaluating commonsenseqa :  28%|███████████████▍                                       | 14/50 [14:13<36:29, 60.81s/it]Evaluating commonsenseqa :  30%|████████████████▌                                      | 15/50 [15:14<35:34, 60.97s/it]Evaluating commonsenseqa :  32%|█████████████████▌                                     | 16/50 [16:15<34:30, 60.91s/it]Evaluating commonsenseqa :  34%|██████████████████▋                                    | 17/50 [17:16<33:37, 61.14s/it]Evaluating commonsenseqa :  36%|███████████████████▊                                   | 18/50 [18:17<32:33, 61.04s/it]Evaluating commonsenseqa :  38%|████████████████████▉                                  | 19/50 [19:17<31:17, 60.58s/it]Evaluating commonsenseqa :  40%|██████████████████████                                 | 20/50 [20:16<30:06, 60.22s/it]Evaluating commonsenseqa :  42%|███████████████████████                                | 21/50 [21:15<28:55, 59.83s/it]Evaluating commonsenseqa :  44%|████████████████████████▏                              | 22/50 [22:15<27:53, 59.76s/it]Evaluating commonsenseqa :  46%|█████████████████████████▎                             | 23/50 [23:14<26:52, 59.73s/it]Evaluating commonsenseqa :  48%|██████████████████████████▍                            | 24/50 [24:17<26:15, 60.59s/it]Evaluating commonsenseqa :  50%|███████████████████████████▌                           | 25/50 [25:18<25:18, 60.75s/it]Evaluating commonsenseqa :  52%|████████████████████████████▌                          | 26/50 [26:20<24:28, 61.18s/it]Evaluating commonsenseqa :  54%|█████████████████████████████▋                         | 27/50 [27:20<23:20, 60.88s/it]Evaluating commonsenseqa :  56%|██████████████████████████████▊                        | 28/50 [28:20<22:10, 60.46s/it]Evaluating commonsenseqa :  58%|███████████████████████████████▉                       | 29/50 [29:20<21:07, 60.36s/it]Evaluating commonsenseqa :  60%|█████████████████████████████████                      | 30/50 [30:22<20:15, 60.75s/it]Evaluating commonsenseqa :  62%|██████████████████████████████████                     | 31/50 [31:20<19:02, 60.15s/it]Evaluating commonsenseqa :  64%|███████████████████████████████████▏                   | 32/50 [32:22<18:13, 60.75s/it]Evaluating commonsenseqa :  66%|████████████████████████████████████▎                  | 33/50 [33:24<17:15, 60.90s/it]Evaluating commonsenseqa :  68%|█████████████████████████████████████▍                 | 34/50 [34:25<16:16, 61.05s/it]Evaluating commonsenseqa :  70%|██████████████████████████████████████▌                | 35/50 [35:26<15:16, 61.10s/it]Evaluating commonsenseqa :  72%|███████████████████████████████████████▌               | 36/50 [36:26<14:10, 60.72s/it]Evaluating commonsenseqa :  74%|████████████████████████████████████████▋              | 37/50 [37:27<13:08, 60.67s/it]Evaluating commonsenseqa :  76%|█████████████████████████████████████████▊             | 38/50 [38:27<12:06, 60.50s/it]Evaluating commonsenseqa :  78%|██████████████████████████████████████████▉            | 39/50 [39:26<11:01, 60.17s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████           | 40/50 [40:26<10:00, 60.09s/it]Evaluating commonsenseqa :  82%|█████████████████████████████████████████████          | 41/50 [41:27<09:03, 60.37s/it]Evaluating commonsenseqa :  84%|██████████████████████████████████████████████▏        | 42/50 [42:29<08:06, 60.81s/it]Evaluating commonsenseqa :  86%|███████████████████████████████████████████████▎       | 43/50 [43:29<07:03, 60.52s/it]Evaluating commonsenseqa :  88%|████████████████████████████████████████████████▍      | 44/50 [44:30<06:03, 60.63s/it]Evaluating commonsenseqa :  90%|█████████████████████████████████████████████████▌     | 45/50 [45:30<05:03, 60.61s/it]Evaluating commonsenseqa :  92%|██████████████████████████████████████████████████▌    | 46/50 [46:30<04:00, 60.24s/it]Evaluating commonsenseqa :  94%|███████████████████████████████████████████████████▋   | 47/50 [47:30<03:00, 60.25s/it]Evaluating commonsenseqa :  96%|████████████████████████████████████████████████████▊  | 48/50 [48:30<02:00, 60.25s/it]Evaluating commonsenseqa :  98%|█████████████████████████████████████████████████████▉ | 49/50 [49:31<01:00, 60.41s/it]Evaluating commonsenseqa : 100%|███████████████████████████████████████████████████████| 50/50 [50:31<00:00, 60.29s/it]Evaluating commonsenseqa : 100%|███████████████████████████████████████████████████████| 50/50 [50:31<00:00, 60.63s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 1.4525} | avg. gen lenth: 353.714
torchrun --nproc_per_node 2 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29500 /home/ylu130/workspace/in-context-generalization/inference.py --model-name opt-1.3b --model-type opt --model-path /scratch/ylu130/model/opt-1.3b --n-gpu 2 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 10 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o4-tgsm8k-s30-rFalse --seed 30 --max-prompt-length 2048 --num-out-domain 4
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 2
[2023-08-23 15:28:05,208] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... opt-1.3b
  model_type ................... opt
  model_path ................... /scratch/ylu130/model/opt-1.3b
  n_gpu ........................ 2
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o4-tgsm8k-s30-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 4
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o4-tgsm8k-s30-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 10
  clip_grad .................... 1.0
  seed ......................... 30
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 2
Loading Data
  0%|                                                                                         | 0/9741 [00:00<?, ?it/s]  2%|█▍                                                                           | 184/9741 [00:00<00:05, 1836.30it/s]  4%|██▉                                                                          | 378/9741 [00:00<00:04, 1896.81it/s]  6%|████▌                                                                        | 574/9741 [00:00<00:04, 1924.20it/s]  8%|██████                                                                       | 771/9741 [00:00<00:04, 1940.17it/s] 10%|███████▋                                                                     | 968/9741 [00:00<00:04, 1949.02it/s] 12%|█████████                                                                   | 1165/9741 [00:00<00:04, 1956.12it/s] 14%|██████████▌                                                                 | 1361/9741 [00:00<00:04, 1955.07it/s] 16%|████████████▏                                                               | 1557/9741 [00:00<00:04, 1955.60it/s] 18%|█████████████▋                                                              | 1754/9741 [00:00<00:04, 1959.08it/s] 20%|███████████████▏                                                            | 1950/9741 [00:01<00:04, 1905.66it/s] 22%|████████████████▋                                                           | 2143/9741 [00:01<00:03, 1912.07it/s] 24%|██████████████████▏                                                         | 2338/9741 [00:01<00:03, 1921.45it/s] 26%|███████████████████▊                                                        | 2533/9741 [00:01<00:03, 1927.33it/s] 28%|█████████████████████▎                                                      | 2727/9741 [00:01<00:03, 1930.05it/s] 30%|██████████████████████▊                                                     | 2921/9741 [00:01<00:03, 1932.65it/s] 32%|████████████████████████▎                                                   | 3116/9741 [00:01<00:03, 1936.62it/s] 34%|█████████████████████████▊                                                  | 3311/9741 [00:01<00:03, 1939.53it/s] 36%|███████████████████████████▎                                                | 3505/9741 [00:01<00:03, 1936.05it/s] 38%|████████████████████████████▊                                               | 3699/9741 [00:01<00:03, 1934.73it/s] 40%|██████████████████████████████▎                                             | 3893/9741 [00:02<00:03, 1931.70it/s] 42%|███████████████████████████████▉                                            | 4087/9741 [00:02<00:02, 1929.76it/s] 44%|█████████████████████████████████▍                                          | 4280/9741 [00:02<00:02, 1926.58it/s] 46%|██████████████████████████████████▉                                         | 4474/9741 [00:02<00:02, 1927.79it/s] 48%|████████████████████████████████████▍                                       | 4667/9741 [00:02<00:02, 1897.55it/s] 50%|█████████████████████████████████████▉                                      | 4857/9741 [00:02<00:03, 1490.48it/s] 52%|███████████████████████████████████████▍                                    | 5048/9741 [00:02<00:02, 1594.20it/s] 54%|████████████████████████████████████████▉                                   | 5239/9741 [00:02<00:02, 1675.99it/s] 56%|██████████████████████████████████████████▎                                 | 5430/9741 [00:02<00:02, 1738.61it/s] 58%|███████████████████████████████████████████▊                                | 5621/9741 [00:03<00:02, 1784.89it/s] 60%|█████████████████████████████████████████████▎                              | 5814/9741 [00:03<00:02, 1824.38it/s] 62%|██████████████████████████████████████████████▊                             | 6005/9741 [00:03<00:02, 1848.21it/s] 64%|████████████████████████████████████████████████▎                           | 6193/9741 [00:03<00:01, 1833.44it/s] 66%|█████████████████████████████████████████████████▊                          | 6383/9741 [00:03<00:01, 1851.13it/s] 67%|███████████████████████████████████████████████████▎                        | 6574/9741 [00:03<00:01, 1865.57it/s] 69%|████████████████████████████████████████████████████▊                       | 6764/9741 [00:03<00:01, 1875.60it/s] 71%|██████████████████████████████████████████████████████▎                     | 6956/9741 [00:03<00:01, 1885.09it/s] 73%|███████████████████████████████████████████████████████▊                    | 7147/9741 [00:03<00:01, 1890.34it/s] 75%|█████████████████████████████████████████████████████████▏                  | 7337/9741 [00:03<00:01, 1890.74it/s] 77%|██████████████████████████████████████████████████████████▋                 | 7527/9741 [00:04<00:01, 1863.00it/s] 79%|████████████████████████████████████████████████████████████▏               | 7717/9741 [00:04<00:01, 1872.82it/s] 81%|█████████████████████████████████████████████████████████████▋              | 7907/9741 [00:04<00:00, 1880.07it/s] 83%|███████████████████████████████████████████████████████████████▏            | 8096/9741 [00:04<00:00, 1882.26it/s] 85%|████████████████████████████████████████████████████████████████▋           | 8285/9741 [00:04<00:00, 1878.77it/s] 87%|██████████████████████████████████████████████████████████████████▏         | 8477/9741 [00:04<00:00, 1888.19it/s] 89%|███████████████████████████████████████████████████████████████████▋        | 8668/9741 [00:04<00:00, 1893.06it/s] 91%|█████████████████████████████████████████████████████████████████████       | 8859/9741 [00:04<00:00, 1897.19it/s] 93%|██████████████████████████████████████████████████████████████████████▌     | 9049/9741 [00:04<00:00, 1897.76it/s] 95%|████████████████████████████████████████████████████████████████████████    | 9239/9741 [00:04<00:00, 1882.13it/s] 97%|█████████████████████████████████████████████████████████████████████████▌  | 9428/9741 [00:05<00:00, 1873.95it/s] 99%|███████████████████████████████████████████████████████████████████████████ | 9616/9741 [00:05<00:00, 1874.61it/s]100%|████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:05<00:00, 1872.50it/s]
Load End
Num instances: 1000
[2023-08-23 15:28:21,322] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-23 15:28:24,827] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-23 15:28:24,827] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-23 15:28:24,827] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fb9ccc1da60>
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fb9ccc1d940>
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-23 15:28:24,828] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-23 15:28:24,829] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-23 15:28:24,829] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-23 15:28:24,829] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-23 15:28:24,829] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-23 15:28:24,829] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-23 15:28:24,829] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-23 15:28:24,829] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-23 15:28:24,829] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-23 15:28:24,829] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-23 15:28:24,829] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-23 15:28:24,829] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-23 15:28:24,829] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-23 15:28:24,829] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  10
[2023-08-23 15:28:24,829] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-23 15:28:24,829] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-23 15:28:24,829] [INFO] [config.py:1012:print]   world_size ................... 2
[2023-08-23 15:28:24,829] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-23 15:28:24,829] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-23 15:28:24,829] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-23 15:28:24,829] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-23 15:28:24,829] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 10, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4713878631591797 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |    2509 MB |    2509 MB |    2509 MB |       0 B  |
|       from large pool |    2508 MB |    2508 MB |    2508 MB |       0 B  |
|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2716 MB |    2716 MB |    2716 MB |       0 B  |
|       from large pool |    2714 MB |    2714 MB |    2714 MB |       0 B  |
|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |  211344 KB |  211384 KB |  605812 KB |  394468 KB |
|       from large pool |  210552 KB |  210552 KB |  603768 KB |  393216 KB |
|       from small pool |     792 KB |    2044 KB |    2044 KB |    1252 KB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     388    |     388    |       0    |
|       from large pool |     146    |     146    |     146    |       0    |
|       from small pool |     242    |     242    |     242    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      99    |      99    |      99    |       0    |
|       from large pool |      98    |      98    |      98    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      51    |      51    |      51    |       0    |
|       from large pool |      50    |      50    |      50    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: The car-rental agency charges $30/day for a car, or $190 for the first week for a rental that lasts an entire week or longer. Jennie rented a car for 11 days. How much, in dollars, did she pay for the rental?
Output: 310

Input: A hurricane is approaching the southern coast of Texas, and a rancher is planning to move 400 head of cattle 60 miles to higher ground to protect them from possible inland flooding that might occur.  His animal transport truck holds 20 head of cattle.  Traveling at 60 miles per hour, what is the total driving time, in hours, it will take to transport all of his cattle to higher ground?
Output: 40

Input: Jason has a carriage house that he rents out.  He’s charging $50.00 per day or $500.00 for 14 days.  Eric wants to rent the house for 20 days.  How much will it cost him?
Output: 800

Input: Melissa works on a poultry farm. She drives to town twice each month to buy supplies. If it takes her 3 hours to drive to town and back, how many hours does Melissa spend driving in a year?
Output: 72

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/opt-1.3b/commonsenseqa/out-domain/o4-tgsm8k-s30-rFalse
Loading extension module utils...
Time to load utils op: 0.4049508571624756 seconds
Evaluating commonsenseqa :   2%|█                                                       | 1/50 [00:59<48:51, 59.83s/it]Evaluating commonsenseqa :   4%|██▏                                                     | 2/50 [01:56<46:17, 57.87s/it]Evaluating commonsenseqa :   6%|███▎                                                    | 3/50 [02:54<45:34, 58.19s/it]Evaluating commonsenseqa :   8%|████▍                                                   | 4/50 [03:52<44:22, 57.89s/it]Evaluating commonsenseqa :  10%|█████▌                                                  | 5/50 [04:49<43:17, 57.71s/it]Evaluating commonsenseqa :  12%|██████▋                                                 | 6/50 [05:47<42:23, 57.82s/it]Evaluating commonsenseqa :  14%|███████▊                                                | 7/50 [06:45<41:22, 57.73s/it]Evaluating commonsenseqa :  16%|████████▉                                               | 8/50 [07:42<40:22, 57.69s/it]Evaluating commonsenseqa :  18%|██████████                                              | 9/50 [08:39<39:17, 57.49s/it]Evaluating commonsenseqa :  20%|███████████                                            | 10/50 [09:39<38:44, 58.10s/it]Evaluating commonsenseqa :  22%|████████████                                           | 11/50 [10:37<37:44, 58.07s/it]Evaluating commonsenseqa :  24%|█████████████▏                                         | 12/50 [11:35<36:44, 58.01s/it]Evaluating commonsenseqa :  26%|██████████████▎                                        | 13/50 [12:33<35:48, 58.05s/it]Evaluating commonsenseqa :  28%|███████████████▍                                       | 14/50 [13:30<34:43, 57.88s/it]Evaluating commonsenseqa :  30%|████████████████▌                                      | 15/50 [14:29<33:52, 58.06s/it]Evaluating commonsenseqa :  32%|█████████████████▌                                     | 16/50 [15:26<32:45, 57.81s/it]Evaluating commonsenseqa :  34%|██████████████████▋                                    | 17/50 [16:25<32:01, 58.22s/it]Evaluating commonsenseqa :  36%|███████████████████▊                                   | 18/50 [17:25<31:13, 58.55s/it]