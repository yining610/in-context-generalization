PYTHONPATH=/home/ylu130/workspace/in-context-generalization
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 2048 --rationales --num-out-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-17 17:28:07,211] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o1-tgsm8k-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 1
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o1-tgsm8k-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                                                                             | 0/9741 [00:00<?, ?it/s]  2%|█▊                                                                                               | 181/9741 [00:00<00:05, 1803.37it/s]  4%|███▌                                                                                             | 364/9741 [00:00<00:05, 1814.56it/s]  6%|█████▍                                                                                           | 548/9741 [00:00<00:05, 1824.57it/s]  8%|███████▎                                                                                         | 731/9741 [00:00<00:04, 1825.71it/s]  9%|█████████                                                                                        | 916/9741 [00:00<00:04, 1833.99it/s] 11%|██████████▊                                                                                     | 1103/9741 [00:00<00:04, 1842.88it/s] 13%|████████████▋                                                                                   | 1288/9741 [00:00<00:04, 1840.87it/s] 15%|██████████████▌                                                                                 | 1473/9741 [00:00<00:04, 1839.50it/s] 17%|████████████████▎                                                                               | 1658/9741 [00:00<00:04, 1839.71it/s] 19%|██████████████████▏                                                                             | 1842/9741 [00:01<00:04, 1820.98it/s] 21%|███████████████████▉                                                                            | 2025/9741 [00:01<00:04, 1823.28it/s] 23%|█████████████████████▊                                                                          | 2208/9741 [00:01<00:04, 1824.94it/s] 25%|███████████████████████▌                                                                        | 2392/9741 [00:01<00:04, 1828.97it/s] 26%|█████████████████████████▍                                                                      | 2576/9741 [00:01<00:03, 1831.27it/s] 28%|███████████████████████████▏                                                                    | 2760/9741 [00:01<00:03, 1829.12it/s] 30%|█████████████████████████████                                                                   | 2944/9741 [00:01<00:03, 1830.22it/s] 32%|██████████████████████████████▊                                                                 | 3129/9741 [00:01<00:03, 1833.79it/s] 34%|████████████████████████████████▋                                                               | 3313/9741 [00:01<00:03, 1835.51it/s] 36%|██████████████████████████████████▍                                                             | 3497/9741 [00:01<00:03, 1833.33it/s] 38%|████████████████████████████████████▎                                                           | 3681/9741 [00:02<00:03, 1831.83it/s] 40%|██████████████████████████████████████                                                          | 3866/9741 [00:02<00:03, 1836.11it/s] 42%|███████████████████████████████████████▉                                                        | 4051/9741 [00:02<00:03, 1839.20it/s] 43%|█████████████████████████████████████████▋                                                      | 4235/9741 [00:02<00:02, 1837.76it/s] 46%|████████████████████████████████████████████▎                                                   | 4501/9741 [00:02<00:02, 2081.92it/s] 49%|██████████████████████████████████████████████▋                                                 | 4740/9741 [00:02<00:02, 1789.53it/s] 52%|█████████████████████████████████████████████████▍                                              | 5017/9741 [00:02<00:02, 2043.59it/s] 54%|████████████████████████████████████████████████████▏                                           | 5296/9741 [00:02<00:01, 2245.54it/s] 57%|███████████████████████████████████████████████████████                                         | 5581/9741 [00:02<00:01, 2413.91it/s] 60%|█████████████████████████████████████████████████████████▉                                      | 5874/9741 [00:02<00:01, 2559.91it/s] 63%|████████████████████████████████████████████████████████████▍                                   | 6138/9741 [00:03<00:01, 2582.49it/s] 66%|███████████████████████████████████████████████████████████████▍                                | 6432/9741 [00:03<00:01, 2686.37it/s] 69%|██████████████████████████████████████████████████████████████████▎                             | 6726/9741 [00:03<00:01, 2759.76it/s] 72%|█████████████████████████████████████████████████████████████████████▏                          | 7021/9741 [00:03<00:00, 2815.78it/s] 75%|████████████████████████████████████████████████████████████████████████                        | 7318/9741 [00:03<00:00, 2859.85it/s] 78%|██████████████████████████████████████████████████████████████████████████▉                     | 7606/9741 [00:03<00:00, 2852.52it/s] 81%|█████████████████████████████████████████████████████████████████████████████▊                  | 7893/9741 [00:03<00:00, 2846.30it/s] 84%|████████████████████████████████████████████████████████████████████████████████▋               | 8186/9741 [00:03<00:00, 2870.74it/s] 87%|███████████████████████████████████████████████████████████████████████████████████▌            | 8481/9741 [00:03<00:00, 2891.52it/s] 90%|██████████████████████████████████████████████████████████████████████████████████████▍         | 8774/9741 [00:03<00:00, 2900.22it/s] 93%|█████████████████████████████████████████████████████████████████████████████████████████▎      | 9066/9741 [00:04<00:00, 2905.56it/s] 96%|████████████████████████████████████████████████████████████████████████████████████████████▎   | 9361/9741 [00:04<00:00, 2916.61it/s] 99%|███████████████████████████████████████████████████████████████████████████████████████████████▏| 9655/9741 [00:04<00:00, 2921.72it/s]100%|████████████████████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:04<00:00, 2255.77it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                                                                     | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                                                     | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                                                     | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                                                     | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|█████████████████████████▋                                                   | 1/3 [00:05<00:10,  5.11s/it]Loading checkpoint shards:  33%|█████████████████████████▋                                                   | 1/3 [00:05<00:10,  5.12s/it]Loading checkpoint shards:  33%|█████████████████████████▋                                                   | 1/3 [00:05<00:10,  5.33s/it]Loading checkpoint shards:  33%|█████████████████████████▋                                                   | 1/3 [00:05<00:11,  5.58s/it]Loading checkpoint shards:  67%|███████████████████████████████████████████████████▎                         | 2/3 [00:10<00:04,  4.99s/it]Loading checkpoint shards:  67%|███████████████████████████████████████████████████▎                         | 2/3 [00:09<00:04,  4.94s/it]Loading checkpoint shards:  67%|███████████████████████████████████████████████████▎                         | 2/3 [00:10<00:05,  5.35s/it]Loading checkpoint shards:  67%|███████████████████████████████████████████████████▎                         | 2/3 [00:10<00:05,  5.40s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.36s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.54s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.32s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.50s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.77s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.92s/it]
[2023-08-17 17:29:03,670] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:15<00:00,  4.90s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.05s/it]
[2023-08-17 17:29:15,851] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-17 17:29:15,852] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-17 17:29:15,852] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-17 17:29:15,852] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-17 17:29:15,852] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-17 17:29:15,852] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-17 17:29:15,853] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-17 17:29:15,853] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-17 17:29:15,853] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-17 17:29:15,853] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-17 17:29:15,853] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-17 17:29:15,853] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7ff230c94280>
[2023-08-17 17:29:15,853] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-17 17:29:15,853] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-17 17:29:15,853] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-17 17:29:15,853] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-17 17:29:15,853] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-17 17:29:15,853] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-17 17:29:15,853] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-17 17:29:15,853] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-17 17:29:15,853] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-17 17:29:15,853] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-17 17:29:15,853] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7ff230c94e20>
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-17 17:29:15,854] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-17 17:29:15,855] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-17 17:29:15,855] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-17 17:29:15,855] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-17 17:29:15,855] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-17 17:29:15,855] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-17 17:29:15,855] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-17 17:29:15,855] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-17 17:29:15,855] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4071958065032959 seconds
Loading extension module utils...
Time to load utils op: 0.3033766746520996 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                                    | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: Mary added a total of 7 stickers/page * 6 pages= <<7*6=42>>42 stickers to the 6 other pages.
In total, Mary added 3 large stickers + 42 stickers = <<3+42=45>>45 stickers to her journal.
Since she started with 89 stickers, she now has 89 - 45 = <<89-45=44>>44 stickers left.
So the final answer is 44

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o1-tgsm8k-s1-rTrue
Loading extension module utils...
Time to load utils op: 0.40453624725341797 seconds
Loading extension module utils...
Time to load utils op: 0.40447449684143066 seconds
Evaluating commonsenseqa :   2%|█▌                                                                          | 1/50 [00:55<45:33, 55.78s/it]Evaluating commonsenseqa :   4%|███                                                                         | 2/50 [01:39<39:03, 48.83s/it]Evaluating commonsenseqa :   6%|████▌                                                                       | 3/50 [02:35<40:48, 52.11s/it]Evaluating commonsenseqa :   8%|██████                                                                      | 4/50 [03:31<41:01, 53.51s/it]Evaluating commonsenseqa :  10%|███████▌                                                                    | 5/50 [04:28<40:58, 54.63s/it]Evaluating commonsenseqa :  12%|█████████                                                                   | 6/50 [05:24<40:29, 55.22s/it]Evaluating commonsenseqa :  14%|██████████▋                                                                 | 7/50 [06:20<39:41, 55.38s/it]Evaluating commonsenseqa :  16%|████████████▏                                                               | 8/50 [07:15<38:47, 55.42s/it]Evaluating commonsenseqa :  18%|█████████████▋                                                              | 9/50 [08:11<38:00, 55.63s/it]Evaluating commonsenseqa :  20%|███████████████                                                            | 10/50 [09:06<36:51, 55.29s/it]Evaluating commonsenseqa :  22%|████████████████▌                                                          | 11/50 [10:01<35:59, 55.38s/it]Evaluating commonsenseqa :  24%|██████████████████                                                         | 12/50 [10:57<35:12, 55.59s/it]Evaluating commonsenseqa :  26%|███████████████████▌                                                       | 13/50 [11:26<29:15, 47.45s/it]Evaluating commonsenseqa :  28%|█████████████████████                                                      | 14/50 [12:21<29:53, 49.82s/it]Evaluating commonsenseqa :  30%|██████████████████████▌                                                    | 15/50 [13:18<30:14, 51.84s/it]Evaluating commonsenseqa :  32%|████████████████████████                                                   | 16/50 [14:13<29:55, 52.81s/it]Evaluating commonsenseqa :  34%|█████████████████████████▌                                                 | 17/50 [15:07<29:18, 53.30s/it]Evaluating commonsenseqa :  36%|███████████████████████████                                                | 18/50 [16:02<28:41, 53.81s/it]Evaluating commonsenseqa :  38%|████████████████████████████▌                                              | 19/50 [16:57<27:53, 53.97s/it]Evaluating commonsenseqa :  40%|██████████████████████████████                                             | 20/50 [17:24<22:56, 45.88s/it]Evaluating commonsenseqa :  42%|███████████████████████████████▌                                           | 21/50 [18:11<22:24, 46.35s/it]Evaluating commonsenseqa :  44%|█████████████████████████████████                                          | 22/50 [19:08<23:05, 49.49s/it]Evaluating commonsenseqa :  46%|██████████████████████████████████▌                                        | 23/50 [20:05<23:15, 51.70s/it]Evaluating commonsenseqa :  48%|████████████████████████████████████                                       | 24/50 [21:00<22:53, 52.82s/it]Evaluating commonsenseqa :  50%|█████████████████████████████████████▌                                     | 25/50 [21:57<22:30, 54.01s/it]Evaluating commonsenseqa :  52%|███████████████████████████████████████                                    | 26/50 [22:52<21:46, 54.42s/it]Evaluating commonsenseqa :  54%|████████████████████████████████████████▌                                  | 27/50 [23:48<20:59, 54.75s/it]Evaluating commonsenseqa :  56%|██████████████████████████████████████████                                 | 28/50 [24:43<20:06, 54.83s/it]Evaluating commonsenseqa :  58%|███████████████████████████████████████████▌                               | 29/50 [25:40<19:22, 55.38s/it]Evaluating commonsenseqa :  60%|█████████████████████████████████████████████                              | 30/50 [26:22<17:06, 51.32s/it]Evaluating commonsenseqa :  62%|██████████████████████████████████████████████▌                            | 31/50 [27:16<16:35, 52.41s/it]Evaluating commonsenseqa :  64%|████████████████████████████████████████████████                           | 32/50 [28:12<15:58, 53.25s/it]Evaluating commonsenseqa :  66%|█████████████████████████████████████████████████▌                         | 33/50 [29:07<15:16, 53.93s/it]Evaluating commonsenseqa :  68%|███████████████████████████████████████████████████                        | 34/50 [30:02<14:26, 54.16s/it]Evaluating commonsenseqa :  70%|████████████████████████████████████████████████████▌                      | 35/50 [30:57<13:34, 54.32s/it]Evaluating commonsenseqa :  72%|██████████████████████████████████████████████████████                     | 36/50 [31:51<12:41, 54.40s/it]Evaluating commonsenseqa :  74%|███████████████████████████████████████████████████████▌                   | 37/50 [32:47<11:53, 54.88s/it]Evaluating commonsenseqa :  76%|█████████████████████████████████████████████████████████                  | 38/50 [33:30<10:14, 51.18s/it]Evaluating commonsenseqa :  78%|██████████████████████████████████████████████████████████▌                | 39/50 [34:20<09:20, 50.97s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████████████████████████               | 40/50 [35:16<08:43, 52.37s/it]Evaluating commonsenseqa :  82%|█████████████████████████████████████████████████████████████▍             | 41/50 [36:12<08:00, 53.37s/it]Evaluating commonsenseqa :  84%|███████████████████████████████████████████████████████████████            | 42/50 [37:06<07:10, 53.78s/it]Evaluating commonsenseqa :  86%|████████████████████████████████████████████████████████████████▌          | 43/50 [38:02<06:21, 54.45s/it]Evaluating commonsenseqa :  88%|██████████████████████████████████████████████████████████████████         | 44/50 [38:57<05:27, 54.64s/it]Evaluating commonsenseqa :  90%|███████████████████████████████████████████████████████████████████▌       | 45/50 [39:53<04:35, 55.06s/it]Evaluating commonsenseqa :  92%|█████████████████████████████████████████████████████████████████████      | 46/50 [40:49<03:41, 55.28s/it]Evaluating commonsenseqa :  94%|██████████████████████████████████████████████████████████████████████▌    | 47/50 [41:46<02:46, 55.62s/it]Evaluating commonsenseqa :  96%|████████████████████████████████████████████████████████████████████████   | 48/50 [42:41<01:51, 55.63s/it]Evaluating commonsenseqa :  98%|█████████████████████████████████████████████████████████████████████████▌ | 49/50 [43:37<00:55, 55.74s/it]Evaluating commonsenseqa : 100%|███████████████████████████████████████████████████████████████████████████| 50/50 [44:33<00:00, 55.65s/it]Evaluating commonsenseqa : 100%|███████████████████████████████████████████████████████████████████████████| 50/50 [44:33<00:00, 53.46s/it]
name: commonsenseqa | {'exact_match': 0.4, 'rougeL': 2.8861} | lm_loss 7.6478 | avg. gen lenth: 315.592
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 29501 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name gsm8k --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s1-rTrue --seed 1 --max-prompt-length 2048 --rationales --num-out-domain 2
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-17 18:14:21,195] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/out-domain/o2-tgsm8k-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 2
  out_domain_data_name ......... gsm8k
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o2-tgsm8k-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                                                                             | 0/9741 [00:00<?, ?it/s]  1%|▊                                                                                                  | 86/9741 [00:00<00:11, 859.55it/s]  2%|█▊                                                                                                | 174/9741 [00:00<00:11, 866.62it/s]  3%|██▋                                                                                               | 261/9741 [00:00<00:11, 861.59it/s]  4%|███▌                                                                                              | 348/9741 [00:00<00:10, 862.40it/s]  4%|████▍                                                                                             | 435/9741 [00:00<00:10, 860.84it/s]  5%|█████▎                                                                                            | 522/9741 [00:00<00:10, 861.57it/s]  6%|██████▏                                                                                           | 609/9741 [00:00<00:10, 860.20it/s]  7%|███████                                                                                           | 696/9741 [00:00<00:10, 861.12it/s]  8%|███████▉                                                                                          | 783/9741 [00:00<00:10, 845.25it/s]  9%|████████▊                                                                                         | 870/9741 [00:01<00:10, 850.20it/s] 10%|█████████▌                                                                                        | 956/9741 [00:01<00:10, 852.85it/s] 11%|██████████▍                                                                                      | 1044/9741 [00:01<00:10, 858.16it/s] 12%|███████████▎                                                                                     | 1131/9741 [00:01<00:10, 860.26it/s] 13%|████████████▏                                                                                    | 1218/9741 [00:01<00:09, 861.47it/s] 13%|████████████▉                                                                                    | 1305/9741 [00:01<00:09, 863.36it/s] 14%|█████████████▊                                                                                   | 1392/9741 [00:01<00:09, 861.51it/s] 15%|██████████████▋                                                                                  | 1479/9741 [00:01<00:09, 863.50it/s] 16%|███████████████▌                                                                                 | 1566/9741 [00:01<00:09, 861.69it/s] 17%|████████████████▍                                                                                | 1653/9741 [00:01<00:09, 857.14it/s] 18%|█████████████████▎                                                                               | 1739/9741 [00:02<00:09, 857.69it/s] 19%|██████████████████▏                                                                              | 1825/9741 [00:02<00:09, 828.81it/s] 20%|███████████████████                                                                              | 1911/9741 [00:02<00:09, 837.30it/s] 21%|███████████████████▉                                                                             | 1997/9741 [00:02<00:09, 842.65it/s] 21%|████████████████████▋                                                                            | 2082/9741 [00:02<00:09, 844.26it/s] 22%|█████████████████████▌                                                                           | 2169/9741 [00:02<00:08, 849.30it/s] 23%|██████████████████████▍                                                                          | 2255/9741 [00:02<00:08, 850.54it/s] 24%|███████████████████████▎                                                                         | 2344/9741 [00:02<00:08, 861.33it/s] 25%|████████████████████████▌                                                                        | 2467/9741 [00:02<00:07, 969.13it/s] 27%|█████████████████████████▌                                                                      | 2598/9741 [00:02<00:06, 1069.79it/s] 28%|██████████████████████████▊                                                                     | 2720/9741 [00:03<00:06, 1113.78it/s] 29%|████████████████████████████                                                                    | 2851/9741 [00:03<00:05, 1171.92it/s] 31%|█████████████████████████████▍                                                                  | 2982/9741 [00:03<00:05, 1210.52it/s] 32%|██████████████████████████████▋                                                                 | 3113/9741 [00:03<00:05, 1240.22it/s] 33%|███████████████████████████████▉                                                                | 3243/9741 [00:03<00:05, 1257.75it/s] 35%|█████████████████████████████████▏                                                              | 3373/9741 [00:03<00:05, 1269.68it/s] 36%|██████████████████████████████████▌                                                             | 3504/9741 [00:03<00:04, 1280.47it/s] 37%|███████████████████████████████████▊                                                            | 3634/9741 [00:03<00:04, 1285.31it/s] 39%|█████████████████████████████████████                                                           | 3765/9741 [00:03<00:04, 1292.10it/s] 40%|██████████████████████████████████████▍                                                         | 3896/9741 [00:03<00:04, 1294.95it/s] 41%|███████████████████████████████████████▋                                                        | 4028/9741 [00:04<00:04, 1299.66it/s] 43%|████████████████████████████████████████▉                                                       | 4158/9741 [00:04<00:04, 1299.67it/s] 44%|██████████████████████████████████████████▎                                                     | 4288/9741 [00:04<00:04, 1299.57it/s] 45%|███████████████████████████████████████████▌                                                    | 4419/9741 [00:04<00:04, 1300.32it/s] 47%|████████████████████████████████████████████▊                                                   | 4550/9741 [00:04<00:04, 1257.02it/s] 48%|██████████████████████████████████████████████▏                                                 | 4681/9741 [00:04<00:03, 1272.17it/s] 49%|███████████████████████████████████████████████▉                                                 | 4809/9741 [00:04<00:05, 961.60it/s] 51%|████████████████████████████████████████████████▋                                               | 4939/9741 [00:04<00:04, 1040.06it/s] 52%|█████████████████████████████████████████████████▉                                              | 5070/9741 [00:04<00:04, 1107.25it/s] 53%|███████████████████████████████████████████████████▏                                            | 5200/9741 [00:05<00:03, 1158.27it/s] 55%|████████████████████████████████████████████████████▌                                           | 5331/9741 [00:05<00:03, 1199.21it/s] 56%|█████████████████████████████████████████████████████▊                                          | 5461/9741 [00:05<00:03, 1226.32it/s] 57%|███████████████████████████████████████████████████████▏                                        | 5597/9741 [00:05<00:03, 1263.00it/s] 59%|████████████████████████████████████████████████████████▍                                       | 5732/9741 [00:05<00:03, 1288.13it/s] 60%|█████████████████████████████████████████████████████████▊                                      | 5868/9741 [00:05<00:02, 1306.51it/s] 62%|███████████████████████████████████████████████████████████▏                                    | 6004/9741 [00:05<00:02, 1322.01it/s] 63%|████████████████████████████████████████████████████████████▍                                   | 6138/9741 [00:05<00:02, 1318.60it/s] 64%|█████████████████████████████████████████████████████████████▊                                  | 6273/9741 [00:05<00:02, 1327.52it/s] 66%|███████████████████████████████████████████████████████████████▏                                | 6407/9741 [00:05<00:02, 1329.54it/s] 67%|████████████████████████████████████████████████████████████████▍                               | 6541/9741 [00:06<00:02, 1330.66it/s] 69%|█████████████████████████████████████████████████████████████████▊                              | 6677/9741 [00:06<00:02, 1337.41it/s] 70%|███████████████████████████████████████████████████████████████████▏                            | 6812/9741 [00:06<00:02, 1338.86it/s] 71%|████████████████████████████████████████████████████████████████████▍                           | 6947/9741 [00:06<00:02, 1342.04it/s] 73%|█████████████████████████████████████████████████████████████████████▊                          | 7082/9741 [00:06<00:01, 1339.76it/s] 74%|███████████████████████████████████████████████████████████████████████▏                        | 7217/9741 [00:06<00:01, 1339.14it/s] 75%|████████████████████████████████████████████████████████████████████████▍                       | 7352/9741 [00:06<00:01, 1339.60it/s] 77%|█████████████████████████████████████████████████████████████████████████▊                      | 7486/9741 [00:06<00:01, 1290.16it/s] 78%|███████████████████████████████████████████████████████████████████████████                     | 7620/9741 [00:06<00:01, 1303.09it/s] 80%|████████████████████████████████████████████████████████████████████████████▍                   | 7754/9741 [00:06<00:01, 1312.85it/s] 81%|█████████████████████████████████████████████████████████████████████████████▋                  | 7886/9741 [00:07<00:01, 1309.24it/s] 82%|███████████████████████████████████████████████████████████████████████████████                 | 8020/9741 [00:07<00:01, 1317.93it/s] 84%|████████████████████████████████████████████████████████████████████████████████▎               | 8155/9741 [00:07<00:01, 1324.49it/s] 85%|█████████████████████████████████████████████████████████████████████████████████▋              | 8290/9741 [00:07<00:01, 1331.28it/s] 86%|███████████████████████████████████████████████████████████████████████████████████             | 8425/9741 [00:07<00:00, 1334.25it/s] 88%|████████████████████████████████████████████████████████████████████████████████████▎           | 8561/9741 [00:07<00:00, 1339.28it/s] 89%|█████████████████████████████████████████████████████████████████████████████████████▋          | 8695/9741 [00:07<00:00, 1337.37it/s] 91%|███████████████████████████████████████████████████████████████████████████████████████         | 8829/9741 [00:07<00:00, 1330.90it/s] 92%|████████████████████████████████████████████████████████████████████████████████████████▎       | 8965/9741 [00:07<00:00, 1336.68it/s] 93%|█████████████████████████████████████████████████████████████████████████████████████████▋      | 9099/9741 [00:08<00:00, 1336.43it/s] 95%|███████████████████████████████████████████████████████████████████████████████████████████     | 9235/9741 [00:08<00:00, 1340.59it/s] 96%|████████████████████████████████████████████████████████████████████████████████████████████▎   | 9370/9741 [00:08<00:00, 1336.86it/s] 98%|█████████████████████████████████████████████████████████████████████████████████████████████▋  | 9504/9741 [00:08<00:00, 1333.10it/s] 99%|██████████████████████████████████████████████████████████████████████████████████████████████▉ | 9638/9741 [00:08<00:00, 1320.66it/s]100%|████████████████████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:08<00:00, 1147.96it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                                                                     | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                                                     | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                                                     | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                                                     | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|█████████████████████████▋                                                   | 1/3 [00:04<00:09,  4.98s/it]Loading checkpoint shards:  33%|█████████████████████████▋                                                   | 1/3 [00:05<00:10,  5.29s/it]Loading checkpoint shards:  33%|█████████████████████████▋                                                   | 1/3 [00:05<00:10,  5.47s/it]Loading checkpoint shards:  33%|█████████████████████████▋                                                   | 1/3 [00:05<00:10,  5.47s/it]Loading checkpoint shards:  67%|███████████████████████████████████████████████████▎                         | 2/3 [00:10<00:05,  5.05s/it]Loading checkpoint shards:  67%|███████████████████████████████████████████████████▎                         | 2/3 [00:10<00:05,  5.32s/it]Loading checkpoint shards:  67%|███████████████████████████████████████████████████▎                         | 2/3 [00:11<00:05,  5.53s/it]Loading checkpoint shards:  67%|███████████████████████████████████████████████████▎                         | 2/3 [00:11<00:05,  5.54s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.39s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.56s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.83s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.96s/it]
[2023-08-17 18:15:21,925] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:15<00:00,  4.84s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.02s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:15<00:00,  4.82s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.01s/it]
[2023-08-17 18:15:31,112] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-17 18:15:31,113] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-17 18:15:31,113] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-17 18:15:31,113] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-17 18:15:31,113] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-17 18:15:31,113] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f7c9ae78e80>
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f7c9ae78dc0>
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-17 18:15:31,114] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-17 18:15:31,115] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-17 18:15:31,115] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-17 18:15:31,115] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-17 18:15:31,115] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-17 18:15:31,115] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-17 18:15:31,115] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-17 18:15:31,115] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-17 18:15:31,115] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-17 18:15:31,115] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-17 18:15:31,115] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-17 18:15:31,115] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-17 18:15:31,115] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-17 18:15:31,115] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-17 18:15:31,115] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-17 18:15:31,115] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-17 18:15:31,115] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-17 18:15:31,115] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-17 18:15:31,115] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-17 18:15:31,115] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-17 18:15:31,115] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4018893241882324 seconds
Loading extension module utils...
Time to load utils op: 0.4044969081878662 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Loading extension module utils...
Loading extension module utils...
Time to load utils op: 0.4043242931365967 seconds
Time to load utils op: 0.30411219596862793 seconds
Evaluating commonsenseqa :   0%|                                                                                    | 0/50 [00:00<?, ?it/s]############### Example ###############
### Instruction:Answer the following multiple choice question.

Input: Mary had 89 stickers.  She used 3 large stickers on the front page of her journal and 7 stickers each to 6 other pages of her journal. How many stickers does Mary have remaining?
Output: Mary added a total of 7 stickers/page * 6 pages= <<7*6=42>>42 stickers to the 6 other pages.
In total, Mary added 3 large stickers + 42 stickers = <<3+42=45>>45 stickers to her journal.
Since she started with 89 stickers, she now has 89 - 45 = <<89-45=44>>44 stickers left.
So the final answer is 44

Input: Zach is saving his money to buy a brand new bike that costs $100.  His weekly allowance is $5.  His parent will pay him an extra $10 to mow the lawn.  His neighbor will pay him $7 per hour to babysit their son.  He has already saved up $65.  He'll receive his allowance on Friday and he's planning on babysitting for 2 hours this Saturday after he mows the lawn.  How much more money does Zach need to earn before he can buy the bike?
Output: If he babysits for 2 hours at $7 per hour, he will earn 2*7 = $<<2*7=14>>14
This week he will earn $5 allowance, $10 mowing the lawn and $14 from babysitting for a total of 5+10+14 = $<<5+10+14=29>>29
If we add the $29 he will earn to his $65 savings, he will have a total of 29 + 65 = $<<29+65=94>>94
The bike costs $100 and he will have $94 leaving $100-$94 = $<<100-94=6>>6 more that he will need to earn
So the final answer is 6

Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/out-domain/o2-tgsm8k-s1-rTrue
