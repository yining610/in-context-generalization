PYTHONPATH=/home/ylu130/workspace/in-context-generalization
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 2 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o1-tcommonsenseqa-s1-rTrue --seed 1 --max-prompt-length 2048 --rationales --num-out-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-17 17:34:28,069] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o1-tcommonsenseqa-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 1
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o1-tcommonsenseqa-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 2
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                                                                             | 0/7473 [00:00<?, ?it/s]  1%|▉                                                                                                  | 68/7473 [00:00<00:10, 676.01it/s]  2%|█▊                                                                                                | 140/7473 [00:00<00:10, 701.63it/s]  3%|██▊                                                                                               | 213/7473 [00:00<00:10, 712.91it/s]  4%|███▋                                                                                              | 285/7473 [00:00<00:10, 713.41it/s]  5%|████▋                                                                                             | 358/7473 [00:00<00:09, 716.24it/s]  6%|█████▋                                                                                            | 430/7473 [00:00<00:09, 715.60it/s]  7%|██████▌                                                                                           | 502/7473 [00:00<00:09, 714.39it/s]  8%|███████▌                                                                                          | 575/7473 [00:00<00:09, 717.89it/s]  9%|████████▍                                                                                         | 647/7473 [00:00<00:09, 704.21it/s] 10%|█████████▍                                                                                        | 720/7473 [00:01<00:09, 710.33it/s] 11%|██████████▍                                                                                       | 793/7473 [00:01<00:09, 713.81it/s] 12%|███████████▎                                                                                      | 866/7473 [00:01<00:09, 715.75it/s] 13%|████████████▎                                                                                     | 938/7473 [00:01<00:09, 715.43it/s] 14%|█████████████                                                                                    | 1011/7473 [00:01<00:08, 719.20it/s] 15%|██████████████                                                                                   | 1085/7473 [00:01<00:08, 722.96it/s] 15%|███████████████                                                                                  | 1158/7473 [00:01<00:08, 719.44it/s] 16%|███████████████▉                                                                                 | 1230/7473 [00:01<00:08, 719.55it/s] 17%|████████████████▉                                                                                | 1303/7473 [00:01<00:08, 720.22it/s] 18%|█████████████████▊                                                                               | 1376/7473 [00:01<00:08, 719.92it/s] 19%|██████████████████▊                                                                              | 1448/7473 [00:02<00:08, 715.22it/s] 20%|███████████████████▋                                                                             | 1521/7473 [00:02<00:08, 719.44it/s] 21%|████████████████████▋                                                                            | 1593/7473 [00:02<00:08, 717.15it/s] 22%|█████████████████████▌                                                                           | 1665/7473 [00:02<00:08, 716.94it/s] 23%|██████████████████████▌                                                                          | 1738/7473 [00:02<00:07, 719.07it/s] 25%|███████████████████████▉                                                                         | 1843/7473 [00:02<00:06, 816.88it/s] 26%|█████████████████████████▎                                                                       | 1952/7473 [00:02<00:06, 897.66it/s] 28%|██████████████████████████▊                                                                      | 2062/7473 [00:02<00:05, 957.27it/s] 29%|████████████████████████████▏                                                                    | 2171/7473 [00:02<00:05, 994.54it/s] 31%|█████████████████████████████▎                                                                  | 2281/7473 [00:02<00:05, 1024.08it/s] 32%|██████████████████████████████▋                                                                 | 2391/7473 [00:03<00:04, 1044.89it/s] 33%|████████████████████████████████▏                                                               | 2503/7473 [00:03<00:04, 1064.01it/s] 35%|█████████████████████████████████▌                                                              | 2610/7473 [00:03<00:04, 1035.79it/s] 36%|██████████████████████████████████▉                                                             | 2721/7473 [00:03<00:04, 1054.95it/s] 38%|████████████████████████████████████▎                                                           | 2831/7473 [00:03<00:04, 1066.65it/s] 39%|█████████████████████████████████████▊                                                          | 2942/7473 [00:03<00:04, 1077.08it/s] 41%|███████████████████████████████████████▏                                                        | 3051/7473 [00:03<00:04, 1080.17it/s] 42%|████████████████████████████████████████▌                                                       | 3160/7473 [00:03<00:04, 1075.84it/s] 44%|█████████████████████████████████████████▉                                                      | 3268/7473 [00:03<00:03, 1056.49it/s] 45%|███████████████████████████████████████████▎                                                    | 3374/7473 [00:03<00:03, 1025.68it/s] 47%|████████████████████████████████████████████▋                                                   | 3481/7473 [00:04<00:03, 1036.83it/s] 48%|██████████████████████████████████████████████                                                  | 3585/7473 [00:04<00:03, 1025.21it/s] 49%|███████████████████████████████████████████████▍                                                | 3693/7473 [00:04<00:03, 1040.70it/s] 51%|████████████████████████████████████████████████▊                                               | 3804/7473 [00:04<00:03, 1059.28it/s] 52%|██████████████████████████████████████████████████▎                                             | 3914/7473 [00:04<00:03, 1069.23it/s] 54%|███████████████████████████████████████████████████▋                                            | 4025/7473 [00:04<00:03, 1078.76it/s] 55%|█████████████████████████████████████████████████████                                           | 4133/7473 [00:04<00:03, 1077.84it/s] 57%|██████████████████████████████████████████████████████▌                                         | 4243/7473 [00:04<00:02, 1082.57it/s] 58%|███████████████████████████████████████████████████████▉                                        | 4352/7473 [00:04<00:02, 1084.18it/s] 60%|█████████████████████████████████████████████████████████▎                                      | 4461/7473 [00:04<00:02, 1085.19it/s] 61%|██████████████████████████████████████████████████████████▋                                     | 4570/7473 [00:05<00:02, 1084.21it/s] 63%|████████████████████████████████████████████████████████████                                    | 4679/7473 [00:05<00:02, 1085.60it/s] 64%|█████████████████████████████████████████████████████████████▌                                  | 4789/7473 [00:05<00:02, 1086.90it/s] 66%|██████████████████████████████████████████████████████████████▉                                 | 4898/7473 [00:05<00:02, 1085.56it/s] 67%|████████████████████████████████████████████████████████████████▎                               | 5008/7473 [00:05<00:02, 1088.05it/s] 68%|█████████████████████████████████████████████████████████████████▋                              | 5117/7473 [00:05<00:02, 1086.85it/s] 70%|███████████████████████████████████████████████████████████████████▏                            | 5226/7473 [00:05<00:02, 1081.23it/s] 71%|█████████████████████████████████████████████████████████████████████▏                           | 5335/7473 [00:05<00:02, 992.38it/s] 73%|█████████████████████████████████████████████████████████████████████▉                          | 5443/7473 [00:05<00:01, 1016.58it/s] 74%|███████████████████████████████████████████████████████████████████████▉                         | 5546/7473 [00:06<00:02, 779.29it/s] 76%|█████████████████████████████████████████████████████████████████████████▍                       | 5656/7473 [00:06<00:02, 855.19it/s] 77%|██████████████████████████████████████████████████████████████████████████▊                      | 5766/7473 [00:06<00:01, 915.07it/s] 79%|████████████████████████████████████████████████████████████████████████████▎                    | 5876/7473 [00:06<00:01, 963.27it/s] 80%|█████████████████████████████████████████████████████████████████████████████▋                   | 5984/7473 [00:06<00:01, 994.21it/s] 82%|██████████████████████████████████████████████████████████████████████████████▎                 | 6095/7473 [00:06<00:01, 1024.22it/s] 83%|███████████████████████████████████████████████████████████████████████████████▋                | 6204/7473 [00:06<00:01, 1042.71it/s] 84%|█████████████████████████████████████████████████████████████████████████████████               | 6314/7473 [00:06<00:01, 1057.27it/s] 86%|██████████████████████████████████████████████████████████████████████████████████▍             | 6422/7473 [00:06<00:00, 1060.91it/s] 87%|███████████████████████████████████████████████████████████████████████████████████▉            | 6532/7473 [00:07<00:00, 1070.94it/s] 89%|█████████████████████████████████████████████████████████████████████████████████████▎          | 6640/7473 [00:07<00:00, 1063.21it/s] 90%|██████████████████████████████████████████████████████████████████████████████████████▋         | 6749/7473 [00:07<00:00, 1068.15it/s] 92%|████████████████████████████████████████████████████████████████████████████████████████        | 6857/7473 [00:07<00:00, 1070.72it/s] 93%|█████████████████████████████████████████████████████████████████████████████████████████▍      | 6967/7473 [00:07<00:00, 1079.28it/s] 95%|██████████████████████████████████████████████████████████████████████████████████████████▉     | 7076/7473 [00:07<00:00, 1081.17it/s] 96%|████████████████████████████████████████████████████████████████████████████████████████████▎   | 7185/7473 [00:07<00:00, 1081.34it/s] 98%|█████████████████████████████████████████████████████████████████████████████████████████████▋  | 7294/7473 [00:07<00:00, 1074.68it/s] 99%|███████████████████████████████████████████████████████████████████████████████████████████████ | 7402/7473 [00:07<00:00, 1023.57it/s]100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 7473/7473 [00:07<00:00, 944.09it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                                                                     | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                                                     | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                                                     | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                                                     | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|█████████████████████████▋                                                   | 1/3 [00:05<00:10,  5.17s/it]Loading checkpoint shards:  33%|█████████████████████████▋                                                   | 1/3 [00:05<00:10,  5.23s/it]Loading checkpoint shards:  33%|█████████████████████████▋                                                   | 1/3 [00:05<00:10,  5.48s/it]Loading checkpoint shards:  33%|█████████████████████████▋                                                   | 1/3 [00:05<00:10,  5.46s/it]Loading checkpoint shards:  67%|███████████████████████████████████████████████████▎                         | 2/3 [00:10<00:05,  5.06s/it]Loading checkpoint shards:  67%|███████████████████████████████████████████████████▎                         | 2/3 [00:10<00:05,  5.07s/it]Loading checkpoint shards:  67%|███████████████████████████████████████████████████▎                         | 2/3 [00:10<00:05,  5.30s/it]Loading checkpoint shards:  67%|███████████████████████████████████████████████████▎                         | 2/3 [00:11<00:05,  5.71s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.46s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.64s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.45s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.63s/it]
[2023-08-17 17:35:27,511] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.66s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.85s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.17s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.29s/it]
[2023-08-17 17:35:42,274] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-17 17:35:42,275] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-17 17:35:42,276] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-17 17:35:42,276] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-17 17:35:42,276] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-17 17:35:42,276] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-17 17:35:42,276] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-17 17:35:42,276] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-17 17:35:42,276] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-17 17:35:42,276] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-17 17:35:42,276] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-17 17:35:42,276] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f3477f5c130>
[2023-08-17 17:35:42,276] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-17 17:35:42,276] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-17 17:35:42,276] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-17 17:35:42,276] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-17 17:35:42,276] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f3477f5c280>
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-17 17:35:42,277] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-17 17:35:42,278] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-17 17:35:42,278] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-17 17:35:42,278] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-17 17:35:42,278] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-17 17:35:42,278] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-17 17:35:42,278] [INFO] [config.py:1012:print]   train_batch_size ............. 8
[2023-08-17 17:35:42,278] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  2
[2023-08-17 17:35:42,278] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-17 17:35:42,278] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-17 17:35:42,278] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-17 17:35:42,278] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-17 17:35:42,278] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-17 17:35:42,278] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-17 17:35:42,278] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-17 17:35:42,278] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 2, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.44365453720092773 seconds
Loading extension module utils...
Time to load utils op: 0.4045438766479492 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Loading extension module utils...
Time to load utils op: 0.5046966075897217 seconds
Evaluating gsm8k :   0%|                                                                                           | 0/125 [00:00<?, ?it/s]############### Example ###############
Loading extension module utils...
### Instruction:Answer the following grade math question.

Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Output: 1. The question is asking where one might find plumbing that wouldn't be useful to a thirsty person. This is equivalent to asking, "Where might you find plumbing that doesn't contain drinkable water?"
2. Answer choice A: oil refineries. Oil refineries have plumbing systems, but these are used to transport oil, not water. Thus, the plumbing in oil refineries would not be useful to someone who is thirsty since its primary function is to move around oil.
3. Answer choice B: wall. Plumbing can be found within the walls of structures, particularly for water supply and waste water evacuation, which hosts drinkable water.
4. Answer choice C: show. This choice is less clear, depends on what kind of show is it about. But usually shows, if they have some plumbing on stage, it will be functional as appearances, not for practical use.
5. Answer choice D: own home. Home plumbing serves functions such as providing water for cooking, cleaning, and most importantly, drinking. Therefore, the plumbing in one's own home would be useful to someone who is thirsty.
6. Answer choice E: water fountain. Public water fountains are also a source of drinkable water.
7. Thus, the plumbing system that would not be useful if one is thirsty is found at an oil refinery because its function is to transport oil, not drinkable water. Therefore, the answer is A: oil refineries.
So the final answer is A: oil refineries

Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?
Output:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o1-tcommonsenseqa-s1-rTrue
Time to load utils op: 0.40455055236816406 seconds
Evaluating gsm8k :   1%|▋                                                                                  | 1/125 [00:28<59:03, 28.57s/it]Evaluating gsm8k :   2%|█▎                                                                                 | 2/125 [00:37<35:20, 17.24s/it]Evaluating gsm8k :   2%|█▉                                                                                 | 3/125 [01:04<44:13, 21.75s/it]Evaluating gsm8k :   3%|██▋                                                                                | 4/125 [01:14<34:05, 16.91s/it]Evaluating gsm8k :   4%|███▎                                                                               | 5/125 [01:41<41:08, 20.57s/it]Evaluating gsm8k :   5%|███▉                                                                               | 6/125 [01:57<37:40, 19.00s/it]Evaluating gsm8k :   6%|████▋                                                                              | 7/125 [02:24<42:33, 21.64s/it]Evaluating gsm8k :   6%|█████▎                                                                             | 8/125 [02:35<35:50, 18.38s/it]Evaluating gsm8k :   7%|█████▉                                                                             | 9/125 [03:03<40:56, 21.18s/it]Evaluating gsm8k :   8%|██████▌                                                                           | 10/125 [03:22<39:07, 20.42s/it]Evaluating gsm8k :   9%|███████▏                                                                          | 11/125 [03:45<40:37, 21.38s/it]Evaluating gsm8k :  10%|███████▊                                                                          | 12/125 [03:53<32:24, 17.21s/it]Evaluating gsm8k :  10%|████████▌                                                                         | 13/125 [04:17<36:06, 19.35s/it]Evaluating gsm8k :  11%|█████████▏                                                                        | 14/125 [04:44<40:06, 21.68s/it]Evaluating gsm8k :  12%|█████████▊                                                                        | 15/125 [05:12<42:59, 23.45s/it]Evaluating gsm8k :  13%|██████████▍                                                                       | 16/125 [05:21<35:09, 19.35s/it]Evaluating gsm8k :  14%|███████████▏                                                                      | 17/125 [05:49<39:03, 21.70s/it]Evaluating gsm8k :  14%|███████████▊                                                                      | 18/125 [06:11<39:03, 21.90s/it]Evaluating gsm8k :  15%|████████████▍                                                                     | 19/125 [06:38<41:29, 23.49s/it]Evaluating gsm8k :  16%|█████████████                                                                     | 20/125 [07:06<43:21, 24.78s/it]Evaluating gsm8k :  17%|█████████████▊                                                                    | 21/125 [07:22<38:16, 22.09s/it]Evaluating gsm8k :  18%|██████████████▍                                                                   | 22/125 [07:45<38:33, 22.46s/it]Evaluating gsm8k :  18%|███████████████                                                                   | 23/125 [08:13<40:51, 24.03s/it]