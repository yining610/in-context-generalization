PYTHONPATH=/home/ylu130/workspace/in-context-generalization
torchrun --nproc_per_node 5 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 5 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-out-domain 0 --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 4 --seed 42 --data-dir /scratch/ylu130/processed_data/commonsenseqa/in-domain/i0-s42-rTrue --rationales --num-in-domain 0
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 5
[2023-08-08 13:16:16,280] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 5
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/in-domain/i0-s42-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 0
  out_domain_data_name ......... None
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i0-s42-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 4
  clip_grad .................... 1.0
  seed ......................... 42
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 5
Loading Data
  0%|                                                                                    | 0/9741 [00:00<?, ?it/s]  3%|██▏                                                                     | 295/9741 [00:00<00:03, 2947.77it/s]  6%|████▌                                                                   | 610/9741 [00:00<00:02, 3061.45it/s] 10%|██████▊                                                                 | 926/9741 [00:00<00:02, 3106.09it/s] 13%|█████████                                                              | 1244/9741 [00:00<00:02, 3134.97it/s] 16%|███████████▎                                                           | 1559/9741 [00:00<00:02, 3138.13it/s] 19%|█████████████▋                                                         | 1873/9741 [00:00<00:02, 2955.52it/s] 22%|███████████████▉                                                       | 2182/9741 [00:00<00:02, 2995.70it/s] 26%|██████████████████▏                                                    | 2494/9741 [00:00<00:02, 3033.36it/s] 29%|████████████████████▍                                                  | 2804/9741 [00:00<00:02, 3052.08it/s] 32%|██████████████████████▋                                                | 3116/9741 [00:01<00:02, 3071.82it/s] 35%|████████████████████████▉                                              | 3426/9741 [00:01<00:02, 3080.24it/s] 38%|███████████████████████████▏                                           | 3736/9741 [00:01<00:01, 3084.59it/s] 42%|█████████████████████████████▌                                         | 4049/9741 [00:01<00:01, 3097.72it/s] 45%|███████████████████████████████▊                                       | 4360/9741 [00:01<00:01, 3098.90it/s] 48%|██████████████████████████████████                                     | 4671/9741 [00:01<00:01, 3051.73it/s] 51%|████████████████████████████████████▎                                  | 4977/9741 [00:01<00:02, 2028.97it/s] 54%|██████████████████████████████████████▌                                | 5285/9741 [00:01<00:01, 2259.03it/s] 57%|████████████████████████████████████████▊                              | 5601/9741 [00:01<00:01, 2473.12it/s] 61%|███████████████████████████████████████████▏                           | 5929/9741 [00:02<00:01, 2676.92it/s] 64%|█████████████████████████████████████████████▌                         | 6259/9741 [00:02<00:01, 2840.83it/s] 68%|████████████████████████████████████████████████                       | 6595/9741 [00:02<00:01, 2981.35it/s] 71%|██████████████████████████████████████████████████▌                    | 6937/9741 [00:02<00:00, 3105.09it/s] 75%|█████████████████████████████████████████████████████▌                 | 7348/9741 [00:02<00:00, 3392.06it/s] 80%|█████████████████████████████████████████████████████████▏             | 7839/9741 [00:02<00:00, 3832.28it/s] 86%|████████████████████████████████████████████████████████████▉          | 8360/9741 [00:02<00:00, 4234.95it/s] 91%|████████████████████████████████████████████████████████████████▋      | 8880/9741 [00:02<00:00, 4519.33it/s] 97%|████████████████████████████████████████████████████████████████████▌  | 9403/9741 [00:02<00:00, 4728.34it/s]100%|███████████████████████████████████████████████████████████████████████| 9741/9741 [00:02<00:00, 3287.76it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:10,  5.08s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:10,  5.29s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:10,  5.27s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:11,  5.68s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:06<00:13,  6.92s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:09<00:04,  4.95s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:10<00:05,  5.28s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:10<00:05,  5.34s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:11<00:05,  5.61s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.31s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.50s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.63s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.81s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.77s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.92s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.01s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.18s/it]
[2023-08-08 13:17:12,423] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:14<00:07,  7.02s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:18<00:00,  6.01s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:18<00:00,  6.27s/it]
[2023-08-08 13:17:31,898] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-08 13:17:31,899] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-08 13:17:31,900] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-08 13:17:31,900] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-08 13:17:31,900] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-08 13:17:31,900] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-08 13:17:31,901] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-08 13:17:31,901] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-08 13:17:31,901] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-08 13:17:31,901] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-08 13:17:31,901] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-08 13:17:31,901] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fad737e7f40>
[2023-08-08 13:17:31,901] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-08 13:17:31,901] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-08 13:17:31,901] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-08 13:17:31,901] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-08 13:17:31,901] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-08 13:17:31,901] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-08 13:17:31,901] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-08 13:17:31,901] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-08 13:17:31,901] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-08 13:17:31,901] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-08 13:17:31,901] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-08 13:17:31,901] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-08 13:17:31,901] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-08 13:17:31,901] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-08 13:17:31,901] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-08 13:17:31,901] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-08 13:17:31,901] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-08 13:17:31,901] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-08 13:17:31,901] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fad784f2dc0>
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  4
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   world_size ................... 5
[2023-08-08 13:17:31,902] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-08 13:17:31,903] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-08 13:17:31,903] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-08 13:17:31,903] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-08 13:17:31,903] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 4, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.3464059829711914 seconds
Loading extension module utils...
Time to load utils op: 0.30490779876708984 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                           | 0/50 [00:00<?, ?it/s]############### Example ###############
Loading extension module utils...
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following multiple choice question.

### Demonstration:


### Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i0-s42-rTrue
Time to load utils op: 0.3049900531768799 seconds
Loading extension module utils...
Time to load utils op: 0.30549144744873047 seconds
Loading extension module utils...
Time to load utils op: 0.40491223335266113 seconds
Evaluating commonsenseqa :   2%|█                                                  | 1/50 [00:11<09:09, 11.21s/it]Evaluating commonsenseqa :   4%|██                                                 | 2/50 [00:44<19:32, 24.43s/it]Evaluating commonsenseqa :   6%|███                                                | 3/50 [01:27<25:44, 32.86s/it]Evaluating commonsenseqa :   8%|████                                               | 4/50 [02:18<30:36, 39.93s/it]Evaluating commonsenseqa :  10%|█████                                              | 5/50 [02:30<22:23, 29.85s/it]Evaluating commonsenseqa :  12%|██████                                             | 6/50 [02:54<20:21, 27.77s/it]Evaluating commonsenseqa :  14%|███████▏                                           | 7/50 [03:18<19:07, 26.68s/it]Evaluating commonsenseqa :  16%|████████▏                                          | 8/50 [04:08<23:50, 34.06s/it]Evaluating commonsenseqa :  18%|█████████▏                                         | 9/50 [04:39<22:31, 32.97s/it]Evaluating commonsenseqa :  20%|██████████                                        | 10/50 [05:10<21:41, 32.53s/it]Evaluating commonsenseqa :  22%|███████████                                       | 11/50 [05:22<17:00, 26.16s/it]Evaluating commonsenseqa :  24%|████████████                                      | 12/50 [05:41<15:09, 23.93s/it]Evaluating commonsenseqa :  26%|█████████████                                     | 13/50 [06:14<16:25, 26.64s/it]Evaluating commonsenseqa :  28%|██████████████                                    | 14/50 [07:01<19:47, 32.99s/it]Evaluating commonsenseqa :  30%|███████████████                                   | 15/50 [07:35<19:24, 33.28s/it]Evaluating commonsenseqa :  32%|████████████████                                  | 16/50 [08:08<18:49, 33.23s/it]Evaluating commonsenseqa :  34%|█████████████████                                 | 17/50 [08:20<14:41, 26.70s/it]Evaluating commonsenseqa :  36%|██████████████████                                | 18/50 [08:47<14:21, 26.92s/it]Evaluating commonsenseqa :  38%|███████████████████                               | 19/50 [09:00<11:38, 22.52s/it]Evaluating commonsenseqa :  40%|████████████████████                              | 20/50 [09:49<15:20, 30.69s/it]Evaluating commonsenseqa :  42%|█████████████████████                             | 21/50 [09:58<11:40, 24.14s/it]Evaluating commonsenseqa :  44%|██████████████████████                            | 22/50 [10:11<09:37, 20.63s/it]Evaluating commonsenseqa :  46%|███████████████████████                           | 23/50 [10:39<10:21, 23.02s/it]Evaluating commonsenseqa :  48%|████████████████████████                          | 24/50 [11:05<10:20, 23.87s/it]Evaluating commonsenseqa :  50%|█████████████████████████                         | 25/50 [11:19<08:41, 20.88s/it]Evaluating commonsenseqa :  52%|██████████████████████████                        | 26/50 [11:45<08:55, 22.30s/it]Evaluating commonsenseqa :  54%|███████████████████████████                       | 27/50 [12:34<11:39, 30.42s/it]Evaluating commonsenseqa :  56%|████████████████████████████                      | 28/50 [13:24<13:21, 36.45s/it]Evaluating commonsenseqa :  58%|████████████████████████████▉                     | 29/50 [13:47<11:20, 32.43s/it]Evaluating commonsenseqa :  60%|██████████████████████████████                    | 30/50 [14:12<09:58, 29.93s/it]Evaluating commonsenseqa :  62%|███████████████████████████████                   | 31/50 [14:36<08:56, 28.22s/it]Evaluating commonsenseqa :  64%|████████████████████████████████                  | 32/50 [15:08<08:48, 29.38s/it]Evaluating commonsenseqa :  66%|█████████████████████████████████                 | 33/50 [15:58<10:03, 35.51s/it]Evaluating commonsenseqa :  68%|██████████████████████████████████                | 34/50 [16:48<10:36, 39.80s/it]Evaluating commonsenseqa :  70%|███████████████████████████████████               | 35/50 [17:31<10:15, 41.03s/it]Evaluating commonsenseqa :  72%|████████████████████████████████████              | 36/50 [17:46<07:44, 33.19s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████             | 37/50 [18:24<07:29, 34.61s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████            | 38/50 [19:15<07:51, 39.32s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████           | 39/50 [19:35<06:08, 33.54s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████          | 40/50 [20:01<05:12, 31.28s/it]Evaluating commonsenseqa :  82%|█████████████████████████████████████████         | 41/50 [20:44<05:13, 34.81s/it]Evaluating commonsenseqa :  84%|██████████████████████████████████████████        | 42/50 [21:33<05:12, 39.04s/it]Evaluating commonsenseqa :  86%|███████████████████████████████████████████       | 43/50 [21:44<03:36, 30.88s/it]Evaluating commonsenseqa :  88%|████████████████████████████████████████████      | 44/50 [21:54<02:27, 24.59s/it]Evaluating commonsenseqa :  90%|█████████████████████████████████████████████     | 45/50 [22:26<02:13, 26.66s/it]Evaluating commonsenseqa :  92%|██████████████████████████████████████████████    | 46/50 [22:35<01:25, 21.27s/it]Evaluating commonsenseqa :  94%|███████████████████████████████████████████████   | 47/50 [22:57<01:04, 21.51s/it]Evaluating commonsenseqa :  96%|████████████████████████████████████████████████  | 48/50 [23:19<00:43, 21.74s/it]Evaluating commonsenseqa :  98%|█████████████████████████████████████████████████ | 49/50 [23:28<00:17, 17.81s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████████████████████| 50/50 [24:18<00:00, 27.62s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████████████████████| 50/50 [24:18<00:00, 29.17s/it]
name: commonsenseqa | {'exact_match': 0.5, 'rougeL': 3.1633} | lm_loss 7.4806 | avg. gen lenth: 119.735
torchrun --nproc_per_node 5 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 5 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-out-domain 0 --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 4 --seed 42 --data-dir /scratch/ylu130/processed_data/commonsenseqa/in-domain/i1-s42-rTrue --rationales --num-in-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 5
[2023-08-08 13:43:29,276] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 5
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/in-domain/i1-s42-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 1
  num_out_domain ............... 0
  out_domain_data_name ......... None
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i1-s42-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 4
  clip_grad .................... 1.0
  seed ......................... 42
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 5
Loading Data
  0%|                                                                                    | 0/9740 [00:00<?, ?it/s]  1%|▌                                                                         | 78/9740 [00:00<00:12, 771.95it/s]  2%|█▏                                                                       | 157/9740 [00:00<00:12, 779.48it/s]  2%|█▊                                                                       | 235/9740 [00:00<00:12, 777.83it/s]  3%|██▎                                                                      | 314/9740 [00:00<00:12, 780.26it/s]  4%|██▉                                                                      | 393/9740 [00:00<00:12, 758.93it/s]  5%|███▌                                                                     | 469/9740 [00:00<00:12, 758.08it/s]  6%|████                                                                     | 548/9740 [00:00<00:12, 765.73it/s]  6%|████▋                                                                    | 626/9740 [00:00<00:11, 770.14it/s]  7%|█████▎                                                                   | 705/9740 [00:00<00:11, 773.30it/s]  8%|█████▉                                                                   | 784/9740 [00:01<00:11, 777.31it/s]  9%|██████▍                                                                  | 863/9740 [00:01<00:11, 780.99it/s] 10%|███████                                                                  | 942/9740 [00:01<00:11, 779.49it/s] 10%|███████▌                                                                | 1020/9740 [00:01<00:11, 778.88it/s] 11%|████████                                                                | 1099/9740 [00:01<00:11, 781.90it/s] 12%|████████▋                                                               | 1178/9740 [00:01<00:10, 781.09it/s] 13%|█████████▎                                                              | 1257/9740 [00:01<00:10, 777.37it/s] 14%|█████████▊                                                              | 1335/9740 [00:01<00:10, 775.64it/s] 15%|██████████▍                                                             | 1414/9740 [00:01<00:10, 778.07it/s] 15%|███████████                                                             | 1493/9740 [00:01<00:10, 778.93it/s] 16%|███████████▌                                                            | 1571/9740 [00:02<00:10, 778.20it/s] 17%|████████████▏                                                           | 1650/9740 [00:02<00:10, 778.86it/s] 18%|████████████▊                                                           | 1729/9740 [00:02<00:10, 780.68it/s] 19%|█████████████▎                                                          | 1808/9740 [00:02<00:10, 772.56it/s] 19%|█████████████▉                                                          | 1890/9740 [00:02<00:10, 784.74it/s] 20%|██████████████▌                                                         | 1972/9740 [00:02<00:09, 794.11it/s] 21%|███████████████▏                                                        | 2054/9740 [00:02<00:09, 799.83it/s] 22%|████████████████                                                        | 2167/9740 [00:02<00:08, 897.03it/s] 24%|████████████████▉                                                       | 2291/9740 [00:02<00:07, 997.96it/s] 25%|█████████████████▌                                                     | 2415/9740 [00:02<00:06, 1069.56it/s] 26%|██████████████████▌                                                    | 2538/9740 [00:03<00:06, 1115.82it/s] 27%|███████████████████▍                                                   | 2662/9740 [00:03<00:06, 1152.76it/s] 29%|████████████████████▎                                                  | 2785/9740 [00:03<00:05, 1173.90it/s] 30%|█████████████████████▏                                                 | 2909/9740 [00:03<00:05, 1193.62it/s] 31%|██████████████████████                                                 | 3034/9740 [00:03<00:05, 1207.36it/s] 32%|███████████████████████                                                | 3159/9740 [00:03<00:05, 1218.91it/s] 34%|███████████████████████▉                                               | 3286/9740 [00:03<00:05, 1232.19it/s] 35%|████████████████████████▊                                              | 3412/9740 [00:03<00:05, 1238.35it/s] 36%|█████████████████████████▊                                             | 3538/9740 [00:03<00:04, 1241.92it/s] 38%|██████████████████████████▋                                            | 3663/9740 [00:03<00:04, 1244.04it/s] 39%|███████████████████████████▋                                           | 3790/9740 [00:04<00:04, 1251.21it/s] 40%|████████████████████████████▌                                          | 3916/9740 [00:04<00:04, 1251.65it/s] 41%|█████████████████████████████▍                                         | 4042/9740 [00:04<00:04, 1245.08it/s] 43%|██████████████████████████████▍                                        | 4167/9740 [00:04<00:04, 1245.62it/s] 44%|███████████████████████████████▎                                       | 4292/9740 [00:04<00:04, 1246.27it/s] 45%|████████████████████████████████▏                                      | 4419/9740 [00:04<00:04, 1250.68it/s] 47%|█████████████████████████████████▏                                     | 4545/9740 [00:04<00:04, 1217.33it/s] 48%|██████████████████████████████████                                     | 4671/9740 [00:04<00:04, 1228.59it/s] 49%|███████████████████████████████████▍                                    | 4795/9740 [00:04<00:05, 947.85it/s] 51%|███████████████████████████████████▊                                   | 4921/9740 [00:05<00:04, 1024.14it/s] 52%|████████████████████████████████████▊                                  | 5047/9740 [00:05<00:04, 1084.27it/s] 53%|█████████████████████████████████████▋                                 | 5173/9740 [00:05<00:04, 1129.67it/s] 54%|██████████████████████████████████████▋                                | 5299/9740 [00:05<00:03, 1165.29it/s] 56%|███████████████████████████████████████▌                               | 5425/9740 [00:05<00:03, 1190.68it/s] 57%|████████████████████████████████████████▍                              | 5551/9740 [00:05<00:03, 1208.92it/s] 58%|█████████████████████████████████████████▍                             | 5680/9740 [00:05<00:03, 1231.65it/s] 60%|██████████████████████████████████████████▎                            | 5812/9740 [00:05<00:03, 1255.49it/s] 61%|███████████████████████████████████████████▎                           | 5943/9740 [00:05<00:02, 1269.68it/s] 62%|████████████████████████████████████████████▎                          | 6075/9740 [00:05<00:02, 1281.70it/s] 64%|█████████████████████████████████████████████▏                         | 6207/9740 [00:06<00:02, 1291.46it/s] 65%|██████████████████████████████████████████████▏                        | 6338/9740 [00:06<00:02, 1294.69it/s] 66%|███████████████████████████████████████████████▏                       | 6470/9740 [00:06<00:02, 1299.98it/s] 68%|████████████████████████████████████████████████                       | 6601/9740 [00:06<00:02, 1300.14it/s] 69%|█████████████████████████████████████████████████                      | 6733/9740 [00:06<00:02, 1304.61it/s] 70%|██████████████████████████████████████████████████                     | 6865/9740 [00:06<00:02, 1306.86it/s] 72%|██████████████████████████████████████████████████▉                    | 6996/9740 [00:06<00:02, 1306.21it/s] 73%|███████████████████████████████████████████████████▉                   | 7127/9740 [00:06<00:02, 1306.05it/s] 75%|████████████████████████████████████████████████████▉                  | 7258/9740 [00:06<00:01, 1294.71it/s] 76%|█████████████████████████████████████████████████████▊                 | 7390/9740 [00:06<00:01, 1300.41it/s] 77%|██████████████████████████████████████████████████████▊                | 7521/9740 [00:07<00:01, 1266.11it/s] 79%|███████████████████████████████████████████████████████▊               | 7652/9740 [00:07<00:01, 1278.79it/s] 80%|████████████████████████████████████████████████████████▋              | 7783/9740 [00:07<00:01, 1287.04it/s] 81%|█████████████████████████████████████████████████████████▋             | 7914/9740 [00:07<00:01, 1292.83it/s] 83%|██████████████████████████████████████████████████████████▋            | 8045/9740 [00:07<00:01, 1297.69it/s] 84%|███████████████████████████████████████████████████████████▌           | 8176/9740 [00:07<00:01, 1300.86it/s] 85%|████████████████████████████████████████████████████████████▌          | 8308/9740 [00:07<00:01, 1303.63it/s] 87%|█████████████████████████████████████████████████████████████▌         | 8439/9740 [00:07<00:00, 1305.43it/s] 88%|██████████████████████████████████████████████████████████████▍        | 8570/9740 [00:07<00:00, 1305.23it/s] 89%|███████████████████████████████████████████████████████████████▍       | 8701/9740 [00:07<00:00, 1304.84it/s] 91%|████████████████████████████████████████████████████████████████▍      | 8832/9740 [00:08<00:00, 1304.21it/s] 92%|█████████████████████████████████████████████████████████████████▎     | 8964/9740 [00:08<00:00, 1306.00it/s] 93%|██████████████████████████████████████████████████████████████████▎    | 9095/9740 [00:08<00:00, 1305.70it/s] 95%|███████████████████████████████████████████████████████████████████▎   | 9227/9740 [00:08<00:00, 1307.90it/s] 96%|████████████████████████████████████████████████████████████████████▏  | 9358/9740 [00:08<00:00, 1307.37it/s] 97%|█████████████████████████████████████████████████████████████████████▏ | 9489/9740 [00:08<00:00, 1300.17it/s] 99%|██████████████████████████████████████████████████████████████████████▏| 9620/9740 [00:08<00:00, 1300.70it/s]100%|███████████████████████████████████████████████████████████████████████| 9740/9740 [00:08<00:00, 1109.53it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:04<00:09,  4.94s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:10,  5.35s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:10,  5.44s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:11,  5.98s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:11,  5.82s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:09<00:04,  4.82s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:10<00:05,  5.21s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:11<00:05,  5.53s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:11<00:05,  5.87s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.19s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.37s/it]
Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:12<00:06,  6.43s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.62s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.79s/it]
[2023-08-08 13:44:29,676] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:15<00:00,  4.87s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.04s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:16<00:00,  5.26s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:16<00:00,  5.44s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:17<00:00,  5.76s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:17<00:00,  5.88s/it]
[2023-08-08 13:44:50,048] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-08 13:44:50,049] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-08 13:44:50,050] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-08 13:44:50,050] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-08 13:44:50,050] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-08 13:44:50,050] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f92c67d6f40>
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-08 13:44:50,051] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-08 13:44:50,052] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-08 13:44:50,052] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-08 13:44:50,052] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-08 13:44:50,052] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-08 13:44:50,052] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-08 13:44:50,052] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f92c62d3dc0>
[2023-08-08 13:44:50,052] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-08 13:44:50,052] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-08 13:44:50,052] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-08 13:44:50,052] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-08 13:44:50,052] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-08 13:44:50,052] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-08 13:44:50,052] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-08 13:44:50,052] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-08 13:44:50,052] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-08 13:44:50,052] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-08 13:44:50,052] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-08 13:44:50,052] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-08 13:44:50,052] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-08 13:44:50,052] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-08 13:44:50,052] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  4
[2023-08-08 13:44:50,052] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-08 13:44:50,052] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-08 13:44:50,052] [INFO] [config.py:1012:print]   world_size ................... 5
[2023-08-08 13:44:50,052] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-08 13:44:50,052] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-08 13:44:50,052] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-08 13:44:50,052] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-08 13:44:50,052] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 4, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Loading extension module utils...
Time to load utils op: 0.44048333168029785 seconds
Time to load utils op: 0.30475616455078125 seconds
Loading extension module utils...
Time to load utils op: 0.40451908111572266 seconds
Loading extension module utils...
Time to load utils op: 0.40485668182373047 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                           | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following multiple choice question.

### Demonstration:
Input: He fantasied about getting a what while driving to work and the pros and cons of the extra responsibilities and benefits? Choices:  A: new car B: promotion C: boredom D: impatience E: pressure
Rationales: 1. The question tells us that the subject is fantasizing about something while driving to work. This suggests that whatever they are fantasizing about is future-oriented and probably related to their job or work life.
2. The phrase "pros and cons of the extra responsibilities and benefits" also provides a substantial hint. We can analyze it piece by piece:
    - "extra responsibilities" suggests an increase in the level of accountability or tasks, what would not arise from getting a new car, experiencing boredom, impatience, or pressure.
    - "benefits" often refers to advantageous or positive results from something, and is commonly used in a work context to refer to employee benefits. This narrows our possible answers even more, leaning towards something related to career advancement.
3. Taking into account the context and the analysis of the clues given in the problem, the most logical answer would be "promotion," as this is something one would fantasize about during a commute and indeed has both extra responsibilities and potential benefits. Hence, the correct answer is B: promotion.
Answer: B: promotion

### Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i1-s42-rTrue
Loading extension module utils...
Time to load utils op: 0.4049372673034668 seconds
Evaluating commonsenseqa :   2%|█                                                  | 1/50 [00:45<37:11, 45.54s/it]Evaluating commonsenseqa :   4%|██                                                 | 2/50 [01:30<36:02, 45.05s/it]Evaluating commonsenseqa :   6%|███                                                | 3/50 [02:13<34:42, 44.32s/it]Evaluating commonsenseqa :   8%|████                                               | 4/50 [02:57<33:58, 44.31s/it]Evaluating commonsenseqa :  10%|█████                                              | 5/50 [03:41<32:54, 43.88s/it]Evaluating commonsenseqa :  12%|██████                                             | 6/50 [04:25<32:15, 43.98s/it]Evaluating commonsenseqa :  14%|███████▏                                           | 7/50 [05:09<31:39, 44.18s/it]Evaluating commonsenseqa :  16%|████████▏                                          | 8/50 [05:54<30:55, 44.19s/it]Evaluating commonsenseqa :  18%|█████████▏                                         | 9/50 [06:37<29:58, 43.88s/it]Evaluating commonsenseqa :  20%|██████████                                        | 10/50 [07:20<29:06, 43.67s/it]Evaluating commonsenseqa :  22%|███████████                                       | 11/50 [08:05<28:40, 44.12s/it]Evaluating commonsenseqa :  24%|████████████                                      | 12/50 [08:49<27:53, 44.04s/it]Evaluating commonsenseqa :  26%|█████████████                                     | 13/50 [09:33<27:10, 44.06s/it]Evaluating commonsenseqa :  28%|██████████████                                    | 14/50 [09:59<23:13, 38.71s/it]Evaluating commonsenseqa :  30%|███████████████                                   | 15/50 [10:43<23:24, 40.12s/it]Evaluating commonsenseqa :  32%|████████████████                                  | 16/50 [11:27<23:22, 41.25s/it]Evaluating commonsenseqa :  34%|█████████████████                                 | 17/50 [12:11<23:07, 42.05s/it]Evaluating commonsenseqa :  36%|██████████████████                                | 18/50 [12:52<22:16, 41.76s/it]Evaluating commonsenseqa :  38%|███████████████████                               | 19/50 [13:36<21:57, 42.50s/it]Evaluating commonsenseqa :  40%|████████████████████                              | 20/50 [14:20<21:28, 42.94s/it]Evaluating commonsenseqa :  42%|█████████████████████                             | 21/50 [15:03<20:48, 43.04s/it]Evaluating commonsenseqa :  44%|██████████████████████                            | 22/50 [15:47<20:11, 43.28s/it]Evaluating commonsenseqa :  46%|███████████████████████                           | 23/50 [16:31<19:33, 43.48s/it]Evaluating commonsenseqa :  48%|████████████████████████                          | 24/50 [17:16<19:02, 43.93s/it]Evaluating commonsenseqa :  50%|█████████████████████████                         | 25/50 [17:58<18:04, 43.36s/it]Evaluating commonsenseqa :  52%|██████████████████████████                        | 26/50 [18:43<17:30, 43.76s/it]Evaluating commonsenseqa :  54%|███████████████████████████                       | 27/50 [18:57<13:25, 35.04s/it]Evaluating commonsenseqa :  56%|████████████████████████████                      | 28/50 [19:42<13:53, 37.87s/it]Evaluating commonsenseqa :  58%|████████████████████████████▉                     | 29/50 [20:26<13:54, 39.73s/it]Evaluating commonsenseqa :  60%|██████████████████████████████                    | 30/50 [21:10<13:40, 41.02s/it]Evaluating commonsenseqa :  62%|███████████████████████████████                   | 31/50 [21:54<13:17, 41.98s/it]Evaluating commonsenseqa :  64%|████████████████████████████████                  | 32/50 [22:39<12:53, 42.97s/it]Evaluating commonsenseqa :  66%|█████████████████████████████████                 | 33/50 [23:16<11:36, 40.95s/it]Evaluating commonsenseqa :  68%|██████████████████████████████████                | 34/50 [23:59<11:09, 41.82s/it]Evaluating commonsenseqa :  70%|███████████████████████████████████               | 35/50 [24:44<10:40, 42.69s/it]Evaluating commonsenseqa :  72%|████████████████████████████████████              | 36/50 [25:28<10:01, 43.00s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████             | 37/50 [26:12<09:23, 43.37s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████            | 38/50 [26:58<08:47, 43.97s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████           | 39/50 [27:19<06:48, 37.12s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████          | 40/50 [27:46<05:40, 34.04s/it]Evaluating commonsenseqa :  82%|█████████████████████████████████████████         | 41/50 [28:31<05:36, 37.34s/it]Evaluating commonsenseqa :  84%|██████████████████████████████████████████        | 42/50 [29:15<05:15, 39.50s/it]Evaluating commonsenseqa :  86%|███████████████████████████████████████████       | 43/50 [29:59<04:46, 40.95s/it]Evaluating commonsenseqa :  88%|████████████████████████████████████████████      | 44/50 [30:44<04:11, 41.93s/it]Evaluating commonsenseqa :  90%|█████████████████████████████████████████████     | 45/50 [31:28<03:33, 42.77s/it]Evaluating commonsenseqa :  92%|██████████████████████████████████████████████    | 46/50 [32:12<02:51, 42.89s/it]Evaluating commonsenseqa :  94%|███████████████████████████████████████████████   | 47/50 [32:56<02:09, 43.25s/it]Evaluating commonsenseqa :  96%|████████████████████████████████████████████████  | 48/50 [33:39<01:26, 43.39s/it]Evaluating commonsenseqa :  98%|█████████████████████████████████████████████████ | 49/50 [34:24<00:43, 43.73s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████████████████████| 50/50 [35:08<00:00, 43.81s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████████████████████| 50/50 [35:08<00:00, 42.17s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 3.1443} | lm_loss 7.4853 | avg. gen lenth: 294.735
torchrun --nproc_per_node 5 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 5 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-out-domain 0 --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 4 --seed 42 --data-dir /scratch/ylu130/processed_data/commonsenseqa/in-domain/i2-s42-rTrue --rationales --num-in-domain 2
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 5
[2023-08-08 14:20:07,923] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 5
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/in-domain/i2-s42-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 2
  num_out_domain ............... 0
  out_domain_data_name ......... None
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i2-s42-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 4
  clip_grad .................... 1.0
  seed ......................... 42
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 5
Loading Data
  0%|                                                                                    | 0/9739 [00:00<?, ?it/s]  1%|▍                                                                         | 53/9739 [00:00<00:18, 526.83it/s]  1%|▊                                                                        | 107/9739 [00:00<00:18, 531.32it/s]  2%|█▏                                                                       | 161/9739 [00:00<00:18, 530.74it/s]  2%|█▌                                                                       | 215/9739 [00:00<00:18, 527.03it/s]  3%|██                                                                       | 269/9739 [00:00<00:17, 528.64it/s]  3%|██▍                                                                      | 323/9739 [00:00<00:17, 530.28it/s]  4%|██▊                                                                      | 377/9739 [00:00<00:17, 530.56it/s]  4%|███▏                                                                     | 431/9739 [00:00<00:17, 528.27it/s]  5%|███▋                                                                     | 485/9739 [00:00<00:17, 529.57it/s]  6%|████                                                                     | 539/9739 [00:01<00:17, 530.49it/s]  6%|████▍                                                                    | 593/9739 [00:01<00:17, 530.30it/s]  7%|████▊                                                                    | 647/9739 [00:01<00:17, 530.48it/s]  7%|█████▎                                                                   | 701/9739 [00:01<00:17, 526.70it/s]  8%|█████▋                                                                   | 754/9739 [00:01<00:17, 527.48it/s]  8%|██████                                                                   | 807/9739 [00:01<00:17, 518.06it/s]  9%|██████▍                                                                  | 860/9739 [00:01<00:17, 520.17it/s]  9%|██████▊                                                                  | 913/9739 [00:01<00:17, 518.23it/s] 10%|███████▏                                                                 | 966/9739 [00:01<00:16, 519.91it/s] 10%|███████▌                                                                | 1019/9739 [00:01<00:16, 521.81it/s] 11%|████████                                                                | 1083/9739 [00:02<00:15, 556.70it/s] 12%|████████▌                                                               | 1165/9739 [00:02<00:13, 634.59it/s] 13%|█████████▏                                                              | 1250/9739 [00:02<00:12, 696.79it/s] 14%|█████████▊                                                              | 1334/9739 [00:02<00:11, 737.48it/s] 15%|██████████▍                                                             | 1419/9739 [00:02<00:10, 768.43it/s] 15%|███████████                                                             | 1504/9739 [00:02<00:10, 790.06it/s] 16%|███████████▋                                                            | 1585/9739 [00:02<00:10, 794.02it/s] 17%|████████████▎                                                           | 1669/9739 [00:02<00:09, 807.07it/s] 18%|████████████▉                                                           | 1753/9739 [00:02<00:09, 816.61it/s] 19%|█████████████▌                                                          | 1835/9739 [00:02<00:09, 798.85it/s] 20%|██████████████▏                                                         | 1919/9739 [00:03<00:09, 809.52it/s] 21%|██████████████▊                                                         | 2003/9739 [00:03<00:09, 816.28it/s] 21%|███████████████▍                                                        | 2085/9739 [00:03<00:09, 817.03it/s] 22%|████████████████                                                        | 2169/9739 [00:03<00:09, 821.55it/s] 23%|████████████████▋                                                       | 2252/9739 [00:03<00:09, 821.81it/s] 24%|█████████████████▎                                                      | 2335/9739 [00:03<00:08, 823.70it/s] 25%|█████████████████▉                                                      | 2419/9739 [00:03<00:08, 825.84it/s] 26%|██████████████████▍                                                     | 2502/9739 [00:03<00:08, 824.26it/s] 27%|███████████████████                                                     | 2585/9739 [00:03<00:08, 824.90it/s] 27%|███████████████████▋                                                    | 2668/9739 [00:03<00:08, 825.79it/s] 28%|████████████████████▎                                                   | 2751/9739 [00:04<00:08, 822.95it/s] 29%|████████████████████▉                                                   | 2834/9739 [00:04<00:08, 823.41it/s] 30%|█████████████████████▌                                                  | 2918/9739 [00:04<00:08, 826.52it/s] 31%|██████████████████████▏                                                 | 3001/9739 [00:04<00:08, 827.55it/s] 32%|██████████████████████▊                                                 | 3085/9739 [00:04<00:08, 830.57it/s] 33%|███████████████████████▍                                                | 3169/9739 [00:04<00:07, 829.91it/s] 33%|████████████████████████                                                | 3253/9739 [00:04<00:07, 832.84it/s] 34%|████████████████████████▋                                               | 3337/9739 [00:04<00:07, 834.20it/s] 35%|█████████████████████████▎                                              | 3421/9739 [00:04<00:07, 833.09it/s] 36%|█████████████████████████▉                                              | 3505/9739 [00:04<00:07, 834.03it/s] 37%|██████████████████████████▌                                             | 3589/9739 [00:05<00:07, 835.19it/s] 38%|███████████████████████████▏                                            | 3673/9739 [00:05<00:07, 833.35it/s] 39%|███████████████████████████▊                                            | 3757/9739 [00:05<00:07, 830.76it/s] 39%|████████████████████████████▍                                           | 3841/9739 [00:05<00:07, 830.04it/s] 40%|█████████████████████████████                                           | 3925/9739 [00:05<00:06, 831.89it/s] 41%|█████████████████████████████▋                                          | 4009/9739 [00:05<00:06, 833.19it/s] 42%|██████████████████████████████▎                                         | 4093/9739 [00:05<00:06, 831.77it/s] 43%|██████████████████████████████▉                                         | 4177/9739 [00:05<00:06, 832.92it/s] 44%|███████████████████████████████▌                                        | 4261/9739 [00:05<00:06, 834.93it/s] 45%|████████████████████████████████                                        | 4345/9739 [00:05<00:06, 834.21it/s] 45%|████████████████████████████████▋                                       | 4429/9739 [00:06<00:06, 835.03it/s] 46%|█████████████████████████████████▎                                      | 4513/9739 [00:06<00:06, 808.62it/s] 47%|█████████████████████████████████▉                                      | 4597/9739 [00:06<00:06, 816.56it/s] 48%|██████████████████████████████████▌                                     | 4681/9739 [00:06<00:06, 822.89it/s] 49%|███████████████████████████████████▏                                    | 4764/9739 [00:06<00:08, 615.43it/s] 50%|███████████████████████████████████▊                                    | 4847/9739 [00:06<00:07, 666.11it/s] 51%|████████████████████████████████████▍                                   | 4931/9739 [00:06<00:06, 708.80it/s] 51%|█████████████████████████████████████                                   | 5014/9739 [00:06<00:06, 740.43it/s] 52%|█████████████████████████████████████▋                                  | 5098/9739 [00:07<00:06, 766.95it/s] 53%|██████████████████████████████████████▎                                 | 5182/9739 [00:07<00:05, 785.02it/s] 54%|██████████████████████████████████████▉                                 | 5266/9739 [00:07<00:05, 799.82it/s] 55%|███████████████████████████████████████▌                                | 5350/9739 [00:07<00:05, 810.49it/s] 56%|████████████████████████████████████████▏                               | 5434/9739 [00:07<00:05, 816.40it/s] 57%|████████████████████████████████████████▊                               | 5520/9739 [00:07<00:05, 827.87it/s] 58%|█████████████████████████████████████████▍                              | 5608/9739 [00:07<00:04, 840.50it/s] 58%|██████████████████████████████████████████                              | 5695/9739 [00:07<00:04, 847.84it/s] 59%|██████████████████████████████████████████▊                             | 5783/9739 [00:07<00:04, 855.15it/s] 60%|███████████████████████████████████████████▍                            | 5869/9739 [00:07<00:04, 849.22it/s] 61%|████████████████████████████████████████████                            | 5957/9739 [00:08<00:04, 856.40it/s] 62%|████████████████████████████████████████████▋                           | 6045/9739 [00:08<00:04, 861.25it/s] 63%|█████████████████████████████████████████████▎                          | 6132/9739 [00:08<00:04, 861.75it/s] 64%|█████████████████████████████████████████████▉                          | 6220/9739 [00:08<00:04, 864.84it/s] 65%|██████████████████████████████████████████████▋                         | 6307/9739 [00:08<00:03, 863.15it/s] 66%|███████████████████████████████████████████████▎                        | 6394/9739 [00:08<00:03, 864.72it/s] 67%|███████████████████████████████████████████████▉                        | 6481/9739 [00:08<00:03, 866.22it/s] 67%|████████████████████████████████████████████████▌                       | 6568/9739 [00:08<00:03, 863.23it/s] 68%|█████████████████████████████████████████████████▏                      | 6656/9739 [00:08<00:03, 865.39it/s] 69%|█████████████████████████████████████████████████▊                      | 6744/9739 [00:08<00:03, 867.93it/s] 70%|██████████████████████████████████████████████████▌                     | 6831/9739 [00:09<00:03, 865.75it/s] 71%|███████████████████████████████████████████████████▏                    | 6918/9739 [00:09<00:03, 860.90it/s] 72%|███████████████████████████████████████████████████▊                    | 7005/9739 [00:09<00:03, 858.99it/s] 73%|████████████████████████████████████████████████████▍                   | 7092/9739 [00:09<00:03, 861.31it/s] 74%|█████████████████████████████████████████████████████                   | 7180/9739 [00:09<00:02, 864.38it/s] 75%|█████████████████████████████████████████████████████▋                  | 7267/9739 [00:09<00:02, 863.99it/s] 76%|██████████████████████████████████████████████████████▎                 | 7354/9739 [00:09<00:02, 862.62it/s] 76%|███████████████████████████████████████████████████████                 | 7441/9739 [00:09<00:02, 827.25it/s] 77%|███████████████████████████████████████████████████████▋                | 7528/9739 [00:09<00:02, 838.50it/s] 78%|████████████████████████████████████████████████████████▎               | 7616/9739 [00:09<00:02, 847.89it/s] 79%|████████████████████████████████████████████████████████▉               | 7701/9739 [00:10<00:02, 847.56it/s] 80%|█████████████████████████████████████████████████████████▌              | 7788/9739 [00:10<00:02, 854.11it/s] 81%|██████████████████████████████████████████████████████████▏             | 7875/9739 [00:10<00:02, 858.69it/s] 82%|██████████████████████████████████████████████████████████▊             | 7962/9739 [00:10<00:02, 860.43it/s] 83%|███████████████████████████████████████████████████████████▌            | 8050/9739 [00:10<00:01, 863.55it/s] 84%|████████████████████████████████████████████████████████████▏           | 8137/9739 [00:10<00:01, 864.27it/s] 84%|████████████████████████████████████████████████████████████▊           | 8225/9739 [00:10<00:01, 865.91it/s] 85%|█████████████████████████████████████████████████████████████▍          | 8312/9739 [00:10<00:01, 865.93it/s] 86%|██████████████████████████████████████████████████████████████          | 8399/9739 [00:10<00:01, 864.01it/s] 87%|██████████████████████████████████████████████████████████████▋         | 8487/9739 [00:10<00:01, 866.24it/s] 88%|███████████████████████████████████████████████████████████████▍        | 8574/9739 [00:11<00:01, 864.67it/s] 89%|████████████████████████████████████████████████████████████████        | 8661/9739 [00:11<00:01, 865.49it/s] 90%|████████████████████████████████████████████████████████████████▋       | 8748/9739 [00:11<00:01, 866.49it/s] 91%|█████████████████████████████████████████████████████████████████▎      | 8835/9739 [00:11<00:01, 864.83it/s] 92%|█████████████████████████████████████████████████████████████████▉      | 8923/9739 [00:11<00:00, 866.60it/s] 93%|██████████████████████████████████████████████████████████████████▌     | 9010/9739 [00:11<00:00, 864.73it/s] 93%|███████████████████████████████████████████████████████████████████▎    | 9097/9739 [00:11<00:00, 860.60it/s] 94%|███████████████████████████████████████████████████████████████████▉    | 9184/9739 [00:11<00:00, 862.11it/s] 95%|████████████████████████████████████████████████████████████████████▌   | 9271/9739 [00:11<00:00, 861.61it/s] 96%|█████████████████████████████████████████████████████████████████████▏  | 9358/9739 [00:11<00:00, 863.04it/s] 97%|█████████████████████████████████████████████████████████████████████▊  | 9445/9739 [00:12<00:00, 864.84it/s] 98%|██████████████████████████████████████████████████████████████████████▍ | 9532/9739 [00:12<00:00, 864.09it/s] 99%|███████████████████████████████████████████████████████████████████████ | 9619/9739 [00:12<00:00, 865.30it/s]100%|███████████████████████████████████████████████████████████████████████▊| 9706/9739 [00:12<00:00, 863.53it/s]100%|████████████████████████████████████████████████████████████████████████| 9739/9739 [00:12<00:00, 785.24it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:10,  5.42s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:10,  5.50s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:11,  5.95s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:11,  5.81s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:06<00:12,  6.16s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:10<00:05,  5.38s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:11<00:05,  5.52s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:11<00:05,  5.60s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:11<00:05,  5.76s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:11<00:05,  5.95s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.74s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.92s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.81s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.99s/it]
[2023-08-08 14:21:12,643] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:15<00:00,  4.88s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.09s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:16<00:00,  5.16s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:16<00:00,  5.34s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:16<00:00,  5.17s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:16<00:00,  5.40s/it]
[2023-08-08 14:21:28,160] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-08 14:21:28,162] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-08 14:21:28,162] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-08 14:21:28,162] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-08 14:21:28,162] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-08 14:21:28,162] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-08 14:21:28,163] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-08 14:21:28,163] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-08 14:21:28,163] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-08 14:21:28,163] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-08 14:21:28,163] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-08 14:21:28,163] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f3df167af40>
[2023-08-08 14:21:28,163] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-08 14:21:28,163] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-08 14:21:28,163] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-08 14:21:28,163] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-08 14:21:28,163] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-08 14:21:28,163] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-08 14:21:28,163] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-08 14:21:28,163] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-08 14:21:28,163] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-08 14:21:28,163] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-08 14:21:28,163] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-08 14:21:28,163] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-08 14:21:28,163] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-08 14:21:28,163] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-08 14:21:28,163] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-08 14:21:28,163] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-08 14:21:28,163] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-08 14:21:28,163] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-08 14:21:28,163] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-08 14:21:28,163] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f3dcb590dc0>
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  4
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   world_size ................... 5
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-08 14:21:28,164] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-08 14:21:28,165] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-08 14:21:28,165] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-08 14:21:28,165] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 4, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.43695688247680664 seconds
Loading extension module utils...
Time to load utils op: 0.4046616554260254 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                           | 0/50 [00:00<?, ?it/s]############### Example ###############
Loading extension module utils...
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following multiple choice question.

### Demonstration:
Input: He fantasied about getting a what while driving to work and the pros and cons of the extra responsibilities and benefits? Choices:  A: new car B: promotion C: boredom D: impatience E: pressure
Rationales: The statement presents a scenario where a person is daydreaming about a potential change that brings not only extra responsibilities but also benefits. 

Analyzing all the choices given: 
A: A new car would be a material possession. While it could bring along responsibilities and benefits, the phrase "extra responsibilities" is generally not associated with a car ownership. 
B: A promotion, in a work context, would bring about additional responsibilities since one would be tasked with more complex duties. However, it would also come with benefits such as higher pay and possibly more workplace perks. 
C: Boredom doesn't fit into this context since it is a feeling and does not carry responsibilities or benefits.
D: Impatience, just like boredom, is a feeling and does not involve responsibilities or benefits. 
E: Pressure could mean additional responsibilities, but it doesn't bring benefits with it, especially not in a work context. 

Among all the options, B: Promotion best fits the context and makes most sense in this scenario. Thus, the answer is B: Promotion.
Answer: B: promotion

Input: He was good at traditional science but excelled at social science, his favorite subject was what? Choices:  A: geography B: history studies C: math D: religion E: dancing
Rationales: 1. The question indicates that the person was good at traditional science.
2. However, the question also states that he excelled at social science.
3. Social science includes various subjects such as sociology, anthropology, political science, psychology, social work, and history.
4. The question does not specify the exact social science where he excelled, but it indicates it was his favorite subject.
5. Among the given options, only history studies fall under social sciences. 
6. Given this, we can determine that his favorite subject is history studies. 
7. Therefore, the answer is B: history studies.
Answer: B: history studies

### Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i2-s42-rTrue
Time to load utils op: 0.40466904640197754 seconds
Loading extension module utils...
Time to load utils op: 0.5046169757843018 seconds
Loading extension module utils...
Time to load utils op: 0.5047574043273926 seconds
Evaluating commonsenseqa :   2%|█                                                  | 1/50 [00:42<35:05, 42.97s/it]Evaluating commonsenseqa :   4%|██                                                 | 2/50 [00:59<22:00, 27.51s/it]Evaluating commonsenseqa :   6%|███                                                | 3/50 [01:41<26:34, 33.92s/it]Evaluating commonsenseqa :   8%|████                                               | 4/50 [02:22<28:07, 36.68s/it]Evaluating commonsenseqa :  10%|█████                                              | 5/50 [03:03<28:51, 38.47s/it]Evaluating commonsenseqa :  12%|██████                                             | 6/50 [03:45<29:04, 39.65s/it]Evaluating commonsenseqa :  14%|███████▏                                           | 7/50 [04:27<28:59, 40.45s/it]Evaluating commonsenseqa :  16%|████████▏                                          | 8/50 [05:08<28:28, 40.67s/it]Evaluating commonsenseqa :  18%|█████████▏                                         | 9/50 [05:50<27:52, 40.80s/it]Evaluating commonsenseqa :  20%|██████████                                        | 10/50 [06:29<26:50, 40.26s/it]Evaluating commonsenseqa :  22%|███████████                                       | 11/50 [07:11<26:34, 40.89s/it]Evaluating commonsenseqa :  24%|████████████                                      | 12/50 [07:53<26:06, 41.22s/it]Evaluating commonsenseqa :  26%|█████████████                                     | 13/50 [08:35<25:34, 41.47s/it]Evaluating commonsenseqa :  28%|██████████████                                    | 14/50 [09:17<24:54, 41.52s/it]Evaluating commonsenseqa :  30%|███████████████                                   | 15/50 [09:58<24:13, 41.53s/it]Evaluating commonsenseqa :  32%|████████████████                                  | 16/50 [10:39<23:23, 41.28s/it]Evaluating commonsenseqa :  34%|█████████████████                                 | 17/50 [11:20<22:39, 41.19s/it]Evaluating commonsenseqa :  36%|██████████████████                                | 18/50 [12:01<21:55, 41.11s/it]Evaluating commonsenseqa :  38%|███████████████████                               | 19/50 [12:41<21:07, 40.88s/it]Evaluating commonsenseqa :  40%|████████████████████                              | 20/50 [13:14<19:18, 38.62s/it]Evaluating commonsenseqa :  42%|█████████████████████                             | 21/50 [13:56<19:04, 39.46s/it]Evaluating commonsenseqa :  44%|██████████████████████                            | 22/50 [14:38<18:44, 40.17s/it]Evaluating commonsenseqa :  46%|███████████████████████                           | 23/50 [15:18<18:03, 40.14s/it]Evaluating commonsenseqa :  48%|████████████████████████                          | 24/50 [15:59<17:36, 40.62s/it]Evaluating commonsenseqa :  50%|█████████████████████████                         | 25/50 [16:41<17:05, 41.02s/it]Evaluating commonsenseqa :  52%|██████████████████████████                        | 26/50 [17:24<16:34, 41.43s/it]Evaluating commonsenseqa :  54%|███████████████████████████                       | 27/50 [17:40<12:59, 33.89s/it]Evaluating commonsenseqa :  56%|████████████████████████████                      | 28/50 [18:21<13:11, 35.99s/it]Evaluating commonsenseqa :  58%|████████████████████████████▉                     | 29/50 [19:02<13:10, 37.64s/it]Evaluating commonsenseqa :  60%|██████████████████████████████                    | 30/50 [19:42<12:41, 38.08s/it]Evaluating commonsenseqa :  62%|███████████████████████████████                   | 31/50 [20:23<12:20, 38.95s/it]Evaluating commonsenseqa :  64%|████████████████████████████████                  | 32/50 [21:03<11:51, 39.51s/it]Evaluating commonsenseqa :  66%|█████████████████████████████████                 | 33/50 [21:44<11:18, 39.94s/it]Evaluating commonsenseqa :  68%|██████████████████████████████████                | 34/50 [22:23<10:35, 39.69s/it]Evaluating commonsenseqa :  70%|███████████████████████████████████               | 35/50 [22:54<09:15, 37.03s/it]Evaluating commonsenseqa :  72%|████████████████████████████████████              | 36/50 [23:36<08:59, 38.51s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████             | 37/50 [24:18<08:32, 39.39s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████            | 38/50 [24:59<08:00, 40.08s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████           | 39/50 [25:42<07:27, 40.71s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████          | 40/50 [26:23<06:50, 41.08s/it]Evaluating commonsenseqa :  82%|█████████████████████████████████████████         | 41/50 [27:05<06:11, 41.24s/it]Evaluating commonsenseqa :  84%|██████████████████████████████████████████        | 42/50 [27:42<05:19, 39.90s/it]Evaluating commonsenseqa :  86%|███████████████████████████████████████████       | 43/50 [28:23<04:42, 40.35s/it]Evaluating commonsenseqa :  88%|████████████████████████████████████████████      | 44/50 [29:05<04:05, 40.88s/it]Evaluating commonsenseqa :  90%|█████████████████████████████████████████████     | 45/50 [29:48<03:26, 41.36s/it]Evaluating commonsenseqa :  92%|██████████████████████████████████████████████    | 46/50 [30:22<02:37, 39.33s/it]Evaluating commonsenseqa :  94%|███████████████████████████████████████████████   | 47/50 [31:04<01:59, 39.95s/it]Evaluating commonsenseqa :  96%|████████████████████████████████████████████████  | 48/50 [31:46<01:21, 40.64s/it]Evaluating commonsenseqa :  98%|█████████████████████████████████████████████████ | 49/50 [32:28<00:40, 40.98s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████████████████████| 50/50 [33:10<00:00, 41.23s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████████████████████| 50/50 [33:10<00:00, 39.80s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 2.3995} | lm_loss 7.5963 | avg. gen lenth: 314.2
torchrun --nproc_per_node 5 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 5 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-out-domain 0 --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 4 --seed 42 --data-dir /scratch/ylu130/processed_data/commonsenseqa/in-domain/i3-s42-rTrue --rationales --num-in-domain 3
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 5
[2023-08-08 14:55:26,559] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 5
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/in-domain/i3-s42-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 3
  num_out_domain ............... 0
  out_domain_data_name ......... None
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i3-s42-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 4
  clip_grad .................... 1.0
  seed ......................... 42
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 5
Loading Data
  0%|                                                                                    | 0/9738 [00:00<?, ?it/s]  0%|▏                                                                         | 31/9738 [00:00<00:32, 300.69it/s]  1%|▍                                                                         | 62/9738 [00:00<00:31, 303.80it/s]  1%|▋                                                                         | 93/9738 [00:00<00:31, 304.14it/s]  1%|▉                                                                        | 124/9738 [00:00<00:31, 304.76it/s]  2%|█▏                                                                       | 155/9738 [00:00<00:31, 305.38it/s]  2%|█▍                                                                       | 186/9738 [00:00<00:31, 300.45it/s]  2%|█▋                                                                       | 217/9738 [00:00<00:31, 297.97it/s]  3%|█▊                                                                       | 248/9738 [00:00<00:31, 299.48it/s]  3%|██                                                                       | 279/9738 [00:00<00:31, 301.24it/s]  3%|██▎                                                                      | 310/9738 [00:01<00:31, 303.70it/s]  4%|██▌                                                                      | 341/9738 [00:01<00:30, 303.77it/s]  4%|██▊                                                                      | 372/9738 [00:01<00:30, 305.20it/s]  4%|███                                                                      | 403/9738 [00:01<00:30, 306.21it/s]  4%|███▎                                                                     | 434/9738 [00:01<00:30, 304.99it/s]  5%|███▍                                                                     | 465/9738 [00:01<00:30, 306.07it/s]  5%|███▋                                                                     | 496/9738 [00:01<00:30, 306.85it/s]  5%|███▉                                                                     | 527/9738 [00:01<00:30, 306.90it/s]  6%|████▏                                                                    | 558/9738 [00:01<00:30, 303.60it/s]  6%|████▍                                                                    | 589/9738 [00:01<00:30, 304.79it/s]  6%|████▋                                                                    | 621/9738 [00:02<00:29, 307.60it/s]  7%|████▉                                                                    | 653/9738 [00:02<00:29, 309.95it/s]  7%|█████▏                                                                   | 686/9738 [00:02<00:28, 314.78it/s]  7%|█████▍                                                                   | 719/9738 [00:02<00:28, 317.83it/s]  8%|█████▋                                                                   | 752/9738 [00:02<00:28, 319.07it/s]  8%|█████▉                                                                   | 785/9738 [00:02<00:27, 321.26it/s]  8%|██████▏                                                                  | 818/9738 [00:02<00:27, 322.82it/s]  9%|██████▍                                                                  | 851/9738 [00:02<00:27, 323.71it/s]  9%|██████▋                                                                  | 884/9738 [00:02<00:27, 323.43it/s]  9%|██████▊                                                                  | 917/9738 [00:02<00:27, 324.27it/s] 10%|███████                                                                  | 950/9738 [00:03<00:27, 325.08it/s] 10%|███████▎                                                                 | 983/9738 [00:03<00:26, 325.31it/s] 10%|███████▌                                                                | 1016/9738 [00:03<00:26, 325.54it/s] 11%|███████▊                                                                | 1049/9738 [00:03<00:26, 324.54it/s] 11%|████████                                                                | 1082/9738 [00:03<00:27, 320.47it/s] 11%|████████▏                                                               | 1115/9738 [00:03<00:26, 320.77it/s] 12%|████████▌                                                               | 1164/9738 [00:03<00:23, 369.47it/s] 12%|████████▉                                                               | 1208/9738 [00:03<00:21, 390.21it/s] 13%|█████████▎                                                              | 1258/9738 [00:03<00:20, 420.43it/s] 13%|█████████▋                                                              | 1308/9738 [00:03<00:19, 442.17it/s] 14%|██████████                                                              | 1357/9738 [00:04<00:18, 455.27it/s] 14%|██████████▍                                                             | 1405/9738 [00:04<00:18, 461.16it/s] 15%|██████████▊                                                             | 1455/9738 [00:04<00:17, 470.00it/s] 15%|███████████▏                                                            | 1505/9738 [00:04<00:17, 476.25it/s] 16%|███████████▍                                                            | 1555/9738 [00:04<00:17, 481.06it/s] 16%|███████████▊                                                            | 1604/9738 [00:04<00:16, 481.51it/s] 17%|████████████▏                                                           | 1654/9738 [00:04<00:16, 484.79it/s] 17%|████████████▌                                                           | 1704/9738 [00:04<00:16, 486.31it/s] 18%|████████████▉                                                           | 1753/9738 [00:04<00:16, 471.53it/s] 18%|█████████████▎                                                          | 1801/9738 [00:05<00:17, 452.27it/s] 19%|█████████████▋                                                          | 1851/9738 [00:05<00:16, 464.22it/s] 20%|██████████████                                                          | 1901/9738 [00:05<00:16, 472.96it/s] 20%|██████████████▍                                                         | 1949/9738 [00:05<00:16, 459.88it/s] 21%|██████████████▊                                                         | 1999/9738 [00:05<00:16, 469.25it/s] 21%|███████████████▏                                                        | 2048/9738 [00:05<00:16, 473.40it/s] 22%|███████████████▌                                                        | 2097/9738 [00:05<00:15, 478.18it/s] 22%|███████████████▊                                                        | 2147/9738 [00:05<00:15, 482.04it/s] 23%|████████████████▏                                                       | 2197/9738 [00:05<00:15, 485.28it/s] 23%|████████████████▌                                                       | 2246/9738 [00:05<00:15, 485.65it/s] 24%|████████████████▉                                                       | 2296/9738 [00:06<00:15, 487.64it/s] 24%|█████████████████▎                                                      | 2346/9738 [00:06<00:15, 488.73it/s] 25%|█████████████████▋                                                      | 2396/9738 [00:06<00:14, 490.14it/s] 25%|██████████████████                                                      | 2446/9738 [00:06<00:14, 490.77it/s] 26%|██████████████████▍                                                     | 2496/9738 [00:06<00:14, 485.95it/s] 26%|██████████████████▊                                                     | 2546/9738 [00:06<00:14, 487.31it/s] 27%|███████████████████▏                                                    | 2596/9738 [00:06<00:14, 489.01it/s] 27%|███████████████████▌                                                    | 2645/9738 [00:06<00:14, 488.99it/s] 28%|███████████████████▉                                                    | 2694/9738 [00:06<00:14, 487.23it/s] 28%|████████████████████▎                                                   | 2743/9738 [00:06<00:14, 487.96it/s] 29%|████████████████████▋                                                   | 2792/9738 [00:07<00:14, 488.18it/s] 29%|█████████████████████                                                   | 2841/9738 [00:07<00:14, 488.30it/s] 30%|█████████████████████▎                                                  | 2890/9738 [00:07<00:14, 488.78it/s] 30%|█████████████████████▋                                                  | 2939/9738 [00:07<00:13, 486.99it/s] 31%|██████████████████████                                                  | 2988/9738 [00:07<00:13, 482.34it/s] 31%|██████████████████████▍                                                 | 3037/9738 [00:07<00:14, 467.70it/s] 32%|██████████████████████▊                                                 | 3086/9738 [00:07<00:14, 474.00it/s] 32%|███████████████████████▏                                                | 3136/9738 [00:07<00:13, 479.16it/s] 33%|███████████████████████▌                                                | 3185/9738 [00:07<00:13, 480.85it/s] 33%|███████████████████████▉                                                | 3235/9738 [00:07<00:13, 484.09it/s] 34%|████████████████████████▎                                               | 3285/9738 [00:08<00:13, 486.51it/s] 34%|████████████████████████▋                                               | 3335/9738 [00:08<00:13, 487.95it/s] 35%|█████████████████████████                                               | 3384/9738 [00:08<00:13, 472.69it/s] 35%|█████████████████████████▍                                              | 3433/9738 [00:08<00:13, 476.95it/s] 36%|█████████████████████████▋                                              | 3482/9738 [00:08<00:13, 479.61it/s] 36%|██████████████████████████                                              | 3531/9738 [00:08<00:13, 466.17it/s] 37%|██████████████████████████▍                                             | 3580/9738 [00:08<00:13, 472.08it/s] 37%|██████████████████████████▊                                             | 3629/9738 [00:08<00:12, 474.79it/s] 38%|███████████████████████████▏                                            | 3678/9738 [00:08<00:12, 478.96it/s] 38%|███████████████████████████▌                                            | 3728/9738 [00:09<00:12, 482.60it/s] 39%|███████████████████████████▉                                            | 3777/9738 [00:09<00:12, 484.50it/s] 39%|████████████████████████████▎                                           | 3827/9738 [00:09<00:12, 486.28it/s] 40%|████████████████████████████▋                                           | 3876/9738 [00:09<00:12, 485.55it/s] 40%|█████████████████████████████                                           | 3925/9738 [00:09<00:11, 486.67it/s] 41%|█████████████████████████████▍                                          | 3974/9738 [00:09<00:11, 487.60it/s] 41%|█████████████████████████████▊                                          | 4024/9738 [00:09<00:11, 488.66it/s] 42%|██████████████████████████████                                          | 4073/9738 [00:09<00:11, 486.51it/s] 42%|██████████████████████████████▍                                         | 4122/9738 [00:09<00:11, 486.96it/s] 43%|██████████████████████████████▊                                         | 4171/9738 [00:09<00:11, 487.15it/s] 43%|███████████████████████████████▏                                        | 4220/9738 [00:10<00:11, 486.46it/s] 44%|███████████████████████████████▌                                        | 4269/9738 [00:10<00:11, 487.37it/s] 44%|███████████████████████████████▉                                        | 4318/9738 [00:10<00:11, 485.49it/s] 45%|████████████████████████████████▎                                       | 4367/9738 [00:10<00:11, 468.04it/s] 45%|████████████████████████████████▋                                       | 4416/9738 [00:10<00:11, 472.85it/s] 46%|█████████████████████████████████                                       | 4465/9738 [00:10<00:11, 476.03it/s] 46%|█████████████████████████████████▎                                      | 4513/9738 [00:10<00:11, 446.04it/s] 47%|█████████████████████████████████▋                                      | 4562/9738 [00:10<00:11, 455.98it/s] 47%|██████████████████████████████████                                      | 4611/9738 [00:10<00:11, 463.69it/s] 48%|██████████████████████████████████▍                                     | 4660/9738 [00:10<00:10, 469.68it/s] 48%|██████████████████████████████████▊                                     | 4709/9738 [00:11<00:10, 473.29it/s] 49%|███████████████████████████████████▏                                    | 4757/9738 [00:11<00:14, 347.71it/s] 49%|███████████████████████████████████▌                                    | 4806/9738 [00:11<00:12, 380.10it/s] 50%|███████████████████████████████████▉                                    | 4855/9738 [00:11<00:12, 406.67it/s] 50%|████████████████████████████████████▏                                   | 4900/9738 [00:11<00:11, 411.43it/s] 51%|████████████████████████████████████▌                                   | 4949/9738 [00:11<00:11, 430.32it/s] 51%|████████████████████████████████████▉                                   | 4998/9738 [00:11<00:10, 446.27it/s] 52%|█████████████████████████████████████▎                                  | 5047/9738 [00:11<00:10, 458.31it/s] 52%|█████████████████████████████████████▋                                  | 5096/9738 [00:11<00:09, 467.07it/s] 53%|██████████████████████████████████████                                  | 5145/9738 [00:12<00:09, 473.48it/s] 53%|██████████████████████████████████████▍                                 | 5194/9738 [00:12<00:09, 475.99it/s] 54%|██████████████████████████████████████▊                                 | 5243/9738 [00:12<00:09, 478.93it/s] 54%|███████████████████████████████████████▏                                | 5292/9738 [00:12<00:09, 480.94it/s] 55%|███████████████████████████████████████▍                                | 5341/9738 [00:12<00:09, 482.43it/s] 55%|███████████████████████████████████████▊                                | 5390/9738 [00:12<00:08, 483.65it/s] 56%|████████████████████████████████████████▏                               | 5439/9738 [00:12<00:08, 482.91it/s] 56%|████████████████████████████████████████▌                               | 5489/9738 [00:12<00:08, 485.46it/s] 57%|████████████████████████████████████████▉                               | 5539/9738 [00:12<00:08, 488.93it/s] 57%|█████████████████████████████████████████▎                              | 5590/9738 [00:13<00:08, 493.35it/s] 58%|█████████████████████████████████████████▋                              | 5640/9738 [00:13<00:08, 494.75it/s] 58%|██████████████████████████████████████████                              | 5691/9738 [00:13<00:08, 497.51it/s] 59%|██████████████████████████████████████████▍                             | 5742/9738 [00:13<00:08, 499.47it/s] 59%|██████████████████████████████████████████▊                             | 5792/9738 [00:13<00:07, 495.64it/s] 60%|███████████████████████████████████████████▏                            | 5843/9738 [00:13<00:07, 497.73it/s] 61%|███████████████████████████████████████████▌                            | 5893/9738 [00:13<00:07, 497.59it/s] 61%|███████████████████████████████████████████▉                            | 5944/9738 [00:13<00:07, 499.50it/s] 62%|████████████████████████████████████████████▎                           | 5995/9738 [00:13<00:07, 501.45it/s] 62%|████████████████████████████████████████████▋                           | 6046/9738 [00:13<00:07, 503.12it/s] 63%|█████████████████████████████████████████████                           | 6097/9738 [00:14<00:07, 502.23it/s] 63%|█████████████████████████████████████████████▍                          | 6148/9738 [00:14<00:07, 502.63it/s] 64%|█████████████████████████████████████████████▊                          | 6199/9738 [00:14<00:07, 503.83it/s] 64%|██████████████████████████████████████████████▏                         | 6250/9738 [00:14<00:06, 503.14it/s] 65%|██████████████████████████████████████████████▌                         | 6301/9738 [00:14<00:06, 503.95it/s] 65%|██████████████████████████████████████████████▉                         | 6352/9738 [00:14<00:06, 502.55it/s] 66%|███████████████████████████████████████████████▎                        | 6403/9738 [00:14<00:06, 503.64it/s] 66%|███████████████████████████████████████████████▋                        | 6454/9738 [00:14<00:06, 503.84it/s] 67%|████████████████████████████████████████████████                        | 6505/9738 [00:14<00:06, 503.52it/s] 67%|████████████████████████████████████████████████▍                       | 6556/9738 [00:14<00:06, 502.21it/s] 68%|████████████████████████████████████████████████▊                       | 6607/9738 [00:15<00:06, 502.83it/s] 68%|█████████████████████████████████████████████████▏                      | 6658/9738 [00:15<00:06, 503.97it/s] 69%|█████████████████████████████████████████████████▌                      | 6709/9738 [00:15<00:06, 504.35it/s] 69%|█████████████████████████████████████████████████▉                      | 6760/9738 [00:15<00:05, 503.18it/s] 70%|██████████████████████████████████████████████████▎                     | 6811/9738 [00:15<00:05, 503.83it/s] 70%|██████████████████████████████████████████████████▋                     | 6862/9738 [00:15<00:05, 504.66it/s] 71%|███████████████████████████████████████████████████                     | 6913/9738 [00:15<00:05, 505.05it/s] 72%|███████████████████████████████████████████████████▍                    | 6964/9738 [00:15<00:05, 487.02it/s] 72%|███████████████████████████████████████████████████▊                    | 7014/9738 [00:15<00:05, 489.26it/s] 73%|████████████████████████████████████████████████████▏                   | 7065/9738 [00:15<00:05, 493.51it/s] 73%|████████████████████████████████████████████████████▌                   | 7115/9738 [00:16<00:05, 481.66it/s] 74%|████████████████████████████████████████████████████▉                   | 7166/9738 [00:16<00:05, 488.81it/s] 74%|█████████████████████████████████████████████████████▎                  | 7216/9738 [00:16<00:05, 491.27it/s] 75%|█████████████████████████████████████████████████████▋                  | 7267/9738 [00:16<00:04, 495.49it/s] 75%|██████████████████████████████████████████████████████                  | 7318/9738 [00:16<00:04, 498.39it/s] 76%|██████████████████████████████████████████████████████▍                 | 7369/9738 [00:16<00:04, 501.53it/s] 76%|██████████████████████████████████████████████████████▊                 | 7420/9738 [00:16<00:04, 502.67it/s] 77%|███████████████████████████████████████████████████████▏                | 7471/9738 [00:16<00:04, 478.14it/s] 77%|███████████████████████████████████████████████████████▌                | 7522/9738 [00:16<00:04, 485.12it/s] 78%|███████████████████████████████████████████████████████▉                | 7573/9738 [00:16<00:04, 491.16it/s] 78%|████████████████████████████████████████████████████████▎               | 7624/9738 [00:17<00:04, 495.61it/s] 79%|████████████████████████████████████████████████████████▋               | 7674/9738 [00:17<00:04, 491.38it/s] 79%|█████████████████████████████████████████████████████████               | 7725/9738 [00:17<00:04, 495.88it/s] 80%|█████████████████████████████████████████████████████████▍              | 7776/9738 [00:17<00:03, 498.46it/s] 80%|█████████████████████████████████████████████████████████▊              | 7827/9738 [00:17<00:03, 500.39it/s] 81%|██████████████████████████████████████████████████████████▏             | 7878/9738 [00:17<00:03, 501.47it/s] 81%|██████████████████████████████████████████████████████████▌             | 7929/9738 [00:17<00:03, 500.36it/s] 82%|███████████████████████████████████████████████████████████             | 7980/9738 [00:17<00:03, 502.13it/s] 82%|███████████████████████████████████████████████████████████▍            | 8031/9738 [00:17<00:03, 502.99it/s] 83%|███████████████████████████████████████████████████████████▊            | 8082/9738 [00:18<00:03, 501.64it/s] 84%|████████████████████████████████████████████████████████████▏           | 8133/9738 [00:18<00:03, 499.01it/s] 84%|████████████████████████████████████████████████████████████▌           | 8183/9738 [00:18<00:03, 499.10it/s] 85%|████████████████████████████████████████████████████████████▊           | 8233/9738 [00:18<00:03, 499.06it/s] 85%|█████████████████████████████████████████████████████████████▏          | 8284/9738 [00:18<00:02, 499.40it/s] 86%|█████████████████████████████████████████████████████████████▌          | 8334/9738 [00:18<00:02, 499.24it/s] 86%|█████████████████████████████████████████████████████████████▉          | 8384/9738 [00:18<00:02, 497.61it/s] 87%|██████████████████████████████████████████████████████████████▎         | 8434/9738 [00:18<00:02, 493.36it/s] 87%|██████████████████████████████████████████████████████████████▋         | 8484/9738 [00:18<00:02, 495.12it/s] 88%|███████████████████████████████████████████████████████████████         | 8534/9738 [00:18<00:02, 495.85it/s] 88%|███████████████████████████████████████████████████████████████▍        | 8584/9738 [00:19<00:02, 494.61it/s] 89%|███████████████████████████████████████████████████████████████▊        | 8634/9738 [00:19<00:02, 496.03it/s] 89%|████████████████████████████████████████████████████████████████▏       | 8684/9738 [00:19<00:02, 496.86it/s] 90%|████████████████████████████████████████████████████████████████▌       | 8734/9738 [00:19<00:02, 497.35it/s] 90%|████████████████████████████████████████████████████████████████▉       | 8784/9738 [00:19<00:01, 498.06it/s] 91%|█████████████████████████████████████████████████████████████████▎      | 8834/9738 [00:19<00:01, 474.79it/s] 91%|█████████████████████████████████████████████████████████████████▋      | 8884/9738 [00:19<00:01, 481.11it/s] 92%|██████████████████████████████████████████████████████████████████      | 8934/9738 [00:19<00:01, 485.80it/s] 92%|██████████████████████████████████████████████████████████████████▍     | 8984/9738 [00:19<00:01, 488.83it/s] 93%|██████████████████████████████████████████████████████████████████▊     | 9034/9738 [00:19<00:01, 489.24it/s] 93%|███████████████████████████████████████████████████████████████████▏    | 9084/9738 [00:20<00:01, 490.85it/s] 94%|███████████████████████████████████████████████████████████████████▌    | 9134/9738 [00:20<00:01, 488.21it/s] 94%|███████████████████████████████████████████████████████████████████▉    | 9184/9738 [00:20<00:01, 490.25it/s] 95%|████████████████████████████████████████████████████████████████████▎   | 9234/9738 [00:20<00:01, 491.87it/s] 95%|████████████████████████████████████████████████████████████████████▋   | 9284/9738 [00:20<00:00, 491.52it/s] 96%|█████████████████████████████████████████████████████████████████████   | 9334/9738 [00:20<00:00, 492.93it/s] 96%|█████████████████████████████████████████████████████████████████████▍  | 9384/9738 [00:20<00:00, 493.37it/s] 97%|█████████████████████████████████████████████████████████████████████▊  | 9434/9738 [00:20<00:00, 492.85it/s] 97%|██████████████████████████████████████████████████████████████████████  | 9484/9738 [00:20<00:00, 490.09it/s] 98%|██████████████████████████████████████████████████████████████████████▍ | 9534/9738 [00:20<00:00, 491.59it/s] 98%|██████████████████████████████████████████████████████████████████████▊ | 9584/9738 [00:21<00:00, 492.24it/s] 99%|███████████████████████████████████████████████████████████████████████▏| 9634/9738 [00:21<00:00, 493.34it/s] 99%|███████████████████████████████████████████████████████████████████████▌| 9684/9738 [00:21<00:00, 493.76it/s]100%|███████████████████████████████████████████████████████████████████████▉| 9734/9738 [00:21<00:00, 492.07it/s]100%|████████████████████████████████████████████████████████████████████████| 9738/9738 [00:21<00:00, 455.66it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:04<00:09,  4.95s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:10,  5.27s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:10,  5.47s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:11,  5.82s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:11,  5.63s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:09<00:04,  4.88s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:10<00:05,  5.18s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:10<00:05,  5.44s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:11<00:05,  5.70s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:11<00:05,  5.54s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.33s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.48s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.58s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.75s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.81s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.99s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.05s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.24s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.00s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.15s/it]
[2023-08-08 14:56:41,489] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-08 14:56:56,726] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-08 14:56:56,727] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-08 14:56:56,727] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-08 14:56:56,727] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-08 14:56:56,727] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-08 14:56:56,727] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fa3da94df40>
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fa3b58b7dc0>
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-08 14:56:56,728] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-08 14:56:56,729] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-08 14:56:56,729] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-08 14:56:56,729] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-08 14:56:56,729] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-08 14:56:56,729] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-08 14:56:56,729] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-08 14:56:56,729] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-08 14:56:56,729] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-08 14:56:56,729] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-08 14:56:56,729] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-08 14:56:56,729] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-08 14:56:56,729] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-08 14:56:56,729] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  4
[2023-08-08 14:56:56,729] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-08 14:56:56,729] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-08 14:56:56,729] [INFO] [config.py:1012:print]   world_size ................... 5
[2023-08-08 14:56:56,729] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-08 14:56:56,729] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-08 14:56:56,729] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-08 14:56:56,729] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-08 14:56:56,729] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 4, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Loading extension module utils...
Time to load utils op: 0.5773100852966309 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Time to load utils op: 0.5050535202026367 seconds
Evaluating commonsenseqa :   0%|                                                           | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following multiple choice question.

### Demonstration:
Input: He fantasied about getting a what while driving to work and the pros and cons of the extra responsibilities and benefits? Choices:  A: new car B: promotion C: boredom D: impatience E: pressure
Rationales: 1. The question talks about someone fantasizing about something while driving to work. This suggests that this person is thinking about something that has to do with his job or professional life.
2. The phrases "extra responsibilities and benefits" are key clues given in the problem. These typically apply to situations involving advancements or progressions in a professional setting.
3. Looking at the options, 'new car', 'boredom', 'impatience', and 'pressure' do not typically correlate with extra responsibilities and benefits at a workplace setting.
4. The only option left is 'promotion' which directly correlates with acquiring extra responsibilities and benefits in a work context.
5. Hence, the answer is B: Promotion.
Answer: B: promotion

Input: He was good at traditional science but excelled at social science, his favorite subject was what? Choices:  A: geography B: history studies C: math D: religion E: dancing
Rationales: The statement mentions that he was good at traditional science, which include areas like math, biology, chemistry but it distinctly mentions that he excelled in social science. 

The social sciences include fields like sociology, anthropology, economics, political science, and history. Out of the given options (geography, history studies, math, religion, and dancing), we can eliminate math because it's not a social science. 

We also eliminate dancing since it's not typically classified as a social science. 

That leaves us with geography, history studies, and religion. Even though all of these could technically be considered within the realm of social sciences, the statement said he "excelled at social science," suggesting the subject he favored most was within this area. 

Since the answer is provided as B: history studies, we can conclude that History is his favorite subject. This makes sense as history is a fundamental discipline within the social sciences.
Answer: B: history studies

Input: Jan wasn't very good at studying.  What might help him study better? Choices:  A: having a bigger brain B: headaches C: inspiration D: more intelligence E: understanding
Rationales: 1. The question asks what could help Jan study better. 
2. We can begin to analyze each answer. Option A, 'having a bigger brain' is not necessarily going to improve studying skills. The size of the brain does not determine its functionality or capability.
3. Option B, 'headaches' would generally make studying more difficult, not easier. It wouldn't improve studying skills.
4. Option C, 'inspiration,' can motivate someone to study, but the inspiration itself does not give the skills or understanding needed to study effectively.
5. Option E, 'understanding,' while closely related to studying, isn't necessarily what would improve Jan's studying. He could understand something but still not be good at studying as understanding involves comprehending what's already learned while studying involves learning new things.
6. This leaves us with option D,'more intelligence.' Being intelligent typically means that an individual can learn, understand, and apply knowledge effectively, which are all critical skills when studying. Consequently, if Jan were more intelligent, he might be better at studying. 
7. Therefore, the answer is D: more intelligence.
Answer: D: more intelligence

### Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i3-s42-rTrue
Loading extension module utils...
Time to load utils op: 0.5048935413360596 seconds
Loading extension module utils...
Time to load utils op: 0.5051257610321045 seconds
Loading extension module utils...
Time to load utils op: 0.5049736499786377 seconds
Evaluating commonsenseqa :   2%|█                                                  | 1/50 [00:39<31:58, 39.15s/it]Evaluating commonsenseqa :   4%|██                                                 | 2/50 [01:17<31:07, 38.90s/it]Evaluating commonsenseqa :   6%|███                                                | 3/50 [01:56<30:21, 38.75s/it]Evaluating commonsenseqa :   8%|████                                               | 4/50 [02:35<29:50, 38.93s/it]Evaluating commonsenseqa :  10%|█████                                              | 5/50 [03:14<29:05, 38.80s/it]Evaluating commonsenseqa :  12%|██████                                             | 6/50 [03:53<28:39, 39.07s/it]Evaluating commonsenseqa :  14%|███████▏                                           | 7/50 [04:32<27:53, 38.91s/it]Evaluating commonsenseqa :  16%|████████▏                                          | 8/50 [05:11<27:15, 38.93s/it]Evaluating commonsenseqa :  18%|█████████▏                                         | 9/50 [05:50<26:35, 38.90s/it]Evaluating commonsenseqa :  20%|██████████                                        | 10/50 [06:28<25:47, 38.68s/it]Evaluating commonsenseqa :  22%|███████████                                       | 11/50 [07:07<25:14, 38.84s/it]Evaluating commonsenseqa :  24%|████████████                                      | 12/50 [07:46<24:38, 38.91s/it]Evaluating commonsenseqa :  26%|█████████████                                     | 13/50 [08:25<23:56, 38.82s/it]Evaluating commonsenseqa :  28%|██████████████                                    | 14/50 [09:04<23:18, 38.85s/it]Evaluating commonsenseqa :  30%|███████████████                                   | 15/50 [09:42<22:31, 38.63s/it]Evaluating commonsenseqa :  32%|████████████████                                  | 16/50 [10:21<21:55, 38.69s/it]Evaluating commonsenseqa :  34%|█████████████████                                 | 17/50 [11:00<21:22, 38.87s/it]Evaluating commonsenseqa :  36%|██████████████████                                | 18/50 [11:39<20:41, 38.79s/it]Evaluating commonsenseqa :  38%|███████████████████                               | 19/50 [12:17<19:56, 38.61s/it]Evaluating commonsenseqa :  40%|████████████████████                              | 20/50 [12:55<19:15, 38.53s/it]Evaluating commonsenseqa :  42%|█████████████████████                             | 21/50 [13:34<18:41, 38.66s/it]Evaluating commonsenseqa :  44%|██████████████████████                            | 22/50 [14:12<17:57, 38.48s/it]Evaluating commonsenseqa :  46%|███████████████████████                           | 23/50 [14:51<17:18, 38.47s/it]Evaluating commonsenseqa :  48%|████████████████████████                          | 24/50 [15:28<16:35, 38.29s/it]Evaluating commonsenseqa :  50%|█████████████████████████                         | 25/50 [16:08<16:07, 38.72s/it]Evaluating commonsenseqa :  52%|██████████████████████████                        | 26/50 [16:32<13:41, 34.22s/it]Evaluating commonsenseqa :  54%|███████████████████████████                       | 27/50 [17:12<13:44, 35.85s/it]Evaluating commonsenseqa :  56%|████████████████████████████                      | 28/50 [17:51<13:29, 36.82s/it]Evaluating commonsenseqa :  58%|████████████████████████████▉                     | 29/50 [18:29<13:02, 37.25s/it]Evaluating commonsenseqa :  60%|██████████████████████████████                    | 30/50 [19:08<12:34, 37.74s/it]Evaluating commonsenseqa :  62%|███████████████████████████████                   | 31/50 [19:46<12:01, 37.99s/it]Evaluating commonsenseqa :  64%|████████████████████████████████                  | 32/50 [20:25<11:28, 38.26s/it]Evaluating commonsenseqa :  66%|█████████████████████████████████                 | 33/50 [20:57<10:15, 36.20s/it]Evaluating commonsenseqa :  68%|██████████████████████████████████                | 34/50 [21:35<09:48, 36.79s/it]Evaluating commonsenseqa :  70%|███████████████████████████████████               | 35/50 [22:13<09:18, 37.24s/it]Evaluating commonsenseqa :  72%|████████████████████████████████████              | 36/50 [22:51<08:45, 37.54s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████             | 37/50 [23:30<08:12, 37.86s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████            | 38/50 [24:08<07:35, 38.00s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████           | 39/50 [24:47<07:01, 38.29s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████          | 40/50 [25:26<06:24, 38.43s/it]Evaluating commonsenseqa :  82%|█████████████████████████████████████████         | 41/50 [26:04<05:45, 38.36s/it]Evaluating commonsenseqa :  84%|██████████████████████████████████████████        | 42/50 [26:43<05:07, 38.46s/it]Evaluating commonsenseqa :  86%|███████████████████████████████████████████       | 43/50 [27:22<04:30, 38.63s/it]Evaluating commonsenseqa :  88%|████████████████████████████████████████████      | 44/50 [28:01<03:53, 38.84s/it]Evaluating commonsenseqa :  90%|█████████████████████████████████████████████     | 45/50 [28:40<03:13, 38.68s/it]Evaluating commonsenseqa :  92%|██████████████████████████████████████████████    | 46/50 [29:18<02:34, 38.72s/it]Evaluating commonsenseqa :  94%|███████████████████████████████████████████████   | 47/50 [29:57<01:55, 38.61s/it]Evaluating commonsenseqa :  96%|████████████████████████████████████████████████  | 48/50 [30:35<01:16, 38.47s/it]Evaluating commonsenseqa :  98%|█████████████████████████████████████████████████ | 49/50 [31:13<00:38, 38.46s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████████████████████| 50/50 [31:52<00:00, 38.53s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████████████████████| 50/50 [31:52<00:00, 38.25s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 2.3136} | lm_loss 7.5091 | avg. gen lenth: 354.67
torchrun --nproc_per_node 5 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 5 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-out-domain 0 --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 4 --seed 42 --data-dir /scratch/ylu130/processed_data/commonsenseqa/in-domain/i4-s42-rTrue --rationales --num-in-domain 4
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 5
[2023-08-08 15:29:00,066] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 5
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/in-domain/i4-s42-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 4
  num_out_domain ............... 0
  out_domain_data_name ......... None
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i4-s42-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 4
  clip_grad .................... 1.0
  seed ......................... 42
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 5
Loading Data
  0%|                                                                                    | 0/9737 [00:00<?, ?it/s]  0%|▏                                                                         | 24/9737 [00:00<00:41, 234.46it/s]  0%|▎                                                                         | 48/9737 [00:00<00:41, 236.00it/s]  1%|▌                                                                         | 72/9737 [00:00<00:40, 236.43it/s]  1%|▋                                                                         | 96/9737 [00:00<00:40, 237.00it/s]  1%|▉                                                                        | 120/9737 [00:00<00:40, 237.31it/s]  1%|█                                                                        | 144/9737 [00:00<00:40, 237.21it/s]  2%|█▎                                                                       | 168/9737 [00:00<00:40, 237.35it/s]  2%|█▍                                                                       | 192/9737 [00:00<00:40, 237.14it/s]  2%|█▌                                                                       | 216/9737 [00:00<00:40, 235.16it/s]  2%|█▊                                                                       | 240/9737 [00:01<00:40, 235.74it/s]  3%|█▉                                                                       | 264/9737 [00:01<00:40, 236.09it/s]  3%|██▏                                                                      | 288/9737 [00:01<00:40, 236.16it/s]  3%|██▎                                                                      | 312/9737 [00:01<00:39, 236.31it/s]  3%|██▌                                                                      | 336/9737 [00:01<00:39, 235.97it/s]  4%|██▋                                                                      | 360/9737 [00:01<00:39, 235.99it/s]  4%|██▉                                                                      | 384/9737 [00:01<00:39, 236.28it/s]  4%|███                                                                      | 408/9737 [00:01<00:39, 236.13it/s]  4%|███▏                                                                     | 432/9737 [00:01<00:39, 233.96it/s]  5%|███▍                                                                     | 456/9737 [00:01<00:39, 234.64it/s]  5%|███▌                                                                     | 480/9737 [00:02<00:39, 234.73it/s]  5%|███▊                                                                     | 505/9737 [00:02<00:38, 236.99it/s]  5%|███▉                                                                     | 530/9737 [00:02<00:38, 239.40it/s]  6%|████▏                                                                    | 555/9737 [00:02<00:38, 240.95it/s]  6%|████▎                                                                    | 580/9737 [00:02<00:37, 242.30it/s]  6%|████▌                                                                    | 605/9737 [00:02<00:37, 243.19it/s]  6%|████▋                                                                    | 630/9737 [00:02<00:37, 243.92it/s]  7%|████▉                                                                    | 656/9737 [00:02<00:36, 248.32it/s]  7%|█████▏                                                                   | 694/9737 [00:02<00:31, 286.07it/s]  8%|█████▍                                                                   | 732/9737 [00:02<00:28, 312.05it/s]  8%|█████▊                                                                   | 770/9737 [00:03<00:27, 330.62it/s]  8%|██████                                                                   | 808/9737 [00:03<00:26, 343.42it/s]  9%|██████▎                                                                  | 846/9737 [00:03<00:25, 352.68it/s]  9%|██████▌                                                                  | 883/9737 [00:03<00:24, 357.30it/s]  9%|██████▉                                                                  | 921/9737 [00:03<00:24, 362.50it/s] 10%|███████▏                                                                 | 959/9737 [00:03<00:23, 365.85it/s] 10%|███████▍                                                                 | 996/9737 [00:03<00:24, 363.87it/s] 11%|███████▋                                                                | 1034/9737 [00:03<00:23, 366.33it/s] 11%|███████▉                                                                | 1072/9737 [00:03<00:23, 368.22it/s] 11%|████████▏                                                               | 1109/9737 [00:03<00:23, 367.83it/s] 12%|████████▍                                                               | 1147/9737 [00:04<00:23, 369.15it/s] 12%|████████▊                                                               | 1185/9737 [00:04<00:23, 370.05it/s] 13%|█████████                                                               | 1223/9737 [00:04<00:22, 370.34it/s] 13%|█████████▎                                                              | 1261/9737 [00:04<00:22, 371.17it/s] 13%|█████████▌                                                              | 1299/9737 [00:04<00:22, 371.51it/s] 14%|█████████▉                                                              | 1337/9737 [00:04<00:22, 369.49it/s] 14%|██████████▏                                                             | 1375/9737 [00:04<00:22, 370.03it/s] 15%|██████████▍                                                             | 1413/9737 [00:04<00:22, 370.40it/s] 15%|██████████▋                                                             | 1451/9737 [00:04<00:22, 370.79it/s] 15%|███████████                                                             | 1489/9737 [00:04<00:22, 370.77it/s] 16%|███████████▎                                                            | 1527/9737 [00:05<00:22, 370.77it/s] 16%|███████████▌                                                            | 1565/9737 [00:05<00:22, 369.19it/s] 16%|███████████▊                                                            | 1602/9737 [00:05<00:22, 369.36it/s] 17%|████████████▏                                                           | 1640/9737 [00:05<00:21, 370.15it/s] 17%|████████████▍                                                           | 1678/9737 [00:05<00:21, 370.47it/s] 18%|████████████▋                                                           | 1716/9737 [00:05<00:21, 370.60it/s] 18%|████████████▉                                                           | 1754/9737 [00:05<00:21, 370.15it/s] 18%|█████████████▎                                                          | 1792/9737 [00:05<00:22, 353.36it/s] 19%|█████████████▌                                                          | 1829/9737 [00:05<00:22, 357.70it/s] 19%|█████████████▊                                                          | 1866/9737 [00:06<00:21, 360.71it/s] 20%|██████████████                                                          | 1903/9737 [00:06<00:21, 363.11it/s] 20%|██████████████▎                                                         | 1940/9737 [00:06<00:21, 365.05it/s] 20%|██████████████▌                                                         | 1977/9737 [00:06<00:21, 366.36it/s] 21%|██████████████▉                                                         | 2014/9737 [00:06<00:21, 365.53it/s] 21%|███████████████▏                                                        | 2051/9737 [00:06<00:20, 366.43it/s] 21%|███████████████▍                                                        | 2088/9737 [00:06<00:20, 366.84it/s] 22%|███████████████▋                                                        | 2125/9737 [00:06<00:20, 367.66it/s] 22%|███████████████▉                                                        | 2162/9737 [00:06<00:20, 367.94it/s] 23%|████████████████▎                                                       | 2199/9737 [00:06<00:20, 368.04it/s] 23%|████████████████▌                                                       | 2236/9737 [00:07<00:20, 368.21it/s] 23%|████████████████▊                                                       | 2273/9737 [00:07<00:20, 366.51it/s] 24%|█████████████████                                                       | 2310/9737 [00:07<00:20, 367.18it/s] 24%|█████████████████▎                                                      | 2347/9737 [00:07<00:20, 367.41it/s] 24%|█████████████████▋                                                      | 2384/9737 [00:07<00:19, 367.96it/s] 25%|█████████████████▉                                                      | 2421/9737 [00:07<00:19, 368.56it/s] 25%|██████████████████▏                                                     | 2458/9737 [00:07<00:19, 365.27it/s] 26%|██████████████████▍                                                     | 2495/9737 [00:07<00:19, 364.04it/s] 26%|██████████████████▋                                                     | 2532/9737 [00:07<00:19, 365.21it/s] 26%|██████████████████▉                                                     | 2569/9737 [00:07<00:19, 366.22it/s] 27%|███████████████████▎                                                    | 2606/9737 [00:08<00:19, 367.34it/s] 27%|███████████████████▌                                                    | 2643/9737 [00:08<00:19, 367.16it/s] 28%|███████████████████▊                                                    | 2680/9737 [00:08<00:19, 367.22it/s] 28%|████████████████████                                                    | 2717/9737 [00:08<00:19, 365.70it/s] 28%|████████████████████▎                                                   | 2754/9737 [00:08<00:19, 366.71it/s] 29%|████████████████████▋                                                   | 2791/9737 [00:08<00:18, 367.06it/s] 29%|████████████████████▉                                                   | 2828/9737 [00:08<00:18, 367.35it/s] 29%|█████████████████████▏                                                  | 2865/9737 [00:08<00:18, 368.09it/s] 30%|█████████████████████▍                                                  | 2902/9737 [00:08<00:18, 368.27it/s] 30%|█████████████████████▋                                                  | 2939/9737 [00:08<00:18, 366.60it/s] 31%|██████████████████████                                                  | 2976/9737 [00:09<00:18, 367.24it/s] 31%|██████████████████████▎                                                 | 3013/9737 [00:09<00:18, 367.80it/s] 31%|██████████████████████▌                                                 | 3050/9737 [00:09<00:18, 367.59it/s] 32%|██████████████████████▊                                                 | 3087/9737 [00:09<00:18, 367.93it/s] 32%|███████████████████████                                                 | 3124/9737 [00:09<00:17, 368.21it/s] 32%|███████████████████████▎                                                | 3161/9737 [00:09<00:17, 366.36it/s] 33%|███████████████████████▋                                                | 3198/9737 [00:09<00:17, 365.11it/s] 33%|███████████████████████▉                                                | 3235/9737 [00:09<00:17, 366.43it/s] 34%|████████████████████████▏                                               | 3272/9737 [00:09<00:17, 367.47it/s] 34%|████████████████████████▍                                               | 3309/9737 [00:09<00:17, 367.93it/s] 34%|████████████████████████▋                                               | 3346/9737 [00:10<00:17, 368.17it/s] 35%|█████████████████████████                                               | 3383/9737 [00:10<00:17, 366.73it/s] 35%|█████████████████████████▎                                              | 3420/9737 [00:10<00:17, 367.02it/s] 36%|█████████████████████████▌                                              | 3457/9737 [00:10<00:17, 366.65it/s] 36%|█████████████████████████▊                                              | 3494/9737 [00:10<00:17, 366.76it/s] 36%|██████████████████████████                                              | 3531/9737 [00:10<00:16, 366.76it/s] 37%|██████████████████████████▍                                             | 3568/9737 [00:10<00:16, 367.27it/s] 37%|██████████████████████████▋                                             | 3605/9737 [00:10<00:16, 365.89it/s] 37%|██████████████████████████▉                                             | 3642/9737 [00:10<00:16, 367.01it/s] 38%|███████████████████████████▏                                            | 3679/9737 [00:10<00:16, 367.47it/s] 38%|███████████████████████████▍                                            | 3716/9737 [00:11<00:16, 367.91it/s] 39%|███████████████████████████▊                                            | 3753/9737 [00:11<00:16, 367.57it/s] 39%|████████████████████████████                                            | 3790/9737 [00:11<00:16, 367.89it/s] 39%|████████████████████████████▎                                           | 3828/9737 [00:11<00:16, 366.65it/s] 40%|████████████████████████████▌                                           | 3865/9737 [00:11<00:15, 367.38it/s] 40%|████████████████████████████▊                                           | 3902/9737 [00:11<00:15, 368.08it/s] 40%|█████████████████████████████▏                                          | 3939/9737 [00:11<00:15, 364.56it/s] 41%|█████████████████████████████▍                                          | 3976/9737 [00:11<00:15, 365.84it/s] 41%|█████████████████████████████▋                                          | 4013/9737 [00:11<00:15, 367.05it/s] 42%|█████████████████████████████▉                                          | 4050/9737 [00:11<00:15, 367.60it/s] 42%|██████████████████████████████▏                                         | 4087/9737 [00:12<00:15, 366.68it/s] 42%|██████████████████████████████▍                                         | 4124/9737 [00:12<00:15, 367.33it/s] 43%|██████████████████████████████▊                                         | 4161/9737 [00:12<00:15, 367.70it/s] 43%|███████████████████████████████                                         | 4198/9737 [00:12<00:15, 367.99it/s] 43%|███████████████████████████████▎                                        | 4235/9737 [00:12<00:14, 368.06it/s] 44%|███████████████████████████████▌                                        | 4272/9737 [00:12<00:15, 353.64it/s] 44%|███████████████████████████████▊                                        | 4309/9737 [00:12<00:15, 356.48it/s] 45%|████████████████████████████████▏                                       | 4346/9737 [00:12<00:14, 360.30it/s] 45%|████████████████████████████████▍                                       | 4383/9737 [00:12<00:14, 361.37it/s] 45%|████████████████████████████████▋                                       | 4420/9737 [00:12<00:14, 363.78it/s] 46%|████████████████████████████████▉                                       | 4457/9737 [00:13<00:14, 365.40it/s] 46%|█████████████████████████████████▏                                      | 4494/9737 [00:13<00:14, 365.87it/s] 47%|█████████████████████████████████▌                                      | 4531/9737 [00:13<00:15, 342.79it/s] 47%|█████████████████████████████████▊                                      | 4569/9737 [00:13<00:14, 351.77it/s] 47%|██████████████████████████████████                                      | 4607/9737 [00:13<00:14, 358.45it/s] 48%|██████████████████████████████████▎                                     | 4645/9737 [00:13<00:14, 362.99it/s] 48%|██████████████████████████████████▋                                     | 4683/9737 [00:13<00:13, 366.43it/s] 48%|██████████████████████████████████▉                                     | 4721/9737 [00:13<00:13, 368.48it/s] 49%|███████████████████████████████████▏                                    | 4758/9737 [00:14<00:18, 271.70it/s] 49%|███████████████████████████████████▍                                    | 4796/9737 [00:14<00:16, 296.26it/s] 50%|███████████████████████████████████▋                                    | 4834/9737 [00:14<00:15, 315.99it/s] 50%|████████████████████████████████████                                    | 4871/9737 [00:14<00:14, 329.51it/s] 50%|████████████████████████████████████▎                                   | 4908/9737 [00:14<00:14, 340.38it/s] 51%|████████████████████████████████████▌                                   | 4945/9737 [00:14<00:13, 347.09it/s] 51%|████████████████████████████████████▊                                   | 4982/9737 [00:14<00:13, 353.28it/s] 52%|█████████████████████████████████████                                   | 5019/9737 [00:14<00:13, 357.79it/s] 52%|█████████████████████████████████████▍                                  | 5056/9737 [00:14<00:12, 361.07it/s] 52%|█████████████████████████████████████▋                                  | 5093/9737 [00:14<00:12, 363.09it/s] 53%|█████████████████████████████████████▉                                  | 5130/9737 [00:15<00:12, 364.50it/s] 53%|██████████████████████████████████████▏                                 | 5167/9737 [00:15<00:12, 363.90it/s] 53%|██████████████████████████████████████▍                                 | 5204/9737 [00:15<00:12, 364.84it/s] 54%|██████████████████████████████████████▊                                 | 5241/9737 [00:15<00:12, 365.43it/s] 54%|███████████████████████████████████████                                 | 5278/9737 [00:15<00:12, 365.91it/s] 55%|███████████████████████████████████████▎                                | 5315/9737 [00:15<00:12, 366.33it/s] 55%|███████████████████████████████████████▌                                | 5352/9737 [00:15<00:12, 363.28it/s] 55%|███████████████████████████████████████▊                                | 5389/9737 [00:15<00:11, 364.57it/s] 56%|████████████████████████████████████████                                | 5426/9737 [00:15<00:11, 364.04it/s] 56%|████████████████████████████████████████▍                               | 5463/9737 [00:15<00:11, 365.59it/s] 56%|████████████████████████████████████████▋                               | 5501/9737 [00:16<00:11, 369.22it/s] 57%|████████████████████████████████████████▉                               | 5540/9737 [00:16<00:11, 372.64it/s] 57%|█████████████████████████████████████████▎                              | 5579/9737 [00:16<00:11, 374.89it/s] 58%|█████████████████████████████████████████▌                              | 5617/9737 [00:16<00:10, 376.23it/s] 58%|█████████████████████████████████████████▊                              | 5655/9737 [00:16<00:10, 375.58it/s] 58%|██████████████████████████████████████████                              | 5694/9737 [00:16<00:10, 377.07it/s] 59%|██████████████████████████████████████████▍                             | 5733/9737 [00:16<00:10, 378.46it/s] 59%|██████████████████████████████████████████▋                             | 5772/9737 [00:16<00:10, 379.20it/s] 60%|██████████████████████████████████████████▉                             | 5811/9737 [00:16<00:10, 379.52it/s] 60%|███████████████████████████████████████████▎                            | 5849/9737 [00:16<00:10, 377.64it/s] 60%|███████████████████████████████████████████▌                            | 5888/9737 [00:17<00:10, 378.57it/s] 61%|███████████████████████████████████████████▊                            | 5927/9737 [00:17<00:10, 379.26it/s] 61%|████████████████████████████████████████████                            | 5966/9737 [00:17<00:09, 379.65it/s] 62%|████████████████████████████████████████████▍                           | 6004/9737 [00:17<00:09, 379.71it/s] 62%|████████████████████████████████████████████▋                           | 6043/9737 [00:17<00:09, 380.16it/s] 62%|████████████████████████████████████████████▉                           | 6082/9737 [00:17<00:09, 378.29it/s] 63%|█████████████████████████████████████████████▎                          | 6121/9737 [00:17<00:09, 378.97it/s] 63%|█████████████████████████████████████████████▌                          | 6159/9737 [00:17<00:09, 379.16it/s] 64%|█████████████████████████████████████████████▊                          | 6198/9737 [00:17<00:09, 379.49it/s] 64%|██████████████████████████████████████████████                          | 6236/9737 [00:18<00:09, 379.50it/s] 64%|██████████████████████████████████████████████▍                         | 6275/9737 [00:18<00:09, 379.72it/s] 65%|██████████████████████████████████████████████▋                         | 6313/9737 [00:18<00:09, 378.07it/s] 65%|██████████████████████████████████████████████▉                         | 6352/9737 [00:18<00:08, 378.76it/s] 66%|███████████████████████████████████████████████▎                        | 6391/9737 [00:18<00:08, 379.65it/s] 66%|███████████████████████████████████████████████▌                        | 6430/9737 [00:18<00:08, 380.07it/s] 66%|███████████████████████████████████████████████▊                        | 6469/9737 [00:18<00:08, 380.57it/s] 67%|████████████████████████████████████████████████                        | 6508/9737 [00:18<00:08, 382.08it/s] 67%|████████████████████████████████████████████████▍                       | 6547/9737 [00:18<00:08, 381.21it/s] 68%|████████████████████████████████████████████████▋                       | 6586/9737 [00:18<00:08, 382.45it/s] 68%|████████████████████████████████████████████████▉                       | 6625/9737 [00:19<00:08, 383.37it/s] 68%|█████████████████████████████████████████████████▎                      | 6664/9737 [00:19<00:07, 384.16it/s] 69%|█████████████████████████████████████████████████▌                      | 6703/9737 [00:19<00:07, 384.17it/s] 69%|█████████████████████████████████████████████████▊                      | 6742/9737 [00:19<00:07, 384.80it/s] 70%|██████████████████████████████████████████████████▏                     | 6781/9737 [00:19<00:07, 383.26it/s] 70%|██████████████████████████████████████████████████▍                     | 6820/9737 [00:19<00:07, 383.92it/s] 70%|██████████████████████████████████████████████████▋                     | 6859/9737 [00:19<00:07, 381.22it/s] 71%|███████████████████████████████████████████████████                     | 6898/9737 [00:19<00:07, 382.48it/s] 71%|███████████████████████████████████████████████████▎                    | 6937/9737 [00:19<00:07, 383.42it/s] 72%|███████████████████████████████████████████████████▌                    | 6976/9737 [00:19<00:07, 384.04it/s] 72%|███████████████████████████████████████████████████▊                    | 7015/9737 [00:20<00:07, 382.53it/s] 72%|████████████████████████████████████████████████████▏                   | 7054/9737 [00:20<00:06, 383.62it/s] 73%|████████████████████████████████████████████████████▍                   | 7093/9737 [00:20<00:06, 384.23it/s] 73%|████████████████████████████████████████████████████▋                   | 7132/9737 [00:20<00:06, 384.89it/s] 74%|█████████████████████████████████████████████████████                   | 7171/9737 [00:20<00:06, 384.77it/s] 74%|█████████████████████████████████████████████████████▎                  | 7210/9737 [00:20<00:06, 381.58it/s] 74%|█████████████████████████████████████████████████████▌                  | 7249/9737 [00:20<00:06, 381.03it/s] 75%|█████████████████████████████████████████████████████▉                  | 7288/9737 [00:20<00:06, 380.84it/s] 75%|██████████████████████████████████████████████████████▏                 | 7327/9737 [00:20<00:06, 380.56it/s] 76%|██████████████████████████████████████████████████████▍                 | 7366/9737 [00:20<00:06, 380.66it/s] 76%|██████████████████████████████████████████████████████▊                 | 7405/9737 [00:21<00:06, 380.31it/s] 76%|███████████████████████████████████████████████████████                 | 7444/9737 [00:21<00:06, 356.45it/s] 77%|███████████████████████████████████████████████████████▎                | 7482/9737 [00:21<00:06, 362.73it/s] 77%|███████████████████████████████████████████████████████▌                | 7520/9737 [00:21<00:06, 367.21it/s] 78%|███████████████████████████████████████████████████████▉                | 7558/9737 [00:21<00:05, 370.86it/s] 78%|████████████████████████████████████████████████████████▏               | 7597/9737 [00:21<00:05, 373.79it/s] 78%|████████████████████████████████████████████████████████▍               | 7636/9737 [00:21<00:05, 375.73it/s] 79%|████████████████████████████████████████████████████████▋               | 7674/9737 [00:21<00:05, 376.32it/s] 79%|█████████████████████████████████████████████████████████               | 7713/9737 [00:21<00:05, 379.26it/s] 80%|█████████████████████████████████████████████████████████▎              | 7752/9737 [00:22<00:05, 381.31it/s] 80%|█████████████████████████████████████████████████████████▌              | 7791/9737 [00:22<00:05, 382.57it/s] 80%|█████████████████████████████████████████████████████████▉              | 7830/9737 [00:22<00:04, 383.44it/s] 81%|██████████████████████████████████████████████████████████▏             | 7869/9737 [00:22<00:04, 384.18it/s] 81%|██████████████████████████████████████████████████████████▍             | 7908/9737 [00:22<00:04, 383.19it/s] 82%|██████████████████████████████████████████████████████████▊             | 7947/9737 [00:22<00:04, 383.87it/s] 82%|███████████████████████████████████████████████████████████             | 7986/9737 [00:22<00:04, 384.38it/s] 82%|███████████████████████████████████████████████████████████▎            | 8025/9737 [00:22<00:04, 384.70it/s] 83%|███████████████████████████████████████████████████████████▋            | 8064/9737 [00:22<00:04, 384.72it/s] 83%|███████████████████████████████████████████████████████████▉            | 8103/9737 [00:22<00:04, 373.84it/s] 84%|████████████████████████████████████████████████████████████▏           | 8141/9737 [00:23<00:04, 375.53it/s] 84%|████████████████████████████████████████████████████████████▍           | 8180/9737 [00:23<00:04, 378.46it/s] 84%|████████████████████████████████████████████████████████████▊           | 8219/9737 [00:23<00:03, 380.78it/s] 85%|█████████████████████████████████████████████████████████████           | 8258/9737 [00:23<00:03, 382.35it/s] 85%|█████████████████████████████████████████████████████████████▎          | 8297/9737 [00:23<00:03, 383.06it/s] 86%|█████████████████████████████████████████████████████████████▋          | 8336/9737 [00:23<00:03, 384.09it/s] 86%|█████████████████████████████████████████████████████████████▉          | 8375/9737 [00:23<00:03, 380.38it/s] 86%|██████████████████████████████████████████████████████████████▏         | 8414/9737 [00:23<00:03, 381.98it/s] 87%|██████████████████████████████████████████████████████████████▌         | 8453/9737 [00:23<00:03, 383.13it/s] 87%|██████████████████████████████████████████████████████████████▊         | 8492/9737 [00:23<00:03, 384.10it/s] 88%|███████████████████████████████████████████████████████████████         | 8531/9737 [00:24<00:03, 384.48it/s] 88%|███████████████████████████████████████████████████████████████▎        | 8570/9737 [00:24<00:03, 384.88it/s] 88%|███████████████████████████████████████████████████████████████▋        | 8609/9737 [00:24<00:02, 382.89it/s] 89%|███████████████████████████████████████████████████████████████▉        | 8648/9737 [00:24<00:02, 383.77it/s] 89%|████████████████████████████████████████████████████████████████▏       | 8687/9737 [00:24<00:02, 384.25it/s] 90%|████████████████████████████████████████████████████████████████▌       | 8726/9737 [00:24<00:02, 384.65it/s] 90%|████████████████████████████████████████████████████████████████▊       | 8765/9737 [00:24<00:02, 384.88it/s] 90%|█████████████████████████████████████████████████████████████████       | 8804/9737 [00:24<00:02, 383.07it/s] 91%|█████████████████████████████████████████████████████████████████▍      | 8843/9737 [00:24<00:02, 383.88it/s] 91%|█████████████████████████████████████████████████████████████████▋      | 8882/9737 [00:24<00:02, 384.42it/s] 92%|█████████████████████████████████████████████████████████████████▉      | 8921/9737 [00:25<00:02, 385.08it/s] 92%|██████████████████████████████████████████████████████████████████▎     | 8960/9737 [00:25<00:02, 385.29it/s] 92%|██████████████████████████████████████████████████████████████████▌     | 8999/9737 [00:25<00:01, 385.30it/s] 93%|██████████████████████████████████████████████████████████████████▊     | 9038/9737 [00:25<00:01, 383.30it/s] 93%|███████████████████████████████████████████████████████████████████     | 9077/9737 [00:25<00:01, 384.00it/s] 94%|███████████████████████████████████████████████████████████████████▍    | 9116/9737 [00:25<00:01, 384.42it/s] 94%|███████████████████████████████████████████████████████████████████▋    | 9155/9737 [00:25<00:01, 384.88it/s] 94%|███████████████████████████████████████████████████████████████████▉    | 9194/9737 [00:25<00:01, 385.06it/s] 95%|████████████████████████████████████████████████████████████████████▎   | 9233/9737 [00:25<00:01, 385.10it/s] 95%|████████████████████████████████████████████████████████████████████▌   | 9272/9737 [00:25<00:01, 383.72it/s] 96%|████████████████████████████████████████████████████████████████████▊   | 9311/9737 [00:26<00:01, 384.29it/s] 96%|█████████████████████████████████████████████████████████████████████▏  | 9350/9737 [00:26<00:01, 384.69it/s] 96%|█████████████████████████████████████████████████████████████████████▍  | 9389/9737 [00:26<00:00, 385.06it/s] 97%|█████████████████████████████████████████████████████████████████████▋  | 9428/9737 [00:26<00:00, 384.59it/s] 97%|██████████████████████████████████████████████████████████████████████  | 9467/9737 [00:26<00:00, 384.22it/s] 98%|██████████████████████████████████████████████████████████████████████▎ | 9506/9737 [00:26<00:00, 382.83it/s] 98%|██████████████████████████████████████████████████████████████████████▌ | 9545/9737 [00:26<00:00, 383.74it/s] 98%|██████████████████████████████████████████████████████████████████████▊ | 9584/9737 [00:26<00:00, 384.12it/s] 99%|███████████████████████████████████████████████████████████████████████▏| 9623/9737 [00:26<00:00, 384.58it/s] 99%|███████████████████████████████████████████████████████████████████████▍| 9662/9737 [00:26<00:00, 384.79it/s]100%|███████████████████████████████████████████████████████████████████████▋| 9701/9737 [00:27<00:00, 384.54it/s]100%|████████████████████████████████████████████████████████████████████████| 9737/9737 [00:27<00:00, 358.24it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:11,  5.64s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:11,  5.73s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:11,  5.94s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:06<00:12,  6.21s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:07<00:15,  7.71s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:11<00:05,  5.74s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:11<00:05,  5.79s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:11<00:05,  5.86s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:11<00:05,  5.88s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:13<00:06,  6.66s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:16<00:00,  5.21s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:16<00:00,  5.39s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:16<00:00,  5.24s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:16<00:00,  5.36s/it]
[2023-08-08 15:30:20,996] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:16<00:00,  5.27s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:16<00:00,  5.40s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:16<00:00,  5.09s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:16<00:00,  5.34s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:18<00:00,  5.95s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:18<00:00,  6.25s/it]
[2023-08-08 15:30:36,816] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-08 15:30:36,817] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-08 15:30:36,817] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-08 15:30:36,817] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-08 15:30:36,817] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-08 15:30:36,817] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-08 15:30:36,817] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-08 15:30:36,817] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-08 15:30:36,817] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-08 15:30:36,817] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-08 15:30:36,817] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-08 15:30:36,817] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f6817c91f40>
[2023-08-08 15:30:36,817] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-08 15:30:36,817] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-08 15:30:36,817] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-08 15:30:36,817] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-08 15:30:36,817] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-08 15:30:36,817] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-08 15:30:36,817] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-08 15:30:36,817] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-08 15:30:36,817] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-08 15:30:36,817] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-08 15:30:36,817] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-08 15:30:36,817] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-08 15:30:36,817] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-08 15:30:36,817] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-08 15:30:36,817] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-08 15:30:36,817] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-08 15:30:36,817] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-08 15:30:36,817] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-08 15:30:36,817] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f68275c3dc0>
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  4
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   world_size ................... 5
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-08 15:30:36,818] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-08 15:30:36,818] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 4, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.6272192001342773 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                           | 0/50 [00:00<?, ?it/s]############### Example ###############
Loading extension module utils...
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following multiple choice question.

### Demonstration:
Input: He fantasied about getting a what while driving to work and the pros and cons of the extra responsibilities and benefits? Choices:  A: new car B: promotion C: boredom D: impatience E: pressure
Rationales: 1. The question refers to someone fantasizing about something while driving to work, so the answer is likely related to work.
2. The mention of "extra responsibilities" and "benefits" suggest that the answer should involve an increase in status or role. This further supports that the answer would be related to the person's job.
3. Options A, C, D, and E do not directly connect to the concepts of work, responsibilities, and benefits.
4. E: "pressure" does relate to work, but it doesn't suggest an increase in roles or benefits. Instead, it relates to stress or overwork.
5. Only option B, which is "promotion," properly fits all aspects of the question. A promotion at work often comes with both increased responsibilities and benefits, and it is something one might fantasize about on the way to work.
6. Hence, the answer is B: promotion.
Answer: B: promotion

Input: He was good at traditional science but excelled at social science, his favorite subject was what? Choices:  A: geography B: history studies C: math D: religion E: dancing
Rationales: 1. The question provides information about the person's academic preferences. 
2. It is mentioned that he was good at traditional science but this isn't his favorite subject.
3. Then it is mentioned that he excelled at social science. So, we can rule out choices that are outside the field of social science such as geography and math.
4. From the remaining choices, religion and history studies are considered social sciences.
5. However, it is also mentioned that his favorite subject was what he excelled at, and if we assume traditional science to refer to natural sciences, this rules out "religion" because theoretical studies about religion is not a natural or traditional science.
6. Hence, by process of elimination and contextual clues, we can infer that his favorite subject was "B: history studies".
Answer: B: history studies

Input: Jan wasn't very good at studying.  What might help him study better? Choices:  A: having a bigger brain B: headaches C: inspiration D: more intelligence E: understanding
Rationales: 1. Let's analyze each choice in relation to Jan's capacity to study better.
2. Option A: A bigger brain does not necessarily correlate with better studying skills. The size of the brain does not directly impact one's capacity to study.
3. Option B: Headaches would likely hinder studying rather than enhance it. Pain and discomfort normally distract from focus, which is essential for effective learning.
4. Option C: While inspiration might motivate Jan to study, it does not inherently improve his ability to understand or recall the information, which are important aspects of studying.
5. Option D: More intelligence could potentially help Jan study better. Increased intelligence often comes with improved comprehension, memory, and problem-solving abilities, which are crucial for studying effectively.
6. Option E: Understanding is a part of studying, not something that improves studying. It's a result, not a tool. 
7. Therefore, after analyzing all the options, we can confirm that the most suitable choice is 'D: more intelligence'.
Answer: D: more intelligence

Input: The cat was wild but like all others he was always read for a cat what? Choices:  A: stealing B: four legs C: tuna fish D: food now E: nap
Rationales: 1. The question or sentence provided is talking about a cat in general.
2. The term "wild" depicts the cat's natural behavior or instincts.
3. The structure of the question suggests that it's looking for a behavior or characteristic that is common to all cats.
4. The options given are A: stealing B: four legs C: tuna fish D: food now E: nap. 
5. Although all cats have four legs, this is not a behavior but a physical characteristic.
6. Cats do often like to eat fish, including tuna, but not all cats universally exhibit this behavior as some might be allergic to fish or simply not like it.
7. "Stealing" isn't a universal cat behavior, even though some cats might occasionally exhibit this kind of behavior.
8. Although cats do eat food, the phrase "food now" doesn't fit well within the context of the question.
9. However, all cats do take naps, as it's a universal behavior for this species.
10. So, out of all the options given, the only one that correctly fits the context and represents a universal cat behavior is E: nap. Hence, nap is the right answer.
Answer: E: nap

### Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i4-s42-rTrue
Time to load utils op: 0.6052207946777344 seconds
Loading extension module utils...
Time to load utils op: 0.604874849319458 seconds
Loading extension module utils...
Time to load utils op: 0.7054023742675781 seconds
Loading extension module utils...
Time to load utils op: 0.705625057220459 seconds
Evaluating commonsenseqa :   2%|█                                                  | 1/50 [00:37<30:20, 37.16s/it]Evaluating commonsenseqa :   4%|██                                                 | 2/50 [01:13<29:11, 36.50s/it]Evaluating commonsenseqa :   6%|███                                                | 3/50 [01:49<28:28, 36.35s/it]Evaluating commonsenseqa :   8%|████                                               | 4/50 [02:18<25:46, 33.61s/it]Evaluating commonsenseqa :  10%|█████                                              | 5/50 [02:49<24:23, 32.53s/it]Evaluating commonsenseqa :  12%|██████                                             | 6/50 [03:16<22:23, 30.53s/it]Evaluating commonsenseqa :  14%|███████▏                                           | 7/50 [03:53<23:24, 32.67s/it]Evaluating commonsenseqa :  16%|████████▏                                          | 8/50 [04:29<23:37, 33.74s/it]Evaluating commonsenseqa :  18%|█████████▏                                         | 9/50 [05:05<23:33, 34.46s/it]Evaluating commonsenseqa :  20%|██████████                                        | 10/50 [05:41<23:18, 34.96s/it]Evaluating commonsenseqa :  22%|███████████                                       | 11/50 [06:17<23:00, 35.40s/it]Evaluating commonsenseqa :  24%|████████████                                      | 12/50 [06:53<22:32, 35.60s/it]Evaluating commonsenseqa :  26%|█████████████                                     | 13/50 [07:30<22:13, 36.04s/it]Evaluating commonsenseqa :  28%|██████████████                                    | 14/50 [07:45<17:42, 29.51s/it]Evaluating commonsenseqa :  30%|███████████████                                   | 15/50 [08:10<16:28, 28.23s/it]Evaluating commonsenseqa :  32%|████████████████                                  | 16/50 [08:47<17:29, 30.86s/it]Evaluating commonsenseqa :  34%|█████████████████                                 | 17/50 [09:24<17:55, 32.60s/it]Evaluating commonsenseqa :  36%|██████████████████                                | 18/50 [10:00<17:56, 33.64s/it]Evaluating commonsenseqa :  38%|███████████████████                               | 19/50 [10:36<17:48, 34.46s/it]Evaluating commonsenseqa :  40%|████████████████████                              | 20/50 [11:12<17:30, 35.00s/it]Evaluating commonsenseqa :  42%|█████████████████████                             | 21/50 [11:46<16:40, 34.50s/it]Evaluating commonsenseqa :  44%|██████████████████████                            | 22/50 [12:22<16:20, 35.02s/it]Evaluating commonsenseqa :  46%|███████████████████████                           | 23/50 [12:59<16:02, 35.63s/it]Evaluating commonsenseqa :  48%|████████████████████████                          | 24/50 [13:24<14:06, 32.55s/it]Evaluating commonsenseqa :  50%|█████████████████████████                         | 25/50 [14:01<14:02, 33.70s/it]Evaluating commonsenseqa :  52%|██████████████████████████                        | 26/50 [14:38<13:51, 34.64s/it]Evaluating commonsenseqa :  54%|███████████████████████████                       | 27/50 [14:55<11:15, 29.38s/it]Evaluating commonsenseqa :  56%|████████████████████████████                      | 28/50 [15:31<11:30, 31.39s/it]Evaluating commonsenseqa :  58%|████████████████████████████▉                     | 29/50 [16:07<11:31, 32.91s/it]Evaluating commonsenseqa :  60%|██████████████████████████████                    | 30/50 [16:44<11:23, 34.17s/it]Evaluating commonsenseqa :  62%|███████████████████████████████                   | 31/50 [17:21<11:01, 34.84s/it]Evaluating commonsenseqa :  64%|████████████████████████████████                  | 32/50 [17:57<10:33, 35.19s/it]Evaluating commonsenseqa :  66%|█████████████████████████████████                 | 33/50 [18:34<10:08, 35.79s/it]Evaluating commonsenseqa :  68%|██████████████████████████████████                | 34/50 [19:10<09:33, 35.86s/it]Evaluating commonsenseqa :  70%|███████████████████████████████████               | 35/50 [19:47<09:01, 36.09s/it]Evaluating commonsenseqa :  72%|████████████████████████████████████              | 36/50 [20:17<08:01, 34.43s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████             | 37/50 [20:54<07:36, 35.10s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████            | 38/50 [21:12<06:01, 30.13s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████           | 39/50 [21:42<05:30, 30.08s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████          | 40/50 [22:19<05:20, 32.08s/it]Evaluating commonsenseqa :  82%|█████████████████████████████████████████         | 41/50 [22:56<05:02, 33.62s/it]Evaluating commonsenseqa :  84%|██████████████████████████████████████████        | 42/50 [23:33<04:36, 34.53s/it]Evaluating commonsenseqa :  86%|███████████████████████████████████████████       | 43/50 [24:10<04:06, 35.27s/it]Evaluating commonsenseqa :  88%|████████████████████████████████████████████      | 44/50 [24:46<03:32, 35.46s/it]Evaluating commonsenseqa :  90%|█████████████████████████████████████████████     | 45/50 [25:24<03:00, 36.17s/it]Evaluating commonsenseqa :  92%|██████████████████████████████████████████████    | 46/50 [25:58<02:22, 35.72s/it]Evaluating commonsenseqa :  94%|███████████████████████████████████████████████   | 47/50 [26:34<01:47, 35.84s/it]Evaluating commonsenseqa :  96%|████████████████████████████████████████████████  | 48/50 [27:11<01:12, 36.07s/it]Evaluating commonsenseqa :  98%|█████████████████████████████████████████████████ | 49/50 [27:48<00:36, 36.25s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████████████████████| 50/50 [28:24<00:00, 36.33s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████████████████████| 50/50 [28:24<00:00, 34.09s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 2.8419} | lm_loss 7.4952 | avg. gen lenth: 302.59
torchrun --nproc_per_node 5 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 5 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-out-domain 0 --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 4 --seed 42 --data-dir /scratch/ylu130/processed_data/commonsenseqa/in-domain/i1-s42-rFalse --num-in-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 5
[2023-08-08 16:00:53,376] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 5
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/in-domain/i1-s42-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 1
  num_out_domain ............... 0
  out_domain_data_name ......... None
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i1-s42-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 4
  clip_grad .................... 1.0
  seed ......................... 42
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 5
Loading Data
  0%|                                                                                    | 0/9740 [00:00<?, ?it/s]  2%|█▌                                                                      | 207/9740 [00:00<00:04, 2062.16it/s]  4%|███                                                                     | 420/9740 [00:00<00:04, 2100.31it/s]  6%|████▋                                                                   | 633/9740 [00:00<00:04, 2109.19it/s]  9%|██████▎                                                                 | 848/9740 [00:00<00:04, 2121.88it/s] 11%|███████▋                                                               | 1062/9740 [00:00<00:04, 2128.23it/s] 13%|█████████▎                                                             | 1275/9740 [00:00<00:03, 2126.23it/s] 15%|██████████▊                                                            | 1488/9740 [00:00<00:03, 2123.99it/s] 17%|████████████▍                                                          | 1701/9740 [00:00<00:03, 2122.62it/s] 20%|█████████████▉                                                         | 1914/9740 [00:00<00:03, 2094.52it/s] 22%|███████████████▍                                                       | 2124/9740 [00:01<00:03, 2095.16it/s] 24%|█████████████████                                                      | 2337/9740 [00:01<00:03, 2105.39it/s] 26%|██████████████████▌                                                    | 2551/9740 [00:01<00:03, 2113.16it/s] 28%|████████████████████▏                                                  | 2763/9740 [00:01<00:03, 2114.11it/s] 31%|█████████████████████▋                                                 | 2976/9740 [00:01<00:03, 2118.76it/s] 33%|███████████████████████▎                                               | 3190/9740 [00:01<00:03, 2123.27it/s] 35%|████████████████████████▊                                              | 3403/9740 [00:01<00:02, 2123.99it/s] 37%|██████████████████████████▎                                            | 3616/9740 [00:01<00:02, 2119.32it/s] 39%|███████████████████████████▉                                           | 3829/9740 [00:01<00:02, 2122.07it/s] 42%|█████████████████████████████▍                                         | 4044/9740 [00:01<00:02, 2127.70it/s] 44%|███████████████████████████████                                        | 4257/9740 [00:02<00:02, 2121.63it/s] 46%|████████████████████████████████▌                                      | 4470/9740 [00:02<00:02, 2118.07it/s] 48%|██████████████████████████████████▏                                    | 4682/9740 [00:02<00:02, 2076.63it/s] 50%|███████████████████████████████████▋                                   | 4890/9740 [00:02<00:02, 1660.90it/s] 54%|██████████████████████████████████████                                 | 5226/9740 [00:02<00:02, 2087.62it/s] 57%|████████████████████████████████████████▌                              | 5567/9740 [00:02<00:01, 2435.72it/s] 61%|███████████████████████████████████████████▏                           | 5919/9740 [00:02<00:01, 2730.94it/s] 64%|█████████████████████████████████████████████▋                         | 6272/9740 [00:02<00:01, 2954.03it/s] 68%|████████████████████████████████████████████████▎                      | 6622/9740 [00:02<00:01, 3109.66it/s] 72%|██████████████████████████████████████████████████▊                    | 6977/9740 [00:03<00:00, 3236.39it/s] 75%|█████████████████████████████████████████████████████▍                 | 7331/9740 [00:03<00:00, 3325.21it/s] 79%|███████████████████████████████████████████████████████▉               | 7670/9740 [00:03<00:00, 3343.46it/s] 82%|██████████████████████████████████████████████████████████▌            | 8026/9740 [00:03<00:00, 3404.92it/s] 86%|█████████████████████████████████████████████████████████████          | 8380/9740 [00:03<00:00, 3443.20it/s] 90%|███████████████████████████████████████████████████████████████▋       | 8734/9740 [00:03<00:00, 3471.26it/s] 93%|██████████████████████████████████████████████████████████████████▏    | 9087/9740 [00:03<00:00, 3486.60it/s] 97%|████████████████████████████████████████████████████████████████████▊  | 9437/9740 [00:03<00:00, 3461.43it/s]100%|███████████████████████████████████████████████████████████████████████| 9740/9740 [00:03<00:00, 2565.88it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:11,  5.76s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:11,  5.85s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:11,  5.94s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:11,  5.93s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:06<00:12,  6.33s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:11<00:05,  5.53s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:11<00:05,  5.67s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:11<00:05,  5.95s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:12<00:06,  6.44s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:12<00:06,  6.25s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:15<00:00,  4.85s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.06s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:15<00:00,  4.96s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.18s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.09s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.32s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:16<00:00,  5.38s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:16<00:00,  5.61s/it]
[2023-08-08 16:01:51,712] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:17<00:00,  5.45s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:17<00:00,  5.68s/it]
[2023-08-08 16:02:07,635] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-08 16:02:07,635] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-08 16:02:07,636] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-08 16:02:07,636] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-08 16:02:07,636] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-08 16:02:07,636] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-08 16:02:07,636] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-08 16:02:07,636] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-08 16:02:07,636] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-08 16:02:07,636] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-08 16:02:07,636] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-08 16:02:07,636] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f0ab381ef40>
[2023-08-08 16:02:07,636] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-08 16:02:07,636] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-08 16:02:07,636] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-08 16:02:07,636] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-08 16:02:07,636] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-08 16:02:07,636] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f0ab9362dc0>
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  4
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   world_size ................... 5
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-08 16:02:07,637] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-08 16:02:07,637] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 4, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.3408687114715576 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Loading extension module utils...
Evaluating commonsenseqa :   0%|                                                           | 0/50 [00:00<?, ?it/s]Time to load utils op: 0.2040872573852539 seconds
############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following multiple choice question.

### Demonstration:
Input: He fantasied about getting a what while driving to work and the pros and cons of the extra responsibilities and benefits? Choices:  A: new car B: promotion C: boredom D: impatience E: pressure
Answer: B: promotion

### Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i1-s42-rFalse
Loading extension module utils...
Time to load utils op: 0.3043699264526367 seconds
Loading extension module utils...
Time to load utils op: 0.3045797348022461 seconds
Loading extension module utils...
Time to load utils op: 0.30430173873901367 seconds
Evaluating commonsenseqa :   2%|█                                                  | 1/50 [00:48<40:00, 48.99s/it]Evaluating commonsenseqa :   4%|██                                                 | 2/50 [01:03<23:02, 28.81s/it]Evaluating commonsenseqa :   6%|███                                                | 3/50 [01:52<29:51, 38.12s/it]Evaluating commonsenseqa :   8%|████                                               | 4/50 [02:19<25:42, 33.54s/it]Evaluating commonsenseqa :  10%|█████                                              | 5/50 [03:08<29:25, 39.24s/it]Evaluating commonsenseqa :  12%|██████                                             | 6/50 [03:26<23:25, 31.94s/it]Evaluating commonsenseqa :  14%|███████▏                                           | 7/50 [04:05<24:38, 34.38s/it]Evaluating commonsenseqa :  16%|████████▏                                          | 8/50 [04:41<24:25, 34.90s/it]Evaluating commonsenseqa :  18%|█████████▏                                         | 9/50 [04:55<19:20, 28.30s/it]Evaluating commonsenseqa :  20%|██████████                                        | 10/50 [05:20<18:07, 27.18s/it]Evaluating commonsenseqa :  22%|███████████                                       | 11/50 [06:02<20:42, 31.87s/it]Evaluating commonsenseqa :  24%|████████████                                      | 12/50 [06:23<18:04, 28.54s/it]Evaluating commonsenseqa :  26%|█████████████                                     | 13/50 [06:45<16:23, 26.59s/it]Evaluating commonsenseqa :  28%|██████████████                                    | 14/50 [07:10<15:34, 25.97s/it]Evaluating commonsenseqa :  30%|███████████████                                   | 15/50 [07:37<15:21, 26.33s/it]Evaluating commonsenseqa :  32%|████████████████                                  | 16/50 [08:25<18:38, 32.88s/it]Evaluating commonsenseqa :  34%|█████████████████                                 | 17/50 [08:39<14:55, 27.14s/it]Evaluating commonsenseqa :  36%|██████████████████                                | 18/50 [09:01<13:43, 25.72s/it]Evaluating commonsenseqa :  38%|███████████████████                               | 19/50 [09:33<14:16, 27.62s/it]Evaluating commonsenseqa :  40%|████████████████████                              | 20/50 [10:22<16:54, 33.82s/it]Evaluating commonsenseqa :  42%|█████████████████████                             | 21/50 [11:03<17:25, 36.04s/it]Evaluating commonsenseqa :  44%|██████████████████████                            | 22/50 [11:51<18:33, 39.75s/it]Evaluating commonsenseqa :  46%|███████████████████████                           | 23/50 [12:24<16:54, 37.58s/it]Evaluating commonsenseqa :  48%|████████████████████████                          | 24/50 [13:13<17:44, 40.94s/it]Evaluating commonsenseqa :  50%|█████████████████████████                         | 25/50 [13:48<16:23, 39.34s/it]Evaluating commonsenseqa :  52%|██████████████████████████                        | 26/50 [14:39<17:07, 42.80s/it]Evaluating commonsenseqa :  54%|███████████████████████████                       | 27/50 [15:15<15:34, 40.63s/it]Evaluating commonsenseqa :  56%|████████████████████████████                      | 28/50 [15:59<15:15, 41.62s/it]Evaluating commonsenseqa :  58%|████████████████████████████▉                     | 29/50 [16:33<13:47, 39.42s/it]Evaluating commonsenseqa :  60%|██████████████████████████████                    | 30/50 [17:06<12:30, 37.51s/it]Evaluating commonsenseqa :  62%|███████████████████████████████                   | 31/50 [17:55<12:59, 41.04s/it]Evaluating commonsenseqa :  64%|████████████████████████████████                  | 32/50 [18:43<12:52, 42.92s/it]Evaluating commonsenseqa :  66%|█████████████████████████████████                 | 33/50 [19:06<10:30, 37.10s/it]Evaluating commonsenseqa :  68%|██████████████████████████████████                | 34/50 [19:55<10:50, 40.67s/it]Evaluating commonsenseqa :  70%|███████████████████████████████████               | 35/50 [20:44<10:44, 43.00s/it]Evaluating commonsenseqa :  72%|████████████████████████████████████              | 36/50 [21:23<09:45, 41.82s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████             | 37/50 [21:44<07:43, 35.64s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████            | 38/50 [22:11<06:36, 33.00s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████           | 39/50 [22:21<04:48, 26.21s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████          | 40/50 [22:39<03:57, 23.79s/it]Evaluating commonsenseqa :  82%|█████████████████████████████████████████         | 41/50 [23:26<04:37, 30.82s/it]Evaluating commonsenseqa :  84%|██████████████████████████████████████████        | 42/50 [24:15<04:49, 36.17s/it]Evaluating commonsenseqa :  86%|███████████████████████████████████████████       | 43/50 [24:47<04:03, 34.79s/it]Evaluating commonsenseqa :  88%|████████████████████████████████████████████      | 44/50 [25:06<03:01, 30.27s/it]Evaluating commonsenseqa :  90%|█████████████████████████████████████████████     | 45/50 [25:20<02:06, 25.37s/it]Evaluating commonsenseqa :  92%|██████████████████████████████████████████████    | 46/50 [26:08<02:08, 32.23s/it]Evaluating commonsenseqa :  94%|███████████████████████████████████████████████   | 47/50 [26:49<01:44, 34.80s/it]Evaluating commonsenseqa :  96%|████████████████████████████████████████████████  | 48/50 [27:11<01:01, 30.94s/it]Evaluating commonsenseqa :  98%|█████████████████████████████████████████████████ | 49/50 [27:30<00:27, 27.36s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████████████████████| 50/50 [28:18<00:00, 33.45s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████████████████████| 50/50 [28:18<00:00, 33.97s/it]
name: commonsenseqa | {'exact_match': 1.5, 'rougeL': 5.5213} | lm_loss 7.1362 | avg. gen lenth: 168.84
torchrun --nproc_per_node 5 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 5 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-out-domain 0 --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 4 --seed 42 --data-dir /scratch/ylu130/processed_data/commonsenseqa/in-domain/i2-s42-rFalse --num-in-domain 2
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 5
[2023-08-08 16:32:26,853] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 5
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/in-domain/i2-s42-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 2
  num_out_domain ............... 0
  out_domain_data_name ......... None
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i2-s42-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 4
  clip_grad .................... 1.0
  seed ......................... 42
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 5
Loading Data
  0%|                                                                                    | 0/9739 [00:00<?, ?it/s]  2%|█▏                                                                      | 164/9739 [00:00<00:05, 1637.57it/s]  3%|██▍                                                                     | 329/9739 [00:00<00:05, 1644.19it/s]  5%|███▋                                                                    | 495/9739 [00:00<00:05, 1649.67it/s]  7%|████▉                                                                   | 661/9739 [00:00<00:05, 1650.64it/s]  8%|██████                                                                  | 827/9739 [00:00<00:05, 1618.27it/s] 10%|███████▎                                                                | 989/9739 [00:00<00:05, 1615.03it/s] 12%|████████▍                                                              | 1155/9739 [00:00<00:05, 1629.17it/s] 14%|█████████▋                                                             | 1321/9739 [00:00<00:05, 1637.20it/s] 15%|██████████▊                                                            | 1486/9739 [00:00<00:05, 1639.11it/s] 17%|████████████                                                           | 1652/9739 [00:01<00:04, 1643.09it/s] 19%|█████████████▏                                                         | 1817/9739 [00:01<00:04, 1612.73it/s] 20%|██████████████▍                                                        | 1983/9739 [00:01<00:04, 1624.19it/s] 22%|███████████████▋                                                       | 2147/9739 [00:01<00:04, 1627.75it/s] 24%|████████████████▊                                                      | 2313/9739 [00:01<00:04, 1634.60it/s] 25%|██████████████████                                                     | 2477/9739 [00:01<00:04, 1635.33it/s] 27%|███████████████████▎                                                   | 2642/9739 [00:01<00:04, 1639.26it/s] 29%|████████████████████▍                                                  | 2806/9739 [00:01<00:04, 1637.48it/s] 31%|█████████████████████▋                                                 | 2972/9739 [00:01<00:04, 1643.08it/s] 32%|██████████████████████▉                                                | 3138/9739 [00:01<00:04, 1648.09it/s] 34%|████████████████████████                                               | 3305/9739 [00:02<00:03, 1653.81it/s] 36%|█████████████████████████▎                                             | 3471/9739 [00:02<00:03, 1653.00it/s] 37%|██████████████████████████▌                                            | 3637/9739 [00:02<00:03, 1648.87it/s] 39%|███████████████████████████▋                                           | 3806/9739 [00:02<00:03, 1658.75it/s] 41%|█████████████████████████████                                          | 3978/9739 [00:02<00:03, 1674.29it/s] 43%|██████████████████████████████▎                                        | 4150/9739 [00:02<00:03, 1685.78it/s] 45%|███████████████████████████████▋                                       | 4341/9739 [00:02<00:03, 1752.61it/s] 47%|█████████████████████████████████▍                                     | 4588/9739 [00:02<00:02, 1966.88it/s] 49%|██████████████████████████████████▉                                    | 4785/9739 [00:02<00:03, 1572.02it/s] 52%|████████████████████████████████████▊                                  | 5046/9739 [00:03<00:02, 1835.17it/s] 55%|██████████████████████████████████████▋                                | 5308/9739 [00:03<00:02, 2042.58it/s] 57%|████████████████████████████████████████▋                              | 5574/9739 [00:03<00:01, 2211.03it/s] 60%|██████████████████████████████████████████▋                            | 5847/9739 [00:03<00:01, 2356.66it/s] 63%|████████████████████████████████████████████▋                          | 6123/9739 [00:03<00:01, 2471.52it/s] 66%|██████████████████████████████████████████████▋                        | 6397/9739 [00:03<00:01, 2549.44it/s] 68%|████████████████████████████████████████████████▋                      | 6671/9739 [00:03<00:01, 2604.01it/s] 71%|██████████████████████████████████████████████████▋                    | 6948/9739 [00:03<00:01, 2651.37it/s] 74%|████████████████████████████████████████████████████▋                  | 7223/9739 [00:03<00:00, 2678.54it/s] 77%|██████████████████████████████████████████████████████▋                | 7493/9739 [00:03<00:00, 2666.88it/s] 80%|████████████████████████████████████████████████████████▋              | 7768/9739 [00:04<00:00, 2689.10it/s] 83%|██████████████████████████████████████████████████████████▋            | 8044/9739 [00:04<00:00, 2707.23it/s] 85%|████████████████████████████████████████████████████████████▋          | 8316/9739 [00:04<00:00, 2702.97it/s] 88%|██████████████████████████████████████████████████████████████▋        | 8591/9739 [00:04<00:00, 2715.33it/s] 91%|████████████████████████████████████████████████████████████████▋      | 8866/9739 [00:04<00:00, 2725.36it/s] 94%|██████████████████████████████████████████████████████████████████▋    | 9143/9739 [00:04<00:00, 2737.18it/s] 97%|████████████████████████████████████████████████████████████████████▋  | 9418/9739 [00:04<00:00, 2739.08it/s]100%|██████████████████████████████████████████████████████████████████████▋| 9693/9739 [00:04<00:00, 2734.08it/s]100%|███████████████████████████████████████████████████████████████████████| 9739/9739 [00:04<00:00, 2058.76it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:10,  5.07s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:10,  5.12s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:10,  5.11s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:10,  5.45s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:11,  5.72s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:10<00:05,  5.18s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:10<00:05,  5.22s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:10<00:05,  5.20s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:10<00:05,  5.45s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:10<00:05,  5.48s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.53s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.70s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.55s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.72s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.53s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.70s/it]
[2023-08-08 16:33:23,009] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.79s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.99s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.78s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.97s/it]
[2023-08-08 16:33:35,991] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-08 16:33:35,992] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-08 16:33:35,992] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-08 16:33:35,992] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-08 16:33:35,992] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-08 16:33:35,992] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-08 16:33:35,992] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-08 16:33:35,992] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-08 16:33:35,992] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-08 16:33:35,992] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-08 16:33:35,992] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-08 16:33:35,992] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fa2dc21ff40>
[2023-08-08 16:33:35,992] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fa2b70acdc0>
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  4
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   world_size ................... 5
[2023-08-08 16:33:35,993] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-08 16:33:35,994] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-08 16:33:35,994] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-08 16:33:35,994] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-08 16:33:35,994] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 4, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.33972644805908203 seconds
Loading extension module utils...
Time to load utils op: 0.204423189163208 seconds
Loading extension module utils...
Time to load utils op: 0.20421886444091797 seconds
Loading extension module utils...
Time to load utils op: 0.4046437740325928 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Loading extension module utils...
Evaluating commonsenseqa :   0%|                                                           | 0/50 [00:00<?, ?it/s]Time to load utils op: 0.3050997257232666 seconds
############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following multiple choice question.

### Demonstration:
Input: He fantasied about getting a what while driving to work and the pros and cons of the extra responsibilities and benefits? Choices:  A: new car B: promotion C: boredom D: impatience E: pressure
Answer: B: promotion

Input: He was good at traditional science but excelled at social science, his favorite subject was what? Choices:  A: geography B: history studies C: math D: religion E: dancing
Answer: B: history studies

### Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i2-s42-rFalse
Evaluating commonsenseqa :   2%|█                                                  | 1/50 [00:12<10:14, 12.54s/it]Evaluating commonsenseqa :   4%|██                                                 | 2/50 [00:59<26:09, 32.70s/it]Evaluating commonsenseqa :   6%|███                                                | 3/50 [01:12<18:40, 23.84s/it]Evaluating commonsenseqa :   8%|████                                               | 4/50 [01:45<21:08, 27.57s/it]Evaluating commonsenseqa :  10%|█████                                              | 5/50 [02:29<25:06, 33.49s/it]Evaluating commonsenseqa :  12%|██████                                             | 6/50 [03:17<28:09, 38.40s/it]Evaluating commonsenseqa :  14%|███████▏                                           | 7/50 [04:04<29:32, 41.22s/it]Evaluating commonsenseqa :  16%|████████▏                                          | 8/50 [04:52<30:21, 43.37s/it]Evaluating commonsenseqa :  18%|█████████▏                                         | 9/50 [05:36<29:44, 43.53s/it]Evaluating commonsenseqa :  20%|██████████                                        | 10/50 [06:18<28:38, 42.97s/it]Evaluating commonsenseqa :  22%|███████████                                       | 11/50 [06:49<25:36, 39.40s/it]Evaluating commonsenseqa :  24%|████████████                                      | 12/50 [07:25<24:15, 38.31s/it]Evaluating commonsenseqa :  26%|█████████████                                     | 13/50 [07:45<20:15, 32.86s/it]Evaluating commonsenseqa :  28%|██████████████                                    | 14/50 [07:59<16:10, 26.96s/it]Evaluating commonsenseqa :  30%|███████████████                                   | 15/50 [08:47<19:25, 33.29s/it]Evaluating commonsenseqa :  32%|████████████████                                  | 16/50 [09:16<18:13, 32.17s/it]Evaluating commonsenseqa :  34%|█████████████████                                 | 17/50 [09:50<17:57, 32.66s/it]Evaluating commonsenseqa :  36%|██████████████████                                | 18/50 [10:38<19:47, 37.11s/it]Evaluating commonsenseqa :  38%|███████████████████                               | 19/50 [10:54<15:59, 30.95s/it]Evaluating commonsenseqa :  40%|████████████████████                              | 20/50 [11:42<18:02, 36.08s/it]Evaluating commonsenseqa :  42%|█████████████████████                             | 21/50 [11:54<13:55, 28.80s/it]Evaluating commonsenseqa :  44%|██████████████████████                            | 22/50 [12:42<16:11, 34.69s/it]Evaluating commonsenseqa :  46%|███████████████████████                           | 23/50 [13:01<13:28, 29.96s/it]Evaluating commonsenseqa :  48%|████████████████████████                          | 24/50 [13:15<10:48, 24.96s/it]Evaluating commonsenseqa :  50%|█████████████████████████                         | 25/50 [14:03<13:16, 31.86s/it]Evaluating commonsenseqa :  52%|██████████████████████████                        | 26/50 [14:50<14:38, 36.62s/it]Evaluating commonsenseqa :  54%|███████████████████████████                       | 27/50 [15:37<15:13, 39.71s/it]Evaluating commonsenseqa :  56%|████████████████████████████                      | 28/50 [16:12<13:58, 38.11s/it]Evaluating commonsenseqa :  58%|████████████████████████████▉                     | 29/50 [16:31<11:20, 32.39s/it]Evaluating commonsenseqa :  60%|██████████████████████████████                    | 30/50 [16:49<09:26, 28.31s/it]Evaluating commonsenseqa :  62%|███████████████████████████████                   | 31/50 [17:37<10:49, 34.18s/it]Evaluating commonsenseqa :  64%|████████████████████████████████                  | 32/50 [17:59<09:10, 30.57s/it]Evaluating commonsenseqa :  66%|█████████████████████████████████                 | 33/50 [18:46<09:58, 35.23s/it]Evaluating commonsenseqa :  68%|██████████████████████████████████                | 34/50 [19:33<10:22, 38.92s/it]Evaluating commonsenseqa :  70%|███████████████████████████████████               | 35/50 [20:21<10:24, 41.61s/it]Evaluating commonsenseqa :  72%|████████████████████████████████████              | 36/50 [21:09<10:09, 43.50s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████             | 37/50 [21:55<09:37, 44.40s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████            | 38/50 [22:40<08:53, 44.44s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████           | 39/50 [23:06<07:07, 38.90s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████          | 40/50 [23:18<05:07, 30.72s/it]Evaluating commonsenseqa :  82%|█████████████████████████████████████████         | 41/50 [24:05<05:21, 35.75s/it]Evaluating commonsenseqa :  84%|██████████████████████████████████████████        | 42/50 [24:25<04:08, 31.02s/it]Evaluating commonsenseqa :  86%|███████████████████████████████████████████       | 43/50 [25:11<04:08, 35.53s/it]Evaluating commonsenseqa :  88%|████████████████████████████████████████████      | 44/50 [25:34<03:11, 31.87s/it]Evaluating commonsenseqa :  90%|█████████████████████████████████████████████     | 45/50 [26:18<02:56, 35.24s/it]Evaluating commonsenseqa :  92%|██████████████████████████████████████████████    | 46/50 [26:44<02:10, 32.73s/it]Evaluating commonsenseqa :  94%|███████████████████████████████████████████████   | 47/50 [27:22<01:42, 34.21s/it]Evaluating commonsenseqa :  96%|████████████████████████████████████████████████  | 48/50 [28:10<01:16, 38.35s/it]Evaluating commonsenseqa :  98%|█████████████████████████████████████████████████ | 49/50 [28:26<00:31, 31.72s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████████████████████| 50/50 [29:14<00:00, 36.60s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████████████████████| 50/50 [29:14<00:00, 35.10s/it]
name: commonsenseqa | {'exact_match': 0.5, 'rougeL': 5.2369} | lm_loss 7.1919 | avg. gen lenth: 176.0
torchrun --nproc_per_node 5 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 5 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-out-domain 0 --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 4 --seed 42 --data-dir /scratch/ylu130/processed_data/commonsenseqa/in-domain/i3-s42-rFalse --num-in-domain 3
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
using world size: 5
[2023-08-08 17:03:00,097] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 5
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/in-domain/i3-s42-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 3
  num_out_domain ............... 0
  out_domain_data_name ......... None
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i3-s42-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 4
  clip_grad .................... 1.0
  seed ......................... 42
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 5
Loading Data
  0%|                                                                                    | 0/9738 [00:00<?, ?it/s]  1%|▉                                                                       | 130/9738 [00:00<00:07, 1293.54it/s]  3%|█▉                                                                      | 260/9738 [00:00<00:07, 1295.56it/s]  4%|██▉                                                                     | 392/9738 [00:00<00:07, 1303.09it/s]  5%|███▊                                                                    | 523/9738 [00:00<00:07, 1302.78it/s]  7%|████▊                                                                   | 654/9738 [00:00<00:06, 1301.13it/s]  8%|█████▊                                                                  | 786/9738 [00:00<00:06, 1307.25it/s]  9%|██████▊                                                                 | 918/9738 [00:00<00:06, 1310.56it/s] 11%|███████▋                                                               | 1050/9738 [00:00<00:06, 1312.48it/s] 12%|████████▌                                                              | 1182/9738 [00:00<00:06, 1282.63it/s] 13%|█████████▌                                                             | 1312/9738 [00:01<00:06, 1287.13it/s] 15%|██████████▌                                                            | 1441/9738 [00:01<00:06, 1287.54it/s] 16%|███████████▍                                                           | 1572/9738 [00:01<00:06, 1292.11it/s] 17%|████████████▍                                                          | 1703/9738 [00:01<00:06, 1296.91it/s] 19%|█████████████▎                                                         | 1833/9738 [00:01<00:06, 1266.05it/s] 20%|██████████████▎                                                        | 1961/9738 [00:01<00:06, 1267.59it/s] 21%|███████████████▏                                                       | 2090/9738 [00:01<00:06, 1272.99it/s] 23%|████████████████▏                                                      | 2222/9738 [00:01<00:05, 1284.45it/s] 24%|█████████████████▏                                                     | 2352/9738 [00:01<00:05, 1288.80it/s] 26%|██████████████████                                                     | 2484/9738 [00:01<00:05, 1295.45it/s] 27%|███████████████████                                                    | 2615/9738 [00:02<00:05, 1298.69it/s] 28%|████████████████████                                                   | 2745/9738 [00:02<00:05, 1296.94it/s] 30%|████████████████████▉                                                  | 2876/9738 [00:02<00:05, 1299.55it/s] 31%|█████████████████████▉                                                 | 3007/9738 [00:02<00:05, 1302.32it/s] 32%|██████████████████████▉                                                | 3138/9738 [00:02<00:05, 1302.76it/s] 34%|███████████████████████▊                                               | 3269/9738 [00:02<00:04, 1301.90it/s] 35%|████████████████████████▉                                              | 3412/9738 [00:02<00:04, 1339.38it/s] 37%|██████████████████████████▎                                            | 3612/9738 [00:02<00:03, 1535.63it/s] 39%|███████████████████████████▊                                           | 3819/9738 [00:02<00:03, 1694.99it/s] 41%|█████████████████████████████▎                                         | 4026/9738 [00:02<00:03, 1804.72it/s] 43%|██████████████████████████████▊                                        | 4232/9738 [00:03<00:02, 1879.41it/s] 46%|████████████████████████████████▎                                      | 4438/9738 [00:03<00:02, 1931.77it/s] 48%|█████████████████████████████████▊                                     | 4633/9738 [00:03<00:02, 1936.72it/s] 50%|███████████████████████████████████▏                                   | 4827/9738 [00:03<00:03, 1598.70it/s] 52%|████████████████████████████████████▋                                  | 5031/9738 [00:03<00:02, 1711.75it/s] 54%|██████████████████████████████████████▏                                | 5235/9738 [00:03<00:02, 1799.50it/s] 56%|███████████████████████████████████████▋                               | 5440/9738 [00:03<00:02, 1868.83it/s] 58%|█████████████████████████████████████████▏                             | 5653/9738 [00:03<00:02, 1941.54it/s] 60%|██████████████████████████████████████████▊                            | 5869/9738 [00:03<00:01, 2002.56it/s] 62%|████████████████████████████████████████████▎                          | 6085/9738 [00:04<00:01, 2046.04it/s] 65%|█████████████████████████████████████████████▉                         | 6295/9738 [00:04<00:01, 2059.82it/s] 67%|███████████████████████████████████████████████▍                       | 6510/9738 [00:04<00:01, 2084.06it/s] 69%|█████████████████████████████████████████████████                      | 6724/9738 [00:04<00:01, 2100.53it/s] 71%|██████████████████████████████████████████████████▌                    | 6941/9738 [00:04<00:01, 2120.35it/s] 74%|████████████████████████████████████████████████████▏                  | 7158/9738 [00:04<00:01, 2132.90it/s] 76%|█████████████████████████████████████████████████████▊                 | 7375/9738 [00:04<00:01, 2141.79it/s] 78%|███████████████████████████████████████████████████████▎               | 7590/9738 [00:04<00:01, 2112.78it/s] 80%|████████████████████████████████████████████████████████▉              | 7805/9738 [00:04<00:00, 2122.51it/s] 82%|██████████████████████████████████████████████████████████▍            | 8018/9738 [00:04<00:00, 2104.25it/s] 85%|████████████████████████████████████████████████████████████           | 8233/9738 [00:05<00:00, 2116.44it/s] 87%|█████████████████████████████████████████████████████████████▌         | 8449/9738 [00:05<00:00, 2126.38it/s] 89%|███████████████████████████████████████████████████████████████▏       | 8664/9738 [00:05<00:00, 2132.99it/s] 91%|████████████████████████████████████████████████████████████████▋      | 8879/9738 [00:05<00:00, 2137.97it/s] 93%|██████████████████████████████████████████████████████████████████▎    | 9095/9738 [00:05<00:00, 2142.35it/s] 96%|███████████████████████████████████████████████████████████████████▉   | 9311/9738 [00:05<00:00, 2146.88it/s] 98%|█████████████████████████████████████████████████████████████████████▍ | 9527/9738 [00:05<00:00, 2149.74it/s]100%|███████████████████████████████████████████████████████████████████████| 9738/9738 [00:05<00:00, 1705.37it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:04<00:09,  4.86s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:10,  5.46s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:11,  5.52s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:11,  5.78s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:06<00:12,  6.45s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:09<00:04,  4.97s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:10<00:05,  5.22s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:10<00:05,  5.41s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:11<00:05,  5.59s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:12<00:06,  6.14s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.35s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.50s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.57s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.77s/it]
[2023-08-08 17:03:57,268] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:15<00:00,  4.91s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.06s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.04s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.21s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:17<00:00,  5.70s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:17<00:00,  5.85s/it]
[2023-08-08 17:04:15,127] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-08 17:04:15,128] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-08 17:04:15,129] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-08 17:04:15,129] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-08 17:04:15,129] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-08 17:04:15,129] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-08 17:04:15,129] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-08 17:04:15,129] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-08 17:04:15,129] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-08 17:04:15,129] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-08 17:04:15,129] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-08 17:04:15,129] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fd6c163bf40>
[2023-08-08 17:04:15,129] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-08 17:04:15,129] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-08 17:04:15,129] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fd69c799dc0>
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-08 17:04:15,130] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-08 17:04:15,131] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-08 17:04:15,131] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-08 17:04:15,131] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-08 17:04:15,131] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-08 17:04:15,131] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-08 17:04:15,131] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-08 17:04:15,131] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-08 17:04:15,131] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-08 17:04:15,131] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  4
[2023-08-08 17:04:15,131] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-08 17:04:15,131] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-08 17:04:15,131] [INFO] [config.py:1012:print]   world_size ................... 5
[2023-08-08 17:04:15,131] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-08 17:04:15,131] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-08 17:04:15,131] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-08 17:04:15,131] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-08 17:04:15,131] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 4, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.3536849021911621 seconds
Loading extension module utils...
Time to load utils op: 0.2041454315185547 seconds
Loading extension module utils...
Time to load utils op: 0.30454063415527344 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Loading extension module utils...
Time to load utils op: 0.40447235107421875 seconds
Evaluating commonsenseqa :   0%|                                                           | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following multiple choice question.

### Demonstration:
Input: He fantasied about getting a what while driving to work and the pros and cons of the extra responsibilities and benefits? Choices:  A: new car B: promotion C: boredom D: impatience E: pressure
Answer: B: promotion

Input: He was good at traditional science but excelled at social science, his favorite subject was what? Choices:  A: geography B: history studies C: math D: religion E: dancing
Answer: B: history studies

Input: Jan wasn't very good at studying.  What might help him study better? Choices:  A: having a bigger brain B: headaches C: inspiration D: more intelligence E: understanding
Answer: D: more intelligence

### Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i3-s42-rFalse
Loading extension module utils...
Time to load utils op: 0.4046046733856201 seconds
Evaluating commonsenseqa :   2%|█                                                  | 1/50 [00:29<24:07, 29.55s/it]Evaluating commonsenseqa :   4%|██                                                 | 2/50 [01:15<31:09, 38.94s/it]Evaluating commonsenseqa :   6%|███                                                | 3/50 [01:44<27:00, 34.47s/it]Evaluating commonsenseqa :   8%|████                                               | 4/50 [02:12<24:39, 32.15s/it]Evaluating commonsenseqa :  10%|█████                                              | 5/50 [02:29<20:01, 26.69s/it]Evaluating commonsenseqa :  12%|██████                                             | 6/50 [02:45<16:56, 23.10s/it]Evaluating commonsenseqa :  14%|███████▏                                           | 7/50 [03:16<18:20, 25.60s/it]Evaluating commonsenseqa :  16%|████████▏                                          | 8/50 [04:03<22:42, 32.44s/it]Evaluating commonsenseqa :  18%|█████████▏                                         | 9/50 [04:43<23:42, 34.70s/it]Evaluating commonsenseqa :  20%|██████████                                        | 10/50 [05:03<20:04, 30.11s/it]Evaluating commonsenseqa :  22%|███████████                                       | 11/50 [05:29<18:49, 28.96s/it]Evaluating commonsenseqa :  24%|████████████                                      | 12/50 [06:16<21:50, 34.49s/it]Evaluating commonsenseqa :  26%|█████████████                                     | 13/50 [07:02<23:20, 37.86s/it]Evaluating commonsenseqa :  28%|██████████████                                    | 14/50 [07:50<24:33, 40.92s/it]Evaluating commonsenseqa :  30%|███████████████                                   | 15/50 [08:04<19:09, 32.83s/it]Evaluating commonsenseqa :  32%|████████████████                                  | 16/50 [08:12<14:26, 25.47s/it]Evaluating commonsenseqa :  34%|█████████████████                                 | 17/50 [08:39<14:15, 25.91s/it]Evaluating commonsenseqa :  36%|██████████████████                                | 18/50 [08:59<12:52, 24.14s/it]Evaluating commonsenseqa :  38%|███████████████████                               | 19/50 [09:08<10:09, 19.65s/it]Evaluating commonsenseqa :  40%|████████████████████                              | 20/50 [09:55<13:47, 27.57s/it]Evaluating commonsenseqa :  42%|█████████████████████                             | 21/50 [10:41<16:00, 33.12s/it]Evaluating commonsenseqa :  44%|██████████████████████                            | 22/50 [10:54<12:43, 27.27s/it]Evaluating commonsenseqa :  46%|███████████████████████                           | 23/50 [11:31<13:37, 30.27s/it]Evaluating commonsenseqa :  48%|████████████████████████                          | 24/50 [12:19<15:20, 35.42s/it]Evaluating commonsenseqa :  50%|█████████████████████████                         | 25/50 [12:53<14:33, 34.92s/it]Evaluating commonsenseqa :  52%|██████████████████████████                        | 26/50 [13:35<14:50, 37.09s/it]Evaluating commonsenseqa :  54%|███████████████████████████                       | 27/50 [13:56<12:21, 32.23s/it]Evaluating commonsenseqa :  56%|████████████████████████████                      | 28/50 [14:39<13:02, 35.58s/it]Evaluating commonsenseqa :  58%|████████████████████████████▉                     | 29/50 [14:49<09:44, 27.83s/it]Evaluating commonsenseqa :  60%|██████████████████████████████                    | 30/50 [15:36<11:11, 33.57s/it]Evaluating commonsenseqa :  62%|███████████████████████████████                   | 31/50 [15:56<09:24, 29.69s/it]Evaluating commonsenseqa :  64%|████████████████████████████████                  | 32/50 [16:25<08:48, 29.38s/it]Evaluating commonsenseqa :  66%|█████████████████████████████████                 | 33/50 [16:48<07:45, 27.36s/it]Evaluating commonsenseqa :  68%|██████████████████████████████████                | 34/50 [17:28<08:20, 31.26s/it]Evaluating commonsenseqa :  70%|███████████████████████████████████               | 35/50 [18:15<09:00, 36.02s/it]Evaluating commonsenseqa :  72%|████████████████████████████████████              | 36/50 [19:00<08:59, 38.57s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████             | 37/50 [19:44<08:44, 40.38s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████            | 38/50 [20:15<07:29, 37.45s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████           | 39/50 [20:29<05:35, 30.49s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████          | 40/50 [21:16<05:53, 35.34s/it]Evaluating commonsenseqa :  82%|█████████████████████████████████████████         | 41/50 [21:29<04:18, 28.67s/it]Evaluating commonsenseqa :  84%|██████████████████████████████████████████        | 42/50 [22:16<04:32, 34.11s/it]Evaluating commonsenseqa :  86%|███████████████████████████████████████████       | 43/50 [22:40<03:38, 31.25s/it]Evaluating commonsenseqa :  88%|████████████████████████████████████████████      | 44/50 [23:28<03:36, 36.17s/it]Evaluating commonsenseqa :  90%|█████████████████████████████████████████████     | 45/50 [23:58<02:51, 34.34s/it]Evaluating commonsenseqa :  92%|██████████████████████████████████████████████    | 46/50 [24:24<02:07, 31.79s/it]Evaluating commonsenseqa :  94%|███████████████████████████████████████████████   | 47/50 [24:49<01:29, 29.88s/it]Evaluating commonsenseqa :  96%|████████████████████████████████████████████████  | 48/50 [25:36<01:10, 35.01s/it]Evaluating commonsenseqa :  98%|█████████████████████████████████████████████████ | 49/50 [26:07<00:33, 33.71s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████████████████████| 50/50 [26:53<00:00, 37.45s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████████████████████| 50/50 [26:53<00:00, 32.27s/it]
name: commonsenseqa | {'exact_match': 2.0, 'rougeL': 5.8792} | lm_loss 7.1753 | avg. gen lenth: 163.28
torchrun --nproc_per_node 5 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 5 --is-opensource --data-name commonsenseqa --num-eval 1000 --num-workers 0 --num-out-domain 0 --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 4 --seed 42 --data-dir /scratch/ylu130/processed_data/commonsenseqa/in-domain/i4-s42-rFalse --num-in-domain 4
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 5
[2023-08-08 17:36:13,403] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 5
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/in-domain/i4-s42-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 4
  num_out_domain ............... 0
  out_domain_data_name ......... None
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i4-s42-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 4
  clip_grad .................... 1.0
  seed ......................... 42
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 5
Loading Data
  0%|                                                                                    | 0/9737 [00:00<?, ?it/s]  1%|▊                                                                       | 112/9737 [00:00<00:08, 1118.06it/s]  2%|█▋                                                                      | 225/9737 [00:00<00:08, 1124.68it/s]  3%|██▌                                                                     | 339/9737 [00:00<00:08, 1131.12it/s]  5%|███▎                                                                    | 453/9737 [00:00<00:08, 1132.51it/s]  6%|████▏                                                                   | 567/9737 [00:00<00:08, 1132.89it/s]  7%|█████                                                                   | 681/9737 [00:00<00:08, 1131.30it/s]  8%|█████▉                                                                  | 796/9737 [00:00<00:07, 1135.57it/s]  9%|██████▋                                                                 | 910/9737 [00:00<00:07, 1135.31it/s] 11%|███████▍                                                               | 1024/9737 [00:00<00:07, 1136.02it/s] 12%|████████▎                                                              | 1138/9737 [00:01<00:07, 1135.18it/s] 13%|█████████▏                                                             | 1252/9737 [00:01<00:07, 1133.99it/s] 14%|█████████▉                                                             | 1366/9737 [00:01<00:07, 1130.84it/s] 15%|██████████▊                                                            | 1480/9737 [00:01<00:07, 1131.73it/s] 16%|███████████▌                                                           | 1594/9737 [00:01<00:07, 1129.42it/s] 18%|████████████▍                                                          | 1709/9737 [00:01<00:07, 1133.55it/s] 19%|█████████████▎                                                         | 1823/9737 [00:01<00:07, 1112.06it/s] 20%|██████████████                                                         | 1936/9737 [00:01<00:06, 1116.80it/s] 21%|██████████████▉                                                        | 2049/9737 [00:01<00:06, 1118.97it/s] 22%|███████████████▊                                                       | 2162/9737 [00:01<00:06, 1121.67it/s] 23%|████████████████▌                                                      | 2275/9737 [00:02<00:06, 1121.46it/s] 25%|█████████████████▍                                                     | 2389/9737 [00:02<00:06, 1125.31it/s] 26%|██████████████████▏                                                    | 2502/9737 [00:02<00:06, 1125.15it/s] 27%|███████████████████                                                    | 2616/9737 [00:02<00:06, 1127.25it/s] 28%|███████████████████▉                                                   | 2730/9737 [00:02<00:06, 1130.74it/s] 29%|████████████████████▊                                                  | 2847/9737 [00:02<00:06, 1141.98it/s] 30%|█████████████████████▌                                                 | 2964/9737 [00:02<00:05, 1149.61it/s] 32%|██████████████████████▍                                                | 3081/9737 [00:02<00:05, 1153.86it/s] 33%|███████████████████████▎                                               | 3199/9737 [00:02<00:05, 1160.93it/s] 34%|████████████████████████▏                                              | 3318/9737 [00:02<00:05, 1167.62it/s] 35%|█████████████████████████                                              | 3436/9737 [00:03<00:05, 1168.08it/s] 36%|█████████████████████████▉                                             | 3554/9737 [00:03<00:05, 1169.68it/s] 38%|██████████████████████████▊                                            | 3672/9737 [00:03<00:05, 1170.03it/s] 39%|███████████████████████████▋                                           | 3791/9737 [00:03<00:05, 1173.18it/s] 40%|████████████████████████████▌                                          | 3909/9737 [00:03<00:04, 1173.55it/s] 41%|█████████████████████████████▎                                         | 4027/9737 [00:03<00:04, 1174.97it/s] 43%|██████████████████████████████▏                                        | 4145/9737 [00:03<00:04, 1172.68it/s] 44%|███████████████████████████████                                        | 4263/9737 [00:03<00:04, 1157.30it/s] 45%|███████████████████████████████▉                                       | 4379/9737 [00:03<00:04, 1157.75it/s] 46%|████████████████████████████████▊                                      | 4496/9737 [00:03<00:04, 1160.08it/s] 47%|█████████████████████████████████▋                                     | 4613/9737 [00:04<00:04, 1133.27it/s] 49%|██████████████████████████████████▌                                    | 4732/9737 [00:04<00:04, 1147.98it/s] 50%|███████████████████████████████████▊                                    | 4847/9737 [00:04<00:05, 871.38it/s] 51%|████████████████████████████████████▋                                   | 4964/9737 [00:04<00:05, 943.23it/s] 52%|█████████████████████████████████████                                  | 5082/9737 [00:04<00:04, 1003.60it/s] 54%|██████████████████████████████████████                                 | 5222/9737 [00:04<00:04, 1109.10it/s] 55%|███████████████████████████████████████▍                               | 5401/9737 [00:04<00:03, 1295.82it/s] 57%|████████████████████████████████████████▋                              | 5586/9737 [00:04<00:02, 1450.72it/s] 59%|██████████████████████████████████████████                             | 5773/9737 [00:04<00:02, 1571.04it/s] 61%|███████████████████████████████████████████▍                           | 5959/9737 [00:05<00:02, 1654.96it/s] 63%|████████████████████████████████████████████▊                          | 6146/9737 [00:05<00:02, 1715.64it/s] 65%|██████████████████████████████████████████████▏                        | 6332/9737 [00:05<00:01, 1756.60it/s] 67%|███████████████████████████████████████████████▌                       | 6518/9737 [00:05<00:01, 1785.58it/s] 69%|████████████████████████████████████████████████▉                      | 6704/9737 [00:05<00:01, 1805.55it/s] 71%|██████████████████████████████████████████████████▏                    | 6890/9737 [00:05<00:01, 1821.20it/s] 73%|███████████████████████████████████████████████████▌                   | 7075/9737 [00:05<00:01, 1827.74it/s] 75%|████████████████████████████████████████████████████▉                  | 7261/9737 [00:05<00:01, 1835.53it/s] 76%|██████████████████████████████████████████████████████▎                | 7445/9737 [00:05<00:01, 1812.61it/s] 78%|███████████████████████████████████████████████████████▋               | 7632/9737 [00:05<00:01, 1828.39it/s] 80%|█████████████████████████████████████████████████████████              | 7818/9737 [00:06<00:01, 1837.74it/s] 82%|██████████████████████████████████████████████████████████▎            | 8005/9737 [00:06<00:00, 1845.42it/s] 84%|███████████████████████████████████████████████████████████▋           | 8193/9737 [00:06<00:00, 1853.50it/s] 86%|█████████████████████████████████████████████████████████████          | 8380/9737 [00:06<00:00, 1856.19it/s] 88%|██████████████████████████████████████████████████████████████▍        | 8567/9737 [00:06<00:00, 1858.52it/s] 90%|███████████████████████████████████████████████████████████████▊       | 8753/9737 [00:06<00:00, 1852.69it/s] 92%|█████████████████████████████████████████████████████████████████▏     | 8939/9737 [00:06<00:00, 1851.24it/s] 94%|██████████████████████████████████████████████████████████████████▌    | 9125/9737 [00:06<00:00, 1848.67it/s] 96%|███████████████████████████████████████████████████████████████████▉   | 9310/9737 [00:06<00:00, 1846.39it/s] 98%|█████████████████████████████████████████████████████████████████████▏ | 9496/9737 [00:06<00:00, 1848.71it/s] 99%|██████████████████████████████████████████████████████████████████████▌| 9683/9737 [00:07<00:00, 1853.14it/s]100%|███████████████████████████████████████████████████████████████████████| 9737/9737 [00:07<00:00, 1372.80it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                            | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:04<00:09,  4.88s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:10,  5.34s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:11,  6.00s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:05<00:11,  5.65s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 1/3 [00:06<00:12,  6.32s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:09<00:04,  5.00s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:11<00:05,  5.61s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:11<00:05,  5.79s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:11<00:05,  5.79s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 2/3 [00:12<00:06,  6.52s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.39s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.54s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.01s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.24s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.02s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.15s/it]
[2023-08-08 17:37:13,385] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.06s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.25s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:17<00:00,  5.68s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:17<00:00,  5.88s/it]
[2023-08-08 17:37:29,986] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-08 17:37:29,988] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-08 17:37:29,989] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-08 17:37:29,989] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-08 17:37:29,989] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-08 17:37:29,989] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f8fa52c6f40>
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f8f99f26dc0>
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-08 17:37:29,990] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-08 17:37:29,991] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-08 17:37:29,991] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-08 17:37:29,991] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-08 17:37:29,991] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-08 17:37:29,991] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-08 17:37:29,991] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-08 17:37:29,991] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-08 17:37:29,991] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-08 17:37:29,991] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  4
[2023-08-08 17:37:29,991] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-08 17:37:29,991] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-08 17:37:29,991] [INFO] [config.py:1012:print]   world_size ................... 5
[2023-08-08 17:37:29,991] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-08 17:37:29,991] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-08 17:37:29,991] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-08 17:37:29,991] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-08 17:37:29,991] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 4, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.40456652641296387 seconds
Loading extension module utils...
Time to load utils op: 0.3048064708709717 seconds
Loading extension module utils...
Loading extension module utils...
Time to load utils op: 0.3045313358306885 seconds
Time to load utils op: 0.4052913188934326 seconds
Loading extension module utils...
Time to load utils op: 0.40487027168273926 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                           | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following multiple choice question.

### Demonstration:
Input: He fantasied about getting a what while driving to work and the pros and cons of the extra responsibilities and benefits? Choices:  A: new car B: promotion C: boredom D: impatience E: pressure
Answer: B: promotion

Input: He was good at traditional science but excelled at social science, his favorite subject was what? Choices:  A: geography B: history studies C: math D: religion E: dancing
Answer: B: history studies

Input: Jan wasn't very good at studying.  What might help him study better? Choices:  A: having a bigger brain B: headaches C: inspiration D: more intelligence E: understanding
Answer: D: more intelligence

Input: The cat was wild but like all others he was always read for a cat what? Choices:  A: stealing B: four legs C: tuna fish D: food now E: nap
Answer: E: nap

### Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/in-domain/i4-s42-rFalse
Evaluating commonsenseqa :   2%|█                                                  | 1/50 [00:36<29:45, 36.45s/it]Evaluating commonsenseqa :   4%|██                                                 | 2/50 [01:22<33:31, 41.90s/it]Evaluating commonsenseqa :   6%|███                                                | 3/50 [01:59<31:08, 39.76s/it]Evaluating commonsenseqa :   8%|████                                               | 4/50 [02:22<25:23, 33.12s/it]Evaluating commonsenseqa :  10%|█████                                              | 5/50 [03:08<28:21, 37.81s/it]Evaluating commonsenseqa :  12%|██████                                             | 6/50 [03:34<24:44, 33.75s/it]Evaluating commonsenseqa :  14%|███████▏                                           | 7/50 [04:19<26:52, 37.49s/it]Evaluating commonsenseqa :  16%|████████▏                                          | 8/50 [05:05<28:03, 40.08s/it]Evaluating commonsenseqa :  18%|█████████▏                                         | 9/50 [05:50<28:37, 41.88s/it]Evaluating commonsenseqa :  20%|██████████                                        | 10/50 [06:35<28:33, 42.84s/it]Evaluating commonsenseqa :  22%|███████████                                       | 11/50 [07:21<28:17, 43.53s/it]Evaluating commonsenseqa :  24%|████████████                                      | 12/50 [08:06<27:55, 44.09s/it]Evaluating commonsenseqa :  26%|█████████████                                     | 13/50 [08:46<26:29, 42.97s/it]Evaluating commonsenseqa :  28%|██████████████                                    | 14/50 [09:01<20:36, 34.35s/it]Evaluating commonsenseqa :  30%|███████████████                                   | 15/50 [09:47<22:07, 37.94s/it]Evaluating commonsenseqa :  32%|████████████████                                  | 16/50 [10:19<20:29, 36.17s/it]Evaluating commonsenseqa :  34%|█████████████████                                 | 17/50 [11:03<21:11, 38.53s/it]Evaluating commonsenseqa :  36%|██████████████████                                | 18/50 [11:19<16:56, 31.76s/it]Evaluating commonsenseqa :  38%|███████████████████                               | 19/50 [11:51<16:28, 31.88s/it]Evaluating commonsenseqa :  40%|████████████████████                              | 20/50 [12:13<14:22, 28.73s/it]Evaluating commonsenseqa :  42%|█████████████████████                             | 21/50 [12:59<16:28, 34.07s/it]Evaluating commonsenseqa :  44%|██████████████████████                            | 22/50 [13:19<13:58, 29.95s/it]Evaluating commonsenseqa :  46%|███████████████████████                           | 23/50 [14:06<15:46, 35.06s/it]Evaluating commonsenseqa :  48%|████████████████████████                          | 24/50 [14:52<16:30, 38.10s/it]Evaluating commonsenseqa :  50%|█████████████████████████                         | 25/50 [15:27<15:35, 37.42s/it]Evaluating commonsenseqa :  52%|██████████████████████████                        | 26/50 [15:48<12:56, 32.34s/it]Evaluating commonsenseqa :  54%|███████████████████████████                       | 27/50 [16:13<11:34, 30.18s/it]Evaluating commonsenseqa :  56%|████████████████████████████                      | 28/50 [16:59<12:49, 34.96s/it]Evaluating commonsenseqa :  58%|████████████████████████████▉                     | 29/50 [17:30<11:48, 33.73s/it]Evaluating commonsenseqa :  60%|██████████████████████████████                    | 30/50 [18:16<12:29, 37.46s/it]Evaluating commonsenseqa :  62%|███████████████████████████████                   | 31/50 [19:02<12:36, 39.80s/it]Evaluating commonsenseqa :  64%|████████████████████████████████                  | 32/50 [19:48<12:29, 41.65s/it]Evaluating commonsenseqa :  66%|█████████████████████████████████                 | 33/50 [19:59<09:12, 32.47s/it]Evaluating commonsenseqa :  68%|██████████████████████████████████                | 34/50 [20:44<09:41, 36.35s/it]Evaluating commonsenseqa :  70%|███████████████████████████████████               | 35/50 [21:31<09:51, 39.44s/it]Evaluating commonsenseqa :  72%|████████████████████████████████████              | 36/50 [21:57<08:16, 35.43s/it]Evaluating commonsenseqa :  74%|█████████████████████████████████████             | 37/50 [22:17<06:41, 30.87s/it]Evaluating commonsenseqa :  76%|██████████████████████████████████████            | 38/50 [23:04<07:07, 35.64s/it]Evaluating commonsenseqa :  78%|███████████████████████████████████████           | 39/50 [23:25<05:45, 31.36s/it]Evaluating commonsenseqa :  80%|████████████████████████████████████████          | 40/50 [23:40<04:23, 26.38s/it]Evaluating commonsenseqa :  82%|█████████████████████████████████████████         | 41/50 [24:25<04:48, 32.01s/it]Evaluating commonsenseqa :  84%|██████████████████████████████████████████        | 42/50 [24:44<03:45, 28.13s/it]Evaluating commonsenseqa :  86%|███████████████████████████████████████████       | 43/50 [25:31<03:56, 33.84s/it]Evaluating commonsenseqa :  88%|████████████████████████████████████████████      | 44/50 [26:17<03:44, 37.46s/it]Evaluating commonsenseqa :  90%|█████████████████████████████████████████████     | 45/50 [27:03<03:20, 40.03s/it]Evaluating commonsenseqa :  92%|██████████████████████████████████████████████    | 46/50 [27:49<02:46, 41.73s/it]Evaluating commonsenseqa :  94%|███████████████████████████████████████████████   | 47/50 [28:33<02:07, 42.36s/it]Evaluating commonsenseqa :  96%|████████████████████████████████████████████████  | 48/50 [28:51<01:10, 35.06s/it]Evaluating commonsenseqa :  98%|█████████████████████████████████████████████████ | 49/50 [29:15<00:31, 31.83s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████████████████████| 50/50 [29:38<00:00, 29.06s/it]Evaluating commonsenseqa : 100%|██████████████████████████████████████████████████| 50/50 [29:38<00:00, 35.56s/it]
name: commonsenseqa | {'exact_match': 0.5, 'rougeL': 3.7362} | lm_loss 7.1105 | avg. gen lenth: 189.19
