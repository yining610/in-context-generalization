PYTHONPATH=/home/ylu130/workspace/in-context-generalization
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o1-tcommonsenseqa-s1-rTrue --seed 1 --rationales --num-out-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-12 14:45:42,402] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date![nltk_data]   Package punkt is already up-to-date!

arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o1-tcommonsenseqa-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 1
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o1-tcommonsenseqa-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  1%|▋                                                    | 92/7473 [00:00<00:08, 916.29it/s]  2%|█▎                                                  | 185/7473 [00:00<00:07, 923.44it/s]  4%|█▉                                                  | 278/7473 [00:00<00:07, 925.97it/s]  5%|██▌                                                 | 371/7473 [00:00<00:07, 907.16it/s]  6%|███▏                                                | 463/7473 [00:00<00:07, 911.50it/s]  7%|███▊                                                | 556/7473 [00:00<00:07, 915.62it/s]  9%|████▌                                               | 648/7473 [00:00<00:07, 916.99it/s] 10%|█████▏                                              | 743/7473 [00:00<00:07, 926.60it/s] 11%|█████▊                                              | 836/7473 [00:00<00:07, 927.21it/s] 12%|██████▍                                             | 930/7473 [00:01<00:07, 928.33it/s] 14%|██████▉                                            | 1024/7473 [00:01<00:06, 931.75it/s] 15%|███████▋                                           | 1118/7473 [00:01<00:06, 933.49it/s] 16%|████████▎                                          | 1212/7473 [00:01<00:06, 929.38it/s] 17%|████████▉                                          | 1305/7473 [00:01<00:06, 928.53it/s] 19%|█████████▌                                         | 1398/7473 [00:01<00:06, 926.50it/s] 20%|██████████▏                                        | 1492/7473 [00:01<00:06, 929.89it/s] 21%|██████████▊                                        | 1585/7473 [00:01<00:06, 927.98it/s] 22%|███████████▍                                       | 1678/7473 [00:01<00:06, 927.20it/s] 24%|████████████                                       | 1771/7473 [00:01<00:06, 927.55it/s] 25%|████████████▋                                      | 1864/7473 [00:02<00:06, 923.96it/s] 26%|█████████████▎                                     | 1957/7473 [00:02<00:05, 921.35it/s] 27%|█████████████▉                                     | 2051/7473 [00:02<00:05, 925.27it/s] 29%|██████████████▋                                    | 2144/7473 [00:02<00:05, 923.63it/s] 30%|███████████████▎                                   | 2238/7473 [00:02<00:05, 927.24it/s] 31%|███████████████▉                                   | 2331/7473 [00:02<00:05, 926.18it/s] 32%|████████████████▌                                  | 2424/7473 [00:02<00:05, 917.49it/s] 34%|█████████████████▏                                 | 2516/7473 [00:02<00:05, 917.43it/s] 35%|█████████████████▊                                 | 2608/7473 [00:02<00:05, 911.46it/s] 37%|██████████████████▍                               | 2750/7473 [00:02<00:04, 1061.46it/s] 39%|███████████████████▎                              | 2893/7473 [00:03<00:03, 1170.35it/s] 41%|████████████████████▎                             | 3036/7473 [00:03<00:03, 1247.36it/s] 43%|█████████████████████▎                            | 3177/7473 [00:03<00:03, 1295.02it/s] 44%|██████████████████████▏                           | 3319/7473 [00:03<00:03, 1330.90it/s] 46%|███████████████████████▏                          | 3458/7473 [00:03<00:02, 1347.28it/s] 48%|████████████████████████                          | 3601/7473 [00:03<00:02, 1371.40it/s] 50%|█████████████████████████                         | 3741/7473 [00:03<00:02, 1378.42it/s] 52%|█████████████████████████▉                        | 3882/7473 [00:03<00:02, 1386.36it/s] 54%|██████████████████████████▉                       | 4025/7473 [00:03<00:02, 1399.23it/s] 56%|███████████████████████████▊                      | 4165/7473 [00:03<00:02, 1390.36it/s] 58%|████████████████████████████▊                     | 4306/7473 [00:04<00:02, 1395.09it/s] 60%|█████████████████████████████▊                    | 4447/7473 [00:04<00:02, 1398.84it/s] 61%|██████████████████████████████▋                   | 4589/7473 [00:04<00:02, 1403.38it/s] 63%|███████████████████████████████▋                  | 4731/7473 [00:04<00:01, 1406.43it/s] 65%|████████████████████████████████▌                 | 4872/7473 [00:04<00:01, 1406.11it/s] 67%|█████████████████████████████████▌                | 5015/7473 [00:04<00:01, 1410.37it/s] 69%|██████████████████████████████████▌               | 5157/7473 [00:04<00:01, 1410.36it/s] 71%|███████████████████████████████████▍              | 5299/7473 [00:04<00:01, 1374.48it/s] 73%|████████████████████████████████████▍             | 5439/7473 [00:04<00:01, 1381.92it/s] 75%|█████████████████████████████████████▎            | 5578/7473 [00:05<00:01, 1150.19it/s] 77%|██████████████████████████████████████▎           | 5718/7473 [00:05<00:01, 1214.35it/s] 78%|███████████████████████████████████████▏          | 5859/7473 [00:05<00:01, 1266.48it/s] 80%|████████████████████████████████████████▏         | 5998/7473 [00:05<00:01, 1299.01it/s] 82%|█████████████████████████████████████████         | 6140/7473 [00:05<00:01, 1330.87it/s] 84%|██████████████████████████████████████████        | 6282/7473 [00:05<00:00, 1355.21it/s] 86%|██████████████████████████████████████████▉       | 6422/7473 [00:05<00:00, 1365.80it/s] 88%|███████████████████████████████████████████▉      | 6560/7473 [00:05<00:00, 1369.58it/s] 90%|████████████████████████████████████████████▊     | 6700/7473 [00:05<00:00, 1376.62it/s] 92%|█████████████████████████████████████████████▊    | 6839/7473 [00:05<00:00, 1379.72it/s] 93%|██████████████████████████████████████████████▋   | 6981/7473 [00:06<00:00, 1389.18it/s] 95%|███████████████████████████████████████████████▋  | 7121/7473 [00:06<00:00, 1387.27it/s] 97%|████████████████████████████████████████████████▌ | 7262/7473 [00:06<00:00, 1390.79it/s] 99%|█████████████████████████████████████████████████▌| 7402/7473 [00:06<00:00, 1391.60it/s]100%|██████████████████████████████████████████████████| 7473/7473 [00:06<00:00, 1173.20it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:04<00:09,  4.94s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.59s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.64s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:04<00:09,  4.99s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:09<00:04,  4.96s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.41s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.45s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.07s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.33s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.50s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.85s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.02s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.42s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.59s/it]
[2023-08-12 14:46:42,450] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.78s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.98s/it]
[2023-08-12 14:46:50,120] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 14:46:50,121] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 14:46:50,121] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 14:46:50,121] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 14:46:50,121] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 14:46:50,121] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 14:46:50,121] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 14:46:50,121] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 14:46:50,121] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 14:46:50,121] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 14:46:50,121] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 14:46:50,121] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f039cd39fa0>
[2023-08-12 14:46:50,121] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f039cd2f700>
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 14:46:50,123] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 14:46:50,123] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 14:46:50,123] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 14:46:50,123] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.40041279792785645 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Rationales: 1. The question is about finding a location where the plumbing system would not help in quenching your thirst.
2. The given options are oil refineries, a wall, a show, own home, and a water fountain.
3. When we think about the role of plumbing, it is to carry water or other fluids from one place to another.
4. Thinking logically, 'wall' and'show' are irrelevant as they do not in general have a plumbing system.
5. At your own home and a water fountain, the plumbing system carries water which you can drink.
6. So they are also not correct answers.
7. Now considering oil refineries, they do indeed have complex plumbing systems, but here the liquid being carried isn't drinkable water, but oil.
8. Therefore, the plumbing in an oil refinery wouldn't be of use to quench your thirst.
9. Hence, the correct answer is A: oil refineries.
Answer: A: oil refineries

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o1-tcommonsenseqa-s1-rTrue
Loading extension module utils...
Time to load utils op: 0.3041253089904785 seconds
Loading extension module utils...
Time to load utils op: 0.3042893409729004 seconds
Loading extension module utils...
Time to load utils op: 0.30423426628112793 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:52<42:58, 52.63s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:44<41:38, 52.06s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:35<40:37, 51.85s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [03:27<39:36, 51.67s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [04:18<38:35, 51.46s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [05:10<38:01, 51.85s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [06:03<37:13, 51.95s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [06:54<36:16, 51.83s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [07:46<35:26, 51.86s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [08:38<34:37, 51.94s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [09:31<33:55, 52.19s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [10:08<30:08, 47.59s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [10:49<28:00, 45.42s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [11:40<28:23, 47.33s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [12:32<28:24, 48.71s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [13:24<28:10, 49.72s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [13:54<24:07, 43.85s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [14:46<24:40, 46.25s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [15:38<24:45, 47.90s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [16:31<24:42, 49.41s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [17:23<24:19, 50.33s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [18:09<22:51, 48.99s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [19:02<22:31, 50.04s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [19:54<21:58, 50.72s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [20:45<21:08, 50.74s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [21:33<20:00, 50.00s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [22:22<18:59, 49.56s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [23:14<18:28, 50.37s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [24:06<17:49, 50.93s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [24:39<15:08, 45.44s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [25:30<14:53, 47.03s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [26:22<14:35, 48.65s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [27:14<14:04, 49.66s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [28:06<13:26, 50.39s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [28:58<12:41, 50.77s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [29:50<11:56, 51.17s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [30:28<10:13, 47.22s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [31:19<09:40, 48.35s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [32:11<09:04, 49.48s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [33:02<08:18, 49.88s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [33:52<07:30, 50.01s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [34:45<06:45, 50.74s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [35:37<05:57, 51.12s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [36:28<05:08, 51.36s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [37:21<04:18, 51.75s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [38:12<03:26, 51.61s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [39:04<02:35, 51.67s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [39:56<01:43, 51.66s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [40:48<00:51, 51.71s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [41:40<00:00, 51.84s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [41:40<00:00, 50.01s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.1842} | lm_loss 10.3322 | avg. gen lenth: 324.428
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o2-tcommonsenseqa-s1-rTrue --seed 1 --rationales --num-out-domain 2
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-12 15:29:11,929] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o2-tcommonsenseqa-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 2
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o2-tcommonsenseqa-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  1%|▎                                                    | 44/7473 [00:00<00:17, 434.28it/s]  1%|▋                                                    | 89/7473 [00:00<00:16, 438.35it/s]  2%|▉                                                   | 133/7473 [00:00<00:16, 438.75it/s]  2%|█▏                                                  | 178/7473 [00:00<00:16, 440.58it/s]  3%|█▌                                                  | 223/7473 [00:00<00:16, 442.47it/s]  4%|█▊                                                  | 268/7473 [00:00<00:16, 439.81it/s]  4%|██▏                                                 | 313/7473 [00:00<00:16, 441.04it/s]  5%|██▍                                                 | 358/7473 [00:00<00:16, 441.54it/s]  5%|██▊                                                 | 403/7473 [00:00<00:16, 432.05it/s]  6%|███                                                 | 447/7473 [00:01<00:16, 433.74it/s]  7%|███▍                                                | 491/7473 [00:01<00:16, 433.11it/s]  7%|███▋                                                | 536/7473 [00:01<00:15, 435.58it/s]  8%|████                                                | 581/7473 [00:01<00:15, 437.00it/s]  8%|████▎                                               | 625/7473 [00:01<00:15, 437.17it/s]  9%|████▋                                               | 670/7473 [00:01<00:15, 439.20it/s] 10%|████▉                                               | 715/7473 [00:01<00:15, 439.73it/s] 10%|█████▎                                              | 760/7473 [00:01<00:15, 441.28it/s] 11%|█████▌                                              | 805/7473 [00:01<00:15, 440.67it/s] 11%|█████▉                                              | 850/7473 [00:01<00:15, 437.77it/s] 12%|██████▏                                             | 894/7473 [00:02<00:15, 438.23it/s] 13%|██████▌                                             | 938/7473 [00:02<00:14, 437.46it/s] 13%|██████▊                                             | 983/7473 [00:02<00:14, 440.02it/s] 14%|███████                                            | 1028/7473 [00:02<00:14, 442.88it/s] 15%|███████▍                                           | 1095/7473 [00:02<00:12, 508.39it/s] 16%|███████▉                                           | 1161/7473 [00:02<00:11, 552.52it/s] 16%|████████▍                                          | 1228/7473 [00:02<00:10, 585.92it/s] 17%|████████▊                                          | 1295/7473 [00:02<00:10, 609.63it/s] 18%|█████████▎                                         | 1362/7473 [00:02<00:09, 625.27it/s] 19%|█████████▋                                         | 1426/7473 [00:02<00:09, 628.48it/s] 20%|██████████▏                                        | 1493/7473 [00:03<00:09, 639.38it/s] 21%|██████████▋                                        | 1559/7473 [00:03<00:09, 645.38it/s] 22%|███████████                                        | 1624/7473 [00:03<00:09, 645.50it/s] 23%|███████████▌                                       | 1690/7473 [00:03<00:08, 649.31it/s] 23%|███████████▉                                       | 1756/7473 [00:03<00:08, 652.08it/s] 24%|████████████▍                                      | 1823/7473 [00:03<00:08, 654.84it/s] 25%|████████████▉                                      | 1889/7473 [00:03<00:08, 654.24it/s] 26%|█████████████▎                                     | 1955/7473 [00:03<00:08, 655.57it/s] 27%|█████████████▊                                     | 2022/7473 [00:03<00:08, 658.21it/s] 28%|██████████████▏                                    | 2088/7473 [00:03<00:08, 656.10it/s] 29%|██████████████▋                                    | 2154/7473 [00:04<00:08, 656.83it/s] 30%|███████████████▏                                   | 2221/7473 [00:04<00:07, 658.44it/s] 31%|███████████████▌                                   | 2288/7473 [00:04<00:07, 659.00it/s] 32%|████████████████                                   | 2354/7473 [00:04<00:07, 658.21it/s] 32%|████████████████▌                                  | 2420/7473 [00:04<00:07, 658.18it/s] 33%|████████████████▉                                  | 2487/7473 [00:04<00:07, 660.72it/s] 34%|█████████████████▍                                 | 2554/7473 [00:04<00:07, 631.35it/s] 35%|█████████████████▉                                 | 2621/7473 [00:04<00:07, 641.83it/s] 36%|██████████████████▎                                | 2688/7473 [00:04<00:07, 648.55it/s] 37%|██████████████████▊                                | 2754/7473 [00:04<00:07, 650.87it/s] 38%|███████████████████▎                               | 2821/7473 [00:05<00:07, 653.88it/s] 39%|███████████████████▋                               | 2888/7473 [00:05<00:06, 656.11it/s] 40%|████████████████████▏                              | 2955/7473 [00:05<00:06, 659.90it/s] 40%|████████████████████▌                              | 3022/7473 [00:05<00:06, 658.80it/s] 41%|█████████████████████                              | 3089/7473 [00:05<00:06, 659.82it/s] 42%|█████████████████████▌                             | 3156/7473 [00:05<00:06, 658.35it/s] 43%|█████████████████████▉                             | 3222/7473 [00:05<00:06, 657.04it/s] 44%|██████████████████████▍                            | 3288/7473 [00:05<00:06, 655.57it/s] 45%|██████████████████████▉                            | 3354/7473 [00:05<00:06, 656.03it/s] 46%|███████████████████████▎                           | 3420/7473 [00:05<00:06, 656.55it/s] 47%|███████████████████████▊                           | 3486/7473 [00:06<00:06, 655.44it/s] 48%|████████████████████████▏                          | 3552/7473 [00:06<00:05, 656.02it/s] 48%|████████████████████████▋                          | 3619/7473 [00:06<00:05, 658.87it/s] 49%|█████████████████████████▏                         | 3685/7473 [00:06<00:05, 656.30it/s] 50%|█████████████████████████▌                         | 3751/7473 [00:06<00:05, 655.22it/s] 51%|██████████████████████████                         | 3818/7473 [00:06<00:05, 658.43it/s] 52%|██████████████████████████▌                        | 3884/7473 [00:06<00:05, 656.23it/s] 53%|██████████████████████████▉                        | 3951/7473 [00:06<00:05, 658.54it/s] 54%|███████████████████████████▍                       | 4018/7473 [00:06<00:05, 660.40it/s] 55%|███████████████████████████▉                       | 4085/7473 [00:06<00:05, 661.33it/s] 56%|████████████████████████████▎                      | 4152/7473 [00:07<00:05, 651.23it/s] 56%|████████████████████████████▊                      | 4218/7473 [00:07<00:04, 652.80it/s] 57%|█████████████████████████████▏                     | 4284/7473 [00:07<00:04, 645.45it/s] 58%|█████████████████████████████▋                     | 4349/7473 [00:07<00:04, 646.00it/s] 59%|██████████████████████████████▏                    | 4415/7473 [00:07<00:04, 649.23it/s] 60%|██████████████████████████████▌                    | 4481/7473 [00:07<00:04, 651.42it/s] 61%|███████████████████████████████                    | 4547/7473 [00:07<00:04, 651.37it/s] 62%|███████████████████████████████▍                   | 4613/7473 [00:07<00:04, 651.88it/s] 63%|███████████████████████████████▉                   | 4679/7473 [00:07<00:04, 653.64it/s] 63%|████████████████████████████████▍                  | 4745/7473 [00:08<00:04, 637.33it/s] 64%|████████████████████████████████▊                  | 4811/7473 [00:08<00:04, 642.88it/s] 65%|█████████████████████████████████▎                 | 4877/7473 [00:08<00:04, 647.83it/s] 66%|█████████████████████████████████▋                 | 4943/7473 [00:08<00:03, 650.50it/s] 67%|██████████████████████████████████▏                | 5009/7473 [00:08<00:03, 644.05it/s] 68%|██████████████████████████████████▋                | 5075/7473 [00:08<00:03, 647.86it/s] 69%|███████████████████████████████████                | 5142/7473 [00:08<00:03, 652.29it/s] 70%|███████████████████████████████████▌               | 5209/7473 [00:08<00:03, 655.77it/s] 71%|███████████████████████████████████▉               | 5275/7473 [00:08<00:03, 622.72it/s] 71%|████████████████████████████████████▍              | 5341/7473 [00:08<00:03, 633.28it/s] 72%|████████████████████████████████████▉              | 5407/7473 [00:09<00:03, 640.83it/s] 73%|█████████████████████████████████████▎             | 5472/7473 [00:09<00:04, 475.11it/s] 74%|█████████████████████████████████████▊             | 5538/7473 [00:09<00:03, 517.67it/s] 75%|██████████████████████████████████████▏            | 5603/7473 [00:09<00:03, 549.77it/s] 76%|██████████████████████████████████████▋            | 5670/7473 [00:09<00:03, 579.52it/s] 77%|███████████████████████████████████████▏           | 5736/7473 [00:09<00:02, 600.10it/s] 78%|███████████████████████████████████████▌           | 5801/7473 [00:09<00:02, 613.11it/s] 79%|████████████████████████████████████████           | 5867/7473 [00:09<00:02, 625.70it/s] 79%|████████████████████████████████████████▍          | 5932/7473 [00:09<00:02, 632.22it/s] 80%|████████████████████████████████████████▉          | 5998/7473 [00:10<00:02, 639.00it/s] 81%|█████████████████████████████████████████▍         | 6065/7473 [00:10<00:02, 646.40it/s] 82%|█████████████████████████████████████████▊         | 6132/7473 [00:10<00:02, 650.46it/s] 83%|██████████████████████████████████████████▎        | 6199/7473 [00:10<00:01, 654.27it/s] 84%|██████████████████████████████████████████▊        | 6265/7473 [00:10<00:01, 650.93it/s] 85%|███████████████████████████████████████████▏       | 6331/7473 [00:10<00:01, 651.97it/s] 86%|███████████████████████████████████████████▋       | 6397/7473 [00:10<00:01, 650.72it/s] 86%|████████████████████████████████████████████       | 6464/7473 [00:10<00:01, 653.84it/s] 87%|████████████████████████████████████████████▌      | 6531/7473 [00:10<00:01, 656.20it/s] 88%|█████████████████████████████████████████████      | 6597/7473 [00:10<00:01, 656.76it/s] 89%|█████████████████████████████████████████████▍     | 6663/7473 [00:11<00:01, 656.65it/s] 90%|█████████████████████████████████████████████▉     | 6729/7473 [00:11<00:01, 657.51it/s] 91%|██████████████████████████████████████████████▎    | 6795/7473 [00:11<00:01, 658.06it/s] 92%|██████████████████████████████████████████████▊    | 6861/7473 [00:11<00:00, 654.94it/s] 93%|███████████████████████████████████████████████▎   | 6928/7473 [00:11<00:00, 657.63it/s] 94%|███████████████████████████████████████████████▋   | 6994/7473 [00:11<00:00, 654.31it/s] 94%|████████████████████████████████████████████████▏  | 7060/7473 [00:11<00:00, 650.53it/s] 95%|████████████████████████████████████████████████▋  | 7126/7473 [00:11<00:00, 652.86it/s] 96%|█████████████████████████████████████████████████  | 7193/7473 [00:11<00:00, 655.33it/s] 97%|█████████████████████████████████████████████████▌ | 7260/7473 [00:12<00:00, 658.46it/s] 98%|█████████████████████████████████████████████████▉ | 7326/7473 [00:12<00:00, 657.65it/s] 99%|██████████████████████████████████████████████████▍| 7392/7473 [00:12<00:00, 658.08it/s]100%|██████████████████████████████████████████████████▉| 7458/7473 [00:12<00:00, 654.58it/s]100%|███████████████████████████████████████████████████| 7473/7473 [00:12<00:00, 606.23it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.13s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.53s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.63s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.73s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.03s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.59s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.52s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.52s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.41s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.59s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.83s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.03s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.83s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.03s/it]
[2023-08-12 15:30:16,882] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.85s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.05s/it]
[2023-08-12 15:30:27,028] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 15:30:27,030] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 15:30:27,030] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 15:30:27,030] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 15:30:27,031] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 15:30:27,031] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 15:30:27,031] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 15:30:27,031] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 15:30:27,031] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 15:30:27,031] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 15:30:27,031] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 15:30:27,031] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f8a89120b20>
[2023-08-12 15:30:27,031] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 15:30:27,031] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 15:30:27,031] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 15:30:27,031] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f8a891208b0>
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 15:30:27,034] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.46192216873168945 seconds
Loading extension module utils...
Time to load utils op: 0.40457606315612793 seconds
Loading extension module utils...
Loading extension module utils...
Time to load utils op: 0.5049164295196533 seconds
Time to load utils op: 0.5049271583557129 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Rationales: 1. The question is asking where you could find some plumbing that you couldn't use to quench your thirst. 
2. Let's consider each choice one by one:
3. Option A is oil refineries. Plumbing in oil refineries is used to transport oil and other substances as part of the refining process. You cannot drink oil, so this plumbing would not be of use if you are thirsty.
4. Option B is a wall. Although plumbing can be found in walls in homes, offices, etc., it typically carries water, so it could potentially be helpful if you are thirsty.
5. Option C is a show. This is a bit ambiguous as it could refers to a variety of things, but many types of shows such as concerts, theaters, tradeshows, etc. have water fountains or concession stands, so potentially you could find a drinkable water source there.
6. Option D is your own home. Most homes have plumbing system that provides clean, drinkable water, so this would be useful to you if you are thirsty.
7. Option E is a water fountain. Water fountains are made specifically for people to drink or quench their thirst, so definitely this would be useful if thirsty.
8. Based on this analysis, the only option that has plumbing system not used for supplying drinkable water is A: oil refineries. Therefore, this is the correct answer.
Answer: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Rationales: 1. The question asks what a person is not doing yet when they are beginning work.
2. We need to find an option that a person can't do while starting work.
3. Let's examine each choice.
4. Option A: working. This can't be the answer because the question states that the person is "beginning work," which means they are, in fact, working.
5. Option B: resting. This can't be the answer because a person can't start work and rest at the same time.
6. Option C: tiredness. This can't be the answer because tiredness isn't an action, so it can't be something someone is doing.
7. Option E: momentum. This can't be the answer because momentum is not something a person does, rather, it is something a person gains as they continue doing their work.
8. Therefore, the best answer is D: accomplishing. A person at the beginning of their work is not yet accomplishing their goals or tasks because they are just starting. The accomplishment comes after, as the result of the work.
Answer: D: accomplishing

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o2-tcommonsenseqa-s1-rTrue
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:48<39:12, 48.00s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:34<37:45, 47.19s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:07<31:40, 40.44s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [02:53<32:53, 42.90s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [03:40<33:20, 44.47s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [04:27<33:09, 45.22s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [05:13<32:36, 45.51s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [05:59<31:55, 45.62s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [06:46<31:25, 45.99s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [07:33<30:49, 46.23s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [08:18<29:56, 46.07s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [09:05<29:20, 46.32s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [09:52<28:43, 46.59s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [10:35<27:11, 45.33s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [11:22<26:47, 45.92s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [12:09<26:14, 46.30s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [12:56<25:35, 46.54s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [13:21<21:21, 40.05s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [14:08<21:46, 42.13s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [14:55<21:44, 43.49s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [15:41<21:26, 44.35s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [16:24<20:29, 43.92s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [17:11<20:07, 44.73s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [17:58<19:41, 45.44s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [18:40<18:27, 44.29s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [19:27<18:05, 45.23s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [20:14<17:29, 45.65s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [20:48<15:32, 42.37s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [21:35<15:13, 43.51s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [22:21<14:49, 44.49s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [23:08<14:20, 45.27s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [23:56<13:45, 45.86s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [24:33<12:17, 43.38s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [25:19<11:47, 44.23s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [26:06<11:15, 45.03s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [26:53<10:37, 45.57s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [27:28<09:10, 42.32s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [28:14<08:42, 43.54s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [29:01<08:09, 44.54s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [29:48<07:33, 45.32s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [30:35<06:50, 45.62s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [31:22<06:08, 46.02s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [32:08<05:23, 46.15s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [32:55<04:37, 46.29s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [33:41<03:51, 46.34s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [34:27<03:05, 46.32s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [35:14<02:19, 46.46s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [36:01<01:32, 46.42s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [36:46<00:46, 46.25s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [37:33<00:00, 46.37s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [37:33<00:00, 45.07s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.2849} | lm_loss 10.1472 | avg. gen lenth: 300.492
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o3-tcommonsenseqa-s1-rTrue --seed 1 --rationales --num-out-domain 3
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date![nltk_data]   Package punkt is already up-to-date!

using world size: 4
[2023-08-12 16:08:30,621] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o3-tcommonsenseqa-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 3
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o3-tcommonsenseqa-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  1%|▎                                                    | 47/7473 [00:00<00:15, 464.83it/s]  1%|▋                                                    | 95/7473 [00:00<00:15, 471.48it/s]  2%|▉                                                   | 143/7473 [00:00<00:15, 472.77it/s]  3%|█▎                                                  | 191/7473 [00:00<00:15, 475.26it/s]  3%|█▋                                                  | 239/7473 [00:00<00:15, 473.90it/s]  4%|█▉                                                  | 287/7473 [00:00<00:15, 473.40it/s]  4%|██▎                                                 | 335/7473 [00:00<00:15, 474.53it/s]  5%|██▋                                                 | 383/7473 [00:00<00:14, 475.34it/s]  6%|██▉                                                 | 431/7473 [00:00<00:15, 467.77it/s]  6%|███▎                                                | 478/7473 [00:01<00:14, 466.65it/s]  7%|███▋                                                | 526/7473 [00:01<00:14, 468.96it/s]  8%|███▉                                                | 574/7473 [00:01<00:14, 471.08it/s]  8%|████▎                                               | 622/7473 [00:01<00:14, 471.40it/s]  9%|████▋                                               | 670/7473 [00:01<00:14, 473.07it/s] 10%|████▉                                               | 718/7473 [00:01<00:14, 473.40it/s] 10%|█████▎                                              | 766/7473 [00:01<00:14, 474.75it/s] 11%|█████▋                                              | 814/7473 [00:01<00:14, 474.52it/s] 12%|█████▉                                              | 862/7473 [00:01<00:13, 474.88it/s] 12%|██████▎                                             | 910/7473 [00:01<00:13, 471.02it/s] 13%|██████▋                                             | 958/7473 [00:02<00:13, 470.84it/s] 13%|██████▊                                            | 1006/7473 [00:02<00:13, 473.27it/s] 14%|███████▏                                           | 1054/7473 [00:02<00:13, 474.91it/s] 15%|███████▌                                           | 1102/7473 [00:02<00:13, 475.57it/s] 15%|███████▊                                           | 1150/7473 [00:02<00:13, 474.57it/s] 16%|████████▏                                          | 1198/7473 [00:02<00:13, 471.29it/s] 17%|████████▌                                          | 1246/7473 [00:02<00:13, 471.66it/s] 17%|████████▊                                          | 1294/7473 [00:02<00:13, 471.72it/s] 18%|█████████▏                                         | 1342/7473 [00:02<00:12, 472.85it/s] 19%|█████████▍                                         | 1390/7473 [00:02<00:12, 470.24it/s] 19%|█████████▊                                         | 1438/7473 [00:03<00:12, 471.37it/s] 20%|██████████▏                                        | 1486/7473 [00:03<00:12, 473.02it/s] 21%|██████████▍                                        | 1534/7473 [00:03<00:12, 473.76it/s] 21%|██████████▊                                        | 1582/7473 [00:03<00:12, 472.29it/s] 22%|███████████                                        | 1630/7473 [00:03<00:12, 470.58it/s] 22%|███████████▍                                       | 1678/7473 [00:03<00:12, 471.28it/s] 23%|███████████▊                                       | 1726/7473 [00:03<00:12, 471.69it/s] 24%|████████████                                       | 1774/7473 [00:03<00:12, 471.12it/s] 24%|████████████▍                                      | 1822/7473 [00:03<00:12, 470.55it/s] 25%|████████████▊                                      | 1870/7473 [00:03<00:11, 468.49it/s] 26%|█████████████                                      | 1918/7473 [00:04<00:11, 469.10it/s] 26%|█████████████▍                                     | 1966/7473 [00:04<00:11, 470.18it/s] 27%|█████████████▋                                     | 2014/7473 [00:04<00:11, 471.32it/s] 28%|██████████████                                     | 2062/7473 [00:04<00:11, 472.33it/s] 28%|██████████████▍                                    | 2110/7473 [00:04<00:11, 468.81it/s] 29%|██████████████▋                                    | 2157/7473 [00:04<00:11, 469.14it/s] 30%|███████████████                                    | 2205/7473 [00:04<00:11, 470.47it/s] 30%|███████████████▍                                   | 2253/7473 [00:04<00:11, 470.84it/s] 31%|███████████████▋                                   | 2301/7473 [00:04<00:11, 467.83it/s] 31%|████████████████                                   | 2348/7473 [00:04<00:10, 468.22it/s] 32%|████████████████▎                                  | 2396/7473 [00:05<00:10, 469.56it/s] 33%|████████████████▋                                  | 2444/7473 [00:05<00:10, 471.42it/s] 33%|█████████████████                                  | 2492/7473 [00:05<00:10, 470.94it/s] 34%|█████████████████▎                                 | 2540/7473 [00:05<00:11, 441.80it/s] 35%|█████████████████▋                                 | 2588/7473 [00:05<00:10, 450.54it/s] 35%|█████████████████▉                                 | 2635/7473 [00:05<00:10, 455.70it/s] 36%|██████████████████▎                                | 2683/7473 [00:05<00:10, 461.39it/s] 37%|██████████████████▋                                | 2730/7473 [00:05<00:10, 461.46it/s] 37%|██████████████████▉                                | 2777/7473 [00:05<00:10, 463.36it/s] 38%|███████████████████▎                               | 2825/7473 [00:06<00:09, 466.35it/s] 38%|███████████████████▌                               | 2873/7473 [00:06<00:09, 467.84it/s] 39%|███████████████████▉                               | 2921/7473 [00:06<00:09, 470.14it/s] 40%|████████████████████▎                              | 2969/7473 [00:06<00:09, 472.11it/s] 40%|████████████████████▌                              | 3017/7473 [00:06<00:09, 469.20it/s] 41%|████████████████████▉                              | 3064/7473 [00:06<00:09, 467.15it/s] 42%|█████████████████████▏                             | 3111/7473 [00:06<00:09, 466.07it/s] 42%|█████████████████████▌                             | 3158/7473 [00:06<00:09, 466.18it/s] 43%|█████████████████████▊                             | 3205/7473 [00:06<00:09, 465.21it/s] 44%|██████████████████████▏                            | 3252/7473 [00:06<00:09, 466.30it/s] 44%|██████████████████████▌                            | 3299/7473 [00:07<00:08, 466.91it/s] 45%|██████████████████████▊                            | 3346/7473 [00:07<00:08, 462.14it/s] 45%|███████████████████████▏                           | 3393/7473 [00:07<00:08, 463.03it/s] 46%|███████████████████████▍                           | 3440/7473 [00:07<00:08, 462.61it/s] 47%|███████████████████████▊                           | 3487/7473 [00:07<00:08, 463.52it/s] 47%|████████████████████████                           | 3534/7473 [00:07<00:08, 465.16it/s] 48%|████████████████████████▍                          | 3581/7473 [00:07<00:08, 465.82it/s] 49%|████████████████████████▊                          | 3628/7473 [00:07<00:08, 466.44it/s] 49%|█████████████████████████                          | 3675/7473 [00:07<00:08, 464.64it/s] 50%|█████████████████████████▍                         | 3723/7473 [00:07<00:08, 466.43it/s] 50%|█████████████████████████▋                         | 3770/7473 [00:08<00:07, 467.40it/s] 51%|██████████████████████████                         | 3818/7473 [00:08<00:07, 469.19it/s] 52%|██████████████████████████▍                        | 3865/7473 [00:08<00:07, 469.02it/s] 52%|██████████████████████████▋                        | 3912/7473 [00:08<00:07, 467.93it/s] 53%|███████████████████████████                        | 3959/7473 [00:08<00:07, 465.28it/s] 54%|███████████████████████████▎                       | 4006/7473 [00:08<00:07, 464.79it/s] 54%|███████████████████████████▋                       | 4053/7473 [00:08<00:07, 466.12it/s] 55%|███████████████████████████▉                       | 4100/7473 [00:08<00:07, 463.31it/s] 55%|████████████████████████████▎                      | 4147/7473 [00:08<00:07, 461.29it/s] 56%|████████████████████████████▌                      | 4194/7473 [00:08<00:07, 463.69it/s] 57%|████████████████████████████▉                      | 4241/7473 [00:09<00:06, 465.49it/s] 57%|█████████████████████████████▎                     | 4288/7473 [00:09<00:06, 464.89it/s] 58%|█████████████████████████████▌                     | 4336/7473 [00:09<00:06, 464.81it/s] 59%|█████████████████████████████▉                     | 4383/7473 [00:09<00:06, 464.69it/s] 59%|██████████████████████████████▏                    | 4430/7473 [00:09<00:06, 463.81it/s] 60%|██████████████████████████████▌                    | 4477/7473 [00:09<00:06, 463.90it/s] 61%|██████████████████████████████▊                    | 4524/7473 [00:09<00:06, 464.69it/s] 61%|███████████████████████████████▏                   | 4571/7473 [00:09<00:06, 459.30it/s] 62%|███████████████████████████████▌                   | 4618/7473 [00:09<00:06, 462.22it/s] 62%|███████████████████████████████▊                   | 4665/7473 [00:09<00:06, 463.53it/s] 63%|████████████████████████████████▏                  | 4712/7473 [00:10<00:05, 464.30it/s] 64%|████████████████████████████████▍                  | 4759/7473 [00:10<00:05, 464.54it/s] 64%|████████████████████████████████▊                  | 4806/7473 [00:10<00:05, 463.15it/s] 65%|█████████████████████████████████                  | 4853/7473 [00:10<00:05, 464.74it/s] 66%|█████████████████████████████████▍                 | 4900/7473 [00:10<00:05, 465.64it/s] 66%|█████████████████████████████████▊                 | 4947/7473 [00:10<00:05, 464.34it/s] 67%|██████████████████████████████████                 | 4994/7473 [00:10<00:05, 464.97it/s] 67%|██████████████████████████████████▍                | 5041/7473 [00:10<00:05, 466.11it/s] 68%|██████████████████████████████████▋                | 5088/7473 [00:10<00:05, 465.72it/s] 69%|███████████████████████████████████                | 5135/7473 [00:10<00:05, 465.50it/s] 69%|███████████████████████████████████▎               | 5183/7473 [00:11<00:04, 466.95it/s] 70%|███████████████████████████████████▋               | 5231/7473 [00:11<00:04, 468.63it/s] 71%|████████████████████████████████████               | 5278/7473 [00:11<00:05, 428.07it/s] 71%|████████████████████████████████████▎              | 5325/7473 [00:11<00:04, 438.84it/s] 72%|████████████████████████████████████▋              | 5372/7473 [00:11<00:04, 447.07it/s] 73%|████████████████████████████████████▉              | 5419/7473 [00:11<00:04, 453.11it/s] 73%|█████████████████████████████████████▎             | 5466/7473 [00:11<00:04, 457.64it/s] 74%|█████████████████████████████████████▌             | 5512/7473 [00:11<00:05, 328.15it/s] 74%|█████████████████████████████████████▉             | 5559/7473 [00:12<00:05, 359.52it/s] 75%|██████████████████████████████████████▎            | 5606/7473 [00:12<00:04, 385.59it/s] 76%|██████████████████████████████████████▌            | 5653/7473 [00:12<00:04, 407.13it/s] 76%|██████████████████████████████████████▉            | 5698/7473 [00:12<00:04, 418.48it/s] 77%|███████████████████████████████████████▏           | 5745/7473 [00:12<00:04, 431.95it/s] 78%|███████████████████████████████████████▌           | 5792/7473 [00:12<00:03, 440.69it/s] 78%|███████████████████████████████████████▊           | 5839/7473 [00:12<00:03, 448.04it/s] 79%|████████████████████████████████████████▏          | 5886/7473 [00:12<00:03, 452.35it/s] 79%|████████████████████████████████████████▍          | 5932/7473 [00:12<00:03, 445.93it/s] 80%|████████████████████████████████████████▊          | 5979/7473 [00:12<00:03, 450.41it/s] 81%|█████████████████████████████████████████          | 6025/7473 [00:13<00:03, 450.45it/s] 81%|█████████████████████████████████████████▍         | 6072/7473 [00:13<00:03, 455.87it/s] 82%|█████████████████████████████████████████▊         | 6119/7473 [00:13<00:02, 459.62it/s] 83%|██████████████████████████████████████████         | 6166/7473 [00:13<00:02, 459.48it/s] 83%|██████████████████████████████████████████▍        | 6213/7473 [00:13<00:02, 462.29it/s] 84%|██████████████████████████████████████████▋        | 6260/7473 [00:13<00:02, 463.36it/s] 84%|███████████████████████████████████████████        | 6307/7473 [00:13<00:02, 464.42it/s] 85%|███████████████████████████████████████████▎       | 6354/7473 [00:13<00:02, 465.65it/s] 86%|███████████████████████████████████████████▋       | 6401/7473 [00:13<00:02, 462.82it/s] 86%|████████████████████████████████████████████       | 6448/7473 [00:13<00:02, 463.89it/s] 87%|████████████████████████████████████████████▎      | 6495/7473 [00:14<00:02, 463.65it/s] 88%|████████████████████████████████████████████▋      | 6542/7473 [00:14<00:02, 462.14it/s] 88%|████████████████████████████████████████████▉      | 6589/7473 [00:14<00:01, 462.74it/s] 89%|█████████████████████████████████████████████▎     | 6636/7473 [00:14<00:01, 464.29it/s] 89%|█████████████████████████████████████████████▌     | 6683/7473 [00:14<00:01, 462.56it/s] 90%|█████████████████████████████████████████████▉     | 6730/7473 [00:14<00:01, 460.95it/s] 91%|██████████████████████████████████████████████▎    | 6777/7473 [00:14<00:01, 460.61it/s] 91%|██████████████████████████████████████████████▌    | 6824/7473 [00:14<00:01, 459.27it/s] 92%|██████████████████████████████████████████████▉    | 6871/7473 [00:14<00:01, 460.15it/s] 93%|███████████████████████████████████████████████▏   | 6918/7473 [00:15<00:01, 460.78it/s] 93%|███████████████████████████████████████████████▌   | 6965/7473 [00:15<00:01, 460.87it/s] 94%|███████████████████████████████████████████████▊   | 7012/7473 [00:15<00:01, 460.30it/s] 94%|████████████████████████████████████████████████▏  | 7059/7473 [00:15<00:00, 458.62it/s] 95%|████████████████████████████████████████████████▍  | 7106/7473 [00:15<00:00, 460.38it/s] 96%|████████████████████████████████████████████████▊  | 7153/7473 [00:15<00:00, 460.40it/s] 96%|█████████████████████████████████████████████████▏ | 7200/7473 [00:15<00:00, 461.15it/s] 97%|█████████████████████████████████████████████████▍ | 7247/7473 [00:15<00:00, 462.92it/s] 98%|█████████████████████████████████████████████████▊ | 7294/7473 [00:15<00:00, 461.71it/s] 98%|██████████████████████████████████████████████████ | 7341/7473 [00:15<00:00, 461.61it/s] 99%|██████████████████████████████████████████████████▍| 7388/7473 [00:16<00:00, 462.47it/s] 99%|██████████████████████████████████████████████████▋| 7435/7473 [00:16<00:00, 463.01it/s]100%|███████████████████████████████████████████████████| 7473/7473 [00:16<00:00, 461.21it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.09s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.55s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.34s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.06s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:09<00:04,  4.96s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.52s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.45s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.35s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.53s/it]
Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.02s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.89s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.06s/it]
[2023-08-12 16:09:39,599] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.85s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.00s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.39s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.56s/it]
[2023-08-12 16:09:48,531] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 16:09:48,533] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 16:09:48,533] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 16:09:48,533] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 16:09:48,533] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 16:09:48,533] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f395da57fa0>
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f395da6f700>
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 16:09:48,536] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 16:09:48,536] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 16:09:48,536] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 16:09:48,536] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.43941259384155273 seconds
Loading extension module utils...
Time to load utils op: 0.4049239158630371 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Loading extension module utils...
Time to load utils op: 0.40436267852783203 seconds
Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Loading extension module utils...
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Rationales: 1. If we are thirsty, we will need a source of water to quench our thirst.
2. Thinking about the choices given, let's evaluate them starting from A to E.
3. Choice A: Oil refineries. They do have plumbing but not to supply drinkable water to people. Instead, they have pipelines to transport crude oil and chemical substances.
4. Therefore, the plumbing of an oil refinery would be of no use to us if we are thirsty.
5. Now, let's look at the other choices to ascertain our answer. 
6. Choice B: Wall. A wall might house plumbing within a building, potentially a source of water.
7. Choice C: Show. This could refer to a variety of things but it generally doesn't provide water. However, there might be water available at a show depending on its nature, such as a trade show or an exhibition.
8. Choice D: Own home. Our own home would definitely have plumbing, and it would be very useful to us if we are thirsty.
9. Choice E: Water fountain. A water fountain would also have accessible water.
10. After assessing all choices, it is clear that the plumbing of an oil refinery would be the least useful if we are thirsty. So, the correct answer is A: Oil refineries.
Answer: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Rationales: 1. The question asks what a person isn't doing yet when they're just beginning to work.
2. We can cross out "A: working" because the person is actively engaging in work, as stated in the question.
3. Then, we can cross out "B: resting" because this suggests they are not doing any work, which contradicts the information provided.
4. We can also cross out "C: tiredness" because it's a state rather than an action and isn't relevant to the question.
5. Lastly, we can cross out "E: momentum" because it's more a state or result of action, rather than an action itself.
6. Therefore, the answer is "D: accomplishing" because when someone is just beginning to work, they haven't had the time to accomplish anything yet. It's the only option left and it makes logical sense based on the information provided in the question.
Answer: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Rationales: 1. The question is asking me where I can find pens with company logos. 
2. I start by understanding the nature of pens with a company logo which are usually provided by businesses or organizations and are not typically found on average consumer items.
3. Looking at choice B: it mentions a pencil, which is incorrect because pencils aren't usually embossed with company logos.
4. Choice C: involves writing sentences on paper. This choice is not relevant to the question as it doesn't specify a location.
5. Choice D: in schools, it is less likely to find pens with company logos as schools usually don't distribute company merchandise.
6. Choice E: in a backpack, you could find a wide range of items including pens, but it doesn't specifically relate to pens with a company logo.
7. Choice A: is an office. Considering offices are places where business transactions occur, it's logical to assume that pens with company logos could be found here.
8. So, the answer is A: Office.
Answer: A: office

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o3-tcommonsenseqa-s1-rTrue
Time to load utils op: 0.5044100284576416 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:44<36:30, 44.71s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:28<35:15, 44.08s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:13<34:53, 44.54s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [02:57<34:02, 44.41s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [03:42<33:19, 44.44s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [04:16<30:00, 40.93s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [05:00<30:05, 41.99s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [05:44<29:52, 42.67s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [06:28<29:30, 43.19s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [07:12<28:58, 43.45s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [07:56<28:21, 43.64s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [08:40<27:42, 43.74s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [09:25<27:03, 43.87s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [10:09<26:22, 43.95s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [10:53<25:40, 44.01s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [11:37<24:58, 44.06s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [12:22<24:25, 44.40s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [13:06<23:35, 44.24s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [13:50<22:47, 44.10s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [14:34<22:01, 44.06s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [15:17<21:10, 43.82s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [16:01<20:27, 43.83s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [16:46<19:50, 44.08s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [17:29<19:02, 43.94s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [18:13<18:16, 43.87s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [18:57<17:33, 43.90s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [19:42<16:55, 44.16s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [20:25<16:06, 43.92s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [21:09<15:20, 43.85s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [21:52<14:36, 43.80s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [22:36<13:50, 43.71s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [23:20<13:09, 43.84s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [24:04<12:27, 43.98s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [24:49<11:47, 44.23s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [25:34<11:03, 44.25s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [26:17<10:17, 44.13s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [27:02<09:35, 44.24s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [27:46<08:52, 44.35s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [28:30<08:06, 44.25s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [29:15<07:23, 44.36s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [29:59<06:38, 44.31s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [30:43<05:53, 44.19s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [31:27<05:08, 44.12s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [32:11<04:24, 44.12s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [32:56<03:41, 44.23s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [33:40<02:56, 44.17s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [34:24<02:12, 44.24s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [35:09<01:28, 44.29s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [35:53<00:44, 44.28s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [36:37<00:00, 44.32s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [36:37<00:00, 43.96s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.2907} | lm_loss 10.2633 | avg. gen lenth: 339.444
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o4-tcommonsenseqa-s1-rTrue --seed 1 --rationales --num-out-domain 4
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-12 16:46:34,359] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o4-tcommonsenseqa-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 4
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o4-tcommonsenseqa-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  0%|▏                                                    | 21/7473 [00:00<00:36, 203.55it/s]  1%|▎                                                    | 42/7473 [00:00<00:36, 204.23it/s]  1%|▍                                                    | 63/7473 [00:00<00:36, 204.50it/s]  1%|▌                                                    | 84/7473 [00:00<00:36, 205.10it/s]  1%|▋                                                   | 105/7473 [00:00<00:35, 205.13it/s]  2%|▉                                                   | 126/7473 [00:00<00:35, 205.37it/s]  2%|█                                                   | 147/7473 [00:00<00:35, 205.41it/s]  2%|█▏                                                  | 168/7473 [00:00<00:36, 202.72it/s]  3%|█▎                                                  | 189/7473 [00:00<00:35, 203.70it/s]  3%|█▍                                                  | 210/7473 [00:01<00:35, 204.78it/s]  3%|█▌                                                  | 231/7473 [00:01<00:35, 205.14it/s]  3%|█▊                                                  | 252/7473 [00:01<00:35, 203.19it/s]  4%|█▉                                                  | 273/7473 [00:01<00:35, 204.06it/s]  4%|██                                                  | 294/7473 [00:01<00:35, 204.61it/s]  4%|██▏                                                 | 315/7473 [00:01<00:34, 205.03it/s]  5%|██▎                                                 | 339/7473 [00:01<00:33, 214.00it/s]  5%|██▌                                                 | 371/7473 [00:01<00:29, 243.43it/s]  5%|██▊                                                 | 402/7473 [00:01<00:27, 260.76it/s]  6%|███                                                 | 434/7473 [00:01<00:25, 275.86it/s]  6%|███▏                                                | 466/7473 [00:02<00:24, 286.77it/s]  7%|███▍                                                | 497/7473 [00:02<00:23, 291.59it/s]  7%|███▋                                                | 529/7473 [00:02<00:23, 298.23it/s]  8%|███▉                                                | 561/7473 [00:02<00:22, 303.13it/s]  8%|████▏                                               | 593/7473 [00:02<00:22, 305.97it/s]  8%|████▎                                               | 624/7473 [00:02<00:22, 306.81it/s]  9%|████▌                                               | 656/7473 [00:02<00:22, 308.30it/s]  9%|████▊                                               | 688/7473 [00:02<00:21, 309.01it/s] 10%|█████                                               | 719/7473 [00:02<00:21, 308.67it/s] 10%|█████▏                                              | 751/7473 [00:02<00:21, 310.25it/s] 10%|█████▍                                              | 783/7473 [00:03<00:21, 310.33it/s] 11%|█████▋                                              | 815/7473 [00:03<00:21, 310.50it/s] 11%|█████▉                                              | 847/7473 [00:03<00:21, 310.71it/s] 12%|██████                                              | 879/7473 [00:03<00:21, 311.03it/s] 12%|██████▎                                             | 911/7473 [00:03<00:21, 311.37it/s] 13%|██████▌                                             | 943/7473 [00:03<00:21, 309.40it/s] 13%|██████▊                                             | 975/7473 [00:03<00:20, 310.09it/s] 13%|██████▊                                            | 1007/7473 [00:03<00:20, 310.27it/s] 14%|███████                                            | 1039/7473 [00:03<00:20, 310.77it/s] 14%|███████▎                                           | 1071/7473 [00:03<00:20, 311.48it/s] 15%|███████▌                                           | 1103/7473 [00:04<00:20, 311.14it/s] 15%|███████▋                                           | 1135/7473 [00:04<00:20, 310.88it/s] 16%|███████▉                                           | 1167/7473 [00:04<00:20, 309.34it/s] 16%|████████▏                                          | 1199/7473 [00:04<00:20, 310.16it/s] 16%|████████▍                                          | 1231/7473 [00:04<00:20, 309.99it/s] 17%|████████▌                                          | 1263/7473 [00:04<00:20, 310.42it/s] 17%|████████▊                                          | 1295/7473 [00:04<00:19, 310.54it/s] 18%|█████████                                          | 1327/7473 [00:04<00:19, 310.03it/s] 18%|█████████▎                                         | 1359/7473 [00:04<00:19, 310.60it/s] 19%|█████████▍                                         | 1391/7473 [00:05<00:19, 308.14it/s] 19%|█████████▋                                         | 1423/7473 [00:05<00:19, 309.09it/s] 19%|█████████▉                                         | 1455/7473 [00:05<00:19, 309.44it/s] 20%|██████████▏                                        | 1487/7473 [00:05<00:19, 310.06it/s] 20%|██████████▎                                        | 1519/7473 [00:05<00:19, 310.87it/s] 21%|██████████▌                                        | 1551/7473 [00:05<00:19, 310.61it/s] 21%|██████████▊                                        | 1583/7473 [00:05<00:19, 309.86it/s] 22%|███████████                                        | 1614/7473 [00:05<00:19, 306.87it/s] 22%|███████████▏                                       | 1645/7473 [00:05<00:18, 307.64it/s] 22%|███████████▍                                       | 1676/7473 [00:05<00:18, 308.33it/s] 23%|███████████▋                                       | 1708/7473 [00:06<00:18, 309.09it/s] 23%|███████████▊                                       | 1740/7473 [00:06<00:18, 309.37it/s] 24%|████████████                                       | 1772/7473 [00:06<00:18, 309.68it/s] 24%|████████████▎                                      | 1804/7473 [00:06<00:18, 309.78it/s] 25%|████████████▌                                      | 1835/7473 [00:06<00:18, 309.61it/s] 25%|████████████▋                                      | 1866/7473 [00:06<00:18, 308.22it/s] 25%|████████████▉                                      | 1897/7473 [00:06<00:18, 308.64it/s] 26%|█████████████▏                                     | 1928/7473 [00:06<00:18, 307.79it/s] 26%|█████████████▍                                     | 1960/7473 [00:06<00:17, 308.59it/s] 27%|█████████████▌                                     | 1991/7473 [00:06<00:17, 308.97it/s] 27%|█████████████▊                                     | 2022/7473 [00:07<00:17, 306.56it/s] 27%|██████████████                                     | 2054/7473 [00:07<00:17, 307.98it/s] 28%|██████████████▏                                    | 2085/7473 [00:07<00:17, 306.84it/s] 28%|██████████████▍                                    | 2116/7473 [00:07<00:17, 307.62it/s] 29%|██████████████▋                                    | 2148/7473 [00:07<00:17, 308.34it/s] 29%|██████████████▉                                    | 2180/7473 [00:07<00:17, 309.05it/s] 30%|███████████████                                    | 2212/7473 [00:07<00:16, 309.70it/s] 30%|███████████████▎                                   | 2244/7473 [00:07<00:16, 309.85it/s] 30%|███████████████▌                                   | 2275/7473 [00:07<00:16, 309.76it/s] 31%|███████████████▋                                   | 2306/7473 [00:07<00:16, 308.44it/s] 31%|███████████████▉                                   | 2338/7473 [00:08<00:16, 309.05it/s] 32%|████████████████▏                                  | 2369/7473 [00:08<00:16, 309.08it/s] 32%|████████████████▍                                  | 2400/7473 [00:08<00:16, 307.33it/s] 33%|████████████████▌                                  | 2432/7473 [00:08<00:16, 308.69it/s] 33%|████████████████▊                                  | 2464/7473 [00:08<00:16, 309.39it/s] 33%|█████████████████                                  | 2496/7473 [00:08<00:16, 309.62it/s] 34%|█████████████████▏                                 | 2527/7473 [00:08<00:17, 282.60it/s] 34%|█████████████████▍                                 | 2558/7473 [00:08<00:16, 289.43it/s] 35%|█████████████████▋                                 | 2590/7473 [00:08<00:16, 295.96it/s] 35%|█████████████████▉                                 | 2622/7473 [00:09<00:16, 300.29it/s] 36%|██████████████████                                 | 2654/7473 [00:09<00:15, 303.27it/s] 36%|██████████████████▎                                | 2686/7473 [00:09<00:15, 305.60it/s] 36%|██████████████████▌                                | 2718/7473 [00:09<00:15, 307.38it/s] 37%|██████████████████▊                                | 2749/7473 [00:09<00:15, 306.23it/s] 37%|██████████████████▉                                | 2780/7473 [00:09<00:15, 307.30it/s] 38%|███████████████████▏                               | 2811/7473 [00:09<00:15, 305.97it/s] 38%|███████████████████▍                               | 2843/7473 [00:09<00:15, 307.34it/s] 38%|███████████████████▌                               | 2874/7473 [00:09<00:14, 306.83it/s] 39%|███████████████████▊                               | 2906/7473 [00:09<00:14, 308.22it/s] 39%|████████████████████                               | 2938/7473 [00:10<00:14, 309.66it/s] 40%|████████████████████▎                              | 2970/7473 [00:10<00:14, 310.31it/s] 40%|████████████████████▍                              | 3002/7473 [00:10<00:14, 308.68it/s] 41%|████████████████████▋                              | 3033/7473 [00:10<00:14, 308.73it/s] 41%|████████████████████▉                              | 3064/7473 [00:10<00:14, 309.07it/s] 41%|█████████████████████                              | 3095/7473 [00:10<00:14, 308.77it/s] 42%|█████████████████████▎                             | 3126/7473 [00:10<00:14, 308.29it/s] 42%|█████████████████████▌                             | 3157/7473 [00:10<00:14, 307.65it/s] 43%|█████████████████████▊                             | 3188/7473 [00:10<00:13, 308.12it/s] 43%|█████████████████████▉                             | 3219/7473 [00:10<00:13, 306.99it/s] 44%|██████████████████████▏                            | 3251/7473 [00:11<00:13, 308.13it/s] 44%|██████████████████████▍                            | 3283/7473 [00:11<00:13, 308.86it/s] 44%|██████████████████████▌                            | 3314/7473 [00:11<00:13, 309.13it/s] 45%|██████████████████████▊                            | 3345/7473 [00:11<00:13, 308.46it/s] 45%|███████████████████████                            | 3376/7473 [00:11<00:13, 308.55it/s] 46%|███████████████████████▎                           | 3407/7473 [00:11<00:13, 308.62it/s] 46%|███████████████████████▍                           | 3438/7473 [00:11<00:13, 306.93it/s] 46%|███████████████████████▋                           | 3469/7473 [00:11<00:13, 307.12it/s] 47%|███████████████████████▉                           | 3501/7473 [00:11<00:12, 308.41it/s] 47%|████████████████████████                           | 3532/7473 [00:11<00:12, 308.70it/s] 48%|████████████████████████▎                          | 3563/7473 [00:12<00:12, 309.07it/s] 48%|████████████████████████▌                          | 3595/7473 [00:12<00:12, 309.70it/s] 49%|████████████████████████▋                          | 3626/7473 [00:12<00:12, 309.55it/s] 49%|████████████████████████▉                          | 3657/7473 [00:12<00:12, 306.87it/s] 49%|█████████████████████████▏                         | 3688/7473 [00:12<00:12, 307.58it/s] 50%|█████████████████████████▍                         | 3719/7473 [00:12<00:12, 307.29it/s] 50%|█████████████████████████▌                         | 3750/7473 [00:12<00:12, 307.59it/s] 51%|█████████████████████████▊                         | 3781/7473 [00:12<00:12, 306.97it/s] 51%|██████████████████████████                         | 3812/7473 [00:12<00:11, 307.70it/s] 51%|██████████████████████████▏                        | 3843/7473 [00:13<00:11, 307.16it/s] 52%|██████████████████████████▍                        | 3874/7473 [00:13<00:11, 307.11it/s] 52%|██████████████████████████▋                        | 3905/7473 [00:13<00:11, 305.50it/s] 53%|██████████████████████████▊                        | 3936/7473 [00:13<00:11, 306.52it/s] 53%|███████████████████████████                        | 3967/7473 [00:13<00:11, 307.25it/s] 53%|███████████████████████████▎                       | 3998/7473 [00:13<00:11, 307.57it/s] 54%|███████████████████████████▍                       | 4029/7473 [00:13<00:11, 308.06it/s] 54%|███████████████████████████▋                       | 4060/7473 [00:13<00:11, 308.42it/s] 55%|███████████████████████████▉                       | 4091/7473 [00:13<00:10, 308.36it/s] 55%|████████████████████████████▏                      | 4122/7473 [00:13<00:10, 305.01it/s] 56%|████████████████████████████▎                      | 4153/7473 [00:14<00:10, 305.09it/s] 56%|████████████████████████████▌                      | 4184/7473 [00:14<00:10, 305.76it/s] 56%|████████████████████████████▊                      | 4215/7473 [00:14<00:10, 306.23it/s] 57%|████████████████████████████▉                      | 4246/7473 [00:14<00:10, 307.24it/s] 57%|█████████████████████████████▏                     | 4277/7473 [00:14<00:10, 306.88it/s] 58%|█████████████████████████████▍                     | 4308/7473 [00:14<00:10, 307.29it/s] 58%|█████████████████████████████▌                     | 4339/7473 [00:14<00:10, 306.20it/s] 58%|█████████████████████████████▊                     | 4370/7473 [00:14<00:10, 306.56it/s] 59%|██████████████████████████████                     | 4401/7473 [00:14<00:10, 305.74it/s] 59%|██████████████████████████████▏                    | 4432/7473 [00:14<00:09, 305.95it/s] 60%|██████████████████████████████▍                    | 4463/7473 [00:15<00:09, 305.84it/s] 60%|██████████████████████████████▋                    | 4494/7473 [00:15<00:09, 306.34it/s] 61%|██████████████████████████████▉                    | 4525/7473 [00:15<00:09, 306.17it/s] 61%|███████████████████████████████                    | 4557/7473 [00:15<00:09, 307.82it/s] 61%|███████████████████████████████▎                   | 4588/7473 [00:15<00:09, 307.87it/s] 62%|███████████████████████████████▌                   | 4620/7473 [00:15<00:09, 309.09it/s] 62%|███████████████████████████████▋                   | 4652/7473 [00:15<00:09, 309.87it/s] 63%|███████████████████████████████▉                   | 4684/7473 [00:15<00:08, 310.48it/s] 63%|████████████████████████████████▏                  | 4716/7473 [00:15<00:08, 310.83it/s] 64%|████████████████████████████████▍                  | 4748/7473 [00:15<00:08, 311.56it/s] 64%|████████████████████████████████▌                  | 4780/7473 [00:16<00:08, 312.28it/s] 64%|████████████████████████████████▊                  | 4812/7473 [00:16<00:08, 310.60it/s] 65%|█████████████████████████████████                  | 4844/7473 [00:16<00:08, 311.46it/s] 65%|█████████████████████████████████▎                 | 4876/7473 [00:16<00:08, 311.25it/s] 66%|█████████████████████████████████▍                 | 4908/7473 [00:16<00:08, 311.73it/s] 66%|█████████████████████████████████▋                 | 4940/7473 [00:16<00:08, 311.54it/s] 67%|█████████████████████████████████▉                 | 4972/7473 [00:16<00:08, 311.69it/s] 67%|██████████████████████████████████▏                | 5004/7473 [00:16<00:07, 312.20it/s] 67%|██████████████████████████████████▎                | 5036/7473 [00:16<00:07, 309.97it/s] 68%|██████████████████████████████████▌                | 5068/7473 [00:16<00:07, 311.08it/s] 68%|██████████████████████████████████▊                | 5100/7473 [00:17<00:07, 311.60it/s] 69%|███████████████████████████████████                | 5132/7473 [00:17<00:07, 312.00it/s] 69%|███████████████████████████████████▏               | 5164/7473 [00:17<00:07, 312.22it/s] 70%|███████████████████████████████████▍               | 5196/7473 [00:17<00:07, 312.32it/s] 70%|███████████████████████████████████▋               | 5228/7473 [00:17<00:07, 312.74it/s] 70%|███████████████████████████████████▉               | 5260/7473 [00:17<00:07, 290.15it/s] 71%|████████████████████████████████████               | 5292/7473 [00:17<00:07, 296.43it/s] 71%|████████████████████████████████████▎              | 5324/7473 [00:17<00:07, 300.71it/s] 72%|████████████████████████████████████▌              | 5356/7473 [00:17<00:06, 304.11it/s] 72%|████████████████████████████████████▊              | 5388/7473 [00:18<00:06, 306.57it/s] 73%|████████████████████████████████████▉              | 5419/7473 [00:18<00:06, 305.97it/s] 73%|█████████████████████████████████████▏             | 5451/7473 [00:18<00:06, 308.12it/s] 73%|█████████████████████████████████████▍             | 5482/7473 [00:18<00:09, 205.31it/s] 74%|█████████████████████████████████████▋             | 5514/7473 [00:18<00:08, 229.10it/s] 74%|█████████████████████████████████████▊             | 5546/7473 [00:18<00:07, 249.02it/s] 75%|██████████████████████████████████████             | 5578/7473 [00:18<00:07, 265.34it/s] 75%|██████████████████████████████████████▎            | 5609/7473 [00:18<00:06, 276.62it/s] 75%|██████████████████████████████████████▍            | 5641/7473 [00:19<00:06, 286.43it/s] 76%|██████████████████████████████████████▋            | 5673/7473 [00:19<00:06, 293.81it/s] 76%|██████████████████████████████████████▉            | 5704/7473 [00:19<00:05, 297.72it/s] 77%|███████████████████████████████████████▏           | 5736/7473 [00:19<00:05, 301.62it/s] 77%|███████████████████████████████████████▎           | 5768/7473 [00:19<00:05, 305.12it/s] 78%|███████████████████████████████████████▌           | 5800/7473 [00:19<00:05, 307.28it/s] 78%|███████████████████████████████████████▊           | 5832/7473 [00:19<00:05, 308.08it/s] 78%|████████████████████████████████████████           | 5864/7473 [00:19<00:05, 309.31it/s] 79%|████████████████████████████████████████▏          | 5896/7473 [00:19<00:05, 307.76it/s] 79%|████████████████████████████████████████▍          | 5927/7473 [00:19<00:05, 306.91it/s] 80%|████████████████████████████████████████▋          | 5958/7473 [00:20<00:04, 307.63it/s] 80%|████████████████████████████████████████▊          | 5989/7473 [00:20<00:04, 308.13it/s] 81%|█████████████████████████████████████████          | 6021/7473 [00:20<00:04, 309.25it/s] 81%|█████████████████████████████████████████▎         | 6053/7473 [00:20<00:04, 310.47it/s] 81%|█████████████████████████████████████████▌         | 6085/7473 [00:20<00:04, 311.49it/s] 82%|█████████████████████████████████████████▋         | 6117/7473 [00:20<00:04, 311.89it/s] 82%|█████████████████████████████████████████▉         | 6149/7473 [00:20<00:04, 310.11it/s] 83%|██████████████████████████████████████████▏        | 6181/7473 [00:20<00:04, 310.77it/s] 83%|██████████████████████████████████████████▍        | 6213/7473 [00:20<00:04, 310.81it/s] 84%|██████████████████████████████████████████▌        | 6245/7473 [00:20<00:03, 310.08it/s] 84%|██████████████████████████████████████████▊        | 6277/7473 [00:21<00:03, 310.96it/s] 84%|███████████████████████████████████████████        | 6309/7473 [00:21<00:03, 311.26it/s] 85%|███████████████████████████████████████████▎       | 6341/7473 [00:21<00:03, 311.88it/s] 85%|███████████████████████████████████████████▍       | 6373/7473 [00:21<00:03, 309.66it/s] 86%|███████████████████████████████████████████▋       | 6405/7473 [00:21<00:03, 310.05it/s] 86%|███████████████████████████████████████████▉       | 6437/7473 [00:21<00:03, 308.14it/s] 87%|████████████████████████████████████████████▏      | 6469/7473 [00:21<00:03, 309.09it/s] 87%|████████████████████████████████████████████▎      | 6501/7473 [00:21<00:03, 310.10it/s] 87%|████████████████████████████████████████████▌      | 6533/7473 [00:21<00:03, 309.97it/s] 88%|████████████████████████████████████████████▊      | 6565/7473 [00:21<00:02, 310.23it/s] 88%|█████████████████████████████████████████████      | 6597/7473 [00:22<00:02, 309.49it/s] 89%|█████████████████████████████████████████████▏     | 6629/7473 [00:22<00:02, 310.04it/s] 89%|█████████████████████████████████████████████▍     | 6661/7473 [00:22<00:02, 310.26it/s] 90%|█████████████████████████████████████████████▋     | 6693/7473 [00:22<00:02, 310.67it/s] 90%|█████████████████████████████████████████████▉     | 6725/7473 [00:22<00:02, 310.94it/s] 90%|██████████████████████████████████████████████     | 6757/7473 [00:22<00:02, 310.97it/s] 91%|██████████████████████████████████████████████▎    | 6789/7473 [00:22<00:02, 311.18it/s] 91%|██████████████████████████████████████████████▌    | 6821/7473 [00:22<00:02, 309.20it/s] 92%|██████████████████████████████████████████████▊    | 6852/7473 [00:22<00:02, 309.19it/s] 92%|██████████████████████████████████████████████▉    | 6884/7473 [00:23<00:01, 310.21it/s] 93%|███████████████████████████████████████████████▏   | 6916/7473 [00:23<00:01, 311.12it/s] 93%|███████████████████████████████████████████████▍   | 6948/7473 [00:23<00:01, 309.35it/s] 93%|███████████████████████████████████████████████▋   | 6980/7473 [00:23<00:01, 309.73it/s] 94%|███████████████████████████████████████████████▊   | 7012/7473 [00:23<00:01, 310.05it/s] 94%|████████████████████████████████████████████████   | 7044/7473 [00:23<00:01, 308.62it/s] 95%|████████████████████████████████████████████████▎  | 7076/7473 [00:23<00:01, 309.76it/s] 95%|████████████████████████████████████████████████▌  | 7108/7473 [00:23<00:01, 310.41it/s] 96%|████████████████████████████████████████████████▋  | 7140/7473 [00:23<00:01, 310.37it/s] 96%|████████████████████████████████████████████████▉  | 7172/7473 [00:23<00:00, 310.79it/s] 96%|█████████████████████████████████████████████████▏ | 7204/7473 [00:24<00:00, 311.05it/s] 97%|█████████████████████████████████████████████████▍ | 7236/7473 [00:24<00:00, 310.77it/s] 97%|█████████████████████████████████████████████████▌ | 7268/7473 [00:24<00:00, 309.54it/s] 98%|█████████████████████████████████████████████████▊ | 7300/7473 [00:24<00:00, 310.49it/s] 98%|██████████████████████████████████████████████████ | 7332/7473 [00:24<00:00, 310.51it/s] 99%|██████████████████████████████████████████████████▎| 7364/7473 [00:24<00:00, 310.64it/s] 99%|██████████████████████████████████████████████████▍| 7396/7473 [00:24<00:00, 311.12it/s] 99%|██████████████████████████████████████████████████▋| 7428/7473 [00:24<00:00, 311.39it/s]100%|██████████████████████████████████████████████████▉| 7460/7473 [00:24<00:00, 310.79it/s]100%|███████████████████████████████████████████████████| 7473/7473 [00:24<00:00, 299.82it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:04<00:09,  4.74s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.18s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.30s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.27s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:09<00:04,  4.82s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.27s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.43s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.38s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.22s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.38s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.81s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.93s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.81s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.97s/it]
[2023-08-12 16:47:51,746] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.78s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.93s/it]
[2023-08-12 16:48:03,303] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 16:48:03,304] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 16:48:03,304] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f49c2797fa0>
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f49c297e700>
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 16:48:03,306] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.5633916854858398 seconds
Loading extension module utils...
Time to load utils op: 0.5046994686126709 seconds
Loading extension module utils...
Time to load utils op: 0.5047354698181152 seconds
Loading extension module utils...
Time to load utils op: 0.6049232482910156 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Rationales: 1. First, consider what the problem is asking. It is questioning where you could find a type of plumbing that would not help you if you were in need of a drink of water.
2. In the process of elimination, start with evaluating each option and its probability of having drinkable water. 
3. Option A is oil refineries. These facilities primarily process oil, not water. As such, most of the plumbing found in oil refineries is used for the transportation of oil and other types of fuels. Drinking the water from oil refineries would have myriad health risks due to potential contamination or exposure to harmful chemicals.
4. Next, option B is a wall. Plumbing inside walls typically carries water. This water could be from the municipal supply or well, which provides potable water inside a house.
5. Option C is a "show." It's somewhat ambiguous, but it could refer to a home show or trade show, where there could be live displays of plumbing in action. In that case, it's likely there would be clean water accessible.
6. Option D is "own home," which most definitely would provide drinkable water coming from faucets, showers, and refrigerators.
7. Finally, option E is a water fountain. Water fountains are specifically designed to provide drinking water.
8. After comparing all the options, the most sensible option is "A: oil refineries." It is the only choice where the primary function does not involve the usage or transportation of drinkable water. Therefore, you could find a type of plumbing that would not be of use to you for drinking purposes.
Answer: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Rationales: 1. First, we need to clarify the meaning of each option in the context of "beginning work".
2. "Working" cannot be the answer because when a person is beginning to work, they are technically already working.
3. "Resting" cannot be the answer either, as it is opposite to the premise. When a person is beginning to work, they certainly are not resting.
4. "Tiredness" is a state that might come during or after work, but it doesn't necessarily relate to the immediate state of beginning work. However, it does not fit as the best answer.
5. "Momentum" is a term that speaks more to the energy or drive to do work, and while it may build as a person begins work, it's not something that the person isn't doing. 
6. This leaves us with "accomplishing". When a person is just beginning to work, they may not have accomplished anything yet, as accomplishing usually indicates completion or reaching a desired outcome.
7. Therefore, "accomplishing" is the correct answer.
Answer: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Rationales: 1. The question asks us where we can find pens that have a company logo.
2. The 'company logo' part of the question suggests that the pens are likely distributed or used in a professional environment where branding is important. 
3. Choice B suggests "on a pencil" which is illogical because pencils and pens are two different types of writing tools. So, this can't be correct.
4. Choice C suggests "write sentences on paper". This is not a place where pens could be found, it's rather an action you do with a pen, hence it is incorrect.
5. Choice D: "school", while pens are indeed commonly used in this setting, pens with company logos are designed to promote the brand, they are not common or usually distributed at schools. So this is not likely the answer.
6. Choice E: "backpack" is too generic, while you may find pens inside it, this doesn't necessarily mean they would be pens with a company logo. 
7. That leaves choice A: "office", offices are professional environments where items like pens can have a company logo for branding purposes.
8. Therefore, the logical choice and answer is A: office.
Answer: A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Rationales: 1. The question tells us that Billy called out to John. This tells us that Billy is attempting some form of communication with John.
2. The phrase "listened for" indicates that Billy is waiting for some sort of feedback or answer from John.
3. We can eliminate answer choice A - "silence" because Billy wouldn't call out to John to hear silence.
4. Answer choice C - "communication" could potentially be a match, but in the context of the question, communication is too broad. Billy is specifically looking for something from John, and not just general communication.
5. Answer choice D - "hanging up" and E - "whisper" are irrelevant as Billy is presumably not using a phone, and there's nothing in the context to suggest that Billy wants John to whisper.
6. Therefore, the correct answer is B: "response", because Billy called out to John and therefore would naturally be waiting for a response.
Answer: B: response

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o4-tcommonsenseqa-s1-rTrue
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:42<34:52, 42.71s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:24<33:36, 42.02s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:06<32:51, 41.96s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [02:47<32:03, 41.81s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [03:29<31:17, 41.72s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [04:10<30:33, 41.68s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [04:52<29:56, 41.77s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [05:31<28:27, 40.67s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [06:06<26:34, 38.89s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [06:47<26:32, 39.81s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [07:29<26:18, 40.48s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [08:11<25:53, 40.87s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [08:53<25:24, 41.20s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [09:35<24:53, 41.49s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [10:17<24:18, 41.69s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [10:59<23:40, 41.78s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [11:41<23:00, 41.83s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [12:23<22:16, 41.78s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [13:05<21:37, 41.87s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [13:47<20:51, 41.71s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [14:28<20:09, 41.70s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [15:11<19:33, 41.91s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [15:52<18:50, 41.89s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [16:34<18:05, 41.75s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [17:16<17:25, 41.83s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [17:58<16:45, 41.91s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [18:40<16:01, 41.81s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [19:21<15:18, 41.76s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [19:55<13:48, 39.45s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [20:37<13:25, 40.27s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [21:19<12:54, 40.75s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [22:01<12:20, 41.15s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [22:31<10:42, 37.82s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [23:13<10:24, 39.02s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [23:56<10:01, 40.07s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [24:38<09:28, 40.63s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [25:19<08:51, 40.92s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [26:01<08:14, 41.21s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [26:43<07:35, 41.40s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [27:25<06:55, 41.52s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [28:07<06:14, 41.61s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [28:31<04:51, 36.48s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [29:13<04:27, 38.15s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [29:55<03:55, 39.22s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [30:37<03:20, 40.03s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [31:19<02:42, 40.63s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [32:01<02:03, 41.01s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [32:43<01:22, 41.31s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [33:24<00:41, 41.40s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [34:06<00:00, 41.53s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [34:06<00:00, 40.93s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.2788} | lm_loss 10.1938 | avg. gen lenth: 328.844
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o5-tcommonsenseqa-s1-rTrue --seed 1 --rationales --num-out-domain 5
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-12 17:22:58,083] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o5-tcommonsenseqa-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 5
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o5-tcommonsenseqa-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  0%|▏                                                    | 18/7473 [00:00<00:41, 179.49it/s]  0%|▎                                                    | 36/7473 [00:00<00:41, 179.31it/s]  1%|▍                                                    | 55/7473 [00:00<00:41, 179.91it/s]  1%|▌                                                    | 74/7473 [00:00<00:41, 180.05it/s]  1%|▋                                                    | 93/7473 [00:00<00:40, 180.76it/s]  1%|▊                                                   | 112/7473 [00:00<00:40, 180.92it/s]  2%|▉                                                   | 131/7473 [00:00<00:41, 178.14it/s]  2%|█                                                   | 150/7473 [00:00<00:40, 179.08it/s]  2%|█▏                                                  | 169/7473 [00:00<00:40, 179.76it/s]  3%|█▎                                                  | 188/7473 [00:01<00:40, 180.43it/s]  3%|█▍                                                  | 207/7473 [00:01<00:40, 181.13it/s]  3%|█▌                                                  | 226/7473 [00:01<00:39, 181.44it/s]  3%|█▋                                                  | 245/7473 [00:01<00:39, 180.99it/s]  4%|█▊                                                  | 264/7473 [00:01<00:40, 179.43it/s]  4%|█▉                                                  | 283/7473 [00:01<00:39, 180.22it/s]  4%|██                                                  | 302/7473 [00:01<00:39, 180.49it/s]  4%|██▏                                                 | 321/7473 [00:01<00:39, 179.51it/s]  5%|██▎                                                 | 339/7473 [00:01<00:39, 179.37it/s]  5%|██▍                                                 | 358/7473 [00:01<00:39, 180.11it/s]  5%|██▌                                                 | 377/7473 [00:02<00:39, 180.12it/s]  5%|██▊                                                 | 396/7473 [00:02<00:39, 180.22it/s]  6%|██▉                                                 | 420/7473 [00:02<00:35, 196.11it/s]  6%|███                                                 | 448/7473 [00:02<00:32, 219.32it/s]  6%|███▎                                                | 476/7473 [00:02<00:29, 234.42it/s]  7%|███▌                                                | 504/7473 [00:02<00:28, 246.37it/s]  7%|███▋                                                | 532/7473 [00:02<00:27, 255.73it/s]  7%|███▉                                                | 560/7473 [00:02<00:26, 262.05it/s]  8%|████                                                | 588/7473 [00:02<00:25, 265.93it/s]  8%|████▎                                               | 616/7473 [00:03<00:25, 268.78it/s]  9%|████▍                                               | 644/7473 [00:03<00:25, 270.67it/s]  9%|████▋                                               | 672/7473 [00:03<00:24, 272.78it/s]  9%|████▊                                               | 700/7473 [00:03<00:24, 273.97it/s] 10%|█████                                               | 728/7473 [00:03<00:24, 273.44it/s] 10%|█████▎                                              | 756/7473 [00:03<00:24, 274.51it/s] 10%|█████▍                                              | 784/7473 [00:03<00:24, 274.61it/s] 11%|█████▋                                              | 812/7473 [00:03<00:24, 275.06it/s] 11%|█████▊                                              | 840/7473 [00:03<00:24, 275.07it/s] 12%|██████                                              | 868/7473 [00:03<00:23, 275.60it/s] 12%|██████▏                                             | 896/7473 [00:04<00:23, 275.79it/s] 12%|██████▍                                             | 924/7473 [00:04<00:23, 275.90it/s] 13%|██████▌                                             | 952/7473 [00:04<00:23, 274.11it/s] 13%|██████▊                                             | 980/7473 [00:04<00:23, 274.82it/s] 13%|██████▉                                            | 1008/7473 [00:04<00:23, 275.02it/s] 14%|███████                                            | 1036/7473 [00:04<00:23, 275.57it/s] 14%|███████▎                                           | 1064/7473 [00:04<00:23, 276.16it/s] 15%|███████▍                                           | 1092/7473 [00:04<00:23, 276.32it/s] 15%|███████▋                                           | 1120/7473 [00:04<00:23, 275.85it/s] 15%|███████▊                                           | 1148/7473 [00:04<00:22, 275.83it/s] 16%|████████                                           | 1176/7473 [00:05<00:22, 273.81it/s] 16%|████████▏                                          | 1204/7473 [00:05<00:22, 273.97it/s] 16%|████████▍                                          | 1232/7473 [00:05<00:22, 274.41it/s] 17%|████████▌                                          | 1260/7473 [00:05<00:22, 275.09it/s] 17%|████████▊                                          | 1288/7473 [00:05<00:22, 275.14it/s] 18%|████████▉                                          | 1316/7473 [00:05<00:22, 275.42it/s] 18%|█████████▏                                         | 1344/7473 [00:05<00:22, 274.23it/s] 18%|█████████▎                                         | 1372/7473 [00:05<00:22, 274.63it/s] 19%|█████████▌                                         | 1400/7473 [00:05<00:22, 272.22it/s] 19%|█████████▋                                         | 1428/7473 [00:05<00:22, 267.09it/s] 19%|█████████▉                                         | 1456/7473 [00:06<00:22, 268.00it/s] 20%|██████████▏                                        | 1484/7473 [00:06<00:22, 270.34it/s] 20%|██████████▎                                        | 1512/7473 [00:06<00:21, 272.28it/s] 21%|██████████▌                                        | 1540/7473 [00:06<00:21, 272.50it/s] 21%|██████████▋                                        | 1568/7473 [00:06<00:21, 272.75it/s] 21%|██████████▉                                        | 1596/7473 [00:06<00:21, 273.20it/s] 22%|███████████                                        | 1624/7473 [00:06<00:21, 271.83it/s] 22%|███████████▎                                       | 1652/7473 [00:06<00:21, 272.85it/s] 22%|███████████▍                                       | 1680/7473 [00:06<00:21, 273.96it/s] 23%|███████████▋                                       | 1708/7473 [00:07<00:21, 271.90it/s] 23%|███████████▊                                       | 1736/7473 [00:07<00:21, 272.75it/s] 24%|████████████                                       | 1764/7473 [00:07<00:20, 272.88it/s] 24%|████████████▏                                      | 1792/7473 [00:07<00:20, 273.34it/s] 24%|████████████▍                                      | 1820/7473 [00:07<00:20, 273.94it/s] 25%|████████████▌                                      | 1848/7473 [00:07<00:20, 271.93it/s] 25%|████████████▊                                      | 1876/7473 [00:07<00:20, 273.15it/s] 25%|████████████▉                                      | 1904/7473 [00:07<00:20, 273.26it/s] 26%|█████████████▏                                     | 1932/7473 [00:07<00:20, 273.35it/s] 26%|█████████████▍                                     | 1960/7473 [00:07<00:20, 273.86it/s] 27%|█████████████▌                                     | 1988/7473 [00:08<00:19, 274.33it/s] 27%|█████████████▊                                     | 2016/7473 [00:08<00:19, 274.60it/s] 27%|█████████████▉                                     | 2044/7473 [00:08<00:19, 274.90it/s] 28%|██████████████▏                                    | 2072/7473 [00:08<00:20, 268.73it/s] 28%|██████████████▎                                    | 2100/7473 [00:08<00:19, 270.23it/s] 28%|██████████████▌                                    | 2128/7473 [00:08<00:19, 270.80it/s] 29%|██████████████▋                                    | 2156/7473 [00:08<00:19, 272.24it/s] 29%|██████████████▉                                    | 2184/7473 [00:08<00:19, 272.96it/s] 30%|███████████████                                    | 2212/7473 [00:08<00:19, 274.12it/s] 30%|███████████████▎                                   | 2240/7473 [00:08<00:19, 274.28it/s] 30%|███████████████▍                                   | 2268/7473 [00:09<00:18, 274.51it/s] 31%|███████████████▋                                   | 2296/7473 [00:09<00:18, 272.56it/s] 31%|███████████████▊                                   | 2324/7473 [00:09<00:18, 273.49it/s] 31%|████████████████                                   | 2352/7473 [00:09<00:18, 273.81it/s] 32%|████████████████▏                                  | 2380/7473 [00:09<00:18, 274.01it/s] 32%|████████████████▍                                  | 2408/7473 [00:09<00:18, 272.80it/s] 33%|████████████████▌                                  | 2436/7473 [00:09<00:18, 273.51it/s] 33%|████████████████▊                                  | 2464/7473 [00:09<00:18, 274.00it/s] 33%|█████████████████                                  | 2492/7473 [00:09<00:18, 274.11it/s] 34%|█████████████████▏                                 | 2520/7473 [00:10<00:20, 239.98it/s] 34%|█████████████████▍                                 | 2548/7473 [00:10<00:19, 249.33it/s] 34%|█████████████████▌                                 | 2576/7473 [00:10<00:19, 256.86it/s] 35%|█████████████████▊                                 | 2604/7473 [00:10<00:18, 262.14it/s] 35%|█████████████████▉                                 | 2632/7473 [00:10<00:18, 265.66it/s] 36%|██████████████████▏                                | 2660/7473 [00:10<00:17, 268.75it/s] 36%|██████████████████▎                                | 2688/7473 [00:10<00:17, 270.83it/s] 36%|██████████████████▌                                | 2716/7473 [00:10<00:17, 272.26it/s] 37%|██████████████████▋                                | 2744/7473 [00:10<00:17, 272.60it/s] 37%|██████████████████▉                                | 2772/7473 [00:10<00:17, 271.75it/s] 37%|███████████████████                                | 2800/7473 [00:11<00:17, 272.99it/s] 38%|███████████████████▎                               | 2828/7473 [00:11<00:17, 271.84it/s] 38%|███████████████████▍                               | 2856/7473 [00:11<00:16, 272.55it/s] 39%|███████████████████▋                               | 2884/7473 [00:11<00:16, 272.96it/s] 39%|███████████████████▊                               | 2912/7473 [00:11<00:16, 273.93it/s] 39%|████████████████████                               | 2940/7473 [00:11<00:16, 274.95it/s] 40%|████████████████████▎                              | 2968/7473 [00:11<00:16, 275.12it/s] 40%|████████████████████▍                              | 2996/7473 [00:11<00:16, 273.25it/s] 40%|████████████████████▋                              | 3024/7473 [00:11<00:16, 273.52it/s] 41%|████████████████████▊                              | 3052/7473 [00:11<00:16, 273.59it/s] 41%|█████████████████████                              | 3080/7473 [00:12<00:16, 274.02it/s] 42%|█████████████████████▏                             | 3108/7473 [00:12<00:15, 274.07it/s] 42%|█████████████████████▍                             | 3136/7473 [00:12<00:15, 273.40it/s] 42%|█████████████████████▌                             | 3164/7473 [00:12<00:15, 273.46it/s] 43%|█████████████████████▊                             | 3192/7473 [00:12<00:15, 272.94it/s] 43%|█████████████████████▉                             | 3220/7473 [00:12<00:15, 271.68it/s] 43%|██████████████████████▏                            | 3248/7473 [00:12<00:15, 272.64it/s] 44%|██████████████████████▎                            | 3276/7473 [00:12<00:15, 273.27it/s] 44%|██████████████████████▌                            | 3304/7473 [00:12<00:15, 273.71it/s] 45%|██████████████████████▋                            | 3332/7473 [00:12<00:15, 272.22it/s] 45%|██████████████████████▉                            | 3360/7473 [00:13<00:15, 272.75it/s] 45%|███████████████████████                            | 3388/7473 [00:13<00:14, 272.65it/s] 46%|███████████████████████▎                           | 3416/7473 [00:13<00:14, 272.53it/s] 46%|███████████████████████▌                           | 3444/7473 [00:13<00:14, 271.23it/s] 46%|███████████████████████▋                           | 3472/7473 [00:13<00:14, 271.42it/s] 47%|███████████████████████▉                           | 3500/7473 [00:13<00:14, 272.59it/s] 47%|████████████████████████                           | 3528/7473 [00:13<00:14, 273.04it/s] 48%|████████████████████████▎                          | 3556/7473 [00:13<00:14, 273.40it/s] 48%|████████████████████████▍                          | 3584/7473 [00:13<00:14, 273.68it/s] 48%|████████████████████████▋                          | 3612/7473 [00:14<00:14, 273.55it/s] 49%|████████████████████████▊                          | 3640/7473 [00:14<00:14, 273.21it/s] 49%|█████████████████████████                          | 3668/7473 [00:14<00:14, 271.32it/s] 49%|█████████████████████████▏                         | 3696/7473 [00:14<00:13, 271.83it/s] 50%|█████████████████████████▍                         | 3724/7473 [00:14<00:13, 271.86it/s] 50%|█████████████████████████▌                         | 3752/7473 [00:14<00:13, 272.23it/s] 51%|█████████████████████████▊                         | 3780/7473 [00:14<00:13, 272.80it/s] 51%|█████████████████████████▉                         | 3808/7473 [00:14<00:13, 272.74it/s] 51%|██████████████████████████▏                        | 3836/7473 [00:14<00:13, 272.91it/s] 52%|██████████████████████████▎                        | 3864/7473 [00:14<00:13, 272.83it/s] 52%|██████████████████████████▌                        | 3892/7473 [00:15<00:13, 271.17it/s] 52%|██████████████████████████▊                        | 3920/7473 [00:15<00:13, 272.05it/s] 53%|██████████████████████████▉                        | 3948/7473 [00:15<00:12, 272.44it/s] 53%|███████████████████████████▏                       | 3976/7473 [00:15<00:12, 272.89it/s] 54%|███████████████████████████▎                       | 4004/7473 [00:15<00:12, 273.28it/s] 54%|███████████████████████████▌                       | 4032/7473 [00:15<00:12, 273.41it/s] 54%|███████████████████████████▋                       | 4060/7473 [00:15<00:12, 273.74it/s] 55%|███████████████████████████▉                       | 4088/7473 [00:15<00:12, 273.45it/s] 55%|████████████████████████████                       | 4116/7473 [00:15<00:12, 270.85it/s] 55%|████████████████████████████▎                      | 4144/7473 [00:15<00:12, 271.05it/s] 56%|████████████████████████████▍                      | 4172/7473 [00:16<00:12, 271.87it/s] 56%|████████████████████████████▋                      | 4200/7473 [00:16<00:12, 272.45it/s] 57%|████████████████████████████▊                      | 4228/7473 [00:16<00:11, 272.40it/s] 57%|█████████████████████████████                      | 4256/7473 [00:16<00:11, 271.81it/s] 57%|█████████████████████████████▏                     | 4284/7473 [00:16<00:11, 271.29it/s] 58%|█████████████████████████████▍                     | 4312/7473 [00:16<00:11, 271.82it/s] 58%|█████████████████████████████▌                     | 4340/7473 [00:16<00:11, 270.92it/s] 58%|█████████████████████████████▊                     | 4368/7473 [00:16<00:11, 271.65it/s] 59%|██████████████████████████████                     | 4396/7473 [00:16<00:11, 272.25it/s] 59%|██████████████████████████████▏                    | 4424/7473 [00:16<00:11, 272.21it/s] 60%|██████████████████████████████▍                    | 4452/7473 [00:17<00:11, 272.01it/s] 60%|██████████████████████████████▌                    | 4480/7473 [00:17<00:10, 272.51it/s] 60%|██████████████████████████████▊                    | 4508/7473 [00:17<00:10, 272.52it/s] 61%|██████████████████████████████▉                    | 4536/7473 [00:17<00:10, 272.76it/s] 61%|███████████████████████████████▏                   | 4564/7473 [00:17<00:10, 270.94it/s] 61%|███████████████████████████████▎                   | 4592/7473 [00:17<00:10, 271.68it/s] 62%|███████████████████████████████▌                   | 4620/7473 [00:17<00:10, 272.05it/s] 62%|███████████████████████████████▋                   | 4648/7473 [00:17<00:10, 272.08it/s] 63%|███████████████████████████████▉                   | 4676/7473 [00:17<00:10, 272.27it/s] 63%|████████████████████████████████                   | 4704/7473 [00:18<00:10, 272.42it/s] 63%|████████████████████████████████▎                  | 4732/7473 [00:18<00:10, 270.60it/s] 64%|████████████████████████████████▍                  | 4760/7473 [00:18<00:09, 271.70it/s] 64%|████████████████████████████████▋                  | 4788/7473 [00:18<00:09, 272.16it/s] 64%|████████████████████████████████▊                  | 4816/7473 [00:18<00:09, 269.88it/s] 65%|█████████████████████████████████                  | 4844/7473 [00:18<00:09, 270.97it/s] 65%|█████████████████████████████████▏                 | 4872/7473 [00:18<00:09, 270.86it/s] 66%|█████████████████████████████████▍                 | 4900/7473 [00:18<00:09, 271.85it/s] 66%|█████████████████████████████████▋                 | 4928/7473 [00:18<00:09, 272.07it/s] 66%|█████████████████████████████████▊                 | 4956/7473 [00:18<00:09, 272.44it/s] 67%|██████████████████████████████████                 | 4984/7473 [00:19<00:09, 272.30it/s] 67%|██████████████████████████████████▏                | 5012/7473 [00:19<00:09, 272.63it/s] 67%|██████████████████████████████████▍                | 5040/7473 [00:19<00:08, 270.76it/s] 68%|██████████████████████████████████▌                | 5068/7473 [00:19<00:08, 271.54it/s] 68%|██████████████████████████████████▊                | 5096/7473 [00:19<00:08, 271.77it/s] 69%|██████████████████████████████████▉                | 5124/7473 [00:19<00:08, 272.29it/s] 69%|███████████████████████████████████▏               | 5152/7473 [00:19<00:08, 272.62it/s] 69%|███████████████████████████████████▎               | 5180/7473 [00:19<00:08, 270.72it/s] 70%|███████████████████████████████████▌               | 5208/7473 [00:19<00:08, 271.33it/s] 70%|███████████████████████████████████▋               | 5236/7473 [00:19<00:08, 271.68it/s] 70%|███████████████████████████████████▉               | 5264/7473 [00:20<00:08, 247.15it/s] 71%|████████████████████████████████████               | 5292/7473 [00:20<00:08, 254.60it/s] 71%|████████████████████████████████████▎              | 5320/7473 [00:20<00:08, 259.47it/s] 72%|████████████████████████████████████▍              | 5348/7473 [00:20<00:08, 263.15it/s] 72%|████████████████████████████████████▋              | 5376/7473 [00:20<00:07, 265.52it/s] 72%|████████████████████████████████████▉              | 5404/7473 [00:20<00:07, 267.75it/s] 73%|█████████████████████████████████████              | 5432/7473 [00:20<00:07, 269.62it/s] 73%|█████████████████████████████████████▎             | 5460/7473 [00:20<00:07, 270.35it/s] 73%|█████████████████████████████████████▍             | 5488/7473 [00:21<00:10, 187.64it/s] 74%|█████████████████████████████████████▋             | 5516/7473 [00:21<00:09, 207.16it/s] 74%|█████████████████████████████████████▊             | 5544/7473 [00:21<00:08, 222.94it/s] 75%|██████████████████████████████████████             | 5572/7473 [00:21<00:08, 235.81it/s] 75%|██████████████████████████████████████▏            | 5599/7473 [00:21<00:07, 243.43it/s] 75%|██████████████████████████████████████▍            | 5627/7473 [00:21<00:07, 251.42it/s] 76%|██████████████████████████████████████▌            | 5655/7473 [00:21<00:07, 257.94it/s] 76%|██████████████████████████████████████▊            | 5682/7473 [00:21<00:06, 260.40it/s] 76%|██████████████████████████████████████▉            | 5710/7473 [00:21<00:06, 263.70it/s] 77%|███████████████████████████████████████▏           | 5738/7473 [00:22<00:06, 266.31it/s] 77%|███████████████████████████████████████▎           | 5766/7473 [00:22<00:06, 268.48it/s] 78%|███████████████████████████████████████▌           | 5794/7473 [00:22<00:06, 269.88it/s] 78%|███████████████████████████████████████▋           | 5822/7473 [00:22<00:06, 270.00it/s] 78%|███████████████████████████████████████▉           | 5850/7473 [00:22<00:05, 270.94it/s] 79%|████████████████████████████████████████           | 5878/7473 [00:22<00:05, 270.92it/s] 79%|████████████████████████████████████████▎          | 5906/7473 [00:22<00:05, 269.62it/s] 79%|████████████████████████████████████████▍          | 5934/7473 [00:22<00:05, 270.36it/s] 80%|████████████████████████████████████████▋          | 5962/7473 [00:22<00:05, 270.37it/s] 80%|████████████████████████████████████████▉          | 5990/7473 [00:22<00:05, 270.99it/s] 81%|█████████████████████████████████████████          | 6018/7473 [00:23<00:05, 271.34it/s] 81%|█████████████████████████████████████████▎         | 6046/7473 [00:23<00:05, 269.47it/s] 81%|█████████████████████████████████████████▍         | 6074/7473 [00:23<00:05, 270.98it/s] 82%|█████████████████████████████████████████▋         | 6102/7473 [00:23<00:05, 271.84it/s] 82%|█████████████████████████████████████████▊         | 6130/7473 [00:23<00:04, 270.51it/s] 82%|██████████████████████████████████████████         | 6158/7473 [00:23<00:04, 271.32it/s] 83%|██████████████████████████████████████████▏        | 6186/7473 [00:23<00:04, 271.83it/s] 83%|██████████████████████████████████████████▍        | 6214/7473 [00:23<00:04, 272.44it/s] 84%|██████████████████████████████████████████▌        | 6242/7473 [00:23<00:04, 272.20it/s] 84%|██████████████████████████████████████████▊        | 6270/7473 [00:23<00:04, 272.56it/s] 84%|██████████████████████████████████████████▉        | 6298/7473 [00:24<00:04, 272.53it/s] 85%|███████████████████████████████████████████▏       | 6326/7473 [00:24<00:04, 273.22it/s] 85%|███████████████████████████████████████████▎       | 6354/7473 [00:24<00:04, 273.34it/s] 85%|███████████████████████████████████████████▌       | 6382/7473 [00:24<00:04, 270.66it/s] 86%|███████████████████████████████████████████▋       | 6410/7473 [00:24<00:03, 270.75it/s] 86%|███████████████████████████████████████████▉       | 6438/7473 [00:24<00:03, 271.22it/s] 87%|████████████████████████████████████████████▏      | 6466/7473 [00:24<00:03, 270.84it/s] 87%|████████████████████████████████████████████▎      | 6494/7473 [00:24<00:03, 271.64it/s] 87%|████████████████████████████████████████████▌      | 6522/7473 [00:24<00:03, 269.36it/s] 88%|████████████████████████████████████████████▋      | 6550/7473 [00:25<00:03, 270.45it/s] 88%|████████████████████████████████████████████▉      | 6578/7473 [00:25<00:03, 271.09it/s] 88%|█████████████████████████████████████████████      | 6606/7473 [00:25<00:03, 268.95it/s] 89%|█████████████████████████████████████████████▎     | 6634/7473 [00:25<00:03, 269.74it/s] 89%|█████████████████████████████████████████████▍     | 6662/7473 [00:25<00:03, 270.07it/s] 90%|█████████████████████████████████████████████▋     | 6690/7473 [00:25<00:02, 270.72it/s] 90%|█████████████████████████████████████████████▊     | 6718/7473 [00:25<00:02, 270.99it/s] 90%|██████████████████████████████████████████████     | 6746/7473 [00:25<00:02, 271.79it/s] 91%|██████████████████████████████████████████████▏    | 6774/7473 [00:25<00:02, 271.65it/s] 91%|██████████████████████████████████████████████▍    | 6802/7473 [00:25<00:02, 272.00it/s] 91%|██████████████████████████████████████████████▌    | 6830/7473 [00:26<00:02, 270.45it/s] 92%|██████████████████████████████████████████████▊    | 6858/7473 [00:26<00:02, 271.11it/s] 92%|██████████████████████████████████████████████▉    | 6886/7473 [00:26<00:02, 271.71it/s] 93%|███████████████████████████████████████████████▏   | 6914/7473 [00:26<00:02, 272.38it/s] 93%|███████████████████████████████████████████████▍   | 6942/7473 [00:26<00:01, 272.72it/s] 93%|███████████████████████████████████████████████▌   | 6970/7473 [00:26<00:01, 269.81it/s] 94%|███████████████████████████████████████████████▊   | 6998/7473 [00:26<00:01, 270.40it/s] 94%|███████████████████████████████████████████████▉   | 7026/7473 [00:26<00:01, 270.67it/s] 94%|████████████████████████████████████████████████▏  | 7054/7473 [00:26<00:01, 269.08it/s] 95%|████████████████████████████████████████████████▎  | 7082/7473 [00:26<00:01, 270.16it/s] 95%|████████████████████████████████████████████████▌  | 7110/7473 [00:27<00:01, 270.88it/s] 96%|████████████████████████████████████████████████▋  | 7138/7473 [00:27<00:01, 270.89it/s] 96%|████████████████████████████████████████████████▉  | 7166/7473 [00:27<00:01, 271.28it/s] 96%|█████████████████████████████████████████████████  | 7194/7473 [00:27<00:01, 271.82it/s] 97%|█████████████████████████████████████████████████▎ | 7222/7473 [00:27<00:00, 272.13it/s] 97%|█████████████████████████████████████████████████▍ | 7250/7473 [00:27<00:00, 272.83it/s] 97%|█████████████████████████████████████████████████▋ | 7278/7473 [00:27<00:00, 270.96it/s] 98%|█████████████████████████████████████████████████▊ | 7306/7473 [00:27<00:00, 271.46it/s] 98%|██████████████████████████████████████████████████ | 7334/7473 [00:27<00:00, 271.70it/s] 99%|██████████████████████████████████████████████████▏| 7362/7473 [00:28<00:00, 271.70it/s] 99%|██████████████████████████████████████████████████▍| 7390/7473 [00:28<00:00, 272.29it/s] 99%|██████████████████████████████████████████████████▌| 7418/7473 [00:28<00:00, 272.29it/s]100%|██████████████████████████████████████████████████▊| 7446/7473 [00:28<00:00, 270.93it/s]100%|███████████████████████████████████████████████████| 7473/7473 [00:28<00:00, 262.99it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:04<00:09,  4.94s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.46s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.32s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.31s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:09<00:04,  4.86s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.38s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.46s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:12<00:06,  6.11s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.28s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.44s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.79s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.94s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.81s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.97s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:16<00:00,  5.16s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:16<00:00,  5.35s/it]
[2023-08-12 17:24:20,243] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-12 17:24:36,391] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 17:24:36,392] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 17:24:36,393] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 17:24:36,393] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 17:24:36,393] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 17:24:36,393] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 17:24:36,393] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 17:24:36,393] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 17:24:36,393] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 17:24:36,393] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 17:24:36,393] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 17:24:36,393] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f9ade69dfa0>
[2023-08-12 17:24:36,393] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 17:24:36,393] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f9ade689700>
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 17:24:36,395] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.6141767501831055 seconds
Loading extension module utils...
Time to load utils op: 0.6050376892089844 seconds
Loading extension module utils...
Time to load utils op: 0.6050198078155518 seconds
Loading extension module utils...
Time to load utils op: 0.6047160625457764 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Rationales: 1. The question is asking where you can find plumbing that won't be useful if you are thirsty. 
2. To answer the question, we need to consider the five choices provided and which of the places mentioned would not have water suitable for drinking. 
3. A wall (option B) may contain plumbing, but its purpose is generally to route water to outlets like faucets or showerheads, where one could, in theory, get water to drink. 
4. A shower (option C) and one's home (option D) actually have essential plumbing to provide water, and hence, they would be useful when you are thirsty.
5. A water fountain (option E), by its very definition, also provides water, so it would be beneficial if one were thirsty as well.
6. An oil refinery (option A), however, involves a complex plumbing system dedicated to the refining of oil - not water. This plumbing would indeed not be of use when you are thirsty, as the fluids transported within this system are not safe or appropriate for human consumption.
7. Therefore, the answer is A: oil refineries as it's the only plumbing in the options given that wouldn't satisfy your thirst.
Answer: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Rationales: 1. First, understand the meaning of the question - "When a person is beginning work, what aren't they doing yet?" This question implies to focus on an activity that doesn't occur at the start of the work.
2. Now, review the given choices: A: working, B: resting, C: tiredness, D: accomplishing, E: momentum.
3. Choice A: working - When a person is beginning work, they are already engaging in work. So, they are working. Eliminate this option.
4. Choice B: resting - When a person is beginning work, it implies that they are not resting as the two actions are contradictory. Therefore, this option, too, is not appropriate.
5. Choice C: tiredness - As the question is about the action just at the beginning of work, feeling tired generally comes after working for a while, hence it cannot be considered here. However, the answer choice asked here for the action, not a feeling or state, so this option can be eliminated.
6. Choice D: accomplishing - This implies achieving or finishing tasks. As the question mentions the beginning of work, no task has been finished yet. So, at the beginning of work, a person couldn't be accomplishing anything. It seems to fit the context of the question.
7. Choice E: momentum - Generally, momentum is gained as a person progresses through their work. At the beginning of the work, the momentum would be low or not existent at all. But, momentum like tiredness is rather a state or condition than an action, so it should be eliminated. 
8. Therefore, the answer is D: accomplishing, referring to the activities that haven't taken place when a person is just starting to work.
Answer: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Rationales: 1. The question is asking about where one might find pens with a company logo.
2. The first step in solving this problem is understanding that pens with a company logo are typically distributed in professional settings, such as promotional events or at the company's offices.
3. Now, I examine the options. Option B, on a pencil, is incorrect because a pencil is an item and not a location.
4. Option C, writing sentences on paper, is a wrong answer because it's an action, not a place to find pens with a company logo.
5. Option D, a school, could potentially have pens with a company logo. However, it's less likely since schools often not directly associated with companies.
6. Option E, a backpack, while it is possible to physically find a pen there, it does not necessarily mean it will always carry a pen with a company logo.
7. Therefore, out of the given choices, the most likely place to find pens with a company logo is an office, option A.
Answer: A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Rationales: 1. The question tells us that Billy called out to John, which indicates that he is trying to communicate with him.
2. When someone initiates a conversation, specifically by calling out, they are typically seeking some form of a reply. 
3. The question then asks what Billy is listening for after calling out to John.
4. This suggests that Billy is expecting something from John. 
5. Reviewing the choices offered, "response" best describes what Billy would be listening for.
6. Therefore, the answer is B: response.
Answer: B: response

Input: The lizard frightened the hiker, it's movements made what rustle? Choices:  A: garden B: trees C: books D: rocks E: bushes
Rationales: 1. The question is asking for what the lizard's movements made rustle, which means to make a soft, muffled cracking sound.
2. The options are a garden, trees, books, rocks, and bushes.
3. The act of rustling pertains to objects that are lightweight enough to be disturbed by small movements and also have surfaces that can rub against each other to produce a sound.  
4. Thus, we can rule out the choices of garden and rocks since these are not typically associated with the rustling sound, and books because it's uncommon to find books in a hiking environment where a lizard might frighten a hiker.
5. Between trees and bushes, bushes are more likely to rustle because they are lower to the ground where a lizard would typically move.
6. Therefore, the answer is E: bushes. The lizard's movements made the bushes rustle.
Answer: E: bushes

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o5-tcommonsenseqa-s1-rTrue
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 139, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 116, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 139, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 116, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    main()Evaluating gsm8k :   0%|                                              | 0/50 [00:06<?, ?it/s]
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main

    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 139, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 116, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 139, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 116, in run_model
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 3438063) of binary: /home/ylu130/.conda/envs/distllm/bin/python
Traceback (most recent call last):
  File "/home/ylu130/.conda/envs/distllm/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/run.py", line 761, in main
    run(args)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/ylu130/workspace/in-context-generalization/inference.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-08-12_17:24:45
  host      : ia1.wse.jhu.edu
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 3438064)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-08-12_17:24:45
  host      : ia1.wse.jhu.edu
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 3438065)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-08-12_17:24:45
  host      : ia1.wse.jhu.edu
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 3438066)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-08-12_17:24:45
  host      : ia1.wse.jhu.edu
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3438063)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o6-tcommonsenseqa-s1-rTrue --seed 1 --rationales --num-out-domain 6
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-12 17:24:49,015] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o6-tcommonsenseqa-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 6
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o6-tcommonsenseqa-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  0%|▏                                                    | 19/7473 [00:00<00:41, 181.63it/s]  1%|▎                                                    | 38/7473 [00:00<00:40, 185.37it/s]  1%|▍                                                    | 57/7473 [00:00<00:39, 187.09it/s]  1%|▌                                                    | 76/7473 [00:00<00:39, 187.34it/s]  1%|▋                                                    | 95/7473 [00:00<00:39, 188.04it/s]  2%|▊                                                   | 114/7473 [00:00<00:39, 188.33it/s]  2%|▉                                                   | 133/7473 [00:00<00:38, 188.61it/s]  2%|█                                                   | 152/7473 [00:00<00:38, 188.87it/s]  2%|█▏                                                  | 172/7473 [00:00<00:38, 189.71it/s]  3%|█▎                                                  | 192/7473 [00:01<00:38, 190.24it/s]  3%|█▍                                                  | 212/7473 [00:01<00:38, 189.09it/s]  3%|█▌                                                  | 232/7473 [00:01<00:38, 189.38it/s]  3%|█▋                                                  | 251/7473 [00:01<00:38, 187.06it/s]  4%|█▉                                                  | 271/7473 [00:01<00:38, 188.31it/s]  4%|██                                                  | 291/7473 [00:01<00:37, 189.30it/s]  4%|██▏                                                 | 311/7473 [00:01<00:37, 189.86it/s]  4%|██▎                                                 | 331/7473 [00:01<00:37, 190.51it/s]  5%|██▍                                                 | 351/7473 [00:01<00:37, 190.00it/s]  5%|██▌                                                 | 371/7473 [00:01<00:38, 184.53it/s]  5%|██▋                                                 | 391/7473 [00:02<00:37, 186.76it/s]  5%|██▊                                                 | 411/7473 [00:02<00:37, 187.92it/s]  6%|██▉                                                 | 431/7473 [00:02<00:37, 189.09it/s]  6%|███▏                                                | 451/7473 [00:02<00:37, 188.99it/s]  6%|███▎                                                | 471/7473 [00:02<00:36, 189.53it/s]  7%|███▍                                                | 490/7473 [00:02<00:37, 188.53it/s]  7%|███▌                                                | 510/7473 [00:02<00:36, 189.17it/s]  7%|███▋                                                | 530/7473 [00:02<00:36, 190.29it/s]  7%|███▊                                                | 550/7473 [00:02<00:36, 190.96it/s]  8%|███▉                                                | 570/7473 [00:03<00:36, 191.29it/s]  8%|████                                                | 590/7473 [00:03<00:35, 191.47it/s]  8%|████▏                                               | 610/7473 [00:03<00:35, 191.29it/s]  8%|████▍                                               | 630/7473 [00:03<00:35, 191.22it/s]  9%|████▌                                               | 650/7473 [00:03<00:35, 191.10it/s]  9%|████▋                                               | 670/7473 [00:03<00:35, 191.63it/s]  9%|████▊                                               | 690/7473 [00:03<00:35, 191.97it/s] 10%|████▉                                               | 710/7473 [00:03<00:36, 186.82it/s] 10%|█████                                               | 730/7473 [00:03<00:35, 187.88it/s] 10%|█████▏                                              | 750/7473 [00:03<00:35, 188.82it/s] 10%|█████▎                                              | 770/7473 [00:04<00:35, 189.38it/s] 11%|█████▍                                              | 790/7473 [00:04<00:35, 189.99it/s] 11%|█████▋                                              | 810/7473 [00:04<00:34, 190.74it/s] 11%|█████▊                                              | 830/7473 [00:04<00:34, 191.02it/s] 11%|█████▉                                              | 850/7473 [00:04<00:34, 191.35it/s] 12%|██████                                              | 870/7473 [00:04<00:34, 191.60it/s] 12%|██████▏                                             | 890/7473 [00:04<00:34, 191.66it/s] 12%|██████▎                                             | 910/7473 [00:04<00:34, 191.57it/s] 12%|██████▍                                             | 930/7473 [00:04<00:34, 189.71it/s] 13%|██████▌                                             | 950/7473 [00:05<00:34, 190.13it/s] 13%|██████▋                                             | 970/7473 [00:05<00:34, 190.79it/s] 13%|██████▉                                             | 990/7473 [00:05<00:33, 191.25it/s] 14%|██████▉                                            | 1010/7473 [00:05<00:33, 191.14it/s] 14%|███████                                            | 1030/7473 [00:05<00:33, 191.72it/s] 14%|███████▏                                           | 1050/7473 [00:05<00:33, 191.51it/s] 14%|███████▎                                           | 1070/7473 [00:05<00:33, 191.96it/s] 15%|███████▍                                           | 1090/7473 [00:05<00:33, 191.97it/s] 15%|███████▌                                           | 1110/7473 [00:05<00:33, 191.24it/s] 15%|███████▋                                           | 1130/7473 [00:05<00:33, 191.26it/s] 15%|███████▊                                           | 1150/7473 [00:06<00:33, 191.45it/s] 16%|███████▉                                           | 1170/7473 [00:06<00:33, 189.58it/s] 16%|████████                                           | 1190/7473 [00:06<00:33, 189.92it/s] 16%|████████▎                                          | 1210/7473 [00:06<00:32, 190.25it/s] 16%|████████▍                                          | 1230/7473 [00:06<00:32, 190.57it/s] 17%|████████▌                                          | 1250/7473 [00:06<00:32, 190.86it/s] 17%|████████▋                                          | 1270/7473 [00:06<00:32, 191.01it/s] 17%|████████▊                                          | 1290/7473 [00:06<00:32, 190.88it/s] 18%|████████▉                                          | 1310/7473 [00:06<00:32, 191.03it/s] 18%|█████████                                          | 1330/7473 [00:07<00:32, 191.24it/s] 18%|█████████▏                                         | 1350/7473 [00:07<00:32, 191.27it/s] 18%|█████████▎                                         | 1370/7473 [00:07<00:32, 190.46it/s] 19%|█████████▍                                         | 1390/7473 [00:07<00:32, 188.05it/s] 19%|█████████▌                                         | 1410/7473 [00:07<00:32, 189.18it/s] 19%|█████████▊                                         | 1430/7473 [00:07<00:31, 189.86it/s] 19%|█████████▉                                         | 1450/7473 [00:07<00:31, 190.57it/s] 20%|██████████                                         | 1470/7473 [00:07<00:31, 190.87it/s] 20%|██████████▏                                        | 1490/7473 [00:07<00:31, 190.78it/s] 20%|██████████▎                                        | 1510/7473 [00:07<00:31, 191.13it/s] 20%|██████████▍                                        | 1530/7473 [00:08<00:31, 191.57it/s] 21%|██████████▌                                        | 1550/7473 [00:08<00:30, 191.19it/s] 21%|██████████▋                                        | 1570/7473 [00:08<00:31, 190.39it/s] 21%|██████████▊                                        | 1590/7473 [00:08<00:30, 190.50it/s] 22%|██████████▉                                        | 1610/7473 [00:08<00:30, 189.93it/s] 22%|███████████                                        | 1629/7473 [00:08<00:31, 188.50it/s] 22%|███████████▎                                       | 1649/7473 [00:08<00:30, 189.42it/s] 22%|███████████▍                                       | 1669/7473 [00:08<00:30, 190.08it/s] 23%|███████████▌                                       | 1689/7473 [00:08<00:30, 190.80it/s] 23%|███████████▋                                       | 1709/7473 [00:08<00:30, 191.12it/s] 23%|███████████▊                                       | 1729/7473 [00:09<00:29, 191.49it/s] 23%|███████████▉                                       | 1749/7473 [00:09<00:29, 191.38it/s] 24%|████████████                                       | 1769/7473 [00:09<00:30, 189.70it/s] 24%|████████████▏                                      | 1788/7473 [00:09<00:30, 187.56it/s] 24%|████████████▎                                      | 1807/7473 [00:09<00:30, 188.03it/s] 24%|████████████▍                                      | 1827/7473 [00:09<00:29, 188.56it/s] 25%|████████████▌                                      | 1846/7473 [00:09<00:29, 187.69it/s] 25%|████████████▋                                      | 1866/7473 [00:09<00:29, 188.79it/s] 25%|████████████▊                                      | 1885/7473 [00:09<00:29, 188.75it/s] 25%|████████████▉                                      | 1904/7473 [00:10<00:30, 183.97it/s] 26%|█████████████▏                                     | 1924/7473 [00:10<00:29, 185.91it/s] 26%|█████████████▎                                     | 1944/7473 [00:10<00:29, 187.38it/s] 26%|█████████████▍                                     | 1964/7473 [00:10<00:29, 188.77it/s] 27%|█████████████▌                                     | 1984/7473 [00:10<00:28, 189.61it/s] 27%|█████████████▋                                     | 2004/7473 [00:10<00:28, 189.76it/s] 27%|█████████████▊                                     | 2024/7473 [00:10<00:28, 190.35it/s] 27%|█████████████▉                                     | 2044/7473 [00:10<00:28, 190.29it/s] 28%|██████████████                                     | 2064/7473 [00:10<00:28, 190.79it/s] 28%|██████████████▏                                    | 2084/7473 [00:10<00:28, 189.04it/s] 28%|██████████████▎                                    | 2104/7473 [00:11<00:28, 189.77it/s] 28%|██████████████▍                                    | 2123/7473 [00:11<00:28, 189.81it/s] 29%|██████████████▋                                    | 2143/7473 [00:11<00:27, 190.47it/s] 29%|██████████████▊                                    | 2163/7473 [00:11<00:27, 190.79it/s] 29%|██████████████▉                                    | 2183/7473 [00:11<00:27, 190.94it/s] 29%|███████████████                                    | 2203/7473 [00:11<00:27, 191.10it/s] 30%|███████████████▏                                   | 2223/7473 [00:11<00:27, 191.31it/s] 30%|███████████████▎                                   | 2243/7473 [00:11<00:27, 190.05it/s] 30%|███████████████▍                                   | 2263/7473 [00:11<00:27, 189.61it/s] 31%|███████████████▌                                   | 2282/7473 [00:12<00:27, 189.70it/s] 31%|███████████████▋                                   | 2301/7473 [00:12<00:27, 188.66it/s] 31%|███████████████▊                                   | 2321/7473 [00:12<00:27, 189.77it/s] 31%|███████████████▉                                   | 2341/7473 [00:12<00:26, 190.24it/s] 32%|████████████████                                   | 2361/7473 [00:12<00:26, 190.23it/s] 32%|████████████████▏                                  | 2381/7473 [00:12<00:26, 190.31it/s] 32%|████████████████▍                                  | 2401/7473 [00:12<00:26, 190.82it/s] 32%|████████████████▌                                  | 2421/7473 [00:12<00:26, 191.12it/s] 33%|████████████████▋                                  | 2441/7473 [00:12<00:26, 191.30it/s] 33%|████████████████▊                                  | 2461/7473 [00:12<00:26, 191.33it/s] 33%|████████████████▉                                  | 2481/7473 [00:13<00:26, 190.21it/s] 33%|█████████████████                                  | 2501/7473 [00:13<00:26, 189.89it/s] 34%|█████████████████▏                                 | 2520/7473 [00:13<00:29, 168.98it/s] 34%|█████████████████▎                                 | 2540/7473 [00:13<00:28, 175.13it/s] 34%|█████████████████▍                                 | 2559/7473 [00:13<00:27, 178.15it/s] 35%|█████████████████▌                                 | 2579/7473 [00:13<00:26, 182.35it/s] 35%|█████████████████▋                                 | 2599/7473 [00:13<00:26, 184.77it/s] 35%|█████████████████▊                                 | 2619/7473 [00:13<00:26, 186.43it/s] 35%|██████████████████                                 | 2638/7473 [00:13<00:25, 186.62it/s] 36%|██████████████████▏                                | 2657/7473 [00:14<00:26, 182.62it/s] 36%|██████████████████▎                                | 2677/7473 [00:14<00:25, 185.54it/s] 36%|██████████████████▍                                | 2697/7473 [00:14<00:25, 187.42it/s] 36%|██████████████████▌                                | 2717/7473 [00:14<00:25, 188.60it/s] 37%|██████████████████▋                                | 2736/7473 [00:14<00:25, 188.97it/s] 37%|██████████████████▊                                | 2755/7473 [00:14<00:25, 188.23it/s] 37%|██████████████████▉                                | 2775/7473 [00:14<00:24, 189.11it/s] 37%|███████████████████                                | 2795/7473 [00:14<00:24, 189.73it/s] 38%|███████████████████▏                               | 2815/7473 [00:14<00:24, 190.05it/s] 38%|███████████████████▎                               | 2835/7473 [00:14<00:24, 190.53it/s] 38%|███████████████████▍                               | 2855/7473 [00:15<00:24, 190.61it/s] 38%|███████████████████▌                               | 2875/7473 [00:15<00:24, 188.76it/s] 39%|███████████████████▊                               | 2894/7473 [00:15<00:24, 188.67it/s] 39%|███████████████████▉                               | 2914/7473 [00:15<00:24, 189.30it/s] 39%|████████████████████                               | 2934/7473 [00:15<00:23, 190.29it/s] 40%|████████████████████▏                              | 2954/7473 [00:15<00:23, 190.46it/s] 40%|████████████████████▎                              | 2974/7473 [00:15<00:23, 189.21it/s] 40%|████████████████████▍                              | 2994/7473 [00:15<00:23, 189.95it/s] 40%|████████████████████▌                              | 3013/7473 [00:15<00:23, 189.65it/s] 41%|████████████████████▋                              | 3033/7473 [00:16<00:23, 190.03it/s] 41%|████████████████████▊                              | 3053/7473 [00:16<00:23, 190.20it/s] 41%|████████████████████▉                              | 3073/7473 [00:16<00:23, 190.53it/s] 41%|█████████████████████                              | 3093/7473 [00:16<00:22, 190.70it/s] 42%|█████████████████████▏                             | 3113/7473 [00:16<00:22, 190.58it/s] 42%|█████████████████████▍                             | 3133/7473 [00:16<00:22, 190.73it/s] 42%|█████████████████████▌                             | 3153/7473 [00:16<00:22, 190.70it/s] 42%|█████████████████████▋                             | 3173/7473 [00:16<00:22, 190.82it/s] 43%|█████████████████████▊                             | 3193/7473 [00:16<00:22, 190.74it/s] 43%|█████████████████████▉                             | 3213/7473 [00:16<00:22, 186.93it/s] 43%|██████████████████████                             | 3232/7473 [00:17<00:22, 185.90it/s] 44%|██████████████████████▏                            | 3252/7473 [00:17<00:22, 187.48it/s] 44%|██████████████████████▎                            | 3272/7473 [00:17<00:22, 188.70it/s] 44%|██████████████████████▍                            | 3292/7473 [00:17<00:22, 189.45it/s] 44%|██████████████████████▌                            | 3312/7473 [00:17<00:21, 189.95it/s] 45%|██████████████████████▋                            | 3331/7473 [00:17<00:21, 189.66it/s] 45%|██████████████████████▊                            | 3350/7473 [00:17<00:21, 189.43it/s] 45%|██████████████████████▉                            | 3370/7473 [00:17<00:21, 189.71it/s] 45%|███████████████████████▏                           | 3390/7473 [00:17<00:21, 189.93it/s] 46%|███████████████████████▎                           | 3409/7473 [00:18<00:21, 189.64it/s] 46%|███████████████████████▍                           | 3428/7473 [00:18<00:21, 188.38it/s] 46%|███████████████████████▌                           | 3448/7473 [00:18<00:21, 188.94it/s] 46%|███████████████████████▋                           | 3468/7473 [00:18<00:21, 189.38it/s] 47%|███████████████████████▊                           | 3488/7473 [00:18<00:20, 189.87it/s] 47%|███████████████████████▉                           | 3508/7473 [00:18<00:20, 190.22it/s] 47%|████████████████████████                           | 3528/7473 [00:18<00:20, 188.89it/s] 47%|████████████████████████▏                          | 3548/7473 [00:18<00:20, 189.32it/s] 48%|████████████████████████▎                          | 3568/7473 [00:18<00:20, 189.75it/s] 48%|████████████████████████▍                          | 3588/7473 [00:18<00:20, 190.18it/s] 48%|████████████████████████▌                          | 3608/7473 [00:19<00:20, 190.27it/s] 49%|████████████████████████▊                          | 3628/7473 [00:19<00:20, 190.29it/s] 49%|████████████████████████▉                          | 3648/7473 [00:19<00:20, 189.79it/s] 49%|█████████████████████████                          | 3667/7473 [00:19<00:20, 184.13it/s] 49%|█████████████████████████▏                         | 3686/7473 [00:19<00:20, 184.46it/s] 50%|█████████████████████████▎                         | 3706/7473 [00:19<00:20, 186.15it/s] 50%|█████████████████████████▍                         | 3726/7473 [00:19<00:19, 187.49it/s] 50%|█████████████████████████▌                         | 3745/7473 [00:19<00:19, 188.02it/s] 50%|█████████████████████████▋                         | 3765/7473 [00:19<00:19, 188.69it/s] 51%|█████████████████████████▊                         | 3784/7473 [00:19<00:19, 188.54it/s] 51%|█████████████████████████▉                         | 3804/7473 [00:20<00:19, 189.45it/s] 51%|██████████████████████████                         | 3824/7473 [00:20<00:19, 189.69it/s] 51%|██████████████████████████▏                        | 3843/7473 [00:20<00:19, 188.19it/s] 52%|██████████████████████████▎                        | 3862/7473 [00:20<00:19, 188.62it/s] 52%|██████████████████████████▍                        | 3881/7473 [00:20<00:19, 187.39it/s] 52%|██████████████████████████▌                        | 3901/7473 [00:20<00:18, 188.61it/s] 52%|██████████████████████████▊                        | 3920/7473 [00:20<00:18, 189.01it/s] 53%|██████████████████████████▉                        | 3940/7473 [00:20<00:18, 189.37it/s] 53%|███████████████████████████                        | 3959/7473 [00:20<00:18, 189.41it/s] 53%|███████████████████████████▏                       | 3979/7473 [00:21<00:18, 189.71it/s] 54%|███████████████████████████▎                       | 3999/7473 [00:21<00:18, 190.02it/s] 54%|███████████████████████████▍                       | 4019/7473 [00:21<00:18, 190.26it/s] 54%|███████████████████████████▌                       | 4039/7473 [00:21<00:18, 190.25it/s] 54%|███████████████████████████▋                       | 4059/7473 [00:21<00:18, 185.26it/s] 55%|███████████████████████████▊                       | 4078/7473 [00:21<00:18, 186.53it/s] 55%|███████████████████████████▉                       | 4098/7473 [00:21<00:17, 187.61it/s] 55%|████████████████████████████                       | 4117/7473 [00:21<00:18, 186.22it/s] 55%|████████████████████████████▏                      | 4136/7473 [00:21<00:17, 186.87it/s] 56%|████████████████████████████▎                      | 4155/7473 [00:21<00:18, 182.32it/s] 56%|████████████████████████████▍                      | 4174/7473 [00:22<00:17, 184.45it/s] 56%|████████████████████████████▌                      | 4193/7473 [00:22<00:17, 185.88it/s] 56%|████████████████████████████▋                      | 4212/7473 [00:22<00:17, 186.94it/s] 57%|████████████████████████████▊                      | 4231/7473 [00:22<00:17, 187.74it/s] 57%|█████████████████████████████                      | 4250/7473 [00:22<00:17, 187.74it/s] 57%|█████████████████████████████▏                     | 4269/7473 [00:22<00:17, 188.00it/s] 57%|█████████████████████████████▎                     | 4288/7473 [00:22<00:16, 188.18it/s] 58%|█████████████████████████████▍                     | 4307/7473 [00:22<00:16, 188.48it/s] 58%|█████████████████████████████▌                     | 4327/7473 [00:22<00:16, 188.93it/s] 58%|█████████████████████████████▋                     | 4346/7473 [00:22<00:16, 187.51it/s] 58%|█████████████████████████████▊                     | 4365/7473 [00:23<00:16, 188.18it/s] 59%|█████████████████████████████▉                     | 4384/7473 [00:23<00:16, 188.50it/s] 59%|██████████████████████████████                     | 4404/7473 [00:23<00:16, 188.95it/s] 59%|██████████████████████████████▏                    | 4423/7473 [00:23<00:16, 189.12it/s] 59%|██████████████████████████████▎                    | 4442/7473 [00:23<00:16, 189.36it/s] 60%|██████████████████████████████▍                    | 4461/7473 [00:23<00:15, 189.39it/s] 60%|██████████████████████████████▌                    | 4480/7473 [00:23<00:15, 189.47it/s] 60%|██████████████████████████████▋                    | 4500/7473 [00:23<00:15, 189.62it/s] 60%|██████████████████████████████▊                    | 4519/7473 [00:23<00:15, 189.36it/s] 61%|██████████████████████████████▉                    | 4538/7473 [00:24<00:16, 183.42it/s] 61%|███████████████████████████████                    | 4558/7473 [00:24<00:15, 185.65it/s] 61%|███████████████████████████████▏                   | 4577/7473 [00:24<00:15, 185.53it/s] 62%|███████████████████████████████▎                   | 4596/7473 [00:24<00:15, 186.73it/s] 62%|███████████████████████████████▌                   | 4616/7473 [00:24<00:15, 187.93it/s] 62%|███████████████████████████████▋                   | 4635/7473 [00:24<00:15, 188.46it/s] 62%|███████████████████████████████▊                   | 4655/7473 [00:24<00:14, 189.31it/s] 63%|███████████████████████████████▉                   | 4674/7473 [00:24<00:14, 189.14it/s] 63%|████████████████████████████████                   | 4694/7473 [00:24<00:14, 189.74it/s] 63%|████████████████████████████████▏                  | 4714/7473 [00:24<00:14, 190.08it/s] 63%|████████████████████████████████▎                  | 4734/7473 [00:25<00:14, 190.15it/s] 64%|████████████████████████████████▍                  | 4754/7473 [00:25<00:14, 190.57it/s] 64%|████████████████████████████████▌                  | 4774/7473 [00:25<00:14, 190.89it/s] 64%|████████████████████████████████▋                  | 4794/7473 [00:25<00:14, 189.26it/s] 64%|████████████████████████████████▊                  | 4814/7473 [00:25<00:14, 189.59it/s] 65%|████████████████████████████████▉                  | 4834/7473 [00:25<00:13, 189.93it/s] 65%|█████████████████████████████████▏                 | 4854/7473 [00:25<00:13, 190.09it/s] 65%|█████████████████████████████████▎                 | 4874/7473 [00:25<00:13, 190.05it/s] 65%|█████████████████████████████████▍                 | 4894/7473 [00:25<00:13, 190.23it/s] 66%|█████████████████████████████████▌                 | 4914/7473 [00:25<00:13, 190.17it/s] 66%|█████████████████████████████████▋                 | 4934/7473 [00:26<00:13, 190.34it/s] 66%|█████████████████████████████████▊                 | 4954/7473 [00:26<00:13, 190.56it/s] 67%|█████████████████████████████████▉                 | 4974/7473 [00:26<00:13, 190.39it/s] 67%|██████████████████████████████████                 | 4994/7473 [00:26<00:13, 190.24it/s] 67%|██████████████████████████████████▏                | 5014/7473 [00:26<00:12, 190.67it/s] 67%|██████████████████████████████████▎                | 5034/7473 [00:26<00:13, 182.47it/s] 68%|██████████████████████████████████▍                | 5054/7473 [00:26<00:13, 185.00it/s] 68%|██████████████████████████████████▋                | 5074/7473 [00:26<00:12, 186.70it/s] 68%|██████████████████████████████████▊                | 5094/7473 [00:26<00:12, 187.59it/s] 68%|██████████████████████████████████▉                | 5114/7473 [00:27<00:12, 188.62it/s] 69%|███████████████████████████████████                | 5134/7473 [00:27<00:12, 189.19it/s] 69%|███████████████████████████████████▏               | 5154/7473 [00:27<00:12, 189.74it/s] 69%|███████████████████████████████████▎               | 5174/7473 [00:27<00:12, 190.39it/s] 70%|███████████████████████████████████▍               | 5194/7473 [00:27<00:11, 190.19it/s] 70%|███████████████████████████████████▌               | 5214/7473 [00:27<00:11, 190.61it/s] 70%|███████████████████████████████████▋               | 5234/7473 [00:27<00:11, 190.64it/s] 70%|███████████████████████████████████▊               | 5254/7473 [00:27<00:13, 166.29it/s] 71%|███████████████████████████████████▉               | 5273/7473 [00:27<00:12, 172.42it/s] 71%|████████████████████████████████████               | 5292/7473 [00:28<00:12, 176.90it/s] 71%|████████████████████████████████████▎              | 5312/7473 [00:28<00:11, 180.83it/s] 71%|████████████████████████████████████▍              | 5331/7473 [00:28<00:11, 183.16it/s] 72%|████████████████████████████████████▌              | 5350/7473 [00:28<00:11, 185.05it/s] 72%|████████████████████████████████████▋              | 5369/7473 [00:28<00:11, 186.48it/s] 72%|████████████████████████████████████▊              | 5389/7473 [00:28<00:11, 187.70it/s] 72%|████████████████████████████████████▉              | 5408/7473 [00:28<00:10, 188.33it/s] 73%|█████████████████████████████████████              | 5428/7473 [00:28<00:10, 188.94it/s] 73%|█████████████████████████████████████▏             | 5448/7473 [00:28<00:10, 189.30it/s] 73%|█████████████████████████████████████▎             | 5467/7473 [00:28<00:10, 189.11it/s] 73%|█████████████████████████████████████▍             | 5486/7473 [00:29<00:16, 118.24it/s] 74%|█████████████████████████████████████▌             | 5505/7473 [00:29<00:14, 133.09it/s] 74%|█████████████████████████████████████▋             | 5525/7473 [00:29<00:13, 146.67it/s] 74%|█████████████████████████████████████▊             | 5544/7473 [00:29<00:12, 157.21it/s] 74%|█████████████████████████████████████▉             | 5564/7473 [00:29<00:11, 166.40it/s] 75%|██████████████████████████████████████             | 5583/7473 [00:29<00:10, 172.66it/s] 75%|██████████████████████████████████████▏            | 5602/7473 [00:29<00:10, 177.32it/s] 75%|██████████████████████████████████████▎            | 5621/7473 [00:29<00:10, 180.60it/s] 75%|██████████████████████████████████████▍            | 5640/7473 [00:30<00:10, 182.46it/s] 76%|██████████████████████████████████████▌            | 5659/7473 [00:30<00:09, 182.48it/s] 76%|██████████████████████████████████████▋            | 5678/7473 [00:30<00:09, 181.80it/s] 76%|██████████████████████████████████████▉            | 5698/7473 [00:30<00:09, 184.26it/s] 77%|███████████████████████████████████████            | 5717/7473 [00:30<00:09, 185.70it/s] 77%|███████████████████████████████████████▏           | 5737/7473 [00:30<00:09, 187.16it/s] 77%|███████████████████████████████████████▎           | 5756/7473 [00:30<00:09, 187.91it/s] 77%|███████████████████████████████████████▍           | 5775/7473 [00:30<00:09, 188.48it/s] 78%|███████████████████████████████████████▌           | 5794/7473 [00:30<00:08, 188.67it/s] 78%|███████████████████████████████████████▋           | 5813/7473 [00:31<00:08, 188.46it/s] 78%|███████████████████████████████████████▊           | 5832/7473 [00:31<00:08, 188.82it/s] 78%|███████████████████████████████████████▉           | 5852/7473 [00:31<00:08, 189.35it/s] 79%|████████████████████████████████████████           | 5871/7473 [00:31<00:08, 188.56it/s] 79%|████████████████████████████████████████▏          | 5890/7473 [00:31<00:08, 188.94it/s] 79%|████████████████████████████████████████▎          | 5909/7473 [00:31<00:08, 187.38it/s] 79%|████████████████████████████████████████▍          | 5928/7473 [00:31<00:08, 188.03it/s] 80%|████████████████████████████████████████▌          | 5947/7473 [00:31<00:08, 188.37it/s] 80%|████████████████████████████████████████▋          | 5966/7473 [00:31<00:07, 188.47it/s] 80%|████████████████████████████████████████▊          | 5986/7473 [00:31<00:07, 189.11it/s] 80%|████████████████████████████████████████▉          | 6005/7473 [00:32<00:07, 189.10it/s] 81%|█████████████████████████████████████████          | 6024/7473 [00:32<00:07, 189.00it/s] 81%|█████████████████████████████████████████▏         | 6043/7473 [00:32<00:07, 189.24it/s] 81%|█████████████████████████████████████████▎         | 6062/7473 [00:32<00:07, 188.89it/s] 81%|█████████████████████████████████████████▌         | 6081/7473 [00:32<00:07, 189.18it/s] 82%|█████████████████████████████████████████▋         | 6101/7473 [00:32<00:07, 189.76it/s] 82%|█████████████████████████████████████████▊         | 6121/7473 [00:32<00:07, 189.96it/s] 82%|█████████████████████████████████████████▉         | 6140/7473 [00:32<00:07, 188.40it/s] 82%|██████████████████████████████████████████         | 6160/7473 [00:32<00:06, 188.96it/s] 83%|██████████████████████████████████████████▏        | 6180/7473 [00:32<00:06, 189.34it/s] 83%|██████████████████████████████████████████▎        | 6200/7473 [00:33<00:06, 189.89it/s] 83%|██████████████████████████████████████████▍        | 6219/7473 [00:33<00:06, 189.70it/s] 83%|██████████████████████████████████████████▌        | 6238/7473 [00:33<00:06, 189.58it/s] 84%|██████████████████████████████████████████▋        | 6257/7473 [00:33<00:06, 188.30it/s] 84%|██████████████████████████████████████████▊        | 6276/7473 [00:33<00:06, 187.39it/s] 84%|██████████████████████████████████████████▉        | 6295/7473 [00:33<00:06, 187.39it/s] 85%|███████████████████████████████████████████        | 6315/7473 [00:33<00:06, 188.38it/s] 85%|███████████████████████████████████████████▏       | 6335/7473 [00:33<00:06, 189.20it/s] 85%|███████████████████████████████████████████▎       | 6354/7473 [00:33<00:05, 187.79it/s] 85%|███████████████████████████████████████████▍       | 6373/7473 [00:33<00:05, 187.93it/s] 86%|███████████████████████████████████████████▌       | 6392/7473 [00:34<00:05, 188.09it/s] 86%|███████████████████████████████████████████▊       | 6411/7473 [00:34<00:05, 188.52it/s] 86%|███████████████████████████████████████████▉       | 6430/7473 [00:34<00:05, 188.86it/s] 86%|████████████████████████████████████████████       | 6449/7473 [00:34<00:05, 189.04it/s] 87%|████████████████████████████████████████████▏      | 6469/7473 [00:34<00:05, 189.45it/s] 87%|████████████████████████████████████████████▎      | 6489/7473 [00:34<00:05, 189.71it/s] 87%|████████████████████████████████████████████▍      | 6508/7473 [00:34<00:05, 189.74it/s] 87%|████████████████████████████████████████████▌      | 6527/7473 [00:34<00:04, 189.45it/s] 88%|████████████████████████████████████████████▋      | 6547/7473 [00:34<00:04, 189.79it/s] 88%|████████████████████████████████████████████▊      | 6567/7473 [00:34<00:04, 189.91it/s] 88%|████████████████████████████████████████████▉      | 6586/7473 [00:35<00:04, 188.51it/s] 88%|█████████████████████████████████████████████      | 6606/7473 [00:35<00:04, 189.11it/s] 89%|█████████████████████████████████████████████▏     | 6625/7473 [00:35<00:04, 189.35it/s] 89%|█████████████████████████████████████████████▎     | 6644/7473 [00:35<00:04, 188.78it/s] 89%|█████████████████████████████████████████████▍     | 6663/7473 [00:35<00:04, 188.46it/s] 89%|█████████████████████████████████████████████▌     | 6682/7473 [00:35<00:04, 188.71it/s] 90%|█████████████████████████████████████████████▋     | 6702/7473 [00:35<00:04, 189.24it/s] 90%|█████████████████████████████████████████████▊     | 6721/7473 [00:35<00:04, 187.94it/s] 90%|██████████████████████████████████████████████     | 6741/7473 [00:35<00:03, 188.77it/s] 90%|██████████████████████████████████████████████▏    | 6760/7473 [00:36<00:03, 183.44it/s] 91%|██████████████████████████████████████████████▎    | 6779/7473 [00:36<00:03, 185.03it/s] 91%|██████████████████████████████████████████████▍    | 6798/7473 [00:36<00:03, 186.27it/s] 91%|██████████████████████████████████████████████▌    | 6817/7473 [00:36<00:03, 185.58it/s] 91%|██████████████████████████████████████████████▋    | 6836/7473 [00:36<00:03, 186.78it/s] 92%|██████████████████████████████████████████████▊    | 6856/7473 [00:36<00:03, 187.97it/s] 92%|██████████████████████████████████████████████▉    | 6875/7473 [00:36<00:03, 188.31it/s] 92%|███████████████████████████████████████████████    | 6894/7473 [00:36<00:03, 188.55it/s] 93%|███████████████████████████████████████████████▏   | 6913/7473 [00:36<00:02, 188.96it/s] 93%|███████████████████████████████████████████████▎   | 6932/7473 [00:36<00:02, 188.86it/s] 93%|███████████████████████████████████████████████▍   | 6951/7473 [00:37<00:02, 188.84it/s] 93%|███████████████████████████████████████████████▌   | 6970/7473 [00:37<00:02, 188.42it/s] 94%|███████████████████████████████████████████████▋   | 6989/7473 [00:37<00:02, 188.46it/s] 94%|███████████████████████████████████████████████▊   | 7008/7473 [00:37<00:02, 188.66it/s] 94%|███████████████████████████████████████████████▉   | 7027/7473 [00:37<00:02, 188.56it/s] 94%|████████████████████████████████████████████████   | 7046/7473 [00:37<00:02, 186.85it/s] 95%|████████████████████████████████████████████████▏  | 7065/7473 [00:37<00:02, 179.95it/s] 95%|████████████████████████████████████████████████▎  | 7084/7473 [00:37<00:02, 182.34it/s] 95%|████████████████████████████████████████████████▍  | 7103/7473 [00:37<00:02, 184.20it/s] 95%|████████████████████████████████████████████████▌  | 7122/7473 [00:37<00:01, 184.06it/s] 96%|████████████████████████████████████████████████▋  | 7141/7473 [00:38<00:01, 185.23it/s] 96%|████████████████████████████████████████████████▊  | 7160/7473 [00:38<00:01, 185.66it/s] 96%|████████████████████████████████████████████████▉  | 7179/7473 [00:38<00:01, 186.52it/s] 96%|█████████████████████████████████████████████████  | 7198/7473 [00:38<00:01, 187.30it/s] 97%|█████████████████████████████████████████████████▎ | 7217/7473 [00:38<00:01, 187.75it/s] 97%|█████████████████████████████████████████████████▍ | 7236/7473 [00:38<00:01, 188.10it/s] 97%|█████████████████████████████████████████████████▌ | 7255/7473 [00:38<00:01, 187.99it/s] 97%|█████████████████████████████████████████████████▋ | 7274/7473 [00:38<00:01, 186.83it/s] 98%|█████████████████████████████████████████████████▊ | 7294/7473 [00:38<00:00, 187.89it/s] 98%|█████████████████████████████████████████████████▉ | 7313/7473 [00:38<00:00, 188.17it/s] 98%|██████████████████████████████████████████████████ | 7332/7473 [00:39<00:00, 188.50it/s] 98%|██████████████████████████████████████████████████▏| 7352/7473 [00:39<00:00, 188.88it/s] 99%|██████████████████████████████████████████████████▎| 7371/7473 [00:39<00:00, 188.91it/s] 99%|██████████████████████████████████████████████████▍| 7390/7473 [00:39<00:00, 189.03it/s] 99%|██████████████████████████████████████████████████▌| 7409/7473 [00:39<00:00, 189.29it/s] 99%|██████████████████████████████████████████████████▋| 7429/7473 [00:39<00:00, 189.57it/s]100%|██████████████████████████████████████████████████▊| 7448/7473 [00:39<00:00, 189.51it/s]100%|██████████████████████████████████████████████████▉| 7467/7473 [00:39<00:00, 189.41it/s]100%|███████████████████████████████████████████████████| 7473/7473 [00:39<00:00, 187.64it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.30s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.43s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.60s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.02s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.20s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.40s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.53s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:09<00:04,  4.90s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.59s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.76s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.80s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.97s/it]
[2023-08-12 17:26:22,327] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.09s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.21s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.30s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.48s/it]
[2023-08-12 17:26:32,770] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 17:26:32,771] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 17:26:32,771] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 17:26:32,771] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f3e6c848b20>
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f3e6c8488b0>
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 17:26:32,773] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.6476607322692871 seconds
Loading extension module utils...
Time to load utils op: 0.5049121379852295 seconds
Loading extension module utils...
Time to load utils op: 0.6049313545227051 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Loading extension module utils...
Time to load utils op: 0.7050950527191162 seconds
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Rationales: 1. The question asks where you could find some plumbing that would not be useful to you if you were thirsty.
2. This means we're looking for a place that has plumbing but doesn't provide potable, or drinkable, water.
3. Let's analyze each choice:
4. Option A: Oil Refineries. These are places where crude oil is processed and refined into more useful products such as petrol, diesel, and other chemical products. While they may have plumbing to facilitate the movement of oil, the purpose is not meant for drinking water. Hence this could be a possible answer.
5. Option B: Wall. The wall might contain plumbing as part of the building's infrastructure, but it is primarily designed to transport water to useful locations like faucets, not for drinking directly. This isn't a strong answer.
6. Option C: Show. The term "show" appears somewhat ambiguous in this context. It could refer to a television show, a play, a showcase, etc. None of these interpretations seem to involve plumbing let alone providing drinking water. However, the question refers to a place so this seems an unlikely answer.
7. Option D: Own Home. In your own home, the plumbing systems serve various purposes like providing drinking water through faucets and taps. Therefore, if you were thirsty at home, the plumbing would be useful to you.
8. Option E: Water Fountain. A water fountain also provides drinking water, so it would be useful if you were thirsty.
9. Only option A, oil refineries, involves plumbing that doesn't normally provide drinking water.
10. Thus, the answer is A: oil refineries.
Answer: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Rationales: 1. The question is asking what a person isn't doing "yet" when they are beginning work.
2. This implies that the answer would be something that generally happens later in the work process.
3. Looking at choice A: "working", we can rule this out because a person is already engaging in work when they are beginning work.
4. Choice B: "resting", can also be ruled out because resting generally happens after or in-between work, so it doesn't quite answer the question.
5. Similarly, choice C: "tiredness", does not fit because it's a condition that might occur while or after working.
6. For choice E: "momentum", it's possible to start work with momentum so this option doesn't generally happen later in the work process.
7. This leaves us with choice D: "accomplishing". Advancement or achievement ("accomplishing") usually comes after having put significant time and effort into the work. Therefore, this is the best choice. 
8. So, when a person is beginning work, they aren't yet accomplishing. This aligns very well with the process of working. Hence, the answer is D: accomplishing.
Answer: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Rationales: 1. The question asks for a location where one might find pens with a company logo.
2. The possible answers are various places or things: an office, a pencil, writing sentences on paper, a school, or a backpack.
3. A company logo on a pen is often a promotional item that is commonly used in a corporate environment.
4. The places where you might find such items are generally offices or corporate events. Therefore, the most logical option is the office, as it is a working environment.
5. Out of all the other options, none consistently have pens with a company logo. Though a pencil, school, or backpack could occasionally contain these pens, they're not as likely because they are not specifically related to a corporate environment. 
6. And writing sentences on paper is not a location, so it's incorrect.
7. Therefore, after analyzing each choice, the answer is A: office, because this location is most likely to have pens with a company logo due to corporate use.
Answer: A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Rationales: 1. The question describes a situation where Billy called out to John. 
2. If someone calls out to another person, they are usually looking for a reply or wanting to get their attention.
3. This means that Billy would be expecting something coming back from John in return.
4. Let's explore the multiple choice answers. Option A: Billy might not expect silence because when you call out to someone, you want them to say something in return.
5. Option C: communication could be a potential answer, but it is quite broad. A response is a specific form of communication that happens when one person replies to another's words or actions.
6. Option D: hanging up is irrelevant because the situation does not involve using a phone.
7. Option E: a whisper could be considered a kind of response, but it is not necessarily what one would expect in this context. The response could be loud or soft, quick or slow, depending on the scenario.
8. Hence, the best choice is B: response, which is what one would commonly expect after calling out to someone.
Answer: B: response

Input: The lizard frightened the hiker, it's movements made what rustle? Choices:  A: garden B: trees C: books D: rocks E: bushes
Rationales: 1. The question is asking about the origin of the sound that frightened the hiker. 
2. The sound is described as a rustle, which typically refers to a soft, muffled crackling sound like that made by the movement of dry leaves or paper.
3. The answer choices given are garden, trees, books, rocks and bushes. We need to select an option where a lizard's movement could cause a rustling sound.
4. Consider 'garden'- the lizard can move in a garden, but a garden itself isn't known to produce a rustling sound specifically.
5. As for 'trees' and 'books', rustling could potentially happen due to wind or movement, but lizards don't typically move on these surfaces enough to cause a rustle.
6. 'Rocks' do not make a rustling sound when moved, ruling out this option.
7. Now, consider 'bushes'. Lizards often move inside and between bushes, where leaves could produce a rustling sound.
8. Hence, E: bushes is the answer. The lizard's movements made the bushes rustle, causing the hiker to be frightened.
Answer: E: bushes

Input: The man spent big money and time maintaining his lawn, it was part of keeping up with the Joneses where? Choices:  A: front yard B: suburbia C: neighborhood D: back yard E: golf course
Rationales: 1. The phrase "keeping up with the Joneses" refers to the comparison and competition one experiences amongst their neighbors where they strive to have the latest and greatest possessions or appearances.
2. In this case, the man is spending money and time maintaining his lawn, which is likely seen by his neighbors.
3. While options like "front yard", "neighborhood", and "back yard" can be places where the man's lawn is located and hence seen by his neighbors, they do not encompass the broader societal setting in which the pressures of "keeping up with the Joneses" occur.
4. Same with "golf course", this term neither implies the residence of the individual nor does it highlight the neighborhood aspect of the phrase.
5. On the other hand, "suburbia" implies a suburban setting where groups of residential houses are present and thus is often associated with the societal pressures of comparisons amongst neighbors or "keeping up with the Joneses".
6. Therefore, answer B: "suburbia" is the appropriate choice as it best fits the context of where "keeping up with the Joneses" takes place.
Answer: B: suburbia

### Input:Natalia sold clips to 4
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o6-tcommonsenseqa-s1-rTrue
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:42<34:35, 42.35s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:23<33:26, 41.80s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:05<32:35, 41.61s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [02:46<31:51, 41.56s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [03:27<31:03, 41.41s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [04:09<30:21, 41.40s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [04:50<29:39, 41.38s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [05:31<28:58, 41.39s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [06:13<28:17, 41.39s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [06:54<27:33, 41.33s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [07:35<26:52, 41.34s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [08:17<26:09, 41.30s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [08:58<25:28, 41.31s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [09:39<24:47, 41.33s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [10:20<24:05, 41.29s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [11:02<23:25, 41.34s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [11:43<22:45, 41.36s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [12:25<22:03, 41.37s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [13:06<21:20, 41.31s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [13:47<20:39, 41.32s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [14:29<19:58, 41.34s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [15:10<19:18, 41.38s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [15:51<18:36, 41.36s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [16:33<17:54, 41.31s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [17:05<16:07, 38.68s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [17:47<15:47, 39.48s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [18:28<15:20, 40.01s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [19:09<14:48, 40.37s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [19:50<14:12, 40.62s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [20:31<13:35, 40.76s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [21:13<12:57, 40.92s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [21:54<12:19, 41.08s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [22:35<11:39, 41.17s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [23:17<10:59, 41.24s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [23:58<10:18, 41.21s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [24:39<09:37, 41.22s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [25:21<08:56, 41.27s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [26:02<08:14, 41.22s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [26:43<07:33, 41.26s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [27:24<06:52, 41.23s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [28:05<06:10, 41.20s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [28:47<05:29, 41.25s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [29:28<04:48, 41.22s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [30:09<04:07, 41.23s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [30:50<03:26, 41.27s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [31:32<02:44, 41.24s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [32:13<02:03, 41.25s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [32:54<01:22, 41.30s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [33:35<00:41, 41.25s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [34:17<00:00, 41.24s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [34:17<00:00, 41.14s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.1383} | lm_loss 10.6211 | avg. gen lenth: 397.12
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o7-tcommonsenseqa-s1-rTrue --seed 1 --rationales --num-out-domain 7
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-12 18:01:18,120] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o7-tcommonsenseqa-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 7
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o7-tcommonsenseqa-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  0%|                                                     | 14/7473 [00:00<00:57, 130.64it/s]  0%|▏                                                    | 28/7473 [00:00<00:56, 131.02it/s]  1%|▎                                                    | 42/7473 [00:00<00:56, 131.23it/s]  1%|▍                                                    | 56/7473 [00:00<00:56, 131.61it/s]  1%|▍                                                    | 70/7473 [00:00<00:56, 131.60it/s]  1%|▌                                                    | 84/7473 [00:00<00:56, 131.65it/s]  1%|▋                                                    | 98/7473 [00:00<00:56, 129.81it/s]  1%|▊                                                   | 112/7473 [00:00<00:56, 130.13it/s]  2%|▉                                                   | 126/7473 [00:00<00:56, 130.37it/s]  2%|▉                                                   | 140/7473 [00:01<00:56, 130.75it/s]  2%|█                                                   | 154/7473 [00:01<00:55, 131.17it/s]  2%|█▏                                                  | 168/7473 [00:01<00:55, 131.11it/s]  2%|█▎                                                  | 182/7473 [00:01<00:55, 131.48it/s]  3%|█▎                                                  | 196/7473 [00:01<00:55, 131.45it/s]  3%|█▍                                                  | 210/7473 [00:01<00:55, 131.71it/s]  3%|█▌                                                  | 224/7473 [00:01<00:55, 130.44it/s]  3%|█▋                                                  | 238/7473 [00:01<00:55, 130.54it/s]  3%|█▊                                                  | 252/7473 [00:01<00:56, 128.52it/s]  4%|█▊                                                  | 266/7473 [00:02<00:55, 129.82it/s]  4%|█▉                                                  | 280/7473 [00:02<00:55, 130.41it/s]  4%|██                                                  | 294/7473 [00:02<00:54, 130.88it/s]  4%|██▏                                                 | 310/7473 [00:02<00:51, 138.07it/s]  4%|██▎                                                 | 331/7473 [00:02<00:45, 156.99it/s]  5%|██▍                                                 | 351/7473 [00:02<00:42, 169.36it/s]  5%|██▌                                                 | 371/7473 [00:02<00:40, 176.64it/s]  5%|██▋                                                 | 391/7473 [00:02<00:38, 181.94it/s]  5%|██▊                                                 | 411/7473 [00:02<00:38, 185.25it/s]  6%|██▉                                                 | 431/7473 [00:02<00:37, 189.34it/s]  6%|███▏                                                | 452/7473 [00:03<00:36, 192.86it/s]  6%|███▎                                                | 473/7473 [00:03<00:35, 195.18it/s]  7%|███▍                                                | 493/7473 [00:03<00:35, 195.24it/s]  7%|███▌                                                | 514/7473 [00:03<00:35, 196.79it/s]  7%|███▋                                                | 535/7473 [00:03<00:35, 198.13it/s]  7%|███▊                                                | 556/7473 [00:03<00:34, 199.37it/s]  8%|████                                                | 577/7473 [00:03<00:34, 199.67it/s]  8%|████▏                                               | 598/7473 [00:03<00:34, 199.86it/s]  8%|████▎                                               | 618/7473 [00:03<00:34, 199.86it/s]  9%|████▍                                               | 638/7473 [00:04<00:34, 199.34it/s]  9%|████▌                                               | 659/7473 [00:04<00:34, 199.84it/s]  9%|████▋                                               | 680/7473 [00:04<00:33, 200.25it/s]  9%|████▉                                               | 701/7473 [00:04<00:33, 200.91it/s] 10%|█████                                               | 722/7473 [00:04<00:33, 199.46it/s] 10%|█████▏                                              | 743/7473 [00:04<00:33, 200.37it/s] 10%|█████▎                                              | 764/7473 [00:04<00:33, 200.26it/s] 11%|█████▍                                              | 785/7473 [00:04<00:33, 200.23it/s] 11%|█████▌                                              | 806/7473 [00:04<00:33, 200.01it/s] 11%|█████▊                                              | 827/7473 [00:04<00:33, 200.22it/s] 11%|█████▉                                              | 848/7473 [00:05<00:33, 200.44it/s] 12%|██████                                              | 869/7473 [00:05<00:32, 200.69it/s] 12%|██████▏                                             | 890/7473 [00:05<00:32, 200.69it/s] 12%|██████▎                                             | 911/7473 [00:05<00:32, 199.14it/s] 12%|██████▍                                             | 931/7473 [00:05<00:33, 197.29it/s] 13%|██████▌                                             | 952/7473 [00:05<00:32, 198.55it/s] 13%|██████▊                                             | 973/7473 [00:05<00:32, 199.74it/s] 13%|██████▉                                             | 994/7473 [00:05<00:32, 200.33it/s] 14%|██████▉                                            | 1015/7473 [00:05<00:32, 200.37it/s] 14%|███████                                            | 1036/7473 [00:05<00:32, 200.39it/s] 14%|███████▏                                           | 1057/7473 [00:06<00:31, 200.85it/s] 14%|███████▎                                           | 1078/7473 [00:06<00:31, 200.88it/s] 15%|███████▌                                           | 1099/7473 [00:06<00:31, 201.10it/s] 15%|███████▋                                           | 1120/7473 [00:06<00:31, 201.02it/s] 15%|███████▊                                           | 1141/7473 [00:06<00:31, 200.80it/s] 16%|███████▉                                           | 1162/7473 [00:06<00:32, 196.89it/s] 16%|████████                                           | 1183/7473 [00:06<00:31, 197.91it/s] 16%|████████▏                                          | 1203/7473 [00:06<00:31, 198.35it/s] 16%|████████▎                                          | 1224/7473 [00:06<00:31, 199.20it/s] 17%|████████▍                                          | 1245/7473 [00:07<00:31, 199.58it/s] 17%|████████▋                                          | 1265/7473 [00:07<00:31, 199.70it/s] 17%|████████▊                                          | 1286/7473 [00:07<00:30, 200.21it/s] 17%|████████▉                                          | 1307/7473 [00:07<00:30, 200.55it/s] 18%|█████████                                          | 1328/7473 [00:07<00:30, 200.69it/s] 18%|█████████▏                                         | 1349/7473 [00:07<00:30, 200.96it/s] 18%|█████████▎                                         | 1370/7473 [00:07<00:30, 200.87it/s] 19%|█████████▍                                         | 1391/7473 [00:07<00:30, 198.55it/s] 19%|█████████▋                                         | 1412/7473 [00:07<00:30, 199.34it/s] 19%|█████████▊                                         | 1432/7473 [00:07<00:30, 199.24it/s] 19%|█████████▉                                         | 1453/7473 [00:08<00:30, 199.80it/s] 20%|██████████                                         | 1474/7473 [00:08<00:29, 200.19it/s] 20%|██████████▏                                        | 1495/7473 [00:08<00:29, 200.57it/s] 20%|██████████▎                                        | 1516/7473 [00:08<00:29, 200.72it/s] 21%|██████████▍                                        | 1537/7473 [00:08<00:29, 200.84it/s] 21%|██████████▋                                        | 1558/7473 [00:08<00:29, 200.50it/s] 21%|██████████▊                                        | 1579/7473 [00:08<00:29, 200.15it/s] 21%|██████████▉                                        | 1600/7473 [00:08<00:29, 199.98it/s] 22%|███████████                                        | 1620/7473 [00:08<00:29, 198.46it/s] 22%|███████████▏                                       | 1641/7473 [00:09<00:29, 199.22it/s] 22%|███████████▎                                       | 1661/7473 [00:09<00:29, 199.33it/s] 23%|███████████▍                                       | 1682/7473 [00:09<00:28, 200.13it/s] 23%|███████████▌                                       | 1703/7473 [00:09<00:28, 200.24it/s] 23%|███████████▊                                       | 1724/7473 [00:09<00:28, 200.17it/s] 23%|███████████▉                                       | 1745/7473 [00:09<00:28, 200.10it/s] 24%|████████████                                       | 1766/7473 [00:09<00:28, 199.47it/s] 24%|████████████▏                                      | 1787/7473 [00:09<00:28, 199.86it/s] 24%|████████████▎                                      | 1808/7473 [00:09<00:28, 200.21it/s] 24%|████████████▍                                      | 1829/7473 [00:09<00:28, 199.86it/s] 25%|████████████▌                                      | 1849/7473 [00:10<00:28, 197.81it/s] 25%|████████████▊                                      | 1870/7473 [00:10<00:28, 198.69it/s] 25%|████████████▉                                      | 1890/7473 [00:10<00:28, 199.02it/s] 26%|█████████████                                      | 1910/7473 [00:10<00:27, 198.90it/s] 26%|█████████████▏                                     | 1930/7473 [00:10<00:27, 199.13it/s] 26%|█████████████▎                                     | 1950/7473 [00:10<00:27, 199.16it/s] 26%|█████████████▍                                     | 1970/7473 [00:10<00:27, 199.27it/s] 27%|█████████████▌                                     | 1991/7473 [00:10<00:27, 199.52it/s] 27%|█████████████▋                                     | 2011/7473 [00:10<00:27, 199.53it/s] 27%|█████████████▊                                     | 2032/7473 [00:10<00:27, 199.93it/s] 27%|██████████████                                     | 2052/7473 [00:11<00:27, 199.74it/s] 28%|██████████████▏                                    | 2072/7473 [00:11<00:27, 197.88it/s] 28%|██████████████▎                                    | 2093/7473 [00:11<00:27, 198.75it/s] 28%|██████████████▍                                    | 2113/7473 [00:11<00:26, 198.83it/s] 29%|██████████████▌                                    | 2133/7473 [00:11<00:26, 198.46it/s] 29%|██████████████▋                                    | 2154/7473 [00:11<00:26, 199.22it/s] 29%|██████████████▊                                    | 2174/7473 [00:11<00:26, 199.34it/s] 29%|██████████████▉                                    | 2194/7473 [00:11<00:26, 199.15it/s] 30%|███████████████                                    | 2215/7473 [00:11<00:26, 199.79it/s] 30%|███████████████▎                                   | 2235/7473 [00:11<00:26, 199.77it/s] 30%|███████████████▍                                   | 2255/7473 [00:12<00:26, 199.17it/s] 30%|███████████████▌                                   | 2275/7473 [00:12<00:26, 199.16it/s] 31%|███████████████▋                                   | 2295/7473 [00:12<00:26, 197.53it/s] 31%|███████████████▊                                   | 2316/7473 [00:12<00:25, 198.65it/s] 31%|███████████████▉                                   | 2337/7473 [00:12<00:25, 199.08it/s] 32%|████████████████                                   | 2357/7473 [00:12<00:25, 198.85it/s] 32%|████████████████▏                                  | 2377/7473 [00:12<00:25, 198.89it/s] 32%|████████████████▎                                  | 2397/7473 [00:12<00:25, 199.07it/s] 32%|████████████████▌                                  | 2418/7473 [00:12<00:25, 199.45it/s] 33%|████████████████▋                                  | 2438/7473 [00:13<00:25, 199.45it/s] 33%|████████████████▊                                  | 2459/7473 [00:13<00:25, 199.56it/s] 33%|████████████████▉                                  | 2479/7473 [00:13<00:25, 199.62it/s] 33%|█████████████████                                  | 2499/7473 [00:13<00:24, 199.44it/s] 34%|█████████████████▏                                 | 2519/7473 [00:13<00:28, 173.58it/s] 34%|█████████████████▎                                 | 2539/7473 [00:13<00:27, 179.89it/s] 34%|█████████████████▍                                 | 2559/7473 [00:13<00:26, 185.25it/s] 35%|█████████████████▌                                 | 2580/7473 [00:13<00:25, 189.95it/s] 35%|█████████████████▋                                 | 2600/7473 [00:13<00:25, 192.42it/s] 35%|█████████████████▉                                 | 2620/7473 [00:13<00:24, 194.35it/s] 35%|██████████████████                                 | 2640/7473 [00:14<00:24, 195.25it/s] 36%|██████████████████▏                                | 2661/7473 [00:14<00:24, 197.14it/s] 36%|██████████████████▎                                | 2682/7473 [00:14<00:24, 198.43it/s] 36%|██████████████████▍                                | 2703/7473 [00:14<00:23, 199.02it/s] 36%|██████████████████▌                                | 2724/7473 [00:14<00:23, 199.43it/s] 37%|██████████████████▋                                | 2744/7473 [00:14<00:23, 199.05it/s] 37%|██████████████████▊                                | 2764/7473 [00:14<00:23, 197.00it/s] 37%|███████████████████                                | 2785/7473 [00:14<00:23, 198.34it/s] 38%|███████████████████▏                               | 2806/7473 [00:14<00:23, 199.19it/s] 38%|███████████████████▎                               | 2826/7473 [00:15<00:23, 199.35it/s] 38%|███████████████████▍                               | 2847/7473 [00:15<00:23, 199.61it/s] 38%|███████████████████▌                               | 2867/7473 [00:15<00:23, 199.57it/s] 39%|███████████████████▋                               | 2888/7473 [00:15<00:22, 199.77it/s] 39%|███████████████████▊                               | 2909/7473 [00:15<00:22, 200.21it/s] 39%|███████████████████▉                               | 2930/7473 [00:15<00:22, 200.82it/s] 39%|████████████████████▏                              | 2951/7473 [00:15<00:22, 200.75it/s] 40%|████████████████████▎                              | 2972/7473 [00:15<00:22, 200.53it/s] 40%|████████████████████▍                              | 2993/7473 [00:15<00:22, 198.85it/s] 40%|████████████████████▌                              | 3014/7473 [00:15<00:22, 199.35it/s] 41%|████████████████████▋                              | 3034/7473 [00:16<00:22, 199.25it/s] 41%|████████████████████▊                              | 3054/7473 [00:16<00:22, 199.32it/s] 41%|████████████████████▉                              | 3075/7473 [00:16<00:22, 199.68it/s] 41%|█████████████████████▏                             | 3096/7473 [00:16<00:21, 199.93it/s] 42%|█████████████████████▎                             | 3116/7473 [00:16<00:22, 197.61it/s] 42%|█████████████████████▍                             | 3136/7473 [00:16<00:21, 198.18it/s] 42%|█████████████████████▌                             | 3156/7473 [00:16<00:21, 198.37it/s] 42%|█████████████████████▋                             | 3176/7473 [00:16<00:21, 198.61it/s] 43%|█████████████████████▊                             | 3197/7473 [00:16<00:21, 199.05it/s] 43%|█████████████████████▉                             | 3217/7473 [00:16<00:21, 197.48it/s] 43%|██████████████████████                             | 3238/7473 [00:17<00:21, 198.34it/s] 44%|██████████████████████▏                            | 3258/7473 [00:17<00:21, 198.82it/s] 44%|██████████████████████▍                            | 3279/7473 [00:17<00:21, 199.34it/s] 44%|██████████████████████▌                            | 3299/7473 [00:17<00:20, 199.52it/s] 44%|██████████████████████▋                            | 3319/7473 [00:17<00:20, 199.56it/s] 45%|██████████████████████▊                            | 3339/7473 [00:17<00:20, 198.83it/s] 45%|██████████████████████▉                            | 3360/7473 [00:17<00:20, 199.28it/s] 45%|███████████████████████                            | 3380/7473 [00:17<00:20, 199.24it/s] 45%|███████████████████████▏                           | 3400/7473 [00:17<00:20, 199.37it/s] 46%|███████████████████████▎                           | 3420/7473 [00:17<00:20, 199.46it/s] 46%|███████████████████████▍                           | 3440/7473 [00:18<00:20, 196.36it/s] 46%|███████████████████████▌                           | 3460/7473 [00:18<00:20, 196.94it/s] 47%|███████████████████████▋                           | 3480/7473 [00:18<00:20, 197.52it/s] 47%|███████████████████████▉                           | 3501/7473 [00:18<00:20, 198.58it/s] 47%|████████████████████████                           | 3522/7473 [00:18<00:19, 199.01it/s] 47%|████████████████████████▏                          | 3542/7473 [00:18<00:19, 199.27it/s] 48%|████████████████████████▎                          | 3562/7473 [00:18<00:19, 199.40it/s] 48%|████████████████████████▍                          | 3583/7473 [00:18<00:19, 199.57it/s] 48%|████████████████████████▌                          | 3603/7473 [00:18<00:19, 199.61it/s] 48%|████████████████████████▋                          | 3624/7473 [00:19<00:19, 199.64it/s] 49%|████████████████████████▊                          | 3644/7473 [00:19<00:19, 199.37it/s] 49%|█████████████████████████                          | 3664/7473 [00:19<00:19, 197.62it/s] 49%|█████████████████████████▏                         | 3685/7473 [00:19<00:19, 198.29it/s] 50%|█████████████████████████▎                         | 3705/7473 [00:19<00:19, 198.27it/s] 50%|█████████████████████████▍                         | 3725/7473 [00:19<00:18, 198.42it/s] 50%|█████████████████████████▌                         | 3745/7473 [00:19<00:18, 198.65it/s] 50%|█████████████████████████▋                         | 3766/7473 [00:19<00:18, 199.12it/s] 51%|█████████████████████████▊                         | 3786/7473 [00:19<00:18, 198.13it/s] 51%|█████████████████████████▉                         | 3806/7473 [00:19<00:18, 198.66it/s] 51%|██████████████████████████                         | 3826/7473 [00:20<00:18, 198.66it/s] 51%|██████████████████████████▏                        | 3846/7473 [00:20<00:18, 198.72it/s] 52%|██████████████████████████▍                        | 3866/7473 [00:20<00:18, 198.85it/s] 52%|██████████████████████████▌                        | 3886/7473 [00:20<00:18, 197.15it/s] 52%|██████████████████████████▋                        | 3906/7473 [00:20<00:18, 197.81it/s] 53%|██████████████████████████▊                        | 3926/7473 [00:20<00:17, 198.22it/s] 53%|██████████████████████████▉                        | 3946/7473 [00:20<00:17, 198.68it/s] 53%|███████████████████████████                        | 3966/7473 [00:20<00:17, 198.93it/s] 53%|███████████████████████████▏                       | 3986/7473 [00:20<00:17, 198.85it/s] 54%|███████████████████████████▎                       | 4007/7473 [00:20<00:17, 199.24it/s] 54%|███████████████████████████▍                       | 4028/7473 [00:21<00:17, 199.44it/s] 54%|███████████████████████████▋                       | 4048/7473 [00:21<00:17, 199.45it/s] 54%|███████████████████████████▊                       | 4069/7473 [00:21<00:17, 199.61it/s] 55%|███████████████████████████▉                       | 4089/7473 [00:21<00:16, 199.51it/s] 55%|████████████████████████████                       | 4109/7473 [00:21<00:17, 197.39it/s] 55%|████████████████████████████▏                      | 4129/7473 [00:21<00:17, 195.70it/s] 56%|████████████████████████████▎                      | 4149/7473 [00:21<00:16, 196.62it/s] 56%|████████████████████████████▍                      | 4169/7473 [00:21<00:16, 197.59it/s] 56%|████████████████████████████▌                      | 4189/7473 [00:21<00:16, 198.10it/s] 56%|████████████████████████████▋                      | 4209/7473 [00:21<00:16, 198.61it/s] 57%|████████████████████████████▊                      | 4229/7473 [00:22<00:16, 198.78it/s] 57%|████████████████████████████▉                      | 4249/7473 [00:22<00:16, 198.88it/s] 57%|█████████████████████████████▏                     | 4269/7473 [00:22<00:16, 198.88it/s] 57%|█████████████████████████████▎                     | 4289/7473 [00:22<00:16, 198.89it/s] 58%|█████████████████████████████▍                     | 4310/7473 [00:22<00:15, 199.28it/s] 58%|█████████████████████████████▌                     | 4331/7473 [00:22<00:15, 199.19it/s] 58%|█████████████████████████████▋                     | 4351/7473 [00:22<00:15, 197.37it/s] 58%|█████████████████████████████▊                     | 4371/7473 [00:22<00:15, 197.64it/s] 59%|█████████████████████████████▉                     | 4391/7473 [00:22<00:15, 198.16it/s] 59%|██████████████████████████████                     | 4412/7473 [00:22<00:15, 198.82it/s] 59%|██████████████████████████████▏                    | 4432/7473 [00:23<00:15, 198.84it/s] 60%|██████████████████████████████▍                    | 4452/7473 [00:23<00:15, 197.00it/s] 60%|██████████████████████████████▌                    | 4472/7473 [00:23<00:15, 197.83it/s] 60%|██████████████████████████████▋                    | 4493/7473 [00:23<00:15, 198.52it/s] 60%|██████████████████████████████▊                    | 4513/7473 [00:23<00:14, 198.66it/s] 61%|██████████████████████████████▉                    | 4533/7473 [00:23<00:14, 198.62it/s] 61%|███████████████████████████████                    | 4554/7473 [00:23<00:14, 199.51it/s] 61%|███████████████████████████████▏                   | 4574/7473 [00:23<00:14, 197.98it/s] 61%|███████████████████████████████▎                   | 4594/7473 [00:23<00:14, 198.33it/s] 62%|███████████████████████████████▍                   | 4614/7473 [00:24<00:14, 198.80it/s] 62%|███████████████████████████████▋                   | 4634/7473 [00:24<00:14, 198.86it/s] 62%|███████████████████████████████▊                   | 4654/7473 [00:24<00:14, 199.18it/s] 63%|███████████████████████████████▉                   | 4674/7473 [00:24<00:14, 199.02it/s] 63%|████████████████████████████████                   | 4694/7473 [00:24<00:13, 199.29it/s] 63%|████████████████████████████████▏                  | 4714/7473 [00:24<00:13, 199.45it/s] 63%|████████████████████████████████▎                  | 4734/7473 [00:24<00:13, 199.61it/s] 64%|████████████████████████████████▍                  | 4755/7473 [00:24<00:13, 199.96it/s] 64%|████████████████████████████████▌                  | 4776/7473 [00:24<00:13, 200.02it/s] 64%|████████████████████████████████▋                  | 4797/7473 [00:24<00:13, 197.99it/s] 64%|████████████████████████████████▊                  | 4817/7473 [00:25<00:13, 198.27it/s] 65%|█████████████████████████████████                  | 4837/7473 [00:25<00:13, 198.65it/s] 65%|█████████████████████████████████▏                 | 4857/7473 [00:25<00:13, 198.90it/s] 65%|█████████████████████████████████▎                 | 4877/7473 [00:25<00:13, 199.06it/s] 66%|█████████████████████████████████▍                 | 4898/7473 [00:25<00:12, 199.72it/s] 66%|█████████████████████████████████▌                 | 4919/7473 [00:25<00:12, 199.84it/s] 66%|█████████████████████████████████▋                 | 4939/7473 [00:25<00:12, 199.66it/s] 66%|█████████████████████████████████▊                 | 4959/7473 [00:25<00:12, 199.74it/s] 67%|█████████████████████████████████▉                 | 4979/7473 [00:25<00:12, 199.47it/s] 67%|██████████████████████████████████                 | 4999/7473 [00:25<00:12, 199.54it/s] 67%|██████████████████████████████████▎                | 5019/7473 [00:26<00:12, 198.31it/s] 67%|██████████████████████████████████▍                | 5039/7473 [00:26<00:12, 198.67it/s] 68%|██████████████████████████████████▌                | 5059/7473 [00:26<00:12, 199.00it/s] 68%|██████████████████████████████████▋                | 5080/7473 [00:26<00:11, 199.46it/s] 68%|██████████████████████████████████▊                | 5100/7473 [00:26<00:11, 199.23it/s] 69%|██████████████████████████████████▉                | 5120/7473 [00:26<00:11, 199.27it/s] 69%|███████████████████████████████████                | 5141/7473 [00:26<00:11, 199.55it/s] 69%|███████████████████████████████████▏               | 5161/7473 [00:26<00:11, 199.62it/s] 69%|███████████████████████████████████▎               | 5181/7473 [00:26<00:11, 199.71it/s] 70%|███████████████████████████████████▍               | 5201/7473 [00:26<00:11, 199.65it/s] 70%|███████████████████████████████████▋               | 5221/7473 [00:27<00:11, 199.59it/s] 70%|███████████████████████████████████▊               | 5241/7473 [00:27<00:11, 198.59it/s] 70%|███████████████████████████████████▉               | 5261/7473 [00:27<00:13, 169.57it/s] 71%|████████████████████████████████████               | 5282/7473 [00:27<00:12, 178.01it/s] 71%|████████████████████████████████████▏              | 5302/7473 [00:27<00:11, 183.74it/s] 71%|████████████████████████████████████▎              | 5322/7473 [00:27<00:11, 187.84it/s] 71%|████████████████████████████████████▍              | 5342/7473 [00:27<00:11, 191.09it/s] 72%|████████████████████████████████████▌              | 5362/7473 [00:27<00:10, 193.30it/s] 72%|████████████████████████████████████▋              | 5382/7473 [00:27<00:10, 195.21it/s] 72%|████████████████████████████████████▊              | 5402/7473 [00:28<00:10, 196.45it/s] 73%|█████████████████████████████████████              | 5422/7473 [00:28<00:10, 197.46it/s] 73%|█████████████████████████████████████▏             | 5442/7473 [00:28<00:10, 197.70it/s] 73%|█████████████████████████████████████▎             | 5462/7473 [00:28<00:10, 197.08it/s] 73%|█████████████████████████████████████▍             | 5482/7473 [00:28<00:15, 132.63it/s] 74%|█████████████████████████████████████▌             | 5502/7473 [00:28<00:13, 147.16it/s] 74%|█████████████████████████████████████▋             | 5522/7473 [00:28<00:12, 159.81it/s] 74%|█████████████████████████████████████▊             | 5542/7473 [00:28<00:11, 169.49it/s] 74%|█████████████████████████████████████▉             | 5562/7473 [00:28<00:10, 177.49it/s] 75%|██████████████████████████████████████             | 5582/7473 [00:29<00:10, 182.93it/s] 75%|██████████████████████████████████████▏            | 5602/7473 [00:29<00:09, 187.25it/s] 75%|██████████████████████████████████████▎            | 5622/7473 [00:29<00:09, 190.12it/s] 75%|██████████████████████████████████████▌            | 5642/7473 [00:29<00:09, 192.73it/s] 76%|██████████████████████████████████████▋            | 5662/7473 [00:29<00:09, 194.55it/s] 76%|██████████████████████████████████████▊            | 5682/7473 [00:29<00:09, 194.04it/s] 76%|██████████████████████████████████████▉            | 5702/7473 [00:29<00:09, 195.15it/s] 77%|███████████████████████████████████████            | 5722/7473 [00:29<00:08, 195.82it/s] 77%|███████████████████████████████████████▏           | 5742/7473 [00:29<00:08, 196.78it/s] 77%|███████████████████████████████████████▎           | 5762/7473 [00:30<00:08, 197.58it/s] 77%|███████████████████████████████████████▍           | 5782/7473 [00:30<00:08, 197.95it/s] 78%|███████████████████████████████████████▌           | 5802/7473 [00:30<00:08, 197.84it/s] 78%|███████████████████████████████████████▋           | 5822/7473 [00:30<00:08, 197.55it/s] 78%|███████████████████████████████████████▊           | 5842/7473 [00:30<00:08, 197.57it/s] 78%|████████████████████████████████████████           | 5862/7473 [00:30<00:08, 197.71it/s] 79%|████████████████████████████████████████▏          | 5882/7473 [00:30<00:08, 197.88it/s] 79%|████████████████████████████████████████▎          | 5902/7473 [00:30<00:08, 196.17it/s] 79%|████████████████████████████████████████▍          | 5922/7473 [00:30<00:07, 195.91it/s] 80%|████████████████████████████████████████▌          | 5942/7473 [00:30<00:07, 196.47it/s] 80%|████████████████████████████████████████▋          | 5962/7473 [00:31<00:07, 196.36it/s] 80%|████████████████████████████████████████▊          | 5982/7473 [00:31<00:07, 196.49it/s] 80%|████████████████████████████████████████▉          | 6002/7473 [00:31<00:07, 196.18it/s] 81%|█████████████████████████████████████████          | 6022/7473 [00:31<00:07, 196.33it/s] 81%|█████████████████████████████████████████▏         | 6042/7473 [00:31<00:07, 196.25it/s] 81%|█████████████████████████████████████████▎         | 6062/7473 [00:31<00:07, 196.39it/s] 81%|█████████████████████████████████████████▌         | 6082/7473 [00:31<00:07, 196.34it/s] 82%|█████████████████████████████████████████▋         | 6102/7473 [00:31<00:06, 196.63it/s] 82%|█████████████████████████████████████████▊         | 6122/7473 [00:31<00:06, 196.48it/s] 82%|█████████████████████████████████████████▉         | 6142/7473 [00:31<00:06, 194.61it/s] 82%|██████████████████████████████████████████         | 6162/7473 [00:32<00:06, 195.32it/s] 83%|██████████████████████████████████████████▏        | 6182/7473 [00:32<00:06, 195.42it/s] 83%|██████████████████████████████████████████▎        | 6202/7473 [00:32<00:06, 195.90it/s] 83%|██████████████████████████████████████████▍        | 6222/7473 [00:32<00:06, 195.87it/s] 84%|██████████████████████████████████████████▌        | 6242/7473 [00:32<00:06, 196.22it/s] 84%|██████████████████████████████████████████▋        | 6262/7473 [00:32<00:06, 196.09it/s] 84%|██████████████████████████████████████████▊        | 6282/7473 [00:32<00:06, 196.50it/s] 84%|███████████████████████████████████████████        | 6302/7473 [00:32<00:05, 196.10it/s] 85%|███████████████████████████████████████████▏       | 6322/7473 [00:32<00:05, 196.46it/s] 85%|███████████████████████████████████████████▎       | 6342/7473 [00:32<00:05, 196.20it/s] 85%|███████████████████████████████████████████▍       | 6362/7473 [00:33<00:05, 194.70it/s] 85%|███████████████████████████████████████████▌       | 6382/7473 [00:33<00:05, 194.54it/s] 86%|███████████████████████████████████████████▋       | 6402/7473 [00:33<00:05, 194.95it/s] 86%|███████████████████████████████████████████▊       | 6422/7473 [00:33<00:05, 195.27it/s] 86%|███████████████████████████████████████████▉       | 6442/7473 [00:33<00:05, 195.30it/s] 86%|████████████████████████████████████████████       | 6462/7473 [00:33<00:05, 195.51it/s] 87%|████████████████████████████████████████████▏      | 6482/7473 [00:33<00:05, 195.77it/s] 87%|████████████████████████████████████████████▎      | 6502/7473 [00:33<00:04, 195.74it/s] 87%|████████████████████████████████████████████▌      | 6522/7473 [00:33<00:04, 195.38it/s] 88%|████████████████████████████████████████████▋      | 6542/7473 [00:33<00:04, 195.98it/s] 88%|████████████████████████████████████████████▊      | 6562/7473 [00:34<00:04, 195.98it/s] 88%|████████████████████████████████████████████▉      | 6582/7473 [00:34<00:04, 194.58it/s] 88%|█████████████████████████████████████████████      | 6602/7473 [00:34<00:04, 195.15it/s] 89%|█████████████████████████████████████████████▏     | 6622/7473 [00:34<00:04, 195.35it/s] 89%|█████████████████████████████████████████████▎     | 6642/7473 [00:34<00:04, 195.44it/s] 89%|█████████████████████████████████████████████▍     | 6662/7473 [00:34<00:04, 195.27it/s] 89%|█████████████████████████████████████████████▌     | 6682/7473 [00:34<00:04, 195.25it/s] 90%|█████████████████████████████████████████████▋     | 6702/7473 [00:34<00:03, 195.80it/s] 90%|█████████████████████████████████████████████▊     | 6722/7473 [00:34<00:03, 195.78it/s] 90%|██████████████████████████████████████████████     | 6742/7473 [00:35<00:03, 195.92it/s] 90%|██████████████████████████████████████████████▏    | 6762/7473 [00:35<00:03, 195.84it/s] 91%|██████████████████████████████████████████████▎    | 6782/7473 [00:35<00:03, 196.13it/s] 91%|██████████████████████████████████████████████▍    | 6802/7473 [00:35<00:03, 196.19it/s] 91%|██████████████████████████████████████████████▌    | 6822/7473 [00:35<00:03, 193.91it/s] 92%|██████████████████████████████████████████████▋    | 6842/7473 [00:35<00:03, 194.62it/s] 92%|██████████████████████████████████████████████▊    | 6862/7473 [00:35<00:03, 195.08it/s] 92%|██████████████████████████████████████████████▉    | 6882/7473 [00:35<00:03, 195.80it/s] 92%|███████████████████████████████████████████████    | 6902/7473 [00:35<00:02, 196.29it/s] 93%|███████████████████████████████████████████████▏   | 6922/7473 [00:35<00:02, 196.23it/s] 93%|███████████████████████████████████████████████▍   | 6942/7473 [00:36<00:02, 196.07it/s] 93%|███████████████████████████████████████████████▌   | 6962/7473 [00:36<00:02, 195.96it/s] 93%|███████████████████████████████████████████████▋   | 6982/7473 [00:36<00:02, 195.67it/s] 94%|███████████████████████████████████████████████▊   | 7002/7473 [00:36<00:02, 196.62it/s] 94%|███████████████████████████████████████████████▉   | 7022/7473 [00:36<00:02, 197.19it/s] 94%|████████████████████████████████████████████████   | 7042/7473 [00:36<00:02, 195.74it/s] 95%|████████████████████████████████████████████████▏  | 7062/7473 [00:36<00:02, 196.48it/s] 95%|████████████████████████████████████████████████▎  | 7082/7473 [00:36<00:01, 197.26it/s] 95%|████████████████████████████████████████████████▍  | 7102/7473 [00:36<00:01, 198.00it/s] 95%|████████████████████████████████████████████████▌  | 7122/7473 [00:36<00:01, 197.69it/s] 96%|████████████████████████████████████████████████▋  | 7142/7473 [00:37<00:01, 197.85it/s] 96%|████████████████████████████████████████████████▉  | 7162/7473 [00:37<00:01, 198.01it/s] 96%|█████████████████████████████████████████████████  | 7182/7473 [00:37<00:01, 197.92it/s] 96%|█████████████████████████████████████████████████▏ | 7202/7473 [00:37<00:01, 198.34it/s] 97%|█████████████████████████████████████████████████▎ | 7222/7473 [00:37<00:01, 198.61it/s] 97%|█████████████████████████████████████████████████▍ | 7242/7473 [00:37<00:01, 198.86it/s] 97%|█████████████████████████████████████████████████▌ | 7262/7473 [00:37<00:01, 197.20it/s] 97%|█████████████████████████████████████████████████▋ | 7282/7473 [00:37<00:00, 197.77it/s] 98%|█████████████████████████████████████████████████▊ | 7302/7473 [00:37<00:00, 198.31it/s] 98%|█████████████████████████████████████████████████▉ | 7322/7473 [00:37<00:00, 198.25it/s] 98%|██████████████████████████████████████████████████ | 7342/7473 [00:38<00:00, 198.07it/s] 99%|██████████████████████████████████████████████████▏| 7362/7473 [00:38<00:00, 197.94it/s] 99%|██████████████████████████████████████████████████▍| 7382/7473 [00:38<00:00, 197.85it/s] 99%|██████████████████████████████████████████████████▌| 7402/7473 [00:38<00:00, 198.39it/s] 99%|██████████████████████████████████████████████████▋| 7422/7473 [00:38<00:00, 198.43it/s]100%|██████████████████████████████████████████████████▊| 7442/7473 [00:38<00:00, 198.38it/s]100%|██████████████████████████████████████████████████▉| 7462/7473 [00:38<00:00, 197.59it/s]100%|███████████████████████████████████████████████████| 7473/7473 [00:38<00:00, 193.01it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.16s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:04<00:09,  4.99s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.12s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.82s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.04s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.04s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.22s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.38s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.43s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.60s/it]
[2023-08-12 18:02:48,282] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.48s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.63s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.67s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.81s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.68s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.91s/it]
[2023-08-12 18:03:04,270] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 18:03:04,271] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 18:03:04,271] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7eff62576b20>
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7eff625768b0>
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 18:03:04,274] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 18:03:04,274] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 18:03:04,274] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 18:03:04,274] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 18:03:04,274] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 18:03:04,274] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 18:03:04,274] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 18:03:04,274] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 18:03:04,274] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.662177324295044 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Rationales: 1. The question is asking to identify a location that has plumbing but will not be of use when thirsty.
2. So, it would help to consider what kind of liquid might be flowing through the plumbing in each option.
3. In the "own home" and "water fountain," it is likely to find potable water, which would be of use when thirsty.
4. The "wall" might contain pipes that carry water, so this option could potentially be of use when thirsty.
5. "Show" is a bit vague, but if it refers to a show or event, there might be water facilities available too. 
6. However, in "oil refineries," the plumbing does not transport water at all, but is used for the refining of oil. This would not be useful if you were thirsty, as you cannot drink oil.
7. Hence the answer is A: oil refineries.
Answer: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Rationales: 1. This question asks about what a person "isn't doing yet" when they are "beginning work".
2. This phrase implies that the person has only just begun their work and therefore can not have done certain things yet.
3. Let's analyze the options:
- A: working. Now, this is not the answer because the person has already begun their work, which means they are currently working.
- B: resting. This answer might make sense, because when a person starts working, they are not resting. But this does not usually imply an accomplishment.
- C: tiredness. This answer might not be correct because while it's true that when a person starts working, they are not typically tired, it doesn't exactly imply something they haven't done yet.
- E: momentum. This is not necessarily accurate because while it's true that someone might not yet have momentum when starting, it doesn't speak to an action or something they haven't done yet.
4. On the other hand, D: accomplishing definitely can be something the person hasn't done yet since they have just begun their work, the accomplishment would come after the work is completed.
5. Therefore, the correct answer is D: accomplishing.
Answer: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Rationales: 1. Pens with a company logo are usually items that are used for promotional purposes.
2. Companies often use these pens at their offices for staff members.
3. Staff members can also give these pens to visitors or clients, so they are often found in workplaces or business events.
4. While pens can indeed be found in places like school or a backpack, pens specifically with a company logo are not typically associated with these places.
5. Therefore, the most logical location to find pens with a company logo is an office. Hence, the answer is A: office.
Answer: A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Rationales: 1. The question is asking what Billy is waiting to hear after he has called out to John. 
2. We look at each of the provided options and consider them in relation to the situation described:
   A: Silence would not be expected after somebody calls out to another person.
   C: Communication is too broad a term and does not denote a specific reaction from John.
   D: Hanging up would not apply since the scenario does not involve a phone call.
   E: Whisper is too specific, the scenario implies that Billy is waiting for an audible and clear answer not a whisper.
3. Hence, we look at B: Response. A response is precisely what a person would expect after they call out to someone; they are waiting for that person to respond.
4. Therefore, the most logical answer to the question is B: Response.
Answer: B: response

Input: The lizard frightened the hiker, it's movements made what rustle? Choices:  A: garden B: trees C: books D: rocks E: bushes
Rationales: 1. The question asks us what rustled due to the lizard's movement when it frightened the hiker.
2. Let's analyze the options one by one. 
3. Option A: A garden might rustle, but it generally refers to an area with a variety of plants and wouldn’t collectively rustle by the movement of a small creature like a lizard.
4. Option B: Trees are too large to rustle due to a lizard's movements.
5. Option C: Books can rustle, but it's unlikely in this context since hikers wouldn't typically encounter books on a trail.
6. Option D: Rocks don’t rustle at all, they are hard and would not create a rustling sound due to a small creature's movement.
7. Option E: Bushes are smaller plants, often found along hiking trails, and could rustle due to a small creature's movement.
8. By a process of elimination and logical analysis, the answer is E: bushes.
Answer: E: bushes

Input: The man spent big money and time maintaining his lawn, it was part of keeping up with the Joneses where? Choices:  A: front yard B: suburbia C: neighborhood D: back yard E: golf course
Rationales: 1. The phrase "keeping up with the Joneses" refers to a situation where a person tries to match their neighbors' social and economic status by emulating their lifestyle and consumer behavior. 
2. The notion of 'keeping up with the Joneses' is usually associated with suburban life or lifestyle, where maintaining lawns and houses is considered as status symbols.
3. While other options such as front yard, neighborhood, back yard, and golf course all can be places where a well-maintained lawn could exist, none of them are as tightly correlated with the context of 'keeping up with the Joneses' as the suburbia, which encapsulates an entire lifestyle and social context.
4. Therefore, taking the whole context into consideration, the most appropropriate and encompassing answer is B: suburbia.
Answer: B: suburbia

Input: What would a human do if they want to get to a store that he or she can see? Choices:  A: cross road B: see around C: drink coffee D: dream dreams E: think critically
Rationales: 1. The question is asking for the action a human would most likely take if they want to get to a store that they can see.
2. To answer, we should think about the most straightforward or necessary act for someone who can see a store and wishes to reach it.
3. Let's look at the options: "cross the road," "see around," "drink coffee," "dream dreams," "think critically."
4. "Drink coffee," "dream dreams," and "think critically" aren't directly related to the act of reaching a visible destination. They could be actions one might take, but they aren't necessary or related to the process of getting to a visually spotted location. Thus, we can eliminate these choices.
5. "See around" could be a potential answer as someone might need to see around to get to a certain place, but it is not the most direct or clear action required in reaching a visible store. So we can remove this as well.
6. That leaves us with the option "cross the road." This is the most plausible answer because when a human sees a store and desires to reach it, one essential action might be to cross a road if the store is situated on the other side of the road. Hence, this is the answer.
7. So, the answer is A: cross the road.
Answer: A: cross road

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o7-tcommonsenseqa-s1-rTrue
Loading extension module utils...
Time to load utils op: 0.6049680709838867 seconds
Loading extension module utils...
Time to load utils op: 0.7049791812896729 seconds
Loading extension module utils...
Time to load utils op: 0.7048122882843018 seconds
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 139, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 116, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 139, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 116, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
Evaluating gsm8k :   0%|                                              | 0/50 [00:05<?, ?it/s]
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 139, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 116, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 139, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 116, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 3449822) of binary: /home/ylu130/.conda/envs/distllm/bin/python
Traceback (most recent call last):
  File "/home/ylu130/.conda/envs/distllm/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/run.py", line 761, in main
    run(args)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/ylu130/workspace/in-context-generalization/inference.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-08-12_18:03:16
  host      : ia1.wse.jhu.edu
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 3449823)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-08-12_18:03:16
  host      : ia1.wse.jhu.edu
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 3449824)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-08-12_18:03:16
  host      : ia1.wse.jhu.edu
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 3449825)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-08-12_18:03:16
  host      : ia1.wse.jhu.edu
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3449822)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o8-tcommonsenseqa-s1-rTrue --seed 1 --rationales --num-out-domain 8
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-12 18:03:19,581] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o8-tcommonsenseqa-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 8
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o8-tcommonsenseqa-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  0%|                                                     | 12/7473 [00:00<01:06, 113.00it/s]  0%|▏                                                    | 24/7473 [00:00<01:05, 114.15it/s]  0%|▎                                                    | 36/7473 [00:00<01:04, 114.46it/s]  1%|▎                                                    | 48/7473 [00:00<01:04, 114.65it/s]  1%|▍                                                    | 60/7473 [00:00<01:04, 114.79it/s]  1%|▌                                                    | 72/7473 [00:00<01:04, 114.72it/s]  1%|▌                                                    | 84/7473 [00:00<01:05, 112.98it/s]  1%|▋                                                    | 96/7473 [00:00<01:04, 113.64it/s]  1%|▊                                                   | 108/7473 [00:00<01:04, 113.75it/s]  2%|▊                                                   | 120/7473 [00:01<01:04, 114.14it/s]  2%|▉                                                   | 132/7473 [00:01<01:04, 114.33it/s]  2%|█                                                   | 144/7473 [00:01<01:03, 114.59it/s]  2%|█                                                   | 156/7473 [00:01<01:03, 114.77it/s]  2%|█▏                                                  | 168/7473 [00:01<01:03, 114.75it/s]  2%|█▎                                                  | 180/7473 [00:01<01:03, 114.94it/s]  3%|█▎                                                  | 192/7473 [00:01<01:03, 113.97it/s]  3%|█▍                                                  | 204/7473 [00:01<01:03, 114.22it/s]  3%|█▌                                                  | 216/7473 [00:01<01:03, 114.53it/s]  3%|█▌                                                  | 228/7473 [00:01<01:03, 114.55it/s]  3%|█▋                                                  | 240/7473 [00:02<01:03, 114.40it/s]  3%|█▊                                                  | 252/7473 [00:02<01:04, 112.33it/s]  4%|█▊                                                  | 265/7473 [00:02<01:02, 116.23it/s]  4%|█▉                                                  | 283/7473 [00:02<00:53, 133.80it/s]  4%|██                                                  | 301/7473 [00:02<00:49, 146.34it/s]  4%|██▏                                                 | 319/7473 [00:02<00:46, 155.09it/s]  5%|██▎                                                 | 337/7473 [00:02<00:44, 161.13it/s]  5%|██▍                                                 | 355/7473 [00:02<00:43, 165.48it/s]  5%|██▌                                                 | 373/7473 [00:02<00:42, 168.18it/s]  5%|██▋                                                 | 391/7473 [00:03<00:41, 170.37it/s]  5%|██▊                                                 | 409/7473 [00:03<00:41, 171.34it/s]  6%|██▉                                                 | 427/7473 [00:03<00:40, 172.02it/s]  6%|███                                                 | 445/7473 [00:03<00:40, 171.91it/s]  6%|███▏                                                | 463/7473 [00:03<00:40, 172.34it/s]  6%|███▎                                                | 481/7473 [00:03<00:40, 170.78it/s]  7%|███▍                                                | 499/7473 [00:03<00:40, 171.34it/s]  7%|███▌                                                | 517/7473 [00:03<00:40, 172.01it/s]  7%|███▋                                                | 535/7473 [00:03<00:40, 172.66it/s]  7%|███▊                                                | 553/7473 [00:03<00:40, 172.69it/s]  8%|███▉                                                | 571/7473 [00:04<00:39, 172.79it/s]  8%|████                                                | 589/7473 [00:04<00:39, 172.74it/s]  8%|████▏                                               | 607/7473 [00:04<00:39, 172.47it/s]  8%|████▎                                               | 625/7473 [00:04<00:39, 172.12it/s]  9%|████▍                                               | 643/7473 [00:04<00:39, 172.13it/s]  9%|████▌                                               | 661/7473 [00:04<00:39, 172.11it/s]  9%|████▋                                               | 679/7473 [00:04<00:39, 172.22it/s]  9%|████▊                                               | 697/7473 [00:04<00:39, 172.85it/s] 10%|████▉                                               | 715/7473 [00:04<00:39, 171.28it/s] 10%|█████                                               | 733/7473 [00:05<00:39, 172.06it/s] 10%|█████▏                                              | 751/7473 [00:05<00:39, 172.01it/s] 10%|█████▎                                              | 769/7473 [00:05<00:39, 171.78it/s] 11%|█████▍                                              | 787/7473 [00:05<00:38, 171.72it/s] 11%|█████▌                                              | 805/7473 [00:05<00:38, 171.73it/s] 11%|█████▋                                              | 823/7473 [00:05<00:38, 171.78it/s] 11%|█████▊                                              | 841/7473 [00:05<00:38, 171.52it/s] 11%|█████▉                                              | 859/7473 [00:05<00:38, 171.75it/s] 12%|██████                                              | 877/7473 [00:05<00:38, 171.99it/s] 12%|██████▏                                             | 895/7473 [00:05<00:38, 172.00it/s] 12%|██████▎                                             | 913/7473 [00:06<00:38, 172.01it/s] 12%|██████▍                                             | 931/7473 [00:06<00:38, 170.22it/s] 13%|██████▌                                             | 949/7473 [00:06<00:38, 170.94it/s] 13%|██████▋                                             | 967/7473 [00:06<00:37, 171.24it/s] 13%|██████▊                                             | 985/7473 [00:06<00:37, 171.73it/s] 13%|██████▊                                            | 1003/7473 [00:06<00:37, 171.47it/s] 14%|██████▉                                            | 1021/7473 [00:06<00:37, 171.89it/s] 14%|███████                                            | 1039/7473 [00:06<00:37, 171.78it/s] 14%|███████▏                                           | 1057/7473 [00:06<00:37, 170.44it/s] 14%|███████▎                                           | 1075/7473 [00:07<00:37, 170.81it/s] 15%|███████▍                                           | 1093/7473 [00:07<00:37, 171.11it/s] 15%|███████▌                                           | 1111/7473 [00:07<00:37, 171.11it/s] 15%|███████▋                                           | 1129/7473 [00:07<00:37, 171.05it/s] 15%|███████▊                                           | 1147/7473 [00:07<00:36, 171.37it/s] 16%|███████▉                                           | 1165/7473 [00:07<00:37, 169.95it/s] 16%|████████                                           | 1183/7473 [00:07<00:36, 170.54it/s] 16%|████████▏                                          | 1201/7473 [00:07<00:36, 171.69it/s] 16%|████████▎                                          | 1219/7473 [00:07<00:36, 173.24it/s] 17%|████████▍                                          | 1237/7473 [00:07<00:35, 174.12it/s] 17%|████████▌                                          | 1255/7473 [00:08<00:35, 174.76it/s] 17%|████████▋                                          | 1273/7473 [00:08<00:35, 175.42it/s] 17%|████████▊                                          | 1291/7473 [00:08<00:35, 174.38it/s] 18%|████████▉                                          | 1309/7473 [00:08<00:35, 174.83it/s] 18%|█████████                                          | 1327/7473 [00:08<00:35, 175.59it/s] 18%|█████████▏                                         | 1345/7473 [00:08<00:34, 175.88it/s] 18%|█████████▎                                         | 1363/7473 [00:08<00:34, 176.20it/s] 18%|█████████▍                                         | 1381/7473 [00:08<00:34, 175.94it/s] 19%|█████████▌                                         | 1399/7473 [00:08<00:35, 173.38it/s] 19%|█████████▋                                         | 1417/7473 [00:08<00:34, 174.06it/s] 19%|█████████▊                                         | 1435/7473 [00:09<00:34, 174.73it/s] 19%|█████████▉                                         | 1453/7473 [00:09<00:34, 175.26it/s] 20%|██████████                                         | 1471/7473 [00:09<00:34, 175.85it/s] 20%|██████████▏                                        | 1489/7473 [00:09<00:33, 176.26it/s] 20%|██████████▎                                        | 1507/7473 [00:09<00:33, 176.35it/s] 20%|██████████▍                                        | 1525/7473 [00:09<00:33, 175.78it/s] 21%|██████████▌                                        | 1543/7473 [00:09<00:33, 175.78it/s] 21%|██████████▋                                        | 1561/7473 [00:09<00:33, 175.73it/s] 21%|██████████▊                                        | 1579/7473 [00:09<00:33, 175.32it/s] 21%|██████████▉                                        | 1597/7473 [00:10<00:33, 175.41it/s] 22%|███████████                                        | 1615/7473 [00:10<00:33, 174.27it/s] 22%|███████████▏                                       | 1633/7473 [00:10<00:33, 174.77it/s] 22%|███████████▎                                       | 1651/7473 [00:10<00:33, 175.06it/s] 22%|███████████▍                                       | 1669/7473 [00:10<00:33, 175.73it/s] 23%|███████████▌                                       | 1687/7473 [00:10<00:32, 176.24it/s] 23%|███████████▋                                       | 1705/7473 [00:10<00:32, 175.90it/s] 23%|███████████▊                                       | 1723/7473 [00:10<00:32, 176.10it/s] 23%|███████████▉                                       | 1741/7473 [00:10<00:32, 176.05it/s] 24%|████████████                                       | 1759/7473 [00:10<00:32, 176.49it/s] 24%|████████████▏                                      | 1777/7473 [00:11<00:32, 176.26it/s] 24%|████████████▎                                      | 1795/7473 [00:11<00:32, 176.34it/s] 24%|████████████▎                                      | 1813/7473 [00:11<00:32, 176.28it/s] 25%|████████████▍                                      | 1831/7473 [00:11<00:32, 175.82it/s] 25%|████████████▌                                      | 1849/7473 [00:11<00:32, 174.41it/s] 25%|████████████▋                                      | 1867/7473 [00:11<00:31, 175.23it/s] 25%|████████████▊                                      | 1885/7473 [00:11<00:31, 175.70it/s] 25%|████████████▉                                      | 1903/7473 [00:11<00:31, 175.60it/s] 26%|█████████████                                      | 1921/7473 [00:11<00:31, 175.57it/s] 26%|█████████████▏                                     | 1939/7473 [00:11<00:31, 175.15it/s] 26%|█████████████▎                                     | 1957/7473 [00:12<00:31, 175.63it/s] 26%|█████████████▍                                     | 1975/7473 [00:12<00:31, 175.89it/s] 27%|█████████████▌                                     | 1993/7473 [00:12<00:31, 176.08it/s] 27%|█████████████▋                                     | 2011/7473 [00:12<00:30, 176.21it/s] 27%|█████████████▊                                     | 2029/7473 [00:12<00:30, 176.22it/s] 27%|█████████████▉                                     | 2047/7473 [00:12<00:30, 176.03it/s] 28%|██████████████                                     | 2065/7473 [00:12<00:30, 174.59it/s] 28%|██████████████▏                                    | 2083/7473 [00:12<00:30, 174.95it/s] 28%|██████████████▎                                    | 2101/7473 [00:12<00:30, 175.56it/s] 28%|██████████████▍                                    | 2119/7473 [00:12<00:30, 174.98it/s] 29%|██████████████▌                                    | 2137/7473 [00:13<00:30, 175.12it/s] 29%|██████████████▋                                    | 2155/7473 [00:13<00:30, 175.51it/s] 29%|██████████████▊                                    | 2173/7473 [00:13<00:30, 175.91it/s] 29%|██████████████▉                                    | 2191/7473 [00:13<00:30, 175.68it/s] 30%|███████████████                                    | 2209/7473 [00:13<00:29, 176.20it/s] 30%|███████████████▏                                   | 2227/7473 [00:13<00:29, 176.33it/s] 30%|███████████████▎                                   | 2245/7473 [00:13<00:29, 176.10it/s] 30%|███████████████▍                                   | 2263/7473 [00:13<00:29, 176.11it/s] 31%|███████████████▌                                   | 2281/7473 [00:13<00:29, 176.02it/s] 31%|███████████████▋                                   | 2299/7473 [00:14<00:29, 174.61it/s] 31%|███████████████▊                                   | 2317/7473 [00:14<00:29, 175.31it/s] 31%|███████████████▉                                   | 2335/7473 [00:14<00:29, 175.36it/s] 31%|████████████████                                   | 2353/7473 [00:14<00:29, 175.22it/s] 32%|████████████████▏                                  | 2371/7473 [00:14<00:29, 175.33it/s] 32%|████████████████▎                                  | 2389/7473 [00:14<00:28, 175.78it/s] 32%|████████████████▍                                  | 2407/7473 [00:14<00:28, 175.86it/s] 32%|████████████████▌                                  | 2425/7473 [00:14<00:28, 176.17it/s] 33%|████████████████▋                                  | 2443/7473 [00:14<00:28, 176.35it/s] 33%|████████████████▊                                  | 2461/7473 [00:14<00:28, 176.16it/s] 33%|████████████████▉                                  | 2479/7473 [00:15<00:28, 176.14it/s] 33%|█████████████████                                  | 2497/7473 [00:15<00:28, 176.07it/s] 34%|█████████████████▏                                 | 2515/7473 [00:15<00:28, 176.20it/s] 34%|█████████████████▎                                 | 2533/7473 [00:15<00:32, 152.26it/s] 34%|█████████████████▍                                 | 2551/7473 [00:15<00:31, 158.44it/s] 34%|█████████████████▌                                 | 2569/7473 [00:15<00:29, 163.51it/s] 35%|█████████████████▋                                 | 2587/7473 [00:15<00:29, 167.23it/s] 35%|█████████████████▊                                 | 2605/7473 [00:15<00:28, 170.22it/s] 35%|█████████████████▉                                 | 2623/7473 [00:15<00:28, 172.14it/s] 35%|██████████████████                                 | 2641/7473 [00:15<00:27, 173.34it/s] 36%|██████████████████▏                                | 2659/7473 [00:16<00:27, 174.24it/s] 36%|██████████████████▎                                | 2677/7473 [00:16<00:27, 174.82it/s] 36%|██████████████████▍                                | 2695/7473 [00:16<00:27, 174.99it/s] 36%|██████████████████▌                                | 2713/7473 [00:16<00:27, 175.57it/s] 37%|██████████████████▋                                | 2731/7473 [00:16<00:27, 175.58it/s] 37%|██████████████████▊                                | 2749/7473 [00:16<00:27, 174.10it/s] 37%|██████████████████▉                                | 2767/7473 [00:16<00:27, 174.24it/s] 37%|███████████████████                                | 2785/7473 [00:16<00:26, 175.13it/s] 38%|███████████████████▏                               | 2803/7473 [00:16<00:26, 175.56it/s] 38%|███████████████████▎                               | 2821/7473 [00:17<00:26, 175.73it/s] 38%|███████████████████▎                               | 2839/7473 [00:17<00:26, 176.25it/s] 38%|███████████████████▍                               | 2857/7473 [00:17<00:26, 175.89it/s] 38%|███████████████████▌                               | 2875/7473 [00:17<00:26, 175.58it/s] 39%|███████████████████▋                               | 2893/7473 [00:17<00:26, 175.74it/s] 39%|███████████████████▊                               | 2911/7473 [00:17<00:25, 175.91it/s] 39%|███████████████████▉                               | 2929/7473 [00:17<00:25, 176.15it/s] 39%|████████████████████                               | 2947/7473 [00:17<00:25, 176.31it/s] 40%|████████████████████▏                              | 2965/7473 [00:17<00:25, 176.13it/s] 40%|████████████████████▎                              | 2983/7473 [00:17<00:25, 174.21it/s] 40%|████████████████████▍                              | 3001/7473 [00:18<00:25, 173.44it/s] 40%|████████████████████▌                              | 3019/7473 [00:18<00:25, 173.99it/s] 41%|████████████████████▋                              | 3037/7473 [00:18<00:25, 174.31it/s] 41%|████████████████████▊                              | 3055/7473 [00:18<00:25, 174.82it/s] 41%|████████████████████▉                              | 3073/7473 [00:18<00:25, 174.78it/s] 41%|█████████████████████                              | 3091/7473 [00:18<00:25, 174.88it/s] 42%|█████████████████████▏                             | 3109/7473 [00:18<00:24, 174.90it/s] 42%|█████████████████████▎                             | 3127/7473 [00:18<00:24, 174.68it/s] 42%|█████████████████████▍                             | 3145/7473 [00:18<00:24, 174.59it/s] 42%|█████████████████████▌                             | 3163/7473 [00:18<00:24, 174.87it/s] 43%|█████████████████████▋                             | 3181/7473 [00:19<00:24, 174.71it/s] 43%|█████████████████████▊                             | 3199/7473 [00:19<00:24, 174.87it/s] 43%|█████████████████████▉                             | 3217/7473 [00:19<00:24, 173.46it/s] 43%|██████████████████████                             | 3235/7473 [00:19<00:24, 174.09it/s] 44%|██████████████████████▏                            | 3253/7473 [00:19<00:24, 174.72it/s] 44%|██████████████████████▎                            | 3271/7473 [00:19<00:24, 174.79it/s] 44%|██████████████████████▍                            | 3289/7473 [00:19<00:24, 173.95it/s] 44%|██████████████████████▌                            | 3307/7473 [00:19<00:23, 174.34it/s] 44%|██████████████████████▋                            | 3325/7473 [00:19<00:23, 174.32it/s] 45%|██████████████████████▊                            | 3343/7473 [00:20<00:23, 174.37it/s] 45%|██████████████████████▉                            | 3361/7473 [00:20<00:23, 174.55it/s] 45%|███████████████████████                            | 3379/7473 [00:20<00:23, 174.52it/s] 45%|███████████████████████▏                           | 3397/7473 [00:20<00:23, 174.77it/s] 46%|███████████████████████▎                           | 3415/7473 [00:20<00:23, 174.82it/s] 46%|███████████████████████▍                           | 3433/7473 [00:20<00:23, 173.39it/s] 46%|███████████████████████▌                           | 3451/7473 [00:20<00:23, 173.82it/s] 46%|███████████████████████▋                           | 3469/7473 [00:20<00:23, 173.87it/s] 47%|███████████████████████▊                           | 3487/7473 [00:20<00:22, 174.37it/s] 47%|███████████████████████▉                           | 3505/7473 [00:20<00:22, 174.79it/s] 47%|████████████████████████                           | 3523/7473 [00:21<00:22, 174.81it/s] 47%|████████████████████████▏                          | 3541/7473 [00:21<00:22, 175.08it/s] 48%|████████████████████████▎                          | 3559/7473 [00:21<00:22, 175.15it/s] 48%|████████████████████████▍                          | 3577/7473 [00:21<00:22, 175.14it/s] 48%|████████████████████████▌                          | 3595/7473 [00:21<00:22, 174.18it/s] 48%|████████████████████████▋                          | 3613/7473 [00:21<00:22, 174.39it/s] 49%|████████████████████████▊                          | 3631/7473 [00:21<00:22, 174.62it/s] 49%|████████████████████████▉                          | 3649/7473 [00:21<00:21, 174.27it/s] 49%|█████████████████████████                          | 3667/7473 [00:21<00:21, 173.06it/s] 49%|█████████████████████████▏                         | 3685/7473 [00:21<00:21, 173.35it/s] 50%|█████████████████████████▎                         | 3703/7473 [00:22<00:21, 173.79it/s] 50%|█████████████████████████▍                         | 3721/7473 [00:22<00:21, 173.86it/s] 50%|█████████████████████████▌                         | 3739/7473 [00:22<00:21, 174.24it/s] 50%|█████████████████████████▋                         | 3757/7473 [00:22<00:21, 174.45it/s] 51%|█████████████████████████▊                         | 3775/7473 [00:22<00:21, 174.45it/s] 51%|█████████████████████████▉                         | 3793/7473 [00:22<00:21, 174.60it/s] 51%|██████████████████████████                         | 3811/7473 [00:22<00:20, 175.09it/s] 51%|██████████████████████████▏                        | 3829/7473 [00:22<00:20, 174.86it/s] 51%|██████████████████████████▎                        | 3847/7473 [00:22<00:20, 174.86it/s] 52%|██████████████████████████▍                        | 3865/7473 [00:22<00:20, 174.92it/s] 52%|██████████████████████████▍                        | 3883/7473 [00:23<00:21, 170.27it/s] 52%|██████████████████████████▌                        | 3901/7473 [00:23<00:20, 171.89it/s] 52%|██████████████████████████▋                        | 3919/7473 [00:23<00:20, 172.81it/s] 53%|██████████████████████████▊                        | 3937/7473 [00:23<00:20, 173.56it/s] 53%|██████████████████████████▉                        | 3955/7473 [00:23<00:20, 174.04it/s] 53%|███████████████████████████                        | 3973/7473 [00:23<00:20, 174.28it/s] 53%|███████████████████████████▏                       | 3991/7473 [00:23<00:19, 174.47it/s] 54%|███████████████████████████▎                       | 4009/7473 [00:23<00:19, 174.75it/s] 54%|███████████████████████████▍                       | 4027/7473 [00:23<00:19, 174.97it/s] 54%|███████████████████████████▌                       | 4045/7473 [00:24<00:19, 175.02it/s] 54%|███████████████████████████▋                       | 4063/7473 [00:24<00:19, 175.05it/s] 55%|███████████████████████████▊                       | 4081/7473 [00:24<00:19, 174.88it/s] 55%|███████████████████████████▉                       | 4099/7473 [00:24<00:19, 174.89it/s] 55%|████████████████████████████                       | 4117/7473 [00:24<00:19, 173.12it/s] 55%|████████████████████████████▏                      | 4135/7473 [00:24<00:19, 173.26it/s] 56%|████████████████████████████▎                      | 4153/7473 [00:24<00:19, 173.61it/s] 56%|████████████████████████████▍                      | 4171/7473 [00:24<00:18, 174.13it/s] 56%|████████████████████████████▌                      | 4189/7473 [00:24<00:19, 172.44it/s] 56%|████████████████████████████▋                      | 4207/7473 [00:24<00:18, 173.16it/s] 57%|████████████████████████████▊                      | 4225/7473 [00:25<00:18, 173.96it/s] 57%|████████████████████████████▉                      | 4243/7473 [00:25<00:18, 174.28it/s] 57%|█████████████████████████████                      | 4261/7473 [00:25<00:18, 174.52it/s] 57%|█████████████████████████████▏                     | 4279/7473 [00:25<00:18, 174.35it/s] 58%|█████████████████████████████▎                     | 4297/7473 [00:25<00:18, 174.41it/s] 58%|█████████████████████████████▍                     | 4315/7473 [00:25<00:18, 174.64it/s] 58%|█████████████████████████████▌                     | 4333/7473 [00:25<00:17, 174.98it/s] 58%|█████████████████████████████▋                     | 4351/7473 [00:25<00:17, 173.67it/s] 58%|█████████████████████████████▊                     | 4369/7473 [00:25<00:17, 174.03it/s] 59%|█████████████████████████████▉                     | 4387/7473 [00:26<00:17, 174.08it/s] 59%|██████████████████████████████                     | 4405/7473 [00:26<00:17, 174.41it/s] 59%|██████████████████████████████▏                    | 4423/7473 [00:26<00:17, 174.46it/s] 59%|██████████████████████████████▎                    | 4441/7473 [00:26<00:17, 174.62it/s] 60%|██████████████████████████████▍                    | 4459/7473 [00:26<00:17, 174.62it/s] 60%|██████████████████████████████▌                    | 4477/7473 [00:26<00:17, 175.00it/s] 60%|██████████████████████████████▋                    | 4495/7473 [00:26<00:17, 174.83it/s] 60%|██████████████████████████████▊                    | 4513/7473 [00:26<00:16, 174.72it/s] 61%|██████████████████████████████▉                    | 4531/7473 [00:26<00:16, 174.78it/s] 61%|███████████████████████████████                    | 4549/7473 [00:26<00:16, 175.18it/s] 61%|███████████████████████████████▏                   | 4567/7473 [00:27<00:16, 174.06it/s] 61%|███████████████████████████████▎                   | 4585/7473 [00:27<00:16, 173.74it/s] 62%|███████████████████████████████▍                   | 4603/7473 [00:27<00:16, 174.19it/s] 62%|███████████████████████████████▌                   | 4621/7473 [00:27<00:16, 174.53it/s] 62%|███████████████████████████████▋                   | 4639/7473 [00:27<00:16, 174.46it/s] 62%|███████████████████████████████▊                   | 4657/7473 [00:27<00:16, 174.70it/s] 63%|███████████████████████████████▉                   | 4675/7473 [00:27<00:16, 174.63it/s] 63%|████████████████████████████████                   | 4693/7473 [00:27<00:15, 174.85it/s] 63%|████████████████████████████████▏                  | 4711/7473 [00:27<00:15, 174.97it/s] 63%|████████████████████████████████▎                  | 4729/7473 [00:27<00:15, 175.24it/s] 64%|████████████████████████████████▍                  | 4747/7473 [00:28<00:15, 175.27it/s] 64%|████████████████████████████████▌                  | 4765/7473 [00:28<00:15, 175.46it/s] 64%|████████████████████████████████▋                  | 4783/7473 [00:28<00:15, 175.36it/s] 64%|████████████████████████████████▊                  | 4801/7473 [00:28<00:15, 173.49it/s] 64%|████████████████████████████████▉                  | 4819/7473 [00:28<00:15, 174.16it/s] 65%|█████████████████████████████████                  | 4837/7473 [00:28<00:15, 173.91it/s] 65%|█████████████████████████████████▏                 | 4855/7473 [00:28<00:15, 174.10it/s] 65%|█████████████████████████████████▎                 | 4873/7473 [00:28<00:14, 174.16it/s] 65%|█████████████████████████████████▍                 | 4891/7473 [00:28<00:14, 174.58it/s] 66%|█████████████████████████████████▌                 | 4909/7473 [00:28<00:14, 174.92it/s] 66%|█████████████████████████████████▌                 | 4927/7473 [00:29<00:14, 174.85it/s] 66%|█████████████████████████████████▋                 | 4945/7473 [00:29<00:14, 174.95it/s] 66%|█████████████████████████████████▊                 | 4963/7473 [00:29<00:14, 175.09it/s] 67%|█████████████████████████████████▉                 | 4981/7473 [00:29<00:14, 174.96it/s] 67%|██████████████████████████████████                 | 4999/7473 [00:29<00:14, 174.82it/s] 67%|██████████████████████████████████▏                | 5017/7473 [00:29<00:14, 173.67it/s] 67%|██████████████████████████████████▎                | 5035/7473 [00:29<00:14, 174.05it/s] 68%|██████████████████████████████████▍                | 5053/7473 [00:29<00:13, 174.41it/s] 68%|██████████████████████████████████▌                | 5071/7473 [00:29<00:13, 174.52it/s] 68%|██████████████████████████████████▋                | 5089/7473 [00:30<00:13, 174.72it/s] 68%|██████████████████████████████████▊                | 5107/7473 [00:30<00:13, 174.92it/s] 69%|██████████████████████████████████▉                | 5125/7473 [00:30<00:13, 175.01it/s] 69%|███████████████████████████████████                | 5143/7473 [00:30<00:13, 175.19it/s] 69%|███████████████████████████████████▏               | 5161/7473 [00:30<00:13, 175.63it/s] 69%|███████████████████████████████████▎               | 5179/7473 [00:30<00:13, 175.77it/s] 70%|███████████████████████████████████▍               | 5197/7473 [00:30<00:12, 175.30it/s] 70%|███████████████████████████████████▌               | 5215/7473 [00:30<00:12, 175.43it/s] 70%|███████████████████████████████████▋               | 5233/7473 [00:30<00:12, 175.62it/s] 70%|███████████████████████████████████▊               | 5251/7473 [00:30<00:14, 151.59it/s] 71%|███████████████████████████████████▉               | 5269/7473 [00:31<00:13, 157.92it/s] 71%|████████████████████████████████████               | 5287/7473 [00:31<00:13, 162.84it/s] 71%|████████████████████████████████████▏              | 5305/7473 [00:31<00:13, 166.42it/s] 71%|████████████████████████████████████▎              | 5323/7473 [00:31<00:12, 168.97it/s] 71%|████████████████████████████████████▍              | 5341/7473 [00:31<00:12, 170.79it/s] 72%|████████████████████████████████████▌              | 5359/7473 [00:31<00:12, 172.10it/s] 72%|████████████████████████████████████▋              | 5377/7473 [00:31<00:12, 172.91it/s] 72%|████████████████████████████████████▊              | 5395/7473 [00:31<00:11, 173.79it/s] 72%|████████████████████████████████████▉              | 5413/7473 [00:31<00:11, 174.34it/s] 73%|█████████████████████████████████████              | 5431/7473 [00:32<00:11, 174.70it/s] 73%|█████████████████████████████████████▏             | 5449/7473 [00:32<00:11, 174.83it/s] 73%|█████████████████████████████████████▎             | 5467/7473 [00:32<00:11, 174.62it/s] 73%|█████████████████████████████████████▍             | 5485/7473 [00:32<00:17, 110.84it/s] 74%|█████████████████████████████████████▌             | 5503/7473 [00:32<00:15, 124.42it/s] 74%|█████████████████████████████████████▋             | 5521/7473 [00:32<00:14, 136.52it/s] 74%|█████████████████████████████████████▊             | 5539/7473 [00:32<00:13, 146.09it/s] 74%|█████████████████████████████████████▉             | 5557/7473 [00:32<00:12, 153.99it/s] 75%|██████████████████████████████████████             | 5575/7473 [00:33<00:11, 159.72it/s] 75%|██████████████████████████████████████▏            | 5593/7473 [00:33<00:11, 164.12it/s] 75%|██████████████████████████████████████▎            | 5611/7473 [00:33<00:11, 167.29it/s] 75%|██████████████████████████████████████▍            | 5629/7473 [00:33<00:10, 169.50it/s] 76%|██████████████████████████████████████▌            | 5647/7473 [00:33<00:10, 171.30it/s] 76%|██████████████████████████████████████▋            | 5665/7473 [00:33<00:10, 172.64it/s] 76%|██████████████████████████████████████▊            | 5683/7473 [00:33<00:10, 172.00it/s] 76%|██████████████████████████████████████▉            | 5701/7473 [00:33<00:10, 173.04it/s] 77%|███████████████████████████████████████            | 5719/7473 [00:33<00:10, 173.64it/s] 77%|███████████████████████████████████████▏           | 5737/7473 [00:33<00:09, 174.12it/s] 77%|███████████████████████████████████████▎           | 5755/7473 [00:34<00:09, 174.44it/s] 77%|███████████████████████████████████████▍           | 5773/7473 [00:34<00:09, 175.13it/s] 77%|███████████████████████████████████████▌           | 5791/7473 [00:34<00:09, 174.97it/s] 78%|███████████████████████████████████████▋           | 5809/7473 [00:34<00:09, 174.97it/s] 78%|███████████████████████████████████████▊           | 5827/7473 [00:34<00:09, 175.17it/s] 78%|███████████████████████████████████████▉           | 5845/7473 [00:34<00:09, 175.10it/s] 78%|████████████████████████████████████████           | 5863/7473 [00:34<00:09, 174.71it/s] 79%|████████████████████████████████████████▏          | 5881/7473 [00:34<00:09, 174.99it/s] 79%|████████████████████████████████████████▎          | 5899/7473 [00:34<00:09, 174.84it/s] 79%|████████████████████████████████████████▍          | 5917/7473 [00:35<00:09, 168.32it/s] 79%|████████████████████████████████████████▌          | 5935/7473 [00:35<00:09, 170.03it/s] 80%|████████████████████████████████████████▋          | 5953/7473 [00:35<00:08, 171.09it/s] 80%|████████████████████████████████████████▋          | 5971/7473 [00:35<00:08, 172.05it/s] 80%|████████████████████████████████████████▊          | 5989/7473 [00:35<00:08, 173.17it/s] 80%|████████████████████████████████████████▉          | 6007/7473 [00:35<00:08, 173.83it/s] 81%|█████████████████████████████████████████          | 6025/7473 [00:35<00:08, 173.97it/s] 81%|█████████████████████████████████████████▏         | 6043/7473 [00:35<00:08, 174.45it/s] 81%|█████████████████████████████████████████▎         | 6061/7473 [00:35<00:08, 175.08it/s] 81%|█████████████████████████████████████████▍         | 6079/7473 [00:35<00:07, 175.20it/s] 82%|█████████████████████████████████████████▌         | 6097/7473 [00:36<00:07, 175.50it/s] 82%|█████████████████████████████████████████▋         | 6115/7473 [00:36<00:07, 175.61it/s] 82%|█████████████████████████████████████████▊         | 6133/7473 [00:36<00:07, 173.75it/s] 82%|█████████████████████████████████████████▉         | 6151/7473 [00:36<00:07, 174.30it/s] 83%|██████████████████████████████████████████         | 6169/7473 [00:36<00:07, 174.69it/s] 83%|██████████████████████████████████████████▏        | 6187/7473 [00:36<00:07, 174.90it/s] 83%|██████████████████████████████████████████▎        | 6205/7473 [00:36<00:07, 175.05it/s] 83%|██████████████████████████████████████████▍        | 6223/7473 [00:36<00:07, 174.88it/s] 84%|██████████████████████████████████████████▌        | 6241/7473 [00:36<00:07, 174.61it/s] 84%|██████████████████████████████████████████▋        | 6259/7473 [00:36<00:06, 174.65it/s] 84%|██████████████████████████████████████████▊        | 6277/7473 [00:37<00:06, 175.25it/s] 84%|██████████████████████████████████████████▉        | 6295/7473 [00:37<00:06, 174.90it/s] 84%|███████████████████████████████████████████        | 6313/7473 [00:37<00:06, 175.34it/s] 85%|███████████████████████████████████████████▏       | 6331/7473 [00:37<00:06, 175.71it/s] 85%|███████████████████████████████████████████▎       | 6349/7473 [00:37<00:06, 175.50it/s] 85%|███████████████████████████████████████████▍       | 6367/7473 [00:37<00:06, 173.82it/s] 85%|███████████████████████████████████████████▌       | 6385/7473 [00:37<00:06, 173.98it/s] 86%|███████████████████████████████████████████▋       | 6403/7473 [00:37<00:06, 174.40it/s] 86%|███████████████████████████████████████████▊       | 6421/7473 [00:37<00:06, 174.35it/s] 86%|███████████████████████████████████████████▉       | 6439/7473 [00:37<00:05, 174.68it/s] 86%|████████████████████████████████████████████       | 6457/7473 [00:38<00:05, 174.73it/s] 87%|████████████████████████████████████████████▏      | 6475/7473 [00:38<00:05, 174.98it/s] 87%|████████████████████████████████████████████▎      | 6493/7473 [00:38<00:05, 174.92it/s] 87%|████████████████████████████████████████████▍      | 6511/7473 [00:38<00:05, 174.94it/s] 87%|████████████████████████████████████████████▌      | 6529/7473 [00:38<00:05, 175.14it/s] 88%|████████████████████████████████████████████▋      | 6547/7473 [00:38<00:05, 175.16it/s] 88%|████████████████████████████████████████████▊      | 6565/7473 [00:38<00:05, 175.09it/s] 88%|████████████████████████████████████████████▉      | 6583/7473 [00:38<00:05, 173.47it/s] 88%|█████████████████████████████████████████████      | 6601/7473 [00:38<00:05, 174.26it/s] 89%|█████████████████████████████████████████████▏     | 6619/7473 [00:39<00:04, 174.42it/s] 89%|█████████████████████████████████████████████▎     | 6637/7473 [00:39<00:04, 174.26it/s] 89%|█████████████████████████████████████████████▍     | 6655/7473 [00:39<00:04, 174.49it/s] 89%|█████████████████████████████████████████████▌     | 6673/7473 [00:39<00:04, 174.43it/s] 90%|█████████████████████████████████████████████▋     | 6691/7473 [00:39<00:04, 174.69it/s] 90%|█████████████████████████████████████████████▊     | 6709/7473 [00:39<00:04, 174.95it/s] 90%|█████████████████████████████████████████████▉     | 6727/7473 [00:39<00:04, 175.09it/s] 90%|██████████████████████████████████████████████     | 6745/7473 [00:39<00:04, 175.14it/s] 90%|██████████████████████████████████████████████▏    | 6763/7473 [00:39<00:04, 174.80it/s] 91%|██████████████████████████████████████████████▎    | 6781/7473 [00:39<00:03, 174.89it/s] 91%|██████████████████████████████████████████████▍    | 6799/7473 [00:40<00:03, 174.81it/s] 91%|██████████████████████████████████████████████▌    | 6817/7473 [00:40<00:03, 173.26it/s] 91%|██████████████████████████████████████████████▋    | 6835/7473 [00:40<00:03, 173.85it/s] 92%|██████████████████████████████████████████████▊    | 6853/7473 [00:40<00:03, 174.25it/s] 92%|██████████████████████████████████████████████▉    | 6871/7473 [00:40<00:03, 174.34it/s] 92%|███████████████████████████████████████████████    | 6889/7473 [00:40<00:03, 174.59it/s] 92%|███████████████████████████████████████████████▏   | 6907/7473 [00:40<00:03, 175.09it/s] 93%|███████████████████████████████████████████████▎   | 6925/7473 [00:40<00:03, 174.72it/s] 93%|███████████████████████████████████████████████▍   | 6943/7473 [00:40<00:03, 175.08it/s] 93%|███████████████████████████████████████████████▌   | 6961/7473 [00:40<00:02, 174.95it/s] 93%|███████████████████████████████████████████████▋   | 6979/7473 [00:41<00:02, 175.02it/s] 94%|███████████████████████████████████████████████▊   | 6997/7473 [00:41<00:02, 174.82it/s] 94%|███████████████████████████████████████████████▊   | 7015/7473 [00:41<00:02, 174.70it/s] 94%|███████████████████████████████████████████████▉   | 7033/7473 [00:41<00:02, 174.74it/s] 94%|████████████████████████████████████████████████   | 7051/7473 [00:41<00:02, 173.11it/s] 95%|████████████████████████████████████████████████▏  | 7069/7473 [00:41<00:02, 173.63it/s] 95%|████████████████████████████████████████████████▎  | 7087/7473 [00:41<00:02, 173.99it/s] 95%|████████████████████████████████████████████████▍  | 7105/7473 [00:41<00:02, 174.33it/s] 95%|████████████████████████████████████████████████▌  | 7123/7473 [00:41<00:02, 174.25it/s] 96%|████████████████████████████████████████████████▋  | 7141/7473 [00:42<00:01, 174.08it/s] 96%|████████████████████████████████████████████████▊  | 7159/7473 [00:42<00:01, 174.27it/s] 96%|████████████████████████████████████████████████▉  | 7177/7473 [00:42<00:01, 174.38it/s] 96%|█████████████████████████████████████████████████  | 7195/7473 [00:42<00:01, 174.69it/s] 97%|█████████████████████████████████████████████████▏ | 7213/7473 [00:42<00:01, 174.81it/s] 97%|█████████████████████████████████████████████████▎ | 7231/7473 [00:42<00:01, 174.99it/s] 97%|█████████████████████████████████████████████████▍ | 7249/7473 [00:42<00:01, 174.91it/s] 97%|█████████████████████████████████████████████████▌ | 7267/7473 [00:42<00:01, 173.32it/s] 97%|█████████████████████████████████████████████████▋ | 7285/7473 [00:42<00:01, 172.95it/s] 98%|█████████████████████████████████████████████████▊ | 7303/7473 [00:42<00:00, 173.67it/s] 98%|█████████████████████████████████████████████████▉ | 7321/7473 [00:43<00:00, 174.22it/s] 98%|██████████████████████████████████████████████████ | 7339/7473 [00:43<00:00, 174.08it/s] 98%|██████████████████████████████████████████████████▏| 7357/7473 [00:43<00:00, 174.09it/s] 99%|██████████████████████████████████████████████████▎| 7375/7473 [00:43<00:00, 173.94it/s] 99%|██████████████████████████████████████████████████▍| 7393/7473 [00:43<00:00, 174.51it/s] 99%|██████████████████████████████████████████████████▌| 7411/7473 [00:43<00:00, 174.63it/s] 99%|██████████████████████████████████████████████████▋| 7429/7473 [00:43<00:00, 175.03it/s]100%|██████████████████████████████████████████████████▊| 7447/7473 [00:43<00:00, 174.72it/s]100%|██████████████████████████████████████████████████▉| 7465/7473 [00:43<00:00, 174.57it/s]100%|███████████████████████████████████████████████████| 7473/7473 [00:43<00:00, 170.12it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.26s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.13s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.38s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.49s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.05s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.02s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.28s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.36s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.45s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.63s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.44s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.61s/it]
[2023-08-12 18:04:55,201] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.65s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.83s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.73s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.92s/it]
[2023-08-12 18:05:06,181] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 18:05:06,182] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 18:05:06,182] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 18:05:06,182] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 18:05:06,182] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 18:05:06,182] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f214c707fa0>
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f214c727700>
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 18:05:06,184] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.6731688976287842 seconds
Loading extension module utils...
Time to load utils op: 0.7050418853759766 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Loading extension module utils...
Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]Time to load utils op: 0.6054830551147461 seconds
############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Rationales: 1. The question asks where you would find plumbing that would not be useful if you were thirsty.
2. The key here is to understand the connection between "plumbing" and "thirsty".
3. You would typically use plumbing to access water, particularly clean drinkable water when you're thirsty.
4. Therefore, we can assume that we're looking for a choice where the plumbing does not supply water, or at least not drinkable water.
5. Looking at the choices, "oil refineries", "wall", "show", "own home", and "water fountain", we need to determine which of these would not supply drinkable water from their plumbing. 
6. Walls and shows wouldn't have plumbing itself, but your own home and a water fountain would typically have plumbing that supplies drinkable water.
7. An oil refinery, however, is a place where the plumbing system is used to transport oil, not water.
8. Therefore, you can't drink anything from the plumbing of an oil refinery, hence it would not be of use if you were thirsty.
9. Thus, the answer is A: oil refineries.
Answer: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Rationales: Intermediate Reasoning Steps:

1. The question asks about the activity that a person is not engaging in yet when they are beginning work.
2. It cannot be A: working. Since the person is beginning work, they are actually performing this activity.
3. It cannot be B: resting. Resting indicates a period of inactivity or relaxation, which is different from beginning work.
4. It cannot be C: tiredness. This is an emotional state, not an action. Besides, someone can feel tired either before starting work, during work or after work. So, this does not relate directly to the action of starting work.
5. It cannot be E: momentum. Momentum generally refers to the force or speed of movement. Although starting work can involve gaining momentum, the term does not directly refer to an action that a person could be engaging in or not.
6. Therefore, the only option left is D: accomplishing. When a person is beginning work, they have not accomplished anything related to that work yet. They are only embarking on the task at hand but they have not yet achieved any results. Thus, they aren't accomplishing anything yet at the very moment they begin to work.
Answer: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Rationales: 1. First, the question asks about a pen with a company logo.
2. This usually indicates a pen that is customized with some business branding.
3. While you may find pens in a few of the given choices like a school or backpack, the pens are typically not company-branded.
4. The most common place to find company-branded pens is in an office setting, as companies often provide custom pens for their employees or for promotional purposes.
5. Therefore, the answer should be the option that corresponds with an office setting, which in these choices, is option A: office.
Answer: A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Rationales: 1. The question talks about Billy calling out to John. 
2. Calling out to someone typically indicates a desire to communicate, or the initiation of a conversation.
3. For communication to work, it usually requires some kind of reaction or response from the other party.
4. So Billy, having initiated the conversation, would be waiting for a reaction or a reply from John.
5. Thus, the correct option is that Billy listened for a response (option B).
Answer: B: response

Input: The lizard frightened the hiker, it's movements made what rustle? Choices:  A: garden B: trees C: books D: rocks E: bushes
Rationales: 1. The question is asking what the lizard's movements made rustle. 
2. 'Rustle' refers to a soft, muffled crackling sound like that made by the movement of dry leaves or paper. 
3. Now, among the given options, we need to choose a noun that is more likely to produce a rustling sound when disturbed by a lizard. 
4. A lizard in a garden can't 'rustle' the entire garden, as there are open spaces and not all parts of a garden would make a rustle noise. So we eliminate option A. 
5. Moving to option B, trees, it's unlikely. Lizards are not typically large or strong enough to rustle trees. Hence, we can eliminate option B.
6. Lizards don't interact with books, so, option C can be eliminated.
7. Rocks can't 'rustle', hence we can eliminate option D.
8. Among the remaining options, bushes are likely to make a rustling sound when a lizard scurries through them. This makes sense since most lizards live in or around bushes in the wild.
9. Therefore, E: bushes is the most appropriate answer.
Answer: E: bushes

Input: The man spent big money and time maintaining his lawn, it was part of keeping up with the Joneses where? Choices:  A: front yard B: suburbia C: neighborhood D: back yard E: golf course
Rationales: 1. The question is asking where the man is keeping up with the Joneses by spending big money and time maintaining his lawn.
2. The phrase "keeping up with the Joneses" typically refers to trying to match or surpass the lifestyle or perceived wealth of neighbors or peers, suggesting that the man is doing this in a residential setting. 
3. The given options are: front yard, suburbia, neighborhood, back yard, and golf course.
4. The options front yard and back yard refer to specific portions of a piece of property and not a broader residential setting.
5. The option golf course could suggest a scenario where a man is maintaining his lawn to match a golf course standard, but this does not match the idea of personally keeping up with neighbors or peers.
6. The options suburbia and neighborhood both suggest a residential setting where the phenomenon of "keeping up with the joneses" commonly occurs. 
7. Yet, the term suburbia not only refers to a residential area, but also carries a cultural connotation of a place where people strive to maintain a certain image of wealth or status, which aligns better with the phrase "keeping up with the Joneses".
8. Therefore, the answer is B: suburbia.
Answer: B: suburbia

Input: What would a human do if they want to get to a store that he or she can see? Choices:  A: cross road B: see around C: drink coffee D: dream dreams E: think critically
Rationales: 1. The question asks what a human would need to do to reach a store they can see.
2. This implies there is some physical distance between the human and the store.
3. Therefore, they would need to perform some action that helps them cover that distance.
4. Looking at the available choices, "drinking coffee," "dreaming dreams," and "thinking critically" do not directly contribute to physical movement.
5. "Seeing around" would be beneficial in observing the environment but it doesn't ensure movement towards the store.
6. Therefore, the only option that involves some form of movement and could physically bring a person closer to the store is "cross the road".
7. So, the answer to the question is A: cross road.
Answer: A: cross road

Input: Where would you grab an object contained by a doorway? Choices:  A: television B: control panel C: opening doors D: doorknob E: doorway
Rationales: 1. To start solving this, we need to understand the question. It's asking where we would grab an object that is contained by a doorway.
2. We can first eliminate option A: television, as it is an
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o8-tcommonsenseqa-s1-rTrue
Loading extension module utils...
Time to load utils op: 0.7050132751464844 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:42<34:35, 42.36s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:23<33:28, 41.85s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:05<32:37, 41.65s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [02:46<31:52, 41.58s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [03:28<31:07, 41.50s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [04:09<30:26, 41.50s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [04:51<29:43, 41.47s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [05:32<29:03, 41.51s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [06:14<28:22, 41.52s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [06:55<27:39, 41.49s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [07:37<26:58, 41.50s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [08:18<26:16, 41.49s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [09:00<25:35, 41.50s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [09:41<24:54, 41.51s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [10:22<24:10, 41.44s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [11:04<23:29, 41.46s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [11:45<22:47, 41.44s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [12:27<22:06, 41.46s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [13:08<21:24, 41.44s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [13:50<20:42, 41.42s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [14:31<20:01, 41.43s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [15:13<19:21, 41.47s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [15:54<18:40, 41.48s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [16:35<17:57, 41.43s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [17:17<17:15, 41.41s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [17:59<16:36, 41.52s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [18:41<15:57, 41.65s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [19:22<15:14, 41.55s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [20:03<14:30, 41.47s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [20:44<13:47, 41.38s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [21:26<13:06, 41.40s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [22:07<12:24, 41.36s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [22:48<11:43, 41.40s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [23:30<11:02, 41.40s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [24:11<10:20, 41.35s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [24:52<09:38, 41.35s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [25:34<08:57, 41.35s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [26:15<08:15, 41.33s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [26:57<07:35, 41.38s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [27:38<06:53, 41.35s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [28:19<06:11, 41.32s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [29:01<05:30, 41.35s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [29:42<04:49, 41.33s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [30:23<04:08, 41.36s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [31:05<03:26, 41.39s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [31:46<02:45, 41.36s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [32:27<02:04, 41.38s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [33:09<01:22, 41.39s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [33:50<00:41, 41.36s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [34:31<00:00, 41.35s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [34:31<00:00, 41.44s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.108} | lm_loss 12.6521 | avg. gen lenth: 474.912
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o9-tcommonsenseqa-s1-rTrue --seed 1 --rationales --num-out-domain 9
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-12 18:39:48,341] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o9-tcommonsenseqa-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 9
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o9-tcommonsenseqa-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  0%|                                                       | 9/7473 [00:00<01:30, 82.52it/s]  0%|▏                                                     | 18/7473 [00:00<01:29, 82.98it/s]  0%|▏                                                     | 27/7473 [00:00<01:29, 82.95it/s]  0%|▎                                                     | 36/7473 [00:00<01:29, 83.02it/s]  1%|▎                                                     | 45/7473 [00:00<01:30, 81.73it/s]  1%|▍                                                     | 54/7473 [00:00<01:30, 82.27it/s]  1%|▍                                                     | 63/7473 [00:00<01:29, 82.37it/s]  1%|▌                                                     | 72/7473 [00:00<01:29, 82.67it/s]  1%|▌                                                     | 81/7473 [00:00<01:29, 82.85it/s]  1%|▋                                                     | 90/7473 [00:01<01:29, 82.85it/s]  1%|▋                                                     | 99/7473 [00:01<01:28, 82.90it/s]  1%|▊                                                    | 108/7473 [00:01<01:28, 82.77it/s]  2%|▊                                                    | 117/7473 [00:01<01:28, 82.87it/s]  2%|▉                                                    | 126/7473 [00:01<01:28, 82.92it/s]  2%|▉                                                    | 135/7473 [00:01<01:29, 81.68it/s]  2%|█                                                    | 144/7473 [00:01<01:28, 82.60it/s]  2%|█                                                    | 157/7473 [00:01<01:16, 95.43it/s]  2%|█▏                                                  | 170/7473 [00:01<01:09, 104.63it/s]  2%|█▎                                                  | 183/7473 [00:02<01:05, 111.30it/s]  3%|█▎                                                  | 196/7473 [00:02<01:02, 115.95it/s]  3%|█▍                                                  | 209/7473 [00:02<01:00, 119.44it/s]  3%|█▌                                                  | 222/7473 [00:02<00:59, 121.78it/s]  3%|█▋                                                  | 235/7473 [00:02<00:58, 123.26it/s]  3%|█▋                                                  | 248/7473 [00:02<00:58, 124.08it/s]  3%|█▊                                                  | 261/7473 [00:02<00:58, 122.65it/s]  4%|█▉                                                  | 274/7473 [00:02<00:58, 123.99it/s]  4%|█▉                                                  | 287/7473 [00:02<00:57, 125.00it/s]  4%|██                                                  | 300/7473 [00:02<00:57, 125.58it/s]  4%|██▏                                                 | 313/7473 [00:03<00:56, 126.05it/s]  4%|██▎                                                 | 326/7473 [00:03<00:56, 126.50it/s]  5%|██▎                                                 | 339/7473 [00:03<00:56, 126.40it/s]  5%|██▍                                                 | 352/7473 [00:03<00:56, 126.83it/s]  5%|██▌                                                 | 365/7473 [00:03<00:56, 126.70it/s]  5%|██▋                                                 | 378/7473 [00:03<00:55, 126.89it/s]  5%|██▋                                                 | 391/7473 [00:03<00:55, 126.98it/s]  5%|██▊                                                 | 404/7473 [00:03<00:55, 126.76it/s]  6%|██▉                                                 | 417/7473 [00:03<00:55, 126.73it/s]  6%|██▉                                                 | 430/7473 [00:04<00:55, 126.82it/s]  6%|███                                                 | 443/7473 [00:04<00:55, 126.61it/s]  6%|███▏                                                | 456/7473 [00:04<00:55, 126.90it/s]  6%|███▎                                                | 469/7473 [00:04<00:55, 126.85it/s]  6%|███▎                                                | 482/7473 [00:04<00:55, 125.31it/s]  7%|███▍                                                | 495/7473 [00:04<00:55, 125.78it/s]  7%|███▌                                                | 508/7473 [00:04<00:55, 125.92it/s]  7%|███▋                                                | 521/7473 [00:04<00:54, 126.43it/s]  7%|███▋                                                | 534/7473 [00:04<00:54, 126.39it/s]  7%|███▊                                                | 547/7473 [00:04<00:54, 126.62it/s]  7%|███▉                                                | 560/7473 [00:05<00:54, 126.85it/s]  8%|███▉                                                | 573/7473 [00:05<00:54, 126.43it/s]  8%|████                                                | 586/7473 [00:05<00:54, 126.41it/s]  8%|████▏                                               | 599/7473 [00:05<00:54, 126.33it/s]  8%|████▎                                               | 612/7473 [00:05<00:54, 126.33it/s]  8%|████▎                                               | 625/7473 [00:05<00:54, 126.12it/s]  9%|████▍                                               | 638/7473 [00:05<00:54, 126.31it/s]  9%|████▌                                               | 651/7473 [00:05<00:54, 126.13it/s]  9%|████▌                                               | 664/7473 [00:05<00:53, 126.52it/s]  9%|████▋                                               | 677/7473 [00:05<00:53, 126.57it/s]  9%|████▊                                               | 690/7473 [00:06<00:53, 126.66it/s]  9%|████▉                                               | 703/7473 [00:06<00:54, 125.15it/s] 10%|████▉                                               | 716/7473 [00:06<00:53, 125.40it/s] 10%|█████                                               | 729/7473 [00:06<00:53, 125.83it/s] 10%|█████▏                                              | 742/7473 [00:06<00:53, 125.84it/s] 10%|█████▎                                              | 755/7473 [00:06<00:53, 125.86it/s] 10%|█████▎                                              | 768/7473 [00:06<00:53, 125.85it/s] 10%|█████▍                                              | 781/7473 [00:06<00:53, 125.93it/s] 11%|█████▌                                              | 794/7473 [00:06<00:53, 125.89it/s] 11%|█████▌                                              | 807/7473 [00:06<00:52, 125.87it/s] 11%|█████▋                                              | 820/7473 [00:07<00:52, 125.80it/s] 11%|█████▊                                              | 833/7473 [00:07<00:52, 125.97it/s] 11%|█████▉                                              | 846/7473 [00:07<00:52, 125.96it/s] 11%|█████▉                                              | 859/7473 [00:07<00:52, 126.03it/s] 12%|██████                                              | 872/7473 [00:07<00:52, 126.10it/s] 12%|██████▏                                             | 885/7473 [00:07<00:52, 126.28it/s] 12%|██████▏                                             | 898/7473 [00:07<00:52, 126.05it/s] 12%|██████▎                                             | 911/7473 [00:07<00:52, 125.49it/s] 12%|██████▍                                             | 924/7473 [00:07<00:52, 125.44it/s] 13%|██████▌                                             | 937/7473 [00:08<00:52, 124.60it/s] 13%|██████▌                                             | 950/7473 [00:08<00:51, 125.63it/s] 13%|██████▋                                             | 963/7473 [00:08<00:51, 126.30it/s] 13%|██████▊                                             | 976/7473 [00:08<00:51, 126.79it/s] 13%|██████▉                                             | 989/7473 [00:08<00:51, 127.11it/s] 13%|██████▊                                            | 1002/7473 [00:08<00:50, 126.93it/s] 14%|██████▉                                            | 1015/7473 [00:08<00:50, 127.34it/s] 14%|███████                                            | 1028/7473 [00:08<00:50, 127.51it/s] 14%|███████                                            | 1041/7473 [00:08<00:50, 127.39it/s] 14%|███████▏                                           | 1054/7473 [00:08<00:50, 127.42it/s] 14%|███████▎                                           | 1067/7473 [00:09<00:50, 127.63it/s] 14%|███████▎                                           | 1080/7473 [00:09<00:50, 126.44it/s] 15%|███████▍                                           | 1093/7473 [00:09<00:50, 126.76it/s] 15%|███████▌                                           | 1106/7473 [00:09<00:50, 126.79it/s] 15%|███████▋                                           | 1119/7473 [00:09<00:50, 126.96it/s] 15%|███████▋                                           | 1132/7473 [00:09<00:49, 126.91it/s] 15%|███████▊                                           | 1145/7473 [00:09<00:49, 127.28it/s] 15%|███████▉                                           | 1158/7473 [00:09<00:50, 125.82it/s] 16%|███████▉                                           | 1171/7473 [00:09<00:49, 126.24it/s] 16%|████████                                           | 1184/7473 [00:09<00:49, 126.46it/s] 16%|████████▏                                          | 1197/7473 [00:10<00:49, 126.74it/s] 16%|████████▎                                          | 1210/7473 [00:10<00:49, 126.75it/s] 16%|████████▎                                          | 1223/7473 [00:10<00:49, 127.05it/s] 17%|████████▍                                          | 1236/7473 [00:10<00:49, 127.03it/s] 17%|████████▌                                          | 1249/7473 [00:10<00:48, 127.05it/s] 17%|████████▌                                          | 1262/7473 [00:10<00:48, 127.13it/s] 17%|████████▋                                          | 1275/7473 [00:10<00:48, 127.28it/s] 17%|████████▊                                          | 1288/7473 [00:10<00:48, 127.40it/s] 17%|████████▉                                          | 1301/7473 [00:10<00:48, 127.38it/s] 18%|████████▉                                          | 1314/7473 [00:10<00:48, 127.43it/s] 18%|█████████                                          | 1327/7473 [00:11<00:48, 127.46it/s] 18%|█████████▏                                         | 1340/7473 [00:11<00:48, 127.50it/s] 18%|█████████▏                                         | 1353/7473 [00:11<00:47, 127.53it/s] 18%|█████████▎                                         | 1366/7473 [00:11<00:47, 127.58it/s] 18%|█████████▍                                         | 1379/7473 [00:11<00:47, 127.49it/s] 19%|█████████▍                                         | 1392/7473 [00:11<00:48, 125.20it/s] 19%|█████████▌                                         | 1405/7473 [00:11<00:48, 125.87it/s] 19%|█████████▋                                         | 1418/7473 [00:11<00:47, 126.45it/s] 19%|█████████▊                                         | 1431/7473 [00:11<00:47, 126.65it/s] 19%|█████████▊                                         | 1444/7473 [00:12<00:47, 126.83it/s] 19%|█████████▉                                         | 1457/7473 [00:12<00:47, 126.91it/s] 20%|██████████                                         | 1470/7473 [00:12<00:47, 127.14it/s] 20%|██████████                                         | 1483/7473 [00:12<00:47, 127.31it/s] 20%|██████████▏                                        | 1496/7473 [00:12<00:46, 127.62it/s] 20%|██████████▎                                        | 1509/7473 [00:12<00:46, 127.46it/s] 20%|██████████▍                                        | 1522/7473 [00:12<00:46, 127.43it/s] 21%|██████████▍                                        | 1535/7473 [00:12<00:46, 127.49it/s] 21%|██████████▌                                        | 1548/7473 [00:12<00:46, 127.40it/s] 21%|██████████▋                                        | 1561/7473 [00:12<00:46, 127.18it/s] 21%|██████████▋                                        | 1574/7473 [00:13<00:46, 125.93it/s] 21%|██████████▊                                        | 1587/7473 [00:13<00:46, 126.12it/s] 21%|██████████▉                                        | 1600/7473 [00:13<00:46, 126.50it/s] 22%|███████████                                        | 1613/7473 [00:13<00:46, 125.31it/s] 22%|███████████                                        | 1626/7473 [00:13<00:46, 125.88it/s] 22%|███████████▏                                       | 1639/7473 [00:13<00:46, 126.59it/s] 22%|███████████▎                                       | 1652/7473 [00:13<00:45, 126.60it/s] 22%|███████████▎                                       | 1665/7473 [00:13<00:45, 126.72it/s] 22%|███████████▍                                       | 1678/7473 [00:13<00:45, 127.17it/s] 23%|███████████▌                                       | 1691/7473 [00:13<00:45, 127.33it/s] 23%|███████████▋                                       | 1704/7473 [00:14<00:45, 127.42it/s] 23%|███████████▋                                       | 1717/7473 [00:14<00:45, 127.29it/s] 23%|███████████▊                                       | 1730/7473 [00:14<00:45, 127.39it/s] 23%|███████████▉                                       | 1743/7473 [00:14<00:45, 126.27it/s] 23%|███████████▉                                       | 1756/7473 [00:14<00:45, 126.83it/s] 24%|████████████                                       | 1769/7473 [00:14<00:44, 126.84it/s] 24%|████████████▏                                      | 1782/7473 [00:14<00:44, 126.87it/s] 24%|████████████▎                                      | 1795/7473 [00:14<00:44, 126.99it/s] 24%|████████████▎                                      | 1808/7473 [00:14<00:44, 127.17it/s] 24%|████████████▍                                      | 1821/7473 [00:14<00:44, 127.23it/s] 25%|████████████▌                                      | 1834/7473 [00:15<00:44, 127.00it/s] 25%|████████████▌                                      | 1847/7473 [00:15<00:45, 124.86it/s] 25%|████████████▋                                      | 1860/7473 [00:15<00:44, 125.18it/s] 25%|████████████▊                                      | 1873/7473 [00:15<00:44, 125.95it/s] 25%|████████████▊                                      | 1886/7473 [00:15<00:44, 126.49it/s] 25%|████████████▉                                      | 1899/7473 [00:15<00:44, 125.85it/s] 26%|█████████████                                      | 1912/7473 [00:15<00:44, 126.08it/s] 26%|█████████████▏                                     | 1925/7473 [00:15<00:43, 126.23it/s] 26%|█████████████▏                                     | 1938/7473 [00:15<00:43, 126.25it/s] 26%|█████████████▎                                     | 1951/7473 [00:16<00:43, 126.76it/s] 26%|█████████████▍                                     | 1964/7473 [00:16<00:43, 127.08it/s] 26%|█████████████▍                                     | 1977/7473 [00:16<00:43, 127.12it/s] 27%|█████████████▌                                     | 1990/7473 [00:16<00:43, 127.03it/s] 27%|█████████████▋                                     | 2003/7473 [00:16<00:43, 127.06it/s] 27%|█████████████▊                                     | 2016/7473 [00:16<00:42, 127.36it/s] 27%|█████████████▊                                     | 2029/7473 [00:16<00:42, 127.57it/s] 27%|█████████████▉                                     | 2042/7473 [00:16<00:42, 127.46it/s] 27%|██████████████                                     | 2055/7473 [00:16<00:42, 127.48it/s] 28%|██████████████                                     | 2068/7473 [00:16<00:42, 125.79it/s] 28%|██████████████▏                                    | 2081/7473 [00:17<00:42, 126.32it/s] 28%|██████████████▎                                    | 2094/7473 [00:17<00:42, 126.86it/s] 28%|██████████████▍                                    | 2107/7473 [00:17<00:42, 127.02it/s] 28%|██████████████▍                                    | 2120/7473 [00:17<00:42, 126.43it/s] 29%|██████████████▌                                    | 2133/7473 [00:17<00:42, 126.35it/s] 29%|██████████████▋                                    | 2146/7473 [00:17<00:42, 126.80it/s] 29%|██████████████▋                                    | 2159/7473 [00:17<00:41, 127.15it/s] 29%|██████████████▊                                    | 2172/7473 [00:17<00:41, 127.28it/s] 29%|██████████████▉                                    | 2185/7473 [00:17<00:41, 127.16it/s] 29%|███████████████                                    | 2198/7473 [00:17<00:41, 126.84it/s] 30%|███████████████                                    | 2211/7473 [00:18<00:41, 127.25it/s] 30%|███████████████▏                                   | 2224/7473 [00:18<00:41, 127.41it/s] 30%|███████████████▎                                   | 2237/7473 [00:18<00:41, 127.44it/s] 30%|███████████████▎                                   | 2250/7473 [00:18<00:41, 127.27it/s] 30%|███████████████▍                                   | 2263/7473 [00:18<00:40, 127.08it/s] 30%|███████████████▌                                   | 2276/7473 [00:18<00:40, 126.97it/s] 31%|███████████████▌                                   | 2289/7473 [00:18<00:40, 126.73it/s] 31%|███████████████▋                                   | 2302/7473 [00:18<00:41, 125.27it/s] 31%|███████████████▊                                   | 2315/7473 [00:18<00:41, 125.62it/s] 31%|███████████████▉                                   | 2328/7473 [00:18<00:41, 125.38it/s] 31%|███████████████▉                                   | 2341/7473 [00:19<00:40, 125.49it/s] 32%|████████████████                                   | 2354/7473 [00:19<00:40, 125.53it/s] 32%|████████████████▏                                  | 2367/7473 [00:19<00:40, 125.58it/s] 32%|████████████████▏                                  | 2380/7473 [00:19<00:40, 125.77it/s] 32%|████████████████▎                                  | 2393/7473 [00:19<00:40, 125.54it/s] 32%|████████████████▍                                  | 2406/7473 [00:19<00:40, 125.85it/s] 32%|████████████████▌                                  | 2419/7473 [00:19<00:40, 125.92it/s] 33%|████████████████▌                                  | 2432/7473 [00:19<00:39, 126.05it/s] 33%|████████████████▋                                  | 2445/7473 [00:19<00:39, 126.11it/s] 33%|████████████████▊                                  | 2458/7473 [00:20<00:39, 125.78it/s] 33%|████████████████▊                                  | 2471/7473 [00:20<00:39, 125.68it/s] 33%|████████████████▉                                  | 2484/7473 [00:20<00:39, 125.82it/s] 33%|█████████████████                                  | 2497/7473 [00:20<00:39, 125.69it/s] 34%|█████████████████▏                                 | 2510/7473 [00:20<00:39, 125.90it/s] 34%|█████████████████▏                                 | 2523/7473 [00:20<00:48, 102.81it/s] 34%|█████████████████▎                                 | 2536/7473 [00:20<00:45, 108.56it/s] 34%|█████████████████▍                                 | 2549/7473 [00:20<00:43, 113.30it/s] 34%|█████████████████▍                                 | 2562/7473 [00:20<00:41, 117.11it/s] 34%|█████████████████▌                                 | 2575/7473 [00:21<00:41, 119.11it/s] 35%|█████████████████▋                                 | 2588/7473 [00:21<00:40, 121.30it/s] 35%|█████████████████▊                                 | 2601/7473 [00:21<00:39, 123.02it/s] 35%|█████████████████▊                                 | 2614/7473 [00:21<00:39, 124.36it/s] 35%|█████████████████▉                                 | 2627/7473 [00:21<00:38, 125.19it/s] 35%|██████████████████                                 | 2640/7473 [00:21<00:38, 125.89it/s] 36%|██████████████████                                 | 2653/7473 [00:21<00:38, 126.29it/s] 36%|██████████████████▏                                | 2666/7473 [00:21<00:37, 126.67it/s] 36%|██████████████████▎                                | 2679/7473 [00:21<00:37, 126.90it/s] 36%|██████████████████▎                                | 2692/7473 [00:21<00:37, 127.08it/s] 36%|██████████████████▍                                | 2705/7473 [00:22<00:37, 126.91it/s] 36%|██████████████████▌                                | 2718/7473 [00:22<00:37, 127.20it/s] 37%|██████████████████▋                                | 2731/7473 [00:22<00:37, 126.89it/s] 37%|██████████████████▋                                | 2744/7473 [00:22<00:37, 126.95it/s] 37%|██████████████████▊                                | 2757/7473 [00:22<00:37, 125.58it/s] 37%|██████████████████▉                                | 2770/7473 [00:22<00:37, 125.91it/s] 37%|██████████████████▉                                | 2783/7473 [00:22<00:37, 126.46it/s] 37%|███████████████████                                | 2796/7473 [00:22<00:36, 126.60it/s] 38%|███████████████████▏                               | 2809/7473 [00:22<00:36, 126.81it/s] 38%|███████████████████▎                               | 2822/7473 [00:22<00:36, 126.95it/s] 38%|███████████████████▎                               | 2835/7473 [00:23<00:36, 127.15it/s] 38%|███████████████████▍                               | 2848/7473 [00:23<00:36, 127.08it/s] 38%|███████████████████▌                               | 2861/7473 [00:23<00:36, 127.03it/s] 38%|███████████████████▌                               | 2874/7473 [00:23<00:36, 126.89it/s] 39%|███████████████████▋                               | 2887/7473 [00:23<00:36, 127.02it/s] 39%|███████████████████▊                               | 2900/7473 [00:23<00:35, 127.04it/s] 39%|███████████████████▉                               | 2913/7473 [00:23<00:35, 127.21it/s] 39%|███████████████████▉                               | 2926/7473 [00:23<00:35, 127.49it/s] 39%|████████████████████                               | 2939/7473 [00:23<00:35, 127.43it/s] 40%|████████████████████▏                              | 2952/7473 [00:24<00:35, 127.38it/s] 40%|████████████████████▏                              | 2965/7473 [00:24<00:35, 126.97it/s] 40%|████████████████████▎                              | 2978/7473 [00:24<00:35, 125.57it/s] 40%|████████████████████▍                              | 2991/7473 [00:24<00:35, 126.12it/s] 40%|████████████████████▌                              | 3004/7473 [00:24<00:35, 126.51it/s] 40%|████████████████████▌                              | 3017/7473 [00:24<00:35, 126.57it/s] 41%|████████████████████▋                              | 3030/7473 [00:24<00:35, 126.60it/s] 41%|████████████████████▊                              | 3043/7473 [00:24<00:35, 126.53it/s] 41%|████████████████████▊                              | 3056/7473 [00:24<00:34, 126.87it/s] 41%|████████████████████▉                              | 3069/7473 [00:24<00:34, 126.93it/s] 41%|█████████████████████                              | 3082/7473 [00:25<00:34, 126.96it/s] 41%|█████████████████████                              | 3095/7473 [00:25<00:34, 126.76it/s] 42%|█████████████████████▏                             | 3108/7473 [00:25<00:34, 126.80it/s] 42%|█████████████████████▎                             | 3121/7473 [00:25<00:34, 126.64it/s] 42%|█████████████████████▍                             | 3134/7473 [00:25<00:34, 126.72it/s] 42%|█████████████████████▍                             | 3147/7473 [00:25<00:34, 126.56it/s] 42%|█████████████████████▌                             | 3160/7473 [00:25<00:34, 126.61it/s] 42%|█████████████████████▋                             | 3173/7473 [00:25<00:33, 126.81it/s] 43%|█████████████████████▋                             | 3186/7473 [00:25<00:34, 125.99it/s] 43%|█████████████████████▊                             | 3199/7473 [00:25<00:33, 126.32it/s] 43%|█████████████████████▉                             | 3212/7473 [00:26<00:34, 125.31it/s] 43%|██████████████████████                             | 3225/7473 [00:26<00:33, 125.72it/s] 43%|██████████████████████                             | 3238/7473 [00:26<00:33, 126.05it/s] 44%|██████████████████████▏                            | 3251/7473 [00:26<00:33, 126.52it/s] 44%|██████████████████████▎                            | 3264/7473 [00:26<00:33, 126.67it/s] 44%|██████████████████████▎                            | 3277/7473 [00:26<00:33, 126.93it/s] 44%|██████████████████████▍                            | 3290/7473 [00:26<00:32, 126.76it/s] 44%|██████████████████████▌                            | 3303/7473 [00:26<00:32, 126.89it/s] 44%|██████████████████████▋                            | 3316/7473 [00:26<00:32, 127.01it/s] 45%|██████████████████████▋                            | 3329/7473 [00:26<00:32, 126.84it/s] 45%|██████████████████████▊                            | 3342/7473 [00:27<00:32, 126.59it/s] 45%|██████████████████████▉                            | 3355/7473 [00:27<00:32, 126.52it/s] 45%|██████████████████████▉                            | 3368/7473 [00:27<00:32, 126.62it/s] 45%|███████████████████████                            | 3381/7473 [00:27<00:32, 126.68it/s] 45%|███████████████████████▏                           | 3394/7473 [00:27<00:32, 125.82it/s] 46%|███████████████████████▎                           | 3407/7473 [00:27<00:32, 126.29it/s] 46%|███████████████████████▎                           | 3420/7473 [00:27<00:32, 126.47it/s] 46%|███████████████████████▍                           | 3433/7473 [00:27<00:32, 124.64it/s] 46%|███████████████████████▌                           | 3446/7473 [00:27<00:32, 125.22it/s] 46%|███████████████████████▌                           | 3459/7473 [00:28<00:31, 125.69it/s] 46%|███████████████████████▋                           | 3472/7473 [00:28<00:31, 126.06it/s] 47%|███████████████████████▊                           | 3485/7473 [00:28<00:31, 126.48it/s] 47%|███████████████████████▊                           | 3498/7473 [00:28<00:31, 126.53it/s] 47%|███████████████████████▉                           | 3511/7473 [00:28<00:31, 126.78it/s] 47%|████████████████████████                           | 3524/7473 [00:28<00:31, 126.90it/s] 47%|████████████████████████▏                          | 3537/7473 [00:28<00:30, 127.09it/s] 48%|████████████████████████▏                          | 3550/7473 [00:28<00:30, 127.12it/s] 48%|████████████████████████▎                          | 3563/7473 [00:28<00:30, 127.04it/s] 48%|████████████████████████▍                          | 3576/7473 [00:28<00:30, 127.32it/s] 48%|████████████████████████▍                          | 3589/7473 [00:29<00:30, 127.27it/s] 48%|████████████████████████▌                          | 3602/7473 [00:29<00:30, 127.25it/s] 48%|████████████████████████▋                          | 3615/7473 [00:29<00:30, 126.32it/s] 49%|████████████████████████▊                          | 3628/7473 [00:29<00:30, 126.58it/s] 49%|████████████████████████▊                          | 3641/7473 [00:29<00:30, 126.54it/s] 49%|████████████████████████▉                          | 3654/7473 [00:29<00:30, 125.24it/s] 49%|█████████████████████████                          | 3667/7473 [00:29<00:30, 125.80it/s] 49%|█████████████████████████                          | 3680/7473 [00:29<00:30, 126.14it/s] 49%|█████████████████████████▏                         | 3693/7473 [00:29<00:29, 126.46it/s] 50%|█████████████████████████▎                         | 3706/7473 [00:29<00:29, 126.67it/s] 50%|█████████████████████████▍                         | 3719/7473 [00:30<00:29, 126.77it/s] 50%|█████████████████████████▍                         | 3732/7473 [00:30<00:29, 126.94it/s] 50%|█████████████████████████▌                         | 3745/7473 [00:30<00:29, 126.78it/s] 50%|█████████████████████████▋                         | 3758/7473 [00:30<00:29, 126.96it/s] 50%|█████████████████████████▋                         | 3771/7473 [00:30<00:29, 127.02it/s] 51%|█████████████████████████▊                         | 3784/7473 [00:30<00:29, 127.12it/s] 51%|█████████████████████████▉                         | 3797/7473 [00:30<00:28, 127.25it/s] 51%|██████████████████████████                         | 3810/7473 [00:30<00:28, 127.33it/s] 51%|██████████████████████████                         | 3823/7473 [00:30<00:28, 126.33it/s] 51%|██████████████████████████▏                        | 3836/7473 [00:30<00:28, 126.53it/s] 52%|██████████████████████████▎                        | 3849/7473 [00:31<00:28, 126.65it/s] 52%|██████████████████████████▎                        | 3862/7473 [00:31<00:28, 126.75it/s] 52%|██████████████████████████▍                        | 3875/7473 [00:31<00:28, 126.79it/s] 52%|██████████████████████████▌                        | 3888/7473 [00:31<00:28, 124.45it/s] 52%|██████████████████████████▌                        | 3901/7473 [00:31<00:28, 125.35it/s] 52%|██████████████████████████▋                        | 3914/7473 [00:31<00:28, 125.86it/s] 53%|██████████████████████████▊                        | 3927/7473 [00:31<00:28, 126.22it/s] 53%|██████████████████████████▉                        | 3940/7473 [00:31<00:27, 126.56it/s] 53%|██████████████████████████▉                        | 3953/7473 [00:31<00:27, 126.79it/s] 53%|███████████████████████████                        | 3966/7473 [00:32<00:27, 126.96it/s] 53%|███████████████████████████▏                       | 3979/7473 [00:32<00:27, 126.91it/s] 53%|███████████████████████████▏                       | 3992/7473 [00:32<00:27, 126.97it/s] 54%|███████████████████████████▎                       | 4005/7473 [00:32<00:27, 127.20it/s] 54%|███████████████████████████▍                       | 4018/7473 [00:32<00:27, 127.20it/s] 54%|███████████████████████████▌                       | 4031/7473 [00:32<00:27, 127.23it/s] 54%|███████████████████████████▌                       | 4044/7473 [00:32<00:27, 126.40it/s] 54%|███████████████████████████▋                       | 4057/7473 [00:32<00:26, 126.66it/s] 54%|███████████████████████████▊                       | 4070/7473 [00:32<00:26, 126.73it/s] 55%|███████████████████████████▊                       | 4083/7473 [00:32<00:26, 126.84it/s] 55%|███████████████████████████▉                       | 4096/7473 [00:33<00:26, 126.96it/s] 55%|████████████████████████████                       | 4109/7473 [00:33<00:26, 125.24it/s] 55%|████████████████████████████▏                      | 4122/7473 [00:33<00:26, 125.68it/s] 55%|████████████████████████████▏                      | 4135/7473 [00:33<00:26, 125.89it/s] 56%|████████████████████████████▎                      | 4148/7473 [00:33<00:26, 125.97it/s] 56%|████████████████████████████▍                      | 4161/7473 [00:33<00:26, 126.39it/s] 56%|████████████████████████████▍                      | 4174/7473 [00:33<00:26, 126.54it/s] 56%|████████████████████████████▌                      | 4187/7473 [00:33<00:25, 126.55it/s] 56%|████████████████████████████▋                      | 4200/7473 [00:33<00:25, 126.91it/s] 56%|████████████████████████████▊                      | 4213/7473 [00:33<00:25, 126.66it/s] 57%|████████████████████████████▊                      | 4226/7473 [00:34<00:25, 126.65it/s] 57%|████████████████████████████▉                      | 4239/7473 [00:34<00:25, 126.89it/s] 57%|█████████████████████████████                      | 4252/7473 [00:34<00:25, 126.08it/s] 57%|█████████████████████████████                      | 4265/7473 [00:34<00:25, 126.15it/s] 57%|█████████████████████████████▏                     | 4278/7473 [00:34<00:25, 126.13it/s] 57%|█████████████████████████████▎                     | 4291/7473 [00:34<00:25, 126.43it/s] 58%|█████████████████████████████▎                     | 4304/7473 [00:34<00:25, 126.56it/s] 58%|█████████████████████████████▍                     | 4317/7473 [00:34<00:24, 126.75it/s] 58%|█████████████████████████████▌                     | 4330/7473 [00:34<00:24, 126.72it/s] 58%|█████████████████████████████▋                     | 4343/7473 [00:35<00:24, 125.58it/s] 58%|█████████████████████████████▋                     | 4356/7473 [00:35<00:24, 126.03it/s] 58%|█████████████████████████████▊                     | 4369/7473 [00:35<00:24, 126.31it/s] 59%|█████████████████████████████▉                     | 4382/7473 [00:35<00:24, 126.34it/s] 59%|█████████████████████████████▉                     | 4395/7473 [00:35<00:24, 126.48it/s] 59%|██████████████████████████████                     | 4408/7473 [00:35<00:24, 126.64it/s] 59%|██████████████████████████████▏                    | 4421/7473 [00:35<00:24, 126.60it/s] 59%|██████████████████████████████▎                    | 4434/7473 [00:35<00:24, 126.54it/s] 60%|██████████████████████████████▎                    | 4447/7473 [00:35<00:23, 126.63it/s] 60%|██████████████████████████████▍                    | 4460/7473 [00:35<00:23, 126.47it/s] 60%|██████████████████████████████▌                    | 4473/7473 [00:36<00:23, 126.69it/s] 60%|██████████████████████████████▌                    | 4486/7473 [00:36<00:23, 126.70it/s] 60%|██████████████████████████████▋                    | 4499/7473 [00:36<00:23, 126.78it/s] 60%|██████████████████████████████▊                    | 4512/7473 [00:36<00:23, 126.75it/s] 61%|██████████████████████████████▉                    | 4525/7473 [00:36<00:23, 126.78it/s] 61%|██████████████████████████████▉                    | 4538/7473 [00:36<00:23, 126.39it/s] 61%|███████████████████████████████                    | 4551/7473 [00:36<00:23, 126.77it/s] 61%|███████████████████████████████▏                   | 4564/7473 [00:36<00:23, 125.54it/s] 61%|███████████████████████████████▏                   | 4577/7473 [00:36<00:23, 125.87it/s] 61%|███████████████████████████████▎                   | 4590/7473 [00:36<00:22, 126.21it/s] 62%|███████████████████████████████▍                   | 4603/7473 [00:37<00:22, 126.37it/s] 62%|███████████████████████████████▌                   | 4616/7473 [00:37<00:22, 126.58it/s] 62%|███████████████████████████████▌                   | 4629/7473 [00:37<00:22, 126.62it/s] 62%|███████████████████████████████▋                   | 4642/7473 [00:37<00:22, 126.61it/s] 62%|███████████████████████████████▊                   | 4655/7473 [00:37<00:22, 126.55it/s] 62%|███████████████████████████████▊                   | 4668/7473 [00:37<00:22, 126.67it/s] 63%|███████████████████████████████▉                   | 4681/7473 [00:37<00:22, 126.68it/s] 63%|████████████████████████████████                   | 4694/7473 [00:37<00:21, 126.70it/s] 63%|████████████████████████████████                   | 4707/7473 [00:37<00:21, 126.70it/s] 63%|████████████████████████████████▏                  | 4720/7473 [00:37<00:21, 126.71it/s] 63%|████████████████████████████████▎                  | 4733/7473 [00:38<00:21, 126.74it/s] 64%|████████████████████████████████▍                  | 4746/7473 [00:38<00:21, 126.69it/s] 64%|████████████████████████████████▍                  | 4759/7473 [00:38<00:21, 126.86it/s] 64%|████████████████████████████████▌                  | 4772/7473 [00:38<00:21, 126.94it/s] 64%|████████████████████████████████▋                  | 4785/7473 [00:38<00:21, 127.04it/s] 64%|████████████████████████████████▋                  | 4798/7473 [00:38<00:21, 125.06it/s] 64%|████████████████████████████████▊                  | 4811/7473 [00:38<00:21, 125.42it/s] 65%|████████████████████████████████▉                  | 4824/7473 [00:38<00:21, 125.58it/s] 65%|█████████████████████████████████                  | 4837/7473 [00:38<00:20, 125.72it/s] 65%|█████████████████████████████████                  | 4850/7473 [00:39<00:20, 125.80it/s] 65%|█████████████████████████████████▏                 | 4863/7473 [00:39<00:20, 125.74it/s] 65%|█████████████████████████████████▎                 | 4876/7473 [00:39<00:20, 125.48it/s] 65%|█████████████████████████████████▎                 | 4889/7473 [00:39<00:20, 125.57it/s] 66%|█████████████████████████████████▍                 | 4902/7473 [00:39<00:20, 125.84it/s] 66%|█████████████████████████████████▌                 | 4915/7473 [00:39<00:20, 125.80it/s] 66%|█████████████████████████████████▋                 | 4928/7473 [00:39<00:20, 125.77it/s] 66%|█████████████████████████████████▋                 | 4941/7473 [00:39<00:20, 125.47it/s] 66%|█████████████████████████████████▊                 | 4954/7473 [00:39<00:20, 125.72it/s] 66%|█████████████████████████████████▉                 | 4967/7473 [00:39<00:19, 125.40it/s] 67%|█████████████████████████████████▉                 | 4980/7473 [00:40<00:19, 125.55it/s] 67%|██████████████████████████████████                 | 4993/7473 [00:40<00:19, 125.50it/s] 67%|██████████████████████████████████▏                | 5006/7473 [00:40<00:19, 125.84it/s] 67%|██████████████████████████████████▎                | 5019/7473 [00:40<00:19, 124.18it/s] 67%|██████████████████████████████████▎                | 5032/7473 [00:40<00:19, 124.53it/s] 68%|██████████████████████████████████▍                | 5045/7473 [00:40<00:19, 125.03it/s] 68%|██████████████████████████████████▌                | 5058/7473 [00:40<00:19, 125.25it/s] 68%|██████████████████████████████████▌                | 5071/7473 [00:40<00:19, 125.45it/s] 68%|██████████████████████████████████▋                | 5084/7473 [00:40<00:19, 125.40it/s] 68%|██████████████████████████████████▊                | 5097/7473 [00:40<00:18, 125.25it/s] 68%|██████████████████████████████████▊                | 5110/7473 [00:41<00:18, 125.33it/s] 69%|██████████████████████████████████▉                | 5123/7473 [00:41<00:18, 125.51it/s] 69%|███████████████████████████████████                | 5136/7473 [00:41<00:18, 125.65it/s] 69%|███████████████████████████████████▏               | 5149/7473 [00:41<00:18, 125.75it/s] 69%|███████████████████████████████████▏               | 5162/7473 [00:41<00:18, 125.54it/s] 69%|███████████████████████████████████▎               | 5175/7473 [00:41<00:18, 125.66it/s] 69%|███████████████████████████████████▍               | 5188/7473 [00:41<00:18, 125.66it/s] 70%|███████████████████████████████████▍               | 5201/7473 [00:41<00:18, 125.69it/s] 70%|███████████████████████████████████▌               | 5214/7473 [00:41<00:17, 125.83it/s] 70%|███████████████████████████████████▋               | 5227/7473 [00:42<00:17, 125.82it/s] 70%|███████████████████████████████████▊               | 5240/7473 [00:42<00:17, 125.24it/s] 70%|███████████████████████████████████▊               | 5253/7473 [00:42<00:21, 104.89it/s] 70%|███████████████████████████████████▉               | 5266/7473 [00:42<00:19, 110.52it/s] 71%|████████████████████████████████████               | 5279/7473 [00:42<00:19, 115.07it/s] 71%|████████████████████████████████████               | 5292/7473 [00:42<00:18, 118.31it/s] 71%|████████████████████████████████████▏              | 5305/7473 [00:42<00:18, 120.22it/s] 71%|████████████████████████████████████▎              | 5318/7473 [00:42<00:17, 121.84it/s] 71%|████████████████████████████████████▍              | 5331/7473 [00:42<00:17, 123.20it/s] 72%|████████████████████████████████████▍              | 5344/7473 [00:43<00:17, 124.22it/s] 72%|████████████████████████████████████▌              | 5357/7473 [00:43<00:16, 124.76it/s] 72%|████████████████████████████████████▋              | 5370/7473 [00:43<00:16, 125.28it/s] 72%|████████████████████████████████████▋              | 5383/7473 [00:43<00:16, 125.59it/s] 72%|████████████████████████████████████▊              | 5396/7473 [00:43<00:16, 125.79it/s] 72%|████████████████████████████████████▉              | 5409/7473 [00:43<00:16, 126.07it/s] 73%|█████████████████████████████████████              | 5422/7473 [00:43<00:16, 126.28it/s] 73%|█████████████████████████████████████              | 5435/7473 [00:43<00:16, 126.51it/s] 73%|█████████████████████████████████████▏             | 5448/7473 [00:43<00:16, 126.40it/s] 73%|█████████████████████████████████████▎             | 5461/7473 [00:43<00:15, 126.19it/s] 73%|██████████████████████████████████████              | 5474/7473 [00:44<00:26, 75.36it/s] 73%|██████████████████████████████████████▏             | 5487/7473 [00:44<00:23, 85.73it/s] 74%|██████████████████████████████████████▎             | 5500/7473 [00:44<00:20, 94.66it/s] 74%|█████████████████████████████████████▌             | 5513/7473 [00:44<00:19, 102.43it/s] 74%|█████████████████████████████████████▋             | 5526/7473 [00:44<00:17, 108.41it/s] 74%|█████████████████████████████████████▊             | 5539/7473 [00:44<00:17, 113.17it/s] 74%|█████████████████████████████████████▉             | 5552/7473 [00:44<00:16, 116.96it/s] 74%|█████████████████████████████████████▉             | 5565/7473 [00:44<00:15, 119.83it/s] 75%|██████████████████████████████████████             | 5578/7473 [00:45<00:15, 121.33it/s] 75%|██████████████████████████████████████▏            | 5591/7473 [00:45<00:15, 122.83it/s] 75%|██████████████████████████████████████▏            | 5604/7473 [00:45<00:15, 123.80it/s] 75%|██████████████████████████████████████▎            | 5617/7473 [00:45<00:14, 124.58it/s] 75%|██████████████████████████████████████▍            | 5630/7473 [00:45<00:14, 125.25it/s] 76%|██████████████████████████████████████▌            | 5643/7473 [00:45<00:14, 125.15it/s] 76%|██████████████████████████████████████▌            | 5656/7473 [00:45<00:14, 125.75it/s] 76%|██████████████████████████████████████▋            | 5669/7473 [00:45<00:14, 126.05it/s] 76%|██████████████████████████████████████▊            | 5682/7473 [00:45<00:14, 124.79it/s] 76%|██████████████████████████████████████▊            | 5695/7473 [00:46<00:14, 125.33it/s] 76%|██████████████████████████████████████▉            | 5708/7473 [00:46<00:14, 125.52it/s] 77%|███████████████████████████████████████            | 5721/7473 [00:46<00:13, 125.63it/s] 77%|███████████████████████████████████████▏           | 5734/7473 [00:46<00:13, 125.94it/s] 77%|███████████████████████████████████████▏           | 5747/7473 [00:46<00:13, 126.24it/s] 77%|███████████████████████████████████████▎           | 5760/7473 [00:46<00:13, 126.41it/s] 77%|███████████████████████████████████████▍           | 5773/7473 [00:46<00:13, 126.61it/s] 77%|███████████████████████████████████████▍           | 5786/7473 [00:46<00:13, 126.04it/s] 78%|███████████████████████████████████████▌           | 5799/7473 [00:46<00:13, 126.26it/s] 78%|███████████████████████████████████████▋           | 5812/7473 [00:46<00:13, 126.08it/s] 78%|███████████████████████████████████████▊           | 5825/7473 [00:47<00:13, 126.26it/s] 78%|███████████████████████████████████████▊           | 5838/7473 [00:47<00:12, 126.34it/s] 78%|███████████████████████████████████████▉           | 5851/7473 [00:47<00:12, 126.56it/s] 78%|████████████████████████████████████████           | 5864/7473 [00:47<00:12, 126.04it/s] 79%|████████████████████████████████████████           | 5877/7473 [00:47<00:12, 126.30it/s] 79%|████████████████████████████████████████▏          | 5890/7473 [00:47<00:12, 126.24it/s] 79%|████████████████████████████████████████▎          | 5903/7473 [00:47<00:12, 124.75it/s] 79%|████████████████████████████████████████▎          | 5916/7473 [00:47<00:12, 125.21it/s] 79%|████████████████████████████████████████▍          | 5929/7473 [00:47<00:12, 125.41it/s] 80%|████████████████████████████████████████▌          | 5942/7473 [00:47<00:12, 125.52it/s] 80%|████████████████████████████████████████▋          | 5955/7473 [00:48<00:12, 125.68it/s] 80%|████████████████████████████████████████▋          | 5968/7473 [00:48<00:11, 125.62it/s] 80%|████████████████████████████████████████▊          | 5981/7473 [00:48<00:11, 126.01it/s] 80%|████████████████████████████████████████▉          | 5994/7473 [00:48<00:11, 125.94it/s] 80%|████████████████████████████████████████▉          | 6007/7473 [00:48<00:11, 125.89it/s] 81%|█████████████████████████████████████████          | 6020/7473 [00:48<00:11, 126.18it/s] 81%|█████████████████████████████████████████▏         | 6033/7473 [00:48<00:11, 126.26it/s] 81%|█████████████████████████████████████████▎         | 6046/7473 [00:48<00:11, 126.40it/s] 81%|█████████████████████████████████████████▎         | 6059/7473 [00:48<00:11, 126.65it/s] 81%|█████████████████████████████████████████▍         | 6072/7473 [00:49<00:11, 126.34it/s] 81%|█████████████████████████████████████████▌         | 6085/7473 [00:49<00:10, 126.48it/s] 82%|█████████████████████████████████████████▌         | 6098/7473 [00:49<00:10, 126.54it/s] 82%|█████████████████████████████████████████▋         | 6111/7473 [00:49<00:10, 126.57it/s] 82%|█████████████████████████████████████████▊         | 6124/7473 [00:49<00:10, 126.59it/s] 82%|█████████████████████████████████████████▉         | 6137/7473 [00:49<00:10, 125.30it/s] 82%|█████████████████████████████████████████▉         | 6150/7473 [00:49<00:10, 125.11it/s] 82%|██████████████████████████████████████████         | 6163/7473 [00:49<00:10, 125.44it/s] 83%|██████████████████████████████████████████▏        | 6176/7473 [00:49<00:10, 125.79it/s] 83%|██████████████████████████████████████████▏        | 6189/7473 [00:49<00:10, 126.04it/s] 83%|██████████████████████████████████████████▎        | 6202/7473 [00:50<00:10, 126.23it/s] 83%|██████████████████████████████████████████▍        | 6215/7473 [00:50<00:09, 126.33it/s] 83%|██████████████████████████████████████████▌        | 6228/7473 [00:50<00:09, 125.94it/s] 84%|██████████████████████████████████████████▌        | 6241/7473 [00:50<00:09, 126.23it/s] 84%|██████████████████████████████████████████▋        | 6254/7473 [00:50<00:09, 126.47it/s] 84%|██████████████████████████████████████████▊        | 6267/7473 [00:50<00:09, 126.40it/s] 84%|██████████████████████████████████████████▊        | 6280/7473 [00:50<00:09, 126.49it/s] 84%|██████████████████████████████████████████▉        | 6293/7473 [00:50<00:09, 126.07it/s] 84%|███████████████████████████████████████████        | 6306/7473 [00:50<00:09, 126.45it/s] 85%|███████████████████████████████████████████        | 6319/7473 [00:50<00:09, 126.57it/s] 85%|███████████████████████████████████████████▏       | 6332/7473 [00:51<00:09, 126.68it/s] 85%|███████████████████████████████████████████▎       | 6345/7473 [00:51<00:08, 126.56it/s] 85%|███████████████████████████████████████████▍       | 6358/7473 [00:51<00:08, 124.39it/s] 85%|███████████████████████████████████████████▍       | 6371/7473 [00:51<00:08, 124.74it/s] 85%|███████████████████████████████████████████▌       | 6384/7473 [00:51<00:08, 124.99it/s] 86%|███████████████████████████████████████████▋       | 6397/7473 [00:51<00:08, 125.48it/s] 86%|███████████████████████████████████████████▋       | 6410/7473 [00:51<00:08, 125.86it/s] 86%|███████████████████████████████████████████▊       | 6423/7473 [00:51<00:08, 125.90it/s] 86%|███████████████████████████████████████████▉       | 6436/7473 [00:51<00:08, 125.83it/s] 86%|████████████████████████████████████████████       | 6449/7473 [00:52<00:08, 125.85it/s] 86%|████████████████████████████████████████████       | 6462/7473 [00:52<00:08, 125.93it/s] 87%|████████████████████████████████████████████▏      | 6475/7473 [00:52<00:07, 126.24it/s] 87%|████████████████████████████████████████████▎      | 6488/7473 [00:52<00:07, 126.35it/s] 87%|████████████████████████████████████████████▎      | 6501/7473 [00:52<00:07, 126.40it/s] 87%|████████████████████████████████████████████▍      | 6514/7473 [00:52<00:07, 125.74it/s] 87%|████████████████████████████████████████████▌      | 6527/7473 [00:52<00:07, 126.02it/s] 88%|████████████████████████████████████████████▋      | 6540/7473 [00:52<00:07, 126.27it/s] 88%|████████████████████████████████████████████▋      | 6553/7473 [00:52<00:07, 126.43it/s] 88%|████████████████████████████████████████████▊      | 6566/7473 [00:52<00:07, 126.49it/s] 88%|████████████████████████████████████████████▉      | 6579/7473 [00:53<00:07, 125.95it/s] 88%|████████████████████████████████████████████▉      | 6592/7473 [00:53<00:07, 124.89it/s] 88%|█████████████████████████████████████████████      | 6605/7473 [00:53<00:06, 125.45it/s] 89%|█████████████████████████████████████████████▏     | 6618/7473 [00:53<00:06, 125.82it/s] 89%|█████████████████████████████████████████████▎     | 6631/7473 [00:53<00:06, 125.91it/s] 89%|█████████████████████████████████████████████▎     | 6644/7473 [00:53<00:06, 125.76it/s] 89%|█████████████████████████████████████████████▍     | 6657/7473 [00:53<00:06, 125.87it/s] 89%|█████████████████████████████████████████████▌     | 6670/7473 [00:53<00:06, 125.88it/s] 89%|█████████████████████████████████████████████▌     | 6683/7473 [00:53<00:06, 126.09it/s] 90%|█████████████████████████████████████████████▋     | 6696/7473 [00:53<00:06, 126.38it/s] 90%|█████████████████████████████████████████████▊     | 6709/7473 [00:54<00:06, 126.46it/s] 90%|█████████████████████████████████████████████▊     | 6722/7473 [00:54<00:05, 125.91it/s] 90%|█████████████████████████████████████████████▉     | 6735/7473 [00:54<00:05, 126.12it/s] 90%|██████████████████████████████████████████████     | 6748/7473 [00:54<00:05, 126.15it/s] 90%|██████████████████████████████████████████████▏    | 6761/7473 [00:54<00:05, 126.08it/s] 91%|██████████████████████████████████████████████▏    | 6774/7473 [00:54<00:05, 126.22it/s] 91%|██████████████████████████████████████████████▎    | 6787/7473 [00:54<00:05, 126.29it/s] 91%|██████████████████████████████████████████████▍    | 6800/7473 [00:54<00:05, 125.93it/s] 91%|██████████████████████████████████████████████▍    | 6813/7473 [00:54<00:05, 124.71it/s] 91%|██████████████████████████████████████████████▌    | 6826/7473 [00:55<00:05, 125.16it/s] 92%|██████████████████████████████████████████████▋    | 6839/7473 [00:55<00:05, 125.55it/s] 92%|██████████████████████████████████████████████▊    | 6852/7473 [00:55<00:04, 125.92it/s] 92%|██████████████████████████████████████████████▊    | 6865/7473 [00:55<00:04, 125.83it/s] 92%|██████████████████████████████████████████████▉    | 6878/7473 [00:55<00:04, 126.16it/s] 92%|███████████████████████████████████████████████    | 6891/7473 [00:55<00:04, 126.33it/s] 92%|███████████████████████████████████████████████    | 6904/7473 [00:55<00:04, 126.65it/s] 93%|███████████████████████████████████████████████▏   | 6917/7473 [00:55<00:04, 126.61it/s] 93%|███████████████████████████████████████████████▎   | 6930/7473 [00:55<00:04, 126.44it/s] 93%|███████████████████████████████████████████████▍   | 6943/7473 [00:55<00:04, 125.11it/s] 93%|███████████████████████████████████████████████▍   | 6956/7473 [00:56<00:04, 122.90it/s] 93%|███████████████████████████████████████████████▌   | 6969/7473 [00:56<00:04, 123.99it/s] 93%|███████████████████████████████████████████████▋   | 6982/7473 [00:56<00:03, 124.70it/s] 94%|███████████████████████████████████████████████▋   | 6995/7473 [00:56<00:03, 124.09it/s] 94%|███████████████████████████████████████████████▊   | 7008/7473 [00:56<00:03, 124.90it/s] 94%|███████████████████████████████████████████████▉   | 7021/7473 [00:56<00:03, 125.34it/s] 94%|████████████████████████████████████████████████   | 7034/7473 [00:56<00:03, 125.47it/s] 94%|████████████████████████████████████████████████   | 7047/7473 [00:56<00:03, 124.17it/s] 94%|████████████████████████████████████████████████▏  | 7060/7473 [00:56<00:03, 125.00it/s] 95%|████████████████████████████████████████████████▎  | 7073/7473 [00:56<00:03, 125.35it/s] 95%|████████████████████████████████████████████████▎  | 7086/7473 [00:57<00:03, 125.82it/s] 95%|████████████████████████████████████████████████▍  | 7099/7473 [00:57<00:02, 126.02it/s] 95%|████████████████████████████████████████████████▌  | 7112/7473 [00:57<00:02, 126.05it/s] 95%|████████████████████████████████████████████████▋  | 7125/7473 [00:57<00:02, 126.12it/s] 96%|████████████████████████████████████████████████▋  | 7138/7473 [00:57<00:02, 125.97it/s] 96%|████████████████████████████████████████████████▊  | 7151/7473 [00:57<00:02, 126.27it/s] 96%|████████████████████████████████████████████████▉  | 7164/7473 [00:57<00:02, 126.07it/s] 96%|████████████████████████████████████████████████▉  | 7177/7473 [00:57<00:02, 126.30it/s] 96%|█████████████████████████████████████████████████  | 7190/7473 [00:57<00:02, 126.44it/s] 96%|█████████████████████████████████████████████████▏ | 7203/7473 [00:58<00:02, 126.53it/s] 97%|█████████████████████████████████████████████████▏ | 7216/7473 [00:58<00:02, 126.43it/s] 97%|█████████████████████████████████████████████████▎ | 7229/7473 [00:58<00:01, 126.58it/s] 97%|█████████████████████████████████████████████████▍ | 7242/7473 [00:58<00:01, 126.56it/s] 97%|█████████████████████████████████████████████████▌ | 7255/7473 [00:58<00:01, 126.59it/s] 97%|█████████████████████████████████████████████████▌ | 7268/7473 [00:58<00:01, 125.35it/s] 97%|█████████████████████████████████████████████████▋ | 7281/7473 [00:58<00:01, 124.78it/s] 98%|█████████████████████████████████████████████████▊ | 7294/7473 [00:58<00:01, 125.46it/s] 98%|█████████████████████████████████████████████████▊ | 7307/7473 [00:58<00:01, 125.75it/s] 98%|█████████████████████████████████████████████████▉ | 7320/7473 [00:58<00:01, 126.11it/s] 98%|██████████████████████████████████████████████████ | 7333/7473 [00:59<00:01, 126.17it/s] 98%|██████████████████████████████████████████████████▏| 7346/7473 [00:59<00:01, 126.18it/s] 98%|██████████████████████████████████████████████████▏| 7359/7473 [00:59<00:00, 126.27it/s] 99%|██████████████████████████████████████████████████▎| 7372/7473 [00:59<00:00, 126.29it/s] 99%|██████████████████████████████████████████████████▍| 7385/7473 [00:59<00:00, 126.36it/s] 99%|██████████████████████████████████████████████████▍| 7398/7473 [00:59<00:00, 126.52it/s] 99%|██████████████████████████████████████████████████▌| 7411/7473 [00:59<00:00, 126.52it/s] 99%|██████████████████████████████████████████████████▋| 7424/7473 [00:59<00:00, 126.39it/s]100%|██████████████████████████████████████████████████▊| 7437/7473 [00:59<00:00, 126.54it/s]100%|██████████████████████████████████████████████████▊| 7450/7473 [00:59<00:00, 126.36it/s]100%|██████████████████████████████████████████████████▉| 7463/7473 [01:00<00:00, 126.21it/s]100%|███████████████████████████████████████████████████| 7473/7473 [01:00<00:00, 124.25it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.01s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.13s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.30s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.40s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.04s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.06s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.17s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.30s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.56s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.69s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.46s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.63s/it]
[2023-08-12 18:41:40,253] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.51s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.70s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.67s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.85s/it]
[2023-08-12 18:41:48,002] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 18:41:48,002] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f2d1a909490>
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f2d00f240a0>
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 18:41:48,004] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.7618715763092041 seconds
Loading extension module utils...
Time to load utils op: 0.6048493385314941 seconds
Loading extension module utils...
Time to load utils op: 0.8052446842193604 seconds
Loading extension module utils...
Time to load utils op: 0.8052573204040527 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Rationales: 1. The question asks where you could find plumbing that would not be usable if you're thirsty.
2. This implies that the plumbing in question doesn't carry drinkable water.
3. Considering the choices given:
    - A: oil refineries
    - B: wall
    - C: show
    - D: own home
    - E: water fountain
4. B: Wall, although it has plumbing, this could actually distribute water depending on the context (a household, for instance), so we cannot directly eliminate this.
5. D: Own home and E: water fountain are locations where one would usually expect to find usable, drinkable water, so these options can be eliminated.
6. C: Show isn't a clear option since the term "show" is very vague and can mean numerous things, but usually, shows involve places where potable water could potentially be accessible.
7. A: Oil refineries are places where plumbing exists, but it's used for transferring oil, not water.
8. Therefore, of all the options given, the only place where you're guaranteed to find plumbing that wouldn't be of use if you're thirsty is in an oil refinery. Thus the answer is A: oil refineries.
Answer: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Rationales: 1. First, consider the meaning of each option. Working means carrying out tasks or duties, resting is being in a state of motionlessness or sleep, tiredness is a state of needing rest, accomplishing refers to achieving or completing a task or aim, momentum refers to the quantity of motion of a moving body.

2. The question is asking us to figure out what a person isn't doing when they are just starting to work.

3. Option A, working, is incorrect because the person is just starting to work, which means they are indeed working.

4. Option B, resting, may initially seem correct since a person who is just beginning to work is not resting. However, the question asks for what a person 'isn't doing yet', implying that this is something they will eventually do. Resting doesn't fit this description as resting is an opposite action to working. 

5. Option C, tiredness, is not correct because tiredness isn't something a person does. It's a state of being.

6. Option E, momentum, also doesn't fit because in this context, it is more of a state or characteristic the work might gain rather than an action performed by a person.

7. Considering all the options, we can deduce that option D, accomplishing, is the right answer. When a person is just beginning to work, they haven't had the time to accomplish or completely finish tasks yet. It is something they will eventually do, but haven't started doing yet, fitting the description given in the question.
Answer: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Rationales: 1. The question is asking about where one can find pens that carry a company logo.
2. This implies that the place needs to be a setting where company goods or merchandise are in use or distributed.
3. Option B, on a pencil, doesn't make sense because a pen is a different object from a pencil. So it's not possible to find a pen with a logo on a pencil.
4. Option C, write sentences on paper, is not a place at all, rather it is an action. This therefore doesn't fit the question's requirements.
5. While options D: school and E: backpack could potentially be places where a pen is placed, they are less associated with company logos.
6. Option A, office, however, is a common setting for businesses where official company merchandise, such as logoed pens, are commonly used or distributed to employees and visitors.
7. So, the answer is A: office.
Answer: A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Rationales: 1. The question is about a situation in which Billy is calling out to John.
2. When we "call out" to someone, it usually means to gain their attention or ask for something.
3. After calling out to someone, the inevitable expectation is a response from the person called. The reason behind Billy calling out is to initiate a dialogue or communication.
4. Therefore, we can rule out "silence," as it doesn't fit the context of expecting something after calling out to someone.
5. "Hanging up" and "whisper" are also easily ruled out as they don't fit the context of Billy calling out to John.
6. Although "communication" may seem a possible choice, it is commonly understood that communication is a process that begins with a response.
7. Hence, the most fitting answer to the question "Billy called out to John, and listened for what?" would be "B: response," as this is the immediate expectation after Billy's action of calling out.
Answer: B: response

Input: The lizard frightened the hiker, it's movements made what rustle? Choices:  A: garden B: trees C: books D: rocks E: bushes
Rationales: 1. The question asks what the lizard's movements caused to rustle.
2. Rustling is usually referred to when leaves or some other light, thin objects move against each other, so they produce a soft, light sound.
3. We can eliminate choices A and C. A garden cannot rustle, it is too large and includes many objects. Books do not make sense in this context because there is no reason to believe that a lizard and a hiker would be near books in this scenario.
4. We can also eliminate choices B and D. Trees are too large to rustle from a tiny lizard's movements. Rocks cannot rustle because they are hard, heavy objects, not light, thin objects.
5. That leaves us with choice E: bushes, which makes sense in the given context. Bushes are made up of multiple thin, light objects (leaves and small branches) that would produce a rustling sound if a lizard moved through them.
6. Therefore, the answer is E: bushes.
Answer: E: bushes

Input: The man spent big money and time maintaining his lawn, it was part of keeping up with the Joneses where? Choices:  A: front yard B: suburbia C: neighborhood D: back yard E: golf course
Rationales: 1. The question requires an understanding of the phrase "keeping up with the Joneses". This phrase typically refers to attempting to maintain social equality with one's peers or neighbors in terms of material possessions or lifestyle.
2. Hence, the context required for this question will be a setting where there is a competition or tendency among individuals or families to follow socio-economic trends.
3. Analyzing the given choices, 'front yard' and 'back yard' are too specific and do not specifically imply this competition or trend.
4. A 'golf course' is unrelated to the typical neighborhood setting which would contain such a trend.
5. The 'neighborhood' could be correct but it’s a broad term and does not necessarily imply there is the type of socio-economic competition described.
6. So, the term'suburbia' refers specifically to residential areas especially on the outskirts of a city and these regions are notorious for having residents that try to keep up with the societal trends of their neighbors.
7. Therefore the most plausible option is B: suburbia.
Answer: B: suburbia

Input: What would a human do if they want to get to a store that he or she can see? Choices:  A: cross road B: see around C: drink coffee D: dream dreams E: think critically
Rationales: The goal mentioned in the question is to get to a store that a person can see. 

This suggests that they are relatively close to the store but some sort of obstacle or distance is in the way.

The given choices are actions that
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o9-tcommonsenseqa-s1-rTrue
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:42<34:35, 42.35s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:23<33:28, 41.85s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:05<32:40, 41.71s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [02:47<31:58, 41.70s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [03:28<31:14, 41.65s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [04:10<30:33, 41.68s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [04:52<29:52, 41.69s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [05:33<29:10, 41.69s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [06:15<28:29, 41.69s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [06:57<27:46, 41.66s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [07:38<27:05, 41.68s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [08:20<26:23, 41.68s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [09:02<25:41, 41.67s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [09:43<24:58, 41.63s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [10:25<24:16, 41.61s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [11:06<23:35, 41.63s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [11:48<22:55, 41.68s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [12:30<22:13, 41.68s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [13:12<21:32, 41.69s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [13:53<20:48, 41.61s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [14:35<20:06, 41.60s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [15:16<19:25, 41.63s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [15:58<18:44, 41.65s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [16:40<18:02, 41.62s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [17:21<17:19, 41.59s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [18:03<16:42, 41.79s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [18:45<16:00, 41.76s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [19:27<15:17, 41.69s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [20:08<14:35, 41.67s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [20:50<13:52, 41.62s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [21:31<13:10, 41.63s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [22:13<12:28, 41.61s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [22:55<11:48, 41.66s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [23:36<11:06, 41.69s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [24:18<10:24, 41.64s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [25:00<09:42, 41.63s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [25:41<09:02, 41.70s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [26:23<08:19, 41.63s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [27:04<07:37, 41.62s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [27:46<06:55, 41.57s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [28:28<06:14, 41.58s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [29:09<05:32, 41.60s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [29:51<04:51, 41.61s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [30:32<04:09, 41.61s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [31:14<03:28, 41.62s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [31:56<02:46, 41.66s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [32:37<02:04, 41.65s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [33:19<01:23, 41.68s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [34:01<00:41, 41.65s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [34:42<00:00, 41.67s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [34:42<00:00, 41.66s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.0224} | lm_loss 11.4443 | avg. gen lenth: 415.396
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o1-tcommonsenseqa-s1-rFalse --seed 1 --num-out-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-12 19:16:52,119] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o1-tcommonsenseqa-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 1
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o1-tcommonsenseqa-s1-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  3%|█▎                                                 | 201/7473 [00:00<00:03, 2004.77it/s]  5%|██▊                                                | 405/7473 [00:00<00:03, 2018.57it/s]  8%|████▏                                              | 609/7473 [00:00<00:03, 2027.43it/s] 11%|█████▌                                             | 815/7473 [00:00<00:03, 2037.17it/s] 14%|██████▊                                           | 1023/7473 [00:00<00:03, 2050.02it/s] 16%|████████▏                                         | 1229/7473 [00:00<00:03, 2049.11it/s] 19%|█████████▌                                        | 1434/7473 [00:00<00:02, 2045.77it/s] 22%|██████████▉                                       | 1639/7473 [00:00<00:02, 2047.02it/s] 25%|████████████▎                                     | 1844/7473 [00:00<00:02, 1989.24it/s] 27%|█████████████▋                                    | 2046/7473 [00:01<00:02, 1998.33it/s] 30%|███████████████                                   | 2250/7473 [00:01<00:02, 2008.13it/s] 33%|████████████████▍                                 | 2457/7473 [00:01<00:02, 2024.39it/s] 36%|█████████████████▊                                | 2660/7473 [00:01<00:02, 1989.10it/s] 38%|███████████████████▏                              | 2865/7473 [00:01<00:02, 2006.66it/s] 41%|████████████████████▌                             | 3073/7473 [00:01<00:02, 2026.27it/s] 44%|█████████████████████▉                            | 3276/7473 [00:01<00:02, 2026.63it/s] 47%|███████████████████████▎                          | 3479/7473 [00:01<00:01, 2017.25it/s] 49%|████████████████████████▋                         | 3683/7473 [00:01<00:01, 2022.31it/s] 52%|██████████████████████████                        | 3886/7473 [00:01<00:01, 2010.95it/s] 55%|███████████████████████████▍                      | 4092/7473 [00:02<00:01, 2022.64it/s] 57%|████████████████████████████▋                     | 4295/7473 [00:02<00:01, 2004.46it/s] 60%|██████████████████████████████                    | 4499/7473 [00:02<00:01, 2012.98it/s] 63%|███████████████████████████████▍                  | 4703/7473 [00:02<00:01, 2019.67it/s] 66%|████████████████████████████████▊                 | 4907/7473 [00:02<00:01, 2024.54it/s] 68%|██████████████████████████████████▏               | 5111/7473 [00:02<00:01, 2027.57it/s] 71%|███████████████████████████████████▌              | 5314/7473 [00:02<00:01, 2007.87it/s] 74%|████████████████████████████████████▉             | 5515/7473 [00:02<00:01, 1451.19it/s] 77%|██████████████████████████████████████▎           | 5718/7473 [00:02<00:01, 1586.68it/s] 79%|███████████████████████████████████████▌          | 5920/7473 [00:03<00:00, 1693.85it/s] 82%|████████████████████████████████████████▉         | 6114/7473 [00:03<00:00, 1758.37it/s] 85%|██████████████████████████████████████████▎       | 6316/7473 [00:03<00:00, 1828.89it/s] 87%|███████████████████████████████████████████▌      | 6517/7473 [00:03<00:00, 1877.22it/s] 90%|████████████████████████████████████████████▉     | 6716/7473 [00:03<00:00, 1908.97it/s] 93%|██████████████████████████████████████████████▎   | 6918/7473 [00:03<00:00, 1940.45it/s] 95%|███████████████████████████████████████████████▌  | 7118/7473 [00:03<00:00, 1957.27it/s] 98%|████████████████████████████████████████████████▉ | 7321/7473 [00:03<00:00, 1975.78it/s]100%|██████████████████████████████████████████████████| 7473/7473 [00:03<00:00, 1945.81it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.48s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.42s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.55s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.57s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.39s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.44s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.54s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.59s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.76s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.94s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.79s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.98s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.84s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.02s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.90s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.09s/it]
[2023-08-12 19:17:48,691] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-12 19:17:58,818] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 19:17:58,819] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 19:17:58,819] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 19:17:58,819] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 19:17:58,819] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 19:17:58,819] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fe59c437fa0>
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fe59c438700>
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 19:17:58,821] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.3628993034362793 seconds
Loading extension module utils...
Time to load utils op: 0.30431580543518066 seconds
Loading extension module utils...
Time to load utils op: 0.40448498725891113 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Answer: A: oil refineries

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o1-tcommonsenseqa-s1-rFalse
Loading extension module utils...
Time to load utils op: 0.30457091331481934 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:59<48:31, 59.42s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:56<46:16, 57.84s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:15<31:29, 40.19s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [03:13<36:06, 47.09s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [04:10<38:12, 50.95s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [05:06<38:36, 52.66s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [06:04<38:57, 54.37s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [06:44<34:52, 49.82s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [07:42<35:38, 52.16s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [08:40<36:00, 54.02s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [09:37<35:46, 55.03s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [10:34<35:16, 55.69s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [11:31<34:37, 56.14s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [12:29<33:53, 56.49s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [13:24<32:46, 56.19s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [14:15<30:57, 54.65s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [15:14<30:42, 55.84s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [16:05<29:00, 54.38s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [16:51<26:48, 51.88s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [17:32<24:16, 48.56s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [18:29<24:44, 51.18s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [19:24<24:22, 52.25s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [19:54<20:30, 45.58s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [20:50<21:10, 48.88s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [21:37<20:04, 48.20s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [21:50<15:05, 37.72s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [22:43<16:13, 42.35s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [23:40<17:04, 46.56s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [24:37<17:23, 49.67s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [25:34<17:20, 52.00s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [26:17<15:37, 49.33s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [27:03<14:26, 48.14s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [28:00<14:26, 50.96s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [28:45<13:07, 49.19s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [29:42<12:53, 51.57s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [30:40<12:26, 53.35s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [30:54<08:59, 41.51s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [31:41<08:38, 43.21s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [32:36<08:35, 46.88s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [33:30<08:10, 49.01s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [34:09<06:53, 45.97s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [35:07<06:35, 49.48s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [35:50<05:33, 47.64s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [36:48<05:03, 50.58s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [37:45<04:23, 52.63s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [38:36<03:28, 52.21s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [39:34<02:41, 53.82s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [40:07<01:35, 47.50s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [41:03<00:50, 50.08s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [42:00<00:00, 52.23s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [42:00<00:00, 50.41s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.6229} | lm_loss 9.6782 | avg. gen lenth: 218.528
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o2-tcommonsenseqa-s1-rFalse --seed 1 --num-out-domain 2
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[nltk_data]   Package punkt is already up-to-date!
[2023-08-12 20:00:06,072] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o2-tcommonsenseqa-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 2
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o2-tcommonsenseqa-s1-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  2%|█▏                                                 | 166/7473 [00:00<00:04, 1657.21it/s]  4%|██▎                                                | 336/7473 [00:00<00:04, 1678.18it/s]  7%|███▍                                               | 504/7473 [00:00<00:04, 1666.24it/s]  9%|████▌                                              | 675/7473 [00:00<00:04, 1680.25it/s] 11%|█████▊                                             | 846/7473 [00:00<00:03, 1688.28it/s] 14%|██████▊                                           | 1018/7473 [00:00<00:03, 1697.39it/s] 16%|███████▉                                          | 1188/7473 [00:00<00:03, 1696.70it/s] 18%|█████████                                         | 1359/7473 [00:00<00:03, 1698.04it/s] 20%|██████████▏                                       | 1529/7473 [00:00<00:03, 1695.40it/s] 23%|███████████▎                                      | 1699/7473 [00:01<00:03, 1656.25it/s] 25%|████████████▍                                     | 1866/7473 [00:01<00:03, 1660.09it/s] 27%|█████████████▌                                    | 2034/7473 [00:01<00:03, 1663.20it/s] 29%|██████████████▋                                   | 2201/7473 [00:01<00:03, 1665.19it/s] 32%|███████████████▊                                  | 2370/7473 [00:01<00:03, 1671.00it/s] 34%|████████████████▉                                 | 2538/7473 [00:01<00:03, 1639.66it/s] 36%|██████████████████▏                               | 2710/7473 [00:01<00:02, 1662.23it/s] 39%|███████████████████▎                              | 2880/7473 [00:01<00:02, 1670.98it/s] 41%|████████████████████▍                             | 3052/7473 [00:01<00:02, 1684.33it/s] 43%|█████████████████████▌                            | 3221/7473 [00:01<00:02, 1673.22it/s] 45%|██████████████████████▋                           | 3389/7473 [00:02<00:02, 1672.57it/s] 48%|███████████████████████▊                          | 3557/7473 [00:02<00:02, 1672.27it/s] 50%|████████████████████████▉                         | 3725/7473 [00:02<00:02, 1668.90it/s] 52%|██████████████████████████                        | 3892/7473 [00:02<00:02, 1667.48it/s] 54%|███████████████████████████▏                      | 4063/7473 [00:02<00:02, 1680.11it/s] 57%|████████████████████████████▋                     | 4295/7473 [00:02<00:01, 1870.06it/s] 61%|██████████████████████████████▍                   | 4551/7473 [00:02<00:01, 2074.96it/s] 64%|████████████████████████████████▏                 | 4804/7473 [00:02<00:01, 2210.15it/s] 68%|█████████████████████████████████▊                | 5061/7473 [00:02<00:01, 2316.81it/s] 71%|███████████████████████████████████▍              | 5304/7473 [00:02<00:00, 2348.92it/s] 74%|█████████████████████████████████████             | 5539/7473 [00:03<00:00, 2053.93it/s] 78%|██████████████████████████████████████▊           | 5795/7473 [00:03<00:00, 2191.55it/s] 81%|████████████████████████████████████████▍         | 6037/7473 [00:03<00:00, 2253.65it/s] 84%|██████████████████████████████████████████        | 6295/7473 [00:03<00:00, 2344.53it/s] 88%|███████████████████████████████████████████▊      | 6546/7473 [00:03<00:00, 2391.97it/s] 91%|█████████████████████████████████████████████▍    | 6799/7473 [00:03<00:00, 2430.81it/s] 94%|███████████████████████████████████████████████▏  | 7053/7473 [00:03<00:00, 2460.55it/s] 98%|████████████████████████████████████████████████▉ | 7308/7473 [00:03<00:00, 2486.04it/s]100%|██████████████████████████████████████████████████| 7473/7473 [00:03<00:00, 1944.92it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.10s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.14s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.87s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.74s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:09<00:04,  4.94s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:09<00:04,  4.97s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.49s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.81s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.32s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.50s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.35s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.54s/it]
[2023-08-12 20:01:00,577] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.82s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.04s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:16<00:00,  5.18s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:16<00:00,  5.34s/it]
[2023-08-12 20:01:12,122] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 20:01:12,123] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 20:01:12,124] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 20:01:12,124] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 20:01:12,124] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 20:01:12,124] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 20:01:12,124] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 20:01:12,124] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 20:01:12,124] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 20:01:12,124] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 20:01:12,124] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 20:01:12,124] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f890f77efa0>
[2023-08-12 20:01:12,124] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f890f77c700>
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 20:01:12,126] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.3788719177246094 seconds
Loading extension module utils...
Time to load utils op: 0.3041188716888428 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Answer: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Answer: D: accomplishing

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o2-tcommonsenseqa-s1-rFalse
Loading extension module utils...
Time to load utils op: 0.30420637130737305 seconds
Loading extension module utils...
Time to load utils op: 0.4044463634490967 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:40<32:56, 40.33s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:34<39:00, 48.75s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:21<37:28, 47.85s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [02:47<29:56, 39.05s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [03:21<27:53, 37.19s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [04:04<28:43, 39.16s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [04:51<29:55, 41.75s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [05:18<25:54, 37.01s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [05:59<26:08, 38.25s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [06:57<29:32, 44.32s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [07:12<23:09, 35.64s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [08:08<26:29, 41.83s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [09:06<28:39, 46.48s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [10:01<29:31, 49.20s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [10:58<29:58, 51.38s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [11:52<29:34, 52.19s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [12:40<28:09, 51.19s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [13:38<28:19, 53.10s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [14:29<27:01, 52.31s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [15:24<26:37, 53.24s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [15:42<20:39, 42.74s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [16:19<19:06, 40.95s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [17:15<20:26, 45.43s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [18:11<21:01, 48.52s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [19:00<20:17, 48.70s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [19:56<20:22, 50.95s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [20:45<19:20, 50.45s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [21:41<19:05, 52.08s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [22:36<18:33, 53.02s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [23:30<17:42, 53.11s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [24:26<17:07, 54.08s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [25:06<14:55, 49.77s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [26:01<14:33, 51.41s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [26:56<14:02, 52.67s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [27:52<13:21, 53.44s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [28:48<12:38, 54.18s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [29:44<11:51, 54.72s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [30:29<10:22, 51.88s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [31:24<09:42, 52.94s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [32:06<08:15, 49.55s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [33:02<07:43, 51.50s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [33:53<06:52, 51.51s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [34:44<05:57, 51.10s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [35:06<04:14, 42.44s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [35:38<03:17, 39.46s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [36:34<02:57, 44.40s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [36:53<01:50, 36.77s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [37:53<01:27, 43.52s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [38:34<00:43, 43.03s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [38:48<00:00, 34.15s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [38:48<00:00, 46.57s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.5849} | lm_loss 9.6312 | avg. gen lenth: 205.82
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o3-tcommonsenseqa-s1-rFalse --seed 1 --num-out-domain 3
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-12 20:40:30,135] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o3-tcommonsenseqa-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 3
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o3-tcommonsenseqa-s1-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  2%|▉                                                  | 135/7473 [00:00<00:05, 1349.08it/s]  4%|█▉                                                 | 275/7473 [00:00<00:05, 1373.81it/s]  6%|██▊                                                | 414/7473 [00:00<00:05, 1378.38it/s]  7%|███▊                                               | 553/7473 [00:00<00:05, 1380.21it/s]  9%|████▋                                              | 693/7473 [00:00<00:04, 1384.79it/s] 11%|█████▋                                             | 833/7473 [00:00<00:04, 1389.74it/s] 13%|██████▋                                            | 974/7473 [00:00<00:04, 1394.11it/s] 15%|███████▍                                          | 1116/7473 [00:00<00:04, 1400.33it/s] 17%|████████▍                                         | 1257/7473 [00:00<00:04, 1368.84it/s] 19%|█████████▎                                        | 1395/7473 [00:01<00:04, 1367.59it/s] 21%|██████████▎                                       | 1536/7473 [00:01<00:04, 1380.16it/s] 22%|███████████▏                                      | 1675/7473 [00:01<00:04, 1377.84it/s] 24%|████████████▏                                     | 1815/7473 [00:01<00:04, 1383.14it/s] 26%|█████████████                                     | 1954/7473 [00:01<00:04, 1375.70it/s] 28%|██████████████                                    | 2094/7473 [00:01<00:03, 1381.32it/s] 30%|██████████████▉                                   | 2234/7473 [00:01<00:03, 1384.58it/s] 32%|███████████████▉                                  | 2373/7473 [00:01<00:03, 1384.01it/s] 34%|████████████████▊                                 | 2514/7473 [00:01<00:03, 1390.04it/s] 36%|█████████████████▊                                | 2654/7473 [00:01<00:03, 1356.84it/s] 37%|██████████████████▋                               | 2792/7473 [00:02<00:03, 1363.03it/s] 39%|███████████████████▋                              | 2934/7473 [00:02<00:03, 1377.29it/s] 41%|████████████████████▌                             | 3074/7473 [00:02<00:03, 1382.12it/s] 43%|█████████████████████▍                            | 3213/7473 [00:02<00:03, 1378.51it/s] 45%|██████████████████████▍                           | 3352/7473 [00:02<00:02, 1379.89it/s] 47%|███████████████████████▎                          | 3491/7473 [00:02<00:02, 1377.06it/s] 49%|████████████████████████▎                         | 3630/7473 [00:02<00:02, 1380.39it/s] 51%|█████████████████████████▌                        | 3826/7473 [00:02<00:02, 1553.06it/s] 54%|███████████████████████████                       | 4039/7473 [00:02<00:01, 1723.27it/s] 57%|████████████████████████████▍                     | 4249/7473 [00:02<00:01, 1833.77it/s] 60%|█████████████████████████████▊                    | 4456/7473 [00:03<00:01, 1902.49it/s] 62%|███████████████████████████████▏                  | 4669/7473 [00:03<00:01, 1968.01it/s] 65%|████████████████████████████████▋                 | 4880/7473 [00:03<00:01, 2009.75it/s] 68%|██████████████████████████████████                | 5093/7473 [00:03<00:01, 2043.95it/s] 71%|███████████████████████████████████▍              | 5298/7473 [00:03<00:01, 2027.81it/s] 74%|████████████████████████████████████▊             | 5501/7473 [00:03<00:01, 1555.71it/s] 76%|██████████████████████████████████████▏           | 5713/7473 [00:03<00:01, 1693.78it/s] 79%|███████████████████████████████████████▋          | 5923/7473 [00:03<00:00, 1798.36it/s] 82%|█████████████████████████████████████████         | 6133/7473 [00:03<00:00, 1879.24it/s] 85%|██████████████████████████████████████████▍       | 6347/7473 [00:04<00:00, 1951.38it/s] 88%|███████████████████████████████████████████▊      | 6556/7473 [00:04<00:00, 1989.48it/s] 91%|█████████████████████████████████████████████▎    | 6766/7473 [00:04<00:00, 2018.96it/s] 93%|██████████████████████████████████████████████▋   | 6979/7473 [00:04<00:00, 2048.65it/s] 96%|████████████████████████████████████████████████  | 7189/7473 [00:04<00:00, 2061.65it/s] 99%|█████████████████████████████████████████████████▌| 7399/7473 [00:04<00:00, 2072.95it/s]100%|██████████████████████████████████████████████████| 7473/7473 [00:04<00:00, 1632.92it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.14s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.18s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.27s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.54s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.38s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.36s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.44s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.62s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.69s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.85s/it]
[2023-08-12 20:41:26,599] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.69s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.86s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.89s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.01s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.96s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.13s/it]
[2023-08-12 20:41:37,574] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 20:41:37,574] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fa611dbdb20>
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fa611dbd8b0>
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 20:41:37,577] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 20:41:37,577] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 20:41:37,577] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 20:41:37,577] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.3735802173614502 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Answer: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Answer: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Answer: A: office

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o3-tcommonsenseqa-s1-rFalse
Loading extension module utils...
Loading extension module utils...
Time to load utils op: 0.304257869720459 seconds
Time to load utils op: 0.40454936027526855 seconds
Loading extension module utils...
Time to load utils op: 0.4040868282318115 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:56<45:52, 56.17s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:51<44:32, 55.68s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:47<43:33, 55.61s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [03:42<42:33, 55.52s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [04:38<41:41, 55.58s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [05:26<38:54, 53.07s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [05:54<32:07, 44.83s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [06:49<33:41, 48.14s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [07:41<33:49, 49.51s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [08:37<34:12, 51.31s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [09:32<34:02, 52.38s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [09:53<27:15, 43.05s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [10:49<28:56, 46.95s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [11:19<24:59, 41.66s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [12:06<25:16, 43.34s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [12:42<23:18, 41.13s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [13:37<25:00, 45.47s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [14:27<24:51, 46.61s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [14:42<19:10, 37.10s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [14:56<15:03, 30.13s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [15:51<18:14, 37.74s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [16:47<20:07, 43.12s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [17:19<17:59, 39.99s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [17:56<16:54, 39.03s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [18:27<15:15, 36.61s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [19:23<16:59, 42.48s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [20:01<15:46, 41.16s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [20:56<16:34, 45.18s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [21:51<16:52, 48.21s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [22:38<15:52, 47.64s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [23:33<15:47, 49.86s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [24:04<13:17, 44.30s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [24:44<12:13, 43.16s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [25:37<12:15, 45.94s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [26:08<10:22, 41.51s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [27:03<10:39, 45.65s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [27:58<10:28, 48.36s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [28:18<07:57, 39.78s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [28:55<07:10, 39.16s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [29:48<07:12, 43.21s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [30:42<06:58, 46.53s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [31:05<05:14, 39.35s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [32:00<05:08, 44.06s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [32:28<03:55, 39.23s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [32:56<02:59, 35.90s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [33:51<02:46, 41.71s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [34:47<02:17, 45.82s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [35:44<01:38, 49.14s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [36:16<00:44, 44.04s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [36:50<00:00, 41.13s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [36:50<00:00, 44.21s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.5608} | lm_loss 9.6357 | avg. gen lenth: 180.396
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o4-tcommonsenseqa-s1-rFalse --seed 1 --num-out-domain 4
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date![nltk_data]   Package punkt is already up-to-date![nltk_data]   Package punkt is already up-to-date!


[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-12 21:20:58,952] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o4-tcommonsenseqa-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 4
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o4-tcommonsenseqa-s1-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  2%|▊                                                  | 119/7473 [00:00<00:06, 1187.81it/s]  3%|█▋                                                 | 242/7473 [00:00<00:05, 1207.91it/s]  5%|██▍                                                | 363/7473 [00:00<00:05, 1208.56it/s]  6%|███▎                                               | 484/7473 [00:00<00:05, 1204.69it/s]  8%|████▏                                              | 607/7473 [00:00<00:05, 1210.26it/s] 10%|████▉                                              | 731/7473 [00:00<00:05, 1217.93it/s] 11%|█████▊                                             | 853/7473 [00:00<00:05, 1218.15it/s] 13%|██████▋                                            | 976/7473 [00:00<00:05, 1220.51it/s] 15%|███████▎                                          | 1099/7473 [00:00<00:05, 1199.05it/s] 16%|████████▏                                         | 1219/7473 [00:01<00:05, 1198.09it/s] 18%|████████▉                                         | 1342/7473 [00:01<00:05, 1205.00it/s] 20%|█████████▊                                        | 1463/7473 [00:01<00:04, 1203.69it/s] 21%|██████████▌                                       | 1585/7473 [00:01<00:04, 1206.29it/s] 23%|███████████▍                                      | 1708/7473 [00:01<00:04, 1211.34it/s] 24%|████████████▏                                     | 1830/7473 [00:01<00:04, 1210.76it/s] 26%|█████████████                                     | 1952/7473 [00:01<00:04, 1207.99it/s] 28%|█████████████▉                                    | 2074/7473 [00:01<00:04, 1210.39it/s] 29%|██████████████▋                                   | 2196/7473 [00:01<00:04, 1211.46it/s] 31%|███████████████▌                                  | 2318/7473 [00:01<00:04, 1207.61it/s] 33%|████████████████▎                                 | 2440/7473 [00:02<00:04, 1210.16it/s] 34%|█████████████████▏                                | 2562/7473 [00:02<00:04, 1174.63it/s] 36%|█████████████████▉                                | 2685/7473 [00:02<00:04, 1190.53it/s] 38%|██████████████████▉                               | 2838/7473 [00:02<00:03, 1288.68it/s] 40%|████████████████████▏                             | 3025/7473 [00:02<00:03, 1459.82it/s] 43%|█████████████████████▍                            | 3208/7473 [00:02<00:02, 1568.20it/s] 45%|██████████████████████▋                           | 3392/7473 [00:02<00:02, 1647.95it/s] 48%|███████████████████████▉                          | 3577/7473 [00:02<00:02, 1705.68it/s] 50%|█████████████████████████▏                        | 3760/7473 [00:02<00:02, 1740.13it/s] 53%|██████████████████████████▍                       | 3943/7473 [00:02<00:02, 1764.67it/s] 55%|███████████████████████████▌                      | 4127/7473 [00:03<00:01, 1785.29it/s] 58%|████████████████████████████▊                     | 4311/7473 [00:03<00:01, 1800.12it/s] 60%|██████████████████████████████                    | 4495/7473 [00:03<00:01, 1809.54it/s] 63%|███████████████████████████████▎                  | 4679/7473 [00:03<00:01, 1816.05it/s] 65%|████████████████████████████████▌                 | 4861/7473 [00:03<00:01, 1815.07it/s] 68%|█████████████████████████████████▊                | 5045/7473 [00:03<00:01, 1821.56it/s] 70%|██████████████████████████████████▉               | 5231/7473 [00:03<00:01, 1830.61it/s] 72%|████████████████████████████████████▏             | 5415/7473 [00:03<00:01, 1794.19it/s] 75%|█████████████████████████████████████▍            | 5595/7473 [00:03<00:01, 1387.63it/s] 77%|██████████████████████████████████████▋           | 5778/7473 [00:04<00:01, 1495.10it/s] 80%|███████████████████████████████████████▊          | 5959/7473 [00:04<00:00, 1576.52it/s] 82%|█████████████████████████████████████████         | 6143/7473 [00:04<00:00, 1647.18it/s] 85%|██████████████████████████████████████████▎       | 6328/7473 [00:04<00:00, 1702.31it/s] 87%|███████████████████████████████████████████▌      | 6510/7473 [00:04<00:00, 1734.79it/s] 90%|████████████████████████████████████████████▊     | 6693/7473 [00:04<00:00, 1761.65it/s] 92%|██████████████████████████████████████████████    | 6876/7473 [00:04<00:00, 1780.48it/s] 94%|███████████████████████████████████████████████▏  | 7059/7473 [00:04<00:00, 1794.08it/s] 97%|████████████████████████████████████████████████▍ | 7243/7473 [00:04<00:00, 1805.83it/s] 99%|█████████████████████████████████████████████████▋| 7426/7473 [00:04<00:00, 1811.99it/s]100%|██████████████████████████████████████████████████| 7473/7473 [00:04<00:00, 1503.45it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.04s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.09s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.34s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.66s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.00s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.05s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.51s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.46s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.46s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.62s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.50s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.65s/it]
[2023-08-12 21:21:55,080] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.82s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.99s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.79s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.99s/it]
[2023-08-12 21:22:04,925] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 21:22:04,926] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 21:22:04,926] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 21:22:04,926] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 21:22:04,926] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 21:22:04,926] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fe04ce6bfa0>
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fe04ce85700>
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 21:22:04,929] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 21:22:04,929] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 21:22:04,929] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 21:22:04,929] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 21:22:04,929] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.40537166595458984 seconds
Loading extension module utils...
Time to load utils op: 0.3066091537475586 seconds
Loading extension module utils...
Time to load utils op: 0.30457615852355957 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Answer: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Answer: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Answer: A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Answer: B: response

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o4-tcommonsenseqa-s1-rFalse
Loading extension module utils...
Time to load utils op: 0.30423474311828613 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:55<45:00, 55.12s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:48<43:20, 54.17s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:42<42:29, 54.25s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [03:37<41:40, 54.37s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [04:20<37:48, 50.40s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [05:09<36:33, 49.84s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [05:35<30:02, 41.93s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [05:59<25:21, 36.24s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [06:53<28:33, 41.78s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [07:42<29:19, 43.99s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [08:35<30:27, 46.87s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [09:10<27:23, 43.25s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [09:43<24:47, 40.19s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [10:39<26:52, 44.80s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [11:00<22:01, 37.76s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [11:55<24:20, 42.94s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [12:48<25:16, 45.95s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [13:20<22:12, 41.65s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [13:43<18:35, 35.99s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [14:38<20:51, 41.73s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [15:00<17:19, 35.84s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [15:44<17:57, 38.48s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [16:23<17:23, 38.66s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [17:18<18:45, 43.28s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [17:58<17:38, 42.35s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [18:12<13:37, 34.07s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [19:04<15:01, 39.22s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [19:38<13:49, 37.70s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [20:11<12:41, 36.26s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [21:07<14:02, 42.12s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [22:01<14:29, 45.79s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [22:17<11:03, 36.85s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [23:11<11:53, 41.97s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [23:52<11:05, 41.60s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [24:47<11:25, 45.70s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [25:37<10:58, 47.02s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [26:32<10:43, 49.47s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [27:27<10:14, 51.18s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [28:22<09:35, 52.32s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [28:54<07:42, 46.27s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [29:51<07:25, 49.50s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [30:36<06:25, 48.14s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [31:31<05:49, 49.98s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [31:51<04:07, 41.18s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [32:28<03:18, 39.72s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [33:22<02:56, 44.22s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [34:01<02:07, 42.55s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [34:40<01:22, 41.45s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [35:14<00:39, 39.37s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [35:24<00:00, 30.59s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [35:24<00:00, 42.50s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.2885} | lm_loss 9.686 | avg. gen lenth: 181.084
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o5-tcommonsenseqa-s1-rFalse --seed 1 --num-out-domain 5
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-12 21:57:52,495] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o5-tcommonsenseqa-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 5
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o5-tcommonsenseqa-s1-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  1%|▋                                                  | 108/7473 [00:00<00:06, 1074.48it/s]  3%|█▍                                                 | 219/7473 [00:00<00:06, 1092.23it/s]  4%|██▏                                                | 329/7473 [00:00<00:06, 1091.88it/s]  6%|██▉                                                | 439/7473 [00:00<00:06, 1087.62it/s]  7%|███▋                                               | 549/7473 [00:00<00:06, 1088.65it/s]  9%|████▍                                              | 658/7473 [00:00<00:06, 1088.65it/s] 10%|█████▎                                             | 770/7473 [00:00<00:06, 1095.90it/s] 12%|██████                                             | 880/7473 [00:00<00:06, 1095.58it/s] 13%|██████▊                                            | 990/7473 [00:00<00:05, 1081.97it/s] 15%|███████▎                                          | 1099/7473 [00:01<00:05, 1084.00it/s] 16%|████████                                          | 1208/7473 [00:01<00:05, 1083.08it/s] 18%|████████▊                                         | 1319/7473 [00:01<00:05, 1088.33it/s] 19%|█████████▌                                        | 1428/7473 [00:01<00:05, 1085.49it/s] 21%|██████████▎                                       | 1539/7473 [00:01<00:05, 1091.99it/s] 22%|███████████                                       | 1649/7473 [00:01<00:05, 1086.28it/s] 24%|███████████▊                                      | 1760/7473 [00:01<00:05, 1091.37it/s] 25%|████████████▌                                     | 1870/7473 [00:01<00:05, 1088.16it/s] 26%|█████████████▏                                    | 1979/7473 [00:01<00:05, 1088.14it/s] 28%|█████████████▉                                    | 2088/7473 [00:01<00:04, 1084.98it/s] 29%|██████████████▋                                   | 2198/7473 [00:02<00:04, 1086.62it/s] 32%|███████████████▊                                  | 2361/7473 [00:02<00:04, 1246.96it/s] 34%|████████████████▊                                 | 2520/7473 [00:02<00:03, 1335.81it/s] 36%|█████████████████▉                                | 2688/7473 [00:02<00:03, 1437.53it/s] 38%|███████████████████                               | 2855/7473 [00:02<00:03, 1505.06it/s] 40%|████████████████████▏                             | 3023/7473 [00:02<00:02, 1556.48it/s] 43%|█████████████████████▎                            | 3189/7473 [00:02<00:02, 1586.01it/s] 45%|██████████████████████▍                           | 3356/7473 [00:02<00:02, 1608.16it/s] 47%|███████████████████████▌                          | 3522/7473 [00:02<00:02, 1621.46it/s] 49%|████████████████████████▋                         | 3689/7473 [00:02<00:02, 1633.59it/s] 52%|█████████████████████████▊                        | 3856/7473 [00:03<00:02, 1641.95it/s] 54%|██████████████████████████▉                       | 4023/7473 [00:03<00:02, 1650.14it/s] 56%|████████████████████████████                      | 4189/7473 [00:03<00:01, 1649.32it/s] 58%|█████████████████████████████▏                    | 4356/7473 [00:03<00:01, 1653.91it/s] 61%|██████████████████████████████▎                   | 4522/7473 [00:03<00:01, 1653.84it/s] 63%|███████████████████████████████▎                  | 4689/7473 [00:03<00:01, 1658.34it/s] 65%|████████████████████████████████▍                 | 4856/7473 [00:03<00:01, 1659.08it/s] 67%|█████████████████████████████████▌                | 5023/7473 [00:03<00:01, 1659.86it/s] 69%|██████████████████████████████████▋               | 5191/7473 [00:03<00:01, 1663.27it/s] 72%|███████████████████████████████████▊              | 5358/7473 [00:03<00:01, 1625.68it/s] 74%|████████████████████████████████████▉             | 5521/7473 [00:04<00:01, 1247.41it/s] 76%|██████████████████████████████████████            | 5688/7473 [00:04<00:01, 1348.56it/s] 78%|███████████████████████████████████████▏          | 5855/7473 [00:04<00:01, 1431.30it/s] 81%|████████████████████████████████████████▎         | 6020/7473 [00:04<00:00, 1489.66it/s] 83%|█████████████████████████████████████████▍        | 6188/7473 [00:04<00:00, 1541.56it/s] 85%|██████████████████████████████████████████▌       | 6356/7473 [00:04<00:00, 1579.73it/s] 87%|███████████████████████████████████████████▋      | 6523/7473 [00:04<00:00, 1602.97it/s] 90%|████████████████████████████████████████████▊     | 6690/7473 [00:04<00:00, 1622.20it/s] 92%|█████████████████████████████████████████████▊    | 6856/7473 [00:04<00:00, 1632.89it/s] 94%|██████████████████████████████████████████████▉   | 7024/7473 [00:05<00:00, 1646.21it/s] 96%|████████████████████████████████████████████████  | 7190/7473 [00:05<00:00, 1646.65it/s] 98%|█████████████████████████████████████████████████▏| 7357/7473 [00:05<00:00, 1652.96it/s]100%|██████████████████████████████████████████████████| 7473/7473 [00:05<00:00, 1406.15it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:04<00:09,  4.95s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.17s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.58s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.57s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:09<00:04,  5.00s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.03s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.48s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.39s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.34s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.51s/it]
[2023-08-12 21:58:48,376] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.42s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.60s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.84s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.03s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.74s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.94s/it]
[2023-08-12 21:58:59,554] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 21:58:59,555] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fd98f20efa0>
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fd98f22f700>
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 21:58:59,557] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.3790452480316162 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Answer: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Answer: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Answer: A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Answer: B: response

Input: The lizard frightened the hiker, it's movements made what rustle? Choices:  A: garden B: trees C: books D: rocks E: bushes
Answer: E: bushes

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o5-tcommonsenseqa-s1-rFalse
Loading extension module utils...
Time to load utils op: 0.3044147491455078 seconds
Loading extension module utils...
Time to load utils op: 0.3046276569366455 seconds
Loading extension module utils...
Time to load utils op: 0.30423474311828613 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:54<44:35, 54.60s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:47<42:50, 53.55s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:40<41:50, 53.41s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [03:33<40:45, 53.17s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [04:27<40:11, 53.59s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [05:05<35:14, 48.05s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [05:32<29:42, 41.46s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [06:26<31:41, 45.27s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [06:49<26:15, 38.42s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [07:12<22:26, 33.65s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [07:49<22:30, 34.64s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [08:33<23:37, 37.30s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [08:51<19:25, 31.51s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [09:46<23:10, 38.63s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [10:22<22:06, 37.89s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [11:16<24:11, 42.68s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [11:48<21:48, 39.66s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [12:42<23:26, 43.95s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [13:32<23:39, 45.80s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [14:25<23:54, 47.82s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [15:16<23:35, 48.81s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [16:02<22:18, 47.80s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [16:55<22:13, 49.39s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [17:30<19:36, 45.25s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [17:59<16:48, 40.36s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [18:30<14:57, 37.40s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [19:24<16:14, 42.36s/it]