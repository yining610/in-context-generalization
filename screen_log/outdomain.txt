PYTHONPATH=/home/ylu130/workspace/in-context-generalization
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o1-tcommonsenseqa-s1-rTrue --seed 1 --rationales --num-out-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-12 14:45:42,402] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date![nltk_data]   Package punkt is already up-to-date!

arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o1-tcommonsenseqa-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 1
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o1-tcommonsenseqa-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  1%|▋                                                    | 92/7473 [00:00<00:08, 916.29it/s]  2%|█▎                                                  | 185/7473 [00:00<00:07, 923.44it/s]  4%|█▉                                                  | 278/7473 [00:00<00:07, 925.97it/s]  5%|██▌                                                 | 371/7473 [00:00<00:07, 907.16it/s]  6%|███▏                                                | 463/7473 [00:00<00:07, 911.50it/s]  7%|███▊                                                | 556/7473 [00:00<00:07, 915.62it/s]  9%|████▌                                               | 648/7473 [00:00<00:07, 916.99it/s] 10%|█████▏                                              | 743/7473 [00:00<00:07, 926.60it/s] 11%|█████▊                                              | 836/7473 [00:00<00:07, 927.21it/s] 12%|██████▍                                             | 930/7473 [00:01<00:07, 928.33it/s] 14%|██████▉                                            | 1024/7473 [00:01<00:06, 931.75it/s] 15%|███████▋                                           | 1118/7473 [00:01<00:06, 933.49it/s] 16%|████████▎                                          | 1212/7473 [00:01<00:06, 929.38it/s] 17%|████████▉                                          | 1305/7473 [00:01<00:06, 928.53it/s] 19%|█████████▌                                         | 1398/7473 [00:01<00:06, 926.50it/s] 20%|██████████▏                                        | 1492/7473 [00:01<00:06, 929.89it/s] 21%|██████████▊                                        | 1585/7473 [00:01<00:06, 927.98it/s] 22%|███████████▍                                       | 1678/7473 [00:01<00:06, 927.20it/s] 24%|████████████                                       | 1771/7473 [00:01<00:06, 927.55it/s] 25%|████████████▋                                      | 1864/7473 [00:02<00:06, 923.96it/s] 26%|█████████████▎                                     | 1957/7473 [00:02<00:05, 921.35it/s] 27%|█████████████▉                                     | 2051/7473 [00:02<00:05, 925.27it/s] 29%|██████████████▋                                    | 2144/7473 [00:02<00:05, 923.63it/s] 30%|███████████████▎                                   | 2238/7473 [00:02<00:05, 927.24it/s] 31%|███████████████▉                                   | 2331/7473 [00:02<00:05, 926.18it/s] 32%|████████████████▌                                  | 2424/7473 [00:02<00:05, 917.49it/s] 34%|█████████████████▏                                 | 2516/7473 [00:02<00:05, 917.43it/s] 35%|█████████████████▊                                 | 2608/7473 [00:02<00:05, 911.46it/s] 37%|██████████████████▍                               | 2750/7473 [00:02<00:04, 1061.46it/s] 39%|███████████████████▎                              | 2893/7473 [00:03<00:03, 1170.35it/s] 41%|████████████████████▎                             | 3036/7473 [00:03<00:03, 1247.36it/s] 43%|█████████████████████▎                            | 3177/7473 [00:03<00:03, 1295.02it/s] 44%|██████████████████████▏                           | 3319/7473 [00:03<00:03, 1330.90it/s] 46%|███████████████████████▏                          | 3458/7473 [00:03<00:02, 1347.28it/s] 48%|████████████████████████                          | 3601/7473 [00:03<00:02, 1371.40it/s] 50%|█████████████████████████                         | 3741/7473 [00:03<00:02, 1378.42it/s] 52%|█████████████████████████▉                        | 3882/7473 [00:03<00:02, 1386.36it/s] 54%|██████████████████████████▉                       | 4025/7473 [00:03<00:02, 1399.23it/s] 56%|███████████████████████████▊                      | 4165/7473 [00:03<00:02, 1390.36it/s] 58%|████████████████████████████▊                     | 4306/7473 [00:04<00:02, 1395.09it/s] 60%|█████████████████████████████▊                    | 4447/7473 [00:04<00:02, 1398.84it/s] 61%|██████████████████████████████▋                   | 4589/7473 [00:04<00:02, 1403.38it/s] 63%|███████████████████████████████▋                  | 4731/7473 [00:04<00:01, 1406.43it/s] 65%|████████████████████████████████▌                 | 4872/7473 [00:04<00:01, 1406.11it/s] 67%|█████████████████████████████████▌                | 5015/7473 [00:04<00:01, 1410.37it/s] 69%|██████████████████████████████████▌               | 5157/7473 [00:04<00:01, 1410.36it/s] 71%|███████████████████████████████████▍              | 5299/7473 [00:04<00:01, 1374.48it/s] 73%|████████████████████████████████████▍             | 5439/7473 [00:04<00:01, 1381.92it/s] 75%|█████████████████████████████████████▎            | 5578/7473 [00:05<00:01, 1150.19it/s] 77%|██████████████████████████████████████▎           | 5718/7473 [00:05<00:01, 1214.35it/s] 78%|███████████████████████████████████████▏          | 5859/7473 [00:05<00:01, 1266.48it/s] 80%|████████████████████████████████████████▏         | 5998/7473 [00:05<00:01, 1299.01it/s] 82%|█████████████████████████████████████████         | 6140/7473 [00:05<00:01, 1330.87it/s] 84%|██████████████████████████████████████████        | 6282/7473 [00:05<00:00, 1355.21it/s] 86%|██████████████████████████████████████████▉       | 6422/7473 [00:05<00:00, 1365.80it/s] 88%|███████████████████████████████████████████▉      | 6560/7473 [00:05<00:00, 1369.58it/s] 90%|████████████████████████████████████████████▊     | 6700/7473 [00:05<00:00, 1376.62it/s] 92%|█████████████████████████████████████████████▊    | 6839/7473 [00:05<00:00, 1379.72it/s] 93%|██████████████████████████████████████████████▋   | 6981/7473 [00:06<00:00, 1389.18it/s] 95%|███████████████████████████████████████████████▋  | 7121/7473 [00:06<00:00, 1387.27it/s] 97%|████████████████████████████████████████████████▌ | 7262/7473 [00:06<00:00, 1390.79it/s] 99%|█████████████████████████████████████████████████▌| 7402/7473 [00:06<00:00, 1391.60it/s]100%|██████████████████████████████████████████████████| 7473/7473 [00:06<00:00, 1173.20it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:04<00:09,  4.94s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.59s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.64s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:04<00:09,  4.99s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:09<00:04,  4.96s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.41s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.45s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.07s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.33s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.50s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.85s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.02s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.42s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.59s/it]
[2023-08-12 14:46:42,450] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.78s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.98s/it]
[2023-08-12 14:46:50,120] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 14:46:50,121] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 14:46:50,121] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 14:46:50,121] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 14:46:50,121] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 14:46:50,121] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 14:46:50,121] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 14:46:50,121] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 14:46:50,121] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 14:46:50,121] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 14:46:50,121] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 14:46:50,121] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f039cd39fa0>
[2023-08-12 14:46:50,121] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f039cd2f700>
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 14:46:50,122] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 14:46:50,123] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 14:46:50,123] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 14:46:50,123] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 14:46:50,123] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.40041279792785645 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Rationales: 1. The question is about finding a location where the plumbing system would not help in quenching your thirst.
2. The given options are oil refineries, a wall, a show, own home, and a water fountain.
3. When we think about the role of plumbing, it is to carry water or other fluids from one place to another.
4. Thinking logically, 'wall' and'show' are irrelevant as they do not in general have a plumbing system.
5. At your own home and a water fountain, the plumbing system carries water which you can drink.
6. So they are also not correct answers.
7. Now considering oil refineries, they do indeed have complex plumbing systems, but here the liquid being carried isn't drinkable water, but oil.
8. Therefore, the plumbing in an oil refinery wouldn't be of use to quench your thirst.
9. Hence, the correct answer is A: oil refineries.
Answer: A: oil refineries

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o1-tcommonsenseqa-s1-rTrue
Loading extension module utils...
Time to load utils op: 0.3041253089904785 seconds
Loading extension module utils...
Time to load utils op: 0.3042893409729004 seconds
Loading extension module utils...
Time to load utils op: 0.30423426628112793 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:52<42:58, 52.63s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:44<41:38, 52.06s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:35<40:37, 51.85s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [03:27<39:36, 51.67s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [04:18<38:35, 51.46s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [05:10<38:01, 51.85s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [06:03<37:13, 51.95s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [06:54<36:16, 51.83s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [07:46<35:26, 51.86s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [08:38<34:37, 51.94s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [09:31<33:55, 52.19s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [10:08<30:08, 47.59s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [10:49<28:00, 45.42s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [11:40<28:23, 47.33s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [12:32<28:24, 48.71s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [13:24<28:10, 49.72s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [13:54<24:07, 43.85s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [14:46<24:40, 46.25s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [15:38<24:45, 47.90s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [16:31<24:42, 49.41s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [17:23<24:19, 50.33s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [18:09<22:51, 48.99s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [19:02<22:31, 50.04s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [19:54<21:58, 50.72s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [20:45<21:08, 50.74s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [21:33<20:00, 50.00s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [22:22<18:59, 49.56s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [23:14<18:28, 50.37s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [24:06<17:49, 50.93s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [24:39<15:08, 45.44s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [25:30<14:53, 47.03s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [26:22<14:35, 48.65s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [27:14<14:04, 49.66s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [28:06<13:26, 50.39s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [28:58<12:41, 50.77s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [29:50<11:56, 51.17s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [30:28<10:13, 47.22s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [31:19<09:40, 48.35s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [32:11<09:04, 49.48s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [33:02<08:18, 49.88s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [33:52<07:30, 50.01s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [34:45<06:45, 50.74s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [35:37<05:57, 51.12s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [36:28<05:08, 51.36s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [37:21<04:18, 51.75s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [38:12<03:26, 51.61s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [39:04<02:35, 51.67s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [39:56<01:43, 51.66s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [40:48<00:51, 51.71s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [41:40<00:00, 51.84s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [41:40<00:00, 50.01s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.1842} | lm_loss 10.3322 | avg. gen lenth: 324.428
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o2-tcommonsenseqa-s1-rTrue --seed 1 --rationales --num-out-domain 2
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-12 15:29:11,929] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o2-tcommonsenseqa-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 2
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o2-tcommonsenseqa-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  1%|▎                                                    | 44/7473 [00:00<00:17, 434.28it/s]  1%|▋                                                    | 89/7473 [00:00<00:16, 438.35it/s]  2%|▉                                                   | 133/7473 [00:00<00:16, 438.75it/s]  2%|█▏                                                  | 178/7473 [00:00<00:16, 440.58it/s]  3%|█▌                                                  | 223/7473 [00:00<00:16, 442.47it/s]  4%|█▊                                                  | 268/7473 [00:00<00:16, 439.81it/s]  4%|██▏                                                 | 313/7473 [00:00<00:16, 441.04it/s]  5%|██▍                                                 | 358/7473 [00:00<00:16, 441.54it/s]  5%|██▊                                                 | 403/7473 [00:00<00:16, 432.05it/s]  6%|███                                                 | 447/7473 [00:01<00:16, 433.74it/s]  7%|███▍                                                | 491/7473 [00:01<00:16, 433.11it/s]  7%|███▋                                                | 536/7473 [00:01<00:15, 435.58it/s]  8%|████                                                | 581/7473 [00:01<00:15, 437.00it/s]  8%|████▎                                               | 625/7473 [00:01<00:15, 437.17it/s]  9%|████▋                                               | 670/7473 [00:01<00:15, 439.20it/s] 10%|████▉                                               | 715/7473 [00:01<00:15, 439.73it/s] 10%|█████▎                                              | 760/7473 [00:01<00:15, 441.28it/s] 11%|█████▌                                              | 805/7473 [00:01<00:15, 440.67it/s] 11%|█████▉                                              | 850/7473 [00:01<00:15, 437.77it/s] 12%|██████▏                                             | 894/7473 [00:02<00:15, 438.23it/s] 13%|██████▌                                             | 938/7473 [00:02<00:14, 437.46it/s] 13%|██████▊                                             | 983/7473 [00:02<00:14, 440.02it/s] 14%|███████                                            | 1028/7473 [00:02<00:14, 442.88it/s] 15%|███████▍                                           | 1095/7473 [00:02<00:12, 508.39it/s] 16%|███████▉                                           | 1161/7473 [00:02<00:11, 552.52it/s] 16%|████████▍                                          | 1228/7473 [00:02<00:10, 585.92it/s] 17%|████████▊                                          | 1295/7473 [00:02<00:10, 609.63it/s] 18%|█████████▎                                         | 1362/7473 [00:02<00:09, 625.27it/s] 19%|█████████▋                                         | 1426/7473 [00:02<00:09, 628.48it/s] 20%|██████████▏                                        | 1493/7473 [00:03<00:09, 639.38it/s] 21%|██████████▋                                        | 1559/7473 [00:03<00:09, 645.38it/s] 22%|███████████                                        | 1624/7473 [00:03<00:09, 645.50it/s] 23%|███████████▌                                       | 1690/7473 [00:03<00:08, 649.31it/s] 23%|███████████▉                                       | 1756/7473 [00:03<00:08, 652.08it/s] 24%|████████████▍                                      | 1823/7473 [00:03<00:08, 654.84it/s] 25%|████████████▉                                      | 1889/7473 [00:03<00:08, 654.24it/s] 26%|█████████████▎                                     | 1955/7473 [00:03<00:08, 655.57it/s] 27%|█████████████▊                                     | 2022/7473 [00:03<00:08, 658.21it/s] 28%|██████████████▏                                    | 2088/7473 [00:03<00:08, 656.10it/s] 29%|██████████████▋                                    | 2154/7473 [00:04<00:08, 656.83it/s] 30%|███████████████▏                                   | 2221/7473 [00:04<00:07, 658.44it/s] 31%|███████████████▌                                   | 2288/7473 [00:04<00:07, 659.00it/s] 32%|████████████████                                   | 2354/7473 [00:04<00:07, 658.21it/s] 32%|████████████████▌                                  | 2420/7473 [00:04<00:07, 658.18it/s] 33%|████████████████▉                                  | 2487/7473 [00:04<00:07, 660.72it/s] 34%|█████████████████▍                                 | 2554/7473 [00:04<00:07, 631.35it/s] 35%|█████████████████▉                                 | 2621/7473 [00:04<00:07, 641.83it/s] 36%|██████████████████▎                                | 2688/7473 [00:04<00:07, 648.55it/s] 37%|██████████████████▊                                | 2754/7473 [00:04<00:07, 650.87it/s] 38%|███████████████████▎                               | 2821/7473 [00:05<00:07, 653.88it/s] 39%|███████████████████▋                               | 2888/7473 [00:05<00:06, 656.11it/s] 40%|████████████████████▏                              | 2955/7473 [00:05<00:06, 659.90it/s] 40%|████████████████████▌                              | 3022/7473 [00:05<00:06, 658.80it/s] 41%|█████████████████████                              | 3089/7473 [00:05<00:06, 659.82it/s] 42%|█████████████████████▌                             | 3156/7473 [00:05<00:06, 658.35it/s] 43%|█████████████████████▉                             | 3222/7473 [00:05<00:06, 657.04it/s] 44%|██████████████████████▍                            | 3288/7473 [00:05<00:06, 655.57it/s] 45%|██████████████████████▉                            | 3354/7473 [00:05<00:06, 656.03it/s] 46%|███████████████████████▎                           | 3420/7473 [00:05<00:06, 656.55it/s] 47%|███████████████████████▊                           | 3486/7473 [00:06<00:06, 655.44it/s] 48%|████████████████████████▏                          | 3552/7473 [00:06<00:05, 656.02it/s] 48%|████████████████████████▋                          | 3619/7473 [00:06<00:05, 658.87it/s] 49%|█████████████████████████▏                         | 3685/7473 [00:06<00:05, 656.30it/s] 50%|█████████████████████████▌                         | 3751/7473 [00:06<00:05, 655.22it/s] 51%|██████████████████████████                         | 3818/7473 [00:06<00:05, 658.43it/s] 52%|██████████████████████████▌                        | 3884/7473 [00:06<00:05, 656.23it/s] 53%|██████████████████████████▉                        | 3951/7473 [00:06<00:05, 658.54it/s] 54%|███████████████████████████▍                       | 4018/7473 [00:06<00:05, 660.40it/s] 55%|███████████████████████████▉                       | 4085/7473 [00:06<00:05, 661.33it/s] 56%|████████████████████████████▎                      | 4152/7473 [00:07<00:05, 651.23it/s] 56%|████████████████████████████▊                      | 4218/7473 [00:07<00:04, 652.80it/s] 57%|█████████████████████████████▏                     | 4284/7473 [00:07<00:04, 645.45it/s] 58%|█████████████████████████████▋                     | 4349/7473 [00:07<00:04, 646.00it/s] 59%|██████████████████████████████▏                    | 4415/7473 [00:07<00:04, 649.23it/s] 60%|██████████████████████████████▌                    | 4481/7473 [00:07<00:04, 651.42it/s] 61%|███████████████████████████████                    | 4547/7473 [00:07<00:04, 651.37it/s] 62%|███████████████████████████████▍                   | 4613/7473 [00:07<00:04, 651.88it/s] 63%|███████████████████████████████▉                   | 4679/7473 [00:07<00:04, 653.64it/s] 63%|████████████████████████████████▍                  | 4745/7473 [00:08<00:04, 637.33it/s] 64%|████████████████████████████████▊                  | 4811/7473 [00:08<00:04, 642.88it/s] 65%|█████████████████████████████████▎                 | 4877/7473 [00:08<00:04, 647.83it/s] 66%|█████████████████████████████████▋                 | 4943/7473 [00:08<00:03, 650.50it/s] 67%|██████████████████████████████████▏                | 5009/7473 [00:08<00:03, 644.05it/s] 68%|██████████████████████████████████▋                | 5075/7473 [00:08<00:03, 647.86it/s] 69%|███████████████████████████████████                | 5142/7473 [00:08<00:03, 652.29it/s] 70%|███████████████████████████████████▌               | 5209/7473 [00:08<00:03, 655.77it/s] 71%|███████████████████████████████████▉               | 5275/7473 [00:08<00:03, 622.72it/s] 71%|████████████████████████████████████▍              | 5341/7473 [00:08<00:03, 633.28it/s] 72%|████████████████████████████████████▉              | 5407/7473 [00:09<00:03, 640.83it/s] 73%|█████████████████████████████████████▎             | 5472/7473 [00:09<00:04, 475.11it/s] 74%|█████████████████████████████████████▊             | 5538/7473 [00:09<00:03, 517.67it/s] 75%|██████████████████████████████████████▏            | 5603/7473 [00:09<00:03, 549.77it/s] 76%|██████████████████████████████████████▋            | 5670/7473 [00:09<00:03, 579.52it/s] 77%|███████████████████████████████████████▏           | 5736/7473 [00:09<00:02, 600.10it/s] 78%|███████████████████████████████████████▌           | 5801/7473 [00:09<00:02, 613.11it/s] 79%|████████████████████████████████████████           | 5867/7473 [00:09<00:02, 625.70it/s] 79%|████████████████████████████████████████▍          | 5932/7473 [00:09<00:02, 632.22it/s] 80%|████████████████████████████████████████▉          | 5998/7473 [00:10<00:02, 639.00it/s] 81%|█████████████████████████████████████████▍         | 6065/7473 [00:10<00:02, 646.40it/s] 82%|█████████████████████████████████████████▊         | 6132/7473 [00:10<00:02, 650.46it/s] 83%|██████████████████████████████████████████▎        | 6199/7473 [00:10<00:01, 654.27it/s] 84%|██████████████████████████████████████████▊        | 6265/7473 [00:10<00:01, 650.93it/s] 85%|███████████████████████████████████████████▏       | 6331/7473 [00:10<00:01, 651.97it/s] 86%|███████████████████████████████████████████▋       | 6397/7473 [00:10<00:01, 650.72it/s] 86%|████████████████████████████████████████████       | 6464/7473 [00:10<00:01, 653.84it/s] 87%|████████████████████████████████████████████▌      | 6531/7473 [00:10<00:01, 656.20it/s] 88%|█████████████████████████████████████████████      | 6597/7473 [00:10<00:01, 656.76it/s] 89%|█████████████████████████████████████████████▍     | 6663/7473 [00:11<00:01, 656.65it/s] 90%|█████████████████████████████████████████████▉     | 6729/7473 [00:11<00:01, 657.51it/s] 91%|██████████████████████████████████████████████▎    | 6795/7473 [00:11<00:01, 658.06it/s] 92%|██████████████████████████████████████████████▊    | 6861/7473 [00:11<00:00, 654.94it/s] 93%|███████████████████████████████████████████████▎   | 6928/7473 [00:11<00:00, 657.63it/s] 94%|███████████████████████████████████████████████▋   | 6994/7473 [00:11<00:00, 654.31it/s] 94%|████████████████████████████████████████████████▏  | 7060/7473 [00:11<00:00, 650.53it/s] 95%|████████████████████████████████████████████████▋  | 7126/7473 [00:11<00:00, 652.86it/s] 96%|█████████████████████████████████████████████████  | 7193/7473 [00:11<00:00, 655.33it/s] 97%|█████████████████████████████████████████████████▌ | 7260/7473 [00:12<00:00, 658.46it/s] 98%|█████████████████████████████████████████████████▉ | 7326/7473 [00:12<00:00, 657.65it/s] 99%|██████████████████████████████████████████████████▍| 7392/7473 [00:12<00:00, 658.08it/s]100%|██████████████████████████████████████████████████▉| 7458/7473 [00:12<00:00, 654.58it/s]100%|███████████████████████████████████████████████████| 7473/7473 [00:12<00:00, 606.23it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.13s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.53s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.63s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.73s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.03s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.59s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.52s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.52s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.41s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.59s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.83s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.03s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.83s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.03s/it]
[2023-08-12 15:30:16,882] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.85s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.05s/it]
[2023-08-12 15:30:27,028] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 15:30:27,030] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 15:30:27,030] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 15:30:27,030] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 15:30:27,031] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 15:30:27,031] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 15:30:27,031] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 15:30:27,031] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 15:30:27,031] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 15:30:27,031] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 15:30:27,031] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 15:30:27,031] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f8a89120b20>
[2023-08-12 15:30:27,031] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 15:30:27,031] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 15:30:27,031] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 15:30:27,031] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 15:30:27,032] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f8a891208b0>
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 15:30:27,033] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 15:30:27,034] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.46192216873168945 seconds
Loading extension module utils...
Time to load utils op: 0.40457606315612793 seconds
Loading extension module utils...
Loading extension module utils...
Time to load utils op: 0.5049164295196533 seconds
Time to load utils op: 0.5049271583557129 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Rationales: 1. The question is asking where you could find some plumbing that you couldn't use to quench your thirst. 
2. Let's consider each choice one by one:
3. Option A is oil refineries. Plumbing in oil refineries is used to transport oil and other substances as part of the refining process. You cannot drink oil, so this plumbing would not be of use if you are thirsty.
4. Option B is a wall. Although plumbing can be found in walls in homes, offices, etc., it typically carries water, so it could potentially be helpful if you are thirsty.
5. Option C is a show. This is a bit ambiguous as it could refers to a variety of things, but many types of shows such as concerts, theaters, tradeshows, etc. have water fountains or concession stands, so potentially you could find a drinkable water source there.
6. Option D is your own home. Most homes have plumbing system that provides clean, drinkable water, so this would be useful to you if you are thirsty.
7. Option E is a water fountain. Water fountains are made specifically for people to drink or quench their thirst, so definitely this would be useful if thirsty.
8. Based on this analysis, the only option that has plumbing system not used for supplying drinkable water is A: oil refineries. Therefore, this is the correct answer.
Answer: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Rationales: 1. The question asks what a person is not doing yet when they are beginning work.
2. We need to find an option that a person can't do while starting work.
3. Let's examine each choice.
4. Option A: working. This can't be the answer because the question states that the person is "beginning work," which means they are, in fact, working.
5. Option B: resting. This can't be the answer because a person can't start work and rest at the same time.
6. Option C: tiredness. This can't be the answer because tiredness isn't an action, so it can't be something someone is doing.
7. Option E: momentum. This can't be the answer because momentum is not something a person does, rather, it is something a person gains as they continue doing their work.
8. Therefore, the best answer is D: accomplishing. A person at the beginning of their work is not yet accomplishing their goals or tasks because they are just starting. The accomplishment comes after, as the result of the work.
Answer: D: accomplishing

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o2-tcommonsenseqa-s1-rTrue
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:48<39:12, 48.00s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:34<37:45, 47.19s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:07<31:40, 40.44s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [02:53<32:53, 42.90s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [03:40<33:20, 44.47s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [04:27<33:09, 45.22s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [05:13<32:36, 45.51s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [05:59<31:55, 45.62s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [06:46<31:25, 45.99s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [07:33<30:49, 46.23s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [08:18<29:56, 46.07s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [09:05<29:20, 46.32s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [09:52<28:43, 46.59s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [10:35<27:11, 45.33s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [11:22<26:47, 45.92s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [12:09<26:14, 46.30s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [12:56<25:35, 46.54s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [13:21<21:21, 40.05s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [14:08<21:46, 42.13s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [14:55<21:44, 43.49s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [15:41<21:26, 44.35s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [16:24<20:29, 43.92s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [17:11<20:07, 44.73s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [17:58<19:41, 45.44s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [18:40<18:27, 44.29s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [19:27<18:05, 45.23s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [20:14<17:29, 45.65s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [20:48<15:32, 42.37s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [21:35<15:13, 43.51s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [22:21<14:49, 44.49s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [23:08<14:20, 45.27s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [23:56<13:45, 45.86s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [24:33<12:17, 43.38s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [25:19<11:47, 44.23s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [26:06<11:15, 45.03s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [26:53<10:37, 45.57s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [27:28<09:10, 42.32s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [28:14<08:42, 43.54s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [29:01<08:09, 44.54s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [29:48<07:33, 45.32s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [30:35<06:50, 45.62s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [31:22<06:08, 46.02s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [32:08<05:23, 46.15s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [32:55<04:37, 46.29s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [33:41<03:51, 46.34s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [34:27<03:05, 46.32s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [35:14<02:19, 46.46s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [36:01<01:32, 46.42s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [36:46<00:46, 46.25s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [37:33<00:00, 46.37s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [37:33<00:00, 45.07s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.2849} | lm_loss 10.1472 | avg. gen lenth: 300.492
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o3-tcommonsenseqa-s1-rTrue --seed 1 --rationales --num-out-domain 3
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date![nltk_data]   Package punkt is already up-to-date!

using world size: 4
[2023-08-12 16:08:30,621] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o3-tcommonsenseqa-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 3
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o3-tcommonsenseqa-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  1%|▎                                                    | 47/7473 [00:00<00:15, 464.83it/s]  1%|▋                                                    | 95/7473 [00:00<00:15, 471.48it/s]  2%|▉                                                   | 143/7473 [00:00<00:15, 472.77it/s]  3%|█▎                                                  | 191/7473 [00:00<00:15, 475.26it/s]  3%|█▋                                                  | 239/7473 [00:00<00:15, 473.90it/s]  4%|█▉                                                  | 287/7473 [00:00<00:15, 473.40it/s]  4%|██▎                                                 | 335/7473 [00:00<00:15, 474.53it/s]  5%|██▋                                                 | 383/7473 [00:00<00:14, 475.34it/s]  6%|██▉                                                 | 431/7473 [00:00<00:15, 467.77it/s]  6%|███▎                                                | 478/7473 [00:01<00:14, 466.65it/s]  7%|███▋                                                | 526/7473 [00:01<00:14, 468.96it/s]  8%|███▉                                                | 574/7473 [00:01<00:14, 471.08it/s]  8%|████▎                                               | 622/7473 [00:01<00:14, 471.40it/s]  9%|████▋                                               | 670/7473 [00:01<00:14, 473.07it/s] 10%|████▉                                               | 718/7473 [00:01<00:14, 473.40it/s] 10%|█████▎                                              | 766/7473 [00:01<00:14, 474.75it/s] 11%|█████▋                                              | 814/7473 [00:01<00:14, 474.52it/s] 12%|█████▉                                              | 862/7473 [00:01<00:13, 474.88it/s] 12%|██████▎                                             | 910/7473 [00:01<00:13, 471.02it/s] 13%|██████▋                                             | 958/7473 [00:02<00:13, 470.84it/s] 13%|██████▊                                            | 1006/7473 [00:02<00:13, 473.27it/s] 14%|███████▏                                           | 1054/7473 [00:02<00:13, 474.91it/s] 15%|███████▌                                           | 1102/7473 [00:02<00:13, 475.57it/s] 15%|███████▊                                           | 1150/7473 [00:02<00:13, 474.57it/s] 16%|████████▏                                          | 1198/7473 [00:02<00:13, 471.29it/s] 17%|████████▌                                          | 1246/7473 [00:02<00:13, 471.66it/s] 17%|████████▊                                          | 1294/7473 [00:02<00:13, 471.72it/s] 18%|█████████▏                                         | 1342/7473 [00:02<00:12, 472.85it/s] 19%|█████████▍                                         | 1390/7473 [00:02<00:12, 470.24it/s] 19%|█████████▊                                         | 1438/7473 [00:03<00:12, 471.37it/s] 20%|██████████▏                                        | 1486/7473 [00:03<00:12, 473.02it/s] 21%|██████████▍                                        | 1534/7473 [00:03<00:12, 473.76it/s] 21%|██████████▊                                        | 1582/7473 [00:03<00:12, 472.29it/s] 22%|███████████                                        | 1630/7473 [00:03<00:12, 470.58it/s] 22%|███████████▍                                       | 1678/7473 [00:03<00:12, 471.28it/s] 23%|███████████▊                                       | 1726/7473 [00:03<00:12, 471.69it/s] 24%|████████████                                       | 1774/7473 [00:03<00:12, 471.12it/s] 24%|████████████▍                                      | 1822/7473 [00:03<00:12, 470.55it/s] 25%|████████████▊                                      | 1870/7473 [00:03<00:11, 468.49it/s] 26%|█████████████                                      | 1918/7473 [00:04<00:11, 469.10it/s] 26%|█████████████▍                                     | 1966/7473 [00:04<00:11, 470.18it/s] 27%|█████████████▋                                     | 2014/7473 [00:04<00:11, 471.32it/s] 28%|██████████████                                     | 2062/7473 [00:04<00:11, 472.33it/s] 28%|██████████████▍                                    | 2110/7473 [00:04<00:11, 468.81it/s] 29%|██████████████▋                                    | 2157/7473 [00:04<00:11, 469.14it/s] 30%|███████████████                                    | 2205/7473 [00:04<00:11, 470.47it/s] 30%|███████████████▍                                   | 2253/7473 [00:04<00:11, 470.84it/s] 31%|███████████████▋                                   | 2301/7473 [00:04<00:11, 467.83it/s] 31%|████████████████                                   | 2348/7473 [00:04<00:10, 468.22it/s] 32%|████████████████▎                                  | 2396/7473 [00:05<00:10, 469.56it/s] 33%|████████████████▋                                  | 2444/7473 [00:05<00:10, 471.42it/s] 33%|█████████████████                                  | 2492/7473 [00:05<00:10, 470.94it/s] 34%|█████████████████▎                                 | 2540/7473 [00:05<00:11, 441.80it/s] 35%|█████████████████▋                                 | 2588/7473 [00:05<00:10, 450.54it/s] 35%|█████████████████▉                                 | 2635/7473 [00:05<00:10, 455.70it/s] 36%|██████████████████▎                                | 2683/7473 [00:05<00:10, 461.39it/s] 37%|██████████████████▋                                | 2730/7473 [00:05<00:10, 461.46it/s] 37%|██████████████████▉                                | 2777/7473 [00:05<00:10, 463.36it/s] 38%|███████████████████▎                               | 2825/7473 [00:06<00:09, 466.35it/s] 38%|███████████████████▌                               | 2873/7473 [00:06<00:09, 467.84it/s] 39%|███████████████████▉                               | 2921/7473 [00:06<00:09, 470.14it/s] 40%|████████████████████▎                              | 2969/7473 [00:06<00:09, 472.11it/s] 40%|████████████████████▌                              | 3017/7473 [00:06<00:09, 469.20it/s] 41%|████████████████████▉                              | 3064/7473 [00:06<00:09, 467.15it/s] 42%|█████████████████████▏                             | 3111/7473 [00:06<00:09, 466.07it/s] 42%|█████████████████████▌                             | 3158/7473 [00:06<00:09, 466.18it/s] 43%|█████████████████████▊                             | 3205/7473 [00:06<00:09, 465.21it/s] 44%|██████████████████████▏                            | 3252/7473 [00:06<00:09, 466.30it/s] 44%|██████████████████████▌                            | 3299/7473 [00:07<00:08, 466.91it/s] 45%|██████████████████████▊                            | 3346/7473 [00:07<00:08, 462.14it/s] 45%|███████████████████████▏                           | 3393/7473 [00:07<00:08, 463.03it/s] 46%|███████████████████████▍                           | 3440/7473 [00:07<00:08, 462.61it/s] 47%|███████████████████████▊                           | 3487/7473 [00:07<00:08, 463.52it/s] 47%|████████████████████████                           | 3534/7473 [00:07<00:08, 465.16it/s] 48%|████████████████████████▍                          | 3581/7473 [00:07<00:08, 465.82it/s] 49%|████████████████████████▊                          | 3628/7473 [00:07<00:08, 466.44it/s] 49%|█████████████████████████                          | 3675/7473 [00:07<00:08, 464.64it/s] 50%|█████████████████████████▍                         | 3723/7473 [00:07<00:08, 466.43it/s] 50%|█████████████████████████▋                         | 3770/7473 [00:08<00:07, 467.40it/s] 51%|██████████████████████████                         | 3818/7473 [00:08<00:07, 469.19it/s] 52%|██████████████████████████▍                        | 3865/7473 [00:08<00:07, 469.02it/s] 52%|██████████████████████████▋                        | 3912/7473 [00:08<00:07, 467.93it/s] 53%|███████████████████████████                        | 3959/7473 [00:08<00:07, 465.28it/s] 54%|███████████████████████████▎                       | 4006/7473 [00:08<00:07, 464.79it/s] 54%|███████████████████████████▋                       | 4053/7473 [00:08<00:07, 466.12it/s] 55%|███████████████████████████▉                       | 4100/7473 [00:08<00:07, 463.31it/s] 55%|████████████████████████████▎                      | 4147/7473 [00:08<00:07, 461.29it/s] 56%|████████████████████████████▌                      | 4194/7473 [00:08<00:07, 463.69it/s] 57%|████████████████████████████▉                      | 4241/7473 [00:09<00:06, 465.49it/s] 57%|█████████████████████████████▎                     | 4288/7473 [00:09<00:06, 464.89it/s] 58%|█████████████████████████████▌                     | 4336/7473 [00:09<00:06, 464.81it/s] 59%|█████████████████████████████▉                     | 4383/7473 [00:09<00:06, 464.69it/s] 59%|██████████████████████████████▏                    | 4430/7473 [00:09<00:06, 463.81it/s] 60%|██████████████████████████████▌                    | 4477/7473 [00:09<00:06, 463.90it/s] 61%|██████████████████████████████▊                    | 4524/7473 [00:09<00:06, 464.69it/s] 61%|███████████████████████████████▏                   | 4571/7473 [00:09<00:06, 459.30it/s] 62%|███████████████████████████████▌                   | 4618/7473 [00:09<00:06, 462.22it/s] 62%|███████████████████████████████▊                   | 4665/7473 [00:09<00:06, 463.53it/s] 63%|████████████████████████████████▏                  | 4712/7473 [00:10<00:05, 464.30it/s] 64%|████████████████████████████████▍                  | 4759/7473 [00:10<00:05, 464.54it/s] 64%|████████████████████████████████▊                  | 4806/7473 [00:10<00:05, 463.15it/s] 65%|█████████████████████████████████                  | 4853/7473 [00:10<00:05, 464.74it/s] 66%|█████████████████████████████████▍                 | 4900/7473 [00:10<00:05, 465.64it/s] 66%|█████████████████████████████████▊                 | 4947/7473 [00:10<00:05, 464.34it/s] 67%|██████████████████████████████████                 | 4994/7473 [00:10<00:05, 464.97it/s] 67%|██████████████████████████████████▍                | 5041/7473 [00:10<00:05, 466.11it/s] 68%|██████████████████████████████████▋                | 5088/7473 [00:10<00:05, 465.72it/s] 69%|███████████████████████████████████                | 5135/7473 [00:10<00:05, 465.50it/s] 69%|███████████████████████████████████▎               | 5183/7473 [00:11<00:04, 466.95it/s] 70%|███████████████████████████████████▋               | 5231/7473 [00:11<00:04, 468.63it/s] 71%|████████████████████████████████████               | 5278/7473 [00:11<00:05, 428.07it/s] 71%|████████████████████████████████████▎              | 5325/7473 [00:11<00:04, 438.84it/s] 72%|████████████████████████████████████▋              | 5372/7473 [00:11<00:04, 447.07it/s] 73%|████████████████████████████████████▉              | 5419/7473 [00:11<00:04, 453.11it/s] 73%|█████████████████████████████████████▎             | 5466/7473 [00:11<00:04, 457.64it/s] 74%|█████████████████████████████████████▌             | 5512/7473 [00:11<00:05, 328.15it/s] 74%|█████████████████████████████████████▉             | 5559/7473 [00:12<00:05, 359.52it/s] 75%|██████████████████████████████████████▎            | 5606/7473 [00:12<00:04, 385.59it/s] 76%|██████████████████████████████████████▌            | 5653/7473 [00:12<00:04, 407.13it/s] 76%|██████████████████████████████████████▉            | 5698/7473 [00:12<00:04, 418.48it/s] 77%|███████████████████████████████████████▏           | 5745/7473 [00:12<00:04, 431.95it/s] 78%|███████████████████████████████████████▌           | 5792/7473 [00:12<00:03, 440.69it/s] 78%|███████████████████████████████████████▊           | 5839/7473 [00:12<00:03, 448.04it/s] 79%|████████████████████████████████████████▏          | 5886/7473 [00:12<00:03, 452.35it/s] 79%|████████████████████████████████████████▍          | 5932/7473 [00:12<00:03, 445.93it/s] 80%|████████████████████████████████████████▊          | 5979/7473 [00:12<00:03, 450.41it/s] 81%|█████████████████████████████████████████          | 6025/7473 [00:13<00:03, 450.45it/s] 81%|█████████████████████████████████████████▍         | 6072/7473 [00:13<00:03, 455.87it/s] 82%|█████████████████████████████████████████▊         | 6119/7473 [00:13<00:02, 459.62it/s] 83%|██████████████████████████████████████████         | 6166/7473 [00:13<00:02, 459.48it/s] 83%|██████████████████████████████████████████▍        | 6213/7473 [00:13<00:02, 462.29it/s] 84%|██████████████████████████████████████████▋        | 6260/7473 [00:13<00:02, 463.36it/s] 84%|███████████████████████████████████████████        | 6307/7473 [00:13<00:02, 464.42it/s] 85%|███████████████████████████████████████████▎       | 6354/7473 [00:13<00:02, 465.65it/s] 86%|███████████████████████████████████████████▋       | 6401/7473 [00:13<00:02, 462.82it/s] 86%|████████████████████████████████████████████       | 6448/7473 [00:13<00:02, 463.89it/s] 87%|████████████████████████████████████████████▎      | 6495/7473 [00:14<00:02, 463.65it/s] 88%|████████████████████████████████████████████▋      | 6542/7473 [00:14<00:02, 462.14it/s] 88%|████████████████████████████████████████████▉      | 6589/7473 [00:14<00:01, 462.74it/s] 89%|█████████████████████████████████████████████▎     | 6636/7473 [00:14<00:01, 464.29it/s] 89%|█████████████████████████████████████████████▌     | 6683/7473 [00:14<00:01, 462.56it/s] 90%|█████████████████████████████████████████████▉     | 6730/7473 [00:14<00:01, 460.95it/s] 91%|██████████████████████████████████████████████▎    | 6777/7473 [00:14<00:01, 460.61it/s] 91%|██████████████████████████████████████████████▌    | 6824/7473 [00:14<00:01, 459.27it/s] 92%|██████████████████████████████████████████████▉    | 6871/7473 [00:14<00:01, 460.15it/s] 93%|███████████████████████████████████████████████▏   | 6918/7473 [00:15<00:01, 460.78it/s] 93%|███████████████████████████████████████████████▌   | 6965/7473 [00:15<00:01, 460.87it/s] 94%|███████████████████████████████████████████████▊   | 7012/7473 [00:15<00:01, 460.30it/s] 94%|████████████████████████████████████████████████▏  | 7059/7473 [00:15<00:00, 458.62it/s] 95%|████████████████████████████████████████████████▍  | 7106/7473 [00:15<00:00, 460.38it/s] 96%|████████████████████████████████████████████████▊  | 7153/7473 [00:15<00:00, 460.40it/s] 96%|█████████████████████████████████████████████████▏ | 7200/7473 [00:15<00:00, 461.15it/s] 97%|█████████████████████████████████████████████████▍ | 7247/7473 [00:15<00:00, 462.92it/s] 98%|█████████████████████████████████████████████████▊ | 7294/7473 [00:15<00:00, 461.71it/s] 98%|██████████████████████████████████████████████████ | 7341/7473 [00:15<00:00, 461.61it/s] 99%|██████████████████████████████████████████████████▍| 7388/7473 [00:16<00:00, 462.47it/s] 99%|██████████████████████████████████████████████████▋| 7435/7473 [00:16<00:00, 463.01it/s]100%|███████████████████████████████████████████████████| 7473/7473 [00:16<00:00, 461.21it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.09s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.55s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.34s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.06s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:09<00:04,  4.96s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.52s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.45s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.35s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.53s/it]
Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.02s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.89s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.06s/it]
[2023-08-12 16:09:39,599] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.85s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.00s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.39s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.56s/it]
[2023-08-12 16:09:48,531] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 16:09:48,533] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 16:09:48,533] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 16:09:48,533] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 16:09:48,533] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 16:09:48,533] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f395da57fa0>
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 16:09:48,534] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f395da6f700>
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 16:09:48,535] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 16:09:48,536] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 16:09:48,536] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 16:09:48,536] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 16:09:48,536] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.43941259384155273 seconds
Loading extension module utils...
Time to load utils op: 0.4049239158630371 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Loading extension module utils...
Time to load utils op: 0.40436267852783203 seconds
Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Loading extension module utils...
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Rationales: 1. If we are thirsty, we will need a source of water to quench our thirst.
2. Thinking about the choices given, let's evaluate them starting from A to E.
3. Choice A: Oil refineries. They do have plumbing but not to supply drinkable water to people. Instead, they have pipelines to transport crude oil and chemical substances.
4. Therefore, the plumbing of an oil refinery would be of no use to us if we are thirsty.
5. Now, let's look at the other choices to ascertain our answer. 
6. Choice B: Wall. A wall might house plumbing within a building, potentially a source of water.
7. Choice C: Show. This could refer to a variety of things but it generally doesn't provide water. However, there might be water available at a show depending on its nature, such as a trade show or an exhibition.
8. Choice D: Own home. Our own home would definitely have plumbing, and it would be very useful to us if we are thirsty.
9. Choice E: Water fountain. A water fountain would also have accessible water.
10. After assessing all choices, it is clear that the plumbing of an oil refinery would be the least useful if we are thirsty. So, the correct answer is A: Oil refineries.
Answer: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Rationales: 1. The question asks what a person isn't doing yet when they're just beginning to work.
2. We can cross out "A: working" because the person is actively engaging in work, as stated in the question.
3. Then, we can cross out "B: resting" because this suggests they are not doing any work, which contradicts the information provided.
4. We can also cross out "C: tiredness" because it's a state rather than an action and isn't relevant to the question.
5. Lastly, we can cross out "E: momentum" because it's more a state or result of action, rather than an action itself.
6. Therefore, the answer is "D: accomplishing" because when someone is just beginning to work, they haven't had the time to accomplish anything yet. It's the only option left and it makes logical sense based on the information provided in the question.
Answer: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Rationales: 1. The question is asking me where I can find pens with company logos. 
2. I start by understanding the nature of pens with a company logo which are usually provided by businesses or organizations and are not typically found on average consumer items.
3. Looking at choice B: it mentions a pencil, which is incorrect because pencils aren't usually embossed with company logos.
4. Choice C: involves writing sentences on paper. This choice is not relevant to the question as it doesn't specify a location.
5. Choice D: in schools, it is less likely to find pens with company logos as schools usually don't distribute company merchandise.
6. Choice E: in a backpack, you could find a wide range of items including pens, but it doesn't specifically relate to pens with a company logo.
7. Choice A: is an office. Considering offices are places where business transactions occur, it's logical to assume that pens with company logos could be found here.
8. So, the answer is A: Office.
Answer: A: office

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o3-tcommonsenseqa-s1-rTrue
Time to load utils op: 0.5044100284576416 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:44<36:30, 44.71s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:28<35:15, 44.08s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:13<34:53, 44.54s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [02:57<34:02, 44.41s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [03:42<33:19, 44.44s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [04:16<30:00, 40.93s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [05:00<30:05, 41.99s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [05:44<29:52, 42.67s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [06:28<29:30, 43.19s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [07:12<28:58, 43.45s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [07:56<28:21, 43.64s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [08:40<27:42, 43.74s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [09:25<27:03, 43.87s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [10:09<26:22, 43.95s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [10:53<25:40, 44.01s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [11:37<24:58, 44.06s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [12:22<24:25, 44.40s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [13:06<23:35, 44.24s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [13:50<22:47, 44.10s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [14:34<22:01, 44.06s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [15:17<21:10, 43.82s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [16:01<20:27, 43.83s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [16:46<19:50, 44.08s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [17:29<19:02, 43.94s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [18:13<18:16, 43.87s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [18:57<17:33, 43.90s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [19:42<16:55, 44.16s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [20:25<16:06, 43.92s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [21:09<15:20, 43.85s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [21:52<14:36, 43.80s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [22:36<13:50, 43.71s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [23:20<13:09, 43.84s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [24:04<12:27, 43.98s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [24:49<11:47, 44.23s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [25:34<11:03, 44.25s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [26:17<10:17, 44.13s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [27:02<09:35, 44.24s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [27:46<08:52, 44.35s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [28:30<08:06, 44.25s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [29:15<07:23, 44.36s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [29:59<06:38, 44.31s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [30:43<05:53, 44.19s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [31:27<05:08, 44.12s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [32:11<04:24, 44.12s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [32:56<03:41, 44.23s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [33:40<02:56, 44.17s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [34:24<02:12, 44.24s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [35:09<01:28, 44.29s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [35:53<00:44, 44.28s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [36:37<00:00, 44.32s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [36:37<00:00, 43.96s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.2907} | lm_loss 10.2633 | avg. gen lenth: 339.444
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o4-tcommonsenseqa-s1-rTrue --seed 1 --rationales --num-out-domain 4
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-12 16:46:34,359] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o4-tcommonsenseqa-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 4
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o4-tcommonsenseqa-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  0%|▏                                                    | 21/7473 [00:00<00:36, 203.55it/s]  1%|▎                                                    | 42/7473 [00:00<00:36, 204.23it/s]  1%|▍                                                    | 63/7473 [00:00<00:36, 204.50it/s]  1%|▌                                                    | 84/7473 [00:00<00:36, 205.10it/s]  1%|▋                                                   | 105/7473 [00:00<00:35, 205.13it/s]  2%|▉                                                   | 126/7473 [00:00<00:35, 205.37it/s]  2%|█                                                   | 147/7473 [00:00<00:35, 205.41it/s]  2%|█▏                                                  | 168/7473 [00:00<00:36, 202.72it/s]  3%|█▎                                                  | 189/7473 [00:00<00:35, 203.70it/s]  3%|█▍                                                  | 210/7473 [00:01<00:35, 204.78it/s]  3%|█▌                                                  | 231/7473 [00:01<00:35, 205.14it/s]  3%|█▊                                                  | 252/7473 [00:01<00:35, 203.19it/s]  4%|█▉                                                  | 273/7473 [00:01<00:35, 204.06it/s]  4%|██                                                  | 294/7473 [00:01<00:35, 204.61it/s]  4%|██▏                                                 | 315/7473 [00:01<00:34, 205.03it/s]  5%|██▎                                                 | 339/7473 [00:01<00:33, 214.00it/s]  5%|██▌                                                 | 371/7473 [00:01<00:29, 243.43it/s]  5%|██▊                                                 | 402/7473 [00:01<00:27, 260.76it/s]  6%|███                                                 | 434/7473 [00:01<00:25, 275.86it/s]  6%|███▏                                                | 466/7473 [00:02<00:24, 286.77it/s]  7%|███▍                                                | 497/7473 [00:02<00:23, 291.59it/s]  7%|███▋                                                | 529/7473 [00:02<00:23, 298.23it/s]  8%|███▉                                                | 561/7473 [00:02<00:22, 303.13it/s]  8%|████▏                                               | 593/7473 [00:02<00:22, 305.97it/s]  8%|████▎                                               | 624/7473 [00:02<00:22, 306.81it/s]  9%|████▌                                               | 656/7473 [00:02<00:22, 308.30it/s]  9%|████▊                                               | 688/7473 [00:02<00:21, 309.01it/s] 10%|█████                                               | 719/7473 [00:02<00:21, 308.67it/s] 10%|█████▏                                              | 751/7473 [00:02<00:21, 310.25it/s] 10%|█████▍                                              | 783/7473 [00:03<00:21, 310.33it/s] 11%|█████▋                                              | 815/7473 [00:03<00:21, 310.50it/s] 11%|█████▉                                              | 847/7473 [00:03<00:21, 310.71it/s] 12%|██████                                              | 879/7473 [00:03<00:21, 311.03it/s] 12%|██████▎                                             | 911/7473 [00:03<00:21, 311.37it/s] 13%|██████▌                                             | 943/7473 [00:03<00:21, 309.40it/s] 13%|██████▊                                             | 975/7473 [00:03<00:20, 310.09it/s] 13%|██████▊                                            | 1007/7473 [00:03<00:20, 310.27it/s] 14%|███████                                            | 1039/7473 [00:03<00:20, 310.77it/s] 14%|███████▎                                           | 1071/7473 [00:03<00:20, 311.48it/s] 15%|███████▌                                           | 1103/7473 [00:04<00:20, 311.14it/s] 15%|███████▋                                           | 1135/7473 [00:04<00:20, 310.88it/s] 16%|███████▉                                           | 1167/7473 [00:04<00:20, 309.34it/s] 16%|████████▏                                          | 1199/7473 [00:04<00:20, 310.16it/s] 16%|████████▍                                          | 1231/7473 [00:04<00:20, 309.99it/s] 17%|████████▌                                          | 1263/7473 [00:04<00:20, 310.42it/s] 17%|████████▊                                          | 1295/7473 [00:04<00:19, 310.54it/s] 18%|█████████                                          | 1327/7473 [00:04<00:19, 310.03it/s] 18%|█████████▎                                         | 1359/7473 [00:04<00:19, 310.60it/s] 19%|█████████▍                                         | 1391/7473 [00:05<00:19, 308.14it/s] 19%|█████████▋                                         | 1423/7473 [00:05<00:19, 309.09it/s] 19%|█████████▉                                         | 1455/7473 [00:05<00:19, 309.44it/s] 20%|██████████▏                                        | 1487/7473 [00:05<00:19, 310.06it/s] 20%|██████████▎                                        | 1519/7473 [00:05<00:19, 310.87it/s] 21%|██████████▌                                        | 1551/7473 [00:05<00:19, 310.61it/s] 21%|██████████▊                                        | 1583/7473 [00:05<00:19, 309.86it/s] 22%|███████████                                        | 1614/7473 [00:05<00:19, 306.87it/s] 22%|███████████▏                                       | 1645/7473 [00:05<00:18, 307.64it/s] 22%|███████████▍                                       | 1676/7473 [00:05<00:18, 308.33it/s] 23%|███████████▋                                       | 1708/7473 [00:06<00:18, 309.09it/s] 23%|███████████▊                                       | 1740/7473 [00:06<00:18, 309.37it/s] 24%|████████████                                       | 1772/7473 [00:06<00:18, 309.68it/s] 24%|████████████▎                                      | 1804/7473 [00:06<00:18, 309.78it/s] 25%|████████████▌                                      | 1835/7473 [00:06<00:18, 309.61it/s] 25%|████████████▋                                      | 1866/7473 [00:06<00:18, 308.22it/s] 25%|████████████▉                                      | 1897/7473 [00:06<00:18, 308.64it/s] 26%|█████████████▏                                     | 1928/7473 [00:06<00:18, 307.79it/s] 26%|█████████████▍                                     | 1960/7473 [00:06<00:17, 308.59it/s] 27%|█████████████▌                                     | 1991/7473 [00:06<00:17, 308.97it/s] 27%|█████████████▊                                     | 2022/7473 [00:07<00:17, 306.56it/s] 27%|██████████████                                     | 2054/7473 [00:07<00:17, 307.98it/s] 28%|██████████████▏                                    | 2085/7473 [00:07<00:17, 306.84it/s] 28%|██████████████▍                                    | 2116/7473 [00:07<00:17, 307.62it/s] 29%|██████████████▋                                    | 2148/7473 [00:07<00:17, 308.34it/s] 29%|██████████████▉                                    | 2180/7473 [00:07<00:17, 309.05it/s] 30%|███████████████                                    | 2212/7473 [00:07<00:16, 309.70it/s] 30%|███████████████▎                                   | 2244/7473 [00:07<00:16, 309.85it/s] 30%|███████████████▌                                   | 2275/7473 [00:07<00:16, 309.76it/s] 31%|███████████████▋                                   | 2306/7473 [00:07<00:16, 308.44it/s] 31%|███████████████▉                                   | 2338/7473 [00:08<00:16, 309.05it/s] 32%|████████████████▏                                  | 2369/7473 [00:08<00:16, 309.08it/s] 32%|████████████████▍                                  | 2400/7473 [00:08<00:16, 307.33it/s] 33%|████████████████▌                                  | 2432/7473 [00:08<00:16, 308.69it/s] 33%|████████████████▊                                  | 2464/7473 [00:08<00:16, 309.39it/s] 33%|█████████████████                                  | 2496/7473 [00:08<00:16, 309.62it/s] 34%|█████████████████▏                                 | 2527/7473 [00:08<00:17, 282.60it/s] 34%|█████████████████▍                                 | 2558/7473 [00:08<00:16, 289.43it/s] 35%|█████████████████▋                                 | 2590/7473 [00:08<00:16, 295.96it/s] 35%|█████████████████▉                                 | 2622/7473 [00:09<00:16, 300.29it/s] 36%|██████████████████                                 | 2654/7473 [00:09<00:15, 303.27it/s] 36%|██████████████████▎                                | 2686/7473 [00:09<00:15, 305.60it/s] 36%|██████████████████▌                                | 2718/7473 [00:09<00:15, 307.38it/s] 37%|██████████████████▊                                | 2749/7473 [00:09<00:15, 306.23it/s] 37%|██████████████████▉                                | 2780/7473 [00:09<00:15, 307.30it/s] 38%|███████████████████▏                               | 2811/7473 [00:09<00:15, 305.97it/s] 38%|███████████████████▍                               | 2843/7473 [00:09<00:15, 307.34it/s] 38%|███████████████████▌                               | 2874/7473 [00:09<00:14, 306.83it/s] 39%|███████████████████▊                               | 2906/7473 [00:09<00:14, 308.22it/s] 39%|████████████████████                               | 2938/7473 [00:10<00:14, 309.66it/s] 40%|████████████████████▎                              | 2970/7473 [00:10<00:14, 310.31it/s] 40%|████████████████████▍                              | 3002/7473 [00:10<00:14, 308.68it/s] 41%|████████████████████▋                              | 3033/7473 [00:10<00:14, 308.73it/s] 41%|████████████████████▉                              | 3064/7473 [00:10<00:14, 309.07it/s] 41%|█████████████████████                              | 3095/7473 [00:10<00:14, 308.77it/s] 42%|█████████████████████▎                             | 3126/7473 [00:10<00:14, 308.29it/s] 42%|█████████████████████▌                             | 3157/7473 [00:10<00:14, 307.65it/s] 43%|█████████████████████▊                             | 3188/7473 [00:10<00:13, 308.12it/s] 43%|█████████████████████▉                             | 3219/7473 [00:10<00:13, 306.99it/s] 44%|██████████████████████▏                            | 3251/7473 [00:11<00:13, 308.13it/s] 44%|██████████████████████▍                            | 3283/7473 [00:11<00:13, 308.86it/s] 44%|██████████████████████▌                            | 3314/7473 [00:11<00:13, 309.13it/s] 45%|██████████████████████▊                            | 3345/7473 [00:11<00:13, 308.46it/s] 45%|███████████████████████                            | 3376/7473 [00:11<00:13, 308.55it/s] 46%|███████████████████████▎                           | 3407/7473 [00:11<00:13, 308.62it/s] 46%|███████████████████████▍                           | 3438/7473 [00:11<00:13, 306.93it/s] 46%|███████████████████████▋                           | 3469/7473 [00:11<00:13, 307.12it/s] 47%|███████████████████████▉                           | 3501/7473 [00:11<00:12, 308.41it/s] 47%|████████████████████████                           | 3532/7473 [00:11<00:12, 308.70it/s] 48%|████████████████████████▎                          | 3563/7473 [00:12<00:12, 309.07it/s] 48%|████████████████████████▌                          | 3595/7473 [00:12<00:12, 309.70it/s] 49%|████████████████████████▋                          | 3626/7473 [00:12<00:12, 309.55it/s] 49%|████████████████████████▉                          | 3657/7473 [00:12<00:12, 306.87it/s] 49%|█████████████████████████▏                         | 3688/7473 [00:12<00:12, 307.58it/s] 50%|█████████████████████████▍                         | 3719/7473 [00:12<00:12, 307.29it/s] 50%|█████████████████████████▌                         | 3750/7473 [00:12<00:12, 307.59it/s] 51%|█████████████████████████▊                         | 3781/7473 [00:12<00:12, 306.97it/s] 51%|██████████████████████████                         | 3812/7473 [00:12<00:11, 307.70it/s] 51%|██████████████████████████▏                        | 3843/7473 [00:13<00:11, 307.16it/s] 52%|██████████████████████████▍                        | 3874/7473 [00:13<00:11, 307.11it/s] 52%|██████████████████████████▋                        | 3905/7473 [00:13<00:11, 305.50it/s] 53%|██████████████████████████▊                        | 3936/7473 [00:13<00:11, 306.52it/s] 53%|███████████████████████████                        | 3967/7473 [00:13<00:11, 307.25it/s] 53%|███████████████████████████▎                       | 3998/7473 [00:13<00:11, 307.57it/s] 54%|███████████████████████████▍                       | 4029/7473 [00:13<00:11, 308.06it/s] 54%|███████████████████████████▋                       | 4060/7473 [00:13<00:11, 308.42it/s] 55%|███████████████████████████▉                       | 4091/7473 [00:13<00:10, 308.36it/s] 55%|████████████████████████████▏                      | 4122/7473 [00:13<00:10, 305.01it/s] 56%|████████████████████████████▎                      | 4153/7473 [00:14<00:10, 305.09it/s] 56%|████████████████████████████▌                      | 4184/7473 [00:14<00:10, 305.76it/s] 56%|████████████████████████████▊                      | 4215/7473 [00:14<00:10, 306.23it/s] 57%|████████████████████████████▉                      | 4246/7473 [00:14<00:10, 307.24it/s] 57%|█████████████████████████████▏                     | 4277/7473 [00:14<00:10, 306.88it/s] 58%|█████████████████████████████▍                     | 4308/7473 [00:14<00:10, 307.29it/s] 58%|█████████████████████████████▌                     | 4339/7473 [00:14<00:10, 306.20it/s] 58%|█████████████████████████████▊                     | 4370/7473 [00:14<00:10, 306.56it/s] 59%|██████████████████████████████                     | 4401/7473 [00:14<00:10, 305.74it/s] 59%|██████████████████████████████▏                    | 4432/7473 [00:14<00:09, 305.95it/s] 60%|██████████████████████████████▍                    | 4463/7473 [00:15<00:09, 305.84it/s] 60%|██████████████████████████████▋                    | 4494/7473 [00:15<00:09, 306.34it/s] 61%|██████████████████████████████▉                    | 4525/7473 [00:15<00:09, 306.17it/s] 61%|███████████████████████████████                    | 4557/7473 [00:15<00:09, 307.82it/s] 61%|███████████████████████████████▎                   | 4588/7473 [00:15<00:09, 307.87it/s] 62%|███████████████████████████████▌                   | 4620/7473 [00:15<00:09, 309.09it/s] 62%|███████████████████████████████▋                   | 4652/7473 [00:15<00:09, 309.87it/s] 63%|███████████████████████████████▉                   | 4684/7473 [00:15<00:08, 310.48it/s] 63%|████████████████████████████████▏                  | 4716/7473 [00:15<00:08, 310.83it/s] 64%|████████████████████████████████▍                  | 4748/7473 [00:15<00:08, 311.56it/s] 64%|████████████████████████████████▌                  | 4780/7473 [00:16<00:08, 312.28it/s] 64%|████████████████████████████████▊                  | 4812/7473 [00:16<00:08, 310.60it/s] 65%|█████████████████████████████████                  | 4844/7473 [00:16<00:08, 311.46it/s] 65%|█████████████████████████████████▎                 | 4876/7473 [00:16<00:08, 311.25it/s] 66%|█████████████████████████████████▍                 | 4908/7473 [00:16<00:08, 311.73it/s] 66%|█████████████████████████████████▋                 | 4940/7473 [00:16<00:08, 311.54it/s] 67%|█████████████████████████████████▉                 | 4972/7473 [00:16<00:08, 311.69it/s] 67%|██████████████████████████████████▏                | 5004/7473 [00:16<00:07, 312.20it/s] 67%|██████████████████████████████████▎                | 5036/7473 [00:16<00:07, 309.97it/s] 68%|██████████████████████████████████▌                | 5068/7473 [00:16<00:07, 311.08it/s] 68%|██████████████████████████████████▊                | 5100/7473 [00:17<00:07, 311.60it/s] 69%|███████████████████████████████████                | 5132/7473 [00:17<00:07, 312.00it/s] 69%|███████████████████████████████████▏               | 5164/7473 [00:17<00:07, 312.22it/s] 70%|███████████████████████████████████▍               | 5196/7473 [00:17<00:07, 312.32it/s] 70%|███████████████████████████████████▋               | 5228/7473 [00:17<00:07, 312.74it/s] 70%|███████████████████████████████████▉               | 5260/7473 [00:17<00:07, 290.15it/s] 71%|████████████████████████████████████               | 5292/7473 [00:17<00:07, 296.43it/s] 71%|████████████████████████████████████▎              | 5324/7473 [00:17<00:07, 300.71it/s] 72%|████████████████████████████████████▌              | 5356/7473 [00:17<00:06, 304.11it/s] 72%|████████████████████████████████████▊              | 5388/7473 [00:18<00:06, 306.57it/s] 73%|████████████████████████████████████▉              | 5419/7473 [00:18<00:06, 305.97it/s] 73%|█████████████████████████████████████▏             | 5451/7473 [00:18<00:06, 308.12it/s] 73%|█████████████████████████████████████▍             | 5482/7473 [00:18<00:09, 205.31it/s] 74%|█████████████████████████████████████▋             | 5514/7473 [00:18<00:08, 229.10it/s] 74%|█████████████████████████████████████▊             | 5546/7473 [00:18<00:07, 249.02it/s] 75%|██████████████████████████████████████             | 5578/7473 [00:18<00:07, 265.34it/s] 75%|██████████████████████████████████████▎            | 5609/7473 [00:18<00:06, 276.62it/s] 75%|██████████████████████████████████████▍            | 5641/7473 [00:19<00:06, 286.43it/s] 76%|██████████████████████████████████████▋            | 5673/7473 [00:19<00:06, 293.81it/s] 76%|██████████████████████████████████████▉            | 5704/7473 [00:19<00:05, 297.72it/s] 77%|███████████████████████████████████████▏           | 5736/7473 [00:19<00:05, 301.62it/s] 77%|███████████████████████████████████████▎           | 5768/7473 [00:19<00:05, 305.12it/s] 78%|███████████████████████████████████████▌           | 5800/7473 [00:19<00:05, 307.28it/s] 78%|███████████████████████████████████████▊           | 5832/7473 [00:19<00:05, 308.08it/s] 78%|████████████████████████████████████████           | 5864/7473 [00:19<00:05, 309.31it/s] 79%|████████████████████████████████████████▏          | 5896/7473 [00:19<00:05, 307.76it/s] 79%|████████████████████████████████████████▍          | 5927/7473 [00:19<00:05, 306.91it/s] 80%|████████████████████████████████████████▋          | 5958/7473 [00:20<00:04, 307.63it/s] 80%|████████████████████████████████████████▊          | 5989/7473 [00:20<00:04, 308.13it/s] 81%|█████████████████████████████████████████          | 6021/7473 [00:20<00:04, 309.25it/s] 81%|█████████████████████████████████████████▎         | 6053/7473 [00:20<00:04, 310.47it/s] 81%|█████████████████████████████████████████▌         | 6085/7473 [00:20<00:04, 311.49it/s] 82%|█████████████████████████████████████████▋         | 6117/7473 [00:20<00:04, 311.89it/s] 82%|█████████████████████████████████████████▉         | 6149/7473 [00:20<00:04, 310.11it/s] 83%|██████████████████████████████████████████▏        | 6181/7473 [00:20<00:04, 310.77it/s] 83%|██████████████████████████████████████████▍        | 6213/7473 [00:20<00:04, 310.81it/s] 84%|██████████████████████████████████████████▌        | 6245/7473 [00:20<00:03, 310.08it/s] 84%|██████████████████████████████████████████▊        | 6277/7473 [00:21<00:03, 310.96it/s] 84%|███████████████████████████████████████████        | 6309/7473 [00:21<00:03, 311.26it/s] 85%|███████████████████████████████████████████▎       | 6341/7473 [00:21<00:03, 311.88it/s] 85%|███████████████████████████████████████████▍       | 6373/7473 [00:21<00:03, 309.66it/s] 86%|███████████████████████████████████████████▋       | 6405/7473 [00:21<00:03, 310.05it/s] 86%|███████████████████████████████████████████▉       | 6437/7473 [00:21<00:03, 308.14it/s] 87%|████████████████████████████████████████████▏      | 6469/7473 [00:21<00:03, 309.09it/s] 87%|████████████████████████████████████████████▎      | 6501/7473 [00:21<00:03, 310.10it/s] 87%|████████████████████████████████████████████▌      | 6533/7473 [00:21<00:03, 309.97it/s] 88%|████████████████████████████████████████████▊      | 6565/7473 [00:21<00:02, 310.23it/s] 88%|█████████████████████████████████████████████      | 6597/7473 [00:22<00:02, 309.49it/s] 89%|█████████████████████████████████████████████▏     | 6629/7473 [00:22<00:02, 310.04it/s] 89%|█████████████████████████████████████████████▍     | 6661/7473 [00:22<00:02, 310.26it/s] 90%|█████████████████████████████████████████████▋     | 6693/7473 [00:22<00:02, 310.67it/s] 90%|█████████████████████████████████████████████▉     | 6725/7473 [00:22<00:02, 310.94it/s] 90%|██████████████████████████████████████████████     | 6757/7473 [00:22<00:02, 310.97it/s] 91%|██████████████████████████████████████████████▎    | 6789/7473 [00:22<00:02, 311.18it/s] 91%|██████████████████████████████████████████████▌    | 6821/7473 [00:22<00:02, 309.20it/s] 92%|██████████████████████████████████████████████▊    | 6852/7473 [00:22<00:02, 309.19it/s] 92%|██████████████████████████████████████████████▉    | 6884/7473 [00:23<00:01, 310.21it/s] 93%|███████████████████████████████████████████████▏   | 6916/7473 [00:23<00:01, 311.12it/s] 93%|███████████████████████████████████████████████▍   | 6948/7473 [00:23<00:01, 309.35it/s] 93%|███████████████████████████████████████████████▋   | 6980/7473 [00:23<00:01, 309.73it/s] 94%|███████████████████████████████████████████████▊   | 7012/7473 [00:23<00:01, 310.05it/s] 94%|████████████████████████████████████████████████   | 7044/7473 [00:23<00:01, 308.62it/s] 95%|████████████████████████████████████████████████▎  | 7076/7473 [00:23<00:01, 309.76it/s] 95%|████████████████████████████████████████████████▌  | 7108/7473 [00:23<00:01, 310.41it/s] 96%|████████████████████████████████████████████████▋  | 7140/7473 [00:23<00:01, 310.37it/s] 96%|████████████████████████████████████████████████▉  | 7172/7473 [00:23<00:00, 310.79it/s] 96%|█████████████████████████████████████████████████▏ | 7204/7473 [00:24<00:00, 311.05it/s] 97%|█████████████████████████████████████████████████▍ | 7236/7473 [00:24<00:00, 310.77it/s] 97%|█████████████████████████████████████████████████▌ | 7268/7473 [00:24<00:00, 309.54it/s] 98%|█████████████████████████████████████████████████▊ | 7300/7473 [00:24<00:00, 310.49it/s] 98%|██████████████████████████████████████████████████ | 7332/7473 [00:24<00:00, 310.51it/s] 99%|██████████████████████████████████████████████████▎| 7364/7473 [00:24<00:00, 310.64it/s] 99%|██████████████████████████████████████████████████▍| 7396/7473 [00:24<00:00, 311.12it/s] 99%|██████████████████████████████████████████████████▋| 7428/7473 [00:24<00:00, 311.39it/s]100%|██████████████████████████████████████████████████▉| 7460/7473 [00:24<00:00, 310.79it/s]100%|███████████████████████████████████████████████████| 7473/7473 [00:24<00:00, 299.82it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:04<00:09,  4.74s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.18s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.30s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.27s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:09<00:04,  4.82s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.27s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.43s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.38s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.22s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.38s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.81s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.93s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.81s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.97s/it]
[2023-08-12 16:47:51,746] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.78s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.93s/it]
[2023-08-12 16:48:03,303] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 16:48:03,304] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 16:48:03,304] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f49c2797fa0>
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 16:48:03,305] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f49c297e700>
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 16:48:03,306] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 16:48:03,306] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.5633916854858398 seconds
Loading extension module utils...
Time to load utils op: 0.5046994686126709 seconds
Loading extension module utils...
Time to load utils op: 0.5047354698181152 seconds
Loading extension module utils...
Time to load utils op: 0.6049232482910156 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Rationales: 1. First, consider what the problem is asking. It is questioning where you could find a type of plumbing that would not help you if you were in need of a drink of water.
2. In the process of elimination, start with evaluating each option and its probability of having drinkable water. 
3. Option A is oil refineries. These facilities primarily process oil, not water. As such, most of the plumbing found in oil refineries is used for the transportation of oil and other types of fuels. Drinking the water from oil refineries would have myriad health risks due to potential contamination or exposure to harmful chemicals.
4. Next, option B is a wall. Plumbing inside walls typically carries water. This water could be from the municipal supply or well, which provides potable water inside a house.
5. Option C is a "show." It's somewhat ambiguous, but it could refer to a home show or trade show, where there could be live displays of plumbing in action. In that case, it's likely there would be clean water accessible.
6. Option D is "own home," which most definitely would provide drinkable water coming from faucets, showers, and refrigerators.
7. Finally, option E is a water fountain. Water fountains are specifically designed to provide drinking water.
8. After comparing all the options, the most sensible option is "A: oil refineries." It is the only choice where the primary function does not involve the usage or transportation of drinkable water. Therefore, you could find a type of plumbing that would not be of use to you for drinking purposes.
Answer: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Rationales: 1. First, we need to clarify the meaning of each option in the context of "beginning work".
2. "Working" cannot be the answer because when a person is beginning to work, they are technically already working.
3. "Resting" cannot be the answer either, as it is opposite to the premise. When a person is beginning to work, they certainly are not resting.
4. "Tiredness" is a state that might come during or after work, but it doesn't necessarily relate to the immediate state of beginning work. However, it does not fit as the best answer.
5. "Momentum" is a term that speaks more to the energy or drive to do work, and while it may build as a person begins work, it's not something that the person isn't doing. 
6. This leaves us with "accomplishing". When a person is just beginning to work, they may not have accomplished anything yet, as accomplishing usually indicates completion or reaching a desired outcome.
7. Therefore, "accomplishing" is the correct answer.
Answer: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Rationales: 1. The question asks us where we can find pens that have a company logo.
2. The 'company logo' part of the question suggests that the pens are likely distributed or used in a professional environment where branding is important. 
3. Choice B suggests "on a pencil" which is illogical because pencils and pens are two different types of writing tools. So, this can't be correct.
4. Choice C suggests "write sentences on paper". This is not a place where pens could be found, it's rather an action you do with a pen, hence it is incorrect.
5. Choice D: "school", while pens are indeed commonly used in this setting, pens with company logos are designed to promote the brand, they are not common or usually distributed at schools. So this is not likely the answer.
6. Choice E: "backpack" is too generic, while you may find pens inside it, this doesn't necessarily mean they would be pens with a company logo. 
7. That leaves choice A: "office", offices are professional environments where items like pens can have a company logo for branding purposes.
8. Therefore, the logical choice and answer is A: office.
Answer: A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Rationales: 1. The question tells us that Billy called out to John. This tells us that Billy is attempting some form of communication with John.
2. The phrase "listened for" indicates that Billy is waiting for some sort of feedback or answer from John.
3. We can eliminate answer choice A - "silence" because Billy wouldn't call out to John to hear silence.
4. Answer choice C - "communication" could potentially be a match, but in the context of the question, communication is too broad. Billy is specifically looking for something from John, and not just general communication.
5. Answer choice D - "hanging up" and E - "whisper" are irrelevant as Billy is presumably not using a phone, and there's nothing in the context to suggest that Billy wants John to whisper.
6. Therefore, the correct answer is B: "response", because Billy called out to John and therefore would naturally be waiting for a response.
Answer: B: response

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o4-tcommonsenseqa-s1-rTrue
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:42<34:52, 42.71s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:24<33:36, 42.02s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:06<32:51, 41.96s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [02:47<32:03, 41.81s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [03:29<31:17, 41.72s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [04:10<30:33, 41.68s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [04:52<29:56, 41.77s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [05:31<28:27, 40.67s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [06:06<26:34, 38.89s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [06:47<26:32, 39.81s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [07:29<26:18, 40.48s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [08:11<25:53, 40.87s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [08:53<25:24, 41.20s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [09:35<24:53, 41.49s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [10:17<24:18, 41.69s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [10:59<23:40, 41.78s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [11:41<23:00, 41.83s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [12:23<22:16, 41.78s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [13:05<21:37, 41.87s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [13:47<20:51, 41.71s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [14:28<20:09, 41.70s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [15:11<19:33, 41.91s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [15:52<18:50, 41.89s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [16:34<18:05, 41.75s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [17:16<17:25, 41.83s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [17:58<16:45, 41.91s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [18:40<16:01, 41.81s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [19:21<15:18, 41.76s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [19:55<13:48, 39.45s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [20:37<13:25, 40.27s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [21:19<12:54, 40.75s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [22:01<12:20, 41.15s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [22:31<10:42, 37.82s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [23:13<10:24, 39.02s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [23:56<10:01, 40.07s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [24:38<09:28, 40.63s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [25:19<08:51, 40.92s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [26:01<08:14, 41.21s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [26:43<07:35, 41.40s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [27:25<06:55, 41.52s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [28:07<06:14, 41.61s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [28:31<04:51, 36.48s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [29:13<04:27, 38.15s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [29:55<03:55, 39.22s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [30:37<03:20, 40.03s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [31:19<02:42, 40.63s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [32:01<02:03, 41.01s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [32:43<01:22, 41.31s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [33:24<00:41, 41.40s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [34:06<00:00, 41.53s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [34:06<00:00, 40.93s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.2788} | lm_loss 10.1938 | avg. gen lenth: 328.844
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o5-tcommonsenseqa-s1-rTrue --seed 1 --rationales --num-out-domain 5
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-12 17:22:58,083] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o5-tcommonsenseqa-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 5
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o5-tcommonsenseqa-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  0%|▏                                                    | 18/7473 [00:00<00:41, 179.49it/s]  0%|▎                                                    | 36/7473 [00:00<00:41, 179.31it/s]  1%|▍                                                    | 55/7473 [00:00<00:41, 179.91it/s]  1%|▌                                                    | 74/7473 [00:00<00:41, 180.05it/s]  1%|▋                                                    | 93/7473 [00:00<00:40, 180.76it/s]  1%|▊                                                   | 112/7473 [00:00<00:40, 180.92it/s]  2%|▉                                                   | 131/7473 [00:00<00:41, 178.14it/s]  2%|█                                                   | 150/7473 [00:00<00:40, 179.08it/s]  2%|█▏                                                  | 169/7473 [00:00<00:40, 179.76it/s]  3%|█▎                                                  | 188/7473 [00:01<00:40, 180.43it/s]  3%|█▍                                                  | 207/7473 [00:01<00:40, 181.13it/s]  3%|█▌                                                  | 226/7473 [00:01<00:39, 181.44it/s]  3%|█▋                                                  | 245/7473 [00:01<00:39, 180.99it/s]  4%|█▊                                                  | 264/7473 [00:01<00:40, 179.43it/s]  4%|█▉                                                  | 283/7473 [00:01<00:39, 180.22it/s]  4%|██                                                  | 302/7473 [00:01<00:39, 180.49it/s]  4%|██▏                                                 | 321/7473 [00:01<00:39, 179.51it/s]  5%|██▎                                                 | 339/7473 [00:01<00:39, 179.37it/s]  5%|██▍                                                 | 358/7473 [00:01<00:39, 180.11it/s]  5%|██▌                                                 | 377/7473 [00:02<00:39, 180.12it/s]  5%|██▊                                                 | 396/7473 [00:02<00:39, 180.22it/s]  6%|██▉                                                 | 420/7473 [00:02<00:35, 196.11it/s]  6%|███                                                 | 448/7473 [00:02<00:32, 219.32it/s]  6%|███▎                                                | 476/7473 [00:02<00:29, 234.42it/s]  7%|███▌                                                | 504/7473 [00:02<00:28, 246.37it/s]  7%|███▋                                                | 532/7473 [00:02<00:27, 255.73it/s]  7%|███▉                                                | 560/7473 [00:02<00:26, 262.05it/s]  8%|████                                                | 588/7473 [00:02<00:25, 265.93it/s]  8%|████▎                                               | 616/7473 [00:03<00:25, 268.78it/s]  9%|████▍                                               | 644/7473 [00:03<00:25, 270.67it/s]  9%|████▋                                               | 672/7473 [00:03<00:24, 272.78it/s]  9%|████▊                                               | 700/7473 [00:03<00:24, 273.97it/s] 10%|█████                                               | 728/7473 [00:03<00:24, 273.44it/s] 10%|█████▎                                              | 756/7473 [00:03<00:24, 274.51it/s] 10%|█████▍                                              | 784/7473 [00:03<00:24, 274.61it/s] 11%|█████▋                                              | 812/7473 [00:03<00:24, 275.06it/s] 11%|█████▊                                              | 840/7473 [00:03<00:24, 275.07it/s] 12%|██████                                              | 868/7473 [00:03<00:23, 275.60it/s] 12%|██████▏                                             | 896/7473 [00:04<00:23, 275.79it/s] 12%|██████▍                                             | 924/7473 [00:04<00:23, 275.90it/s] 13%|██████▌                                             | 952/7473 [00:04<00:23, 274.11it/s] 13%|██████▊                                             | 980/7473 [00:04<00:23, 274.82it/s] 13%|██████▉                                            | 1008/7473 [00:04<00:23, 275.02it/s] 14%|███████                                            | 1036/7473 [00:04<00:23, 275.57it/s] 14%|███████▎                                           | 1064/7473 [00:04<00:23, 276.16it/s] 15%|███████▍                                           | 1092/7473 [00:04<00:23, 276.32it/s] 15%|███████▋                                           | 1120/7473 [00:04<00:23, 275.85it/s] 15%|███████▊                                           | 1148/7473 [00:04<00:22, 275.83it/s] 16%|████████                                           | 1176/7473 [00:05<00:22, 273.81it/s] 16%|████████▏                                          | 1204/7473 [00:05<00:22, 273.97it/s] 16%|████████▍                                          | 1232/7473 [00:05<00:22, 274.41it/s] 17%|████████▌                                          | 1260/7473 [00:05<00:22, 275.09it/s] 17%|████████▊                                          | 1288/7473 [00:05<00:22, 275.14it/s] 18%|████████▉                                          | 1316/7473 [00:05<00:22, 275.42it/s] 18%|█████████▏                                         | 1344/7473 [00:05<00:22, 274.23it/s] 18%|█████████▎                                         | 1372/7473 [00:05<00:22, 274.63it/s] 19%|█████████▌                                         | 1400/7473 [00:05<00:22, 272.22it/s] 19%|█████████▋                                         | 1428/7473 [00:05<00:22, 267.09it/s] 19%|█████████▉                                         | 1456/7473 [00:06<00:22, 268.00it/s] 20%|██████████▏                                        | 1484/7473 [00:06<00:22, 270.34it/s] 20%|██████████▎                                        | 1512/7473 [00:06<00:21, 272.28it/s] 21%|██████████▌                                        | 1540/7473 [00:06<00:21, 272.50it/s] 21%|██████████▋                                        | 1568/7473 [00:06<00:21, 272.75it/s] 21%|██████████▉                                        | 1596/7473 [00:06<00:21, 273.20it/s] 22%|███████████                                        | 1624/7473 [00:06<00:21, 271.83it/s] 22%|███████████▎                                       | 1652/7473 [00:06<00:21, 272.85it/s] 22%|███████████▍                                       | 1680/7473 [00:06<00:21, 273.96it/s] 23%|███████████▋                                       | 1708/7473 [00:07<00:21, 271.90it/s] 23%|███████████▊                                       | 1736/7473 [00:07<00:21, 272.75it/s] 24%|████████████                                       | 1764/7473 [00:07<00:20, 272.88it/s] 24%|████████████▏                                      | 1792/7473 [00:07<00:20, 273.34it/s] 24%|████████████▍                                      | 1820/7473 [00:07<00:20, 273.94it/s] 25%|████████████▌                                      | 1848/7473 [00:07<00:20, 271.93it/s] 25%|████████████▊                                      | 1876/7473 [00:07<00:20, 273.15it/s] 25%|████████████▉                                      | 1904/7473 [00:07<00:20, 273.26it/s] 26%|█████████████▏                                     | 1932/7473 [00:07<00:20, 273.35it/s] 26%|█████████████▍                                     | 1960/7473 [00:07<00:20, 273.86it/s] 27%|█████████████▌                                     | 1988/7473 [00:08<00:19, 274.33it/s] 27%|█████████████▊                                     | 2016/7473 [00:08<00:19, 274.60it/s] 27%|█████████████▉                                     | 2044/7473 [00:08<00:19, 274.90it/s] 28%|██████████████▏                                    | 2072/7473 [00:08<00:20, 268.73it/s] 28%|██████████████▎                                    | 2100/7473 [00:08<00:19, 270.23it/s] 28%|██████████████▌                                    | 2128/7473 [00:08<00:19, 270.80it/s] 29%|██████████████▋                                    | 2156/7473 [00:08<00:19, 272.24it/s] 29%|██████████████▉                                    | 2184/7473 [00:08<00:19, 272.96it/s] 30%|███████████████                                    | 2212/7473 [00:08<00:19, 274.12it/s] 30%|███████████████▎                                   | 2240/7473 [00:08<00:19, 274.28it/s] 30%|███████████████▍                                   | 2268/7473 [00:09<00:18, 274.51it/s] 31%|███████████████▋                                   | 2296/7473 [00:09<00:18, 272.56it/s] 31%|███████████████▊                                   | 2324/7473 [00:09<00:18, 273.49it/s] 31%|████████████████                                   | 2352/7473 [00:09<00:18, 273.81it/s] 32%|████████████████▏                                  | 2380/7473 [00:09<00:18, 274.01it/s] 32%|████████████████▍                                  | 2408/7473 [00:09<00:18, 272.80it/s] 33%|████████████████▌                                  | 2436/7473 [00:09<00:18, 273.51it/s] 33%|████████████████▊                                  | 2464/7473 [00:09<00:18, 274.00it/s] 33%|█████████████████                                  | 2492/7473 [00:09<00:18, 274.11it/s] 34%|█████████████████▏                                 | 2520/7473 [00:10<00:20, 239.98it/s] 34%|█████████████████▍                                 | 2548/7473 [00:10<00:19, 249.33it/s] 34%|█████████████████▌                                 | 2576/7473 [00:10<00:19, 256.86it/s] 35%|█████████████████▊                                 | 2604/7473 [00:10<00:18, 262.14it/s] 35%|█████████████████▉                                 | 2632/7473 [00:10<00:18, 265.66it/s] 36%|██████████████████▏                                | 2660/7473 [00:10<00:17, 268.75it/s] 36%|██████████████████▎                                | 2688/7473 [00:10<00:17, 270.83it/s] 36%|██████████████████▌                                | 2716/7473 [00:10<00:17, 272.26it/s] 37%|██████████████████▋                                | 2744/7473 [00:10<00:17, 272.60it/s] 37%|██████████████████▉                                | 2772/7473 [00:10<00:17, 271.75it/s] 37%|███████████████████                                | 2800/7473 [00:11<00:17, 272.99it/s] 38%|███████████████████▎                               | 2828/7473 [00:11<00:17, 271.84it/s] 38%|███████████████████▍                               | 2856/7473 [00:11<00:16, 272.55it/s] 39%|███████████████████▋                               | 2884/7473 [00:11<00:16, 272.96it/s] 39%|███████████████████▊                               | 2912/7473 [00:11<00:16, 273.93it/s] 39%|████████████████████                               | 2940/7473 [00:11<00:16, 274.95it/s] 40%|████████████████████▎                              | 2968/7473 [00:11<00:16, 275.12it/s] 40%|████████████████████▍                              | 2996/7473 [00:11<00:16, 273.25it/s] 40%|████████████████████▋                              | 3024/7473 [00:11<00:16, 273.52it/s] 41%|████████████████████▊                              | 3052/7473 [00:11<00:16, 273.59it/s] 41%|█████████████████████                              | 3080/7473 [00:12<00:16, 274.02it/s] 42%|█████████████████████▏                             | 3108/7473 [00:12<00:15, 274.07it/s] 42%|█████████████████████▍                             | 3136/7473 [00:12<00:15, 273.40it/s] 42%|█████████████████████▌                             | 3164/7473 [00:12<00:15, 273.46it/s] 43%|█████████████████████▊                             | 3192/7473 [00:12<00:15, 272.94it/s] 43%|█████████████████████▉                             | 3220/7473 [00:12<00:15, 271.68it/s] 43%|██████████████████████▏                            | 3248/7473 [00:12<00:15, 272.64it/s] 44%|██████████████████████▎                            | 3276/7473 [00:12<00:15, 273.27it/s] 44%|██████████████████████▌                            | 3304/7473 [00:12<00:15, 273.71it/s] 45%|██████████████████████▋                            | 3332/7473 [00:12<00:15, 272.22it/s] 45%|██████████████████████▉                            | 3360/7473 [00:13<00:15, 272.75it/s] 45%|███████████████████████                            | 3388/7473 [00:13<00:14, 272.65it/s] 46%|███████████████████████▎                           | 3416/7473 [00:13<00:14, 272.53it/s] 46%|███████████████████████▌                           | 3444/7473 [00:13<00:14, 271.23it/s] 46%|███████████████████████▋                           | 3472/7473 [00:13<00:14, 271.42it/s] 47%|███████████████████████▉                           | 3500/7473 [00:13<00:14, 272.59it/s] 47%|████████████████████████                           | 3528/7473 [00:13<00:14, 273.04it/s] 48%|████████████████████████▎                          | 3556/7473 [00:13<00:14, 273.40it/s] 48%|████████████████████████▍                          | 3584/7473 [00:13<00:14, 273.68it/s] 48%|████████████████████████▋                          | 3612/7473 [00:14<00:14, 273.55it/s] 49%|████████████████████████▊                          | 3640/7473 [00:14<00:14, 273.21it/s] 49%|█████████████████████████                          | 3668/7473 [00:14<00:14, 271.32it/s] 49%|█████████████████████████▏                         | 3696/7473 [00:14<00:13, 271.83it/s] 50%|█████████████████████████▍                         | 3724/7473 [00:14<00:13, 271.86it/s] 50%|█████████████████████████▌                         | 3752/7473 [00:14<00:13, 272.23it/s] 51%|█████████████████████████▊                         | 3780/7473 [00:14<00:13, 272.80it/s] 51%|█████████████████████████▉                         | 3808/7473 [00:14<00:13, 272.74it/s] 51%|██████████████████████████▏                        | 3836/7473 [00:14<00:13, 272.91it/s] 52%|██████████████████████████▎                        | 3864/7473 [00:14<00:13, 272.83it/s] 52%|██████████████████████████▌                        | 3892/7473 [00:15<00:13, 271.17it/s] 52%|██████████████████████████▊                        | 3920/7473 [00:15<00:13, 272.05it/s] 53%|██████████████████████████▉                        | 3948/7473 [00:15<00:12, 272.44it/s] 53%|███████████████████████████▏                       | 3976/7473 [00:15<00:12, 272.89it/s] 54%|███████████████████████████▎                       | 4004/7473 [00:15<00:12, 273.28it/s] 54%|███████████████████████████▌                       | 4032/7473 [00:15<00:12, 273.41it/s] 54%|███████████████████████████▋                       | 4060/7473 [00:15<00:12, 273.74it/s] 55%|███████████████████████████▉                       | 4088/7473 [00:15<00:12, 273.45it/s] 55%|████████████████████████████                       | 4116/7473 [00:15<00:12, 270.85it/s] 55%|████████████████████████████▎                      | 4144/7473 [00:15<00:12, 271.05it/s] 56%|████████████████████████████▍                      | 4172/7473 [00:16<00:12, 271.87it/s] 56%|████████████████████████████▋                      | 4200/7473 [00:16<00:12, 272.45it/s] 57%|████████████████████████████▊                      | 4228/7473 [00:16<00:11, 272.40it/s] 57%|█████████████████████████████                      | 4256/7473 [00:16<00:11, 271.81it/s] 57%|█████████████████████████████▏                     | 4284/7473 [00:16<00:11, 271.29it/s] 58%|█████████████████████████████▍                     | 4312/7473 [00:16<00:11, 271.82it/s] 58%|█████████████████████████████▌                     | 4340/7473 [00:16<00:11, 270.92it/s] 58%|█████████████████████████████▊                     | 4368/7473 [00:16<00:11, 271.65it/s] 59%|██████████████████████████████                     | 4396/7473 [00:16<00:11, 272.25it/s] 59%|██████████████████████████████▏                    | 4424/7473 [00:16<00:11, 272.21it/s] 60%|██████████████████████████████▍                    | 4452/7473 [00:17<00:11, 272.01it/s] 60%|██████████████████████████████▌                    | 4480/7473 [00:17<00:10, 272.51it/s] 60%|██████████████████████████████▊                    | 4508/7473 [00:17<00:10, 272.52it/s] 61%|██████████████████████████████▉                    | 4536/7473 [00:17<00:10, 272.76it/s] 61%|███████████████████████████████▏                   | 4564/7473 [00:17<00:10, 270.94it/s] 61%|███████████████████████████████▎                   | 4592/7473 [00:17<00:10, 271.68it/s] 62%|███████████████████████████████▌                   | 4620/7473 [00:17<00:10, 272.05it/s] 62%|███████████████████████████████▋                   | 4648/7473 [00:17<00:10, 272.08it/s] 63%|███████████████████████████████▉                   | 4676/7473 [00:17<00:10, 272.27it/s] 63%|████████████████████████████████                   | 4704/7473 [00:18<00:10, 272.42it/s] 63%|████████████████████████████████▎                  | 4732/7473 [00:18<00:10, 270.60it/s] 64%|████████████████████████████████▍                  | 4760/7473 [00:18<00:09, 271.70it/s] 64%|████████████████████████████████▋                  | 4788/7473 [00:18<00:09, 272.16it/s] 64%|████████████████████████████████▊                  | 4816/7473 [00:18<00:09, 269.88it/s] 65%|█████████████████████████████████                  | 4844/7473 [00:18<00:09, 270.97it/s] 65%|█████████████████████████████████▏                 | 4872/7473 [00:18<00:09, 270.86it/s] 66%|█████████████████████████████████▍                 | 4900/7473 [00:18<00:09, 271.85it/s] 66%|█████████████████████████████████▋                 | 4928/7473 [00:18<00:09, 272.07it/s] 66%|█████████████████████████████████▊                 | 4956/7473 [00:18<00:09, 272.44it/s] 67%|██████████████████████████████████                 | 4984/7473 [00:19<00:09, 272.30it/s] 67%|██████████████████████████████████▏                | 5012/7473 [00:19<00:09, 272.63it/s] 67%|██████████████████████████████████▍                | 5040/7473 [00:19<00:08, 270.76it/s] 68%|██████████████████████████████████▌                | 5068/7473 [00:19<00:08, 271.54it/s] 68%|██████████████████████████████████▊                | 5096/7473 [00:19<00:08, 271.77it/s] 69%|██████████████████████████████████▉                | 5124/7473 [00:19<00:08, 272.29it/s] 69%|███████████████████████████████████▏               | 5152/7473 [00:19<00:08, 272.62it/s] 69%|███████████████████████████████████▎               | 5180/7473 [00:19<00:08, 270.72it/s] 70%|███████████████████████████████████▌               | 5208/7473 [00:19<00:08, 271.33it/s] 70%|███████████████████████████████████▋               | 5236/7473 [00:19<00:08, 271.68it/s] 70%|███████████████████████████████████▉               | 5264/7473 [00:20<00:08, 247.15it/s] 71%|████████████████████████████████████               | 5292/7473 [00:20<00:08, 254.60it/s] 71%|████████████████████████████████████▎              | 5320/7473 [00:20<00:08, 259.47it/s] 72%|████████████████████████████████████▍              | 5348/7473 [00:20<00:08, 263.15it/s] 72%|████████████████████████████████████▋              | 5376/7473 [00:20<00:07, 265.52it/s] 72%|████████████████████████████████████▉              | 5404/7473 [00:20<00:07, 267.75it/s] 73%|█████████████████████████████████████              | 5432/7473 [00:20<00:07, 269.62it/s] 73%|█████████████████████████████████████▎             | 5460/7473 [00:20<00:07, 270.35it/s] 73%|█████████████████████████████████████▍             | 5488/7473 [00:21<00:10, 187.64it/s] 74%|█████████████████████████████████████▋             | 5516/7473 [00:21<00:09, 207.16it/s] 74%|█████████████████████████████████████▊             | 5544/7473 [00:21<00:08, 222.94it/s] 75%|██████████████████████████████████████             | 5572/7473 [00:21<00:08, 235.81it/s] 75%|██████████████████████████████████████▏            | 5599/7473 [00:21<00:07, 243.43it/s] 75%|██████████████████████████████████████▍            | 5627/7473 [00:21<00:07, 251.42it/s] 76%|██████████████████████████████████████▌            | 5655/7473 [00:21<00:07, 257.94it/s] 76%|██████████████████████████████████████▊            | 5682/7473 [00:21<00:06, 260.40it/s] 76%|██████████████████████████████████████▉            | 5710/7473 [00:21<00:06, 263.70it/s] 77%|███████████████████████████████████████▏           | 5738/7473 [00:22<00:06, 266.31it/s] 77%|███████████████████████████████████████▎           | 5766/7473 [00:22<00:06, 268.48it/s] 78%|███████████████████████████████████████▌           | 5794/7473 [00:22<00:06, 269.88it/s] 78%|███████████████████████████████████████▋           | 5822/7473 [00:22<00:06, 270.00it/s] 78%|███████████████████████████████████████▉           | 5850/7473 [00:22<00:05, 270.94it/s] 79%|████████████████████████████████████████           | 5878/7473 [00:22<00:05, 270.92it/s] 79%|████████████████████████████████████████▎          | 5906/7473 [00:22<00:05, 269.62it/s] 79%|████████████████████████████████████████▍          | 5934/7473 [00:22<00:05, 270.36it/s] 80%|████████████████████████████████████████▋          | 5962/7473 [00:22<00:05, 270.37it/s] 80%|████████████████████████████████████████▉          | 5990/7473 [00:22<00:05, 270.99it/s] 81%|█████████████████████████████████████████          | 6018/7473 [00:23<00:05, 271.34it/s] 81%|█████████████████████████████████████████▎         | 6046/7473 [00:23<00:05, 269.47it/s] 81%|█████████████████████████████████████████▍         | 6074/7473 [00:23<00:05, 270.98it/s] 82%|█████████████████████████████████████████▋         | 6102/7473 [00:23<00:05, 271.84it/s] 82%|█████████████████████████████████████████▊         | 6130/7473 [00:23<00:04, 270.51it/s] 82%|██████████████████████████████████████████         | 6158/7473 [00:23<00:04, 271.32it/s] 83%|██████████████████████████████████████████▏        | 6186/7473 [00:23<00:04, 271.83it/s] 83%|██████████████████████████████████████████▍        | 6214/7473 [00:23<00:04, 272.44it/s] 84%|██████████████████████████████████████████▌        | 6242/7473 [00:23<00:04, 272.20it/s] 84%|██████████████████████████████████████████▊        | 6270/7473 [00:23<00:04, 272.56it/s] 84%|██████████████████████████████████████████▉        | 6298/7473 [00:24<00:04, 272.53it/s] 85%|███████████████████████████████████████████▏       | 6326/7473 [00:24<00:04, 273.22it/s] 85%|███████████████████████████████████████████▎       | 6354/7473 [00:24<00:04, 273.34it/s] 85%|███████████████████████████████████████████▌       | 6382/7473 [00:24<00:04, 270.66it/s] 86%|███████████████████████████████████████████▋       | 6410/7473 [00:24<00:03, 270.75it/s] 86%|███████████████████████████████████████████▉       | 6438/7473 [00:24<00:03, 271.22it/s] 87%|████████████████████████████████████████████▏      | 6466/7473 [00:24<00:03, 270.84it/s] 87%|████████████████████████████████████████████▎      | 6494/7473 [00:24<00:03, 271.64it/s] 87%|████████████████████████████████████████████▌      | 6522/7473 [00:24<00:03, 269.36it/s] 88%|████████████████████████████████████████████▋      | 6550/7473 [00:25<00:03, 270.45it/s] 88%|████████████████████████████████████████████▉      | 6578/7473 [00:25<00:03, 271.09it/s] 88%|█████████████████████████████████████████████      | 6606/7473 [00:25<00:03, 268.95it/s] 89%|█████████████████████████████████████████████▎     | 6634/7473 [00:25<00:03, 269.74it/s] 89%|█████████████████████████████████████████████▍     | 6662/7473 [00:25<00:03, 270.07it/s] 90%|█████████████████████████████████████████████▋     | 6690/7473 [00:25<00:02, 270.72it/s] 90%|█████████████████████████████████████████████▊     | 6718/7473 [00:25<00:02, 270.99it/s] 90%|██████████████████████████████████████████████     | 6746/7473 [00:25<00:02, 271.79it/s] 91%|██████████████████████████████████████████████▏    | 6774/7473 [00:25<00:02, 271.65it/s] 91%|██████████████████████████████████████████████▍    | 6802/7473 [00:25<00:02, 272.00it/s] 91%|██████████████████████████████████████████████▌    | 6830/7473 [00:26<00:02, 270.45it/s] 92%|██████████████████████████████████████████████▊    | 6858/7473 [00:26<00:02, 271.11it/s] 92%|██████████████████████████████████████████████▉    | 6886/7473 [00:26<00:02, 271.71it/s] 93%|███████████████████████████████████████████████▏   | 6914/7473 [00:26<00:02, 272.38it/s] 93%|███████████████████████████████████████████████▍   | 6942/7473 [00:26<00:01, 272.72it/s] 93%|███████████████████████████████████████████████▌   | 6970/7473 [00:26<00:01, 269.81it/s] 94%|███████████████████████████████████████████████▊   | 6998/7473 [00:26<00:01, 270.40it/s] 94%|███████████████████████████████████████████████▉   | 7026/7473 [00:26<00:01, 270.67it/s] 94%|████████████████████████████████████████████████▏  | 7054/7473 [00:26<00:01, 269.08it/s] 95%|████████████████████████████████████████████████▎  | 7082/7473 [00:26<00:01, 270.16it/s] 95%|████████████████████████████████████████████████▌  | 7110/7473 [00:27<00:01, 270.88it/s] 96%|████████████████████████████████████████████████▋  | 7138/7473 [00:27<00:01, 270.89it/s] 96%|████████████████████████████████████████████████▉  | 7166/7473 [00:27<00:01, 271.28it/s] 96%|█████████████████████████████████████████████████  | 7194/7473 [00:27<00:01, 271.82it/s] 97%|█████████████████████████████████████████████████▎ | 7222/7473 [00:27<00:00, 272.13it/s] 97%|█████████████████████████████████████████████████▍ | 7250/7473 [00:27<00:00, 272.83it/s] 97%|█████████████████████████████████████████████████▋ | 7278/7473 [00:27<00:00, 270.96it/s] 98%|█████████████████████████████████████████████████▊ | 7306/7473 [00:27<00:00, 271.46it/s] 98%|██████████████████████████████████████████████████ | 7334/7473 [00:27<00:00, 271.70it/s] 99%|██████████████████████████████████████████████████▏| 7362/7473 [00:28<00:00, 271.70it/s] 99%|██████████████████████████████████████████████████▍| 7390/7473 [00:28<00:00, 272.29it/s] 99%|██████████████████████████████████████████████████▌| 7418/7473 [00:28<00:00, 272.29it/s]100%|██████████████████████████████████████████████████▊| 7446/7473 [00:28<00:00, 270.93it/s]100%|███████████████████████████████████████████████████| 7473/7473 [00:28<00:00, 262.99it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:04<00:09,  4.94s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.46s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.32s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.31s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:09<00:04,  4.86s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.38s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.46s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:12<00:06,  6.11s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.28s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.44s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.79s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.94s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.81s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.97s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:16<00:00,  5.16s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:16<00:00,  5.35s/it]
[2023-08-12 17:24:20,243] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-12 17:24:36,391] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 17:24:36,392] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 17:24:36,393] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 17:24:36,393] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 17:24:36,393] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 17:24:36,393] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 17:24:36,393] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 17:24:36,393] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 17:24:36,393] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 17:24:36,393] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 17:24:36,393] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 17:24:36,393] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f9ade69dfa0>
[2023-08-12 17:24:36,393] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 17:24:36,393] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f9ade689700>
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 17:24:36,394] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 17:24:36,395] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 17:24:36,395] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.6141767501831055 seconds
Loading extension module utils...
Time to load utils op: 0.6050376892089844 seconds
Loading extension module utils...
Time to load utils op: 0.6050198078155518 seconds
Loading extension module utils...
Time to load utils op: 0.6047160625457764 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Rationales: 1. The question is asking where you can find plumbing that won't be useful if you are thirsty. 
2. To answer the question, we need to consider the five choices provided and which of the places mentioned would not have water suitable for drinking. 
3. A wall (option B) may contain plumbing, but its purpose is generally to route water to outlets like faucets or showerheads, where one could, in theory, get water to drink. 
4. A shower (option C) and one's home (option D) actually have essential plumbing to provide water, and hence, they would be useful when you are thirsty.
5. A water fountain (option E), by its very definition, also provides water, so it would be beneficial if one were thirsty as well.
6. An oil refinery (option A), however, involves a complex plumbing system dedicated to the refining of oil - not water. This plumbing would indeed not be of use when you are thirsty, as the fluids transported within this system are not safe or appropriate for human consumption.
7. Therefore, the answer is A: oil refineries as it's the only plumbing in the options given that wouldn't satisfy your thirst.
Answer: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Rationales: 1. First, understand the meaning of the question - "When a person is beginning work, what aren't they doing yet?" This question implies to focus on an activity that doesn't occur at the start of the work.
2. Now, review the given choices: A: working, B: resting, C: tiredness, D: accomplishing, E: momentum.
3. Choice A: working - When a person is beginning work, they are already engaging in work. So, they are working. Eliminate this option.
4. Choice B: resting - When a person is beginning work, it implies that they are not resting as the two actions are contradictory. Therefore, this option, too, is not appropriate.
5. Choice C: tiredness - As the question is about the action just at the beginning of work, feeling tired generally comes after working for a while, hence it cannot be considered here. However, the answer choice asked here for the action, not a feeling or state, so this option can be eliminated.
6. Choice D: accomplishing - This implies achieving or finishing tasks. As the question mentions the beginning of work, no task has been finished yet. So, at the beginning of work, a person couldn't be accomplishing anything. It seems to fit the context of the question.
7. Choice E: momentum - Generally, momentum is gained as a person progresses through their work. At the beginning of the work, the momentum would be low or not existent at all. But, momentum like tiredness is rather a state or condition than an action, so it should be eliminated. 
8. Therefore, the answer is D: accomplishing, referring to the activities that haven't taken place when a person is just starting to work.
Answer: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Rationales: 1. The question is asking about where one might find pens with a company logo.
2. The first step in solving this problem is understanding that pens with a company logo are typically distributed in professional settings, such as promotional events or at the company's offices.
3. Now, I examine the options. Option B, on a pencil, is incorrect because a pencil is an item and not a location.
4. Option C, writing sentences on paper, is a wrong answer because it's an action, not a place to find pens with a company logo.
5. Option D, a school, could potentially have pens with a company logo. However, it's less likely since schools often not directly associated with companies.
6. Option E, a backpack, while it is possible to physically find a pen there, it does not necessarily mean it will always carry a pen with a company logo.
7. Therefore, out of the given choices, the most likely place to find pens with a company logo is an office, option A.
Answer: A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Rationales: 1. The question tells us that Billy called out to John, which indicates that he is trying to communicate with him.
2. When someone initiates a conversation, specifically by calling out, they are typically seeking some form of a reply. 
3. The question then asks what Billy is listening for after calling out to John.
4. This suggests that Billy is expecting something from John. 
5. Reviewing the choices offered, "response" best describes what Billy would be listening for.
6. Therefore, the answer is B: response.
Answer: B: response

Input: The lizard frightened the hiker, it's movements made what rustle? Choices:  A: garden B: trees C: books D: rocks E: bushes
Rationales: 1. The question is asking for what the lizard's movements made rustle, which means to make a soft, muffled cracking sound.
2. The options are a garden, trees, books, rocks, and bushes.
3. The act of rustling pertains to objects that are lightweight enough to be disturbed by small movements and also have surfaces that can rub against each other to produce a sound.  
4. Thus, we can rule out the choices of garden and rocks since these are not typically associated with the rustling sound, and books because it's uncommon to find books in a hiking environment where a lizard might frighten a hiker.
5. Between trees and bushes, bushes are more likely to rustle because they are lower to the ground where a lizard would typically move.
6. Therefore, the answer is E: bushes. The lizard's movements made the bushes rustle.
Answer: E: bushes

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o5-tcommonsenseqa-s1-rTrue
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 139, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 116, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 139, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 116, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    main()Evaluating gsm8k :   0%|                                              | 0/50 [00:06<?, ?it/s]
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main

    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 139, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 116, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 139, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 116, in run_model
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 3438063) of binary: /home/ylu130/.conda/envs/distllm/bin/python
Traceback (most recent call last):
  File "/home/ylu130/.conda/envs/distllm/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/run.py", line 761, in main
    run(args)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/ylu130/workspace/in-context-generalization/inference.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-08-12_17:24:45
  host      : ia1.wse.jhu.edu
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 3438064)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-08-12_17:24:45
  host      : ia1.wse.jhu.edu
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 3438065)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-08-12_17:24:45
  host      : ia1.wse.jhu.edu
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 3438066)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-08-12_17:24:45
  host      : ia1.wse.jhu.edu
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3438063)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o6-tcommonsenseqa-s1-rTrue --seed 1 --rationales --num-out-domain 6
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-12 17:24:49,015] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o6-tcommonsenseqa-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 6
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o6-tcommonsenseqa-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  0%|▏                                                    | 19/7473 [00:00<00:41, 181.63it/s]  1%|▎                                                    | 38/7473 [00:00<00:40, 185.37it/s]  1%|▍                                                    | 57/7473 [00:00<00:39, 187.09it/s]  1%|▌                                                    | 76/7473 [00:00<00:39, 187.34it/s]  1%|▋                                                    | 95/7473 [00:00<00:39, 188.04it/s]  2%|▊                                                   | 114/7473 [00:00<00:39, 188.33it/s]  2%|▉                                                   | 133/7473 [00:00<00:38, 188.61it/s]  2%|█                                                   | 152/7473 [00:00<00:38, 188.87it/s]  2%|█▏                                                  | 172/7473 [00:00<00:38, 189.71it/s]  3%|█▎                                                  | 192/7473 [00:01<00:38, 190.24it/s]  3%|█▍                                                  | 212/7473 [00:01<00:38, 189.09it/s]  3%|█▌                                                  | 232/7473 [00:01<00:38, 189.38it/s]  3%|█▋                                                  | 251/7473 [00:01<00:38, 187.06it/s]  4%|█▉                                                  | 271/7473 [00:01<00:38, 188.31it/s]  4%|██                                                  | 291/7473 [00:01<00:37, 189.30it/s]  4%|██▏                                                 | 311/7473 [00:01<00:37, 189.86it/s]  4%|██▎                                                 | 331/7473 [00:01<00:37, 190.51it/s]  5%|██▍                                                 | 351/7473 [00:01<00:37, 190.00it/s]  5%|██▌                                                 | 371/7473 [00:01<00:38, 184.53it/s]  5%|██▋                                                 | 391/7473 [00:02<00:37, 186.76it/s]  5%|██▊                                                 | 411/7473 [00:02<00:37, 187.92it/s]  6%|██▉                                                 | 431/7473 [00:02<00:37, 189.09it/s]  6%|███▏                                                | 451/7473 [00:02<00:37, 188.99it/s]  6%|███▎                                                | 471/7473 [00:02<00:36, 189.53it/s]  7%|███▍                                                | 490/7473 [00:02<00:37, 188.53it/s]  7%|███▌                                                | 510/7473 [00:02<00:36, 189.17it/s]  7%|███▋                                                | 530/7473 [00:02<00:36, 190.29it/s]  7%|███▊                                                | 550/7473 [00:02<00:36, 190.96it/s]  8%|███▉                                                | 570/7473 [00:03<00:36, 191.29it/s]  8%|████                                                | 590/7473 [00:03<00:35, 191.47it/s]  8%|████▏                                               | 610/7473 [00:03<00:35, 191.29it/s]  8%|████▍                                               | 630/7473 [00:03<00:35, 191.22it/s]  9%|████▌                                               | 650/7473 [00:03<00:35, 191.10it/s]  9%|████▋                                               | 670/7473 [00:03<00:35, 191.63it/s]  9%|████▊                                               | 690/7473 [00:03<00:35, 191.97it/s] 10%|████▉                                               | 710/7473 [00:03<00:36, 186.82it/s] 10%|█████                                               | 730/7473 [00:03<00:35, 187.88it/s] 10%|█████▏                                              | 750/7473 [00:03<00:35, 188.82it/s] 10%|█████▎                                              | 770/7473 [00:04<00:35, 189.38it/s] 11%|█████▍                                              | 790/7473 [00:04<00:35, 189.99it/s] 11%|█████▋                                              | 810/7473 [00:04<00:34, 190.74it/s] 11%|█████▊                                              | 830/7473 [00:04<00:34, 191.02it/s] 11%|█████▉                                              | 850/7473 [00:04<00:34, 191.35it/s] 12%|██████                                              | 870/7473 [00:04<00:34, 191.60it/s] 12%|██████▏                                             | 890/7473 [00:04<00:34, 191.66it/s] 12%|██████▎                                             | 910/7473 [00:04<00:34, 191.57it/s] 12%|██████▍                                             | 930/7473 [00:04<00:34, 189.71it/s] 13%|██████▌                                             | 950/7473 [00:05<00:34, 190.13it/s] 13%|██████▋                                             | 970/7473 [00:05<00:34, 190.79it/s] 13%|██████▉                                             | 990/7473 [00:05<00:33, 191.25it/s] 14%|██████▉                                            | 1010/7473 [00:05<00:33, 191.14it/s] 14%|███████                                            | 1030/7473 [00:05<00:33, 191.72it/s] 14%|███████▏                                           | 1050/7473 [00:05<00:33, 191.51it/s] 14%|███████▎                                           | 1070/7473 [00:05<00:33, 191.96it/s] 15%|███████▍                                           | 1090/7473 [00:05<00:33, 191.97it/s] 15%|███████▌                                           | 1110/7473 [00:05<00:33, 191.24it/s] 15%|███████▋                                           | 1130/7473 [00:05<00:33, 191.26it/s] 15%|███████▊                                           | 1150/7473 [00:06<00:33, 191.45it/s] 16%|███████▉                                           | 1170/7473 [00:06<00:33, 189.58it/s] 16%|████████                                           | 1190/7473 [00:06<00:33, 189.92it/s] 16%|████████▎                                          | 1210/7473 [00:06<00:32, 190.25it/s] 16%|████████▍                                          | 1230/7473 [00:06<00:32, 190.57it/s] 17%|████████▌                                          | 1250/7473 [00:06<00:32, 190.86it/s] 17%|████████▋                                          | 1270/7473 [00:06<00:32, 191.01it/s] 17%|████████▊                                          | 1290/7473 [00:06<00:32, 190.88it/s] 18%|████████▉                                          | 1310/7473 [00:06<00:32, 191.03it/s] 18%|█████████                                          | 1330/7473 [00:07<00:32, 191.24it/s] 18%|█████████▏                                         | 1350/7473 [00:07<00:32, 191.27it/s] 18%|█████████▎                                         | 1370/7473 [00:07<00:32, 190.46it/s] 19%|█████████▍                                         | 1390/7473 [00:07<00:32, 188.05it/s] 19%|█████████▌                                         | 1410/7473 [00:07<00:32, 189.18it/s] 19%|█████████▊                                         | 1430/7473 [00:07<00:31, 189.86it/s] 19%|█████████▉                                         | 1450/7473 [00:07<00:31, 190.57it/s] 20%|██████████                                         | 1470/7473 [00:07<00:31, 190.87it/s] 20%|██████████▏                                        | 1490/7473 [00:07<00:31, 190.78it/s] 20%|██████████▎                                        | 1510/7473 [00:07<00:31, 191.13it/s] 20%|██████████▍                                        | 1530/7473 [00:08<00:31, 191.57it/s] 21%|██████████▌                                        | 1550/7473 [00:08<00:30, 191.19it/s] 21%|██████████▋                                        | 1570/7473 [00:08<00:31, 190.39it/s] 21%|██████████▊                                        | 1590/7473 [00:08<00:30, 190.50it/s] 22%|██████████▉                                        | 1610/7473 [00:08<00:30, 189.93it/s] 22%|███████████                                        | 1629/7473 [00:08<00:31, 188.50it/s] 22%|███████████▎                                       | 1649/7473 [00:08<00:30, 189.42it/s] 22%|███████████▍                                       | 1669/7473 [00:08<00:30, 190.08it/s] 23%|███████████▌                                       | 1689/7473 [00:08<00:30, 190.80it/s] 23%|███████████▋                                       | 1709/7473 [00:08<00:30, 191.12it/s] 23%|███████████▊                                       | 1729/7473 [00:09<00:29, 191.49it/s] 23%|███████████▉                                       | 1749/7473 [00:09<00:29, 191.38it/s] 24%|████████████                                       | 1769/7473 [00:09<00:30, 189.70it/s] 24%|████████████▏                                      | 1788/7473 [00:09<00:30, 187.56it/s] 24%|████████████▎                                      | 1807/7473 [00:09<00:30, 188.03it/s] 24%|████████████▍                                      | 1827/7473 [00:09<00:29, 188.56it/s] 25%|████████████▌                                      | 1846/7473 [00:09<00:29, 187.69it/s] 25%|████████████▋                                      | 1866/7473 [00:09<00:29, 188.79it/s] 25%|████████████▊                                      | 1885/7473 [00:09<00:29, 188.75it/s] 25%|████████████▉                                      | 1904/7473 [00:10<00:30, 183.97it/s] 26%|█████████████▏                                     | 1924/7473 [00:10<00:29, 185.91it/s] 26%|█████████████▎                                     | 1944/7473 [00:10<00:29, 187.38it/s] 26%|█████████████▍                                     | 1964/7473 [00:10<00:29, 188.77it/s] 27%|█████████████▌                                     | 1984/7473 [00:10<00:28, 189.61it/s] 27%|█████████████▋                                     | 2004/7473 [00:10<00:28, 189.76it/s] 27%|█████████████▊                                     | 2024/7473 [00:10<00:28, 190.35it/s] 27%|█████████████▉                                     | 2044/7473 [00:10<00:28, 190.29it/s] 28%|██████████████                                     | 2064/7473 [00:10<00:28, 190.79it/s] 28%|██████████████▏                                    | 2084/7473 [00:10<00:28, 189.04it/s] 28%|██████████████▎                                    | 2104/7473 [00:11<00:28, 189.77it/s] 28%|██████████████▍                                    | 2123/7473 [00:11<00:28, 189.81it/s] 29%|██████████████▋                                    | 2143/7473 [00:11<00:27, 190.47it/s] 29%|██████████████▊                                    | 2163/7473 [00:11<00:27, 190.79it/s] 29%|██████████████▉                                    | 2183/7473 [00:11<00:27, 190.94it/s] 29%|███████████████                                    | 2203/7473 [00:11<00:27, 191.10it/s] 30%|███████████████▏                                   | 2223/7473 [00:11<00:27, 191.31it/s] 30%|███████████████▎                                   | 2243/7473 [00:11<00:27, 190.05it/s] 30%|███████████████▍                                   | 2263/7473 [00:11<00:27, 189.61it/s] 31%|███████████████▌                                   | 2282/7473 [00:12<00:27, 189.70it/s] 31%|███████████████▋                                   | 2301/7473 [00:12<00:27, 188.66it/s] 31%|███████████████▊                                   | 2321/7473 [00:12<00:27, 189.77it/s] 31%|███████████████▉                                   | 2341/7473 [00:12<00:26, 190.24it/s] 32%|████████████████                                   | 2361/7473 [00:12<00:26, 190.23it/s] 32%|████████████████▏                                  | 2381/7473 [00:12<00:26, 190.31it/s] 32%|████████████████▍                                  | 2401/7473 [00:12<00:26, 190.82it/s] 32%|████████████████▌                                  | 2421/7473 [00:12<00:26, 191.12it/s] 33%|████████████████▋                                  | 2441/7473 [00:12<00:26, 191.30it/s] 33%|████████████████▊                                  | 2461/7473 [00:12<00:26, 191.33it/s] 33%|████████████████▉                                  | 2481/7473 [00:13<00:26, 190.21it/s] 33%|█████████████████                                  | 2501/7473 [00:13<00:26, 189.89it/s] 34%|█████████████████▏                                 | 2520/7473 [00:13<00:29, 168.98it/s] 34%|█████████████████▎                                 | 2540/7473 [00:13<00:28, 175.13it/s] 34%|█████████████████▍                                 | 2559/7473 [00:13<00:27, 178.15it/s] 35%|█████████████████▌                                 | 2579/7473 [00:13<00:26, 182.35it/s] 35%|█████████████████▋                                 | 2599/7473 [00:13<00:26, 184.77it/s] 35%|█████████████████▊                                 | 2619/7473 [00:13<00:26, 186.43it/s] 35%|██████████████████                                 | 2638/7473 [00:13<00:25, 186.62it/s] 36%|██████████████████▏                                | 2657/7473 [00:14<00:26, 182.62it/s] 36%|██████████████████▎                                | 2677/7473 [00:14<00:25, 185.54it/s] 36%|██████████████████▍                                | 2697/7473 [00:14<00:25, 187.42it/s] 36%|██████████████████▌                                | 2717/7473 [00:14<00:25, 188.60it/s] 37%|██████████████████▋                                | 2736/7473 [00:14<00:25, 188.97it/s] 37%|██████████████████▊                                | 2755/7473 [00:14<00:25, 188.23it/s] 37%|██████████████████▉                                | 2775/7473 [00:14<00:24, 189.11it/s] 37%|███████████████████                                | 2795/7473 [00:14<00:24, 189.73it/s] 38%|███████████████████▏                               | 2815/7473 [00:14<00:24, 190.05it/s] 38%|███████████████████▎                               | 2835/7473 [00:14<00:24, 190.53it/s] 38%|███████████████████▍                               | 2855/7473 [00:15<00:24, 190.61it/s] 38%|███████████████████▌                               | 2875/7473 [00:15<00:24, 188.76it/s] 39%|███████████████████▊                               | 2894/7473 [00:15<00:24, 188.67it/s] 39%|███████████████████▉                               | 2914/7473 [00:15<00:24, 189.30it/s] 39%|████████████████████                               | 2934/7473 [00:15<00:23, 190.29it/s] 40%|████████████████████▏                              | 2954/7473 [00:15<00:23, 190.46it/s] 40%|████████████████████▎                              | 2974/7473 [00:15<00:23, 189.21it/s] 40%|████████████████████▍                              | 2994/7473 [00:15<00:23, 189.95it/s] 40%|████████████████████▌                              | 3013/7473 [00:15<00:23, 189.65it/s] 41%|████████████████████▋                              | 3033/7473 [00:16<00:23, 190.03it/s] 41%|████████████████████▊                              | 3053/7473 [00:16<00:23, 190.20it/s] 41%|████████████████████▉                              | 3073/7473 [00:16<00:23, 190.53it/s] 41%|█████████████████████                              | 3093/7473 [00:16<00:22, 190.70it/s] 42%|█████████████████████▏                             | 3113/7473 [00:16<00:22, 190.58it/s] 42%|█████████████████████▍                             | 3133/7473 [00:16<00:22, 190.73it/s] 42%|█████████████████████▌                             | 3153/7473 [00:16<00:22, 190.70it/s] 42%|█████████████████████▋                             | 3173/7473 [00:16<00:22, 190.82it/s] 43%|█████████████████████▊                             | 3193/7473 [00:16<00:22, 190.74it/s] 43%|█████████████████████▉                             | 3213/7473 [00:16<00:22, 186.93it/s] 43%|██████████████████████                             | 3232/7473 [00:17<00:22, 185.90it/s] 44%|██████████████████████▏                            | 3252/7473 [00:17<00:22, 187.48it/s] 44%|██████████████████████▎                            | 3272/7473 [00:17<00:22, 188.70it/s] 44%|██████████████████████▍                            | 3292/7473 [00:17<00:22, 189.45it/s] 44%|██████████████████████▌                            | 3312/7473 [00:17<00:21, 189.95it/s] 45%|██████████████████████▋                            | 3331/7473 [00:17<00:21, 189.66it/s] 45%|██████████████████████▊                            | 3350/7473 [00:17<00:21, 189.43it/s] 45%|██████████████████████▉                            | 3370/7473 [00:17<00:21, 189.71it/s] 45%|███████████████████████▏                           | 3390/7473 [00:17<00:21, 189.93it/s] 46%|███████████████████████▎                           | 3409/7473 [00:18<00:21, 189.64it/s] 46%|███████████████████████▍                           | 3428/7473 [00:18<00:21, 188.38it/s] 46%|███████████████████████▌                           | 3448/7473 [00:18<00:21, 188.94it/s] 46%|███████████████████████▋                           | 3468/7473 [00:18<00:21, 189.38it/s] 47%|███████████████████████▊                           | 3488/7473 [00:18<00:20, 189.87it/s] 47%|███████████████████████▉                           | 3508/7473 [00:18<00:20, 190.22it/s] 47%|████████████████████████                           | 3528/7473 [00:18<00:20, 188.89it/s] 47%|████████████████████████▏                          | 3548/7473 [00:18<00:20, 189.32it/s] 48%|████████████████████████▎                          | 3568/7473 [00:18<00:20, 189.75it/s] 48%|████████████████████████▍                          | 3588/7473 [00:18<00:20, 190.18it/s] 48%|████████████████████████▌                          | 3608/7473 [00:19<00:20, 190.27it/s] 49%|████████████████████████▊                          | 3628/7473 [00:19<00:20, 190.29it/s] 49%|████████████████████████▉                          | 3648/7473 [00:19<00:20, 189.79it/s] 49%|█████████████████████████                          | 3667/7473 [00:19<00:20, 184.13it/s] 49%|█████████████████████████▏                         | 3686/7473 [00:19<00:20, 184.46it/s] 50%|█████████████████████████▎                         | 3706/7473 [00:19<00:20, 186.15it/s] 50%|█████████████████████████▍                         | 3726/7473 [00:19<00:19, 187.49it/s] 50%|█████████████████████████▌                         | 3745/7473 [00:19<00:19, 188.02it/s] 50%|█████████████████████████▋                         | 3765/7473 [00:19<00:19, 188.69it/s] 51%|█████████████████████████▊                         | 3784/7473 [00:19<00:19, 188.54it/s] 51%|█████████████████████████▉                         | 3804/7473 [00:20<00:19, 189.45it/s] 51%|██████████████████████████                         | 3824/7473 [00:20<00:19, 189.69it/s] 51%|██████████████████████████▏                        | 3843/7473 [00:20<00:19, 188.19it/s] 52%|██████████████████████████▎                        | 3862/7473 [00:20<00:19, 188.62it/s] 52%|██████████████████████████▍                        | 3881/7473 [00:20<00:19, 187.39it/s] 52%|██████████████████████████▌                        | 3901/7473 [00:20<00:18, 188.61it/s] 52%|██████████████████████████▊                        | 3920/7473 [00:20<00:18, 189.01it/s] 53%|██████████████████████████▉                        | 3940/7473 [00:20<00:18, 189.37it/s] 53%|███████████████████████████                        | 3959/7473 [00:20<00:18, 189.41it/s] 53%|███████████████████████████▏                       | 3979/7473 [00:21<00:18, 189.71it/s] 54%|███████████████████████████▎                       | 3999/7473 [00:21<00:18, 190.02it/s] 54%|███████████████████████████▍                       | 4019/7473 [00:21<00:18, 190.26it/s] 54%|███████████████████████████▌                       | 4039/7473 [00:21<00:18, 190.25it/s] 54%|███████████████████████████▋                       | 4059/7473 [00:21<00:18, 185.26it/s] 55%|███████████████████████████▊                       | 4078/7473 [00:21<00:18, 186.53it/s] 55%|███████████████████████████▉                       | 4098/7473 [00:21<00:17, 187.61it/s] 55%|████████████████████████████                       | 4117/7473 [00:21<00:18, 186.22it/s] 55%|████████████████████████████▏                      | 4136/7473 [00:21<00:17, 186.87it/s] 56%|████████████████████████████▎                      | 4155/7473 [00:21<00:18, 182.32it/s] 56%|████████████████████████████▍                      | 4174/7473 [00:22<00:17, 184.45it/s] 56%|████████████████████████████▌                      | 4193/7473 [00:22<00:17, 185.88it/s] 56%|████████████████████████████▋                      | 4212/7473 [00:22<00:17, 186.94it/s] 57%|████████████████████████████▊                      | 4231/7473 [00:22<00:17, 187.74it/s] 57%|█████████████████████████████                      | 4250/7473 [00:22<00:17, 187.74it/s] 57%|█████████████████████████████▏                     | 4269/7473 [00:22<00:17, 188.00it/s] 57%|█████████████████████████████▎                     | 4288/7473 [00:22<00:16, 188.18it/s] 58%|█████████████████████████████▍                     | 4307/7473 [00:22<00:16, 188.48it/s] 58%|█████████████████████████████▌                     | 4327/7473 [00:22<00:16, 188.93it/s] 58%|█████████████████████████████▋                     | 4346/7473 [00:22<00:16, 187.51it/s] 58%|█████████████████████████████▊                     | 4365/7473 [00:23<00:16, 188.18it/s] 59%|█████████████████████████████▉                     | 4384/7473 [00:23<00:16, 188.50it/s] 59%|██████████████████████████████                     | 4404/7473 [00:23<00:16, 188.95it/s] 59%|██████████████████████████████▏                    | 4423/7473 [00:23<00:16, 189.12it/s] 59%|██████████████████████████████▎                    | 4442/7473 [00:23<00:16, 189.36it/s] 60%|██████████████████████████████▍                    | 4461/7473 [00:23<00:15, 189.39it/s] 60%|██████████████████████████████▌                    | 4480/7473 [00:23<00:15, 189.47it/s] 60%|██████████████████████████████▋                    | 4500/7473 [00:23<00:15, 189.62it/s] 60%|██████████████████████████████▊                    | 4519/7473 [00:23<00:15, 189.36it/s] 61%|██████████████████████████████▉                    | 4538/7473 [00:24<00:16, 183.42it/s] 61%|███████████████████████████████                    | 4558/7473 [00:24<00:15, 185.65it/s] 61%|███████████████████████████████▏                   | 4577/7473 [00:24<00:15, 185.53it/s] 62%|███████████████████████████████▎                   | 4596/7473 [00:24<00:15, 186.73it/s] 62%|███████████████████████████████▌                   | 4616/7473 [00:24<00:15, 187.93it/s] 62%|███████████████████████████████▋                   | 4635/7473 [00:24<00:15, 188.46it/s] 62%|███████████████████████████████▊                   | 4655/7473 [00:24<00:14, 189.31it/s] 63%|███████████████████████████████▉                   | 4674/7473 [00:24<00:14, 189.14it/s] 63%|████████████████████████████████                   | 4694/7473 [00:24<00:14, 189.74it/s] 63%|████████████████████████████████▏                  | 4714/7473 [00:24<00:14, 190.08it/s] 63%|████████████████████████████████▎                  | 4734/7473 [00:25<00:14, 190.15it/s] 64%|████████████████████████████████▍                  | 4754/7473 [00:25<00:14, 190.57it/s] 64%|████████████████████████████████▌                  | 4774/7473 [00:25<00:14, 190.89it/s] 64%|████████████████████████████████▋                  | 4794/7473 [00:25<00:14, 189.26it/s] 64%|████████████████████████████████▊                  | 4814/7473 [00:25<00:14, 189.59it/s] 65%|████████████████████████████████▉                  | 4834/7473 [00:25<00:13, 189.93it/s] 65%|█████████████████████████████████▏                 | 4854/7473 [00:25<00:13, 190.09it/s] 65%|█████████████████████████████████▎                 | 4874/7473 [00:25<00:13, 190.05it/s] 65%|█████████████████████████████████▍                 | 4894/7473 [00:25<00:13, 190.23it/s] 66%|█████████████████████████████████▌                 | 4914/7473 [00:25<00:13, 190.17it/s] 66%|█████████████████████████████████▋                 | 4934/7473 [00:26<00:13, 190.34it/s] 66%|█████████████████████████████████▊                 | 4954/7473 [00:26<00:13, 190.56it/s] 67%|█████████████████████████████████▉                 | 4974/7473 [00:26<00:13, 190.39it/s] 67%|██████████████████████████████████                 | 4994/7473 [00:26<00:13, 190.24it/s] 67%|██████████████████████████████████▏                | 5014/7473 [00:26<00:12, 190.67it/s] 67%|██████████████████████████████████▎                | 5034/7473 [00:26<00:13, 182.47it/s] 68%|██████████████████████████████████▍                | 5054/7473 [00:26<00:13, 185.00it/s] 68%|██████████████████████████████████▋                | 5074/7473 [00:26<00:12, 186.70it/s] 68%|██████████████████████████████████▊                | 5094/7473 [00:26<00:12, 187.59it/s] 68%|██████████████████████████████████▉                | 5114/7473 [00:27<00:12, 188.62it/s] 69%|███████████████████████████████████                | 5134/7473 [00:27<00:12, 189.19it/s] 69%|███████████████████████████████████▏               | 5154/7473 [00:27<00:12, 189.74it/s] 69%|███████████████████████████████████▎               | 5174/7473 [00:27<00:12, 190.39it/s] 70%|███████████████████████████████████▍               | 5194/7473 [00:27<00:11, 190.19it/s] 70%|███████████████████████████████████▌               | 5214/7473 [00:27<00:11, 190.61it/s] 70%|███████████████████████████████████▋               | 5234/7473 [00:27<00:11, 190.64it/s] 70%|███████████████████████████████████▊               | 5254/7473 [00:27<00:13, 166.29it/s] 71%|███████████████████████████████████▉               | 5273/7473 [00:27<00:12, 172.42it/s] 71%|████████████████████████████████████               | 5292/7473 [00:28<00:12, 176.90it/s] 71%|████████████████████████████████████▎              | 5312/7473 [00:28<00:11, 180.83it/s] 71%|████████████████████████████████████▍              | 5331/7473 [00:28<00:11, 183.16it/s] 72%|████████████████████████████████████▌              | 5350/7473 [00:28<00:11, 185.05it/s] 72%|████████████████████████████████████▋              | 5369/7473 [00:28<00:11, 186.48it/s] 72%|████████████████████████████████████▊              | 5389/7473 [00:28<00:11, 187.70it/s] 72%|████████████████████████████████████▉              | 5408/7473 [00:28<00:10, 188.33it/s] 73%|█████████████████████████████████████              | 5428/7473 [00:28<00:10, 188.94it/s] 73%|█████████████████████████████████████▏             | 5448/7473 [00:28<00:10, 189.30it/s] 73%|█████████████████████████████████████▎             | 5467/7473 [00:28<00:10, 189.11it/s] 73%|█████████████████████████████████████▍             | 5486/7473 [00:29<00:16, 118.24it/s] 74%|█████████████████████████████████████▌             | 5505/7473 [00:29<00:14, 133.09it/s] 74%|█████████████████████████████████████▋             | 5525/7473 [00:29<00:13, 146.67it/s] 74%|█████████████████████████████████████▊             | 5544/7473 [00:29<00:12, 157.21it/s] 74%|█████████████████████████████████████▉             | 5564/7473 [00:29<00:11, 166.40it/s] 75%|██████████████████████████████████████             | 5583/7473 [00:29<00:10, 172.66it/s] 75%|██████████████████████████████████████▏            | 5602/7473 [00:29<00:10, 177.32it/s] 75%|██████████████████████████████████████▎            | 5621/7473 [00:29<00:10, 180.60it/s] 75%|██████████████████████████████████████▍            | 5640/7473 [00:30<00:10, 182.46it/s] 76%|██████████████████████████████████████▌            | 5659/7473 [00:30<00:09, 182.48it/s] 76%|██████████████████████████████████████▋            | 5678/7473 [00:30<00:09, 181.80it/s] 76%|██████████████████████████████████████▉            | 5698/7473 [00:30<00:09, 184.26it/s] 77%|███████████████████████████████████████            | 5717/7473 [00:30<00:09, 185.70it/s] 77%|███████████████████████████████████████▏           | 5737/7473 [00:30<00:09, 187.16it/s] 77%|███████████████████████████████████████▎           | 5756/7473 [00:30<00:09, 187.91it/s] 77%|███████████████████████████████████████▍           | 5775/7473 [00:30<00:09, 188.48it/s] 78%|███████████████████████████████████████▌           | 5794/7473 [00:30<00:08, 188.67it/s] 78%|███████████████████████████████████████▋           | 5813/7473 [00:31<00:08, 188.46it/s] 78%|███████████████████████████████████████▊           | 5832/7473 [00:31<00:08, 188.82it/s] 78%|███████████████████████████████████████▉           | 5852/7473 [00:31<00:08, 189.35it/s] 79%|████████████████████████████████████████           | 5871/7473 [00:31<00:08, 188.56it/s] 79%|████████████████████████████████████████▏          | 5890/7473 [00:31<00:08, 188.94it/s] 79%|████████████████████████████████████████▎          | 5909/7473 [00:31<00:08, 187.38it/s] 79%|████████████████████████████████████████▍          | 5928/7473 [00:31<00:08, 188.03it/s] 80%|████████████████████████████████████████▌          | 5947/7473 [00:31<00:08, 188.37it/s] 80%|████████████████████████████████████████▋          | 5966/7473 [00:31<00:07, 188.47it/s] 80%|████████████████████████████████████████▊          | 5986/7473 [00:31<00:07, 189.11it/s] 80%|████████████████████████████████████████▉          | 6005/7473 [00:32<00:07, 189.10it/s] 81%|█████████████████████████████████████████          | 6024/7473 [00:32<00:07, 189.00it/s] 81%|█████████████████████████████████████████▏         | 6043/7473 [00:32<00:07, 189.24it/s] 81%|█████████████████████████████████████████▎         | 6062/7473 [00:32<00:07, 188.89it/s] 81%|█████████████████████████████████████████▌         | 6081/7473 [00:32<00:07, 189.18it/s] 82%|█████████████████████████████████████████▋         | 6101/7473 [00:32<00:07, 189.76it/s] 82%|█████████████████████████████████████████▊         | 6121/7473 [00:32<00:07, 189.96it/s] 82%|█████████████████████████████████████████▉         | 6140/7473 [00:32<00:07, 188.40it/s] 82%|██████████████████████████████████████████         | 6160/7473 [00:32<00:06, 188.96it/s] 83%|██████████████████████████████████████████▏        | 6180/7473 [00:32<00:06, 189.34it/s] 83%|██████████████████████████████████████████▎        | 6200/7473 [00:33<00:06, 189.89it/s] 83%|██████████████████████████████████████████▍        | 6219/7473 [00:33<00:06, 189.70it/s] 83%|██████████████████████████████████████████▌        | 6238/7473 [00:33<00:06, 189.58it/s] 84%|██████████████████████████████████████████▋        | 6257/7473 [00:33<00:06, 188.30it/s] 84%|██████████████████████████████████████████▊        | 6276/7473 [00:33<00:06, 187.39it/s] 84%|██████████████████████████████████████████▉        | 6295/7473 [00:33<00:06, 187.39it/s] 85%|███████████████████████████████████████████        | 6315/7473 [00:33<00:06, 188.38it/s] 85%|███████████████████████████████████████████▏       | 6335/7473 [00:33<00:06, 189.20it/s] 85%|███████████████████████████████████████████▎       | 6354/7473 [00:33<00:05, 187.79it/s] 85%|███████████████████████████████████████████▍       | 6373/7473 [00:33<00:05, 187.93it/s] 86%|███████████████████████████████████████████▌       | 6392/7473 [00:34<00:05, 188.09it/s] 86%|███████████████████████████████████████████▊       | 6411/7473 [00:34<00:05, 188.52it/s] 86%|███████████████████████████████████████████▉       | 6430/7473 [00:34<00:05, 188.86it/s] 86%|████████████████████████████████████████████       | 6449/7473 [00:34<00:05, 189.04it/s] 87%|████████████████████████████████████████████▏      | 6469/7473 [00:34<00:05, 189.45it/s] 87%|████████████████████████████████████████████▎      | 6489/7473 [00:34<00:05, 189.71it/s] 87%|████████████████████████████████████████████▍      | 6508/7473 [00:34<00:05, 189.74it/s] 87%|████████████████████████████████████████████▌      | 6527/7473 [00:34<00:04, 189.45it/s] 88%|████████████████████████████████████████████▋      | 6547/7473 [00:34<00:04, 189.79it/s] 88%|████████████████████████████████████████████▊      | 6567/7473 [00:34<00:04, 189.91it/s] 88%|████████████████████████████████████████████▉      | 6586/7473 [00:35<00:04, 188.51it/s] 88%|█████████████████████████████████████████████      | 6606/7473 [00:35<00:04, 189.11it/s] 89%|█████████████████████████████████████████████▏     | 6625/7473 [00:35<00:04, 189.35it/s] 89%|█████████████████████████████████████████████▎     | 6644/7473 [00:35<00:04, 188.78it/s] 89%|█████████████████████████████████████████████▍     | 6663/7473 [00:35<00:04, 188.46it/s] 89%|█████████████████████████████████████████████▌     | 6682/7473 [00:35<00:04, 188.71it/s] 90%|█████████████████████████████████████████████▋     | 6702/7473 [00:35<00:04, 189.24it/s] 90%|█████████████████████████████████████████████▊     | 6721/7473 [00:35<00:04, 187.94it/s] 90%|██████████████████████████████████████████████     | 6741/7473 [00:35<00:03, 188.77it/s] 90%|██████████████████████████████████████████████▏    | 6760/7473 [00:36<00:03, 183.44it/s] 91%|██████████████████████████████████████████████▎    | 6779/7473 [00:36<00:03, 185.03it/s] 91%|██████████████████████████████████████████████▍    | 6798/7473 [00:36<00:03, 186.27it/s] 91%|██████████████████████████████████████████████▌    | 6817/7473 [00:36<00:03, 185.58it/s] 91%|██████████████████████████████████████████████▋    | 6836/7473 [00:36<00:03, 186.78it/s] 92%|██████████████████████████████████████████████▊    | 6856/7473 [00:36<00:03, 187.97it/s] 92%|██████████████████████████████████████████████▉    | 6875/7473 [00:36<00:03, 188.31it/s] 92%|███████████████████████████████████████████████    | 6894/7473 [00:36<00:03, 188.55it/s] 93%|███████████████████████████████████████████████▏   | 6913/7473 [00:36<00:02, 188.96it/s] 93%|███████████████████████████████████████████████▎   | 6932/7473 [00:36<00:02, 188.86it/s] 93%|███████████████████████████████████████████████▍   | 6951/7473 [00:37<00:02, 188.84it/s] 93%|███████████████████████████████████████████████▌   | 6970/7473 [00:37<00:02, 188.42it/s] 94%|███████████████████████████████████████████████▋   | 6989/7473 [00:37<00:02, 188.46it/s] 94%|███████████████████████████████████████████████▊   | 7008/7473 [00:37<00:02, 188.66it/s] 94%|███████████████████████████████████████████████▉   | 7027/7473 [00:37<00:02, 188.56it/s] 94%|████████████████████████████████████████████████   | 7046/7473 [00:37<00:02, 186.85it/s] 95%|████████████████████████████████████████████████▏  | 7065/7473 [00:37<00:02, 179.95it/s] 95%|████████████████████████████████████████████████▎  | 7084/7473 [00:37<00:02, 182.34it/s] 95%|████████████████████████████████████████████████▍  | 7103/7473 [00:37<00:02, 184.20it/s] 95%|████████████████████████████████████████████████▌  | 7122/7473 [00:37<00:01, 184.06it/s] 96%|████████████████████████████████████████████████▋  | 7141/7473 [00:38<00:01, 185.23it/s] 96%|████████████████████████████████████████████████▊  | 7160/7473 [00:38<00:01, 185.66it/s] 96%|████████████████████████████████████████████████▉  | 7179/7473 [00:38<00:01, 186.52it/s] 96%|█████████████████████████████████████████████████  | 7198/7473 [00:38<00:01, 187.30it/s] 97%|█████████████████████████████████████████████████▎ | 7217/7473 [00:38<00:01, 187.75it/s] 97%|█████████████████████████████████████████████████▍ | 7236/7473 [00:38<00:01, 188.10it/s] 97%|█████████████████████████████████████████████████▌ | 7255/7473 [00:38<00:01, 187.99it/s] 97%|█████████████████████████████████████████████████▋ | 7274/7473 [00:38<00:01, 186.83it/s] 98%|█████████████████████████████████████████████████▊ | 7294/7473 [00:38<00:00, 187.89it/s] 98%|█████████████████████████████████████████████████▉ | 7313/7473 [00:38<00:00, 188.17it/s] 98%|██████████████████████████████████████████████████ | 7332/7473 [00:39<00:00, 188.50it/s] 98%|██████████████████████████████████████████████████▏| 7352/7473 [00:39<00:00, 188.88it/s] 99%|██████████████████████████████████████████████████▎| 7371/7473 [00:39<00:00, 188.91it/s] 99%|██████████████████████████████████████████████████▍| 7390/7473 [00:39<00:00, 189.03it/s] 99%|██████████████████████████████████████████████████▌| 7409/7473 [00:39<00:00, 189.29it/s] 99%|██████████████████████████████████████████████████▋| 7429/7473 [00:39<00:00, 189.57it/s]100%|██████████████████████████████████████████████████▊| 7448/7473 [00:39<00:00, 189.51it/s]100%|██████████████████████████████████████████████████▉| 7467/7473 [00:39<00:00, 189.41it/s]100%|███████████████████████████████████████████████████| 7473/7473 [00:39<00:00, 187.64it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.30s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.43s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.60s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.02s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.20s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.40s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.53s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:09<00:04,  4.90s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.59s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.76s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.80s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.97s/it]
[2023-08-12 17:26:22,327] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.09s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.21s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.30s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.48s/it]
[2023-08-12 17:26:32,770] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 17:26:32,771] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 17:26:32,771] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 17:26:32,771] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f3e6c848b20>
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 17:26:32,772] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f3e6c8488b0>
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 17:26:32,773] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 17:26:32,773] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.6476607322692871 seconds
Loading extension module utils...
Time to load utils op: 0.5049121379852295 seconds
Loading extension module utils...
Time to load utils op: 0.6049313545227051 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Loading extension module utils...
Time to load utils op: 0.7050950527191162 seconds
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Rationales: 1. The question asks where you could find some plumbing that would not be useful to you if you were thirsty.
2. This means we're looking for a place that has plumbing but doesn't provide potable, or drinkable, water.
3. Let's analyze each choice:
4. Option A: Oil Refineries. These are places where crude oil is processed and refined into more useful products such as petrol, diesel, and other chemical products. While they may have plumbing to facilitate the movement of oil, the purpose is not meant for drinking water. Hence this could be a possible answer.
5. Option B: Wall. The wall might contain plumbing as part of the building's infrastructure, but it is primarily designed to transport water to useful locations like faucets, not for drinking directly. This isn't a strong answer.
6. Option C: Show. The term "show" appears somewhat ambiguous in this context. It could refer to a television show, a play, a showcase, etc. None of these interpretations seem to involve plumbing let alone providing drinking water. However, the question refers to a place so this seems an unlikely answer.
7. Option D: Own Home. In your own home, the plumbing systems serve various purposes like providing drinking water through faucets and taps. Therefore, if you were thirsty at home, the plumbing would be useful to you.
8. Option E: Water Fountain. A water fountain also provides drinking water, so it would be useful if you were thirsty.
9. Only option A, oil refineries, involves plumbing that doesn't normally provide drinking water.
10. Thus, the answer is A: oil refineries.
Answer: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Rationales: 1. The question is asking what a person isn't doing "yet" when they are beginning work.
2. This implies that the answer would be something that generally happens later in the work process.
3. Looking at choice A: "working", we can rule this out because a person is already engaging in work when they are beginning work.
4. Choice B: "resting", can also be ruled out because resting generally happens after or in-between work, so it doesn't quite answer the question.
5. Similarly, choice C: "tiredness", does not fit because it's a condition that might occur while or after working.
6. For choice E: "momentum", it's possible to start work with momentum so this option doesn't generally happen later in the work process.
7. This leaves us with choice D: "accomplishing". Advancement or achievement ("accomplishing") usually comes after having put significant time and effort into the work. Therefore, this is the best choice. 
8. So, when a person is beginning work, they aren't yet accomplishing. This aligns very well with the process of working. Hence, the answer is D: accomplishing.
Answer: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Rationales: 1. The question asks for a location where one might find pens with a company logo.
2. The possible answers are various places or things: an office, a pencil, writing sentences on paper, a school, or a backpack.
3. A company logo on a pen is often a promotional item that is commonly used in a corporate environment.
4. The places where you might find such items are generally offices or corporate events. Therefore, the most logical option is the office, as it is a working environment.
5. Out of all the other options, none consistently have pens with a company logo. Though a pencil, school, or backpack could occasionally contain these pens, they're not as likely because they are not specifically related to a corporate environment. 
6. And writing sentences on paper is not a location, so it's incorrect.
7. Therefore, after analyzing each choice, the answer is A: office, because this location is most likely to have pens with a company logo due to corporate use.
Answer: A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Rationales: 1. The question describes a situation where Billy called out to John. 
2. If someone calls out to another person, they are usually looking for a reply or wanting to get their attention.
3. This means that Billy would be expecting something coming back from John in return.
4. Let's explore the multiple choice answers. Option A: Billy might not expect silence because when you call out to someone, you want them to say something in return.
5. Option C: communication could be a potential answer, but it is quite broad. A response is a specific form of communication that happens when one person replies to another's words or actions.
6. Option D: hanging up is irrelevant because the situation does not involve using a phone.
7. Option E: a whisper could be considered a kind of response, but it is not necessarily what one would expect in this context. The response could be loud or soft, quick or slow, depending on the scenario.
8. Hence, the best choice is B: response, which is what one would commonly expect after calling out to someone.
Answer: B: response

Input: The lizard frightened the hiker, it's movements made what rustle? Choices:  A: garden B: trees C: books D: rocks E: bushes
Rationales: 1. The question is asking about the origin of the sound that frightened the hiker. 
2. The sound is described as a rustle, which typically refers to a soft, muffled crackling sound like that made by the movement of dry leaves or paper.
3. The answer choices given are garden, trees, books, rocks and bushes. We need to select an option where a lizard's movement could cause a rustling sound.
4. Consider 'garden'- the lizard can move in a garden, but a garden itself isn't known to produce a rustling sound specifically.
5. As for 'trees' and 'books', rustling could potentially happen due to wind or movement, but lizards don't typically move on these surfaces enough to cause a rustle.
6. 'Rocks' do not make a rustling sound when moved, ruling out this option.
7. Now, consider 'bushes'. Lizards often move inside and between bushes, where leaves could produce a rustling sound.
8. Hence, E: bushes is the answer. The lizard's movements made the bushes rustle, causing the hiker to be frightened.
Answer: E: bushes

Input: The man spent big money and time maintaining his lawn, it was part of keeping up with the Joneses where? Choices:  A: front yard B: suburbia C: neighborhood D: back yard E: golf course
Rationales: 1. The phrase "keeping up with the Joneses" refers to the comparison and competition one experiences amongst their neighbors where they strive to have the latest and greatest possessions or appearances.
2. In this case, the man is spending money and time maintaining his lawn, which is likely seen by his neighbors.
3. While options like "front yard", "neighborhood", and "back yard" can be places where the man's lawn is located and hence seen by his neighbors, they do not encompass the broader societal setting in which the pressures of "keeping up with the Joneses" occur.
4. Same with "golf course", this term neither implies the residence of the individual nor does it highlight the neighborhood aspect of the phrase.
5. On the other hand, "suburbia" implies a suburban setting where groups of residential houses are present and thus is often associated with the societal pressures of comparisons amongst neighbors or "keeping up with the Joneses".
6. Therefore, answer B: "suburbia" is the appropriate choice as it best fits the context of where "keeping up with the Joneses" takes place.
Answer: B: suburbia

### Input:Natalia sold clips to 4
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o6-tcommonsenseqa-s1-rTrue
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:42<34:35, 42.35s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:23<33:26, 41.80s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:05<32:35, 41.61s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [02:46<31:51, 41.56s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [03:27<31:03, 41.41s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [04:09<30:21, 41.40s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [04:50<29:39, 41.38s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [05:31<28:58, 41.39s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [06:13<28:17, 41.39s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [06:54<27:33, 41.33s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [07:35<26:52, 41.34s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [08:17<26:09, 41.30s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [08:58<25:28, 41.31s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [09:39<24:47, 41.33s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [10:20<24:05, 41.29s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [11:02<23:25, 41.34s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [11:43<22:45, 41.36s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [12:25<22:03, 41.37s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [13:06<21:20, 41.31s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [13:47<20:39, 41.32s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [14:29<19:58, 41.34s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [15:10<19:18, 41.38s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [15:51<18:36, 41.36s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [16:33<17:54, 41.31s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [17:05<16:07, 38.68s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [17:47<15:47, 39.48s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [18:28<15:20, 40.01s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [19:09<14:48, 40.37s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [19:50<14:12, 40.62s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [20:31<13:35, 40.76s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [21:13<12:57, 40.92s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [21:54<12:19, 41.08s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [22:35<11:39, 41.17s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [23:17<10:59, 41.24s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [23:58<10:18, 41.21s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [24:39<09:37, 41.22s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [25:21<08:56, 41.27s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [26:02<08:14, 41.22s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [26:43<07:33, 41.26s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [27:24<06:52, 41.23s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [28:05<06:10, 41.20s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [28:47<05:29, 41.25s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [29:28<04:48, 41.22s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [30:09<04:07, 41.23s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [30:50<03:26, 41.27s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [31:32<02:44, 41.24s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [32:13<02:03, 41.25s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [32:54<01:22, 41.30s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [33:35<00:41, 41.25s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [34:17<00:00, 41.24s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [34:17<00:00, 41.14s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.1383} | lm_loss 10.6211 | avg. gen lenth: 397.12
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o7-tcommonsenseqa-s1-rTrue --seed 1 --rationales --num-out-domain 7
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-12 18:01:18,120] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o7-tcommonsenseqa-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 7
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o7-tcommonsenseqa-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  0%|                                                     | 14/7473 [00:00<00:57, 130.64it/s]  0%|▏                                                    | 28/7473 [00:00<00:56, 131.02it/s]  1%|▎                                                    | 42/7473 [00:00<00:56, 131.23it/s]  1%|▍                                                    | 56/7473 [00:00<00:56, 131.61it/s]  1%|▍                                                    | 70/7473 [00:00<00:56, 131.60it/s]  1%|▌                                                    | 84/7473 [00:00<00:56, 131.65it/s]  1%|▋                                                    | 98/7473 [00:00<00:56, 129.81it/s]  1%|▊                                                   | 112/7473 [00:00<00:56, 130.13it/s]  2%|▉                                                   | 126/7473 [00:00<00:56, 130.37it/s]  2%|▉                                                   | 140/7473 [00:01<00:56, 130.75it/s]  2%|█                                                   | 154/7473 [00:01<00:55, 131.17it/s]  2%|█▏                                                  | 168/7473 [00:01<00:55, 131.11it/s]  2%|█▎                                                  | 182/7473 [00:01<00:55, 131.48it/s]  3%|█▎                                                  | 196/7473 [00:01<00:55, 131.45it/s]  3%|█▍                                                  | 210/7473 [00:01<00:55, 131.71it/s]  3%|█▌                                                  | 224/7473 [00:01<00:55, 130.44it/s]  3%|█▋                                                  | 238/7473 [00:01<00:55, 130.54it/s]  3%|█▊                                                  | 252/7473 [00:01<00:56, 128.52it/s]  4%|█▊                                                  | 266/7473 [00:02<00:55, 129.82it/s]  4%|█▉                                                  | 280/7473 [00:02<00:55, 130.41it/s]  4%|██                                                  | 294/7473 [00:02<00:54, 130.88it/s]  4%|██▏                                                 | 310/7473 [00:02<00:51, 138.07it/s]  4%|██▎                                                 | 331/7473 [00:02<00:45, 156.99it/s]  5%|██▍                                                 | 351/7473 [00:02<00:42, 169.36it/s]  5%|██▌                                                 | 371/7473 [00:02<00:40, 176.64it/s]  5%|██▋                                                 | 391/7473 [00:02<00:38, 181.94it/s]  5%|██▊                                                 | 411/7473 [00:02<00:38, 185.25it/s]  6%|██▉                                                 | 431/7473 [00:02<00:37, 189.34it/s]  6%|███▏                                                | 452/7473 [00:03<00:36, 192.86it/s]  6%|███▎                                                | 473/7473 [00:03<00:35, 195.18it/s]  7%|███▍                                                | 493/7473 [00:03<00:35, 195.24it/s]  7%|███▌                                                | 514/7473 [00:03<00:35, 196.79it/s]  7%|███▋                                                | 535/7473 [00:03<00:35, 198.13it/s]  7%|███▊                                                | 556/7473 [00:03<00:34, 199.37it/s]  8%|████                                                | 577/7473 [00:03<00:34, 199.67it/s]  8%|████▏                                               | 598/7473 [00:03<00:34, 199.86it/s]  8%|████▎                                               | 618/7473 [00:03<00:34, 199.86it/s]  9%|████▍                                               | 638/7473 [00:04<00:34, 199.34it/s]  9%|████▌                                               | 659/7473 [00:04<00:34, 199.84it/s]  9%|████▋                                               | 680/7473 [00:04<00:33, 200.25it/s]  9%|████▉                                               | 701/7473 [00:04<00:33, 200.91it/s] 10%|█████                                               | 722/7473 [00:04<00:33, 199.46it/s] 10%|█████▏                                              | 743/7473 [00:04<00:33, 200.37it/s] 10%|█████▎                                              | 764/7473 [00:04<00:33, 200.26it/s] 11%|█████▍                                              | 785/7473 [00:04<00:33, 200.23it/s] 11%|█████▌                                              | 806/7473 [00:04<00:33, 200.01it/s] 11%|█████▊                                              | 827/7473 [00:04<00:33, 200.22it/s] 11%|█████▉                                              | 848/7473 [00:05<00:33, 200.44it/s] 12%|██████                                              | 869/7473 [00:05<00:32, 200.69it/s] 12%|██████▏                                             | 890/7473 [00:05<00:32, 200.69it/s] 12%|██████▎                                             | 911/7473 [00:05<00:32, 199.14it/s] 12%|██████▍                                             | 931/7473 [00:05<00:33, 197.29it/s] 13%|██████▌                                             | 952/7473 [00:05<00:32, 198.55it/s] 13%|██████▊                                             | 973/7473 [00:05<00:32, 199.74it/s] 13%|██████▉                                             | 994/7473 [00:05<00:32, 200.33it/s] 14%|██████▉                                            | 1015/7473 [00:05<00:32, 200.37it/s] 14%|███████                                            | 1036/7473 [00:05<00:32, 200.39it/s] 14%|███████▏                                           | 1057/7473 [00:06<00:31, 200.85it/s] 14%|███████▎                                           | 1078/7473 [00:06<00:31, 200.88it/s] 15%|███████▌                                           | 1099/7473 [00:06<00:31, 201.10it/s] 15%|███████▋                                           | 1120/7473 [00:06<00:31, 201.02it/s] 15%|███████▊                                           | 1141/7473 [00:06<00:31, 200.80it/s] 16%|███████▉                                           | 1162/7473 [00:06<00:32, 196.89it/s] 16%|████████                                           | 1183/7473 [00:06<00:31, 197.91it/s] 16%|████████▏                                          | 1203/7473 [00:06<00:31, 198.35it/s] 16%|████████▎                                          | 1224/7473 [00:06<00:31, 199.20it/s] 17%|████████▍                                          | 1245/7473 [00:07<00:31, 199.58it/s] 17%|████████▋                                          | 1265/7473 [00:07<00:31, 199.70it/s] 17%|████████▊                                          | 1286/7473 [00:07<00:30, 200.21it/s] 17%|████████▉                                          | 1307/7473 [00:07<00:30, 200.55it/s] 18%|█████████                                          | 1328/7473 [00:07<00:30, 200.69it/s] 18%|█████████▏                                         | 1349/7473 [00:07<00:30, 200.96it/s] 18%|█████████▎                                         | 1370/7473 [00:07<00:30, 200.87it/s] 19%|█████████▍                                         | 1391/7473 [00:07<00:30, 198.55it/s] 19%|█████████▋                                         | 1412/7473 [00:07<00:30, 199.34it/s] 19%|█████████▊                                         | 1432/7473 [00:07<00:30, 199.24it/s] 19%|█████████▉                                         | 1453/7473 [00:08<00:30, 199.80it/s] 20%|██████████                                         | 1474/7473 [00:08<00:29, 200.19it/s] 20%|██████████▏                                        | 1495/7473 [00:08<00:29, 200.57it/s] 20%|██████████▎                                        | 1516/7473 [00:08<00:29, 200.72it/s] 21%|██████████▍                                        | 1537/7473 [00:08<00:29, 200.84it/s] 21%|██████████▋                                        | 1558/7473 [00:08<00:29, 200.50it/s] 21%|██████████▊                                        | 1579/7473 [00:08<00:29, 200.15it/s] 21%|██████████▉                                        | 1600/7473 [00:08<00:29, 199.98it/s] 22%|███████████                                        | 1620/7473 [00:08<00:29, 198.46it/s] 22%|███████████▏                                       | 1641/7473 [00:09<00:29, 199.22it/s] 22%|███████████▎                                       | 1661/7473 [00:09<00:29, 199.33it/s] 23%|███████████▍                                       | 1682/7473 [00:09<00:28, 200.13it/s] 23%|███████████▌                                       | 1703/7473 [00:09<00:28, 200.24it/s] 23%|███████████▊                                       | 1724/7473 [00:09<00:28, 200.17it/s] 23%|███████████▉                                       | 1745/7473 [00:09<00:28, 200.10it/s] 24%|████████████                                       | 1766/7473 [00:09<00:28, 199.47it/s] 24%|████████████▏                                      | 1787/7473 [00:09<00:28, 199.86it/s] 24%|████████████▎                                      | 1808/7473 [00:09<00:28, 200.21it/s] 24%|████████████▍                                      | 1829/7473 [00:09<00:28, 199.86it/s] 25%|████████████▌                                      | 1849/7473 [00:10<00:28, 197.81it/s] 25%|████████████▊                                      | 1870/7473 [00:10<00:28, 198.69it/s] 25%|████████████▉                                      | 1890/7473 [00:10<00:28, 199.02it/s] 26%|█████████████                                      | 1910/7473 [00:10<00:27, 198.90it/s] 26%|█████████████▏                                     | 1930/7473 [00:10<00:27, 199.13it/s] 26%|█████████████▎                                     | 1950/7473 [00:10<00:27, 199.16it/s] 26%|█████████████▍                                     | 1970/7473 [00:10<00:27, 199.27it/s] 27%|█████████████▌                                     | 1991/7473 [00:10<00:27, 199.52it/s] 27%|█████████████▋                                     | 2011/7473 [00:10<00:27, 199.53it/s] 27%|█████████████▊                                     | 2032/7473 [00:10<00:27, 199.93it/s] 27%|██████████████                                     | 2052/7473 [00:11<00:27, 199.74it/s] 28%|██████████████▏                                    | 2072/7473 [00:11<00:27, 197.88it/s] 28%|██████████████▎                                    | 2093/7473 [00:11<00:27, 198.75it/s] 28%|██████████████▍                                    | 2113/7473 [00:11<00:26, 198.83it/s] 29%|██████████████▌                                    | 2133/7473 [00:11<00:26, 198.46it/s] 29%|██████████████▋                                    | 2154/7473 [00:11<00:26, 199.22it/s] 29%|██████████████▊                                    | 2174/7473 [00:11<00:26, 199.34it/s] 29%|██████████████▉                                    | 2194/7473 [00:11<00:26, 199.15it/s] 30%|███████████████                                    | 2215/7473 [00:11<00:26, 199.79it/s] 30%|███████████████▎                                   | 2235/7473 [00:11<00:26, 199.77it/s] 30%|███████████████▍                                   | 2255/7473 [00:12<00:26, 199.17it/s] 30%|███████████████▌                                   | 2275/7473 [00:12<00:26, 199.16it/s] 31%|███████████████▋                                   | 2295/7473 [00:12<00:26, 197.53it/s] 31%|███████████████▊                                   | 2316/7473 [00:12<00:25, 198.65it/s] 31%|███████████████▉                                   | 2337/7473 [00:12<00:25, 199.08it/s] 32%|████████████████                                   | 2357/7473 [00:12<00:25, 198.85it/s] 32%|████████████████▏                                  | 2377/7473 [00:12<00:25, 198.89it/s] 32%|████████████████▎                                  | 2397/7473 [00:12<00:25, 199.07it/s] 32%|████████████████▌                                  | 2418/7473 [00:12<00:25, 199.45it/s] 33%|████████████████▋                                  | 2438/7473 [00:13<00:25, 199.45it/s] 33%|████████████████▊                                  | 2459/7473 [00:13<00:25, 199.56it/s] 33%|████████████████▉                                  | 2479/7473 [00:13<00:25, 199.62it/s] 33%|█████████████████                                  | 2499/7473 [00:13<00:24, 199.44it/s] 34%|█████████████████▏                                 | 2519/7473 [00:13<00:28, 173.58it/s] 34%|█████████████████▎                                 | 2539/7473 [00:13<00:27, 179.89it/s] 34%|█████████████████▍                                 | 2559/7473 [00:13<00:26, 185.25it/s] 35%|█████████████████▌                                 | 2580/7473 [00:13<00:25, 189.95it/s] 35%|█████████████████▋                                 | 2600/7473 [00:13<00:25, 192.42it/s] 35%|█████████████████▉                                 | 2620/7473 [00:13<00:24, 194.35it/s] 35%|██████████████████                                 | 2640/7473 [00:14<00:24, 195.25it/s] 36%|██████████████████▏                                | 2661/7473 [00:14<00:24, 197.14it/s] 36%|██████████████████▎                                | 2682/7473 [00:14<00:24, 198.43it/s] 36%|██████████████████▍                                | 2703/7473 [00:14<00:23, 199.02it/s] 36%|██████████████████▌                                | 2724/7473 [00:14<00:23, 199.43it/s] 37%|██████████████████▋                                | 2744/7473 [00:14<00:23, 199.05it/s] 37%|██████████████████▊                                | 2764/7473 [00:14<00:23, 197.00it/s] 37%|███████████████████                                | 2785/7473 [00:14<00:23, 198.34it/s] 38%|███████████████████▏                               | 2806/7473 [00:14<00:23, 199.19it/s] 38%|███████████████████▎                               | 2826/7473 [00:15<00:23, 199.35it/s] 38%|███████████████████▍                               | 2847/7473 [00:15<00:23, 199.61it/s] 38%|███████████████████▌                               | 2867/7473 [00:15<00:23, 199.57it/s] 39%|███████████████████▋                               | 2888/7473 [00:15<00:22, 199.77it/s] 39%|███████████████████▊                               | 2909/7473 [00:15<00:22, 200.21it/s] 39%|███████████████████▉                               | 2930/7473 [00:15<00:22, 200.82it/s] 39%|████████████████████▏                              | 2951/7473 [00:15<00:22, 200.75it/s] 40%|████████████████████▎                              | 2972/7473 [00:15<00:22, 200.53it/s] 40%|████████████████████▍                              | 2993/7473 [00:15<00:22, 198.85it/s] 40%|████████████████████▌                              | 3014/7473 [00:15<00:22, 199.35it/s] 41%|████████████████████▋                              | 3034/7473 [00:16<00:22, 199.25it/s] 41%|████████████████████▊                              | 3054/7473 [00:16<00:22, 199.32it/s] 41%|████████████████████▉                              | 3075/7473 [00:16<00:22, 199.68it/s] 41%|█████████████████████▏                             | 3096/7473 [00:16<00:21, 199.93it/s] 42%|█████████████████████▎                             | 3116/7473 [00:16<00:22, 197.61it/s] 42%|█████████████████████▍                             | 3136/7473 [00:16<00:21, 198.18it/s] 42%|█████████████████████▌                             | 3156/7473 [00:16<00:21, 198.37it/s] 42%|█████████████████████▋                             | 3176/7473 [00:16<00:21, 198.61it/s] 43%|█████████████████████▊                             | 3197/7473 [00:16<00:21, 199.05it/s] 43%|█████████████████████▉                             | 3217/7473 [00:16<00:21, 197.48it/s] 43%|██████████████████████                             | 3238/7473 [00:17<00:21, 198.34it/s] 44%|██████████████████████▏                            | 3258/7473 [00:17<00:21, 198.82it/s] 44%|██████████████████████▍                            | 3279/7473 [00:17<00:21, 199.34it/s] 44%|██████████████████████▌                            | 3299/7473 [00:17<00:20, 199.52it/s] 44%|██████████████████████▋                            | 3319/7473 [00:17<00:20, 199.56it/s] 45%|██████████████████████▊                            | 3339/7473 [00:17<00:20, 198.83it/s] 45%|██████████████████████▉                            | 3360/7473 [00:17<00:20, 199.28it/s] 45%|███████████████████████                            | 3380/7473 [00:17<00:20, 199.24it/s] 45%|███████████████████████▏                           | 3400/7473 [00:17<00:20, 199.37it/s] 46%|███████████████████████▎                           | 3420/7473 [00:17<00:20, 199.46it/s] 46%|███████████████████████▍                           | 3440/7473 [00:18<00:20, 196.36it/s] 46%|███████████████████████▌                           | 3460/7473 [00:18<00:20, 196.94it/s] 47%|███████████████████████▋                           | 3480/7473 [00:18<00:20, 197.52it/s] 47%|███████████████████████▉                           | 3501/7473 [00:18<00:20, 198.58it/s] 47%|████████████████████████                           | 3522/7473 [00:18<00:19, 199.01it/s] 47%|████████████████████████▏                          | 3542/7473 [00:18<00:19, 199.27it/s] 48%|████████████████████████▎                          | 3562/7473 [00:18<00:19, 199.40it/s] 48%|████████████████████████▍                          | 3583/7473 [00:18<00:19, 199.57it/s] 48%|████████████████████████▌                          | 3603/7473 [00:18<00:19, 199.61it/s] 48%|████████████████████████▋                          | 3624/7473 [00:19<00:19, 199.64it/s] 49%|████████████████████████▊                          | 3644/7473 [00:19<00:19, 199.37it/s] 49%|█████████████████████████                          | 3664/7473 [00:19<00:19, 197.62it/s] 49%|█████████████████████████▏                         | 3685/7473 [00:19<00:19, 198.29it/s] 50%|█████████████████████████▎                         | 3705/7473 [00:19<00:19, 198.27it/s] 50%|█████████████████████████▍                         | 3725/7473 [00:19<00:18, 198.42it/s] 50%|█████████████████████████▌                         | 3745/7473 [00:19<00:18, 198.65it/s] 50%|█████████████████████████▋                         | 3766/7473 [00:19<00:18, 199.12it/s] 51%|█████████████████████████▊                         | 3786/7473 [00:19<00:18, 198.13it/s] 51%|█████████████████████████▉                         | 3806/7473 [00:19<00:18, 198.66it/s] 51%|██████████████████████████                         | 3826/7473 [00:20<00:18, 198.66it/s] 51%|██████████████████████████▏                        | 3846/7473 [00:20<00:18, 198.72it/s] 52%|██████████████████████████▍                        | 3866/7473 [00:20<00:18, 198.85it/s] 52%|██████████████████████████▌                        | 3886/7473 [00:20<00:18, 197.15it/s] 52%|██████████████████████████▋                        | 3906/7473 [00:20<00:18, 197.81it/s] 53%|██████████████████████████▊                        | 3926/7473 [00:20<00:17, 198.22it/s] 53%|██████████████████████████▉                        | 3946/7473 [00:20<00:17, 198.68it/s] 53%|███████████████████████████                        | 3966/7473 [00:20<00:17, 198.93it/s] 53%|███████████████████████████▏                       | 3986/7473 [00:20<00:17, 198.85it/s] 54%|███████████████████████████▎                       | 4007/7473 [00:20<00:17, 199.24it/s] 54%|███████████████████████████▍                       | 4028/7473 [00:21<00:17, 199.44it/s] 54%|███████████████████████████▋                       | 4048/7473 [00:21<00:17, 199.45it/s] 54%|███████████████████████████▊                       | 4069/7473 [00:21<00:17, 199.61it/s] 55%|███████████████████████████▉                       | 4089/7473 [00:21<00:16, 199.51it/s] 55%|████████████████████████████                       | 4109/7473 [00:21<00:17, 197.39it/s] 55%|████████████████████████████▏                      | 4129/7473 [00:21<00:17, 195.70it/s] 56%|████████████████████████████▎                      | 4149/7473 [00:21<00:16, 196.62it/s] 56%|████████████████████████████▍                      | 4169/7473 [00:21<00:16, 197.59it/s] 56%|████████████████████████████▌                      | 4189/7473 [00:21<00:16, 198.10it/s] 56%|████████████████████████████▋                      | 4209/7473 [00:21<00:16, 198.61it/s] 57%|████████████████████████████▊                      | 4229/7473 [00:22<00:16, 198.78it/s] 57%|████████████████████████████▉                      | 4249/7473 [00:22<00:16, 198.88it/s] 57%|█████████████████████████████▏                     | 4269/7473 [00:22<00:16, 198.88it/s] 57%|█████████████████████████████▎                     | 4289/7473 [00:22<00:16, 198.89it/s] 58%|█████████████████████████████▍                     | 4310/7473 [00:22<00:15, 199.28it/s] 58%|█████████████████████████████▌                     | 4331/7473 [00:22<00:15, 199.19it/s] 58%|█████████████████████████████▋                     | 4351/7473 [00:22<00:15, 197.37it/s] 58%|█████████████████████████████▊                     | 4371/7473 [00:22<00:15, 197.64it/s] 59%|█████████████████████████████▉                     | 4391/7473 [00:22<00:15, 198.16it/s] 59%|██████████████████████████████                     | 4412/7473 [00:22<00:15, 198.82it/s] 59%|██████████████████████████████▏                    | 4432/7473 [00:23<00:15, 198.84it/s] 60%|██████████████████████████████▍                    | 4452/7473 [00:23<00:15, 197.00it/s] 60%|██████████████████████████████▌                    | 4472/7473 [00:23<00:15, 197.83it/s] 60%|██████████████████████████████▋                    | 4493/7473 [00:23<00:15, 198.52it/s] 60%|██████████████████████████████▊                    | 4513/7473 [00:23<00:14, 198.66it/s] 61%|██████████████████████████████▉                    | 4533/7473 [00:23<00:14, 198.62it/s] 61%|███████████████████████████████                    | 4554/7473 [00:23<00:14, 199.51it/s] 61%|███████████████████████████████▏                   | 4574/7473 [00:23<00:14, 197.98it/s] 61%|███████████████████████████████▎                   | 4594/7473 [00:23<00:14, 198.33it/s] 62%|███████████████████████████████▍                   | 4614/7473 [00:24<00:14, 198.80it/s] 62%|███████████████████████████████▋                   | 4634/7473 [00:24<00:14, 198.86it/s] 62%|███████████████████████████████▊                   | 4654/7473 [00:24<00:14, 199.18it/s] 63%|███████████████████████████████▉                   | 4674/7473 [00:24<00:14, 199.02it/s] 63%|████████████████████████████████                   | 4694/7473 [00:24<00:13, 199.29it/s] 63%|████████████████████████████████▏                  | 4714/7473 [00:24<00:13, 199.45it/s] 63%|████████████████████████████████▎                  | 4734/7473 [00:24<00:13, 199.61it/s] 64%|████████████████████████████████▍                  | 4755/7473 [00:24<00:13, 199.96it/s] 64%|████████████████████████████████▌                  | 4776/7473 [00:24<00:13, 200.02it/s] 64%|████████████████████████████████▋                  | 4797/7473 [00:24<00:13, 197.99it/s] 64%|████████████████████████████████▊                  | 4817/7473 [00:25<00:13, 198.27it/s] 65%|█████████████████████████████████                  | 4837/7473 [00:25<00:13, 198.65it/s] 65%|█████████████████████████████████▏                 | 4857/7473 [00:25<00:13, 198.90it/s] 65%|█████████████████████████████████▎                 | 4877/7473 [00:25<00:13, 199.06it/s] 66%|█████████████████████████████████▍                 | 4898/7473 [00:25<00:12, 199.72it/s] 66%|█████████████████████████████████▌                 | 4919/7473 [00:25<00:12, 199.84it/s] 66%|█████████████████████████████████▋                 | 4939/7473 [00:25<00:12, 199.66it/s] 66%|█████████████████████████████████▊                 | 4959/7473 [00:25<00:12, 199.74it/s] 67%|█████████████████████████████████▉                 | 4979/7473 [00:25<00:12, 199.47it/s] 67%|██████████████████████████████████                 | 4999/7473 [00:25<00:12, 199.54it/s] 67%|██████████████████████████████████▎                | 5019/7473 [00:26<00:12, 198.31it/s] 67%|██████████████████████████████████▍                | 5039/7473 [00:26<00:12, 198.67it/s] 68%|██████████████████████████████████▌                | 5059/7473 [00:26<00:12, 199.00it/s] 68%|██████████████████████████████████▋                | 5080/7473 [00:26<00:11, 199.46it/s] 68%|██████████████████████████████████▊                | 5100/7473 [00:26<00:11, 199.23it/s] 69%|██████████████████████████████████▉                | 5120/7473 [00:26<00:11, 199.27it/s] 69%|███████████████████████████████████                | 5141/7473 [00:26<00:11, 199.55it/s] 69%|███████████████████████████████████▏               | 5161/7473 [00:26<00:11, 199.62it/s] 69%|███████████████████████████████████▎               | 5181/7473 [00:26<00:11, 199.71it/s] 70%|███████████████████████████████████▍               | 5201/7473 [00:26<00:11, 199.65it/s] 70%|███████████████████████████████████▋               | 5221/7473 [00:27<00:11, 199.59it/s] 70%|███████████████████████████████████▊               | 5241/7473 [00:27<00:11, 198.59it/s] 70%|███████████████████████████████████▉               | 5261/7473 [00:27<00:13, 169.57it/s] 71%|████████████████████████████████████               | 5282/7473 [00:27<00:12, 178.01it/s] 71%|████████████████████████████████████▏              | 5302/7473 [00:27<00:11, 183.74it/s] 71%|████████████████████████████████████▎              | 5322/7473 [00:27<00:11, 187.84it/s] 71%|████████████████████████████████████▍              | 5342/7473 [00:27<00:11, 191.09it/s] 72%|████████████████████████████████████▌              | 5362/7473 [00:27<00:10, 193.30it/s] 72%|████████████████████████████████████▋              | 5382/7473 [00:27<00:10, 195.21it/s] 72%|████████████████████████████████████▊              | 5402/7473 [00:28<00:10, 196.45it/s] 73%|█████████████████████████████████████              | 5422/7473 [00:28<00:10, 197.46it/s] 73%|█████████████████████████████████████▏             | 5442/7473 [00:28<00:10, 197.70it/s] 73%|█████████████████████████████████████▎             | 5462/7473 [00:28<00:10, 197.08it/s] 73%|█████████████████████████████████████▍             | 5482/7473 [00:28<00:15, 132.63it/s] 74%|█████████████████████████████████████▌             | 5502/7473 [00:28<00:13, 147.16it/s] 74%|█████████████████████████████████████▋             | 5522/7473 [00:28<00:12, 159.81it/s] 74%|█████████████████████████████████████▊             | 5542/7473 [00:28<00:11, 169.49it/s] 74%|█████████████████████████████████████▉             | 5562/7473 [00:28<00:10, 177.49it/s] 75%|██████████████████████████████████████             | 5582/7473 [00:29<00:10, 182.93it/s] 75%|██████████████████████████████████████▏            | 5602/7473 [00:29<00:09, 187.25it/s] 75%|██████████████████████████████████████▎            | 5622/7473 [00:29<00:09, 190.12it/s] 75%|██████████████████████████████████████▌            | 5642/7473 [00:29<00:09, 192.73it/s] 76%|██████████████████████████████████████▋            | 5662/7473 [00:29<00:09, 194.55it/s] 76%|██████████████████████████████████████▊            | 5682/7473 [00:29<00:09, 194.04it/s] 76%|██████████████████████████████████████▉            | 5702/7473 [00:29<00:09, 195.15it/s] 77%|███████████████████████████████████████            | 5722/7473 [00:29<00:08, 195.82it/s] 77%|███████████████████████████████████████▏           | 5742/7473 [00:29<00:08, 196.78it/s] 77%|███████████████████████████████████████▎           | 5762/7473 [00:30<00:08, 197.58it/s] 77%|███████████████████████████████████████▍           | 5782/7473 [00:30<00:08, 197.95it/s] 78%|███████████████████████████████████████▌           | 5802/7473 [00:30<00:08, 197.84it/s] 78%|███████████████████████████████████████▋           | 5822/7473 [00:30<00:08, 197.55it/s] 78%|███████████████████████████████████████▊           | 5842/7473 [00:30<00:08, 197.57it/s] 78%|████████████████████████████████████████           | 5862/7473 [00:30<00:08, 197.71it/s] 79%|████████████████████████████████████████▏          | 5882/7473 [00:30<00:08, 197.88it/s] 79%|████████████████████████████████████████▎          | 5902/7473 [00:30<00:08, 196.17it/s] 79%|████████████████████████████████████████▍          | 5922/7473 [00:30<00:07, 195.91it/s] 80%|████████████████████████████████████████▌          | 5942/7473 [00:30<00:07, 196.47it/s] 80%|████████████████████████████████████████▋          | 5962/7473 [00:31<00:07, 196.36it/s] 80%|████████████████████████████████████████▊          | 5982/7473 [00:31<00:07, 196.49it/s] 80%|████████████████████████████████████████▉          | 6002/7473 [00:31<00:07, 196.18it/s] 81%|█████████████████████████████████████████          | 6022/7473 [00:31<00:07, 196.33it/s] 81%|█████████████████████████████████████████▏         | 6042/7473 [00:31<00:07, 196.25it/s] 81%|█████████████████████████████████████████▎         | 6062/7473 [00:31<00:07, 196.39it/s] 81%|█████████████████████████████████████████▌         | 6082/7473 [00:31<00:07, 196.34it/s] 82%|█████████████████████████████████████████▋         | 6102/7473 [00:31<00:06, 196.63it/s] 82%|█████████████████████████████████████████▊         | 6122/7473 [00:31<00:06, 196.48it/s] 82%|█████████████████████████████████████████▉         | 6142/7473 [00:31<00:06, 194.61it/s] 82%|██████████████████████████████████████████         | 6162/7473 [00:32<00:06, 195.32it/s] 83%|██████████████████████████████████████████▏        | 6182/7473 [00:32<00:06, 195.42it/s] 83%|██████████████████████████████████████████▎        | 6202/7473 [00:32<00:06, 195.90it/s] 83%|██████████████████████████████████████████▍        | 6222/7473 [00:32<00:06, 195.87it/s] 84%|██████████████████████████████████████████▌        | 6242/7473 [00:32<00:06, 196.22it/s] 84%|██████████████████████████████████████████▋        | 6262/7473 [00:32<00:06, 196.09it/s] 84%|██████████████████████████████████████████▊        | 6282/7473 [00:32<00:06, 196.50it/s] 84%|███████████████████████████████████████████        | 6302/7473 [00:32<00:05, 196.10it/s] 85%|███████████████████████████████████████████▏       | 6322/7473 [00:32<00:05, 196.46it/s] 85%|███████████████████████████████████████████▎       | 6342/7473 [00:32<00:05, 196.20it/s] 85%|███████████████████████████████████████████▍       | 6362/7473 [00:33<00:05, 194.70it/s] 85%|███████████████████████████████████████████▌       | 6382/7473 [00:33<00:05, 194.54it/s] 86%|███████████████████████████████████████████▋       | 6402/7473 [00:33<00:05, 194.95it/s] 86%|███████████████████████████████████████████▊       | 6422/7473 [00:33<00:05, 195.27it/s] 86%|███████████████████████████████████████████▉       | 6442/7473 [00:33<00:05, 195.30it/s] 86%|████████████████████████████████████████████       | 6462/7473 [00:33<00:05, 195.51it/s] 87%|████████████████████████████████████████████▏      | 6482/7473 [00:33<00:05, 195.77it/s] 87%|████████████████████████████████████████████▎      | 6502/7473 [00:33<00:04, 195.74it/s] 87%|████████████████████████████████████████████▌      | 6522/7473 [00:33<00:04, 195.38it/s] 88%|████████████████████████████████████████████▋      | 6542/7473 [00:33<00:04, 195.98it/s] 88%|████████████████████████████████████████████▊      | 6562/7473 [00:34<00:04, 195.98it/s] 88%|████████████████████████████████████████████▉      | 6582/7473 [00:34<00:04, 194.58it/s] 88%|█████████████████████████████████████████████      | 6602/7473 [00:34<00:04, 195.15it/s] 89%|█████████████████████████████████████████████▏     | 6622/7473 [00:34<00:04, 195.35it/s] 89%|█████████████████████████████████████████████▎     | 6642/7473 [00:34<00:04, 195.44it/s] 89%|█████████████████████████████████████████████▍     | 6662/7473 [00:34<00:04, 195.27it/s] 89%|█████████████████████████████████████████████▌     | 6682/7473 [00:34<00:04, 195.25it/s] 90%|█████████████████████████████████████████████▋     | 6702/7473 [00:34<00:03, 195.80it/s] 90%|█████████████████████████████████████████████▊     | 6722/7473 [00:34<00:03, 195.78it/s] 90%|██████████████████████████████████████████████     | 6742/7473 [00:35<00:03, 195.92it/s] 90%|██████████████████████████████████████████████▏    | 6762/7473 [00:35<00:03, 195.84it/s] 91%|██████████████████████████████████████████████▎    | 6782/7473 [00:35<00:03, 196.13it/s] 91%|██████████████████████████████████████████████▍    | 6802/7473 [00:35<00:03, 196.19it/s] 91%|██████████████████████████████████████████████▌    | 6822/7473 [00:35<00:03, 193.91it/s] 92%|██████████████████████████████████████████████▋    | 6842/7473 [00:35<00:03, 194.62it/s] 92%|██████████████████████████████████████████████▊    | 6862/7473 [00:35<00:03, 195.08it/s] 92%|██████████████████████████████████████████████▉    | 6882/7473 [00:35<00:03, 195.80it/s] 92%|███████████████████████████████████████████████    | 6902/7473 [00:35<00:02, 196.29it/s] 93%|███████████████████████████████████████████████▏   | 6922/7473 [00:35<00:02, 196.23it/s] 93%|███████████████████████████████████████████████▍   | 6942/7473 [00:36<00:02, 196.07it/s] 93%|███████████████████████████████████████████████▌   | 6962/7473 [00:36<00:02, 195.96it/s] 93%|███████████████████████████████████████████████▋   | 6982/7473 [00:36<00:02, 195.67it/s] 94%|███████████████████████████████████████████████▊   | 7002/7473 [00:36<00:02, 196.62it/s] 94%|███████████████████████████████████████████████▉   | 7022/7473 [00:36<00:02, 197.19it/s] 94%|████████████████████████████████████████████████   | 7042/7473 [00:36<00:02, 195.74it/s] 95%|████████████████████████████████████████████████▏  | 7062/7473 [00:36<00:02, 196.48it/s] 95%|████████████████████████████████████████████████▎  | 7082/7473 [00:36<00:01, 197.26it/s] 95%|████████████████████████████████████████████████▍  | 7102/7473 [00:36<00:01, 198.00it/s] 95%|████████████████████████████████████████████████▌  | 7122/7473 [00:36<00:01, 197.69it/s] 96%|████████████████████████████████████████████████▋  | 7142/7473 [00:37<00:01, 197.85it/s] 96%|████████████████████████████████████████████████▉  | 7162/7473 [00:37<00:01, 198.01it/s] 96%|█████████████████████████████████████████████████  | 7182/7473 [00:37<00:01, 197.92it/s] 96%|█████████████████████████████████████████████████▏ | 7202/7473 [00:37<00:01, 198.34it/s] 97%|█████████████████████████████████████████████████▎ | 7222/7473 [00:37<00:01, 198.61it/s] 97%|█████████████████████████████████████████████████▍ | 7242/7473 [00:37<00:01, 198.86it/s] 97%|█████████████████████████████████████████████████▌ | 7262/7473 [00:37<00:01, 197.20it/s] 97%|█████████████████████████████████████████████████▋ | 7282/7473 [00:37<00:00, 197.77it/s] 98%|█████████████████████████████████████████████████▊ | 7302/7473 [00:37<00:00, 198.31it/s] 98%|█████████████████████████████████████████████████▉ | 7322/7473 [00:37<00:00, 198.25it/s] 98%|██████████████████████████████████████████████████ | 7342/7473 [00:38<00:00, 198.07it/s] 99%|██████████████████████████████████████████████████▏| 7362/7473 [00:38<00:00, 197.94it/s] 99%|██████████████████████████████████████████████████▍| 7382/7473 [00:38<00:00, 197.85it/s] 99%|██████████████████████████████████████████████████▌| 7402/7473 [00:38<00:00, 198.39it/s] 99%|██████████████████████████████████████████████████▋| 7422/7473 [00:38<00:00, 198.43it/s]100%|██████████████████████████████████████████████████▊| 7442/7473 [00:38<00:00, 198.38it/s]100%|██████████████████████████████████████████████████▉| 7462/7473 [00:38<00:00, 197.59it/s]100%|███████████████████████████████████████████████████| 7473/7473 [00:38<00:00, 193.01it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.16s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:04<00:09,  4.99s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.12s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.82s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.04s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.04s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.22s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.38s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.43s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.60s/it]
[2023-08-12 18:02:48,282] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.48s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.63s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.67s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.81s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.68s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.91s/it]
[2023-08-12 18:03:04,270] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 18:03:04,271] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 18:03:04,271] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7eff62576b20>
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 18:03:04,272] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7eff625768b0>
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 18:03:04,273] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 18:03:04,274] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 18:03:04,274] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 18:03:04,274] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 18:03:04,274] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 18:03:04,274] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 18:03:04,274] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 18:03:04,274] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 18:03:04,274] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 18:03:04,274] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.662177324295044 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Rationales: 1. The question is asking to identify a location that has plumbing but will not be of use when thirsty.
2. So, it would help to consider what kind of liquid might be flowing through the plumbing in each option.
3. In the "own home" and "water fountain," it is likely to find potable water, which would be of use when thirsty.
4. The "wall" might contain pipes that carry water, so this option could potentially be of use when thirsty.
5. "Show" is a bit vague, but if it refers to a show or event, there might be water facilities available too. 
6. However, in "oil refineries," the plumbing does not transport water at all, but is used for the refining of oil. This would not be useful if you were thirsty, as you cannot drink oil.
7. Hence the answer is A: oil refineries.
Answer: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Rationales: 1. This question asks about what a person "isn't doing yet" when they are "beginning work".
2. This phrase implies that the person has only just begun their work and therefore can not have done certain things yet.
3. Let's analyze the options:
- A: working. Now, this is not the answer because the person has already begun their work, which means they are currently working.
- B: resting. This answer might make sense, because when a person starts working, they are not resting. But this does not usually imply an accomplishment.
- C: tiredness. This answer might not be correct because while it's true that when a person starts working, they are not typically tired, it doesn't exactly imply something they haven't done yet.
- E: momentum. This is not necessarily accurate because while it's true that someone might not yet have momentum when starting, it doesn't speak to an action or something they haven't done yet.
4. On the other hand, D: accomplishing definitely can be something the person hasn't done yet since they have just begun their work, the accomplishment would come after the work is completed.
5. Therefore, the correct answer is D: accomplishing.
Answer: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Rationales: 1. Pens with a company logo are usually items that are used for promotional purposes.
2. Companies often use these pens at their offices for staff members.
3. Staff members can also give these pens to visitors or clients, so they are often found in workplaces or business events.
4. While pens can indeed be found in places like school or a backpack, pens specifically with a company logo are not typically associated with these places.
5. Therefore, the most logical location to find pens with a company logo is an office. Hence, the answer is A: office.
Answer: A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Rationales: 1. The question is asking what Billy is waiting to hear after he has called out to John. 
2. We look at each of the provided options and consider them in relation to the situation described:
   A: Silence would not be expected after somebody calls out to another person.
   C: Communication is too broad a term and does not denote a specific reaction from John.
   D: Hanging up would not apply since the scenario does not involve a phone call.
   E: Whisper is too specific, the scenario implies that Billy is waiting for an audible and clear answer not a whisper.
3. Hence, we look at B: Response. A response is precisely what a person would expect after they call out to someone; they are waiting for that person to respond.
4. Therefore, the most logical answer to the question is B: Response.
Answer: B: response

Input: The lizard frightened the hiker, it's movements made what rustle? Choices:  A: garden B: trees C: books D: rocks E: bushes
Rationales: 1. The question asks us what rustled due to the lizard's movement when it frightened the hiker.
2. Let's analyze the options one by one. 
3. Option A: A garden might rustle, but it generally refers to an area with a variety of plants and wouldn’t collectively rustle by the movement of a small creature like a lizard.
4. Option B: Trees are too large to rustle due to a lizard's movements.
5. Option C: Books can rustle, but it's unlikely in this context since hikers wouldn't typically encounter books on a trail.
6. Option D: Rocks don’t rustle at all, they are hard and would not create a rustling sound due to a small creature's movement.
7. Option E: Bushes are smaller plants, often found along hiking trails, and could rustle due to a small creature's movement.
8. By a process of elimination and logical analysis, the answer is E: bushes.
Answer: E: bushes

Input: The man spent big money and time maintaining his lawn, it was part of keeping up with the Joneses where? Choices:  A: front yard B: suburbia C: neighborhood D: back yard E: golf course
Rationales: 1. The phrase "keeping up with the Joneses" refers to a situation where a person tries to match their neighbors' social and economic status by emulating their lifestyle and consumer behavior. 
2. The notion of 'keeping up with the Joneses' is usually associated with suburban life or lifestyle, where maintaining lawns and houses is considered as status symbols.
3. While other options such as front yard, neighborhood, back yard, and golf course all can be places where a well-maintained lawn could exist, none of them are as tightly correlated with the context of 'keeping up with the Joneses' as the suburbia, which encapsulates an entire lifestyle and social context.
4. Therefore, taking the whole context into consideration, the most appropropriate and encompassing answer is B: suburbia.
Answer: B: suburbia

Input: What would a human do if they want to get to a store that he or she can see? Choices:  A: cross road B: see around C: drink coffee D: dream dreams E: think critically
Rationales: 1. The question is asking for the action a human would most likely take if they want to get to a store that they can see.
2. To answer, we should think about the most straightforward or necessary act for someone who can see a store and wishes to reach it.
3. Let's look at the options: "cross the road," "see around," "drink coffee," "dream dreams," "think critically."
4. "Drink coffee," "dream dreams," and "think critically" aren't directly related to the act of reaching a visible destination. They could be actions one might take, but they aren't necessary or related to the process of getting to a visually spotted location. Thus, we can eliminate these choices.
5. "See around" could be a potential answer as someone might need to see around to get to a certain place, but it is not the most direct or clear action required in reaching a visible store. So we can remove this as well.
6. That leaves us with the option "cross the road." This is the most plausible answer because when a human sees a store and desires to reach it, one essential action might be to cross a road if the store is situated on the other side of the road. Hence, this is the answer.
7. So, the answer is A: cross the road.
Answer: A: cross road

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o7-tcommonsenseqa-s1-rTrue
Loading extension module utils...
Time to load utils op: 0.6049680709838867 seconds
Loading extension module utils...
Time to load utils op: 0.7049791812896729 seconds
Loading extension module utils...
Time to load utils op: 0.7048122882843018 seconds
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 139, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 116, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 139, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 116, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
Evaluating gsm8k :   0%|                                              | 0/50 [00:05<?, ?it/s]
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 139, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 116, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 139, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 116, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 3449822) of binary: /home/ylu130/.conda/envs/distllm/bin/python
Traceback (most recent call last):
  File "/home/ylu130/.conda/envs/distllm/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/run.py", line 761, in main
    run(args)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/ylu130/workspace/in-context-generalization/inference.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-08-12_18:03:16
  host      : ia1.wse.jhu.edu
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 3449823)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-08-12_18:03:16
  host      : ia1.wse.jhu.edu
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 3449824)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-08-12_18:03:16
  host      : ia1.wse.jhu.edu
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 3449825)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-08-12_18:03:16
  host      : ia1.wse.jhu.edu
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3449822)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o8-tcommonsenseqa-s1-rTrue --seed 1 --rationales --num-out-domain 8
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-12 18:03:19,581] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o8-tcommonsenseqa-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 8
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o8-tcommonsenseqa-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  0%|                                                     | 12/7473 [00:00<01:06, 113.00it/s]  0%|▏                                                    | 24/7473 [00:00<01:05, 114.15it/s]  0%|▎                                                    | 36/7473 [00:00<01:04, 114.46it/s]  1%|▎                                                    | 48/7473 [00:00<01:04, 114.65it/s]  1%|▍                                                    | 60/7473 [00:00<01:04, 114.79it/s]  1%|▌                                                    | 72/7473 [00:00<01:04, 114.72it/s]  1%|▌                                                    | 84/7473 [00:00<01:05, 112.98it/s]  1%|▋                                                    | 96/7473 [00:00<01:04, 113.64it/s]  1%|▊                                                   | 108/7473 [00:00<01:04, 113.75it/s]  2%|▊                                                   | 120/7473 [00:01<01:04, 114.14it/s]  2%|▉                                                   | 132/7473 [00:01<01:04, 114.33it/s]  2%|█                                                   | 144/7473 [00:01<01:03, 114.59it/s]  2%|█                                                   | 156/7473 [00:01<01:03, 114.77it/s]  2%|█▏                                                  | 168/7473 [00:01<01:03, 114.75it/s]  2%|█▎                                                  | 180/7473 [00:01<01:03, 114.94it/s]  3%|█▎                                                  | 192/7473 [00:01<01:03, 113.97it/s]  3%|█▍                                                  | 204/7473 [00:01<01:03, 114.22it/s]  3%|█▌                                                  | 216/7473 [00:01<01:03, 114.53it/s]  3%|█▌                                                  | 228/7473 [00:01<01:03, 114.55it/s]  3%|█▋                                                  | 240/7473 [00:02<01:03, 114.40it/s]  3%|█▊                                                  | 252/7473 [00:02<01:04, 112.33it/s]  4%|█▊                                                  | 265/7473 [00:02<01:02, 116.23it/s]  4%|█▉                                                  | 283/7473 [00:02<00:53, 133.80it/s]  4%|██                                                  | 301/7473 [00:02<00:49, 146.34it/s]  4%|██▏                                                 | 319/7473 [00:02<00:46, 155.09it/s]  5%|██▎                                                 | 337/7473 [00:02<00:44, 161.13it/s]  5%|██▍                                                 | 355/7473 [00:02<00:43, 165.48it/s]  5%|██▌                                                 | 373/7473 [00:02<00:42, 168.18it/s]  5%|██▋                                                 | 391/7473 [00:03<00:41, 170.37it/s]  5%|██▊                                                 | 409/7473 [00:03<00:41, 171.34it/s]  6%|██▉                                                 | 427/7473 [00:03<00:40, 172.02it/s]  6%|███                                                 | 445/7473 [00:03<00:40, 171.91it/s]  6%|███▏                                                | 463/7473 [00:03<00:40, 172.34it/s]  6%|███▎                                                | 481/7473 [00:03<00:40, 170.78it/s]  7%|███▍                                                | 499/7473 [00:03<00:40, 171.34it/s]  7%|███▌                                                | 517/7473 [00:03<00:40, 172.01it/s]  7%|███▋                                                | 535/7473 [00:03<00:40, 172.66it/s]  7%|███▊                                                | 553/7473 [00:03<00:40, 172.69it/s]  8%|███▉                                                | 571/7473 [00:04<00:39, 172.79it/s]  8%|████                                                | 589/7473 [00:04<00:39, 172.74it/s]  8%|████▏                                               | 607/7473 [00:04<00:39, 172.47it/s]  8%|████▎                                               | 625/7473 [00:04<00:39, 172.12it/s]  9%|████▍                                               | 643/7473 [00:04<00:39, 172.13it/s]  9%|████▌                                               | 661/7473 [00:04<00:39, 172.11it/s]  9%|████▋                                               | 679/7473 [00:04<00:39, 172.22it/s]  9%|████▊                                               | 697/7473 [00:04<00:39, 172.85it/s] 10%|████▉                                               | 715/7473 [00:04<00:39, 171.28it/s] 10%|█████                                               | 733/7473 [00:05<00:39, 172.06it/s] 10%|█████▏                                              | 751/7473 [00:05<00:39, 172.01it/s] 10%|█████▎                                              | 769/7473 [00:05<00:39, 171.78it/s] 11%|█████▍                                              | 787/7473 [00:05<00:38, 171.72it/s] 11%|█████▌                                              | 805/7473 [00:05<00:38, 171.73it/s] 11%|█████▋                                              | 823/7473 [00:05<00:38, 171.78it/s] 11%|█████▊                                              | 841/7473 [00:05<00:38, 171.52it/s] 11%|█████▉                                              | 859/7473 [00:05<00:38, 171.75it/s] 12%|██████                                              | 877/7473 [00:05<00:38, 171.99it/s] 12%|██████▏                                             | 895/7473 [00:05<00:38, 172.00it/s] 12%|██████▎                                             | 913/7473 [00:06<00:38, 172.01it/s] 12%|██████▍                                             | 931/7473 [00:06<00:38, 170.22it/s] 13%|██████▌                                             | 949/7473 [00:06<00:38, 170.94it/s] 13%|██████▋                                             | 967/7473 [00:06<00:37, 171.24it/s] 13%|██████▊                                             | 985/7473 [00:06<00:37, 171.73it/s] 13%|██████▊                                            | 1003/7473 [00:06<00:37, 171.47it/s] 14%|██████▉                                            | 1021/7473 [00:06<00:37, 171.89it/s] 14%|███████                                            | 1039/7473 [00:06<00:37, 171.78it/s] 14%|███████▏                                           | 1057/7473 [00:06<00:37, 170.44it/s] 14%|███████▎                                           | 1075/7473 [00:07<00:37, 170.81it/s] 15%|███████▍                                           | 1093/7473 [00:07<00:37, 171.11it/s] 15%|███████▌                                           | 1111/7473 [00:07<00:37, 171.11it/s] 15%|███████▋                                           | 1129/7473 [00:07<00:37, 171.05it/s] 15%|███████▊                                           | 1147/7473 [00:07<00:36, 171.37it/s] 16%|███████▉                                           | 1165/7473 [00:07<00:37, 169.95it/s] 16%|████████                                           | 1183/7473 [00:07<00:36, 170.54it/s] 16%|████████▏                                          | 1201/7473 [00:07<00:36, 171.69it/s] 16%|████████▎                                          | 1219/7473 [00:07<00:36, 173.24it/s] 17%|████████▍                                          | 1237/7473 [00:07<00:35, 174.12it/s] 17%|████████▌                                          | 1255/7473 [00:08<00:35, 174.76it/s] 17%|████████▋                                          | 1273/7473 [00:08<00:35, 175.42it/s] 17%|████████▊                                          | 1291/7473 [00:08<00:35, 174.38it/s] 18%|████████▉                                          | 1309/7473 [00:08<00:35, 174.83it/s] 18%|█████████                                          | 1327/7473 [00:08<00:35, 175.59it/s] 18%|█████████▏                                         | 1345/7473 [00:08<00:34, 175.88it/s] 18%|█████████▎                                         | 1363/7473 [00:08<00:34, 176.20it/s] 18%|█████████▍                                         | 1381/7473 [00:08<00:34, 175.94it/s] 19%|█████████▌                                         | 1399/7473 [00:08<00:35, 173.38it/s] 19%|█████████▋                                         | 1417/7473 [00:08<00:34, 174.06it/s] 19%|█████████▊                                         | 1435/7473 [00:09<00:34, 174.73it/s] 19%|█████████▉                                         | 1453/7473 [00:09<00:34, 175.26it/s] 20%|██████████                                         | 1471/7473 [00:09<00:34, 175.85it/s] 20%|██████████▏                                        | 1489/7473 [00:09<00:33, 176.26it/s] 20%|██████████▎                                        | 1507/7473 [00:09<00:33, 176.35it/s] 20%|██████████▍                                        | 1525/7473 [00:09<00:33, 175.78it/s] 21%|██████████▌                                        | 1543/7473 [00:09<00:33, 175.78it/s] 21%|██████████▋                                        | 1561/7473 [00:09<00:33, 175.73it/s] 21%|██████████▊                                        | 1579/7473 [00:09<00:33, 175.32it/s] 21%|██████████▉                                        | 1597/7473 [00:10<00:33, 175.41it/s] 22%|███████████                                        | 1615/7473 [00:10<00:33, 174.27it/s] 22%|███████████▏                                       | 1633/7473 [00:10<00:33, 174.77it/s] 22%|███████████▎                                       | 1651/7473 [00:10<00:33, 175.06it/s] 22%|███████████▍                                       | 1669/7473 [00:10<00:33, 175.73it/s] 23%|███████████▌                                       | 1687/7473 [00:10<00:32, 176.24it/s] 23%|███████████▋                                       | 1705/7473 [00:10<00:32, 175.90it/s] 23%|███████████▊                                       | 1723/7473 [00:10<00:32, 176.10it/s] 23%|███████████▉                                       | 1741/7473 [00:10<00:32, 176.05it/s] 24%|████████████                                       | 1759/7473 [00:10<00:32, 176.49it/s] 24%|████████████▏                                      | 1777/7473 [00:11<00:32, 176.26it/s] 24%|████████████▎                                      | 1795/7473 [00:11<00:32, 176.34it/s] 24%|████████████▎                                      | 1813/7473 [00:11<00:32, 176.28it/s] 25%|████████████▍                                      | 1831/7473 [00:11<00:32, 175.82it/s] 25%|████████████▌                                      | 1849/7473 [00:11<00:32, 174.41it/s] 25%|████████████▋                                      | 1867/7473 [00:11<00:31, 175.23it/s] 25%|████████████▊                                      | 1885/7473 [00:11<00:31, 175.70it/s] 25%|████████████▉                                      | 1903/7473 [00:11<00:31, 175.60it/s] 26%|█████████████                                      | 1921/7473 [00:11<00:31, 175.57it/s] 26%|█████████████▏                                     | 1939/7473 [00:11<00:31, 175.15it/s] 26%|█████████████▎                                     | 1957/7473 [00:12<00:31, 175.63it/s] 26%|█████████████▍                                     | 1975/7473 [00:12<00:31, 175.89it/s] 27%|█████████████▌                                     | 1993/7473 [00:12<00:31, 176.08it/s] 27%|█████████████▋                                     | 2011/7473 [00:12<00:30, 176.21it/s] 27%|█████████████▊                                     | 2029/7473 [00:12<00:30, 176.22it/s] 27%|█████████████▉                                     | 2047/7473 [00:12<00:30, 176.03it/s] 28%|██████████████                                     | 2065/7473 [00:12<00:30, 174.59it/s] 28%|██████████████▏                                    | 2083/7473 [00:12<00:30, 174.95it/s] 28%|██████████████▎                                    | 2101/7473 [00:12<00:30, 175.56it/s] 28%|██████████████▍                                    | 2119/7473 [00:12<00:30, 174.98it/s] 29%|██████████████▌                                    | 2137/7473 [00:13<00:30, 175.12it/s] 29%|██████████████▋                                    | 2155/7473 [00:13<00:30, 175.51it/s] 29%|██████████████▊                                    | 2173/7473 [00:13<00:30, 175.91it/s] 29%|██████████████▉                                    | 2191/7473 [00:13<00:30, 175.68it/s] 30%|███████████████                                    | 2209/7473 [00:13<00:29, 176.20it/s] 30%|███████████████▏                                   | 2227/7473 [00:13<00:29, 176.33it/s] 30%|███████████████▎                                   | 2245/7473 [00:13<00:29, 176.10it/s] 30%|███████████████▍                                   | 2263/7473 [00:13<00:29, 176.11it/s] 31%|███████████████▌                                   | 2281/7473 [00:13<00:29, 176.02it/s] 31%|███████████████▋                                   | 2299/7473 [00:14<00:29, 174.61it/s] 31%|███████████████▊                                   | 2317/7473 [00:14<00:29, 175.31it/s] 31%|███████████████▉                                   | 2335/7473 [00:14<00:29, 175.36it/s] 31%|████████████████                                   | 2353/7473 [00:14<00:29, 175.22it/s] 32%|████████████████▏                                  | 2371/7473 [00:14<00:29, 175.33it/s] 32%|████████████████▎                                  | 2389/7473 [00:14<00:28, 175.78it/s] 32%|████████████████▍                                  | 2407/7473 [00:14<00:28, 175.86it/s] 32%|████████████████▌                                  | 2425/7473 [00:14<00:28, 176.17it/s] 33%|████████████████▋                                  | 2443/7473 [00:14<00:28, 176.35it/s] 33%|████████████████▊                                  | 2461/7473 [00:14<00:28, 176.16it/s] 33%|████████████████▉                                  | 2479/7473 [00:15<00:28, 176.14it/s] 33%|█████████████████                                  | 2497/7473 [00:15<00:28, 176.07it/s] 34%|█████████████████▏                                 | 2515/7473 [00:15<00:28, 176.20it/s] 34%|█████████████████▎                                 | 2533/7473 [00:15<00:32, 152.26it/s] 34%|█████████████████▍                                 | 2551/7473 [00:15<00:31, 158.44it/s] 34%|█████████████████▌                                 | 2569/7473 [00:15<00:29, 163.51it/s] 35%|█████████████████▋                                 | 2587/7473 [00:15<00:29, 167.23it/s] 35%|█████████████████▊                                 | 2605/7473 [00:15<00:28, 170.22it/s] 35%|█████████████████▉                                 | 2623/7473 [00:15<00:28, 172.14it/s] 35%|██████████████████                                 | 2641/7473 [00:15<00:27, 173.34it/s] 36%|██████████████████▏                                | 2659/7473 [00:16<00:27, 174.24it/s] 36%|██████████████████▎                                | 2677/7473 [00:16<00:27, 174.82it/s] 36%|██████████████████▍                                | 2695/7473 [00:16<00:27, 174.99it/s] 36%|██████████████████▌                                | 2713/7473 [00:16<00:27, 175.57it/s] 37%|██████████████████▋                                | 2731/7473 [00:16<00:27, 175.58it/s] 37%|██████████████████▊                                | 2749/7473 [00:16<00:27, 174.10it/s] 37%|██████████████████▉                                | 2767/7473 [00:16<00:27, 174.24it/s] 37%|███████████████████                                | 2785/7473 [00:16<00:26, 175.13it/s] 38%|███████████████████▏                               | 2803/7473 [00:16<00:26, 175.56it/s] 38%|███████████████████▎                               | 2821/7473 [00:17<00:26, 175.73it/s] 38%|███████████████████▎                               | 2839/7473 [00:17<00:26, 176.25it/s] 38%|███████████████████▍                               | 2857/7473 [00:17<00:26, 175.89it/s] 38%|███████████████████▌                               | 2875/7473 [00:17<00:26, 175.58it/s] 39%|███████████████████▋                               | 2893/7473 [00:17<00:26, 175.74it/s] 39%|███████████████████▊                               | 2911/7473 [00:17<00:25, 175.91it/s] 39%|███████████████████▉                               | 2929/7473 [00:17<00:25, 176.15it/s] 39%|████████████████████                               | 2947/7473 [00:17<00:25, 176.31it/s] 40%|████████████████████▏                              | 2965/7473 [00:17<00:25, 176.13it/s] 40%|████████████████████▎                              | 2983/7473 [00:17<00:25, 174.21it/s] 40%|████████████████████▍                              | 3001/7473 [00:18<00:25, 173.44it/s] 40%|████████████████████▌                              | 3019/7473 [00:18<00:25, 173.99it/s] 41%|████████████████████▋                              | 3037/7473 [00:18<00:25, 174.31it/s] 41%|████████████████████▊                              | 3055/7473 [00:18<00:25, 174.82it/s] 41%|████████████████████▉                              | 3073/7473 [00:18<00:25, 174.78it/s] 41%|█████████████████████                              | 3091/7473 [00:18<00:25, 174.88it/s] 42%|█████████████████████▏                             | 3109/7473 [00:18<00:24, 174.90it/s] 42%|█████████████████████▎                             | 3127/7473 [00:18<00:24, 174.68it/s] 42%|█████████████████████▍                             | 3145/7473 [00:18<00:24, 174.59it/s] 42%|█████████████████████▌                             | 3163/7473 [00:18<00:24, 174.87it/s] 43%|█████████████████████▋                             | 3181/7473 [00:19<00:24, 174.71it/s] 43%|█████████████████████▊                             | 3199/7473 [00:19<00:24, 174.87it/s] 43%|█████████████████████▉                             | 3217/7473 [00:19<00:24, 173.46it/s] 43%|██████████████████████                             | 3235/7473 [00:19<00:24, 174.09it/s] 44%|██████████████████████▏                            | 3253/7473 [00:19<00:24, 174.72it/s] 44%|██████████████████████▎                            | 3271/7473 [00:19<00:24, 174.79it/s] 44%|██████████████████████▍                            | 3289/7473 [00:19<00:24, 173.95it/s] 44%|██████████████████████▌                            | 3307/7473 [00:19<00:23, 174.34it/s] 44%|██████████████████████▋                            | 3325/7473 [00:19<00:23, 174.32it/s] 45%|██████████████████████▊                            | 3343/7473 [00:20<00:23, 174.37it/s] 45%|██████████████████████▉                            | 3361/7473 [00:20<00:23, 174.55it/s] 45%|███████████████████████                            | 3379/7473 [00:20<00:23, 174.52it/s] 45%|███████████████████████▏                           | 3397/7473 [00:20<00:23, 174.77it/s] 46%|███████████████████████▎                           | 3415/7473 [00:20<00:23, 174.82it/s] 46%|███████████████████████▍                           | 3433/7473 [00:20<00:23, 173.39it/s] 46%|███████████████████████▌                           | 3451/7473 [00:20<00:23, 173.82it/s] 46%|███████████████████████▋                           | 3469/7473 [00:20<00:23, 173.87it/s] 47%|███████████████████████▊                           | 3487/7473 [00:20<00:22, 174.37it/s] 47%|███████████████████████▉                           | 3505/7473 [00:20<00:22, 174.79it/s] 47%|████████████████████████                           | 3523/7473 [00:21<00:22, 174.81it/s] 47%|████████████████████████▏                          | 3541/7473 [00:21<00:22, 175.08it/s] 48%|████████████████████████▎                          | 3559/7473 [00:21<00:22, 175.15it/s] 48%|████████████████████████▍                          | 3577/7473 [00:21<00:22, 175.14it/s] 48%|████████████████████████▌                          | 3595/7473 [00:21<00:22, 174.18it/s] 48%|████████████████████████▋                          | 3613/7473 [00:21<00:22, 174.39it/s] 49%|████████████████████████▊                          | 3631/7473 [00:21<00:22, 174.62it/s] 49%|████████████████████████▉                          | 3649/7473 [00:21<00:21, 174.27it/s] 49%|█████████████████████████                          | 3667/7473 [00:21<00:21, 173.06it/s] 49%|█████████████████████████▏                         | 3685/7473 [00:21<00:21, 173.35it/s] 50%|█████████████████████████▎                         | 3703/7473 [00:22<00:21, 173.79it/s] 50%|█████████████████████████▍                         | 3721/7473 [00:22<00:21, 173.86it/s] 50%|█████████████████████████▌                         | 3739/7473 [00:22<00:21, 174.24it/s] 50%|█████████████████████████▋                         | 3757/7473 [00:22<00:21, 174.45it/s] 51%|█████████████████████████▊                         | 3775/7473 [00:22<00:21, 174.45it/s] 51%|█████████████████████████▉                         | 3793/7473 [00:22<00:21, 174.60it/s] 51%|██████████████████████████                         | 3811/7473 [00:22<00:20, 175.09it/s] 51%|██████████████████████████▏                        | 3829/7473 [00:22<00:20, 174.86it/s] 51%|██████████████████████████▎                        | 3847/7473 [00:22<00:20, 174.86it/s] 52%|██████████████████████████▍                        | 3865/7473 [00:22<00:20, 174.92it/s] 52%|██████████████████████████▍                        | 3883/7473 [00:23<00:21, 170.27it/s] 52%|██████████████████████████▌                        | 3901/7473 [00:23<00:20, 171.89it/s] 52%|██████████████████████████▋                        | 3919/7473 [00:23<00:20, 172.81it/s] 53%|██████████████████████████▊                        | 3937/7473 [00:23<00:20, 173.56it/s] 53%|██████████████████████████▉                        | 3955/7473 [00:23<00:20, 174.04it/s] 53%|███████████████████████████                        | 3973/7473 [00:23<00:20, 174.28it/s] 53%|███████████████████████████▏                       | 3991/7473 [00:23<00:19, 174.47it/s] 54%|███████████████████████████▎                       | 4009/7473 [00:23<00:19, 174.75it/s] 54%|███████████████████████████▍                       | 4027/7473 [00:23<00:19, 174.97it/s] 54%|███████████████████████████▌                       | 4045/7473 [00:24<00:19, 175.02it/s] 54%|███████████████████████████▋                       | 4063/7473 [00:24<00:19, 175.05it/s] 55%|███████████████████████████▊                       | 4081/7473 [00:24<00:19, 174.88it/s] 55%|███████████████████████████▉                       | 4099/7473 [00:24<00:19, 174.89it/s] 55%|████████████████████████████                       | 4117/7473 [00:24<00:19, 173.12it/s] 55%|████████████████████████████▏                      | 4135/7473 [00:24<00:19, 173.26it/s] 56%|████████████████████████████▎                      | 4153/7473 [00:24<00:19, 173.61it/s] 56%|████████████████████████████▍                      | 4171/7473 [00:24<00:18, 174.13it/s] 56%|████████████████████████████▌                      | 4189/7473 [00:24<00:19, 172.44it/s] 56%|████████████████████████████▋                      | 4207/7473 [00:24<00:18, 173.16it/s] 57%|████████████████████████████▊                      | 4225/7473 [00:25<00:18, 173.96it/s] 57%|████████████████████████████▉                      | 4243/7473 [00:25<00:18, 174.28it/s] 57%|█████████████████████████████                      | 4261/7473 [00:25<00:18, 174.52it/s] 57%|█████████████████████████████▏                     | 4279/7473 [00:25<00:18, 174.35it/s] 58%|█████████████████████████████▎                     | 4297/7473 [00:25<00:18, 174.41it/s] 58%|█████████████████████████████▍                     | 4315/7473 [00:25<00:18, 174.64it/s] 58%|█████████████████████████████▌                     | 4333/7473 [00:25<00:17, 174.98it/s] 58%|█████████████████████████████▋                     | 4351/7473 [00:25<00:17, 173.67it/s] 58%|█████████████████████████████▊                     | 4369/7473 [00:25<00:17, 174.03it/s] 59%|█████████████████████████████▉                     | 4387/7473 [00:26<00:17, 174.08it/s] 59%|██████████████████████████████                     | 4405/7473 [00:26<00:17, 174.41it/s] 59%|██████████████████████████████▏                    | 4423/7473 [00:26<00:17, 174.46it/s] 59%|██████████████████████████████▎                    | 4441/7473 [00:26<00:17, 174.62it/s] 60%|██████████████████████████████▍                    | 4459/7473 [00:26<00:17, 174.62it/s] 60%|██████████████████████████████▌                    | 4477/7473 [00:26<00:17, 175.00it/s] 60%|██████████████████████████████▋                    | 4495/7473 [00:26<00:17, 174.83it/s] 60%|██████████████████████████████▊                    | 4513/7473 [00:26<00:16, 174.72it/s] 61%|██████████████████████████████▉                    | 4531/7473 [00:26<00:16, 174.78it/s] 61%|███████████████████████████████                    | 4549/7473 [00:26<00:16, 175.18it/s] 61%|███████████████████████████████▏                   | 4567/7473 [00:27<00:16, 174.06it/s] 61%|███████████████████████████████▎                   | 4585/7473 [00:27<00:16, 173.74it/s] 62%|███████████████████████████████▍                   | 4603/7473 [00:27<00:16, 174.19it/s] 62%|███████████████████████████████▌                   | 4621/7473 [00:27<00:16, 174.53it/s] 62%|███████████████████████████████▋                   | 4639/7473 [00:27<00:16, 174.46it/s] 62%|███████████████████████████████▊                   | 4657/7473 [00:27<00:16, 174.70it/s] 63%|███████████████████████████████▉                   | 4675/7473 [00:27<00:16, 174.63it/s] 63%|████████████████████████████████                   | 4693/7473 [00:27<00:15, 174.85it/s] 63%|████████████████████████████████▏                  | 4711/7473 [00:27<00:15, 174.97it/s] 63%|████████████████████████████████▎                  | 4729/7473 [00:27<00:15, 175.24it/s] 64%|████████████████████████████████▍                  | 4747/7473 [00:28<00:15, 175.27it/s] 64%|████████████████████████████████▌                  | 4765/7473 [00:28<00:15, 175.46it/s] 64%|████████████████████████████████▋                  | 4783/7473 [00:28<00:15, 175.36it/s] 64%|████████████████████████████████▊                  | 4801/7473 [00:28<00:15, 173.49it/s] 64%|████████████████████████████████▉                  | 4819/7473 [00:28<00:15, 174.16it/s] 65%|█████████████████████████████████                  | 4837/7473 [00:28<00:15, 173.91it/s] 65%|█████████████████████████████████▏                 | 4855/7473 [00:28<00:15, 174.10it/s] 65%|█████████████████████████████████▎                 | 4873/7473 [00:28<00:14, 174.16it/s] 65%|█████████████████████████████████▍                 | 4891/7473 [00:28<00:14, 174.58it/s] 66%|█████████████████████████████████▌                 | 4909/7473 [00:28<00:14, 174.92it/s] 66%|█████████████████████████████████▌                 | 4927/7473 [00:29<00:14, 174.85it/s] 66%|█████████████████████████████████▋                 | 4945/7473 [00:29<00:14, 174.95it/s] 66%|█████████████████████████████████▊                 | 4963/7473 [00:29<00:14, 175.09it/s] 67%|█████████████████████████████████▉                 | 4981/7473 [00:29<00:14, 174.96it/s] 67%|██████████████████████████████████                 | 4999/7473 [00:29<00:14, 174.82it/s] 67%|██████████████████████████████████▏                | 5017/7473 [00:29<00:14, 173.67it/s] 67%|██████████████████████████████████▎                | 5035/7473 [00:29<00:14, 174.05it/s] 68%|██████████████████████████████████▍                | 5053/7473 [00:29<00:13, 174.41it/s] 68%|██████████████████████████████████▌                | 5071/7473 [00:29<00:13, 174.52it/s] 68%|██████████████████████████████████▋                | 5089/7473 [00:30<00:13, 174.72it/s] 68%|██████████████████████████████████▊                | 5107/7473 [00:30<00:13, 174.92it/s] 69%|██████████████████████████████████▉                | 5125/7473 [00:30<00:13, 175.01it/s] 69%|███████████████████████████████████                | 5143/7473 [00:30<00:13, 175.19it/s] 69%|███████████████████████████████████▏               | 5161/7473 [00:30<00:13, 175.63it/s] 69%|███████████████████████████████████▎               | 5179/7473 [00:30<00:13, 175.77it/s] 70%|███████████████████████████████████▍               | 5197/7473 [00:30<00:12, 175.30it/s] 70%|███████████████████████████████████▌               | 5215/7473 [00:30<00:12, 175.43it/s] 70%|███████████████████████████████████▋               | 5233/7473 [00:30<00:12, 175.62it/s] 70%|███████████████████████████████████▊               | 5251/7473 [00:30<00:14, 151.59it/s] 71%|███████████████████████████████████▉               | 5269/7473 [00:31<00:13, 157.92it/s] 71%|████████████████████████████████████               | 5287/7473 [00:31<00:13, 162.84it/s] 71%|████████████████████████████████████▏              | 5305/7473 [00:31<00:13, 166.42it/s] 71%|████████████████████████████████████▎              | 5323/7473 [00:31<00:12, 168.97it/s] 71%|████████████████████████████████████▍              | 5341/7473 [00:31<00:12, 170.79it/s] 72%|████████████████████████████████████▌              | 5359/7473 [00:31<00:12, 172.10it/s] 72%|████████████████████████████████████▋              | 5377/7473 [00:31<00:12, 172.91it/s] 72%|████████████████████████████████████▊              | 5395/7473 [00:31<00:11, 173.79it/s] 72%|████████████████████████████████████▉              | 5413/7473 [00:31<00:11, 174.34it/s] 73%|█████████████████████████████████████              | 5431/7473 [00:32<00:11, 174.70it/s] 73%|█████████████████████████████████████▏             | 5449/7473 [00:32<00:11, 174.83it/s] 73%|█████████████████████████████████████▎             | 5467/7473 [00:32<00:11, 174.62it/s] 73%|█████████████████████████████████████▍             | 5485/7473 [00:32<00:17, 110.84it/s] 74%|█████████████████████████████████████▌             | 5503/7473 [00:32<00:15, 124.42it/s] 74%|█████████████████████████████████████▋             | 5521/7473 [00:32<00:14, 136.52it/s] 74%|█████████████████████████████████████▊             | 5539/7473 [00:32<00:13, 146.09it/s] 74%|█████████████████████████████████████▉             | 5557/7473 [00:32<00:12, 153.99it/s] 75%|██████████████████████████████████████             | 5575/7473 [00:33<00:11, 159.72it/s] 75%|██████████████████████████████████████▏            | 5593/7473 [00:33<00:11, 164.12it/s] 75%|██████████████████████████████████████▎            | 5611/7473 [00:33<00:11, 167.29it/s] 75%|██████████████████████████████████████▍            | 5629/7473 [00:33<00:10, 169.50it/s] 76%|██████████████████████████████████████▌            | 5647/7473 [00:33<00:10, 171.30it/s] 76%|██████████████████████████████████████▋            | 5665/7473 [00:33<00:10, 172.64it/s] 76%|██████████████████████████████████████▊            | 5683/7473 [00:33<00:10, 172.00it/s] 76%|██████████████████████████████████████▉            | 5701/7473 [00:33<00:10, 173.04it/s] 77%|███████████████████████████████████████            | 5719/7473 [00:33<00:10, 173.64it/s] 77%|███████████████████████████████████████▏           | 5737/7473 [00:33<00:09, 174.12it/s] 77%|███████████████████████████████████████▎           | 5755/7473 [00:34<00:09, 174.44it/s] 77%|███████████████████████████████████████▍           | 5773/7473 [00:34<00:09, 175.13it/s] 77%|███████████████████████████████████████▌           | 5791/7473 [00:34<00:09, 174.97it/s] 78%|███████████████████████████████████████▋           | 5809/7473 [00:34<00:09, 174.97it/s] 78%|███████████████████████████████████████▊           | 5827/7473 [00:34<00:09, 175.17it/s] 78%|███████████████████████████████████████▉           | 5845/7473 [00:34<00:09, 175.10it/s] 78%|████████████████████████████████████████           | 5863/7473 [00:34<00:09, 174.71it/s] 79%|████████████████████████████████████████▏          | 5881/7473 [00:34<00:09, 174.99it/s] 79%|████████████████████████████████████████▎          | 5899/7473 [00:34<00:09, 174.84it/s] 79%|████████████████████████████████████████▍          | 5917/7473 [00:35<00:09, 168.32it/s] 79%|████████████████████████████████████████▌          | 5935/7473 [00:35<00:09, 170.03it/s] 80%|████████████████████████████████████████▋          | 5953/7473 [00:35<00:08, 171.09it/s] 80%|████████████████████████████████████████▋          | 5971/7473 [00:35<00:08, 172.05it/s] 80%|████████████████████████████████████████▊          | 5989/7473 [00:35<00:08, 173.17it/s] 80%|████████████████████████████████████████▉          | 6007/7473 [00:35<00:08, 173.83it/s] 81%|█████████████████████████████████████████          | 6025/7473 [00:35<00:08, 173.97it/s] 81%|█████████████████████████████████████████▏         | 6043/7473 [00:35<00:08, 174.45it/s] 81%|█████████████████████████████████████████▎         | 6061/7473 [00:35<00:08, 175.08it/s] 81%|█████████████████████████████████████████▍         | 6079/7473 [00:35<00:07, 175.20it/s] 82%|█████████████████████████████████████████▌         | 6097/7473 [00:36<00:07, 175.50it/s] 82%|█████████████████████████████████████████▋         | 6115/7473 [00:36<00:07, 175.61it/s] 82%|█████████████████████████████████████████▊         | 6133/7473 [00:36<00:07, 173.75it/s] 82%|█████████████████████████████████████████▉         | 6151/7473 [00:36<00:07, 174.30it/s] 83%|██████████████████████████████████████████         | 6169/7473 [00:36<00:07, 174.69it/s] 83%|██████████████████████████████████████████▏        | 6187/7473 [00:36<00:07, 174.90it/s] 83%|██████████████████████████████████████████▎        | 6205/7473 [00:36<00:07, 175.05it/s] 83%|██████████████████████████████████████████▍        | 6223/7473 [00:36<00:07, 174.88it/s] 84%|██████████████████████████████████████████▌        | 6241/7473 [00:36<00:07, 174.61it/s] 84%|██████████████████████████████████████████▋        | 6259/7473 [00:36<00:06, 174.65it/s] 84%|██████████████████████████████████████████▊        | 6277/7473 [00:37<00:06, 175.25it/s] 84%|██████████████████████████████████████████▉        | 6295/7473 [00:37<00:06, 174.90it/s] 84%|███████████████████████████████████████████        | 6313/7473 [00:37<00:06, 175.34it/s] 85%|███████████████████████████████████████████▏       | 6331/7473 [00:37<00:06, 175.71it/s] 85%|███████████████████████████████████████████▎       | 6349/7473 [00:37<00:06, 175.50it/s] 85%|███████████████████████████████████████████▍       | 6367/7473 [00:37<00:06, 173.82it/s] 85%|███████████████████████████████████████████▌       | 6385/7473 [00:37<00:06, 173.98it/s] 86%|███████████████████████████████████████████▋       | 6403/7473 [00:37<00:06, 174.40it/s] 86%|███████████████████████████████████████████▊       | 6421/7473 [00:37<00:06, 174.35it/s] 86%|███████████████████████████████████████████▉       | 6439/7473 [00:37<00:05, 174.68it/s] 86%|████████████████████████████████████████████       | 6457/7473 [00:38<00:05, 174.73it/s] 87%|████████████████████████████████████████████▏      | 6475/7473 [00:38<00:05, 174.98it/s] 87%|████████████████████████████████████████████▎      | 6493/7473 [00:38<00:05, 174.92it/s] 87%|████████████████████████████████████████████▍      | 6511/7473 [00:38<00:05, 174.94it/s] 87%|████████████████████████████████████████████▌      | 6529/7473 [00:38<00:05, 175.14it/s] 88%|████████████████████████████████████████████▋      | 6547/7473 [00:38<00:05, 175.16it/s] 88%|████████████████████████████████████████████▊      | 6565/7473 [00:38<00:05, 175.09it/s] 88%|████████████████████████████████████████████▉      | 6583/7473 [00:38<00:05, 173.47it/s] 88%|█████████████████████████████████████████████      | 6601/7473 [00:38<00:05, 174.26it/s] 89%|█████████████████████████████████████████████▏     | 6619/7473 [00:39<00:04, 174.42it/s] 89%|█████████████████████████████████████████████▎     | 6637/7473 [00:39<00:04, 174.26it/s] 89%|█████████████████████████████████████████████▍     | 6655/7473 [00:39<00:04, 174.49it/s] 89%|█████████████████████████████████████████████▌     | 6673/7473 [00:39<00:04, 174.43it/s] 90%|█████████████████████████████████████████████▋     | 6691/7473 [00:39<00:04, 174.69it/s] 90%|█████████████████████████████████████████████▊     | 6709/7473 [00:39<00:04, 174.95it/s] 90%|█████████████████████████████████████████████▉     | 6727/7473 [00:39<00:04, 175.09it/s] 90%|██████████████████████████████████████████████     | 6745/7473 [00:39<00:04, 175.14it/s] 90%|██████████████████████████████████████████████▏    | 6763/7473 [00:39<00:04, 174.80it/s] 91%|██████████████████████████████████████████████▎    | 6781/7473 [00:39<00:03, 174.89it/s] 91%|██████████████████████████████████████████████▍    | 6799/7473 [00:40<00:03, 174.81it/s] 91%|██████████████████████████████████████████████▌    | 6817/7473 [00:40<00:03, 173.26it/s] 91%|██████████████████████████████████████████████▋    | 6835/7473 [00:40<00:03, 173.85it/s] 92%|██████████████████████████████████████████████▊    | 6853/7473 [00:40<00:03, 174.25it/s] 92%|██████████████████████████████████████████████▉    | 6871/7473 [00:40<00:03, 174.34it/s] 92%|███████████████████████████████████████████████    | 6889/7473 [00:40<00:03, 174.59it/s] 92%|███████████████████████████████████████████████▏   | 6907/7473 [00:40<00:03, 175.09it/s] 93%|███████████████████████████████████████████████▎   | 6925/7473 [00:40<00:03, 174.72it/s] 93%|███████████████████████████████████████████████▍   | 6943/7473 [00:40<00:03, 175.08it/s] 93%|███████████████████████████████████████████████▌   | 6961/7473 [00:40<00:02, 174.95it/s] 93%|███████████████████████████████████████████████▋   | 6979/7473 [00:41<00:02, 175.02it/s] 94%|███████████████████████████████████████████████▊   | 6997/7473 [00:41<00:02, 174.82it/s] 94%|███████████████████████████████████████████████▊   | 7015/7473 [00:41<00:02, 174.70it/s] 94%|███████████████████████████████████████████████▉   | 7033/7473 [00:41<00:02, 174.74it/s] 94%|████████████████████████████████████████████████   | 7051/7473 [00:41<00:02, 173.11it/s] 95%|████████████████████████████████████████████████▏  | 7069/7473 [00:41<00:02, 173.63it/s] 95%|████████████████████████████████████████████████▎  | 7087/7473 [00:41<00:02, 173.99it/s] 95%|████████████████████████████████████████████████▍  | 7105/7473 [00:41<00:02, 174.33it/s] 95%|████████████████████████████████████████████████▌  | 7123/7473 [00:41<00:02, 174.25it/s] 96%|████████████████████████████████████████████████▋  | 7141/7473 [00:42<00:01, 174.08it/s] 96%|████████████████████████████████████████████████▊  | 7159/7473 [00:42<00:01, 174.27it/s] 96%|████████████████████████████████████████████████▉  | 7177/7473 [00:42<00:01, 174.38it/s] 96%|█████████████████████████████████████████████████  | 7195/7473 [00:42<00:01, 174.69it/s] 97%|█████████████████████████████████████████████████▏ | 7213/7473 [00:42<00:01, 174.81it/s] 97%|█████████████████████████████████████████████████▎ | 7231/7473 [00:42<00:01, 174.99it/s] 97%|█████████████████████████████████████████████████▍ | 7249/7473 [00:42<00:01, 174.91it/s] 97%|█████████████████████████████████████████████████▌ | 7267/7473 [00:42<00:01, 173.32it/s] 97%|█████████████████████████████████████████████████▋ | 7285/7473 [00:42<00:01, 172.95it/s] 98%|█████████████████████████████████████████████████▊ | 7303/7473 [00:42<00:00, 173.67it/s] 98%|█████████████████████████████████████████████████▉ | 7321/7473 [00:43<00:00, 174.22it/s] 98%|██████████████████████████████████████████████████ | 7339/7473 [00:43<00:00, 174.08it/s] 98%|██████████████████████████████████████████████████▏| 7357/7473 [00:43<00:00, 174.09it/s] 99%|██████████████████████████████████████████████████▎| 7375/7473 [00:43<00:00, 173.94it/s] 99%|██████████████████████████████████████████████████▍| 7393/7473 [00:43<00:00, 174.51it/s] 99%|██████████████████████████████████████████████████▌| 7411/7473 [00:43<00:00, 174.63it/s] 99%|██████████████████████████████████████████████████▋| 7429/7473 [00:43<00:00, 175.03it/s]100%|██████████████████████████████████████████████████▊| 7447/7473 [00:43<00:00, 174.72it/s]100%|██████████████████████████████████████████████████▉| 7465/7473 [00:43<00:00, 174.57it/s]100%|███████████████████████████████████████████████████| 7473/7473 [00:43<00:00, 170.12it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.26s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.13s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.38s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.49s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.05s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.02s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.28s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.36s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.45s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.63s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.44s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.61s/it]
[2023-08-12 18:04:55,201] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.65s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.83s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.73s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.92s/it]
[2023-08-12 18:05:06,181] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 18:05:06,182] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 18:05:06,182] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 18:05:06,182] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 18:05:06,182] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 18:05:06,182] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f214c707fa0>
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 18:05:06,183] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f214c727700>
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 18:05:06,184] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 18:05:06,184] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.6731688976287842 seconds
Loading extension module utils...
Time to load utils op: 0.7050418853759766 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Loading extension module utils...
Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]Time to load utils op: 0.6054830551147461 seconds
############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Rationales: 1. The question asks where you would find plumbing that would not be useful if you were thirsty.
2. The key here is to understand the connection between "plumbing" and "thirsty".
3. You would typically use plumbing to access water, particularly clean drinkable water when you're thirsty.
4. Therefore, we can assume that we're looking for a choice where the plumbing does not supply water, or at least not drinkable water.
5. Looking at the choices, "oil refineries", "wall", "show", "own home", and "water fountain", we need to determine which of these would not supply drinkable water from their plumbing. 
6. Walls and shows wouldn't have plumbing itself, but your own home and a water fountain would typically have plumbing that supplies drinkable water.
7. An oil refinery, however, is a place where the plumbing system is used to transport oil, not water.
8. Therefore, you can't drink anything from the plumbing of an oil refinery, hence it would not be of use if you were thirsty.
9. Thus, the answer is A: oil refineries.
Answer: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Rationales: Intermediate Reasoning Steps:

1. The question asks about the activity that a person is not engaging in yet when they are beginning work.
2. It cannot be A: working. Since the person is beginning work, they are actually performing this activity.
3. It cannot be B: resting. Resting indicates a period of inactivity or relaxation, which is different from beginning work.
4. It cannot be C: tiredness. This is an emotional state, not an action. Besides, someone can feel tired either before starting work, during work or after work. So, this does not relate directly to the action of starting work.
5. It cannot be E: momentum. Momentum generally refers to the force or speed of movement. Although starting work can involve gaining momentum, the term does not directly refer to an action that a person could be engaging in or not.
6. Therefore, the only option left is D: accomplishing. When a person is beginning work, they have not accomplished anything related to that work yet. They are only embarking on the task at hand but they have not yet achieved any results. Thus, they aren't accomplishing anything yet at the very moment they begin to work.
Answer: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Rationales: 1. First, the question asks about a pen with a company logo.
2. This usually indicates a pen that is customized with some business branding.
3. While you may find pens in a few of the given choices like a school or backpack, the pens are typically not company-branded.
4. The most common place to find company-branded pens is in an office setting, as companies often provide custom pens for their employees or for promotional purposes.
5. Therefore, the answer should be the option that corresponds with an office setting, which in these choices, is option A: office.
Answer: A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Rationales: 1. The question talks about Billy calling out to John. 
2. Calling out to someone typically indicates a desire to communicate, or the initiation of a conversation.
3. For communication to work, it usually requires some kind of reaction or response from the other party.
4. So Billy, having initiated the conversation, would be waiting for a reaction or a reply from John.
5. Thus, the correct option is that Billy listened for a response (option B).
Answer: B: response

Input: The lizard frightened the hiker, it's movements made what rustle? Choices:  A: garden B: trees C: books D: rocks E: bushes
Rationales: 1. The question is asking what the lizard's movements made rustle. 
2. 'Rustle' refers to a soft, muffled crackling sound like that made by the movement of dry leaves or paper. 
3. Now, among the given options, we need to choose a noun that is more likely to produce a rustling sound when disturbed by a lizard. 
4. A lizard in a garden can't 'rustle' the entire garden, as there are open spaces and not all parts of a garden would make a rustle noise. So we eliminate option A. 
5. Moving to option B, trees, it's unlikely. Lizards are not typically large or strong enough to rustle trees. Hence, we can eliminate option B.
6. Lizards don't interact with books, so, option C can be eliminated.
7. Rocks can't 'rustle', hence we can eliminate option D.
8. Among the remaining options, bushes are likely to make a rustling sound when a lizard scurries through them. This makes sense since most lizards live in or around bushes in the wild.
9. Therefore, E: bushes is the most appropriate answer.
Answer: E: bushes

Input: The man spent big money and time maintaining his lawn, it was part of keeping up with the Joneses where? Choices:  A: front yard B: suburbia C: neighborhood D: back yard E: golf course
Rationales: 1. The question is asking where the man is keeping up with the Joneses by spending big money and time maintaining his lawn.
2. The phrase "keeping up with the Joneses" typically refers to trying to match or surpass the lifestyle or perceived wealth of neighbors or peers, suggesting that the man is doing this in a residential setting. 
3. The given options are: front yard, suburbia, neighborhood, back yard, and golf course.
4. The options front yard and back yard refer to specific portions of a piece of property and not a broader residential setting.
5. The option golf course could suggest a scenario where a man is maintaining his lawn to match a golf course standard, but this does not match the idea of personally keeping up with neighbors or peers.
6. The options suburbia and neighborhood both suggest a residential setting where the phenomenon of "keeping up with the joneses" commonly occurs. 
7. Yet, the term suburbia not only refers to a residential area, but also carries a cultural connotation of a place where people strive to maintain a certain image of wealth or status, which aligns better with the phrase "keeping up with the Joneses".
8. Therefore, the answer is B: suburbia.
Answer: B: suburbia

Input: What would a human do if they want to get to a store that he or she can see? Choices:  A: cross road B: see around C: drink coffee D: dream dreams E: think critically
Rationales: 1. The question asks what a human would need to do to reach a store they can see.
2. This implies there is some physical distance between the human and the store.
3. Therefore, they would need to perform some action that helps them cover that distance.
4. Looking at the available choices, "drinking coffee," "dreaming dreams," and "thinking critically" do not directly contribute to physical movement.
5. "Seeing around" would be beneficial in observing the environment but it doesn't ensure movement towards the store.
6. Therefore, the only option that involves some form of movement and could physically bring a person closer to the store is "cross the road".
7. So, the answer to the question is A: cross road.
Answer: A: cross road

Input: Where would you grab an object contained by a doorway? Choices:  A: television B: control panel C: opening doors D: doorknob E: doorway
Rationales: 1. To start solving this, we need to understand the question. It's asking where we would grab an object that is contained by a doorway.
2. We can first eliminate option A: television, as it is an
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o8-tcommonsenseqa-s1-rTrue
Loading extension module utils...
Time to load utils op: 0.7050132751464844 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:42<34:35, 42.36s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:23<33:28, 41.85s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:05<32:37, 41.65s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [02:46<31:52, 41.58s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [03:28<31:07, 41.50s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [04:09<30:26, 41.50s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [04:51<29:43, 41.47s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [05:32<29:03, 41.51s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [06:14<28:22, 41.52s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [06:55<27:39, 41.49s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [07:37<26:58, 41.50s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [08:18<26:16, 41.49s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [09:00<25:35, 41.50s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [09:41<24:54, 41.51s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [10:22<24:10, 41.44s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [11:04<23:29, 41.46s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [11:45<22:47, 41.44s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [12:27<22:06, 41.46s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [13:08<21:24, 41.44s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [13:50<20:42, 41.42s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [14:31<20:01, 41.43s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [15:13<19:21, 41.47s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [15:54<18:40, 41.48s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [16:35<17:57, 41.43s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [17:17<17:15, 41.41s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [17:59<16:36, 41.52s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [18:41<15:57, 41.65s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [19:22<15:14, 41.55s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [20:03<14:30, 41.47s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [20:44<13:47, 41.38s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [21:26<13:06, 41.40s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [22:07<12:24, 41.36s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [22:48<11:43, 41.40s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [23:30<11:02, 41.40s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [24:11<10:20, 41.35s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [24:52<09:38, 41.35s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [25:34<08:57, 41.35s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [26:15<08:15, 41.33s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [26:57<07:35, 41.38s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [27:38<06:53, 41.35s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [28:19<06:11, 41.32s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [29:01<05:30, 41.35s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [29:42<04:49, 41.33s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [30:23<04:08, 41.36s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [31:05<03:26, 41.39s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [31:46<02:45, 41.36s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [32:27<02:04, 41.38s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [33:09<01:22, 41.39s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [33:50<00:41, 41.36s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [34:31<00:00, 41.35s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [34:31<00:00, 41.44s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.108} | lm_loss 12.6521 | avg. gen lenth: 474.912
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o9-tcommonsenseqa-s1-rTrue --seed 1 --rationales --num-out-domain 9
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-12 18:39:48,341] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o9-tcommonsenseqa-s1-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 9
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o9-tcommonsenseqa-s1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  0%|                                                       | 9/7473 [00:00<01:30, 82.52it/s]  0%|▏                                                     | 18/7473 [00:00<01:29, 82.98it/s]  0%|▏                                                     | 27/7473 [00:00<01:29, 82.95it/s]  0%|▎                                                     | 36/7473 [00:00<01:29, 83.02it/s]  1%|▎                                                     | 45/7473 [00:00<01:30, 81.73it/s]  1%|▍                                                     | 54/7473 [00:00<01:30, 82.27it/s]  1%|▍                                                     | 63/7473 [00:00<01:29, 82.37it/s]  1%|▌                                                     | 72/7473 [00:00<01:29, 82.67it/s]  1%|▌                                                     | 81/7473 [00:00<01:29, 82.85it/s]  1%|▋                                                     | 90/7473 [00:01<01:29, 82.85it/s]  1%|▋                                                     | 99/7473 [00:01<01:28, 82.90it/s]  1%|▊                                                    | 108/7473 [00:01<01:28, 82.77it/s]  2%|▊                                                    | 117/7473 [00:01<01:28, 82.87it/s]  2%|▉                                                    | 126/7473 [00:01<01:28, 82.92it/s]  2%|▉                                                    | 135/7473 [00:01<01:29, 81.68it/s]  2%|█                                                    | 144/7473 [00:01<01:28, 82.60it/s]  2%|█                                                    | 157/7473 [00:01<01:16, 95.43it/s]  2%|█▏                                                  | 170/7473 [00:01<01:09, 104.63it/s]  2%|█▎                                                  | 183/7473 [00:02<01:05, 111.30it/s]  3%|█▎                                                  | 196/7473 [00:02<01:02, 115.95it/s]  3%|█▍                                                  | 209/7473 [00:02<01:00, 119.44it/s]  3%|█▌                                                  | 222/7473 [00:02<00:59, 121.78it/s]  3%|█▋                                                  | 235/7473 [00:02<00:58, 123.26it/s]  3%|█▋                                                  | 248/7473 [00:02<00:58, 124.08it/s]  3%|█▊                                                  | 261/7473 [00:02<00:58, 122.65it/s]  4%|█▉                                                  | 274/7473 [00:02<00:58, 123.99it/s]  4%|█▉                                                  | 287/7473 [00:02<00:57, 125.00it/s]  4%|██                                                  | 300/7473 [00:02<00:57, 125.58it/s]  4%|██▏                                                 | 313/7473 [00:03<00:56, 126.05it/s]  4%|██▎                                                 | 326/7473 [00:03<00:56, 126.50it/s]  5%|██▎                                                 | 339/7473 [00:03<00:56, 126.40it/s]  5%|██▍                                                 | 352/7473 [00:03<00:56, 126.83it/s]  5%|██▌                                                 | 365/7473 [00:03<00:56, 126.70it/s]  5%|██▋                                                 | 378/7473 [00:03<00:55, 126.89it/s]  5%|██▋                                                 | 391/7473 [00:03<00:55, 126.98it/s]  5%|██▊                                                 | 404/7473 [00:03<00:55, 126.76it/s]  6%|██▉                                                 | 417/7473 [00:03<00:55, 126.73it/s]  6%|██▉                                                 | 430/7473 [00:04<00:55, 126.82it/s]  6%|███                                                 | 443/7473 [00:04<00:55, 126.61it/s]  6%|███▏                                                | 456/7473 [00:04<00:55, 126.90it/s]  6%|███▎                                                | 469/7473 [00:04<00:55, 126.85it/s]  6%|███▎                                                | 482/7473 [00:04<00:55, 125.31it/s]  7%|███▍                                                | 495/7473 [00:04<00:55, 125.78it/s]  7%|███▌                                                | 508/7473 [00:04<00:55, 125.92it/s]  7%|███▋                                                | 521/7473 [00:04<00:54, 126.43it/s]  7%|███▋                                                | 534/7473 [00:04<00:54, 126.39it/s]  7%|███▊                                                | 547/7473 [00:04<00:54, 126.62it/s]  7%|███▉                                                | 560/7473 [00:05<00:54, 126.85it/s]  8%|███▉                                                | 573/7473 [00:05<00:54, 126.43it/s]  8%|████                                                | 586/7473 [00:05<00:54, 126.41it/s]  8%|████▏                                               | 599/7473 [00:05<00:54, 126.33it/s]  8%|████▎                                               | 612/7473 [00:05<00:54, 126.33it/s]  8%|████▎                                               | 625/7473 [00:05<00:54, 126.12it/s]  9%|████▍                                               | 638/7473 [00:05<00:54, 126.31it/s]  9%|████▌                                               | 651/7473 [00:05<00:54, 126.13it/s]  9%|████▌                                               | 664/7473 [00:05<00:53, 126.52it/s]  9%|████▋                                               | 677/7473 [00:05<00:53, 126.57it/s]  9%|████▊                                               | 690/7473 [00:06<00:53, 126.66it/s]  9%|████▉                                               | 703/7473 [00:06<00:54, 125.15it/s] 10%|████▉                                               | 716/7473 [00:06<00:53, 125.40it/s] 10%|█████                                               | 729/7473 [00:06<00:53, 125.83it/s] 10%|█████▏                                              | 742/7473 [00:06<00:53, 125.84it/s] 10%|█████▎                                              | 755/7473 [00:06<00:53, 125.86it/s] 10%|█████▎                                              | 768/7473 [00:06<00:53, 125.85it/s] 10%|█████▍                                              | 781/7473 [00:06<00:53, 125.93it/s] 11%|█████▌                                              | 794/7473 [00:06<00:53, 125.89it/s] 11%|█████▌                                              | 807/7473 [00:06<00:52, 125.87it/s] 11%|█████▋                                              | 820/7473 [00:07<00:52, 125.80it/s] 11%|█████▊                                              | 833/7473 [00:07<00:52, 125.97it/s] 11%|█████▉                                              | 846/7473 [00:07<00:52, 125.96it/s] 11%|█████▉                                              | 859/7473 [00:07<00:52, 126.03it/s] 12%|██████                                              | 872/7473 [00:07<00:52, 126.10it/s] 12%|██████▏                                             | 885/7473 [00:07<00:52, 126.28it/s] 12%|██████▏                                             | 898/7473 [00:07<00:52, 126.05it/s] 12%|██████▎                                             | 911/7473 [00:07<00:52, 125.49it/s] 12%|██████▍                                             | 924/7473 [00:07<00:52, 125.44it/s] 13%|██████▌                                             | 937/7473 [00:08<00:52, 124.60it/s] 13%|██████▌                                             | 950/7473 [00:08<00:51, 125.63it/s] 13%|██████▋                                             | 963/7473 [00:08<00:51, 126.30it/s] 13%|██████▊                                             | 976/7473 [00:08<00:51, 126.79it/s] 13%|██████▉                                             | 989/7473 [00:08<00:51, 127.11it/s] 13%|██████▊                                            | 1002/7473 [00:08<00:50, 126.93it/s] 14%|██████▉                                            | 1015/7473 [00:08<00:50, 127.34it/s] 14%|███████                                            | 1028/7473 [00:08<00:50, 127.51it/s] 14%|███████                                            | 1041/7473 [00:08<00:50, 127.39it/s] 14%|███████▏                                           | 1054/7473 [00:08<00:50, 127.42it/s] 14%|███████▎                                           | 1067/7473 [00:09<00:50, 127.63it/s] 14%|███████▎                                           | 1080/7473 [00:09<00:50, 126.44it/s] 15%|███████▍                                           | 1093/7473 [00:09<00:50, 126.76it/s] 15%|███████▌                                           | 1106/7473 [00:09<00:50, 126.79it/s] 15%|███████▋                                           | 1119/7473 [00:09<00:50, 126.96it/s] 15%|███████▋                                           | 1132/7473 [00:09<00:49, 126.91it/s] 15%|███████▊                                           | 1145/7473 [00:09<00:49, 127.28it/s] 15%|███████▉                                           | 1158/7473 [00:09<00:50, 125.82it/s] 16%|███████▉                                           | 1171/7473 [00:09<00:49, 126.24it/s] 16%|████████                                           | 1184/7473 [00:09<00:49, 126.46it/s] 16%|████████▏                                          | 1197/7473 [00:10<00:49, 126.74it/s] 16%|████████▎                                          | 1210/7473 [00:10<00:49, 126.75it/s] 16%|████████▎                                          | 1223/7473 [00:10<00:49, 127.05it/s] 17%|████████▍                                          | 1236/7473 [00:10<00:49, 127.03it/s] 17%|████████▌                                          | 1249/7473 [00:10<00:48, 127.05it/s] 17%|████████▌                                          | 1262/7473 [00:10<00:48, 127.13it/s] 17%|████████▋                                          | 1275/7473 [00:10<00:48, 127.28it/s] 17%|████████▊                                          | 1288/7473 [00:10<00:48, 127.40it/s] 17%|████████▉                                          | 1301/7473 [00:10<00:48, 127.38it/s] 18%|████████▉                                          | 1314/7473 [00:10<00:48, 127.43it/s] 18%|█████████                                          | 1327/7473 [00:11<00:48, 127.46it/s] 18%|█████████▏                                         | 1340/7473 [00:11<00:48, 127.50it/s] 18%|█████████▏                                         | 1353/7473 [00:11<00:47, 127.53it/s] 18%|█████████▎                                         | 1366/7473 [00:11<00:47, 127.58it/s] 18%|█████████▍                                         | 1379/7473 [00:11<00:47, 127.49it/s] 19%|█████████▍                                         | 1392/7473 [00:11<00:48, 125.20it/s] 19%|█████████▌                                         | 1405/7473 [00:11<00:48, 125.87it/s] 19%|█████████▋                                         | 1418/7473 [00:11<00:47, 126.45it/s] 19%|█████████▊                                         | 1431/7473 [00:11<00:47, 126.65it/s] 19%|█████████▊                                         | 1444/7473 [00:12<00:47, 126.83it/s] 19%|█████████▉                                         | 1457/7473 [00:12<00:47, 126.91it/s] 20%|██████████                                         | 1470/7473 [00:12<00:47, 127.14it/s] 20%|██████████                                         | 1483/7473 [00:12<00:47, 127.31it/s] 20%|██████████▏                                        | 1496/7473 [00:12<00:46, 127.62it/s] 20%|██████████▎                                        | 1509/7473 [00:12<00:46, 127.46it/s] 20%|██████████▍                                        | 1522/7473 [00:12<00:46, 127.43it/s] 21%|██████████▍                                        | 1535/7473 [00:12<00:46, 127.49it/s] 21%|██████████▌                                        | 1548/7473 [00:12<00:46, 127.40it/s] 21%|██████████▋                                        | 1561/7473 [00:12<00:46, 127.18it/s] 21%|██████████▋                                        | 1574/7473 [00:13<00:46, 125.93it/s] 21%|██████████▊                                        | 1587/7473 [00:13<00:46, 126.12it/s] 21%|██████████▉                                        | 1600/7473 [00:13<00:46, 126.50it/s] 22%|███████████                                        | 1613/7473 [00:13<00:46, 125.31it/s] 22%|███████████                                        | 1626/7473 [00:13<00:46, 125.88it/s] 22%|███████████▏                                       | 1639/7473 [00:13<00:46, 126.59it/s] 22%|███████████▎                                       | 1652/7473 [00:13<00:45, 126.60it/s] 22%|███████████▎                                       | 1665/7473 [00:13<00:45, 126.72it/s] 22%|███████████▍                                       | 1678/7473 [00:13<00:45, 127.17it/s] 23%|███████████▌                                       | 1691/7473 [00:13<00:45, 127.33it/s] 23%|███████████▋                                       | 1704/7473 [00:14<00:45, 127.42it/s] 23%|███████████▋                                       | 1717/7473 [00:14<00:45, 127.29it/s] 23%|███████████▊                                       | 1730/7473 [00:14<00:45, 127.39it/s] 23%|███████████▉                                       | 1743/7473 [00:14<00:45, 126.27it/s] 23%|███████████▉                                       | 1756/7473 [00:14<00:45, 126.83it/s] 24%|████████████                                       | 1769/7473 [00:14<00:44, 126.84it/s] 24%|████████████▏                                      | 1782/7473 [00:14<00:44, 126.87it/s] 24%|████████████▎                                      | 1795/7473 [00:14<00:44, 126.99it/s] 24%|████████████▎                                      | 1808/7473 [00:14<00:44, 127.17it/s] 24%|████████████▍                                      | 1821/7473 [00:14<00:44, 127.23it/s] 25%|████████████▌                                      | 1834/7473 [00:15<00:44, 127.00it/s] 25%|████████████▌                                      | 1847/7473 [00:15<00:45, 124.86it/s] 25%|████████████▋                                      | 1860/7473 [00:15<00:44, 125.18it/s] 25%|████████████▊                                      | 1873/7473 [00:15<00:44, 125.95it/s] 25%|████████████▊                                      | 1886/7473 [00:15<00:44, 126.49it/s] 25%|████████████▉                                      | 1899/7473 [00:15<00:44, 125.85it/s] 26%|█████████████                                      | 1912/7473 [00:15<00:44, 126.08it/s] 26%|█████████████▏                                     | 1925/7473 [00:15<00:43, 126.23it/s] 26%|█████████████▏                                     | 1938/7473 [00:15<00:43, 126.25it/s] 26%|█████████████▎                                     | 1951/7473 [00:16<00:43, 126.76it/s] 26%|█████████████▍                                     | 1964/7473 [00:16<00:43, 127.08it/s] 26%|█████████████▍                                     | 1977/7473 [00:16<00:43, 127.12it/s] 27%|█████████████▌                                     | 1990/7473 [00:16<00:43, 127.03it/s] 27%|█████████████▋                                     | 2003/7473 [00:16<00:43, 127.06it/s] 27%|█████████████▊                                     | 2016/7473 [00:16<00:42, 127.36it/s] 27%|█████████████▊                                     | 2029/7473 [00:16<00:42, 127.57it/s] 27%|█████████████▉                                     | 2042/7473 [00:16<00:42, 127.46it/s] 27%|██████████████                                     | 2055/7473 [00:16<00:42, 127.48it/s] 28%|██████████████                                     | 2068/7473 [00:16<00:42, 125.79it/s] 28%|██████████████▏                                    | 2081/7473 [00:17<00:42, 126.32it/s] 28%|██████████████▎                                    | 2094/7473 [00:17<00:42, 126.86it/s] 28%|██████████████▍                                    | 2107/7473 [00:17<00:42, 127.02it/s] 28%|██████████████▍                                    | 2120/7473 [00:17<00:42, 126.43it/s] 29%|██████████████▌                                    | 2133/7473 [00:17<00:42, 126.35it/s] 29%|██████████████▋                                    | 2146/7473 [00:17<00:42, 126.80it/s] 29%|██████████████▋                                    | 2159/7473 [00:17<00:41, 127.15it/s] 29%|██████████████▊                                    | 2172/7473 [00:17<00:41, 127.28it/s] 29%|██████████████▉                                    | 2185/7473 [00:17<00:41, 127.16it/s] 29%|███████████████                                    | 2198/7473 [00:17<00:41, 126.84it/s] 30%|███████████████                                    | 2211/7473 [00:18<00:41, 127.25it/s] 30%|███████████████▏                                   | 2224/7473 [00:18<00:41, 127.41it/s] 30%|███████████████▎                                   | 2237/7473 [00:18<00:41, 127.44it/s] 30%|███████████████▎                                   | 2250/7473 [00:18<00:41, 127.27it/s] 30%|███████████████▍                                   | 2263/7473 [00:18<00:40, 127.08it/s] 30%|███████████████▌                                   | 2276/7473 [00:18<00:40, 126.97it/s] 31%|███████████████▌                                   | 2289/7473 [00:18<00:40, 126.73it/s] 31%|███████████████▋                                   | 2302/7473 [00:18<00:41, 125.27it/s] 31%|███████████████▊                                   | 2315/7473 [00:18<00:41, 125.62it/s] 31%|███████████████▉                                   | 2328/7473 [00:18<00:41, 125.38it/s] 31%|███████████████▉                                   | 2341/7473 [00:19<00:40, 125.49it/s] 32%|████████████████                                   | 2354/7473 [00:19<00:40, 125.53it/s] 32%|████████████████▏                                  | 2367/7473 [00:19<00:40, 125.58it/s] 32%|████████████████▏                                  | 2380/7473 [00:19<00:40, 125.77it/s] 32%|████████████████▎                                  | 2393/7473 [00:19<00:40, 125.54it/s] 32%|████████████████▍                                  | 2406/7473 [00:19<00:40, 125.85it/s] 32%|████████████████▌                                  | 2419/7473 [00:19<00:40, 125.92it/s] 33%|████████████████▌                                  | 2432/7473 [00:19<00:39, 126.05it/s] 33%|████████████████▋                                  | 2445/7473 [00:19<00:39, 126.11it/s] 33%|████████████████▊                                  | 2458/7473 [00:20<00:39, 125.78it/s] 33%|████████████████▊                                  | 2471/7473 [00:20<00:39, 125.68it/s] 33%|████████████████▉                                  | 2484/7473 [00:20<00:39, 125.82it/s] 33%|█████████████████                                  | 2497/7473 [00:20<00:39, 125.69it/s] 34%|█████████████████▏                                 | 2510/7473 [00:20<00:39, 125.90it/s] 34%|█████████████████▏                                 | 2523/7473 [00:20<00:48, 102.81it/s] 34%|█████████████████▎                                 | 2536/7473 [00:20<00:45, 108.56it/s] 34%|█████████████████▍                                 | 2549/7473 [00:20<00:43, 113.30it/s] 34%|█████████████████▍                                 | 2562/7473 [00:20<00:41, 117.11it/s] 34%|█████████████████▌                                 | 2575/7473 [00:21<00:41, 119.11it/s] 35%|█████████████████▋                                 | 2588/7473 [00:21<00:40, 121.30it/s] 35%|█████████████████▊                                 | 2601/7473 [00:21<00:39, 123.02it/s] 35%|█████████████████▊                                 | 2614/7473 [00:21<00:39, 124.36it/s] 35%|█████████████████▉                                 | 2627/7473 [00:21<00:38, 125.19it/s] 35%|██████████████████                                 | 2640/7473 [00:21<00:38, 125.89it/s] 36%|██████████████████                                 | 2653/7473 [00:21<00:38, 126.29it/s] 36%|██████████████████▏                                | 2666/7473 [00:21<00:37, 126.67it/s] 36%|██████████████████▎                                | 2679/7473 [00:21<00:37, 126.90it/s] 36%|██████████████████▎                                | 2692/7473 [00:21<00:37, 127.08it/s] 36%|██████████████████▍                                | 2705/7473 [00:22<00:37, 126.91it/s] 36%|██████████████████▌                                | 2718/7473 [00:22<00:37, 127.20it/s] 37%|██████████████████▋                                | 2731/7473 [00:22<00:37, 126.89it/s] 37%|██████████████████▋                                | 2744/7473 [00:22<00:37, 126.95it/s] 37%|██████████████████▊                                | 2757/7473 [00:22<00:37, 125.58it/s] 37%|██████████████████▉                                | 2770/7473 [00:22<00:37, 125.91it/s] 37%|██████████████████▉                                | 2783/7473 [00:22<00:37, 126.46it/s] 37%|███████████████████                                | 2796/7473 [00:22<00:36, 126.60it/s] 38%|███████████████████▏                               | 2809/7473 [00:22<00:36, 126.81it/s] 38%|███████████████████▎                               | 2822/7473 [00:22<00:36, 126.95it/s] 38%|███████████████████▎                               | 2835/7473 [00:23<00:36, 127.15it/s] 38%|███████████████████▍                               | 2848/7473 [00:23<00:36, 127.08it/s] 38%|███████████████████▌                               | 2861/7473 [00:23<00:36, 127.03it/s] 38%|███████████████████▌                               | 2874/7473 [00:23<00:36, 126.89it/s] 39%|███████████████████▋                               | 2887/7473 [00:23<00:36, 127.02it/s] 39%|███████████████████▊                               | 2900/7473 [00:23<00:35, 127.04it/s] 39%|███████████████████▉                               | 2913/7473 [00:23<00:35, 127.21it/s] 39%|███████████████████▉                               | 2926/7473 [00:23<00:35, 127.49it/s] 39%|████████████████████                               | 2939/7473 [00:23<00:35, 127.43it/s] 40%|████████████████████▏                              | 2952/7473 [00:24<00:35, 127.38it/s] 40%|████████████████████▏                              | 2965/7473 [00:24<00:35, 126.97it/s] 40%|████████████████████▎                              | 2978/7473 [00:24<00:35, 125.57it/s] 40%|████████████████████▍                              | 2991/7473 [00:24<00:35, 126.12it/s] 40%|████████████████████▌                              | 3004/7473 [00:24<00:35, 126.51it/s] 40%|████████████████████▌                              | 3017/7473 [00:24<00:35, 126.57it/s] 41%|████████████████████▋                              | 3030/7473 [00:24<00:35, 126.60it/s] 41%|████████████████████▊                              | 3043/7473 [00:24<00:35, 126.53it/s] 41%|████████████████████▊                              | 3056/7473 [00:24<00:34, 126.87it/s] 41%|████████████████████▉                              | 3069/7473 [00:24<00:34, 126.93it/s] 41%|█████████████████████                              | 3082/7473 [00:25<00:34, 126.96it/s] 41%|█████████████████████                              | 3095/7473 [00:25<00:34, 126.76it/s] 42%|█████████████████████▏                             | 3108/7473 [00:25<00:34, 126.80it/s] 42%|█████████████████████▎                             | 3121/7473 [00:25<00:34, 126.64it/s] 42%|█████████████████████▍                             | 3134/7473 [00:25<00:34, 126.72it/s] 42%|█████████████████████▍                             | 3147/7473 [00:25<00:34, 126.56it/s] 42%|█████████████████████▌                             | 3160/7473 [00:25<00:34, 126.61it/s] 42%|█████████████████████▋                             | 3173/7473 [00:25<00:33, 126.81it/s] 43%|█████████████████████▋                             | 3186/7473 [00:25<00:34, 125.99it/s] 43%|█████████████████████▊                             | 3199/7473 [00:25<00:33, 126.32it/s] 43%|█████████████████████▉                             | 3212/7473 [00:26<00:34, 125.31it/s] 43%|██████████████████████                             | 3225/7473 [00:26<00:33, 125.72it/s] 43%|██████████████████████                             | 3238/7473 [00:26<00:33, 126.05it/s] 44%|██████████████████████▏                            | 3251/7473 [00:26<00:33, 126.52it/s] 44%|██████████████████████▎                            | 3264/7473 [00:26<00:33, 126.67it/s] 44%|██████████████████████▎                            | 3277/7473 [00:26<00:33, 126.93it/s] 44%|██████████████████████▍                            | 3290/7473 [00:26<00:32, 126.76it/s] 44%|██████████████████████▌                            | 3303/7473 [00:26<00:32, 126.89it/s] 44%|██████████████████████▋                            | 3316/7473 [00:26<00:32, 127.01it/s] 45%|██████████████████████▋                            | 3329/7473 [00:26<00:32, 126.84it/s] 45%|██████████████████████▊                            | 3342/7473 [00:27<00:32, 126.59it/s] 45%|██████████████████████▉                            | 3355/7473 [00:27<00:32, 126.52it/s] 45%|██████████████████████▉                            | 3368/7473 [00:27<00:32, 126.62it/s] 45%|███████████████████████                            | 3381/7473 [00:27<00:32, 126.68it/s] 45%|███████████████████████▏                           | 3394/7473 [00:27<00:32, 125.82it/s] 46%|███████████████████████▎                           | 3407/7473 [00:27<00:32, 126.29it/s] 46%|███████████████████████▎                           | 3420/7473 [00:27<00:32, 126.47it/s] 46%|███████████████████████▍                           | 3433/7473 [00:27<00:32, 124.64it/s] 46%|███████████████████████▌                           | 3446/7473 [00:27<00:32, 125.22it/s] 46%|███████████████████████▌                           | 3459/7473 [00:28<00:31, 125.69it/s] 46%|███████████████████████▋                           | 3472/7473 [00:28<00:31, 126.06it/s] 47%|███████████████████████▊                           | 3485/7473 [00:28<00:31, 126.48it/s] 47%|███████████████████████▊                           | 3498/7473 [00:28<00:31, 126.53it/s] 47%|███████████████████████▉                           | 3511/7473 [00:28<00:31, 126.78it/s] 47%|████████████████████████                           | 3524/7473 [00:28<00:31, 126.90it/s] 47%|████████████████████████▏                          | 3537/7473 [00:28<00:30, 127.09it/s] 48%|████████████████████████▏                          | 3550/7473 [00:28<00:30, 127.12it/s] 48%|████████████████████████▎                          | 3563/7473 [00:28<00:30, 127.04it/s] 48%|████████████████████████▍                          | 3576/7473 [00:28<00:30, 127.32it/s] 48%|████████████████████████▍                          | 3589/7473 [00:29<00:30, 127.27it/s] 48%|████████████████████████▌                          | 3602/7473 [00:29<00:30, 127.25it/s] 48%|████████████████████████▋                          | 3615/7473 [00:29<00:30, 126.32it/s] 49%|████████████████████████▊                          | 3628/7473 [00:29<00:30, 126.58it/s] 49%|████████████████████████▊                          | 3641/7473 [00:29<00:30, 126.54it/s] 49%|████████████████████████▉                          | 3654/7473 [00:29<00:30, 125.24it/s] 49%|█████████████████████████                          | 3667/7473 [00:29<00:30, 125.80it/s] 49%|█████████████████████████                          | 3680/7473 [00:29<00:30, 126.14it/s] 49%|█████████████████████████▏                         | 3693/7473 [00:29<00:29, 126.46it/s] 50%|█████████████████████████▎                         | 3706/7473 [00:29<00:29, 126.67it/s] 50%|█████████████████████████▍                         | 3719/7473 [00:30<00:29, 126.77it/s] 50%|█████████████████████████▍                         | 3732/7473 [00:30<00:29, 126.94it/s] 50%|█████████████████████████▌                         | 3745/7473 [00:30<00:29, 126.78it/s] 50%|█████████████████████████▋                         | 3758/7473 [00:30<00:29, 126.96it/s] 50%|█████████████████████████▋                         | 3771/7473 [00:30<00:29, 127.02it/s] 51%|█████████████████████████▊                         | 3784/7473 [00:30<00:29, 127.12it/s] 51%|█████████████████████████▉                         | 3797/7473 [00:30<00:28, 127.25it/s] 51%|██████████████████████████                         | 3810/7473 [00:30<00:28, 127.33it/s] 51%|██████████████████████████                         | 3823/7473 [00:30<00:28, 126.33it/s] 51%|██████████████████████████▏                        | 3836/7473 [00:30<00:28, 126.53it/s] 52%|██████████████████████████▎                        | 3849/7473 [00:31<00:28, 126.65it/s] 52%|██████████████████████████▎                        | 3862/7473 [00:31<00:28, 126.75it/s] 52%|██████████████████████████▍                        | 3875/7473 [00:31<00:28, 126.79it/s] 52%|██████████████████████████▌                        | 3888/7473 [00:31<00:28, 124.45it/s] 52%|██████████████████████████▌                        | 3901/7473 [00:31<00:28, 125.35it/s] 52%|██████████████████████████▋                        | 3914/7473 [00:31<00:28, 125.86it/s] 53%|██████████████████████████▊                        | 3927/7473 [00:31<00:28, 126.22it/s] 53%|██████████████████████████▉                        | 3940/7473 [00:31<00:27, 126.56it/s] 53%|██████████████████████████▉                        | 3953/7473 [00:31<00:27, 126.79it/s] 53%|███████████████████████████                        | 3966/7473 [00:32<00:27, 126.96it/s] 53%|███████████████████████████▏                       | 3979/7473 [00:32<00:27, 126.91it/s] 53%|███████████████████████████▏                       | 3992/7473 [00:32<00:27, 126.97it/s] 54%|███████████████████████████▎                       | 4005/7473 [00:32<00:27, 127.20it/s] 54%|███████████████████████████▍                       | 4018/7473 [00:32<00:27, 127.20it/s] 54%|███████████████████████████▌                       | 4031/7473 [00:32<00:27, 127.23it/s] 54%|███████████████████████████▌                       | 4044/7473 [00:32<00:27, 126.40it/s] 54%|███████████████████████████▋                       | 4057/7473 [00:32<00:26, 126.66it/s] 54%|███████████████████████████▊                       | 4070/7473 [00:32<00:26, 126.73it/s] 55%|███████████████████████████▊                       | 4083/7473 [00:32<00:26, 126.84it/s] 55%|███████████████████████████▉                       | 4096/7473 [00:33<00:26, 126.96it/s] 55%|████████████████████████████                       | 4109/7473 [00:33<00:26, 125.24it/s] 55%|████████████████████████████▏                      | 4122/7473 [00:33<00:26, 125.68it/s] 55%|████████████████████████████▏                      | 4135/7473 [00:33<00:26, 125.89it/s] 56%|████████████████████████████▎                      | 4148/7473 [00:33<00:26, 125.97it/s] 56%|████████████████████████████▍                      | 4161/7473 [00:33<00:26, 126.39it/s] 56%|████████████████████████████▍                      | 4174/7473 [00:33<00:26, 126.54it/s] 56%|████████████████████████████▌                      | 4187/7473 [00:33<00:25, 126.55it/s] 56%|████████████████████████████▋                      | 4200/7473 [00:33<00:25, 126.91it/s] 56%|████████████████████████████▊                      | 4213/7473 [00:33<00:25, 126.66it/s] 57%|████████████████████████████▊                      | 4226/7473 [00:34<00:25, 126.65it/s] 57%|████████████████████████████▉                      | 4239/7473 [00:34<00:25, 126.89it/s] 57%|█████████████████████████████                      | 4252/7473 [00:34<00:25, 126.08it/s] 57%|█████████████████████████████                      | 4265/7473 [00:34<00:25, 126.15it/s] 57%|█████████████████████████████▏                     | 4278/7473 [00:34<00:25, 126.13it/s] 57%|█████████████████████████████▎                     | 4291/7473 [00:34<00:25, 126.43it/s] 58%|█████████████████████████████▎                     | 4304/7473 [00:34<00:25, 126.56it/s] 58%|█████████████████████████████▍                     | 4317/7473 [00:34<00:24, 126.75it/s] 58%|█████████████████████████████▌                     | 4330/7473 [00:34<00:24, 126.72it/s] 58%|█████████████████████████████▋                     | 4343/7473 [00:35<00:24, 125.58it/s] 58%|█████████████████████████████▋                     | 4356/7473 [00:35<00:24, 126.03it/s] 58%|█████████████████████████████▊                     | 4369/7473 [00:35<00:24, 126.31it/s] 59%|█████████████████████████████▉                     | 4382/7473 [00:35<00:24, 126.34it/s] 59%|█████████████████████████████▉                     | 4395/7473 [00:35<00:24, 126.48it/s] 59%|██████████████████████████████                     | 4408/7473 [00:35<00:24, 126.64it/s] 59%|██████████████████████████████▏                    | 4421/7473 [00:35<00:24, 126.60it/s] 59%|██████████████████████████████▎                    | 4434/7473 [00:35<00:24, 126.54it/s] 60%|██████████████████████████████▎                    | 4447/7473 [00:35<00:23, 126.63it/s] 60%|██████████████████████████████▍                    | 4460/7473 [00:35<00:23, 126.47it/s] 60%|██████████████████████████████▌                    | 4473/7473 [00:36<00:23, 126.69it/s] 60%|██████████████████████████████▌                    | 4486/7473 [00:36<00:23, 126.70it/s] 60%|██████████████████████████████▋                    | 4499/7473 [00:36<00:23, 126.78it/s] 60%|██████████████████████████████▊                    | 4512/7473 [00:36<00:23, 126.75it/s] 61%|██████████████████████████████▉                    | 4525/7473 [00:36<00:23, 126.78it/s] 61%|██████████████████████████████▉                    | 4538/7473 [00:36<00:23, 126.39it/s] 61%|███████████████████████████████                    | 4551/7473 [00:36<00:23, 126.77it/s] 61%|███████████████████████████████▏                   | 4564/7473 [00:36<00:23, 125.54it/s] 61%|███████████████████████████████▏                   | 4577/7473 [00:36<00:23, 125.87it/s] 61%|███████████████████████████████▎                   | 4590/7473 [00:36<00:22, 126.21it/s] 62%|███████████████████████████████▍                   | 4603/7473 [00:37<00:22, 126.37it/s] 62%|███████████████████████████████▌                   | 4616/7473 [00:37<00:22, 126.58it/s] 62%|███████████████████████████████▌                   | 4629/7473 [00:37<00:22, 126.62it/s] 62%|███████████████████████████████▋                   | 4642/7473 [00:37<00:22, 126.61it/s] 62%|███████████████████████████████▊                   | 4655/7473 [00:37<00:22, 126.55it/s] 62%|███████████████████████████████▊                   | 4668/7473 [00:37<00:22, 126.67it/s] 63%|███████████████████████████████▉                   | 4681/7473 [00:37<00:22, 126.68it/s] 63%|████████████████████████████████                   | 4694/7473 [00:37<00:21, 126.70it/s] 63%|████████████████████████████████                   | 4707/7473 [00:37<00:21, 126.70it/s] 63%|████████████████████████████████▏                  | 4720/7473 [00:37<00:21, 126.71it/s] 63%|████████████████████████████████▎                  | 4733/7473 [00:38<00:21, 126.74it/s] 64%|████████████████████████████████▍                  | 4746/7473 [00:38<00:21, 126.69it/s] 64%|████████████████████████████████▍                  | 4759/7473 [00:38<00:21, 126.86it/s] 64%|████████████████████████████████▌                  | 4772/7473 [00:38<00:21, 126.94it/s] 64%|████████████████████████████████▋                  | 4785/7473 [00:38<00:21, 127.04it/s] 64%|████████████████████████████████▋                  | 4798/7473 [00:38<00:21, 125.06it/s] 64%|████████████████████████████████▊                  | 4811/7473 [00:38<00:21, 125.42it/s] 65%|████████████████████████████████▉                  | 4824/7473 [00:38<00:21, 125.58it/s] 65%|█████████████████████████████████                  | 4837/7473 [00:38<00:20, 125.72it/s] 65%|█████████████████████████████████                  | 4850/7473 [00:39<00:20, 125.80it/s] 65%|█████████████████████████████████▏                 | 4863/7473 [00:39<00:20, 125.74it/s] 65%|█████████████████████████████████▎                 | 4876/7473 [00:39<00:20, 125.48it/s] 65%|█████████████████████████████████▎                 | 4889/7473 [00:39<00:20, 125.57it/s] 66%|█████████████████████████████████▍                 | 4902/7473 [00:39<00:20, 125.84it/s] 66%|█████████████████████████████████▌                 | 4915/7473 [00:39<00:20, 125.80it/s] 66%|█████████████████████████████████▋                 | 4928/7473 [00:39<00:20, 125.77it/s] 66%|█████████████████████████████████▋                 | 4941/7473 [00:39<00:20, 125.47it/s] 66%|█████████████████████████████████▊                 | 4954/7473 [00:39<00:20, 125.72it/s] 66%|█████████████████████████████████▉                 | 4967/7473 [00:39<00:19, 125.40it/s] 67%|█████████████████████████████████▉                 | 4980/7473 [00:40<00:19, 125.55it/s] 67%|██████████████████████████████████                 | 4993/7473 [00:40<00:19, 125.50it/s] 67%|██████████████████████████████████▏                | 5006/7473 [00:40<00:19, 125.84it/s] 67%|██████████████████████████████████▎                | 5019/7473 [00:40<00:19, 124.18it/s] 67%|██████████████████████████████████▎                | 5032/7473 [00:40<00:19, 124.53it/s] 68%|██████████████████████████████████▍                | 5045/7473 [00:40<00:19, 125.03it/s] 68%|██████████████████████████████████▌                | 5058/7473 [00:40<00:19, 125.25it/s] 68%|██████████████████████████████████▌                | 5071/7473 [00:40<00:19, 125.45it/s] 68%|██████████████████████████████████▋                | 5084/7473 [00:40<00:19, 125.40it/s] 68%|██████████████████████████████████▊                | 5097/7473 [00:40<00:18, 125.25it/s] 68%|██████████████████████████████████▊                | 5110/7473 [00:41<00:18, 125.33it/s] 69%|██████████████████████████████████▉                | 5123/7473 [00:41<00:18, 125.51it/s] 69%|███████████████████████████████████                | 5136/7473 [00:41<00:18, 125.65it/s] 69%|███████████████████████████████████▏               | 5149/7473 [00:41<00:18, 125.75it/s] 69%|███████████████████████████████████▏               | 5162/7473 [00:41<00:18, 125.54it/s] 69%|███████████████████████████████████▎               | 5175/7473 [00:41<00:18, 125.66it/s] 69%|███████████████████████████████████▍               | 5188/7473 [00:41<00:18, 125.66it/s] 70%|███████████████████████████████████▍               | 5201/7473 [00:41<00:18, 125.69it/s] 70%|███████████████████████████████████▌               | 5214/7473 [00:41<00:17, 125.83it/s] 70%|███████████████████████████████████▋               | 5227/7473 [00:42<00:17, 125.82it/s] 70%|███████████████████████████████████▊               | 5240/7473 [00:42<00:17, 125.24it/s] 70%|███████████████████████████████████▊               | 5253/7473 [00:42<00:21, 104.89it/s] 70%|███████████████████████████████████▉               | 5266/7473 [00:42<00:19, 110.52it/s] 71%|████████████████████████████████████               | 5279/7473 [00:42<00:19, 115.07it/s] 71%|████████████████████████████████████               | 5292/7473 [00:42<00:18, 118.31it/s] 71%|████████████████████████████████████▏              | 5305/7473 [00:42<00:18, 120.22it/s] 71%|████████████████████████████████████▎              | 5318/7473 [00:42<00:17, 121.84it/s] 71%|████████████████████████████████████▍              | 5331/7473 [00:42<00:17, 123.20it/s] 72%|████████████████████████████████████▍              | 5344/7473 [00:43<00:17, 124.22it/s] 72%|████████████████████████████████████▌              | 5357/7473 [00:43<00:16, 124.76it/s] 72%|████████████████████████████████████▋              | 5370/7473 [00:43<00:16, 125.28it/s] 72%|████████████████████████████████████▋              | 5383/7473 [00:43<00:16, 125.59it/s] 72%|████████████████████████████████████▊              | 5396/7473 [00:43<00:16, 125.79it/s] 72%|████████████████████████████████████▉              | 5409/7473 [00:43<00:16, 126.07it/s] 73%|█████████████████████████████████████              | 5422/7473 [00:43<00:16, 126.28it/s] 73%|█████████████████████████████████████              | 5435/7473 [00:43<00:16, 126.51it/s] 73%|█████████████████████████████████████▏             | 5448/7473 [00:43<00:16, 126.40it/s] 73%|█████████████████████████████████████▎             | 5461/7473 [00:43<00:15, 126.19it/s] 73%|██████████████████████████████████████              | 5474/7473 [00:44<00:26, 75.36it/s] 73%|██████████████████████████████████████▏             | 5487/7473 [00:44<00:23, 85.73it/s] 74%|██████████████████████████████████████▎             | 5500/7473 [00:44<00:20, 94.66it/s] 74%|█████████████████████████████████████▌             | 5513/7473 [00:44<00:19, 102.43it/s] 74%|█████████████████████████████████████▋             | 5526/7473 [00:44<00:17, 108.41it/s] 74%|█████████████████████████████████████▊             | 5539/7473 [00:44<00:17, 113.17it/s] 74%|█████████████████████████████████████▉             | 5552/7473 [00:44<00:16, 116.96it/s] 74%|█████████████████████████████████████▉             | 5565/7473 [00:44<00:15, 119.83it/s] 75%|██████████████████████████████████████             | 5578/7473 [00:45<00:15, 121.33it/s] 75%|██████████████████████████████████████▏            | 5591/7473 [00:45<00:15, 122.83it/s] 75%|██████████████████████████████████████▏            | 5604/7473 [00:45<00:15, 123.80it/s] 75%|██████████████████████████████████████▎            | 5617/7473 [00:45<00:14, 124.58it/s] 75%|██████████████████████████████████████▍            | 5630/7473 [00:45<00:14, 125.25it/s] 76%|██████████████████████████████████████▌            | 5643/7473 [00:45<00:14, 125.15it/s] 76%|██████████████████████████████████████▌            | 5656/7473 [00:45<00:14, 125.75it/s] 76%|██████████████████████████████████████▋            | 5669/7473 [00:45<00:14, 126.05it/s] 76%|██████████████████████████████████████▊            | 5682/7473 [00:45<00:14, 124.79it/s] 76%|██████████████████████████████████████▊            | 5695/7473 [00:46<00:14, 125.33it/s] 76%|██████████████████████████████████████▉            | 5708/7473 [00:46<00:14, 125.52it/s] 77%|███████████████████████████████████████            | 5721/7473 [00:46<00:13, 125.63it/s] 77%|███████████████████████████████████████▏           | 5734/7473 [00:46<00:13, 125.94it/s] 77%|███████████████████████████████████████▏           | 5747/7473 [00:46<00:13, 126.24it/s] 77%|███████████████████████████████████████▎           | 5760/7473 [00:46<00:13, 126.41it/s] 77%|███████████████████████████████████████▍           | 5773/7473 [00:46<00:13, 126.61it/s] 77%|███████████████████████████████████████▍           | 5786/7473 [00:46<00:13, 126.04it/s] 78%|███████████████████████████████████████▌           | 5799/7473 [00:46<00:13, 126.26it/s] 78%|███████████████████████████████████████▋           | 5812/7473 [00:46<00:13, 126.08it/s] 78%|███████████████████████████████████████▊           | 5825/7473 [00:47<00:13, 126.26it/s] 78%|███████████████████████████████████████▊           | 5838/7473 [00:47<00:12, 126.34it/s] 78%|███████████████████████████████████████▉           | 5851/7473 [00:47<00:12, 126.56it/s] 78%|████████████████████████████████████████           | 5864/7473 [00:47<00:12, 126.04it/s] 79%|████████████████████████████████████████           | 5877/7473 [00:47<00:12, 126.30it/s] 79%|████████████████████████████████████████▏          | 5890/7473 [00:47<00:12, 126.24it/s] 79%|████████████████████████████████████████▎          | 5903/7473 [00:47<00:12, 124.75it/s] 79%|████████████████████████████████████████▎          | 5916/7473 [00:47<00:12, 125.21it/s] 79%|████████████████████████████████████████▍          | 5929/7473 [00:47<00:12, 125.41it/s] 80%|████████████████████████████████████████▌          | 5942/7473 [00:47<00:12, 125.52it/s] 80%|████████████████████████████████████████▋          | 5955/7473 [00:48<00:12, 125.68it/s] 80%|████████████████████████████████████████▋          | 5968/7473 [00:48<00:11, 125.62it/s] 80%|████████████████████████████████████████▊          | 5981/7473 [00:48<00:11, 126.01it/s] 80%|████████████████████████████████████████▉          | 5994/7473 [00:48<00:11, 125.94it/s] 80%|████████████████████████████████████████▉          | 6007/7473 [00:48<00:11, 125.89it/s] 81%|█████████████████████████████████████████          | 6020/7473 [00:48<00:11, 126.18it/s] 81%|█████████████████████████████████████████▏         | 6033/7473 [00:48<00:11, 126.26it/s] 81%|█████████████████████████████████████████▎         | 6046/7473 [00:48<00:11, 126.40it/s] 81%|█████████████████████████████████████████▎         | 6059/7473 [00:48<00:11, 126.65it/s] 81%|█████████████████████████████████████████▍         | 6072/7473 [00:49<00:11, 126.34it/s] 81%|█████████████████████████████████████████▌         | 6085/7473 [00:49<00:10, 126.48it/s] 82%|█████████████████████████████████████████▌         | 6098/7473 [00:49<00:10, 126.54it/s] 82%|█████████████████████████████████████████▋         | 6111/7473 [00:49<00:10, 126.57it/s] 82%|█████████████████████████████████████████▊         | 6124/7473 [00:49<00:10, 126.59it/s] 82%|█████████████████████████████████████████▉         | 6137/7473 [00:49<00:10, 125.30it/s] 82%|█████████████████████████████████████████▉         | 6150/7473 [00:49<00:10, 125.11it/s] 82%|██████████████████████████████████████████         | 6163/7473 [00:49<00:10, 125.44it/s] 83%|██████████████████████████████████████████▏        | 6176/7473 [00:49<00:10, 125.79it/s] 83%|██████████████████████████████████████████▏        | 6189/7473 [00:49<00:10, 126.04it/s] 83%|██████████████████████████████████████████▎        | 6202/7473 [00:50<00:10, 126.23it/s] 83%|██████████████████████████████████████████▍        | 6215/7473 [00:50<00:09, 126.33it/s] 83%|██████████████████████████████████████████▌        | 6228/7473 [00:50<00:09, 125.94it/s] 84%|██████████████████████████████████████████▌        | 6241/7473 [00:50<00:09, 126.23it/s] 84%|██████████████████████████████████████████▋        | 6254/7473 [00:50<00:09, 126.47it/s] 84%|██████████████████████████████████████████▊        | 6267/7473 [00:50<00:09, 126.40it/s] 84%|██████████████████████████████████████████▊        | 6280/7473 [00:50<00:09, 126.49it/s] 84%|██████████████████████████████████████████▉        | 6293/7473 [00:50<00:09, 126.07it/s] 84%|███████████████████████████████████████████        | 6306/7473 [00:50<00:09, 126.45it/s] 85%|███████████████████████████████████████████        | 6319/7473 [00:50<00:09, 126.57it/s] 85%|███████████████████████████████████████████▏       | 6332/7473 [00:51<00:09, 126.68it/s] 85%|███████████████████████████████████████████▎       | 6345/7473 [00:51<00:08, 126.56it/s] 85%|███████████████████████████████████████████▍       | 6358/7473 [00:51<00:08, 124.39it/s] 85%|███████████████████████████████████████████▍       | 6371/7473 [00:51<00:08, 124.74it/s] 85%|███████████████████████████████████████████▌       | 6384/7473 [00:51<00:08, 124.99it/s] 86%|███████████████████████████████████████████▋       | 6397/7473 [00:51<00:08, 125.48it/s] 86%|███████████████████████████████████████████▋       | 6410/7473 [00:51<00:08, 125.86it/s] 86%|███████████████████████████████████████████▊       | 6423/7473 [00:51<00:08, 125.90it/s] 86%|███████████████████████████████████████████▉       | 6436/7473 [00:51<00:08, 125.83it/s] 86%|████████████████████████████████████████████       | 6449/7473 [00:52<00:08, 125.85it/s] 86%|████████████████████████████████████████████       | 6462/7473 [00:52<00:08, 125.93it/s] 87%|████████████████████████████████████████████▏      | 6475/7473 [00:52<00:07, 126.24it/s] 87%|████████████████████████████████████████████▎      | 6488/7473 [00:52<00:07, 126.35it/s] 87%|████████████████████████████████████████████▎      | 6501/7473 [00:52<00:07, 126.40it/s] 87%|████████████████████████████████████████████▍      | 6514/7473 [00:52<00:07, 125.74it/s] 87%|████████████████████████████████████████████▌      | 6527/7473 [00:52<00:07, 126.02it/s] 88%|████████████████████████████████████████████▋      | 6540/7473 [00:52<00:07, 126.27it/s] 88%|████████████████████████████████████████████▋      | 6553/7473 [00:52<00:07, 126.43it/s] 88%|████████████████████████████████████████████▊      | 6566/7473 [00:52<00:07, 126.49it/s] 88%|████████████████████████████████████████████▉      | 6579/7473 [00:53<00:07, 125.95it/s] 88%|████████████████████████████████████████████▉      | 6592/7473 [00:53<00:07, 124.89it/s] 88%|█████████████████████████████████████████████      | 6605/7473 [00:53<00:06, 125.45it/s] 89%|█████████████████████████████████████████████▏     | 6618/7473 [00:53<00:06, 125.82it/s] 89%|█████████████████████████████████████████████▎     | 6631/7473 [00:53<00:06, 125.91it/s] 89%|█████████████████████████████████████████████▎     | 6644/7473 [00:53<00:06, 125.76it/s] 89%|█████████████████████████████████████████████▍     | 6657/7473 [00:53<00:06, 125.87it/s] 89%|█████████████████████████████████████████████▌     | 6670/7473 [00:53<00:06, 125.88it/s] 89%|█████████████████████████████████████████████▌     | 6683/7473 [00:53<00:06, 126.09it/s] 90%|█████████████████████████████████████████████▋     | 6696/7473 [00:53<00:06, 126.38it/s] 90%|█████████████████████████████████████████████▊     | 6709/7473 [00:54<00:06, 126.46it/s] 90%|█████████████████████████████████████████████▊     | 6722/7473 [00:54<00:05, 125.91it/s] 90%|█████████████████████████████████████████████▉     | 6735/7473 [00:54<00:05, 126.12it/s] 90%|██████████████████████████████████████████████     | 6748/7473 [00:54<00:05, 126.15it/s] 90%|██████████████████████████████████████████████▏    | 6761/7473 [00:54<00:05, 126.08it/s] 91%|██████████████████████████████████████████████▏    | 6774/7473 [00:54<00:05, 126.22it/s] 91%|██████████████████████████████████████████████▎    | 6787/7473 [00:54<00:05, 126.29it/s] 91%|██████████████████████████████████████████████▍    | 6800/7473 [00:54<00:05, 125.93it/s] 91%|██████████████████████████████████████████████▍    | 6813/7473 [00:54<00:05, 124.71it/s] 91%|██████████████████████████████████████████████▌    | 6826/7473 [00:55<00:05, 125.16it/s] 92%|██████████████████████████████████████████████▋    | 6839/7473 [00:55<00:05, 125.55it/s] 92%|██████████████████████████████████████████████▊    | 6852/7473 [00:55<00:04, 125.92it/s] 92%|██████████████████████████████████████████████▊    | 6865/7473 [00:55<00:04, 125.83it/s] 92%|██████████████████████████████████████████████▉    | 6878/7473 [00:55<00:04, 126.16it/s] 92%|███████████████████████████████████████████████    | 6891/7473 [00:55<00:04, 126.33it/s] 92%|███████████████████████████████████████████████    | 6904/7473 [00:55<00:04, 126.65it/s] 93%|███████████████████████████████████████████████▏   | 6917/7473 [00:55<00:04, 126.61it/s] 93%|███████████████████████████████████████████████▎   | 6930/7473 [00:55<00:04, 126.44it/s] 93%|███████████████████████████████████████████████▍   | 6943/7473 [00:55<00:04, 125.11it/s] 93%|███████████████████████████████████████████████▍   | 6956/7473 [00:56<00:04, 122.90it/s] 93%|███████████████████████████████████████████████▌   | 6969/7473 [00:56<00:04, 123.99it/s] 93%|███████████████████████████████████████████████▋   | 6982/7473 [00:56<00:03, 124.70it/s] 94%|███████████████████████████████████████████████▋   | 6995/7473 [00:56<00:03, 124.09it/s] 94%|███████████████████████████████████████████████▊   | 7008/7473 [00:56<00:03, 124.90it/s] 94%|███████████████████████████████████████████████▉   | 7021/7473 [00:56<00:03, 125.34it/s] 94%|████████████████████████████████████████████████   | 7034/7473 [00:56<00:03, 125.47it/s] 94%|████████████████████████████████████████████████   | 7047/7473 [00:56<00:03, 124.17it/s] 94%|████████████████████████████████████████████████▏  | 7060/7473 [00:56<00:03, 125.00it/s] 95%|████████████████████████████████████████████████▎  | 7073/7473 [00:56<00:03, 125.35it/s] 95%|████████████████████████████████████████████████▎  | 7086/7473 [00:57<00:03, 125.82it/s] 95%|████████████████████████████████████████████████▍  | 7099/7473 [00:57<00:02, 126.02it/s] 95%|████████████████████████████████████████████████▌  | 7112/7473 [00:57<00:02, 126.05it/s] 95%|████████████████████████████████████████████████▋  | 7125/7473 [00:57<00:02, 126.12it/s] 96%|████████████████████████████████████████████████▋  | 7138/7473 [00:57<00:02, 125.97it/s] 96%|████████████████████████████████████████████████▊  | 7151/7473 [00:57<00:02, 126.27it/s] 96%|████████████████████████████████████████████████▉  | 7164/7473 [00:57<00:02, 126.07it/s] 96%|████████████████████████████████████████████████▉  | 7177/7473 [00:57<00:02, 126.30it/s] 96%|█████████████████████████████████████████████████  | 7190/7473 [00:57<00:02, 126.44it/s] 96%|█████████████████████████████████████████████████▏ | 7203/7473 [00:58<00:02, 126.53it/s] 97%|█████████████████████████████████████████████████▏ | 7216/7473 [00:58<00:02, 126.43it/s] 97%|█████████████████████████████████████████████████▎ | 7229/7473 [00:58<00:01, 126.58it/s] 97%|█████████████████████████████████████████████████▍ | 7242/7473 [00:58<00:01, 126.56it/s] 97%|█████████████████████████████████████████████████▌ | 7255/7473 [00:58<00:01, 126.59it/s] 97%|█████████████████████████████████████████████████▌ | 7268/7473 [00:58<00:01, 125.35it/s] 97%|█████████████████████████████████████████████████▋ | 7281/7473 [00:58<00:01, 124.78it/s] 98%|█████████████████████████████████████████████████▊ | 7294/7473 [00:58<00:01, 125.46it/s] 98%|█████████████████████████████████████████████████▊ | 7307/7473 [00:58<00:01, 125.75it/s] 98%|█████████████████████████████████████████████████▉ | 7320/7473 [00:58<00:01, 126.11it/s] 98%|██████████████████████████████████████████████████ | 7333/7473 [00:59<00:01, 126.17it/s] 98%|██████████████████████████████████████████████████▏| 7346/7473 [00:59<00:01, 126.18it/s] 98%|██████████████████████████████████████████████████▏| 7359/7473 [00:59<00:00, 126.27it/s] 99%|██████████████████████████████████████████████████▎| 7372/7473 [00:59<00:00, 126.29it/s] 99%|██████████████████████████████████████████████████▍| 7385/7473 [00:59<00:00, 126.36it/s] 99%|██████████████████████████████████████████████████▍| 7398/7473 [00:59<00:00, 126.52it/s] 99%|██████████████████████████████████████████████████▌| 7411/7473 [00:59<00:00, 126.52it/s] 99%|██████████████████████████████████████████████████▋| 7424/7473 [00:59<00:00, 126.39it/s]100%|██████████████████████████████████████████████████▊| 7437/7473 [00:59<00:00, 126.54it/s]100%|██████████████████████████████████████████████████▊| 7450/7473 [00:59<00:00, 126.36it/s]100%|██████████████████████████████████████████████████▉| 7463/7473 [01:00<00:00, 126.21it/s]100%|███████████████████████████████████████████████████| 7473/7473 [01:00<00:00, 124.25it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.01s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.13s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.30s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.40s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.04s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.06s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.17s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.30s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.56s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.69s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.46s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.63s/it]
[2023-08-12 18:41:40,253] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.51s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.70s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.67s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.85s/it]
[2023-08-12 18:41:48,002] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 18:41:48,002] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f2d1a909490>
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 18:41:48,003] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f2d00f240a0>
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 18:41:48,004] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 18:41:48,004] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.7618715763092041 seconds
Loading extension module utils...
Time to load utils op: 0.6048493385314941 seconds
Loading extension module utils...
Time to load utils op: 0.8052446842193604 seconds
Loading extension module utils...
Time to load utils op: 0.8052573204040527 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Rationales: 1. The question asks where you could find plumbing that would not be usable if you're thirsty.
2. This implies that the plumbing in question doesn't carry drinkable water.
3. Considering the choices given:
    - A: oil refineries
    - B: wall
    - C: show
    - D: own home
    - E: water fountain
4. B: Wall, although it has plumbing, this could actually distribute water depending on the context (a household, for instance), so we cannot directly eliminate this.
5. D: Own home and E: water fountain are locations where one would usually expect to find usable, drinkable water, so these options can be eliminated.
6. C: Show isn't a clear option since the term "show" is very vague and can mean numerous things, but usually, shows involve places where potable water could potentially be accessible.
7. A: Oil refineries are places where plumbing exists, but it's used for transferring oil, not water.
8. Therefore, of all the options given, the only place where you're guaranteed to find plumbing that wouldn't be of use if you're thirsty is in an oil refinery. Thus the answer is A: oil refineries.
Answer: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Rationales: 1. First, consider the meaning of each option. Working means carrying out tasks or duties, resting is being in a state of motionlessness or sleep, tiredness is a state of needing rest, accomplishing refers to achieving or completing a task or aim, momentum refers to the quantity of motion of a moving body.

2. The question is asking us to figure out what a person isn't doing when they are just starting to work.

3. Option A, working, is incorrect because the person is just starting to work, which means they are indeed working.

4. Option B, resting, may initially seem correct since a person who is just beginning to work is not resting. However, the question asks for what a person 'isn't doing yet', implying that this is something they will eventually do. Resting doesn't fit this description as resting is an opposite action to working. 

5. Option C, tiredness, is not correct because tiredness isn't something a person does. It's a state of being.

6. Option E, momentum, also doesn't fit because in this context, it is more of a state or characteristic the work might gain rather than an action performed by a person.

7. Considering all the options, we can deduce that option D, accomplishing, is the right answer. When a person is just beginning to work, they haven't had the time to accomplish or completely finish tasks yet. It is something they will eventually do, but haven't started doing yet, fitting the description given in the question.
Answer: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Rationales: 1. The question is asking about where one can find pens that carry a company logo.
2. This implies that the place needs to be a setting where company goods or merchandise are in use or distributed.
3. Option B, on a pencil, doesn't make sense because a pen is a different object from a pencil. So it's not possible to find a pen with a logo on a pencil.
4. Option C, write sentences on paper, is not a place at all, rather it is an action. This therefore doesn't fit the question's requirements.
5. While options D: school and E: backpack could potentially be places where a pen is placed, they are less associated with company logos.
6. Option A, office, however, is a common setting for businesses where official company merchandise, such as logoed pens, are commonly used or distributed to employees and visitors.
7. So, the answer is A: office.
Answer: A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Rationales: 1. The question is about a situation in which Billy is calling out to John.
2. When we "call out" to someone, it usually means to gain their attention or ask for something.
3. After calling out to someone, the inevitable expectation is a response from the person called. The reason behind Billy calling out is to initiate a dialogue or communication.
4. Therefore, we can rule out "silence," as it doesn't fit the context of expecting something after calling out to someone.
5. "Hanging up" and "whisper" are also easily ruled out as they don't fit the context of Billy calling out to John.
6. Although "communication" may seem a possible choice, it is commonly understood that communication is a process that begins with a response.
7. Hence, the most fitting answer to the question "Billy called out to John, and listened for what?" would be "B: response," as this is the immediate expectation after Billy's action of calling out.
Answer: B: response

Input: The lizard frightened the hiker, it's movements made what rustle? Choices:  A: garden B: trees C: books D: rocks E: bushes
Rationales: 1. The question asks what the lizard's movements caused to rustle.
2. Rustling is usually referred to when leaves or some other light, thin objects move against each other, so they produce a soft, light sound.
3. We can eliminate choices A and C. A garden cannot rustle, it is too large and includes many objects. Books do not make sense in this context because there is no reason to believe that a lizard and a hiker would be near books in this scenario.
4. We can also eliminate choices B and D. Trees are too large to rustle from a tiny lizard's movements. Rocks cannot rustle because they are hard, heavy objects, not light, thin objects.
5. That leaves us with choice E: bushes, which makes sense in the given context. Bushes are made up of multiple thin, light objects (leaves and small branches) that would produce a rustling sound if a lizard moved through them.
6. Therefore, the answer is E: bushes.
Answer: E: bushes

Input: The man spent big money and time maintaining his lawn, it was part of keeping up with the Joneses where? Choices:  A: front yard B: suburbia C: neighborhood D: back yard E: golf course
Rationales: 1. The question requires an understanding of the phrase "keeping up with the Joneses". This phrase typically refers to attempting to maintain social equality with one's peers or neighbors in terms of material possessions or lifestyle.
2. Hence, the context required for this question will be a setting where there is a competition or tendency among individuals or families to follow socio-economic trends.
3. Analyzing the given choices, 'front yard' and 'back yard' are too specific and do not specifically imply this competition or trend.
4. A 'golf course' is unrelated to the typical neighborhood setting which would contain such a trend.
5. The 'neighborhood' could be correct but it’s a broad term and does not necessarily imply there is the type of socio-economic competition described.
6. So, the term'suburbia' refers specifically to residential areas especially on the outskirts of a city and these regions are notorious for having residents that try to keep up with the societal trends of their neighbors.
7. Therefore the most plausible option is B: suburbia.
Answer: B: suburbia

Input: What would a human do if they want to get to a store that he or she can see? Choices:  A: cross road B: see around C: drink coffee D: dream dreams E: think critically
Rationales: The goal mentioned in the question is to get to a store that a person can see. 

This suggests that they are relatively close to the store but some sort of obstacle or distance is in the way.

The given choices are actions that
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o9-tcommonsenseqa-s1-rTrue
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:42<34:35, 42.35s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:23<33:28, 41.85s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:05<32:40, 41.71s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [02:47<31:58, 41.70s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [03:28<31:14, 41.65s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [04:10<30:33, 41.68s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [04:52<29:52, 41.69s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [05:33<29:10, 41.69s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [06:15<28:29, 41.69s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [06:57<27:46, 41.66s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [07:38<27:05, 41.68s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [08:20<26:23, 41.68s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [09:02<25:41, 41.67s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [09:43<24:58, 41.63s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [10:25<24:16, 41.61s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [11:06<23:35, 41.63s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [11:48<22:55, 41.68s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [12:30<22:13, 41.68s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [13:12<21:32, 41.69s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [13:53<20:48, 41.61s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [14:35<20:06, 41.60s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [15:16<19:25, 41.63s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [15:58<18:44, 41.65s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [16:40<18:02, 41.62s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [17:21<17:19, 41.59s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [18:03<16:42, 41.79s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [18:45<16:00, 41.76s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [19:27<15:17, 41.69s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [20:08<14:35, 41.67s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [20:50<13:52, 41.62s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [21:31<13:10, 41.63s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [22:13<12:28, 41.61s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [22:55<11:48, 41.66s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [23:36<11:06, 41.69s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [24:18<10:24, 41.64s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [25:00<09:42, 41.63s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [25:41<09:02, 41.70s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [26:23<08:19, 41.63s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [27:04<07:37, 41.62s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [27:46<06:55, 41.57s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [28:28<06:14, 41.58s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [29:09<05:32, 41.60s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [29:51<04:51, 41.61s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [30:32<04:09, 41.61s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [31:14<03:28, 41.62s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [31:56<02:46, 41.66s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [32:37<02:04, 41.65s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [33:19<01:23, 41.68s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [34:01<00:41, 41.65s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [34:42<00:00, 41.67s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [34:42<00:00, 41.66s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.0224} | lm_loss 11.4443 | avg. gen lenth: 415.396
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o1-tcommonsenseqa-s1-rFalse --seed 1 --num-out-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-12 19:16:52,119] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o1-tcommonsenseqa-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 1
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o1-tcommonsenseqa-s1-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  3%|█▎                                                 | 201/7473 [00:00<00:03, 2004.77it/s]  5%|██▊                                                | 405/7473 [00:00<00:03, 2018.57it/s]  8%|████▏                                              | 609/7473 [00:00<00:03, 2027.43it/s] 11%|█████▌                                             | 815/7473 [00:00<00:03, 2037.17it/s] 14%|██████▊                                           | 1023/7473 [00:00<00:03, 2050.02it/s] 16%|████████▏                                         | 1229/7473 [00:00<00:03, 2049.11it/s] 19%|█████████▌                                        | 1434/7473 [00:00<00:02, 2045.77it/s] 22%|██████████▉                                       | 1639/7473 [00:00<00:02, 2047.02it/s] 25%|████████████▎                                     | 1844/7473 [00:00<00:02, 1989.24it/s] 27%|█████████████▋                                    | 2046/7473 [00:01<00:02, 1998.33it/s] 30%|███████████████                                   | 2250/7473 [00:01<00:02, 2008.13it/s] 33%|████████████████▍                                 | 2457/7473 [00:01<00:02, 2024.39it/s] 36%|█████████████████▊                                | 2660/7473 [00:01<00:02, 1989.10it/s] 38%|███████████████████▏                              | 2865/7473 [00:01<00:02, 2006.66it/s] 41%|████████████████████▌                             | 3073/7473 [00:01<00:02, 2026.27it/s] 44%|█████████████████████▉                            | 3276/7473 [00:01<00:02, 2026.63it/s] 47%|███████████████████████▎                          | 3479/7473 [00:01<00:01, 2017.25it/s] 49%|████████████████████████▋                         | 3683/7473 [00:01<00:01, 2022.31it/s] 52%|██████████████████████████                        | 3886/7473 [00:01<00:01, 2010.95it/s] 55%|███████████████████████████▍                      | 4092/7473 [00:02<00:01, 2022.64it/s] 57%|████████████████████████████▋                     | 4295/7473 [00:02<00:01, 2004.46it/s] 60%|██████████████████████████████                    | 4499/7473 [00:02<00:01, 2012.98it/s] 63%|███████████████████████████████▍                  | 4703/7473 [00:02<00:01, 2019.67it/s] 66%|████████████████████████████████▊                 | 4907/7473 [00:02<00:01, 2024.54it/s] 68%|██████████████████████████████████▏               | 5111/7473 [00:02<00:01, 2027.57it/s] 71%|███████████████████████████████████▌              | 5314/7473 [00:02<00:01, 2007.87it/s] 74%|████████████████████████████████████▉             | 5515/7473 [00:02<00:01, 1451.19it/s] 77%|██████████████████████████████████████▎           | 5718/7473 [00:02<00:01, 1586.68it/s] 79%|███████████████████████████████████████▌          | 5920/7473 [00:03<00:00, 1693.85it/s] 82%|████████████████████████████████████████▉         | 6114/7473 [00:03<00:00, 1758.37it/s] 85%|██████████████████████████████████████████▎       | 6316/7473 [00:03<00:00, 1828.89it/s] 87%|███████████████████████████████████████████▌      | 6517/7473 [00:03<00:00, 1877.22it/s] 90%|████████████████████████████████████████████▉     | 6716/7473 [00:03<00:00, 1908.97it/s] 93%|██████████████████████████████████████████████▎   | 6918/7473 [00:03<00:00, 1940.45it/s] 95%|███████████████████████████████████████████████▌  | 7118/7473 [00:03<00:00, 1957.27it/s] 98%|████████████████████████████████████████████████▉ | 7321/7473 [00:03<00:00, 1975.78it/s]100%|██████████████████████████████████████████████████| 7473/7473 [00:03<00:00, 1945.81it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.48s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.42s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.55s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.57s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.39s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.44s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.54s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.59s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.76s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.94s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.79s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.98s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.84s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.02s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.90s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.09s/it]
[2023-08-12 19:17:48,691] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-12 19:17:58,818] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 19:17:58,819] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 19:17:58,819] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 19:17:58,819] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 19:17:58,819] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 19:17:58,819] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fe59c437fa0>
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 19:17:58,820] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fe59c438700>
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 19:17:58,821] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 19:17:58,821] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.3628993034362793 seconds
Loading extension module utils...
Time to load utils op: 0.30431580543518066 seconds
Loading extension module utils...
Time to load utils op: 0.40448498725891113 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Answer: A: oil refineries

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o1-tcommonsenseqa-s1-rFalse
Loading extension module utils...
Time to load utils op: 0.30457091331481934 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:59<48:31, 59.42s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:56<46:16, 57.84s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:15<31:29, 40.19s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [03:13<36:06, 47.09s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [04:10<38:12, 50.95s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [05:06<38:36, 52.66s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [06:04<38:57, 54.37s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [06:44<34:52, 49.82s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [07:42<35:38, 52.16s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [08:40<36:00, 54.02s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [09:37<35:46, 55.03s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [10:34<35:16, 55.69s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [11:31<34:37, 56.14s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [12:29<33:53, 56.49s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [13:24<32:46, 56.19s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [14:15<30:57, 54.65s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [15:14<30:42, 55.84s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [16:05<29:00, 54.38s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [16:51<26:48, 51.88s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [17:32<24:16, 48.56s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [18:29<24:44, 51.18s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [19:24<24:22, 52.25s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [19:54<20:30, 45.58s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [20:50<21:10, 48.88s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [21:37<20:04, 48.20s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [21:50<15:05, 37.72s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [22:43<16:13, 42.35s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [23:40<17:04, 46.56s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [24:37<17:23, 49.67s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [25:34<17:20, 52.00s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [26:17<15:37, 49.33s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [27:03<14:26, 48.14s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [28:00<14:26, 50.96s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [28:45<13:07, 49.19s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [29:42<12:53, 51.57s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [30:40<12:26, 53.35s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [30:54<08:59, 41.51s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [31:41<08:38, 43.21s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [32:36<08:35, 46.88s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [33:30<08:10, 49.01s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [34:09<06:53, 45.97s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [35:07<06:35, 49.48s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [35:50<05:33, 47.64s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [36:48<05:03, 50.58s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [37:45<04:23, 52.63s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [38:36<03:28, 52.21s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [39:34<02:41, 53.82s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [40:07<01:35, 47.50s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [41:03<00:50, 50.08s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [42:00<00:00, 52.23s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [42:00<00:00, 50.41s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.6229} | lm_loss 9.6782 | avg. gen lenth: 218.528
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o2-tcommonsenseqa-s1-rFalse --seed 1 --num-out-domain 2
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[nltk_data]   Package punkt is already up-to-date!
[2023-08-12 20:00:06,072] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o2-tcommonsenseqa-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 2
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o2-tcommonsenseqa-s1-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  2%|█▏                                                 | 166/7473 [00:00<00:04, 1657.21it/s]  4%|██▎                                                | 336/7473 [00:00<00:04, 1678.18it/s]  7%|███▍                                               | 504/7473 [00:00<00:04, 1666.24it/s]  9%|████▌                                              | 675/7473 [00:00<00:04, 1680.25it/s] 11%|█████▊                                             | 846/7473 [00:00<00:03, 1688.28it/s] 14%|██████▊                                           | 1018/7473 [00:00<00:03, 1697.39it/s] 16%|███████▉                                          | 1188/7473 [00:00<00:03, 1696.70it/s] 18%|█████████                                         | 1359/7473 [00:00<00:03, 1698.04it/s] 20%|██████████▏                                       | 1529/7473 [00:00<00:03, 1695.40it/s] 23%|███████████▎                                      | 1699/7473 [00:01<00:03, 1656.25it/s] 25%|████████████▍                                     | 1866/7473 [00:01<00:03, 1660.09it/s] 27%|█████████████▌                                    | 2034/7473 [00:01<00:03, 1663.20it/s] 29%|██████████████▋                                   | 2201/7473 [00:01<00:03, 1665.19it/s] 32%|███████████████▊                                  | 2370/7473 [00:01<00:03, 1671.00it/s] 34%|████████████████▉                                 | 2538/7473 [00:01<00:03, 1639.66it/s] 36%|██████████████████▏                               | 2710/7473 [00:01<00:02, 1662.23it/s] 39%|███████████████████▎                              | 2880/7473 [00:01<00:02, 1670.98it/s] 41%|████████████████████▍                             | 3052/7473 [00:01<00:02, 1684.33it/s] 43%|█████████████████████▌                            | 3221/7473 [00:01<00:02, 1673.22it/s] 45%|██████████████████████▋                           | 3389/7473 [00:02<00:02, 1672.57it/s] 48%|███████████████████████▊                          | 3557/7473 [00:02<00:02, 1672.27it/s] 50%|████████████████████████▉                         | 3725/7473 [00:02<00:02, 1668.90it/s] 52%|██████████████████████████                        | 3892/7473 [00:02<00:02, 1667.48it/s] 54%|███████████████████████████▏                      | 4063/7473 [00:02<00:02, 1680.11it/s] 57%|████████████████████████████▋                     | 4295/7473 [00:02<00:01, 1870.06it/s] 61%|██████████████████████████████▍                   | 4551/7473 [00:02<00:01, 2074.96it/s] 64%|████████████████████████████████▏                 | 4804/7473 [00:02<00:01, 2210.15it/s] 68%|█████████████████████████████████▊                | 5061/7473 [00:02<00:01, 2316.81it/s] 71%|███████████████████████████████████▍              | 5304/7473 [00:02<00:00, 2348.92it/s] 74%|█████████████████████████████████████             | 5539/7473 [00:03<00:00, 2053.93it/s] 78%|██████████████████████████████████████▊           | 5795/7473 [00:03<00:00, 2191.55it/s] 81%|████████████████████████████████████████▍         | 6037/7473 [00:03<00:00, 2253.65it/s] 84%|██████████████████████████████████████████        | 6295/7473 [00:03<00:00, 2344.53it/s] 88%|███████████████████████████████████████████▊      | 6546/7473 [00:03<00:00, 2391.97it/s] 91%|█████████████████████████████████████████████▍    | 6799/7473 [00:03<00:00, 2430.81it/s] 94%|███████████████████████████████████████████████▏  | 7053/7473 [00:03<00:00, 2460.55it/s] 98%|████████████████████████████████████████████████▉ | 7308/7473 [00:03<00:00, 2486.04it/s]100%|██████████████████████████████████████████████████| 7473/7473 [00:03<00:00, 1944.92it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.10s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.14s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.87s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.74s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:09<00:04,  4.94s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:09<00:04,  4.97s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.49s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.81s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.32s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.50s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.35s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.54s/it]
[2023-08-12 20:01:00,577] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.82s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.04s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:16<00:00,  5.18s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:16<00:00,  5.34s/it]
[2023-08-12 20:01:12,122] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 20:01:12,123] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 20:01:12,124] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 20:01:12,124] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 20:01:12,124] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 20:01:12,124] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 20:01:12,124] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 20:01:12,124] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 20:01:12,124] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 20:01:12,124] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 20:01:12,124] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 20:01:12,124] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f890f77efa0>
[2023-08-12 20:01:12,124] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f890f77c700>
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 20:01:12,125] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 20:01:12,126] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 20:01:12,126] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.3788719177246094 seconds
Loading extension module utils...
Time to load utils op: 0.3041188716888428 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Answer: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Answer: D: accomplishing

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o2-tcommonsenseqa-s1-rFalse
Loading extension module utils...
Time to load utils op: 0.30420637130737305 seconds
Loading extension module utils...
Time to load utils op: 0.4044463634490967 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:40<32:56, 40.33s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:34<39:00, 48.75s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:21<37:28, 47.85s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [02:47<29:56, 39.05s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [03:21<27:53, 37.19s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [04:04<28:43, 39.16s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [04:51<29:55, 41.75s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [05:18<25:54, 37.01s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [05:59<26:08, 38.25s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [06:57<29:32, 44.32s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [07:12<23:09, 35.64s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [08:08<26:29, 41.83s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [09:06<28:39, 46.48s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [10:01<29:31, 49.20s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [10:58<29:58, 51.38s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [11:52<29:34, 52.19s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [12:40<28:09, 51.19s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [13:38<28:19, 53.10s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [14:29<27:01, 52.31s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [15:24<26:37, 53.24s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [15:42<20:39, 42.74s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [16:19<19:06, 40.95s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [17:15<20:26, 45.43s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [18:11<21:01, 48.52s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [19:00<20:17, 48.70s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [19:56<20:22, 50.95s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [20:45<19:20, 50.45s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [21:41<19:05, 52.08s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [22:36<18:33, 53.02s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [23:30<17:42, 53.11s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [24:26<17:07, 54.08s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [25:06<14:55, 49.77s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [26:01<14:33, 51.41s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [26:56<14:02, 52.67s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [27:52<13:21, 53.44s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [28:48<12:38, 54.18s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [29:44<11:51, 54.72s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [30:29<10:22, 51.88s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [31:24<09:42, 52.94s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [32:06<08:15, 49.55s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [33:02<07:43, 51.50s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [33:53<06:52, 51.51s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [34:44<05:57, 51.10s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [35:06<04:14, 42.44s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [35:38<03:17, 39.46s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [36:34<02:57, 44.40s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [36:53<01:50, 36.77s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [37:53<01:27, 43.52s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [38:34<00:43, 43.03s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [38:48<00:00, 34.15s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [38:48<00:00, 46.57s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.5849} | lm_loss 9.6312 | avg. gen lenth: 205.82
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o3-tcommonsenseqa-s1-rFalse --seed 1 --num-out-domain 3
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-12 20:40:30,135] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o3-tcommonsenseqa-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 3
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o3-tcommonsenseqa-s1-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  2%|▉                                                  | 135/7473 [00:00<00:05, 1349.08it/s]  4%|█▉                                                 | 275/7473 [00:00<00:05, 1373.81it/s]  6%|██▊                                                | 414/7473 [00:00<00:05, 1378.38it/s]  7%|███▊                                               | 553/7473 [00:00<00:05, 1380.21it/s]  9%|████▋                                              | 693/7473 [00:00<00:04, 1384.79it/s] 11%|█████▋                                             | 833/7473 [00:00<00:04, 1389.74it/s] 13%|██████▋                                            | 974/7473 [00:00<00:04, 1394.11it/s] 15%|███████▍                                          | 1116/7473 [00:00<00:04, 1400.33it/s] 17%|████████▍                                         | 1257/7473 [00:00<00:04, 1368.84it/s] 19%|█████████▎                                        | 1395/7473 [00:01<00:04, 1367.59it/s] 21%|██████████▎                                       | 1536/7473 [00:01<00:04, 1380.16it/s] 22%|███████████▏                                      | 1675/7473 [00:01<00:04, 1377.84it/s] 24%|████████████▏                                     | 1815/7473 [00:01<00:04, 1383.14it/s] 26%|█████████████                                     | 1954/7473 [00:01<00:04, 1375.70it/s] 28%|██████████████                                    | 2094/7473 [00:01<00:03, 1381.32it/s] 30%|██████████████▉                                   | 2234/7473 [00:01<00:03, 1384.58it/s] 32%|███████████████▉                                  | 2373/7473 [00:01<00:03, 1384.01it/s] 34%|████████████████▊                                 | 2514/7473 [00:01<00:03, 1390.04it/s] 36%|█████████████████▊                                | 2654/7473 [00:01<00:03, 1356.84it/s] 37%|██████████████████▋                               | 2792/7473 [00:02<00:03, 1363.03it/s] 39%|███████████████████▋                              | 2934/7473 [00:02<00:03, 1377.29it/s] 41%|████████████████████▌                             | 3074/7473 [00:02<00:03, 1382.12it/s] 43%|█████████████████████▍                            | 3213/7473 [00:02<00:03, 1378.51it/s] 45%|██████████████████████▍                           | 3352/7473 [00:02<00:02, 1379.89it/s] 47%|███████████████████████▎                          | 3491/7473 [00:02<00:02, 1377.06it/s] 49%|████████████████████████▎                         | 3630/7473 [00:02<00:02, 1380.39it/s] 51%|█████████████████████████▌                        | 3826/7473 [00:02<00:02, 1553.06it/s] 54%|███████████████████████████                       | 4039/7473 [00:02<00:01, 1723.27it/s] 57%|████████████████████████████▍                     | 4249/7473 [00:02<00:01, 1833.77it/s] 60%|█████████████████████████████▊                    | 4456/7473 [00:03<00:01, 1902.49it/s] 62%|███████████████████████████████▏                  | 4669/7473 [00:03<00:01, 1968.01it/s] 65%|████████████████████████████████▋                 | 4880/7473 [00:03<00:01, 2009.75it/s] 68%|██████████████████████████████████                | 5093/7473 [00:03<00:01, 2043.95it/s] 71%|███████████████████████████████████▍              | 5298/7473 [00:03<00:01, 2027.81it/s] 74%|████████████████████████████████████▊             | 5501/7473 [00:03<00:01, 1555.71it/s] 76%|██████████████████████████████████████▏           | 5713/7473 [00:03<00:01, 1693.78it/s] 79%|███████████████████████████████████████▋          | 5923/7473 [00:03<00:00, 1798.36it/s] 82%|█████████████████████████████████████████         | 6133/7473 [00:03<00:00, 1879.24it/s] 85%|██████████████████████████████████████████▍       | 6347/7473 [00:04<00:00, 1951.38it/s] 88%|███████████████████████████████████████████▊      | 6556/7473 [00:04<00:00, 1989.48it/s] 91%|█████████████████████████████████████████████▎    | 6766/7473 [00:04<00:00, 2018.96it/s] 93%|██████████████████████████████████████████████▋   | 6979/7473 [00:04<00:00, 2048.65it/s] 96%|████████████████████████████████████████████████  | 7189/7473 [00:04<00:00, 2061.65it/s] 99%|█████████████████████████████████████████████████▌| 7399/7473 [00:04<00:00, 2072.95it/s]100%|██████████████████████████████████████████████████| 7473/7473 [00:04<00:00, 1632.92it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.14s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.18s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.27s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.54s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.38s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.36s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.44s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.62s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.69s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.85s/it]
[2023-08-12 20:41:26,599] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.69s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.86s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.89s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.01s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.96s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.13s/it]
[2023-08-12 20:41:37,574] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 20:41:37,574] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fa611dbdb20>
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 20:41:37,575] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fa611dbd8b0>
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 20:41:37,576] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 20:41:37,577] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 20:41:37,577] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 20:41:37,577] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 20:41:37,577] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.3735802173614502 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Answer: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Answer: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Answer: A: office

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o3-tcommonsenseqa-s1-rFalse
Loading extension module utils...
Loading extension module utils...
Time to load utils op: 0.304257869720459 seconds
Time to load utils op: 0.40454936027526855 seconds
Loading extension module utils...
Time to load utils op: 0.4040868282318115 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:56<45:52, 56.17s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:51<44:32, 55.68s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:47<43:33, 55.61s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [03:42<42:33, 55.52s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [04:38<41:41, 55.58s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [05:26<38:54, 53.07s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [05:54<32:07, 44.83s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [06:49<33:41, 48.14s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [07:41<33:49, 49.51s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [08:37<34:12, 51.31s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [09:32<34:02, 52.38s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [09:53<27:15, 43.05s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [10:49<28:56, 46.95s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [11:19<24:59, 41.66s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [12:06<25:16, 43.34s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [12:42<23:18, 41.13s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [13:37<25:00, 45.47s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [14:27<24:51, 46.61s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [14:42<19:10, 37.10s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [14:56<15:03, 30.13s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [15:51<18:14, 37.74s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [16:47<20:07, 43.12s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [17:19<17:59, 39.99s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [17:56<16:54, 39.03s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [18:27<15:15, 36.61s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [19:23<16:59, 42.48s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [20:01<15:46, 41.16s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [20:56<16:34, 45.18s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [21:51<16:52, 48.21s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [22:38<15:52, 47.64s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [23:33<15:47, 49.86s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [24:04<13:17, 44.30s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [24:44<12:13, 43.16s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [25:37<12:15, 45.94s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [26:08<10:22, 41.51s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [27:03<10:39, 45.65s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [27:58<10:28, 48.36s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [28:18<07:57, 39.78s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [28:55<07:10, 39.16s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [29:48<07:12, 43.21s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [30:42<06:58, 46.53s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [31:05<05:14, 39.35s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [32:00<05:08, 44.06s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [32:28<03:55, 39.23s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [32:56<02:59, 35.90s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [33:51<02:46, 41.71s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [34:47<02:17, 45.82s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [35:44<01:38, 49.14s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [36:16<00:44, 44.04s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [36:50<00:00, 41.13s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [36:50<00:00, 44.21s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.5608} | lm_loss 9.6357 | avg. gen lenth: 180.396
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o4-tcommonsenseqa-s1-rFalse --seed 1 --num-out-domain 4
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date![nltk_data]   Package punkt is already up-to-date![nltk_data]   Package punkt is already up-to-date!


[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-12 21:20:58,952] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o4-tcommonsenseqa-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 4
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o4-tcommonsenseqa-s1-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  2%|▊                                                  | 119/7473 [00:00<00:06, 1187.81it/s]  3%|█▋                                                 | 242/7473 [00:00<00:05, 1207.91it/s]  5%|██▍                                                | 363/7473 [00:00<00:05, 1208.56it/s]  6%|███▎                                               | 484/7473 [00:00<00:05, 1204.69it/s]  8%|████▏                                              | 607/7473 [00:00<00:05, 1210.26it/s] 10%|████▉                                              | 731/7473 [00:00<00:05, 1217.93it/s] 11%|█████▊                                             | 853/7473 [00:00<00:05, 1218.15it/s] 13%|██████▋                                            | 976/7473 [00:00<00:05, 1220.51it/s] 15%|███████▎                                          | 1099/7473 [00:00<00:05, 1199.05it/s] 16%|████████▏                                         | 1219/7473 [00:01<00:05, 1198.09it/s] 18%|████████▉                                         | 1342/7473 [00:01<00:05, 1205.00it/s] 20%|█████████▊                                        | 1463/7473 [00:01<00:04, 1203.69it/s] 21%|██████████▌                                       | 1585/7473 [00:01<00:04, 1206.29it/s] 23%|███████████▍                                      | 1708/7473 [00:01<00:04, 1211.34it/s] 24%|████████████▏                                     | 1830/7473 [00:01<00:04, 1210.76it/s] 26%|█████████████                                     | 1952/7473 [00:01<00:04, 1207.99it/s] 28%|█████████████▉                                    | 2074/7473 [00:01<00:04, 1210.39it/s] 29%|██████████████▋                                   | 2196/7473 [00:01<00:04, 1211.46it/s] 31%|███████████████▌                                  | 2318/7473 [00:01<00:04, 1207.61it/s] 33%|████████████████▎                                 | 2440/7473 [00:02<00:04, 1210.16it/s] 34%|█████████████████▏                                | 2562/7473 [00:02<00:04, 1174.63it/s] 36%|█████████████████▉                                | 2685/7473 [00:02<00:04, 1190.53it/s] 38%|██████████████████▉                               | 2838/7473 [00:02<00:03, 1288.68it/s] 40%|████████████████████▏                             | 3025/7473 [00:02<00:03, 1459.82it/s] 43%|█████████████████████▍                            | 3208/7473 [00:02<00:02, 1568.20it/s] 45%|██████████████████████▋                           | 3392/7473 [00:02<00:02, 1647.95it/s] 48%|███████████████████████▉                          | 3577/7473 [00:02<00:02, 1705.68it/s] 50%|█████████████████████████▏                        | 3760/7473 [00:02<00:02, 1740.13it/s] 53%|██████████████████████████▍                       | 3943/7473 [00:02<00:02, 1764.67it/s] 55%|███████████████████████████▌                      | 4127/7473 [00:03<00:01, 1785.29it/s] 58%|████████████████████████████▊                     | 4311/7473 [00:03<00:01, 1800.12it/s] 60%|██████████████████████████████                    | 4495/7473 [00:03<00:01, 1809.54it/s] 63%|███████████████████████████████▎                  | 4679/7473 [00:03<00:01, 1816.05it/s] 65%|████████████████████████████████▌                 | 4861/7473 [00:03<00:01, 1815.07it/s] 68%|█████████████████████████████████▊                | 5045/7473 [00:03<00:01, 1821.56it/s] 70%|██████████████████████████████████▉               | 5231/7473 [00:03<00:01, 1830.61it/s] 72%|████████████████████████████████████▏             | 5415/7473 [00:03<00:01, 1794.19it/s] 75%|█████████████████████████████████████▍            | 5595/7473 [00:03<00:01, 1387.63it/s] 77%|██████████████████████████████████████▋           | 5778/7473 [00:04<00:01, 1495.10it/s] 80%|███████████████████████████████████████▊          | 5959/7473 [00:04<00:00, 1576.52it/s] 82%|█████████████████████████████████████████         | 6143/7473 [00:04<00:00, 1647.18it/s] 85%|██████████████████████████████████████████▎       | 6328/7473 [00:04<00:00, 1702.31it/s] 87%|███████████████████████████████████████████▌      | 6510/7473 [00:04<00:00, 1734.79it/s] 90%|████████████████████████████████████████████▊     | 6693/7473 [00:04<00:00, 1761.65it/s] 92%|██████████████████████████████████████████████    | 6876/7473 [00:04<00:00, 1780.48it/s] 94%|███████████████████████████████████████████████▏  | 7059/7473 [00:04<00:00, 1794.08it/s] 97%|████████████████████████████████████████████████▍ | 7243/7473 [00:04<00:00, 1805.83it/s] 99%|█████████████████████████████████████████████████▋| 7426/7473 [00:04<00:00, 1811.99it/s]100%|██████████████████████████████████████████████████| 7473/7473 [00:04<00:00, 1503.45it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.04s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.09s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.34s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.66s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.00s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.05s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.51s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.46s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.46s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.62s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.50s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.65s/it]
[2023-08-12 21:21:55,080] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.82s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.99s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.79s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.99s/it]
[2023-08-12 21:22:04,925] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 21:22:04,926] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 21:22:04,926] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 21:22:04,926] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 21:22:04,926] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 21:22:04,926] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fe04ce6bfa0>
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 21:22:04,927] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fe04ce85700>
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 21:22:04,928] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 21:22:04,929] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 21:22:04,929] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 21:22:04,929] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 21:22:04,929] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 21:22:04,929] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.40537166595458984 seconds
Loading extension module utils...
Time to load utils op: 0.3066091537475586 seconds
Loading extension module utils...
Time to load utils op: 0.30457615852355957 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Answer: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Answer: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Answer: A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Answer: B: response

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o4-tcommonsenseqa-s1-rFalse
Loading extension module utils...
Time to load utils op: 0.30423474311828613 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:55<45:00, 55.12s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:48<43:20, 54.17s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:42<42:29, 54.25s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [03:37<41:40, 54.37s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [04:20<37:48, 50.40s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [05:09<36:33, 49.84s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [05:35<30:02, 41.93s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [05:59<25:21, 36.24s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [06:53<28:33, 41.78s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [07:42<29:19, 43.99s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [08:35<30:27, 46.87s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [09:10<27:23, 43.25s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [09:43<24:47, 40.19s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [10:39<26:52, 44.80s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [11:00<22:01, 37.76s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [11:55<24:20, 42.94s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [12:48<25:16, 45.95s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [13:20<22:12, 41.65s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [13:43<18:35, 35.99s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [14:38<20:51, 41.73s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [15:00<17:19, 35.84s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [15:44<17:57, 38.48s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [16:23<17:23, 38.66s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [17:18<18:45, 43.28s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [17:58<17:38, 42.35s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [18:12<13:37, 34.07s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [19:04<15:01, 39.22s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [19:38<13:49, 37.70s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [20:11<12:41, 36.26s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [21:07<14:02, 42.12s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [22:01<14:29, 45.79s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [22:17<11:03, 36.85s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [23:11<11:53, 41.97s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [23:52<11:05, 41.60s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [24:47<11:25, 45.70s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [25:37<10:58, 47.02s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [26:32<10:43, 49.47s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [27:27<10:14, 51.18s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [28:22<09:35, 52.32s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [28:54<07:42, 46.27s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [29:51<07:25, 49.50s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [30:36<06:25, 48.14s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [31:31<05:49, 49.98s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [31:51<04:07, 41.18s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [32:28<03:18, 39.72s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [33:22<02:56, 44.22s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [34:01<02:07, 42.55s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [34:40<01:22, 41.45s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [35:14<00:39, 39.37s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [35:24<00:00, 30.59s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [35:24<00:00, 42.50s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.2885} | lm_loss 9.686 | avg. gen lenth: 181.084
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o5-tcommonsenseqa-s1-rFalse --seed 1 --num-out-domain 5
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-12 21:57:52,495] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o5-tcommonsenseqa-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 5
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o5-tcommonsenseqa-s1-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  1%|▋                                                  | 108/7473 [00:00<00:06, 1074.48it/s]  3%|█▍                                                 | 219/7473 [00:00<00:06, 1092.23it/s]  4%|██▏                                                | 329/7473 [00:00<00:06, 1091.88it/s]  6%|██▉                                                | 439/7473 [00:00<00:06, 1087.62it/s]  7%|███▋                                               | 549/7473 [00:00<00:06, 1088.65it/s]  9%|████▍                                              | 658/7473 [00:00<00:06, 1088.65it/s] 10%|█████▎                                             | 770/7473 [00:00<00:06, 1095.90it/s] 12%|██████                                             | 880/7473 [00:00<00:06, 1095.58it/s] 13%|██████▊                                            | 990/7473 [00:00<00:05, 1081.97it/s] 15%|███████▎                                          | 1099/7473 [00:01<00:05, 1084.00it/s] 16%|████████                                          | 1208/7473 [00:01<00:05, 1083.08it/s] 18%|████████▊                                         | 1319/7473 [00:01<00:05, 1088.33it/s] 19%|█████████▌                                        | 1428/7473 [00:01<00:05, 1085.49it/s] 21%|██████████▎                                       | 1539/7473 [00:01<00:05, 1091.99it/s] 22%|███████████                                       | 1649/7473 [00:01<00:05, 1086.28it/s] 24%|███████████▊                                      | 1760/7473 [00:01<00:05, 1091.37it/s] 25%|████████████▌                                     | 1870/7473 [00:01<00:05, 1088.16it/s] 26%|█████████████▏                                    | 1979/7473 [00:01<00:05, 1088.14it/s] 28%|█████████████▉                                    | 2088/7473 [00:01<00:04, 1084.98it/s] 29%|██████████████▋                                   | 2198/7473 [00:02<00:04, 1086.62it/s] 32%|███████████████▊                                  | 2361/7473 [00:02<00:04, 1246.96it/s] 34%|████████████████▊                                 | 2520/7473 [00:02<00:03, 1335.81it/s] 36%|█████████████████▉                                | 2688/7473 [00:02<00:03, 1437.53it/s] 38%|███████████████████                               | 2855/7473 [00:02<00:03, 1505.06it/s] 40%|████████████████████▏                             | 3023/7473 [00:02<00:02, 1556.48it/s] 43%|█████████████████████▎                            | 3189/7473 [00:02<00:02, 1586.01it/s] 45%|██████████████████████▍                           | 3356/7473 [00:02<00:02, 1608.16it/s] 47%|███████████████████████▌                          | 3522/7473 [00:02<00:02, 1621.46it/s] 49%|████████████████████████▋                         | 3689/7473 [00:02<00:02, 1633.59it/s] 52%|█████████████████████████▊                        | 3856/7473 [00:03<00:02, 1641.95it/s] 54%|██████████████████████████▉                       | 4023/7473 [00:03<00:02, 1650.14it/s] 56%|████████████████████████████                      | 4189/7473 [00:03<00:01, 1649.32it/s] 58%|█████████████████████████████▏                    | 4356/7473 [00:03<00:01, 1653.91it/s] 61%|██████████████████████████████▎                   | 4522/7473 [00:03<00:01, 1653.84it/s] 63%|███████████████████████████████▎                  | 4689/7473 [00:03<00:01, 1658.34it/s] 65%|████████████████████████████████▍                 | 4856/7473 [00:03<00:01, 1659.08it/s] 67%|█████████████████████████████████▌                | 5023/7473 [00:03<00:01, 1659.86it/s] 69%|██████████████████████████████████▋               | 5191/7473 [00:03<00:01, 1663.27it/s] 72%|███████████████████████████████████▊              | 5358/7473 [00:03<00:01, 1625.68it/s] 74%|████████████████████████████████████▉             | 5521/7473 [00:04<00:01, 1247.41it/s] 76%|██████████████████████████████████████            | 5688/7473 [00:04<00:01, 1348.56it/s] 78%|███████████████████████████████████████▏          | 5855/7473 [00:04<00:01, 1431.30it/s] 81%|████████████████████████████████████████▎         | 6020/7473 [00:04<00:00, 1489.66it/s] 83%|█████████████████████████████████████████▍        | 6188/7473 [00:04<00:00, 1541.56it/s] 85%|██████████████████████████████████████████▌       | 6356/7473 [00:04<00:00, 1579.73it/s] 87%|███████████████████████████████████████████▋      | 6523/7473 [00:04<00:00, 1602.97it/s] 90%|████████████████████████████████████████████▊     | 6690/7473 [00:04<00:00, 1622.20it/s] 92%|█████████████████████████████████████████████▊    | 6856/7473 [00:04<00:00, 1632.89it/s] 94%|██████████████████████████████████████████████▉   | 7024/7473 [00:05<00:00, 1646.21it/s] 96%|████████████████████████████████████████████████  | 7190/7473 [00:05<00:00, 1646.65it/s] 98%|█████████████████████████████████████████████████▏| 7357/7473 [00:05<00:00, 1652.96it/s]100%|██████████████████████████████████████████████████| 7473/7473 [00:05<00:00, 1406.15it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:04<00:09,  4.95s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.17s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.58s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.57s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:09<00:04,  5.00s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.03s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.48s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.39s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.34s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.51s/it]
[2023-08-12 21:58:48,376] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.42s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.60s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.84s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.03s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.74s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.94s/it]
[2023-08-12 21:58:59,554] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 21:58:59,555] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fd98f20efa0>
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 21:58:59,556] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fd98f22f700>
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 21:58:59,557] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 21:58:59,557] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.3790452480316162 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Answer: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Answer: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Answer: A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Answer: B: response

Input: The lizard frightened the hiker, it's movements made what rustle? Choices:  A: garden B: trees C: books D: rocks E: bushes
Answer: E: bushes

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o5-tcommonsenseqa-s1-rFalse
Loading extension module utils...
Time to load utils op: 0.3044147491455078 seconds
Loading extension module utils...
Time to load utils op: 0.3046276569366455 seconds
Loading extension module utils...
Time to load utils op: 0.30423474311828613 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:54<44:35, 54.60s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:47<42:50, 53.55s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:40<41:50, 53.41s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [03:33<40:45, 53.17s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [04:27<40:11, 53.59s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [05:05<35:14, 48.05s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [05:32<29:42, 41.46s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [06:26<31:41, 45.27s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [06:49<26:15, 38.42s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [07:12<22:26, 33.65s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [07:49<22:30, 34.64s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [08:33<23:37, 37.30s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [08:51<19:25, 31.51s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [09:46<23:10, 38.63s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [10:22<22:06, 37.89s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [11:16<24:11, 42.68s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [11:48<21:48, 39.66s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [12:42<23:26, 43.95s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [13:32<23:39, 45.80s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [14:25<23:54, 47.82s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [15:16<23:35, 48.81s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [16:02<22:18, 47.80s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [16:55<22:13, 49.39s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [17:30<19:36, 45.25s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [17:59<16:48, 40.36s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [18:30<14:57, 37.40s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [19:24<16:14, 42.36s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [20:18<16:49, 45.89s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [21:12<16:55, 48.38s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [21:38<13:54, 41.74s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [22:02<11:30, 36.35s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [22:55<12:25, 41.40s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [23:50<12:50, 45.33s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [24:43<12:45, 47.87s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [25:34<12:08, 48.58s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [26:19<11:07, 47.68s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [27:10<10:31, 48.61s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [28:04<10:02, 50.18s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [28:43<08:34, 46.73s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [29:37<08:10, 49.01s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [30:23<07:14, 48.29s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [31:17<06:39, 49.88s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [31:46<05:05, 43.70s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [32:27<04:17, 42.87s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [33:15<03:40, 44.20s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [34:09<03:08, 47.21s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [35:03<02:28, 49.38s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [35:53<01:38, 49.41s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [36:46<00:50, 50.62s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [37:06<00:00, 41.52s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [37:06<00:00, 44.54s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.3953} | lm_loss 9.6544 | avg. gen lenth: 186.476
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o6-tcommonsenseqa-s1-rFalse --seed 1 --num-out-domain 6
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-12 22:37:56,438] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o6-tcommonsenseqa-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 6
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o6-tcommonsenseqa-s1-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  1%|▋                                                    | 93/7473 [00:00<00:07, 929.93it/s]  3%|█▎                                                  | 188/7473 [00:00<00:07, 935.81it/s]  4%|█▉                                                  | 282/7473 [00:00<00:07, 937.55it/s]  5%|██▌                                                 | 377/7473 [00:00<00:07, 940.59it/s]  6%|███▎                                                | 472/7473 [00:00<00:07, 938.21it/s]  8%|███▉                                                | 567/7473 [00:00<00:07, 940.94it/s]  9%|████▌                                               | 662/7473 [00:00<00:07, 939.46it/s] 10%|█████▎                                              | 758/7473 [00:00<00:07, 945.48it/s] 11%|█████▉                                              | 853/7473 [00:00<00:07, 924.71it/s] 13%|██████▌                                             | 947/7473 [00:01<00:07, 927.90it/s] 14%|███████                                            | 1043/7473 [00:01<00:06, 936.50it/s] 15%|███████▊                                           | 1138/7473 [00:01<00:06, 940.07it/s] 16%|████████▍                                          | 1233/7473 [00:01<00:06, 937.72it/s] 18%|█████████                                          | 1328/7473 [00:01<00:06, 940.89it/s] 19%|█████████▋                                         | 1423/7473 [00:01<00:06, 938.22it/s] 20%|██████████▎                                        | 1519/7473 [00:01<00:06, 942.81it/s] 22%|███████████                                        | 1614/7473 [00:01<00:06, 937.85it/s] 23%|███████████▋                                       | 1710/7473 [00:01<00:06, 941.26it/s] 24%|████████████▏                                     | 1830/7473 [00:01<00:05, 1016.55it/s] 26%|█████████████▏                                    | 1972/7473 [00:02<00:04, 1134.44it/s] 28%|██████████████▏                                   | 2116/7473 [00:02<00:04, 1223.39it/s] 30%|███████████████▏                                  | 2261/7473 [00:02<00:04, 1289.69it/s] 32%|████████████████                                  | 2405/7473 [00:02<00:03, 1333.51it/s] 34%|████████████████▉                                 | 2539/7473 [00:02<00:03, 1323.22it/s] 36%|█████████████████▉                                | 2685/7473 [00:02<00:03, 1361.99it/s] 38%|██████████████████▉                               | 2829/7473 [00:02<00:03, 1384.60it/s] 40%|███████████████████▉                              | 2974/7473 [00:02<00:03, 1402.20it/s] 42%|████████████████████▊                             | 3117/7473 [00:02<00:03, 1410.02it/s] 44%|█████████████████████▊                            | 3260/7473 [00:02<00:02, 1414.95it/s] 46%|██████████████████████▊                           | 3402/7473 [00:03<00:02, 1415.99it/s] 47%|███████████████████████▋                          | 3544/7473 [00:03<00:02, 1414.26it/s] 49%|████████████████████████▋                         | 3686/7473 [00:03<00:02, 1412.92it/s] 51%|█████████████████████████▋                        | 3830/7473 [00:03<00:02, 1418.81it/s] 53%|██████████████████████████▌                       | 3973/7473 [00:03<00:02, 1420.48it/s] 55%|███████████████████████████▌                      | 4116/7473 [00:03<00:02, 1422.88it/s] 57%|████████████████████████████▌                     | 4260/7473 [00:03<00:02, 1425.17it/s] 59%|█████████████████████████████▍                    | 4403/7473 [00:03<00:02, 1425.60it/s] 61%|██████████████████████████████▍                   | 4546/7473 [00:03<00:02, 1425.75it/s] 63%|███████████████████████████████▎                  | 4689/7473 [00:03<00:01, 1426.08it/s] 65%|████████████████████████████████▎                 | 4832/7473 [00:04<00:01, 1427.07it/s] 67%|█████████████████████████████████▎                | 4975/7473 [00:04<00:01, 1427.28it/s] 68%|██████████████████████████████████▏               | 5119/7473 [00:04<00:01, 1429.28it/s] 70%|███████████████████████████████████▏              | 5262/7473 [00:04<00:01, 1395.88it/s] 72%|████████████████████████████████████▏             | 5402/7473 [00:04<00:01, 1396.44it/s] 74%|█████████████████████████████████████             | 5542/7473 [00:04<00:01, 1073.65it/s] 76%|██████████████████████████████████████            | 5684/7473 [00:04<00:01, 1158.54it/s] 78%|██████████████████████████████████████▉           | 5826/7473 [00:04<00:01, 1225.83it/s] 80%|███████████████████████████████████████▉          | 5967/7473 [00:04<00:01, 1274.77it/s] 82%|████████████████████████████████████████▉         | 6111/7473 [00:05<00:01, 1320.39it/s] 84%|█████████████████████████████████████████▊        | 6255/7473 [00:05<00:00, 1351.72it/s] 86%|██████████████████████████████████████████▊       | 6398/7473 [00:05<00:00, 1371.83it/s] 88%|███████████████████████████████████████████▊      | 6542/7473 [00:05<00:00, 1391.23it/s] 89%|████████████████████████████████████████████▋     | 6685/7473 [00:05<00:00, 1399.89it/s] 91%|█████████████████████████████████████████████▋    | 6827/7473 [00:05<00:00, 1404.70it/s] 93%|██████████████████████████████████████████████▋   | 6971/7473 [00:05<00:00, 1414.64it/s] 95%|███████████████████████████████████████████████▌  | 7114/7473 [00:05<00:00, 1402.42it/s] 97%|████████████████████████████████████████████████▌ | 7257/7473 [00:05<00:00, 1409.81it/s] 99%|█████████████████████████████████████████████████▌| 7400/7473 [00:05<00:00, 1414.08it/s]100%|██████████████████████████████████████████████████| 7473/7473 [00:06<00:00, 1244.87it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.17s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.08s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.43s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.59s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:04,  4.99s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:09<00:04,  4.92s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.23s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.44s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.33s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.53s/it]
[2023-08-12 22:38:53,149] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.34s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.51s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.67s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.84s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.84s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.02s/it]
[2023-08-12 22:39:03,024] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 22:39:03,024] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 22:39:03,025] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 22:39:03,025] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 22:39:03,025] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 22:39:03,025] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 22:39:03,025] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 22:39:03,025] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 22:39:03,025] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 22:39:03,025] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 22:39:03,025] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 22:39:03,025] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f5470841fa0>
[2023-08-12 22:39:03,025] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 22:39:03,025] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 22:39:03,025] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 22:39:03,025] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 22:39:03,025] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 22:39:03,025] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 22:39:03,025] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 22:39:03,025] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 22:39:03,025] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f5470832700>
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 22:39:03,026] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 22:39:03,026] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.39165234565734863 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Answer: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Answer: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Answer: A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Answer: B: response

Input: The lizard frightened the hiker, it's movements made what rustle? Choices:  A: garden B: trees C: books D: rocks E: bushes
Answer: E: bushes

Input: The man spent big money and time maintaining his lawn, it was part of keeping up with the Joneses where? Choices:  A: front yard B: suburbia C: neighborhood D: back yard E: golf course
Answer: B: suburbia

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o6-tcommonsenseqa-s1-rFalse
Loading extension module utils...
Time to load utils op: 0.3046133518218994 seconds
Loading extension module utils...
Time to load utils op: 0.30432915687561035 seconds
Loading extension module utils...
Time to load utils op: 0.3043208122253418 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:53<43:55, 53.79s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:23<31:52, 39.84s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:14<35:07, 44.84s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [02:47<30:43, 40.08s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [03:27<30:09, 40.20s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [04:20<32:32, 44.37s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [05:12<33:41, 47.02s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [05:49<30:38, 43.77s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [06:41<31:44, 46.45s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [06:54<24:03, 36.08s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [07:41<25:36, 39.41s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [08:34<27:30, 43.44s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [09:27<28:39, 46.47s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [10:04<26:02, 43.40s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [10:30<22:15, 38.17s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [11:22<23:57, 42.29s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [12:14<24:55, 45.31s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [12:33<19:55, 37.35s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [13:06<18:35, 35.99s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [13:54<19:47, 39.60s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [14:22<17:27, 36.11s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [15:13<19:02, 40.79s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [15:56<18:39, 41.48s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [16:48<19:18, 44.55s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [17:40<19:30, 46.83s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [18:32<19:18, 48.28s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [19:25<19:02, 49.67s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [20:04<17:00, 46.40s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [20:27<13:51, 39.59s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [20:53<11:46, 35.34s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [21:45<12:48, 40.43s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [22:34<12:54, 43.03s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [23:27<13:00, 45.89s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [24:20<12:49, 48.08s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [25:13<12:23, 49.54s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [25:45<10:21, 44.36s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [26:21<09:04, 41.85s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [26:54<07:51, 39.30s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [27:46<07:52, 42.96s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [28:19<06:40, 40.05s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [28:53<05:42, 38.07s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [29:38<05:22, 40.36s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [30:16<04:37, 39.61s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [31:09<04:20, 43.45s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [31:52<03:36, 43.34s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [32:43<03:03, 45.81s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [33:36<02:23, 47.82s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [33:57<01:19, 39.84s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [34:36<00:39, 39.73s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [35:29<00:00, 43.60s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [35:29<00:00, 42.59s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.3307} | lm_loss 9.6998 | avg. gen lenth: 193.86
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o7-tcommonsenseqa-s1-rFalse --seed 1 --num-out-domain 7
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-12 23:18:35,419] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o7-tcommonsenseqa-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 7
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o7-tcommonsenseqa-s1-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  1%|▌                                                    | 82/7473 [00:00<00:09, 818.78it/s]  2%|█▏                                                  | 166/7473 [00:00<00:08, 827.92it/s]  3%|█▋                                                  | 250/7473 [00:00<00:08, 827.67it/s]  4%|██▎                                                 | 335/7473 [00:00<00:08, 831.91it/s]  6%|██▉                                                 | 419/7473 [00:00<00:08, 829.59it/s]  7%|███▍                                                | 502/7473 [00:00<00:08, 826.09it/s]  8%|████                                                | 587/7473 [00:00<00:08, 831.23it/s]  9%|████▋                                               | 671/7473 [00:00<00:08, 831.74it/s] 10%|█████▎                                              | 755/7473 [00:00<00:08, 819.13it/s] 11%|█████▊                                              | 838/7473 [00:01<00:08, 821.93it/s] 12%|██████▍                                             | 922/7473 [00:01<00:07, 825.25it/s] 13%|██████▊                                            | 1006/7473 [00:01<00:07, 829.31it/s] 15%|███████▍                                           | 1091/7473 [00:01<00:07, 834.39it/s] 16%|████████                                           | 1175/7473 [00:01<00:07, 831.60it/s] 17%|████████▌                                          | 1259/7473 [00:01<00:07, 831.17it/s] 18%|█████████▏                                         | 1343/7473 [00:01<00:07, 833.16it/s] 19%|█████████▋                                         | 1427/7473 [00:01<00:07, 829.19it/s] 20%|██████████▎                                        | 1512/7473 [00:01<00:07, 832.88it/s] 21%|██████████▉                                        | 1596/7473 [00:01<00:07, 826.73it/s] 23%|███████████▍                                       | 1684/7473 [00:02<00:06, 841.80it/s] 24%|████████████▎                                      | 1811/7473 [00:02<00:05, 968.32it/s] 26%|████████████▉                                     | 1935/7473 [00:02<00:05, 1049.01it/s] 28%|█████████████▊                                    | 2063/7473 [00:02<00:04, 1117.44it/s] 29%|██████████████▋                                   | 2189/7473 [00:02<00:04, 1158.05it/s] 31%|███████████████▍                                  | 2316/7473 [00:02<00:04, 1191.17it/s] 33%|████████████████▎                                 | 2444/7473 [00:02<00:04, 1217.48it/s] 34%|█████████████████▏                                | 2566/7473 [00:02<00:04, 1192.73it/s] 36%|██████████████████                                | 2694/7473 [00:02<00:03, 1218.31it/s] 38%|██████████████████▊                               | 2821/7473 [00:02<00:03, 1232.15it/s] 39%|███████████████████▋                              | 2950/7473 [00:03<00:03, 1248.35it/s] 41%|████████████████████▌                             | 3077/7473 [00:03<00:03, 1253.56it/s] 43%|█████████████████████▍                            | 3203/7473 [00:03<00:03, 1240.01it/s] 45%|██████████████████████▎                           | 3331/7473 [00:03<00:03, 1249.19it/s] 46%|███████████████████████                           | 3456/7473 [00:03<00:03, 1246.53it/s] 48%|███████████████████████▉                          | 3583/7473 [00:03<00:03, 1252.02it/s] 50%|████████████████████████▊                         | 3709/7473 [00:03<00:03, 1248.93it/s] 51%|█████████████████████████▋                        | 3836/7473 [00:03<00:02, 1253.76it/s] 53%|██████████████████████████▌                       | 3962/7473 [00:03<00:02, 1254.41it/s] 55%|███████████████████████████▎                      | 4090/7473 [00:03<00:02, 1261.04it/s] 56%|████████████████████████████▏                     | 4217/7473 [00:04<00:02, 1254.74it/s] 58%|█████████████████████████████                     | 4344/7473 [00:04<00:02, 1257.43it/s] 60%|█████████████████████████████▉                    | 4470/7473 [00:04<00:02, 1256.87it/s] 62%|██████████████████████████████▊                   | 4597/7473 [00:04<00:02, 1257.97it/s] 63%|███████████████████████████████▌                  | 4723/7473 [00:04<00:02, 1243.63it/s] 65%|████████████████████████████████▍                 | 4848/7473 [00:04<00:02, 1243.33it/s] 67%|█████████████████████████████████▎                | 4974/7473 [00:04<00:02, 1245.63it/s] 68%|██████████████████████████████████▏               | 5101/7473 [00:04<00:01, 1251.30it/s] 70%|██████████████████████████████████▉               | 5229/7473 [00:04<00:01, 1258.61it/s] 72%|███████████████████████████████████▊              | 5355/7473 [00:04<00:01, 1198.76it/s] 73%|█████████████████████████████████████▎             | 5476/7473 [00:05<00:02, 997.72it/s] 75%|█████████████████████████████████████▍            | 5602/7473 [00:05<00:01, 1062.94it/s] 77%|██████████████████████████████████████▎           | 5728/7473 [00:05<00:01, 1113.54it/s] 78%|███████████████████████████████████████▏          | 5854/7473 [00:05<00:01, 1151.56it/s] 80%|███████████████████████████████████████▉          | 5977/7473 [00:05<00:01, 1173.06it/s] 82%|████████████████████████████████████████▊         | 6104/7473 [00:05<00:01, 1199.40it/s] 83%|█████████████████████████████████████████▋        | 6229/7473 [00:05<00:01, 1213.99it/s] 85%|██████████████████████████████████████████▌       | 6354/7473 [00:05<00:00, 1223.87it/s] 87%|███████████████████████████████████████████▎      | 6479/7473 [00:05<00:00, 1229.16it/s] 88%|████████████████████████████████████████████▏     | 6606/7473 [00:06<00:00, 1238.21it/s] 90%|█████████████████████████████████████████████     | 6732/7473 [00:06<00:00, 1243.99it/s] 92%|█████████████████████████████████████████████▉    | 6857/7473 [00:06<00:00, 1243.67it/s] 93%|██████████████████████████████████████████████▋   | 6984/7473 [00:06<00:00, 1250.97it/s] 95%|███████████████████████████████████████████████▌  | 7110/7473 [00:06<00:00, 1250.29it/s] 97%|████████████████████████████████████████████████▍ | 7237/7473 [00:06<00:00, 1254.19it/s] 99%|█████████████████████████████████████████████████▎| 7363/7473 [00:06<00:00, 1253.93it/s]100%|██████████████████████████████████████████████████| 7473/7473 [00:06<00:00, 1109.27it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.40s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.05s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.41s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.17s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.27s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:04,  5.00s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.30s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.09s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.62s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.81s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.53s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.66s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.77s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.92s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.63s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.76s/it]
[2023-08-12 23:19:36,630] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-12 23:19:43,400] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 23:19:43,401] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 23:19:43,402] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 23:19:43,402] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 23:19:43,402] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 23:19:43,402] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 23:19:43,402] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 23:19:43,402] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 23:19:43,402] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 23:19:43,402] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 23:19:43,403] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 23:19:43,403] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f80c1374b20>
[2023-08-12 23:19:43,403] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 23:19:43,403] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 23:19:43,403] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 23:19:43,403] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 23:19:43,403] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 23:19:43,403] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 23:19:43,403] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 23:19:43,403] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 23:19:43,403] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 23:19:43,403] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 23:19:43,403] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 23:19:43,403] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 23:19:43,403] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 23:19:43,403] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 23:19:43,403] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 23:19:43,403] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 23:19:43,403] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 23:19:43,403] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 23:19:43,403] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 23:19:43,403] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 23:19:43,403] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 23:19:43,403] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 23:19:43,403] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 23:19:43,403] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 23:19:43,403] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 23:19:43,404] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 23:19:43,404] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 23:19:43,404] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 23:19:43,404] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 23:19:43,404] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 23:19:43,404] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 23:19:43,404] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 23:19:43,404] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f80c13748b0>
[2023-08-12 23:19:43,404] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 23:19:43,404] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 23:19:43,404] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 23:19:43,404] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 23:19:43,404] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 23:19:43,404] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 23:19:43,404] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 23:19:43,404] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 23:19:43,404] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 23:19:43,404] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 23:19:43,404] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 23:19:43,404] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 23:19:43,404] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 23:19:43,404] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 23:19:43,404] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 23:19:43,404] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 23:19:43,404] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 23:19:43,404] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 23:19:43,404] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 23:19:43,405] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 23:19:43,405] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 23:19:43,405] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 23:19:43,405] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Loading extension module utils...
Time to load utils op: 0.41248559951782227 seconds
Time to load utils op: 0.4042072296142578 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Answer: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Answer: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Answer: A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Answer: B: response

Input: The lizard frightened the hiker, it's movements made what rustle? Choices:  A: garden B: trees C: books D: rocks E: bushes
Answer: E: bushes

Input: The man spent big money and time maintaining his lawn, it was part of keeping up with the Joneses where? Choices:  A: front yard B: suburbia C: neighborhood D: back yard E: golf course
Answer: B: suburbia

Input: What would a human do if they want to get to a store that he or she can see? Choices:  A: cross road B: see around C: drink coffee D: dream dreams E: think critically
Answer: A: cross road

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o7-tcommonsenseqa-s1-rFalse
Loading extension module utils...
Time to load utils op: 0.40462589263916016 seconds
Loading extension module utils...
Time to load utils op: 0.5046489238739014 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:52<42:34, 52.14s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:42<40:55, 51.16s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:33<40:01, 51.09s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [03:03<32:53, 42.91s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [03:55<34:30, 46.00s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [04:47<35:12, 48.02s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [05:32<33:46, 47.13s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [06:04<29:30, 42.16s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [06:56<30:54, 45.24s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [07:46<31:17, 46.95s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [08:37<31:18, 48.18s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [09:24<30:10, 47.65s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [10:11<29:16, 47.46s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [10:37<24:30, 40.85s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [11:27<25:34, 43.85s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [12:18<26:03, 45.97s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [13:11<26:20, 47.91s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [13:51<24:16, 45.53s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [14:42<24:27, 47.33s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [15:34<24:22, 48.74s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [16:25<23:53, 49.42s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [17:16<23:19, 49.98s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [18:08<22:44, 50.55s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [18:53<21:08, 48.81s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [19:13<16:46, 40.26s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [19:49<15:33, 38.92s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [20:05<12:13, 31.90s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [20:37<11:44, 32.00s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [21:08<11:04, 31.65s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [21:34<09:59, 29.97s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [22:07<09:48, 30.99s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [22:59<11:08, 37.13s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [23:16<08:50, 31.19s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [24:05<09:46, 36.65s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [24:57<10:18, 41.21s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [25:49<10:19, 44.24s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [26:23<08:56, 41.25s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [27:14<08:50, 44.23s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [27:46<07:26, 40.61s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [28:39<07:21, 44.14s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [29:29<06:55, 46.15s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [30:21<06:21, 47.74s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [31:14<05:44, 49.24s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [32:05<05:00, 50.01s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [32:34<03:38, 43.70s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [33:25<03:03, 45.82s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [34:00<02:07, 42.60s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [34:51<01:30, 45.20s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [35:43<00:47, 47.12s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [36:07<00:00, 40.28s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [36:07<00:00, 43.36s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.3605} | lm_loss 9.7127 | avg. gen lenth: 203.932
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o8-tcommonsenseqa-s1-rFalse --seed 1 --num-out-domain 8
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-12 23:56:43,948] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o8-tcommonsenseqa-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 8
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o8-tcommonsenseqa-s1-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  1%|▌                                                    | 73/7473 [00:00<00:10, 726.24it/s]  2%|█                                                   | 148/7473 [00:00<00:09, 736.29it/s]  3%|█▌                                                  | 224/7473 [00:00<00:09, 745.41it/s]  4%|██                                                  | 299/7473 [00:00<00:09, 742.90it/s]  5%|██▌                                                 | 374/7473 [00:00<00:09, 743.77it/s]  6%|███                                                 | 449/7473 [00:00<00:09, 741.41it/s]  7%|███▋                                                | 524/7473 [00:00<00:09, 740.96it/s]  8%|████▏                                               | 599/7473 [00:00<00:09, 742.77it/s]  9%|████▋                                               | 674/7473 [00:00<00:09, 729.11it/s] 10%|█████▏                                              | 749/7473 [00:01<00:09, 733.06it/s] 11%|█████▋                                              | 823/7473 [00:01<00:09, 734.32it/s] 12%|██████▏                                             | 898/7473 [00:01<00:08, 738.28it/s] 13%|██████▊                                             | 974/7473 [00:01<00:08, 741.92it/s] 14%|███████▏                                           | 1049/7473 [00:01<00:08, 743.57it/s] 15%|███████▋                                           | 1124/7473 [00:01<00:08, 745.29it/s] 16%|████████▏                                          | 1199/7473 [00:01<00:08, 742.79it/s] 17%|████████▋                                          | 1274/7473 [00:01<00:08, 742.27it/s] 18%|█████████▏                                         | 1350/7473 [00:01<00:08, 745.13it/s] 19%|█████████▋                                         | 1425/7473 [00:01<00:08, 736.70it/s] 20%|██████████▏                                        | 1500/7473 [00:02<00:08, 738.96it/s] 21%|██████████▊                                        | 1591/7473 [00:02<00:07, 787.92it/s] 23%|███████████▋                                       | 1704/7473 [00:02<00:06, 888.34it/s] 24%|████████████▍                                      | 1818/7473 [00:02<00:05, 961.46it/s] 26%|████████████▉                                     | 1929/7473 [00:02<00:05, 1004.52it/s] 27%|█████████████▋                                    | 2043/7473 [00:02<00:05, 1043.78it/s] 29%|██████████████▍                                   | 2156/7473 [00:02<00:04, 1067.34it/s] 30%|███████████████▏                                  | 2269/7473 [00:02<00:04, 1084.68it/s] 32%|███████████████▉                                  | 2382/7473 [00:02<00:04, 1097.07it/s] 33%|████████████████▋                                 | 2496/7473 [00:02<00:04, 1107.95it/s] 35%|█████████████████▍                                | 2607/7473 [00:03<00:04, 1078.76it/s] 36%|██████████████████▏                               | 2721/7473 [00:03<00:04, 1096.46it/s] 38%|██████████████████▉                               | 2831/7473 [00:03<00:04, 1092.93it/s] 39%|███████████████████▋                              | 2944/7473 [00:03<00:04, 1103.29it/s] 41%|████████████████████▍                             | 3057/7473 [00:03<00:03, 1110.85it/s] 42%|█████████████████████▏                            | 3169/7473 [00:03<00:03, 1113.37it/s] 44%|█████████████████████▉                            | 3282/7473 [00:03<00:03, 1116.95it/s] 45%|██████████████████████▋                           | 3394/7473 [00:03<00:03, 1113.46it/s] 47%|███████████████████████▍                          | 3506/7473 [00:03<00:03, 1082.26it/s] 48%|████████████████████████▏                         | 3620/7473 [00:03<00:03, 1096.95it/s] 50%|████████████████████████▉                         | 3732/7473 [00:04<00:03, 1101.45it/s] 51%|█████████████████████████▋                        | 3845/7473 [00:04<00:03, 1107.03it/s] 53%|██████████████████████████▍                       | 3956/7473 [00:04<00:03, 1106.65it/s] 54%|███████████████████████████▏                      | 4069/7473 [00:04<00:03, 1113.38it/s] 56%|███████████████████████████▉                      | 4181/7473 [00:04<00:02, 1111.73it/s] 57%|████████████████████████████▋                     | 4293/7473 [00:04<00:02, 1101.33it/s] 59%|█████████████████████████████▍                    | 4404/7473 [00:04<00:02, 1103.56it/s] 60%|██████████████████████████████▏                   | 4516/7473 [00:04<00:02, 1106.48it/s] 62%|██████████████████████████████▉                   | 4628/7473 [00:04<00:02, 1110.46it/s] 63%|███████████████████████████████▋                  | 4740/7473 [00:04<00:02, 1111.55it/s] 65%|████████████████████████████████▍                 | 4852/7473 [00:05<00:02, 1112.21it/s] 66%|█████████████████████████████████▏                | 4964/7473 [00:05<00:02, 1111.26it/s] 68%|█████████████████████████████████▉                | 5077/7473 [00:05<00:02, 1115.04it/s] 69%|██████████████████████████████████▋               | 5190/7473 [00:05<00:02, 1117.21it/s] 71%|███████████████████████████████████▍              | 5302/7473 [00:05<00:02, 1066.15it/s] 72%|████████████████████████████████████▏             | 5415/7473 [00:05<00:01, 1082.60it/s] 74%|█████████████████████████████████████▋             | 5524/7473 [00:05<00:02, 808.85it/s] 75%|██████████████████████████████████████▍            | 5634/7473 [00:05<00:02, 877.55it/s] 77%|███████████████████████████████████████▏           | 5746/7473 [00:06<00:01, 938.02it/s] 78%|███████████████████████████████████████▉           | 5857/7473 [00:06<00:01, 981.79it/s] 80%|███████████████████████████████████████▉          | 5967/7473 [00:06<00:01, 1013.39it/s] 81%|████████████████████████████████████████▋         | 6081/7473 [00:06<00:01, 1046.92it/s] 83%|█████████████████████████████████████████▍        | 6194/7473 [00:06<00:01, 1069.05it/s] 84%|██████████████████████████████████████████▏       | 6307/7473 [00:06<00:01, 1084.89it/s] 86%|██████████████████████████████████████████▉       | 6419/7473 [00:06<00:00, 1093.16it/s] 87%|███████████████████████████████████████████▋      | 6532/7473 [00:06<00:00, 1103.07it/s] 89%|████████████████████████████████████████████▍     | 6644/7473 [00:06<00:00, 1105.50it/s] 90%|█████████████████████████████████████████████▏    | 6757/7473 [00:06<00:00, 1111.01it/s] 92%|█████████████████████████████████████████████▉    | 6869/7473 [00:07<00:00, 1107.65it/s] 93%|██████████████████████████████████████████████▋   | 6982/7473 [00:07<00:00, 1113.60it/s] 95%|███████████████████████████████████████████████▍  | 7094/7473 [00:07<00:00, 1112.52it/s] 96%|████████████████████████████████████████████████▏ | 7206/7473 [00:07<00:00, 1113.50it/s] 98%|████████████████████████████████████████████████▉ | 7319/7473 [00:07<00:00, 1116.02it/s] 99%|█████████████████████████████████████████████████▋| 7431/7473 [00:07<00:00, 1116.81it/s]100%|███████████████████████████████████████████████████| 7473/7473 [00:07<00:00, 989.73it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.30s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.42s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.53s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.69s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.18s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.38s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.49s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.69s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.67s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.82s/it]
[2023-08-12 23:57:43,053] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.88s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.02s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:16<00:00,  5.28s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:16<00:00,  5.34s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.15s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.30s/it]
[2023-08-12 23:58:00,096] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-12 23:58:00,097] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-12 23:58:00,097] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-12 23:58:00,097] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-12 23:58:00,097] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-12 23:58:00,097] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-12 23:58:00,098] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-12 23:58:00,098] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-12 23:58:00,098] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-12 23:58:00,098] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-12 23:58:00,098] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-12 23:58:00,098] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f719d2718b0>
[2023-08-12 23:58:00,098] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-12 23:58:00,098] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-12 23:58:00,098] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-12 23:58:00,098] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-12 23:58:00,098] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-12 23:58:00,098] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-12 23:58:00,098] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-12 23:58:00,098] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-12 23:58:00,098] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-12 23:58:00,098] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-12 23:58:00,098] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-12 23:58:00,098] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-12 23:58:00,098] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-12 23:58:00,098] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-12 23:58:00,098] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-12 23:58:00,098] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-12 23:58:00,098] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f719d279070>
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-12 23:58:00,099] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-12 23:58:00,100] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-12 23:58:00,100] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-12 23:58:00,100] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-12 23:58:00,100] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.48035240173339844 seconds
Loading extension module utils...
Time to load utils op: 0.40442705154418945 seconds
Loading extension module utils...
Time to load utils op: 0.4029364585876465 seconds
Loading extension module utils...
Time to load utils op: 0.5047554969787598 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Answer: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Answer: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Answer: A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Answer: B: response

Input: The lizard frightened the hiker, it's movements made what rustle? Choices:  A: garden B: trees C: books D: rocks E: bushes
Answer: E: bushes

Input: The man spent big money and time maintaining his lawn, it was part of keeping up with the Joneses where? Choices:  A: front yard B: suburbia C: neighborhood D: back yard E: golf course
Answer: B: suburbia

Input: What would a human do if they want to get to a store that he or she can see? Choices:  A: cross road B: see around C: drink coffee D: dream dreams E: think critically
Answer: A: cross road

Input: Where would you grab an object contained by a doorway? Choices:  A: television B: control panel C: opening doors D: doorknob E: doorway
Answer: E: doorway

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o8-tcommonsenseqa-s1-rFalse
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:51<42:25, 51.95s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:38<39:12, 49.01s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:30<39:18, 50.17s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [03:22<38:56, 50.78s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [04:13<38:10, 50.90s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [04:46<32:59, 44.98s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [05:38<33:53, 47.29s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [06:29<33:45, 48.22s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [06:50<27:07, 39.70s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [07:41<28:50, 43.25s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [08:32<29:39, 45.63s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [08:56<24:46, 39.13s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [09:13<20:04, 32.55s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [10:04<22:52, 38.13s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [10:56<24:33, 42.10s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [11:25<21:39, 38.22s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [12:17<23:15, 42.28s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [13:07<23:53, 44.79s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [13:58<24:01, 46.50s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [14:49<23:59, 47.98s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [15:40<23:34, 48.77s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [16:30<23:01, 49.33s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [17:23<22:34, 50.17s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [18:13<21:48, 50.32s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [19:04<21:00, 50.43s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [19:55<20:12, 50.51s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [20:46<19:24, 50.64s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [21:15<16:16, 44.40s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [22:06<16:11, 46.28s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [22:57<15:54, 47.74s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [23:48<15:24, 48.68s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [24:40<14:52, 49.56s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [25:01<11:35, 40.93s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [25:51<11:42, 43.90s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [26:42<11:28, 45.93s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [27:33<11:02, 47.34s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [28:25<10:33, 48.70s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [29:15<09:50, 49.17s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [30:06<09:07, 49.76s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [30:51<08:02, 48.22s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [31:42<07:23, 49.25s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [32:34<06:40, 50.11s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [33:24<05:49, 49.87s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [34:16<05:03, 50.55s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [34:28<03:14, 38.96s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [35:18<02:49, 42.32s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [36:03<02:09, 43.19s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [36:54<01:30, 45.46s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [37:45<00:47, 47.21s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [38:30<00:00, 46.56s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [38:30<00:00, 46.21s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.6112} | lm_loss 9.6947 | avg. gen lenth: 213.552
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o9-tcommonsenseqa-s1-rFalse --seed 1 --num-out-domain 9
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-13 00:36:37,938] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o9-tcommonsenseqa-s1-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 9
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o9-tcommonsenseqa-s1-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 1
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  1%|▍                                                    | 66/7473 [00:00<00:11, 654.30it/s]  2%|▉                                                   | 133/7473 [00:00<00:11, 659.67it/s]  3%|█▍                                                  | 201/7473 [00:00<00:10, 664.69it/s]  4%|█▊                                                  | 268/7473 [00:00<00:10, 663.42it/s]  4%|██▎                                                 | 335/7473 [00:00<00:10, 665.24it/s]  5%|██▊                                                 | 402/7473 [00:00<00:10, 663.32it/s]  6%|███▎                                                | 469/7473 [00:00<00:10, 662.55it/s]  7%|███▋                                                | 536/7473 [00:00<00:10, 662.23it/s]  8%|████▏                                               | 603/7473 [00:00<00:10, 648.80it/s]  9%|████▋                                               | 670/7473 [00:01<00:10, 652.34it/s] 10%|█████▏                                              | 737/7473 [00:01<00:10, 655.65it/s] 11%|█████▌                                              | 804/7473 [00:01<00:10, 656.53it/s] 12%|██████                                              | 871/7473 [00:01<00:10, 658.86it/s] 13%|██████▌                                             | 937/7473 [00:01<00:09, 658.86it/s] 13%|██████▊                                            | 1004/7473 [00:01<00:09, 661.77it/s] 14%|███████▎                                           | 1072/7473 [00:01<00:09, 664.18it/s] 15%|███████▊                                           | 1139/7473 [00:01<00:09, 663.90it/s] 16%|████████▏                                          | 1206/7473 [00:01<00:09, 661.46it/s] 17%|████████▋                                          | 1273/7473 [00:01<00:09, 658.95it/s] 18%|█████████▏                                         | 1340/7473 [00:02<00:09, 660.60it/s] 19%|█████████▌                                         | 1407/7473 [00:02<00:09, 657.90it/s] 20%|██████████                                         | 1474/7473 [00:02<00:09, 658.98it/s] 21%|██████████▌                                        | 1541/7473 [00:02<00:08, 661.76it/s] 22%|███████████                                        | 1615/7473 [00:02<00:08, 683.95it/s] 23%|███████████▋                                       | 1717/7473 [00:02<00:07, 782.03it/s] 24%|████████████▍                                      | 1818/7473 [00:02<00:06, 849.66it/s] 26%|█████████████                                      | 1917/7473 [00:02<00:06, 890.91it/s] 27%|█████████████▊                                     | 2018/7473 [00:02<00:05, 925.36it/s] 28%|██████████████▍                                    | 2118/7473 [00:02<00:05, 945.93it/s] 30%|███████████████▏                                   | 2219/7473 [00:03<00:05, 964.92it/s] 31%|███████████████▊                                   | 2318/7473 [00:03<00:05, 970.95it/s] 32%|████████████████▌                                  | 2419/7473 [00:03<00:05, 981.63it/s] 34%|█████████████████▏                                 | 2520/7473 [00:03<00:05, 952.49it/s] 35%|█████████████████▉                                 | 2621/7473 [00:03<00:05, 969.15it/s] 36%|██████████████████▌                                | 2723/7473 [00:03<00:04, 982.72it/s] 38%|███████████████████▎                               | 2824/7473 [00:03<00:04, 988.98it/s] 39%|███████████████████▉                               | 2926/7473 [00:03<00:04, 997.43it/s] 41%|████████████████████▎                             | 3027/7473 [00:03<00:04, 1000.89it/s] 42%|████████████████████▉                             | 3128/7473 [00:03<00:04, 1001.72it/s] 43%|█████████████████████▌                            | 3229/7473 [00:04<00:04, 1000.20it/s] 45%|██████████████████████▎                           | 3330/7473 [00:04<00:04, 1002.47it/s] 46%|███████████████████████▍                           | 3431/7473 [00:04<00:04, 998.00it/s] 47%|████████████████████████                           | 3531/7473 [00:04<00:03, 993.59it/s] 49%|████████████████████████▊                          | 3632/7473 [00:04<00:03, 997.56it/s] 50%|█████████████████████████▍                         | 3732/7473 [00:04<00:03, 995.44it/s] 51%|██████████████████████████▏                        | 3833/7473 [00:04<00:03, 998.61it/s] 53%|██████████████████████████▊                        | 3933/7473 [00:04<00:03, 997.94it/s] 54%|██████████████████████████▉                       | 4034/7473 [00:04<00:03, 1001.29it/s] 55%|████████████████████████████▏                      | 4135/7473 [00:04<00:03, 997.91it/s] 57%|████████████████████████████▉                      | 4236/7473 [00:05<00:03, 999.96it/s] 58%|█████████████████████████████▌                     | 4337/7473 [00:05<00:03, 994.76it/s] 59%|██████████████████████████████▎                    | 4437/7473 [00:05<00:03, 994.54it/s] 61%|██████████████████████████████▉                    | 4537/7473 [00:05<00:02, 993.71it/s] 62%|███████████████████████████████▋                   | 4637/7473 [00:05<00:02, 991.66it/s] 63%|████████████████████████████████▎                  | 4738/7473 [00:05<00:02, 994.88it/s] 65%|█████████████████████████████████                  | 4838/7473 [00:05<00:02, 994.71it/s] 66%|█████████████████████████████████▋                 | 4938/7473 [00:05<00:02, 995.65it/s] 67%|██████████████████████████████████▍                | 5038/7473 [00:05<00:02, 989.36it/s] 69%|███████████████████████████████████                | 5139/7473 [00:05<00:02, 994.01it/s] 70%|███████████████████████████████████▊               | 5240/7473 [00:06<00:02, 998.42it/s] 71%|████████████████████████████████████▍              | 5340/7473 [00:06<00:02, 963.09it/s] 73%|█████████████████████████████████████▏             | 5440/7473 [00:06<00:02, 973.27it/s] 74%|█████████████████████████████████████▊             | 5538/7473 [00:06<00:02, 719.91it/s] 75%|██████████████████████████████████████▍            | 5638/7473 [00:06<00:02, 785.31it/s] 77%|███████████████████████████████████████▏           | 5738/7473 [00:06<00:02, 838.62it/s] 78%|███████████████████████████████████████▊           | 5839/7473 [00:06<00:01, 882.08it/s] 79%|████████████████████████████████████████▌          | 5939/7473 [00:06<00:01, 912.05it/s] 81%|█████████████████████████████████████████▏         | 6040/7473 [00:07<00:01, 937.10it/s] 82%|█████████████████████████████████████████▉         | 6137/7473 [00:07<00:01, 945.88it/s] 83%|██████████████████████████████████████████▌        | 6238/7473 [00:07<00:01, 963.34it/s] 85%|███████████████████████████████████████████▎       | 6339/7473 [00:07<00:01, 974.35it/s] 86%|███████████████████████████████████████████▉       | 6438/7473 [00:07<00:01, 978.02it/s] 88%|████████████████████████████████████████████▋      | 6539/7473 [00:07<00:00, 984.69it/s] 89%|█████████████████████████████████████████████▎     | 6639/7473 [00:07<00:00, 982.50it/s] 90%|█████████████████████████████████████████████▉     | 6740/7473 [00:07<00:00, 988.10it/s] 92%|██████████████████████████████████████████████▋    | 6840/7473 [00:07<00:00, 989.94it/s] 93%|███████████████████████████████████████████████▍   | 6942/7473 [00:07<00:00, 997.31it/s] 94%|████████████████████████████████████████████████   | 7042/7473 [00:08<00:00, 995.30it/s] 96%|████████████████████████████████████████████████▋  | 7142/7473 [00:08<00:00, 994.45it/s] 97%|█████████████████████████████████████████████████▍ | 7242/7473 [00:08<00:00, 995.03it/s] 98%|██████████████████████████████████████████████████ | 7342/7473 [00:08<00:00, 993.20it/s]100%|██████████████████████████████████████████████████▊| 7442/7473 [00:08<00:00, 987.73it/s]100%|███████████████████████████████████████████████████| 7473/7473 [00:08<00:00, 883.79it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:04<00:09,  4.99s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.18s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.38s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.63s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:09<00:04,  4.85s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.34s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.33s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.53s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.24s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.42s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.67s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.83s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.77s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.92s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.87s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.06s/it]
[2023-08-13 00:37:39,207] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-13 00:37:46,536] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-13 00:37:46,537] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f0a5b12dfa0>
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-13 00:37:46,538] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f0a5b13c700>
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-13 00:37:46,539] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-13 00:37:46,539] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.39401721954345703 seconds
Loading extension module utils...
Time to load utils op: 0.30403685569763184 seconds
Loading extension module utils...
Time to load utils op: 0.40444469451904297 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]Loading extension module utils...
############### Example ###############
Time to load utils op: 0.4043426513671875 seconds
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Where could you find some plumbing that would not be of use to you if you are thirsty? Choices:  A: oil refineries B: wall C: show D: own home E: water fountain
Answer: A: oil refineries

Input: When a person is beginning work, what aren't they doing yet? Choices:  A: working B: resting C: tiredness D: accomplishing E: momentum
Answer: D: accomplishing

Input: Where might I find pens with a company logo? Choices:  A: office B: on a pencil C: write sentences on paper D: school E: backpack
Answer: A: office

Input: Billy called out to John, and listened for what? Choices:  A: silence B: response C: communication D: hanging up E: whisper
Answer: B: response

Input: The lizard frightened the hiker, it's movements made what rustle? Choices:  A: garden B: trees C: books D: rocks E: bushes
Answer: E: bushes

Input: The man spent big money and time maintaining his lawn, it was part of keeping up with the Joneses where? Choices:  A: front yard B: suburbia C: neighborhood D: back yard E: golf course
Answer: B: suburbia

Input: What would a human do if they want to get to a store that he or she can see? Choices:  A: cross road B: see around C: drink coffee D: dream dreams E: think critically
Answer: A: cross road

Input: Where would you grab an object contained by a doorway? Choices:  A: television B: control panel C: opening doors D: doorknob E: doorway
Answer: E: doorway

Input: Sarah knew she was committing perjury, so there was a lot of what feeling between her and the prosecutor? Choices:  A: arrest B: tension C: shame D: attraction E: embarrassment
Answer: B: tension

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o9-tcommonsenseqa-s1-rFalse
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:36<29:33, 36.20s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:24<34:50, 43.56s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:15<36:34, 46.69s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [03:05<36:46, 47.98s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [03:55<36:36, 48.80s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [04:20<29:56, 40.84s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [04:52<27:00, 37.68s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [05:42<29:17, 41.85s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [06:33<30:26, 44.55s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [07:07<27:34, 41.37s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [07:46<26:22, 40.58s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [08:37<27:40, 43.69s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [09:14<25:44, 41.75s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [09:39<22:02, 36.74s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [10:29<23:43, 40.68s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [11:19<24:42, 43.61s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [12:10<25:08, 45.72s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [12:57<24:32, 46.01s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [13:32<22:10, 42.90s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [14:22<22:30, 45.02s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [15:11<22:21, 46.26s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [15:50<20:27, 43.85s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [16:40<20:38, 45.86s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [17:30<20:26, 47.16s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [18:21<20:04, 48.16s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [19:11<19:32, 48.85s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [20:01<18:47, 49.01s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [20:50<17:57, 48.99s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [21:39<17:08, 48.96s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [21:49<12:29, 37.46s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [22:38<12:58, 40.95s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [23:28<13:04, 43.59s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [24:19<12:57, 45.73s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [24:43<10:28, 39.26s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [25:18<09:31, 38.11s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [25:44<08:02, 34.43s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [26:34<08:27, 39.03s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [27:10<07:37, 38.10s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [28:00<07:38, 41.70s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [28:19<05:49, 34.97s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [29:08<05:52, 39.18s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [29:43<05:03, 37.89s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [30:33<04:51, 41.58s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [31:25<04:27, 44.52s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [32:16<03:52, 46.49s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [33:06<03:10, 47.51s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [33:55<02:24, 48.17s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [34:46<01:37, 48.97s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [35:14<00:42, 42.73s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [36:04<00:00, 44.88s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [36:04<00:00, 43.30s/it]
name: gsm8k | {'exact_match': 0.4, 'rougeL': 0.6356} | lm_loss 9.6949 | avg. gen lenth: 225.816
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o1-tcommonsenseqa-s10-rTrue --seed 10 --rationales --num-out-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-13 01:16:46,847] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o1-tcommonsenseqa-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 1
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o1-tcommonsenseqa-s10-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  1%|▍                                                    | 69/7473 [00:00<00:10, 689.17it/s]  2%|▉                                                   | 140/7473 [00:00<00:10, 697.09it/s]  3%|█▍                                                  | 212/7473 [00:00<00:10, 704.22it/s]  4%|█▉                                                  | 283/7473 [00:00<00:10, 701.69it/s]  5%|██▍                                                 | 354/7473 [00:00<00:10, 703.37it/s]  6%|██▉                                                 | 425/7473 [00:00<00:10, 700.30it/s]  7%|███▍                                                | 496/7473 [00:00<00:10, 696.66it/s]  8%|███▉                                                | 567/7473 [00:00<00:09, 699.81it/s]  9%|████▍                                               | 637/7473 [00:00<00:10, 682.53it/s]  9%|████▉                                               | 707/7473 [00:01<00:09, 687.57it/s] 10%|█████▍                                              | 778/7473 [00:01<00:09, 692.83it/s] 11%|█████▉                                              | 848/7473 [00:01<00:09, 694.12it/s] 12%|██████▍                                             | 919/7473 [00:01<00:09, 696.23it/s] 13%|██████▉                                             | 990/7473 [00:01<00:09, 698.60it/s] 14%|███████▏                                           | 1061/7473 [00:01<00:09, 699.02it/s] 15%|███████▋                                           | 1131/7473 [00:01<00:09, 698.69it/s] 16%|████████▏                                          | 1201/7473 [00:01<00:08, 697.85it/s] 17%|████████▋                                          | 1271/7473 [00:01<00:08, 697.60it/s] 18%|█████████▏                                         | 1341/7473 [00:01<00:08, 696.91it/s] 19%|█████████▋                                         | 1411/7473 [00:02<00:08, 693.62it/s] 20%|██████████                                         | 1482/7473 [00:02<00:08, 695.82it/s] 21%|██████████▌                                        | 1553/7473 [00:02<00:08, 697.89it/s] 22%|███████████                                        | 1623/7473 [00:02<00:08, 695.29it/s] 23%|███████████▊                                       | 1723/7473 [00:02<00:07, 785.01it/s] 24%|████████████▍                                      | 1830/7473 [00:02<00:06, 868.05it/s] 26%|█████████████▏                                     | 1936/7473 [00:02<00:05, 922.84it/s] 27%|█████████████▉                                     | 2044/7473 [00:02<00:05, 967.14it/s] 29%|██████████████▋                                    | 2150/7473 [00:02<00:05, 993.04it/s] 30%|███████████████                                   | 2256/7473 [00:02<00:05, 1010.75it/s] 32%|███████████████▊                                  | 2362/7473 [00:03<00:04, 1022.94it/s] 33%|████████████████▌                                 | 2469/7473 [00:03<00:04, 1036.47it/s] 34%|█████████████████▏                                | 2573/7473 [00:03<00:04, 1009.86it/s] 36%|█████████████████▉                                | 2680/7473 [00:03<00:04, 1024.92it/s] 37%|██████████████████▋                               | 2787/7473 [00:03<00:04, 1035.67it/s] 39%|███████████████████▎                              | 2894/7473 [00:03<00:04, 1045.41it/s] 40%|████████████████████                              | 3002/7473 [00:03<00:04, 1053.85it/s] 42%|████████████████████▊                             | 3109/7473 [00:03<00:04, 1058.50it/s] 43%|█████████████████████▌                            | 3215/7473 [00:03<00:04, 1056.98it/s] 44%|██████████████████████▏                           | 3323/7473 [00:03<00:03, 1061.55it/s] 46%|██████████████████████▉                           | 3430/7473 [00:04<00:03, 1056.90it/s] 47%|███████████████████████▋                          | 3536/7473 [00:04<00:03, 1057.51it/s] 49%|████████████████████████▎                         | 3642/7473 [00:04<00:03, 1058.20it/s] 50%|█████████████████████████                         | 3748/7473 [00:04<00:03, 1056.00it/s] 52%|█████████████████████████▊                        | 3855/7473 [00:04<00:03, 1059.13it/s] 53%|██████████████████████████▌                       | 3961/7473 [00:04<00:03, 1059.19it/s] 54%|███████████████████████████▏                      | 4068/7473 [00:04<00:03, 1061.35it/s] 56%|███████████████████████████▉                      | 4175/7473 [00:04<00:03, 1055.80it/s] 57%|████████████████████████████▋                     | 4281/7473 [00:04<00:03, 1054.46it/s] 59%|█████████████████████████████▎                    | 4388/7473 [00:04<00:02, 1056.19it/s] 60%|██████████████████████████████                    | 4494/7473 [00:05<00:02, 1056.27it/s] 62%|██████████████████████████████▊                   | 4600/7473 [00:05<00:02, 1055.01it/s] 63%|███████████████████████████████▍                  | 4706/7473 [00:05<00:02, 1056.27it/s] 64%|████████████████████████████████▏                 | 4812/7473 [00:05<00:02, 1052.63it/s] 66%|████████████████████████████████▉                 | 4918/7473 [00:05<00:02, 1054.16it/s] 67%|█████████████████████████████████▌                | 5024/7473 [00:05<00:02, 1053.53it/s] 69%|██████████████████████████████████▎               | 5131/7473 [00:05<00:02, 1056.27it/s] 70%|███████████████████████████████████               | 5238/7473 [00:05<00:02, 1057.98it/s] 72%|███████████████████████████████████▊              | 5344/7473 [00:05<00:02, 1018.95it/s] 73%|████████████████████████████████████▍             | 5450/7473 [00:05<00:01, 1030.28it/s] 74%|█████████████████████████████████████▉             | 5554/7473 [00:06<00:02, 782.14it/s] 76%|██████████████████████████████████████▋            | 5661/7473 [00:06<00:02, 850.09it/s] 77%|███████████████████████████████████████▎           | 5767/7473 [00:06<00:01, 903.25it/s] 79%|████████████████████████████████████████           | 5873/7473 [00:06<00:01, 945.02it/s] 80%|████████████████████████████████████████▊          | 5978/7473 [00:06<00:01, 971.64it/s] 81%|█████████████████████████████████████████▌         | 6085/7473 [00:06<00:01, 999.15it/s] 83%|█████████████████████████████████████████▍        | 6192/7473 [00:06<00:01, 1017.68it/s] 84%|██████████████████████████████████████████▏       | 6299/7473 [00:06<00:01, 1031.95it/s] 86%|██████████████████████████████████████████▊       | 6405/7473 [00:06<00:01, 1038.79it/s] 87%|███████████████████████████████████████████▌      | 6510/7473 [00:07<00:00, 1035.17it/s] 89%|████████████████████████████████████████████▎     | 6616/7473 [00:07<00:00, 1041.72it/s] 90%|████████████████████████████████████████████▉     | 6722/7473 [00:07<00:00, 1045.45it/s] 91%|█████████████████████████████████████████████▋    | 6827/7473 [00:07<00:00, 1045.48it/s] 93%|██████████████████████████████████████████████▍   | 6934/7473 [00:07<00:00, 1049.78it/s] 94%|███████████████████████████████████████████████   | 7040/7473 [00:07<00:00, 1048.31it/s] 96%|███████████████████████████████████████████████▊  | 7146/7473 [00:07<00:00, 1050.91it/s] 97%|████████████████████████████████████████████████▌ | 7252/7473 [00:07<00:00, 1052.00it/s] 98%|█████████████████████████████████████████████████▏| 7358/7473 [00:07<00:00, 1051.43it/s]100%|█████████████████████████████████████████████████▉| 7464/7473 [00:07<00:00, 1050.74it/s]100%|███████████████████████████████████████████████████| 7473/7473 [00:08<00:00, 933.39it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.18s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.23s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.31s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.43s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.05s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.06s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.23s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.37s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.41s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.60s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.48s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.66s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.59s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.77s/it]
[2023-08-13 01:17:46,398] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.79s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.95s/it]
[2023-08-13 01:17:55,098] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-13 01:17:55,100] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-13 01:17:55,100] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-13 01:17:55,100] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-13 01:17:55,100] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-13 01:17:55,100] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fcc6f73eb20>
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-13 01:17:55,101] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fcc6f73e8b0>
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-13 01:17:55,102] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-13 01:17:55,102] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.40015602111816406 seconds
Loading extension module utils...
Time to load utils op: 0.3043038845062256 seconds
Loading extension module utils...
Time to load utils op: 0.4044647216796875 seconds
Loading extension module utils...
Time to load utils op: 0.40456247329711914 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Fabric is cut to order at what type of seller? Choices:  A: curtains B: tailor shop C: clothing store D: sewing room E: hardware store
Rationales: 1. First, understand what is being asked in the question. Here, we are required to determine where fabric is cut to a specific order.

2. Analyzing the choices, identify the types of sellers or locations that could possibly cut fabric to order. 

3. Look at choice A: Curtains are usually sold at stores that may not necessary have to customize or cut fabric to order. Hence, "curtains" is not a suitable answer.

4. Choice B: A tailor shop is a location where tailors often cut fabric as per the requirements of the customers. So, this could be a possible answer. 

5. Choice C: Clothing stores usually sell ready-made clothes and not fabric which is cut to order. Hence, discard "clothing store" as an option. 

6. For choice D: A sewing room is a categorical concept or a place where sewing is done. But, sewing rooms are not necessarily commercial places where all types of fabric are cut to order. Therefore, "sewing room" isn't the correct answer.

7. Choice E: A hardware store mainly deals with items like tools, machinery, building materials, and not fabric. Hence, "hardware store" can be discarded. 

8. So, by process of elimination and analyzing the options thoroughly, the most suitable answer is B - Tailor shop, where fabric is most likely to be cut as per specific orders.
Answer: B: tailor shop

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o1-tcommonsenseqa-s10-rTrue
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:39<32:26, 39.73s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:30<36:54, 46.13s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:21<37:57, 48.45s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [03:10<37:15, 48.60s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [04:01<37:00, 49.34s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [04:52<36:35, 49.90s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [05:42<35:49, 49.98s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [06:33<35:21, 50.51s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [07:25<34:44, 50.84s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [08:15<33:50, 50.77s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [09:06<32:52, 50.57s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [09:56<31:54, 50.37s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [10:46<31:07, 50.47s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [11:36<30:13, 50.38s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [12:03<25:12, 43.22s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [12:53<25:40, 45.31s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [13:43<25:43, 46.76s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [14:34<25:34, 47.94s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [15:23<24:58, 48.34s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [16:14<24:27, 48.92s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [17:04<23:51, 49.37s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [17:54<23:07, 49.54s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [18:45<22:30, 50.01s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [19:35<21:40, 50.01s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [20:26<20:54, 50.18s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [21:16<20:02, 50.10s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [22:06<19:15, 50.23s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [22:57<18:29, 50.42s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [23:48<17:40, 50.48s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [24:38<16:50, 50.53s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [25:28<15:55, 50.28s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [26:19<15:09, 50.54s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [27:10<14:23, 50.81s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [28:01<13:29, 50.62s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [28:52<12:41, 50.74s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [29:43<11:53, 50.97s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [30:34<11:01, 50.90s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [31:24<10:06, 50.52s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [32:14<09:15, 50.51s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [33:05<08:27, 50.77s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [33:55<07:34, 50.50s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [34:45<06:42, 50.31s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [35:35<05:52, 50.31s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [36:27<05:03, 50.65s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [37:18<04:13, 50.70s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [38:08<03:22, 50.60s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [38:59<02:31, 50.59s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [39:46<01:38, 49.48s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [40:37<00:49, 49.99s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [41:28<00:00, 50.25s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [41:28<00:00, 49.76s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.3945} | lm_loss 10.5473 | avg. gen lenth: 337.976
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o2-tcommonsenseqa-s10-rTrue --seed 10 --rationales --num-out-domain 2
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-13 01:59:35,818] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o2-tcommonsenseqa-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 2
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o2-tcommonsenseqa-s10-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  1%|▍                                                    | 63/7473 [00:00<00:11, 620.91it/s]  2%|▉                                                   | 126/7473 [00:00<00:11, 624.98it/s]  3%|█▎                                                  | 190/7473 [00:00<00:11, 628.82it/s]  3%|█▊                                                  | 253/7473 [00:00<00:11, 627.77it/s]  4%|██▏                                                 | 317/7473 [00:00<00:11, 630.82it/s]  5%|██▋                                                 | 381/7473 [00:00<00:11, 631.30it/s]  6%|███                                                 | 445/7473 [00:00<00:11, 628.27it/s]  7%|███▌                                                | 508/7473 [00:00<00:11, 626.21it/s]  8%|███▉                                                | 571/7473 [00:00<00:11, 620.30it/s]  8%|████▍                                               | 634/7473 [00:01<00:11, 621.06it/s]  9%|████▊                                               | 698/7473 [00:01<00:10, 624.84it/s] 10%|█████▎                                              | 762/7473 [00:01<00:10, 626.70it/s] 11%|█████▋                                              | 825/7473 [00:01<00:10, 626.46it/s] 12%|██████▏                                             | 889/7473 [00:01<00:10, 628.47it/s] 13%|██████▌                                             | 952/7473 [00:01<00:10, 628.36it/s] 14%|██████▉                                            | 1016/7473 [00:01<00:10, 631.24it/s] 14%|███████▎                                           | 1080/7473 [00:01<00:10, 633.04it/s] 15%|███████▊                                           | 1144/7473 [00:01<00:09, 632.91it/s] 16%|████████▏                                          | 1208/7473 [00:01<00:09, 628.20it/s] 17%|████████▋                                          | 1272/7473 [00:02<00:09, 629.23it/s] 18%|█████████                                          | 1336/7473 [00:02<00:09, 630.75it/s] 19%|█████████▌                                         | 1400/7473 [00:02<00:09, 628.19it/s] 20%|█████████▉                                         | 1464/7473 [00:02<00:09, 629.62it/s] 20%|██████████▍                                        | 1528/7473 [00:02<00:09, 632.62it/s] 21%|██████████▊                                        | 1592/7473 [00:02<00:09, 629.25it/s] 23%|███████████▌                                       | 1689/7473 [00:02<00:07, 729.91it/s] 24%|████████████▏                                      | 1786/7473 [00:02<00:07, 800.86it/s] 25%|████████████▊                                      | 1882/7473 [00:02<00:06, 847.90it/s] 26%|█████████████▌                                     | 1979/7473 [00:02<00:06, 882.22it/s] 28%|██████████████▏                                    | 2076/7473 [00:03<00:05, 905.93it/s] 29%|██████████████▊                                    | 2173/7473 [00:03<00:05, 925.01it/s] 30%|███████████████▍                                   | 2268/7473 [00:03<00:05, 931.73it/s] 32%|████████████████▏                                  | 2365/7473 [00:03<00:05, 940.75it/s] 33%|████████████████▊                                  | 2463/7473 [00:03<00:05, 950.70it/s] 34%|█████████████████▍                                 | 2559/7473 [00:03<00:05, 919.40it/s] 36%|██████████████████▏                                | 2657/7473 [00:03<00:05, 935.73it/s] 37%|██████████████████▊                                | 2754/7473 [00:03<00:04, 945.12it/s] 38%|███████████████████▍                               | 2852/7473 [00:03<00:04, 954.49it/s] 39%|████████████████████▏                              | 2950/7473 [00:03<00:04, 960.68it/s] 41%|████████████████████▊                              | 3047/7473 [00:04<00:04, 961.45it/s] 42%|█████████████████████▍                             | 3144/7473 [00:04<00:04, 961.43it/s] 43%|██████████████████████                             | 3241/7473 [00:04<00:04, 961.47it/s] 45%|██████████████████████▊                            | 3338/7473 [00:04<00:04, 962.22it/s] 46%|███████████████████████▍                           | 3435/7473 [00:04<00:04, 960.56it/s] 47%|████████████████████████                           | 3532/7473 [00:04<00:04, 953.05it/s] 49%|████████████████████████▊                          | 3629/7473 [00:04<00:04, 957.87it/s] 50%|█████████████████████████▍                         | 3725/7473 [00:04<00:03, 956.14it/s] 51%|██████████████████████████                         | 3823/7473 [00:04<00:03, 959.62it/s] 52%|██████████████████████████▋                        | 3919/7473 [00:04<00:03, 958.71it/s] 54%|███████████████████████████▍                       | 4017/7473 [00:05<00:03, 962.34it/s] 55%|████████████████████████████                       | 4114/7473 [00:05<00:03, 960.91it/s] 56%|████████████████████████████▋                      | 4211/7473 [00:05<00:03, 960.97it/s] 58%|█████████████████████████████▍                     | 4308/7473 [00:05<00:03, 962.27it/s] 59%|██████████████████████████████                     | 4405/7473 [00:05<00:03, 962.34it/s] 60%|██████████████████████████████▋                    | 4502/7473 [00:05<00:03, 960.72it/s] 62%|███████████████████████████████▍                   | 4599/7473 [00:05<00:02, 961.45it/s] 63%|████████████████████████████████                   | 4696/7473 [00:05<00:02, 962.45it/s] 64%|████████████████████████████████▋                  | 4793/7473 [00:05<00:02, 960.25it/s] 65%|█████████████████████████████████▎                 | 4890/7473 [00:05<00:02, 960.58it/s] 67%|██████████████████████████████████                 | 4987/7473 [00:06<00:02, 958.60it/s] 68%|██████████████████████████████████▋                | 5084/7473 [00:06<00:02, 959.75it/s] 69%|███████████████████████████████████▎               | 5182/7473 [00:06<00:02, 962.61it/s] 71%|████████████████████████████████████               | 5279/7473 [00:06<00:02, 924.83it/s] 72%|████████████████████████████████████▋              | 5376/7473 [00:06<00:02, 935.51it/s] 73%|█████████████████████████████████████▎             | 5471/7473 [00:06<00:02, 770.75it/s] 74%|█████████████████████████████████████▉             | 5567/7473 [00:06<00:02, 817.72it/s] 76%|██████████████████████████████████████▋            | 5663/7473 [00:06<00:02, 855.59it/s] 77%|███████████████████████████████████████▎           | 5759/7473 [00:06<00:01, 882.46it/s] 78%|███████████████████████████████████████▉           | 5855/7473 [00:07<00:01, 903.69it/s] 80%|████████████████████████████████████████▌          | 5950/7473 [00:07<00:01, 916.08it/s] 81%|█████████████████████████████████████████▎         | 6046/7473 [00:07<00:01, 927.97it/s] 82%|█████████████████████████████████████████▉         | 6142/7473 [00:07<00:01, 937.07it/s] 83%|██████████████████████████████████████████▌        | 6239/7473 [00:07<00:01, 944.08it/s] 85%|███████████████████████████████████████████▏       | 6335/7473 [00:07<00:01, 947.08it/s] 86%|███████████████████████████████████████████▉       | 6431/7473 [00:07<00:01, 946.34it/s] 87%|████████████████████████████████████████████▌      | 6528/7473 [00:07<00:00, 951.25it/s] 89%|█████████████████████████████████████████████▏     | 6625/7473 [00:07<00:00, 954.26it/s] 90%|█████████████████████████████████████████████▊     | 6722/7473 [00:07<00:00, 956.22it/s] 91%|██████████████████████████████████████████████▌    | 6818/7473 [00:08<00:00, 954.56it/s] 93%|███████████████████████████████████████████████▏   | 6915/7473 [00:08<00:00, 958.01it/s] 94%|███████████████████████████████████████████████▊   | 7012/7473 [00:08<00:00, 959.74it/s] 95%|████████████████████████████████████████████████▌  | 7109/7473 [00:08<00:00, 958.66it/s] 96%|█████████████████████████████████████████████████▏ | 7206/7473 [00:08<00:00, 959.47it/s] 98%|█████████████████████████████████████████████████▊ | 7303/7473 [00:08<00:00, 961.49it/s] 99%|██████████████████████████████████████████████████▌| 7400/7473 [00:08<00:00, 962.16it/s]100%|███████████████████████████████████████████████████| 7473/7473 [00:08<00:00, 853.51it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.42s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.01s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.48s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.70s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:09<00:04,  4.85s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.16s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.39s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.50s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.34s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.50s/it]
[2023-08-13 02:00:35,273] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.65s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.82s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.89s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.04s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.98s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.14s/it]
[2023-08-13 02:00:47,341] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-13 02:00:47,342] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-13 02:00:47,343] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-13 02:00:47,343] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-13 02:00:47,343] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-13 02:00:47,343] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-13 02:00:47,343] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-13 02:00:47,343] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-13 02:00:47,343] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-13 02:00:47,343] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fb63c472fa0>
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fb63c479700>
[2023-08-13 02:00:47,344] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-13 02:00:47,345] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-13 02:00:47,345] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-13 02:00:47,345] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-13 02:00:47,345] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-13 02:00:47,345] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-13 02:00:47,345] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-13 02:00:47,345] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-13 02:00:47,345] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-13 02:00:47,345] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-13 02:00:47,345] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-13 02:00:47,345] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-13 02:00:47,345] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-13 02:00:47,345] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-13 02:00:47,345] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-13 02:00:47,345] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-13 02:00:47,345] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-13 02:00:47,345] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-13 02:00:47,345] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-13 02:00:47,345] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-13 02:00:47,345] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-13 02:00:47,345] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-13 02:00:47,345] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4120826721191406 seconds
Loading extension module utils...
Time to load utils op: 0.404613733291626 seconds
Loading extension module utils...
Time to load utils op: 0.3043966293334961 seconds
Loading extension module utils...
Time to load utils op: 0.40430521965026855 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Fabric is cut to order at what type of seller? Choices:  A: curtains B: tailor shop C: clothing store D: sewing room E: hardware store
Rationales: 1. This question is about a seller where fabric is cut to order.
2. Option A: Curtains. While curtains are made of fabric, curtain shops typically sell pre-made curtains.
3. Option B: Tailor shop. Tailors work directly with fabric, customizing it to fit clients' measurements, which means they would need to cut fabric to order.
4. Option C: Clothing store. A clothing store is more likely to sell pre-made clothes rather than cutting fabric to order.
5. Option D: Sewing room. A sewing room isn't a seller, it's usually a dedicated workspace in someone's home where they sew.
6. Option E: Hardware store. A hardware store sells tools and materials for home improvement, not fabric.
7. Therefore, B: Tailor shop is the correct answer as it is the type of seller that would cut fabric to order.
Answer: B: tailor shop

Input: Where are you if your reading magazines while waiting for a vehicle on rails? Choices:  A: vegetables B: market C: doctor D: train station E: bookstore
Rationales: 1. The question states that you are waiting for a vehicle on rails.
2. This phrase narrows down the possible locations to ones where rail-based vehicles operate. 
3. The choices include: vegetables, market, doctor, train station, and bookstore. Among these given options, the vehicle on rails could only be at a train station. 
4. The aspect of reading a magazine is a common activity people might do while waiting, but it doesn't necessarily indicate the specific location.
5. Therefore, the correct answer is D: train station.
Answer: D: train station

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o2-tcommonsenseqa-s10-rTrue
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:51<41:44, 51.12s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:40<40:09, 50.20s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:31<39:31, 50.45s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [03:20<38:16, 49.93s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [04:10<37:20, 49.79s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [05:00<36:38, 49.97s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [05:51<35:58, 50.20s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [06:40<34:52, 49.82s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [07:30<34:09, 49.99s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [07:58<28:48, 43.22s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [08:47<29:08, 44.84s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [09:26<27:19, 43.15s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [10:14<27:33, 44.68s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [11:04<27:46, 46.29s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [11:31<23:36, 40.48s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [12:21<24:31, 43.27s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [13:03<23:33, 42.84s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [13:52<23:50, 44.70s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [14:42<23:56, 46.34s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [15:32<23:42, 47.42s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [16:21<23:13, 48.07s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [17:12<22:45, 48.75s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [18:01<22:00, 48.89s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [18:50<21:09, 48.83s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [19:40<20:29, 49.17s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [20:30<19:46, 49.44s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [21:20<19:03, 49.70s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [22:10<18:12, 49.68s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [22:59<17:20, 49.55s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [23:24<14:06, 42.32s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [24:14<14:04, 44.44s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [24:44<12:02, 40.13s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [25:23<11:16, 39.78s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [26:12<11:22, 42.64s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [26:44<09:49, 39.33s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [27:33<09:52, 42.34s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [28:23<09:39, 44.54s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [29:13<09:13, 46.16s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [30:02<08:37, 47.08s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [30:52<07:59, 47.96s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [31:41<07:15, 48.35s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [32:31<06:29, 48.74s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [33:21<05:43, 49.07s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [34:02<04:40, 46.68s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [34:52<03:58, 47.71s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [35:24<02:52, 43.15s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [35:56<01:59, 39.83s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [36:46<01:25, 42.64s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [37:36<00:44, 44.86s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [38:25<00:00, 46.28s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [38:25<00:00, 46.11s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.2326} | lm_loss 10.1747 | avg. gen lenth: 301.064
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o3-tcommonsenseqa-s10-rTrue --seed 10 --rationales --num-out-domain 3
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-13 02:41:19,845] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o3-tcommonsenseqa-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 3
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o3-tcommonsenseqa-s10-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  0%|▏                                                    | 32/7473 [00:00<00:23, 315.71it/s]  1%|▍                                                    | 64/7473 [00:00<00:23, 317.43it/s]  1%|▋                                                    | 97/7473 [00:00<00:23, 319.51it/s]  2%|▉                                                   | 129/7473 [00:00<00:23, 319.13it/s]  2%|█▏                                                  | 162/7473 [00:00<00:22, 320.18it/s]  3%|█▎                                                  | 195/7473 [00:00<00:22, 319.99it/s]  3%|█▌                                                  | 228/7473 [00:00<00:22, 320.61it/s]  3%|█▊                                                  | 261/7473 [00:00<00:23, 310.32it/s]  4%|██                                                  | 293/7473 [00:00<00:22, 312.74it/s]  4%|██▎                                                 | 326/7473 [00:01<00:22, 315.06it/s]  5%|██▍                                                 | 358/7473 [00:01<00:22, 316.35it/s]  5%|██▋                                                 | 390/7473 [00:01<00:22, 316.67it/s]  6%|██▉                                                 | 424/7473 [00:01<00:21, 322.91it/s]  6%|███▎                                                | 473/7473 [00:01<00:18, 370.88it/s]  7%|███▋                                                | 521/7473 [00:01<00:17, 403.01it/s]  8%|███▉                                                | 569/7473 [00:01<00:16, 425.78it/s]  8%|████▎                                               | 617/7473 [00:01<00:15, 441.70it/s]  9%|████▋                                               | 665/7473 [00:01<00:15, 451.28it/s] 10%|████▉                                               | 713/7473 [00:01<00:14, 459.69it/s] 10%|█████▎                                              | 762/7473 [00:02<00:14, 467.43it/s] 11%|█████▋                                              | 810/7473 [00:02<00:14, 471.18it/s] 11%|█████▉                                              | 859/7473 [00:02<00:13, 474.31it/s] 12%|██████▎                                             | 908/7473 [00:02<00:13, 476.43it/s] 13%|██████▋                                             | 956/7473 [00:02<00:13, 476.84it/s] 13%|██████▊                                            | 1005/7473 [00:02<00:13, 477.99it/s] 14%|███████▏                                           | 1054/7473 [00:02<00:13, 480.23it/s] 15%|███████▌                                           | 1103/7473 [00:02<00:13, 479.66it/s] 15%|███████▊                                           | 1152/7473 [00:02<00:13, 480.38it/s] 16%|████████▏                                          | 1201/7473 [00:02<00:13, 478.73it/s] 17%|████████▌                                          | 1249/7473 [00:03<00:13, 478.70it/s] 17%|████████▊                                          | 1298/7473 [00:03<00:12, 479.56it/s] 18%|█████████▏                                         | 1347/7473 [00:03<00:12, 479.93it/s] 19%|█████████▌                                         | 1395/7473 [00:03<00:12, 477.62it/s] 19%|█████████▊                                         | 1443/7473 [00:03<00:12, 478.12it/s] 20%|██████████▏                                        | 1492/7473 [00:03<00:12, 479.85it/s] 21%|██████████▌                                        | 1541/7473 [00:03<00:12, 481.03it/s] 21%|██████████▊                                        | 1590/7473 [00:03<00:12, 479.18it/s] 22%|███████████▏                                       | 1638/7473 [00:03<00:12, 477.74it/s] 23%|███████████▌                                       | 1687/7473 [00:03<00:12, 479.00it/s] 23%|███████████▊                                       | 1736/7473 [00:04<00:11, 479.66it/s] 24%|████████████▏                                      | 1785/7473 [00:04<00:11, 480.38it/s] 25%|████████████▌                                      | 1834/7473 [00:04<00:11, 479.46it/s] 25%|████████████▊                                      | 1882/7473 [00:04<00:11, 477.91it/s] 26%|█████████████▏                                     | 1930/7473 [00:04<00:11, 473.26it/s] 26%|█████████████▍                                     | 1978/7473 [00:04<00:11, 474.05it/s] 27%|█████████████▊                                     | 2026/7473 [00:04<00:11, 475.48it/s] 28%|██████████████▏                                    | 2074/7473 [00:04<00:11, 474.98it/s] 28%|██████████████▍                                    | 2122/7473 [00:04<00:11, 475.36it/s] 29%|██████████████▊                                    | 2171/7473 [00:04<00:11, 476.81it/s] 30%|███████████████▏                                   | 2220/7473 [00:05<00:10, 478.14it/s] 30%|███████████████▍                                   | 2268/7473 [00:05<00:10, 478.28it/s] 31%|███████████████▊                                   | 2316/7473 [00:05<00:10, 476.78it/s] 32%|████████████████▏                                  | 2365/7473 [00:05<00:10, 477.63it/s] 32%|████████████████▍                                  | 2414/7473 [00:05<00:10, 478.66it/s] 33%|████████████████▊                                  | 2463/7473 [00:05<00:10, 480.52it/s] 34%|█████████████████▏                                 | 2512/7473 [00:05<00:10, 476.16it/s] 34%|█████████████████▍                                 | 2560/7473 [00:05<00:10, 447.59it/s] 35%|█████████████████▊                                 | 2608/7473 [00:05<00:10, 456.40it/s] 36%|██████████████████▏                                | 2656/7473 [00:06<00:10, 462.29it/s] 36%|██████████████████▍                                | 2705/7473 [00:06<00:10, 467.99it/s] 37%|██████████████████▊                                | 2753/7473 [00:06<00:10, 469.70it/s] 37%|███████████████████                                | 2801/7473 [00:06<00:09, 472.38it/s] 38%|███████████████████▍                               | 2849/7473 [00:06<00:09, 473.92it/s] 39%|███████████████████▊                               | 2897/7473 [00:06<00:09, 473.35it/s] 39%|████████████████████                               | 2945/7473 [00:06<00:09, 475.04it/s] 40%|████████████████████▍                              | 2993/7473 [00:06<00:09, 474.46it/s] 41%|████████████████████▊                              | 3041/7473 [00:06<00:09, 475.18it/s] 41%|█████████████████████                              | 3089/7473 [00:06<00:09, 476.55it/s] 42%|█████████████████████▍                             | 3137/7473 [00:07<00:09, 471.11it/s] 43%|█████████████████████▋                             | 3185/7473 [00:07<00:09, 472.16it/s] 43%|██████████████████████                             | 3233/7473 [00:07<00:09, 470.99it/s] 44%|██████████████████████▍                            | 3281/7473 [00:07<00:08, 473.47it/s] 45%|██████████████████████▋                            | 3329/7473 [00:07<00:08, 474.01it/s] 45%|███████████████████████                            | 3377/7473 [00:07<00:08, 473.23it/s] 46%|███████████████████████▎                           | 3425/7473 [00:07<00:08, 474.03it/s] 46%|███████████████████████▋                           | 3473/7473 [00:07<00:08, 472.44it/s] 47%|████████████████████████                           | 3521/7473 [00:07<00:08, 474.00it/s] 48%|████████████████████████▎                          | 3569/7473 [00:07<00:08, 475.51it/s] 48%|████████████████████████▋                          | 3617/7473 [00:08<00:08, 474.86it/s] 49%|█████████████████████████                          | 3665/7473 [00:08<00:08, 471.35it/s] 50%|█████████████████████████▎                         | 3713/7473 [00:08<00:07, 471.31it/s] 50%|█████████████████████████▋                         | 3761/7473 [00:08<00:07, 469.16it/s] 51%|█████████████████████████▉                         | 3809/7473 [00:08<00:07, 471.80it/s] 52%|██████████████████████████▎                        | 3857/7473 [00:08<00:07, 471.57it/s] 52%|██████████████████████████▋                        | 3905/7473 [00:08<00:07, 470.73it/s] 53%|██████████████████████████▉                        | 3953/7473 [00:08<00:07, 472.69it/s] 54%|███████████████████████████▎                       | 4001/7473 [00:08<00:07, 474.25it/s] 54%|███████████████████████████▋                       | 4049/7473 [00:08<00:07, 475.68it/s] 55%|███████████████████████████▉                       | 4097/7473 [00:09<00:07, 476.76it/s] 55%|████████████████████████████▎                      | 4145/7473 [00:09<00:07, 473.02it/s] 56%|████████████████████████████▌                      | 4193/7473 [00:09<00:06, 474.39it/s] 57%|████████████████████████████▉                      | 4241/7473 [00:09<00:06, 475.48it/s] 57%|█████████████████████████████▎                     | 4289/7473 [00:09<00:06, 474.93it/s] 58%|█████████████████████████████▌                     | 4337/7473 [00:09<00:06, 473.99it/s] 59%|█████████████████████████████▉                     | 4385/7473 [00:09<00:06, 473.47it/s] 59%|██████████████████████████████▎                    | 4433/7473 [00:09<00:06, 473.97it/s] 60%|██████████████████████████████▌                    | 4481/7473 [00:09<00:06, 474.25it/s] 61%|██████████████████████████████▉                    | 4529/7473 [00:09<00:06, 474.41it/s] 61%|███████████████████████████████▏                   | 4577/7473 [00:10<00:06, 473.48it/s] 62%|███████████████████████████████▌                   | 4625/7473 [00:10<00:06, 473.01it/s] 63%|███████████████████████████████▉                   | 4673/7473 [00:10<00:05, 472.23it/s] 63%|████████████████████████████████▏                  | 4721/7473 [00:10<00:05, 473.56it/s] 64%|████████████████████████████████▌                  | 4769/7473 [00:10<00:05, 474.97it/s] 64%|████████████████████████████████▊                  | 4817/7473 [00:10<00:05, 472.38it/s] 65%|█████████████████████████████████▏                 | 4865/7473 [00:10<00:05, 473.40it/s] 66%|█████████████████████████████████▌                 | 4913/7473 [00:10<00:05, 474.83it/s] 66%|█████████████████████████████████▊                 | 4961/7473 [00:10<00:05, 475.46it/s] 67%|██████████████████████████████████▏                | 5009/7473 [00:10<00:05, 476.44it/s] 68%|██████████████████████████████████▌                | 5057/7473 [00:11<00:05, 475.33it/s] 68%|██████████████████████████████████▊                | 5105/7473 [00:11<00:04, 475.50it/s] 69%|███████████████████████████████████▏               | 5153/7473 [00:11<00:04, 475.93it/s] 70%|███████████████████████████████████▍               | 5201/7473 [00:11<00:04, 476.63it/s] 70%|███████████████████████████████████▊               | 5249/7473 [00:11<00:04, 447.32it/s] 71%|████████████████████████████████████▏              | 5297/7473 [00:11<00:04, 455.00it/s] 72%|████████████████████████████████████▍              | 5345/7473 [00:11<00:04, 460.14it/s] 72%|████████████████████████████████████▊              | 5393/7473 [00:11<00:04, 464.76it/s] 73%|█████████████████████████████████████▏             | 5441/7473 [00:11<00:04, 468.05it/s] 73%|█████████████████████████████████████▍             | 5488/7473 [00:12<00:05, 331.18it/s] 74%|█████████████████████████████████████▊             | 5536/7473 [00:12<00:05, 365.14it/s] 75%|██████████████████████████████████████             | 5584/7473 [00:12<00:04, 392.22it/s] 75%|██████████████████████████████████████▍            | 5632/7473 [00:12<00:04, 413.48it/s] 76%|██████████████████████████████████████▊            | 5680/7473 [00:12<00:04, 429.44it/s] 77%|███████████████████████████████████████            | 5728/7473 [00:12<00:03, 441.74it/s] 77%|███████████████████████████████████████▍           | 5776/7473 [00:12<00:03, 451.72it/s] 78%|███████████████████████████████████████▋           | 5824/7473 [00:12<00:03, 457.63it/s] 79%|████████████████████████████████████████           | 5872/7473 [00:12<00:03, 462.75it/s] 79%|████████████████████████████████████████▍          | 5919/7473 [00:13<00:03, 464.05it/s] 80%|████████████████████████████████████████▋          | 5967/7473 [00:13<00:03, 466.27it/s] 80%|█████████████████████████████████████████          | 6014/7473 [00:13<00:03, 467.01it/s] 81%|█████████████████████████████████████████▎         | 6062/7473 [00:13<00:03, 470.07it/s] 82%|█████████████████████████████████████████▋         | 6110/7473 [00:13<00:02, 469.48it/s] 82%|██████████████████████████████████████████         | 6158/7473 [00:13<00:02, 469.45it/s] 83%|██████████████████████████████████████████▎        | 6206/7473 [00:13<00:02, 471.68it/s] 84%|██████████████████████████████████████████▋        | 6254/7473 [00:13<00:02, 472.47it/s] 84%|███████████████████████████████████████████        | 6302/7473 [00:13<00:02, 472.96it/s] 85%|███████████████████████████████████████████▎       | 6350/7473 [00:13<00:02, 473.09it/s] 86%|███████████████████████████████████████████▋       | 6398/7473 [00:14<00:02, 469.29it/s] 86%|███████████████████████████████████████████▉       | 6445/7473 [00:14<00:02, 469.42it/s] 87%|████████████████████████████████████████████▎      | 6493/7473 [00:14<00:02, 470.51it/s] 88%|████████████████████████████████████████████▋      | 6541/7473 [00:14<00:01, 472.32it/s] 88%|████████████████████████████████████████████▉      | 6589/7473 [00:14<00:01, 472.71it/s] 89%|█████████████████████████████████████████████▎     | 6637/7473 [00:14<00:01, 471.44it/s] 89%|█████████████████████████████████████████████▌     | 6685/7473 [00:14<00:01, 472.61it/s] 90%|█████████████████████████████████████████████▉     | 6733/7473 [00:14<00:01, 474.21it/s] 91%|██████████████████████████████████████████████▎    | 6781/7473 [00:14<00:01, 474.48it/s] 91%|██████████████████████████████████████████████▌    | 6829/7473 [00:14<00:01, 473.25it/s] 92%|██████████████████████████████████████████████▉    | 6877/7473 [00:15<00:01, 473.11it/s] 93%|███████████████████████████████████████████████▎   | 6925/7473 [00:15<00:01, 473.46it/s] 93%|███████████████████████████████████████████████▌   | 6973/7473 [00:15<00:01, 471.54it/s] 94%|███████████████████████████████████████████████▉   | 7021/7473 [00:15<00:00, 471.63it/s] 95%|████████████████████████████████████████████████▏  | 7069/7473 [00:15<00:00, 469.14it/s] 95%|████████████████████████████████████████████████▌  | 7117/7473 [00:15<00:00, 469.82it/s] 96%|████████████████████████████████████████████████▉  | 7165/7473 [00:15<00:00, 470.39it/s] 97%|█████████████████████████████████████████████████▏ | 7213/7473 [00:15<00:00, 472.78it/s] 97%|█████████████████████████████████████████████████▌ | 7261/7473 [00:15<00:00, 474.82it/s] 98%|█████████████████████████████████████████████████▉ | 7309/7473 [00:16<00:00, 474.46it/s] 98%|██████████████████████████████████████████████████▏| 7357/7473 [00:16<00:00, 474.72it/s] 99%|██████████████████████████████████████████████████▌| 7405/7473 [00:16<00:00, 475.16it/s]100%|██████████████████████████████████████████████████▊| 7453/7473 [00:16<00:00, 475.45it/s]100%|███████████████████████████████████████████████████| 7473/7473 [00:16<00:00, 457.01it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.02s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.18s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:06<00:12,  6.25s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.42s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.14s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.58s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.34s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.26s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.52s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.67s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.69s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.85s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.09s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.29s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.64s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.83s/it]
[2023-08-13 02:42:30,380] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-13 02:42:38,695] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-13 02:42:38,696] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-13 02:42:38,697] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-13 02:42:38,697] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-13 02:42:38,697] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-13 02:42:38,697] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-13 02:42:38,697] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-13 02:42:38,697] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-13 02:42:38,697] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-13 02:42:38,697] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-13 02:42:38,697] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-13 02:42:38,697] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fd52e927b20>
[2023-08-13 02:42:38,697] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fd52e9278b0>
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-13 02:42:38,698] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-13 02:42:38,699] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-13 02:42:38,699] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-13 02:42:38,699] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-13 02:42:38,699] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-13 02:42:38,699] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-13 02:42:38,699] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-13 02:42:38,699] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-13 02:42:38,699] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-13 02:42:38,699] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-13 02:42:38,699] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-13 02:42:38,699] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-13 02:42:38,699] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-13 02:42:38,699] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-13 02:42:38,699] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-13 02:42:38,699] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-13 02:42:38,699] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-13 02:42:38,699] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-13 02:42:38,699] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.44759225845336914 seconds
Loading extension module utils...
Time to load utils op: 0.40448498725891113 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Fabric is cut to order at what type of seller? Choices:  A: curtains B: tailor shop C: clothing store D: sewing room E: hardware store
Rationales: 1. To find the answer, we need to define what is meant by "fabric is cut to order".
2. "Cut to order" means that fabric is cut in exact lengths according to the requirements of the customer.
3. Curtains (Option A) are already made products and although they use fabric, they are not places where fabric is customarily cut to order. 
4. A clothing store (Option C) most commonly sells ready-made clothes rather than providing services for cutting fabric.
5. Sewing room (Option D) is a place where sewing is done but it isn't specifically a seller. 
6. A hardware store (Option E) primarily sells tools, hardware and construction materials. They do not typically offer fabric or tailoring services.
7. So, we are left with the tailor shop (Option B) which is a place specifically for customizing garments.
8. Therefore, it would be logical to assume that a tailor shop (Option B) is the type of seller where fabric is cut to order. This assumption makes tailor shop the best choice among the provided options.
Answer: B: tailor shop

Input: Where are you if your reading magazines while waiting for a vehicle on rails? Choices:  A: vegetables B: market C: doctor D: train station E: bookstore
Rationales: 1. The key details in the question are: "reading magazines", "waiting for a vehicle on rails".
2. The'vehicle on rails' is likely referring to a train.
3. One typically waits for a train at a train station.
4. Thus the possible places one can be while waiting for a train and reading magazines are likely to be a train station.
5. Comparing the options provided: vegetables, market, doctor, train station, bookstore; we can easily remove'vegetables' and 'doctor' as these are not locations where a train is present.
6. While'market' and 'bookstore' could theoretically be located near a train station, they are not places where one directly waits for a train.
7. Therefore, the most logical answer would be D: train station.
Answer: D: train station

Input: What would need oil to be used? Choices:  A: ground B: human  body C: repair shop D: combustion engines E: service station
Rationales: 1. We start off by examining the question, we need to figure out which option would require the use of oil.
2. Oil in this context is most likely referring to engine oil or a similar product, rather than oil for cooking or body moisturiser. This would be more intuitive based on general knowledge of objects or entities that require oil.
3. The first option, ground, generally doesn't need oil. Oil may be derived from it but it is not used for the ground. 
4. Similarly, human body does not need oil that the question probably refers to. While there are oils that are beneficial for skincare, that's not likely the kind of oil the question implies.
5. For C: repair shop and E:service station, while these places may use oils in the process of their work, they do not need the oil themselves, but would use oil for repairing or servicing things that need oil, such as vehicles.
6. Therefore, the answer that makes the most sense is D: combustion engines. Combustion engines need oil for lubrication and cooling. Without oil, engines would overheat and eventually fail due to the metal parts grinding together. So, combustion engines truly need oil to be used. 
7. Concluding, the answer is D: combustion engines.
Answer: D: combustion engines

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o3-tcommonsenseqa-s10-rTrue
Loading extension module utils...
Time to load utils op: 0.40447402000427246 seconds
Loading extension module utils...
Time to load utils op: 0.5043692588806152 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:46<37:41, 46.15s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:30<35:55, 44.91s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:03<30:58, 39.54s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [02:47<31:35, 41.21s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [03:31<31:47, 42.39s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [04:16<31:44, 43.27s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [05:01<31:17, 43.66s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [05:45<30:46, 43.96s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [06:30<30:07, 44.09s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [07:14<29:27, 44.18s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [07:58<28:40, 44.11s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [08:42<27:55, 44.09s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [09:26<27:12, 44.12s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [10:11<26:34, 44.29s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [10:55<25:45, 44.16s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [11:39<25:02, 44.18s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [12:23<24:19, 44.22s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [13:08<23:37, 44.30s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [13:52<22:53, 44.30s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [14:36<22:06, 44.23s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [15:20<21:23, 44.27s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [16:04<20:37, 44.20s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [16:49<19:54, 44.23s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [17:33<19:11, 44.29s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [18:17<18:24, 44.16s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [19:02<17:47, 44.48s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [19:44<16:45, 43.71s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [20:29<16:06, 43.91s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [21:13<15:26, 44.13s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [21:58<14:44, 44.23s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [22:42<13:59, 44.20s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [23:26<13:15, 44.22s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [24:11<12:37, 44.55s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [24:57<11:56, 44.81s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [25:41<11:09, 44.62s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [26:25<10:22, 44.48s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [27:09<09:36, 44.38s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [27:53<08:51, 44.28s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [28:37<08:06, 44.23s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [29:22<07:24, 44.44s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [30:07<06:40, 44.53s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [30:42<05:33, 41.71s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [31:26<04:56, 42.41s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [32:11<04:19, 43.19s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [32:56<03:38, 43.64s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [33:41<02:55, 43.93s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [34:24<02:11, 43.89s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [35:03<01:24, 42.45s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [35:47<00:42, 42.91s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [36:32<00:00, 43.29s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [36:32<00:00, 43.84s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.1632} | lm_loss 10.2235 | avg. gen lenth: 354.608
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o4-tcommonsenseqa-s10-rTrue --seed 10 --rationales --num-out-domain 4
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-13 03:19:38,466] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o4-tcommonsenseqa-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 4
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o4-tcommonsenseqa-s10-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  0%|▏                                                    | 23/7473 [00:00<00:33, 224.07it/s]  1%|▎                                                    | 48/7473 [00:00<00:31, 236.75it/s]  1%|▌                                                    | 75/7473 [00:00<00:29, 248.52it/s]  1%|▋                                                   | 102/7473 [00:00<00:28, 254.46it/s]  2%|▉                                                   | 129/7473 [00:00<00:28, 257.63it/s]  2%|█                                                   | 156/7473 [00:00<00:28, 260.08it/s]  2%|█▎                                                  | 183/7473 [00:00<00:27, 260.38it/s]  3%|█▍                                                  | 210/7473 [00:00<00:27, 261.75it/s]  3%|█▋                                                  | 237/7473 [00:00<00:28, 252.60it/s]  4%|█▊                                                  | 263/7473 [00:01<00:28, 252.29it/s]  4%|██                                                  | 290/7473 [00:01<00:28, 255.88it/s]  4%|██▏                                                 | 317/7473 [00:01<00:27, 257.40it/s]  5%|██▍                                                 | 343/7473 [00:01<00:28, 250.50it/s]  5%|██▌                                                 | 369/7473 [00:01<00:28, 252.24it/s]  5%|██▊                                                 | 396/7473 [00:01<00:27, 255.32it/s]  6%|██▉                                                 | 422/7473 [00:01<00:27, 256.20it/s]  6%|███                                                 | 449/7473 [00:01<00:27, 257.93it/s]  6%|███▎                                                | 476/7473 [00:01<00:27, 257.66it/s]  7%|███▍                                                | 502/7473 [00:01<00:27, 257.07it/s]  7%|███▋                                                | 529/7473 [00:02<00:26, 259.21it/s]  7%|███▊                                                | 556/7473 [00:02<00:26, 261.04it/s]  8%|████                                                | 583/7473 [00:02<00:26, 261.47it/s]  8%|████▏                                               | 610/7473 [00:02<00:26, 261.12it/s]  9%|████▍                                               | 637/7473 [00:02<00:26, 261.53it/s]  9%|████▌                                               | 664/7473 [00:02<00:25, 262.23it/s]  9%|████▊                                               | 691/7473 [00:02<00:25, 263.11it/s] 10%|████▉                                               | 718/7473 [00:02<00:25, 262.76it/s] 10%|█████▏                                              | 745/7473 [00:02<00:25, 263.61it/s] 10%|█████▎                                              | 772/7473 [00:02<00:25, 263.68it/s] 11%|█████▌                                              | 799/7473 [00:03<00:25, 263.44it/s] 11%|█████▋                                              | 826/7473 [00:03<00:25, 261.49it/s] 11%|█████▉                                              | 853/7473 [00:03<00:25, 262.72it/s] 12%|██████                                              | 880/7473 [00:03<00:25, 263.03it/s] 12%|██████▎                                             | 907/7473 [00:03<00:24, 263.60it/s] 12%|██████▍                                             | 934/7473 [00:03<00:24, 261.88it/s] 13%|██████▋                                             | 961/7473 [00:03<00:24, 263.38it/s] 13%|██████▊                                             | 988/7473 [00:03<00:24, 264.37it/s] 14%|██████▉                                            | 1015/7473 [00:03<00:24, 263.79it/s] 14%|███████                                            | 1042/7473 [00:04<00:24, 263.55it/s] 14%|███████▎                                           | 1069/7473 [00:04<00:24, 263.98it/s] 15%|███████▍                                           | 1096/7473 [00:04<00:24, 263.61it/s] 15%|███████▋                                           | 1123/7473 [00:04<00:24, 263.15it/s] 15%|███████▊                                           | 1150/7473 [00:04<00:24, 263.02it/s] 16%|████████                                           | 1177/7473 [00:04<00:24, 261.01it/s] 16%|████████▎                                          | 1217/7473 [00:04<00:20, 300.85it/s] 17%|████████▌                                          | 1257/7473 [00:04<00:18, 329.24it/s] 17%|████████▊                                          | 1297/7473 [00:04<00:17, 349.95it/s] 18%|█████████▏                                         | 1338/7473 [00:04<00:16, 365.50it/s] 18%|█████████▍                                         | 1378/7473 [00:05<00:16, 375.36it/s] 19%|█████████▋                                         | 1417/7473 [00:05<00:15, 379.66it/s] 19%|█████████▉                                         | 1457/7473 [00:05<00:15, 385.53it/s] 20%|██████████▏                                        | 1498/7473 [00:05<00:15, 390.33it/s] 21%|██████████▌                                        | 1539/7473 [00:05<00:15, 393.32it/s] 21%|██████████▊                                        | 1579/7473 [00:05<00:14, 393.55it/s] 22%|███████████                                        | 1619/7473 [00:05<00:14, 393.08it/s] 22%|███████████▎                                       | 1659/7473 [00:05<00:14, 394.11it/s] 23%|███████████▌                                       | 1699/7473 [00:05<00:14, 395.59it/s] 23%|███████████▊                                       | 1739/7473 [00:05<00:14, 394.40it/s] 24%|████████████▏                                      | 1779/7473 [00:06<00:14, 394.82it/s] 24%|████████████▍                                      | 1819/7473 [00:06<00:14, 394.34it/s] 25%|████████████▋                                      | 1859/7473 [00:06<00:14, 391.94it/s] 25%|████████████▉                                      | 1899/7473 [00:06<00:14, 392.87it/s] 26%|█████████████▏                                     | 1939/7473 [00:06<00:14, 392.15it/s] 26%|█████████████▌                                     | 1979/7473 [00:06<00:13, 393.59it/s] 27%|█████████████▊                                     | 2019/7473 [00:06<00:13, 393.93it/s] 28%|██████████████                                     | 2059/7473 [00:06<00:13, 394.75it/s] 28%|██████████████▎                                    | 2099/7473 [00:06<00:13, 393.45it/s] 29%|██████████████▌                                    | 2139/7473 [00:06<00:13, 394.29it/s] 29%|██████████████▊                                    | 2179/7473 [00:07<00:13, 395.41it/s] 30%|███████████████▏                                   | 2219/7473 [00:07<00:13, 395.30it/s] 30%|███████████████▍                                   | 2259/7473 [00:07<00:13, 395.61it/s] 31%|███████████████▋                                   | 2299/7473 [00:07<00:13, 393.35it/s] 31%|███████████████▉                                   | 2339/7473 [00:07<00:13, 394.08it/s] 32%|████████████████▏                                  | 2379/7473 [00:07<00:12, 394.29it/s] 32%|████████████████▌                                  | 2419/7473 [00:07<00:12, 394.84it/s] 33%|████████████████▊                                  | 2459/7473 [00:07<00:12, 394.98it/s] 33%|█████████████████                                  | 2499/7473 [00:07<00:12, 393.76it/s] 34%|█████████████████▎                                 | 2539/7473 [00:08<00:13, 361.44it/s] 35%|█████████████████▌                                 | 2579/7473 [00:08<00:13, 370.57it/s] 35%|█████████████████▊                                 | 2619/7473 [00:08<00:12, 376.34it/s] 36%|██████████████████▏                                | 2659/7473 [00:08<00:12, 381.33it/s] 36%|██████████████████▍                                | 2699/7473 [00:08<00:12, 384.06it/s] 37%|██████████████████▋                                | 2739/7473 [00:08<00:12, 386.18it/s] 37%|██████████████████▉                                | 2778/7473 [00:08<00:12, 386.09it/s] 38%|███████████████████▏                               | 2818/7473 [00:08<00:11, 388.03it/s] 38%|███████████████████▍                               | 2857/7473 [00:08<00:11, 388.17it/s] 39%|███████████████████▊                               | 2896/7473 [00:08<00:11, 388.39it/s] 39%|████████████████████                               | 2936/7473 [00:09<00:11, 390.12it/s] 40%|████████████████████▎                              | 2976/7473 [00:09<00:11, 388.58it/s] 40%|████████████████████▌                              | 3015/7473 [00:09<00:11, 388.38it/s] 41%|████████████████████▊                              | 3054/7473 [00:09<00:11, 388.04it/s] 41%|█████████████████████                              | 3093/7473 [00:09<00:11, 388.21it/s] 42%|█████████████████████▎                             | 3132/7473 [00:09<00:11, 388.02it/s] 42%|█████████████████████▋                             | 3171/7473 [00:09<00:11, 386.03it/s] 43%|█████████████████████▉                             | 3210/7473 [00:09<00:11, 385.86it/s] 43%|██████████████████████▏                            | 3250/7473 [00:09<00:10, 388.24it/s] 44%|██████████████████████▍                            | 3290/7473 [00:09<00:10, 390.66it/s] 45%|██████████████████████▋                            | 3330/7473 [00:10<00:10, 390.75it/s] 45%|██████████████████████▉                            | 3370/7473 [00:10<00:10, 390.29it/s] 46%|███████████████████████▎                           | 3410/7473 [00:10<00:10, 388.64it/s] 46%|███████████████████████▌                           | 3449/7473 [00:10<00:10, 386.44it/s] 47%|███████████████████████▊                           | 3489/7473 [00:10<00:10, 388.66it/s] 47%|████████████████████████                           | 3529/7473 [00:10<00:10, 390.89it/s] 48%|████████████████████████▎                          | 3569/7473 [00:10<00:09, 392.43it/s] 48%|████████████████████████▋                          | 3609/7473 [00:10<00:09, 394.03it/s] 49%|████████████████████████▉                          | 3649/7473 [00:10<00:09, 393.44it/s] 49%|█████████████████████████▏                         | 3689/7473 [00:10<00:09, 392.40it/s] 50%|█████████████████████████▍                         | 3729/7473 [00:11<00:09, 392.78it/s] 50%|█████████████████████████▋                         | 3769/7473 [00:11<00:09, 392.83it/s] 51%|█████████████████████████▉                         | 3809/7473 [00:11<00:09, 392.82it/s] 52%|██████████████████████████▎                        | 3849/7473 [00:11<00:09, 392.84it/s] 52%|██████████████████████████▌                        | 3889/7473 [00:11<00:09, 391.91it/s] 53%|██████████████████████████▊                        | 3929/7473 [00:11<00:09, 393.17it/s] 53%|███████████████████████████                        | 3969/7473 [00:11<00:08, 393.77it/s] 54%|███████████████████████████▎                       | 4009/7473 [00:11<00:08, 394.70it/s] 54%|███████████████████████████▋                       | 4049/7473 [00:11<00:08, 394.78it/s] 55%|███████████████████████████▉                       | 4089/7473 [00:11<00:08, 394.17it/s] 55%|████████████████████████████▏                      | 4129/7473 [00:12<00:08, 390.17it/s] 56%|████████████████████████████▍                      | 4169/7473 [00:12<00:08, 390.54it/s] 56%|████████████████████████████▋                      | 4209/7473 [00:12<00:08, 391.69it/s] 57%|████████████████████████████▉                      | 4249/7473 [00:12<00:08, 392.90it/s] 57%|█████████████████████████████▎                     | 4289/7473 [00:12<00:08, 392.10it/s] 58%|█████████████████████████████▌                     | 4329/7473 [00:12<00:08, 391.91it/s] 58%|█████████████████████████████▊                     | 4369/7473 [00:12<00:07, 390.78it/s] 59%|██████████████████████████████                     | 4409/7473 [00:12<00:07, 391.90it/s] 60%|██████████████████████████████▎                    | 4449/7473 [00:12<00:07, 392.31it/s] 60%|██████████████████████████████▋                    | 4489/7473 [00:13<00:07, 387.16it/s] 61%|██████████████████████████████▉                    | 4528/7473 [00:13<00:07, 387.85it/s] 61%|███████████████████████████████▏                   | 4567/7473 [00:13<00:07, 388.29it/s] 62%|███████████████████████████████▍                   | 4607/7473 [00:13<00:07, 390.98it/s] 62%|███████████████████████████████▋                   | 4647/7473 [00:13<00:07, 391.99it/s] 63%|███████████████████████████████▉                   | 4687/7473 [00:13<00:07, 393.37it/s] 63%|████████████████████████████████▎                  | 4727/7473 [00:13<00:06, 394.48it/s] 64%|████████████████████████████████▌                  | 4767/7473 [00:13<00:06, 393.78it/s] 64%|████████████████████████████████▊                  | 4807/7473 [00:13<00:06, 391.48it/s] 65%|█████████████████████████████████                  | 4847/7473 [00:13<00:06, 393.13it/s] 65%|█████████████████████████████████▎                 | 4887/7473 [00:14<00:06, 392.64it/s] 66%|█████████████████████████████████▌                 | 4927/7473 [00:14<00:06, 392.90it/s] 66%|█████████████████████████████████▉                 | 4967/7473 [00:14<00:06, 392.50it/s] 67%|██████████████████████████████████▏                | 5007/7473 [00:14<00:06, 393.47it/s] 68%|██████████████████████████████████▍                | 5047/7473 [00:14<00:06, 392.16it/s] 68%|██████████████████████████████████▋                | 5087/7473 [00:14<00:06, 392.53it/s] 69%|██████████████████████████████████▉                | 5127/7473 [00:14<00:05, 392.72it/s] 69%|███████████████████████████████████▎               | 5167/7473 [00:14<00:05, 389.35it/s] 70%|███████████████████████████████████▌               | 5207/7473 [00:14<00:05, 390.52it/s] 70%|███████████████████████████████████▊               | 5247/7473 [00:14<00:06, 364.80it/s] 71%|████████████████████████████████████               | 5287/7473 [00:15<00:05, 373.16it/s] 71%|████████████████████████████████████▎              | 5327/7473 [00:15<00:05, 379.36it/s] 72%|████████████████████████████████████▋              | 5367/7473 [00:15<00:05, 384.13it/s] 72%|████████████████████████████████████▉              | 5407/7473 [00:15<00:05, 388.14it/s] 73%|█████████████████████████████████████▏             | 5447/7473 [00:15<00:05, 390.73it/s] 73%|█████████████████████████████████████▍             | 5487/7473 [00:15<00:07, 277.31it/s] 74%|█████████████████████████████████████▋             | 5527/7473 [00:15<00:06, 304.51it/s] 74%|█████████████████████████████████████▉             | 5567/7473 [00:15<00:05, 326.98it/s] 75%|██████████████████████████████████████▎            | 5607/7473 [00:16<00:05, 344.33it/s] 76%|██████████████████████████████████████▌            | 5647/7473 [00:16<00:05, 359.02it/s] 76%|██████████████████████████████████████▊            | 5686/7473 [00:16<00:04, 366.46it/s] 77%|███████████████████████████████████████            | 5726/7473 [00:16<00:04, 375.07it/s] 77%|███████████████████████████████████████▎           | 5765/7473 [00:16<00:04, 378.22it/s] 78%|███████████████████████████████████████▌           | 5805/7473 [00:16<00:04, 382.19it/s] 78%|███████████████████████████████████████▉           | 5845/7473 [00:16<00:04, 385.61it/s] 79%|████████████████████████████████████████▏          | 5885/7473 [00:16<00:04, 388.53it/s] 79%|████████████████████████████████████████▍          | 5925/7473 [00:16<00:03, 387.85it/s] 80%|████████████████████████████████████████▋          | 5965/7473 [00:16<00:03, 389.21it/s] 80%|████████████████████████████████████████▉          | 6005/7473 [00:17<00:03, 391.28it/s] 81%|█████████████████████████████████████████▎         | 6045/7473 [00:17<00:03, 392.88it/s] 81%|█████████████████████████████████████████▌         | 6085/7473 [00:17<00:03, 394.34it/s] 82%|█████████████████████████████████████████▊         | 6125/7473 [00:17<00:03, 395.26it/s] 82%|██████████████████████████████████████████         | 6165/7473 [00:17<00:03, 393.73it/s] 83%|██████████████████████████████████████████▎        | 6205/7473 [00:17<00:03, 393.89it/s] 84%|██████████████████████████████████████████▌        | 6245/7473 [00:17<00:03, 393.97it/s] 84%|██████████████████████████████████████████▉        | 6285/7473 [00:17<00:03, 394.58it/s] 85%|███████████████████████████████████████████▏       | 6325/7473 [00:17<00:02, 395.53it/s] 85%|███████████████████████████████████████████▍       | 6365/7473 [00:17<00:02, 393.91it/s] 86%|███████████████████████████████████████████▋       | 6405/7473 [00:18<00:02, 393.70it/s] 86%|███████████████████████████████████████████▉       | 6445/7473 [00:18<00:02, 390.99it/s] 87%|████████████████████████████████████████████▎      | 6485/7473 [00:18<00:02, 391.99it/s] 87%|████████████████████████████████████████████▌      | 6525/7473 [00:18<00:02, 392.71it/s] 88%|████████████████████████████████████████████▊      | 6565/7473 [00:18<00:02, 394.20it/s] 88%|█████████████████████████████████████████████      | 6605/7473 [00:18<00:02, 392.53it/s] 89%|█████████████████████████████████████████████▎     | 6645/7473 [00:18<00:02, 392.74it/s] 89%|█████████████████████████████████████████████▌     | 6685/7473 [00:18<00:02, 393.51it/s] 90%|█████████████████████████████████████████████▉     | 6725/7473 [00:18<00:01, 393.65it/s] 91%|██████████████████████████████████████████████▏    | 6765/7473 [00:18<00:01, 392.99it/s] 91%|██████████████████████████████████████████████▍    | 6805/7473 [00:19<00:01, 392.82it/s] 92%|██████████████████████████████████████████████▋    | 6845/7473 [00:19<00:01, 390.68it/s] 92%|██████████████████████████████████████████████▉    | 6885/7473 [00:19<00:01, 391.83it/s] 93%|███████████████████████████████████████████████▎   | 6925/7473 [00:19<00:01, 392.62it/s] 93%|███████████████████████████████████████████████▌   | 6965/7473 [00:19<00:01, 392.33it/s] 94%|███████████████████████████████████████████████▊   | 7005/7473 [00:19<00:01, 391.96it/s] 94%|████████████████████████████████████████████████   | 7045/7473 [00:19<00:01, 385.93it/s] 95%|████████████████████████████████████████████████▎  | 7084/7473 [00:19<00:01, 382.66it/s] 95%|████████████████████████████████████████████████▌  | 7124/7473 [00:19<00:00, 385.31it/s] 96%|████████████████████████████████████████████████▉  | 7164/7473 [00:19<00:00, 387.36it/s] 96%|█████████████████████████████████████████████████▏ | 7204/7473 [00:20<00:00, 389.39it/s] 97%|█████████████████████████████████████████████████▍ | 7244/7473 [00:20<00:00, 390.69it/s] 97%|█████████████████████████████████████████████████▋ | 7284/7473 [00:20<00:00, 388.32it/s] 98%|█████████████████████████████████████████████████▉ | 7324/7473 [00:20<00:00, 389.46it/s] 99%|██████████████████████████████████████████████████▏| 7363/7473 [00:20<00:00, 389.61it/s] 99%|██████████████████████████████████████████████████▌| 7403/7473 [00:20<00:00, 390.01it/s]100%|██████████████████████████████████████████████████▊| 7443/7473 [00:20<00:00, 389.94it/s]100%|███████████████████████████████████████████████████| 7473/7473 [00:20<00:00, 359.68it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:04<00:09,  4.81s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:04<00:09,  4.97s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.33s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.43s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:09<00:04,  4.90s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.02s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.34s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.38s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.29s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.45s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.39s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.55s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.74s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.90s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.80s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.97s/it]
[2023-08-13 03:20:51,935] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-13 03:21:01,425] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-13 03:21:01,426] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f021e9eed60>
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-13 03:21:01,427] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f021e9ee8b0>
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-13 03:21:01,428] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-13 03:21:01,428] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.49342823028564453 seconds
Loading extension module utils...
Time to load utils op: 0.40462183952331543 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Fabric is cut to order at what type of seller? Choices:  A: curtains B: tailor shop C: clothing store D: sewing room E: hardware store
Rationales: The question asks for where fabric is cut to order. 

The option A: curtains, doesn't work because curtains refer to a type of product, not a place where fabric can be cut to order. 

The option C: clothing store, could be potentially correct since clothing stores deal with fabric. However, most clothing stores sell pre-made clothes, not fabric cut to order.

Option D: sewing room can be eliminated, despite the fact that fabric is cut there, it is not a commercial place or a seller. It rather refers to a personal space where someone might cut their own fabric.

Option E: hardware store mostly deals with tools and materials related to construction and hardware, not fabric.

So this leaves us with option B: Tailor shop. Tailor shops do indeed cut fabric to order to create custom clothing, which makes B: tailor shop the correct answer.
Answer: B: tailor shop

Input: Where are you if your reading magazines while waiting for a vehicle on rails? Choices:  A: vegetables B: market C: doctor D: train station E: bookstore
Rationales: 1. The question is asking for a location where someone is waiting for a vehicle on rails while reading magazines. 
2. Vehicle on rails refers to a train or subway. 
3. The place where travelers wait for a train or subway to arrive is a train station. 
4. Therefore, D: train station is the correct choice.
Answer: D: train station

Input: What would need oil to be used? Choices:  A: ground B: human  body C: repair shop D: combustion engines E: service station
Rationales: 1. The question asks for something that requires oil to be used. 
2. We know that oil is a type of fuel or lubricant, which is often used in machines and engines to ensure their proper functioning.
3. Let's evaluate each of the given options in relation to the clue provided.
4. Option A, the ground, does not require oil for it to function.
5. Option B, the human body, while it requires oils in the form of natural body oils and dietary fats, does not use the type of oil typically associated with engines or machinery.
6. Option C, a repair shop, is a location and therefore, doesn't independently require oil, though it may house machines that do.
7. Option D, combustion engines, indeed need oil for lubrication and to help facilitate the combustion process.
8. Option E, a service station, like option C, is a location and doesn't directly require oil, though it may sell it.
9. Given this evaluation, we can see that out of the available options, combustion engines, option D, is the most relevant and correct answer, as they indeed require oil for their operation.
Answer: D: combustion engines

Input: What is person probably feeling that plans on stopping being married to their spouse? Choices:  A: detachment B: bankruptcy C: sad D: fights E: wrong
Rationales: Step 1: Identify the key action from the question: The person plans on to stop being married, which suggests an emotional distancing or separation from their spouse.
Step 2: Reflect on the possible emotional states linked to this action: This could potentially be linked to feelings of sadness, anger, or detachment.
Step 3: Evaluate each of the options provided:
Option A: Detachment - This can be logically linked to the desire of wanting to stop being married as it requires a certain degree of emotional distancing from the spouse.
Option B: Bankruptcy - This option is a financial state and not a feeling or emotion, hence discarded.
Option C: Sad - This could potentially be a feeling a person who plans on stopping being married might experience. However, it is generally a consequence of the detachment and not the cause of wanting to end a marriage.
Option D: Fights - This is a state of conflict, not a feeling or emotion a person might have while planning to end a marriage.
Option E: Wrong - This is a moral judgement or conclusion, not an emotional state.
Step 4: Select the most appropriate option: Based on the emotional state that drives the action of wanting to stop being married, the most appropriate choice is A: Detachment.
Answer: A: detachment

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o4-tcommonsenseqa-s10-rTrue
Loading extension module utils...
Time to load utils op: 0.404524564743042 seconds
Loading extension module utils...
Time to load utils op: 0.5045599937438965 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:44<36:03, 44.15s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:27<34:50, 43.55s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:10<33:57, 43.35s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [02:53<33:08, 43.23s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [03:28<30:19, 40.43s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [04:11<30:18, 41.33s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [04:55<30:07, 42.04s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [05:38<29:42, 42.44s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [06:22<29:17, 42.87s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [07:06<28:41, 43.04s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [07:49<28:02, 43.13s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [08:32<27:17, 43.10s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [09:16<26:40, 43.26s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [09:59<26:03, 43.43s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [10:43<25:27, 43.64s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [11:26<24:37, 43.44s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [12:10<23:58, 43.58s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [12:54<23:17, 43.67s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [13:37<22:27, 43.46s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [14:20<21:37, 43.25s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [15:03<20:52, 43.18s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [15:47<20:13, 43.33s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [16:30<19:29, 43.33s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [17:13<18:45, 43.30s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [17:57<18:02, 43.32s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [18:40<17:17, 43.25s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [19:23<16:33, 43.20s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [20:06<15:52, 43.28s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [20:49<15:06, 43.14s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [21:32<14:22, 43.11s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [22:16<13:43, 43.37s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [22:59<12:57, 43.20s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [23:42<12:15, 43.27s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [24:26<11:33, 43.34s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [25:04<10:28, 41.88s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [25:47<09:50, 42.18s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [26:31<09:13, 42.54s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [27:14<08:33, 42.83s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [27:57<07:52, 42.95s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [28:41<07:12, 43.21s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [29:24<06:27, 43.10s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [30:07<05:45, 43.22s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [30:50<05:02, 43.17s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [31:33<04:18, 43.10s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [32:17<03:36, 43.34s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [33:01<02:53, 43.29s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [33:44<02:09, 43.24s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [34:28<01:26, 43.45s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [35:11<00:43, 43.46s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [35:55<00:00, 43.55s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [35:55<00:00, 43.11s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.1893} | lm_loss 10.2116 | avg. gen lenth: 348.94
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o5-tcommonsenseqa-s10-rTrue --seed 10 --rationales --num-out-domain 5
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-13 03:57:07,407] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o5-tcommonsenseqa-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 5
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o5-tcommonsenseqa-s10-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  0%|▏                                                    | 19/7473 [00:00<00:39, 189.49it/s]  1%|▎                                                    | 38/7473 [00:00<00:39, 189.38it/s]  1%|▍                                                    | 58/7473 [00:00<00:39, 189.88it/s]  1%|▌                                                    | 77/7473 [00:00<00:38, 189.89it/s]  1%|▋                                                    | 97/7473 [00:00<00:38, 190.52it/s]  2%|▊                                                   | 117/7473 [00:00<00:38, 190.29it/s]  2%|▉                                                   | 137/7473 [00:00<00:38, 188.28it/s]  2%|█                                                   | 157/7473 [00:00<00:38, 189.16it/s]  2%|█▏                                                  | 177/7473 [00:00<00:38, 189.59it/s]  3%|█▎                                                  | 197/7473 [00:01<00:38, 190.10it/s]  3%|█▌                                                  | 217/7473 [00:01<00:38, 190.11it/s]  3%|█▋                                                  | 237/7473 [00:01<00:38, 189.81it/s]  3%|█▊                                                  | 256/7473 [00:01<00:38, 187.81it/s]  4%|█▉                                                  | 276/7473 [00:01<00:38, 188.62it/s]  4%|██                                                  | 296/7473 [00:01<00:37, 189.06it/s]  4%|██▏                                                 | 315/7473 [00:01<00:37, 189.30it/s]  4%|██▎                                                 | 334/7473 [00:01<00:37, 187.97it/s]  5%|██▍                                                 | 353/7473 [00:01<00:37, 188.11it/s]  5%|██▌                                                 | 372/7473 [00:01<00:37, 188.01it/s]  5%|██▋                                                 | 391/7473 [00:02<00:37, 188.47it/s]  5%|██▊                                                 | 410/7473 [00:02<00:37, 188.11it/s]  6%|██▉                                                 | 429/7473 [00:02<00:37, 188.38it/s]  6%|███                                                 | 448/7473 [00:02<00:37, 188.40it/s]  6%|███▏                                                | 467/7473 [00:02<00:37, 188.57it/s]  7%|███▍                                                | 487/7473 [00:02<00:36, 191.22it/s]  7%|███▌                                                | 516/7473 [00:02<00:31, 220.26it/s]  7%|███▊                                                | 545/7473 [00:02<00:28, 241.03it/s]  8%|███▉                                                | 574/7473 [00:02<00:27, 255.32it/s]  8%|████▏                                               | 603/7473 [00:02<00:25, 264.68it/s]  8%|████▍                                               | 632/7473 [00:03<00:25, 271.42it/s]  9%|████▌                                               | 661/7473 [00:03<00:24, 276.12it/s]  9%|████▊                                               | 690/7473 [00:03<00:24, 280.11it/s] 10%|█████                                               | 719/7473 [00:03<00:24, 281.03it/s] 10%|█████▏                                              | 748/7473 [00:03<00:23, 283.06it/s] 10%|█████▍                                              | 777/7473 [00:03<00:23, 283.66it/s] 11%|█████▌                                              | 806/7473 [00:03<00:23, 284.07it/s] 11%|█████▊                                              | 835/7473 [00:03<00:23, 284.59it/s] 12%|██████                                              | 864/7473 [00:03<00:23, 284.70it/s] 12%|██████▏                                             | 894/7473 [00:03<00:22, 286.41it/s] 12%|██████▍                                             | 924/7473 [00:04<00:22, 288.01it/s] 13%|██████▋                                             | 953/7473 [00:04<00:22, 287.53it/s] 13%|██████▊                                             | 983/7473 [00:04<00:22, 289.53it/s] 14%|██████▉                                            | 1012/7473 [00:04<00:22, 288.81it/s] 14%|███████                                            | 1042/7473 [00:04<00:22, 289.80it/s] 14%|███████▎                                           | 1072/7473 [00:04<00:22, 290.89it/s] 15%|███████▌                                           | 1102/7473 [00:04<00:21, 291.47it/s] 15%|███████▋                                           | 1132/7473 [00:04<00:21, 291.00it/s] 16%|███████▉                                           | 1162/7473 [00:04<00:21, 289.65it/s] 16%|████████▏                                          | 1192/7473 [00:05<00:21, 290.38it/s] 16%|████████▎                                          | 1222/7473 [00:05<00:21, 290.62it/s] 17%|████████▌                                          | 1252/7473 [00:05<00:21, 290.87it/s] 17%|████████▋                                          | 1282/7473 [00:05<00:21, 290.97it/s] 18%|████████▉                                          | 1312/7473 [00:05<00:21, 291.33it/s] 18%|█████████▏                                         | 1342/7473 [00:05<00:21, 291.79it/s] 18%|█████████▎                                         | 1372/7473 [00:05<00:21, 288.92it/s] 19%|█████████▌                                         | 1401/7473 [00:05<00:21, 286.72it/s] 19%|█████████▊                                         | 1431/7473 [00:05<00:20, 287.96it/s] 20%|█████████▉                                         | 1461/7473 [00:05<00:20, 289.19it/s] 20%|██████████▏                                        | 1491/7473 [00:06<00:20, 290.21it/s] 20%|██████████▍                                        | 1521/7473 [00:06<00:20, 291.01it/s] 21%|██████████▌                                        | 1551/7473 [00:06<00:20, 290.59it/s] 21%|██████████▊                                        | 1581/7473 [00:06<00:20, 289.95it/s] 22%|██████████▉                                        | 1611/7473 [00:06<00:20, 288.66it/s] 22%|███████████▏                                       | 1641/7473 [00:06<00:20, 289.63it/s] 22%|███████████▍                                       | 1671/7473 [00:06<00:20, 289.96it/s] 23%|███████████▌                                       | 1701/7473 [00:06<00:19, 290.52it/s] 23%|███████████▊                                       | 1731/7473 [00:06<00:19, 291.24it/s] 24%|████████████                                       | 1761/7473 [00:06<00:19, 288.34it/s] 24%|████████████▏                                      | 1790/7473 [00:07<00:19, 288.82it/s] 24%|████████████▍                                      | 1820/7473 [00:07<00:19, 289.62it/s] 25%|████████████▌                                      | 1849/7473 [00:07<00:19, 286.62it/s] 25%|████████████▊                                      | 1879/7473 [00:07<00:19, 288.17it/s] 26%|█████████████                                      | 1908/7473 [00:07<00:19, 288.37it/s] 26%|█████████████▏                                     | 1938/7473 [00:07<00:19, 288.84it/s] 26%|█████████████▍                                     | 1968/7473 [00:07<00:18, 289.94it/s] 27%|█████████████▋                                     | 1998/7473 [00:07<00:18, 290.47it/s] 27%|█████████████▊                                     | 2028/7473 [00:07<00:18, 291.03it/s] 28%|██████████████                                     | 2058/7473 [00:08<00:18, 291.29it/s] 28%|██████████████▏                                    | 2088/7473 [00:08<00:18, 289.23it/s] 28%|██████████████▍                                    | 2118/7473 [00:08<00:18, 289.74it/s] 29%|██████████████▋                                    | 2148/7473 [00:08<00:18, 290.02it/s] 29%|██████████████▊                                    | 2178/7473 [00:08<00:18, 290.57it/s] 30%|███████████████                                    | 2208/7473 [00:08<00:18, 290.60it/s] 30%|███████████████▎                                   | 2238/7473 [00:08<00:18, 290.60it/s] 30%|███████████████▍                                   | 2268/7473 [00:08<00:17, 290.07it/s] 31%|███████████████▋                                   | 2298/7473 [00:08<00:17, 288.16it/s] 31%|███████████████▉                                   | 2328/7473 [00:08<00:17, 289.10it/s] 32%|████████████████                                   | 2357/7473 [00:09<00:17, 289.21it/s] 32%|████████████████▎                                  | 2387/7473 [00:09<00:17, 289.41it/s] 32%|████████████████▍                                  | 2417/7473 [00:09<00:17, 289.72it/s] 33%|████████████████▋                                  | 2447/7473 [00:09<00:17, 290.23it/s] 33%|████████████████▉                                  | 2477/7473 [00:09<00:17, 290.03it/s] 34%|█████████████████                                  | 2507/7473 [00:09<00:17, 289.95it/s] 34%|█████████████████▎                                 | 2536/7473 [00:09<00:19, 257.47it/s] 34%|█████████████████▌                                 | 2565/7473 [00:09<00:18, 266.21it/s] 35%|█████████████████▋                                 | 2594/7473 [00:09<00:17, 272.84it/s] 35%|█████████████████▉                                 | 2624/7473 [00:10<00:17, 277.89it/s] 36%|██████████████████                                 | 2654/7473 [00:10<00:17, 281.70it/s] 36%|██████████████████▎                                | 2684/7473 [00:10<00:16, 284.40it/s] 36%|██████████████████▌                                | 2714/7473 [00:10<00:16, 286.02it/s] 37%|██████████████████▋                                | 2743/7473 [00:10<00:16, 286.79it/s] 37%|██████████████████▉                                | 2772/7473 [00:10<00:16, 286.10it/s] 37%|███████████████████                                | 2802/7473 [00:10<00:16, 287.39it/s] 38%|███████████████████▎                               | 2831/7473 [00:10<00:16, 288.06it/s] 38%|███████████████████▌                               | 2860/7473 [00:10<00:15, 288.35it/s] 39%|███████████████████▋                               | 2889/7473 [00:10<00:15, 288.51it/s] 39%|███████████████████▉                               | 2919/7473 [00:11<00:15, 289.01it/s] 39%|████████████████████▏                              | 2949/7473 [00:11<00:15, 289.83it/s] 40%|████████████████████▎                              | 2978/7473 [00:11<00:15, 287.92it/s] 40%|████████████████████▌                              | 3007/7473 [00:11<00:15, 288.35it/s] 41%|████████████████████▋                              | 3036/7473 [00:11<00:15, 288.35it/s] 41%|████████████████████▉                              | 3065/7473 [00:11<00:15, 288.63it/s] 41%|█████████████████████                              | 3094/7473 [00:11<00:15, 288.67it/s] 42%|█████████████████████▎                             | 3123/7473 [00:11<00:15, 288.21it/s] 42%|█████████████████████▌                             | 3152/7473 [00:11<00:15, 287.99it/s] 43%|█████████████████████▋                             | 3181/7473 [00:11<00:14, 288.12it/s] 43%|█████████████████████▉                             | 3210/7473 [00:12<00:14, 286.74it/s] 43%|██████████████████████                             | 3239/7473 [00:12<00:14, 287.25it/s] 44%|██████████████████████▎                            | 3268/7473 [00:12<00:14, 287.85it/s] 44%|██████████████████████▌                            | 3297/7473 [00:12<00:14, 288.37it/s] 45%|██████████████████████▋                            | 3326/7473 [00:12<00:14, 288.10it/s] 45%|██████████████████████▉                            | 3355/7473 [00:12<00:14, 287.74it/s] 45%|███████████████████████                            | 3384/7473 [00:12<00:14, 288.29it/s] 46%|███████████████████████▎                           | 3413/7473 [00:12<00:14, 288.45it/s] 46%|███████████████████████▍                           | 3442/7473 [00:12<00:14, 287.47it/s] 46%|███████████████████████▋                           | 3471/7473 [00:12<00:13, 287.72it/s] 47%|███████████████████████▉                           | 3501/7473 [00:13<00:13, 289.22it/s] 47%|████████████████████████                           | 3530/7473 [00:13<00:13, 289.44it/s] 48%|████████████████████████▎                          | 3560/7473 [00:13<00:13, 289.93it/s] 48%|████████████████████████▍                          | 3589/7473 [00:13<00:13, 289.67it/s] 48%|████████████████████████▋                          | 3619/7473 [00:13<00:13, 290.05it/s] 49%|████████████████████████▉                          | 3649/7473 [00:13<00:13, 289.33it/s] 49%|█████████████████████████                          | 3678/7473 [00:13<00:13, 287.91it/s] 50%|█████████████████████████▎                         | 3708/7473 [00:13<00:13, 288.73it/s] 50%|█████████████████████████▌                         | 3738/7473 [00:13<00:12, 289.53it/s] 50%|█████████████████████████▋                         | 3768/7473 [00:13<00:12, 289.83it/s] 51%|█████████████████████████▉                         | 3798/7473 [00:14<00:12, 290.41it/s] 51%|██████████████████████████                         | 3828/7473 [00:14<00:12, 290.55it/s] 52%|██████████████████████████▎                        | 3858/7473 [00:14<00:12, 290.10it/s] 52%|██████████████████████████▌                        | 3888/7473 [00:14<00:12, 288.57it/s] 52%|██████████████████████████▋                        | 3918/7473 [00:14<00:12, 289.59it/s] 53%|██████████████████████████▉                        | 3948/7473 [00:14<00:12, 290.02it/s] 53%|███████████████████████████▏                       | 3978/7473 [00:14<00:12, 290.14it/s] 54%|███████████████████████████▎                       | 4008/7473 [00:14<00:11, 290.74it/s] 54%|███████████████████████████▌                       | 4038/7473 [00:14<00:11, 291.21it/s] 54%|███████████████████████████▊                       | 4068/7473 [00:14<00:11, 291.09it/s] 55%|███████████████████████████▉                       | 4098/7473 [00:15<00:11, 290.61it/s] 55%|████████████████████████████▏                      | 4128/7473 [00:15<00:11, 287.92it/s] 56%|████████████████████████████▎                      | 4157/7473 [00:15<00:11, 288.38it/s] 56%|████████████████████████████▌                      | 4187/7473 [00:15<00:11, 288.89it/s] 56%|████████████████████████████▊                      | 4217/7473 [00:15<00:11, 289.33it/s] 57%|████████████████████████████▉                      | 4247/7473 [00:15<00:11, 290.13it/s] 57%|█████████████████████████████▏                     | 4277/7473 [00:15<00:11, 289.78it/s] 58%|█████████████████████████████▍                     | 4307/7473 [00:15<00:10, 289.92it/s] 58%|█████████████████████████████▌                     | 4336/7473 [00:15<00:10, 288.81it/s] 58%|█████████████████████████████▊                     | 4366/7473 [00:16<00:10, 289.36it/s] 59%|██████████████████████████████                     | 4396/7473 [00:16<00:10, 289.65it/s] 59%|██████████████████████████████▏                    | 4425/7473 [00:16<00:10, 289.51it/s] 60%|██████████████████████████████▍                    | 4454/7473 [00:16<00:10, 289.28it/s] 60%|██████████████████████████████▌                    | 4484/7473 [00:16<00:10, 289.58it/s] 60%|██████████████████████████████▊                    | 4514/7473 [00:16<00:10, 289.77it/s] 61%|███████████████████████████████                    | 4544/7473 [00:16<00:10, 290.42it/s] 61%|███████████████████████████████▏                   | 4574/7473 [00:16<00:10, 287.93it/s] 62%|███████████████████████████████▍                   | 4604/7473 [00:16<00:09, 288.68it/s] 62%|███████████████████████████████▌                   | 4633/7473 [00:16<00:09, 289.01it/s] 62%|███████████████████████████████▊                   | 4663/7473 [00:17<00:09, 289.44it/s] 63%|████████████████████████████████                   | 4693/7473 [00:17<00:09, 289.70it/s] 63%|████████████████████████████████▏                  | 4723/7473 [00:17<00:09, 290.07it/s] 64%|████████████████████████████████▍                  | 4753/7473 [00:17<00:09, 290.33it/s] 64%|████████████████████████████████▋                  | 4783/7473 [00:17<00:09, 290.55it/s] 64%|████████████████████████████████▊                  | 4813/7473 [00:17<00:09, 288.31it/s] 65%|█████████████████████████████████                  | 4843/7473 [00:17<00:09, 289.16it/s] 65%|█████████████████████████████████▏                 | 4872/7473 [00:17<00:08, 289.02it/s] 66%|█████████████████████████████████▍                 | 4902/7473 [00:17<00:08, 289.99it/s] 66%|█████████████████████████████████▋                 | 4932/7473 [00:17<00:08, 290.09it/s] 66%|█████████████████████████████████▊                 | 4962/7473 [00:18<00:08, 290.09it/s] 67%|██████████████████████████████████                 | 4992/7473 [00:18<00:08, 289.85it/s] 67%|██████████████████████████████████▎                | 5021/7473 [00:18<00:08, 288.80it/s] 68%|██████████████████████████████████▍                | 5051/7473 [00:18<00:08, 289.29it/s] 68%|██████████████████████████████████▋                | 5080/7473 [00:18<00:08, 287.77it/s] 68%|██████████████████████████████████▊                | 5109/7473 [00:18<00:08, 288.38it/s] 69%|███████████████████████████████████                | 5139/7473 [00:18<00:08, 289.18it/s] 69%|███████████████████████████████████▎               | 5169/7473 [00:18<00:07, 289.77it/s] 70%|███████████████████████████████████▍               | 5199/7473 [00:18<00:07, 289.82it/s] 70%|███████████████████████████████████▋               | 5229/7473 [00:19<00:07, 290.27it/s] 70%|███████████████████████████████████▉               | 5259/7473 [00:19<00:08, 267.02it/s] 71%|████████████████████████████████████               | 5289/7473 [00:19<00:07, 273.86it/s] 71%|████████████████████████████████████▎              | 5318/7473 [00:19<00:07, 278.23it/s] 72%|████████████████████████████████████▍              | 5348/7473 [00:19<00:07, 281.72it/s] 72%|████████████████████████████████████▋              | 5378/7473 [00:19<00:07, 284.36it/s] 72%|████████████████████████████████████▉              | 5408/7473 [00:19<00:07, 286.09it/s] 73%|█████████████████████████████████████              | 5438/7473 [00:19<00:07, 287.50it/s] 73%|█████████████████████████████████████▎             | 5467/7473 [00:19<00:06, 287.21it/s] 74%|█████████████████████████████████████▌             | 5496/7473 [00:20<00:09, 216.10it/s] 74%|█████████████████████████████████████▋             | 5525/7473 [00:20<00:08, 232.31it/s] 74%|█████████████████████████████████████▉             | 5554/7473 [00:20<00:07, 246.82it/s] 75%|██████████████████████████████████████             | 5583/7473 [00:20<00:07, 258.15it/s] 75%|██████████████████████████████████████▎            | 5612/7473 [00:20<00:06, 266.49it/s] 75%|██████████████████████████████████████▍            | 5641/7473 [00:20<00:06, 272.91it/s] 76%|██████████████████████████████████████▋            | 5671/7473 [00:20<00:06, 277.96it/s] 76%|██████████████████████████████████████▉            | 5700/7473 [00:20<00:06, 279.53it/s] 77%|███████████████████████████████████████            | 5729/7473 [00:20<00:06, 281.62it/s] 77%|███████████████████████████████████████▎           | 5758/7473 [00:20<00:06, 283.89it/s] 77%|███████████████████████████████████████▍           | 5787/7473 [00:21<00:05, 285.37it/s] 78%|███████████████████████████████████████▋           | 5816/7473 [00:21<00:05, 286.25it/s] 78%|███████████████████████████████████████▉           | 5845/7473 [00:21<00:05, 287.06it/s] 79%|████████████████████████████████████████           | 5874/7473 [00:21<00:05, 287.52it/s] 79%|████████████████████████████████████████▎          | 5903/7473 [00:21<00:05, 285.78it/s] 79%|████████████████████████████████████████▍          | 5932/7473 [00:21<00:05, 286.50it/s] 80%|████████████████████████████████████████▋          | 5961/7473 [00:21<00:05, 286.79it/s] 80%|████████████████████████████████████████▉          | 5990/7473 [00:21<00:05, 287.24it/s] 81%|█████████████████████████████████████████          | 6019/7473 [00:21<00:05, 285.60it/s] 81%|█████████████████████████████████████████▎         | 6048/7473 [00:21<00:04, 286.55it/s] 81%|█████████████████████████████████████████▍         | 6078/7473 [00:22<00:04, 287.95it/s] 82%|█████████████████████████████████████████▋         | 6108/7473 [00:22<00:04, 288.75it/s] 82%|█████████████████████████████████████████▉         | 6137/7473 [00:22<00:04, 287.44it/s] 83%|██████████████████████████████████████████         | 6166/7473 [00:22<00:04, 288.05it/s] 83%|██████████████████████████████████████████▎        | 6196/7473 [00:22<00:04, 288.79it/s] 83%|██████████████████████████████████████████▍        | 6225/7473 [00:22<00:04, 288.91it/s] 84%|██████████████████████████████████████████▋        | 6255/7473 [00:22<00:04, 289.67it/s] 84%|██████████████████████████████████████████▉        | 6285/7473 [00:22<00:04, 289.83it/s] 85%|███████████████████████████████████████████        | 6315/7473 [00:22<00:03, 290.11it/s] 85%|███████████████████████████████████████████▎       | 6345/7473 [00:23<00:03, 290.19it/s] 85%|███████████████████████████████████████████▌       | 6375/7473 [00:23<00:03, 287.90it/s] 86%|███████████████████████████████████████████▋       | 6404/7473 [00:23<00:03, 288.20it/s] 86%|███████████████████████████████████████████▉       | 6433/7473 [00:23<00:03, 288.42it/s] 86%|████████████████████████████████████████████       | 6463/7473 [00:23<00:03, 289.00it/s] 87%|████████████████████████████████████████████▎      | 6492/7473 [00:23<00:03, 286.93it/s] 87%|████████████████████████████████████████████▌      | 6521/7473 [00:23<00:03, 287.70it/s] 88%|████████████████████████████████████████████▋      | 6551/7473 [00:23<00:03, 288.75it/s] 88%|████████████████████████████████████████████▉      | 6580/7473 [00:23<00:03, 287.31it/s] 88%|█████████████████████████████████████████████      | 6610/7473 [00:23<00:02, 288.42it/s] 89%|█████████████████████████████████████████████▎     | 6639/7473 [00:24<00:02, 288.12it/s] 89%|█████████████████████████████████████████████▌     | 6668/7473 [00:24<00:02, 288.16it/s] 90%|█████████████████████████████████████████████▋     | 6698/7473 [00:24<00:02, 289.05it/s] 90%|█████████████████████████████████████████████▉     | 6727/7473 [00:24<00:02, 289.21it/s] 90%|██████████████████████████████████████████████     | 6756/7473 [00:24<00:02, 289.37it/s] 91%|██████████████████████████████████████████████▎    | 6785/7473 [00:24<00:02, 289.29it/s] 91%|██████████████████████████████████████████████▌    | 6814/7473 [00:24<00:02, 287.56it/s] 92%|██████████████████████████████████████████████▋    | 6843/7473 [00:24<00:02, 288.17it/s] 92%|██████████████████████████████████████████████▉    | 6873/7473 [00:24<00:02, 289.01it/s] 92%|███████████████████████████████████████████████    | 6903/7473 [00:24<00:01, 289.59it/s] 93%|███████████████████████████████████████████████▎   | 6933/7473 [00:25<00:01, 289.94it/s] 93%|███████████████████████████████████████████████▌   | 6962/7473 [00:25<00:01, 289.53it/s] 94%|███████████████████████████████████████████████▋   | 6991/7473 [00:25<00:01, 287.22it/s] 94%|███████████████████████████████████████████████▉   | 7020/7473 [00:25<00:01, 287.84it/s] 94%|████████████████████████████████████████████████   | 7049/7473 [00:25<00:01, 285.94it/s] 95%|████████████████████████████████████████████████▎  | 7079/7473 [00:25<00:01, 287.29it/s] 95%|████████████████████████████████████████████████▌  | 7108/7473 [00:25<00:01, 287.89it/s] 96%|████████████████████████████████████████████████▋  | 7137/7473 [00:25<00:01, 287.99it/s] 96%|████████████████████████████████████████████████▉  | 7166/7473 [00:25<00:01, 288.35it/s] 96%|█████████████████████████████████████████████████  | 7195/7473 [00:25<00:00, 288.75it/s] 97%|█████████████████████████████████████████████████▎ | 7224/7473 [00:26<00:00, 288.84it/s] 97%|█████████████████████████████████████████████████▌ | 7254/7473 [00:26<00:00, 289.31it/s] 97%|█████████████████████████████████████████████████▋ | 7283/7473 [00:26<00:00, 288.11it/s] 98%|█████████████████████████████████████████████████▉ | 7313/7473 [00:26<00:00, 288.74it/s] 98%|██████████████████████████████████████████████████ | 7342/7473 [00:26<00:00, 288.91it/s] 99%|██████████████████████████████████████████████████▎| 7371/7473 [00:26<00:00, 289.12it/s] 99%|██████████████████████████████████████████████████▌| 7400/7473 [00:26<00:00, 289.32it/s] 99%|██████████████████████████████████████████████████▋| 7429/7473 [00:26<00:00, 289.26it/s]100%|██████████████████████████████████████████████████▉| 7458/7473 [00:26<00:00, 289.04it/s]100%|███████████████████████████████████████████████████| 7473/7473 [00:26<00:00, 277.47it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:04<00:09,  4.84s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:04<00:09,  4.85s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:04<00:09,  4.95s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.40s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:09<00:04,  4.90s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:09<00:04,  4.91s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.56s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.46s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.30s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.46s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.31s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.47s/it]
[2023-08-13 03:58:25,327] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.78s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.96s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.18s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.22s/it]
[2023-08-13 03:58:39,954] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-13 03:58:39,955] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f0551e3efa0>
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-13 03:58:39,956] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f0551e36700>
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-13 03:58:39,957] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-13 03:58:39,957] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.5986342430114746 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Loading extension module utils...
Time to load utils op: 0.5046000480651855 seconds
Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Fabric is cut to order at what type of seller? Choices:  A: curtains B: tailor shop C: clothing store D: sewing room E: hardware store
Rationales: 1. First, evaluate each choice based on the context of the question. 
2. The question refers to a place where fabric is cut to order, implying a service that makes custom items from fabric.
3. The first choice (A) is curtains. Although curtains are made of fabric, they are usually pre-made and sold in specific sizes, not usually cut to order. So, this is not the correct answer.
4. Choice C is a clothing store. While a clothing store does sell items made from fabric, they usually sell pre-made clothes, again, not cut to order.
5. Choice D is a sewing room. This is a place that might see fabric being cut, but it's more of a location in which the act occurs, not a seller of services or goods. 
6. Choice E is a hardware store. This type of store usually deals with building materials, not fabric, so this is not the correct answer.
7. Therefore, the correct answer would be B, a tailor shop. Tailor shops specifically offer services where they cut and shape fabric to fit custom orders, such as suits, dresses, or other clothes.
Answer: B: tailor shop

Input: Where are you if your reading magazines while waiting for a vehicle on rails? Choices:  A: vegetables B: market C: doctor D: train station E: bookstore
Rationales: 1. The question asks about a location where you are waiting for a vehicle on rails. 
2. This implies you are waiting for a kind of transport that moves on rails, such as a train or a tram.
3. Thus, we can eliminate choices A, B, C, and E as they are not typical places where one waits for a vehicle on rails. Vegetables is not a location, the market is usually for shopping, the doctor is for health consultations, and a bookstore is for buying books.
4. Tallied against all these options, choice D: train station is the only appropriate choice where one waits for a vehicle on rails.
5. So, the answer is D: train station.
Answer: D: train station

Input: What would need oil to be used? Choices:  A: ground B: human  body C: repair shop D: combustion engines E: service station
Rationales: 1. A ground won't need oil, as oil doesn't help in any ground-related processes or functionality. It is usually organic matter or water that is required for the soil enrichment or growth of plants.
2. A human body doesn't require oil for operating. Instead, it requires food, water, and oxygen for its normal functionalities.
3. A repair shop may use oils for some of the machinery or equipment repairs, but oil is not necessarily required to run a repair shop, as it also depends on what type of repair shop it is.
4. Combustion engines require oil for its operation. Oil is used for lubrication, cooling, and cleaning of internal combustion engines. Without oil, a combustion engine would overheat or malfunction, leading to a breakdown.
5. Similar to a repair shop, a service station might use oil for various purposes but not necessarily requires oil to function. It highly depends on the type of service station.
6. Therefore, out of all the options, only combustion engines "need" oil to work. Hence, the answer is D: combustion engines.
Answer: D: combustion engines

Input: What is person probably feeling that plans on stopping being married to their spouse? Choices:  A: detachment B: bankruptcy C: sad D: fights E: wrong
Rationales: 1. The question is asking about emotional conditions that could be associated with someone who plans on not being married anymore or considering divorce.
2. Option B, bankruptcy, is a financial situation rather than an emotional state, making it a non-suitable answer.
3. Option D, fights, suggest conflicts, but this alone cannot describe the probable feeling of a person intending to end their marriage.
4. Option E, wrong, can be an emotional state, but it doesn't directly imply the feelings associated with someone intending to stop being married.
5. Option C, sad, could be a possible feeling as well. However it's specific and, at this point, doesn't cover the whole range of emotions the person might feel.
6. Hence, we left with option A, detachment, which accurately depicts the general emotional state of withdrawing or distancing one's self from their spouse.
7. Thus, the answer is A: detachment.
Answer: A: detachment

Input: What could you use to store a clock? Choices:  A: shelf B: own bedroom C: desk D: wall E: car
Rationales: 1. To identify which option could serve as a store for a clock, we should analyze each option and its functionality. 
2. The first choices A. Shelf: A shelf is designed to hold objects and provide display space for items. It is feasible to place a clock on a shelf.
3. The second choice B: Own Bedroom: A bedroom remains a larger area. While a clock could be placed somewhere in a bedroom, the bedroom in itself does not provide a specific placement or storage for the clock.
4. The third options C: Desk: A desk could potentially hold a clock, but it's primarily used to do work on, so the placement of a clock on it may not be ideal for everyone.
5. Fourth option D: Wall: A wall can hold a wall clock but not the typical table clock. A wall clock requires being fastened to the wall which means not all clocks can be placed on a wall.
6. Lastly, E: Car: Cars are primarily used for transportation and while some cars have built-in clocks, they aren't typically used to store clocks in the general sense.
7. From all the above reasoning the most suitable answer for storing a clock is A: shelf since it can accommodate all types of clocks.
Answer: A: shelf

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o5-tcommonsenseqa-s10-rTrue
Loading extension module utils...
Time to load utils op: 0.5041749477386475 seconds
Loading extension module utils...
Time to load utils op: 0.40439319610595703 seconds
Evaluating gsm8k :   0%|                                              | 0/50 [00:05<?, ?it/s]
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 139, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 116, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 139, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 116, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 139, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 116, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 139, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 116, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 3614471) of binary: /home/ylu130/.conda/envs/distllm/bin/python
Traceback (most recent call last):
  File "/home/ylu130/.conda/envs/distllm/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/run.py", line 761, in main
    run(args)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/ylu130/workspace/in-context-generalization/inference.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-08-13_03:58:50
  host      : ia1.wse.jhu.edu
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 3614472)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-08-13_03:58:50
  host      : ia1.wse.jhu.edu
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 3614473)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-08-13_03:58:50
  host      : ia1.wse.jhu.edu
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 3614474)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-08-13_03:58:50
  host      : ia1.wse.jhu.edu
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3614471)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o6-tcommonsenseqa-s10-rTrue --seed 10 --rationales --num-out-domain 6
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-13 03:58:53,851] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o6-tcommonsenseqa-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 6
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o6-tcommonsenseqa-s10-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  0%|                                                     | 14/7473 [00:00<00:57, 130.85it/s]  0%|▏                                                    | 28/7473 [00:00<00:56, 131.37it/s]  1%|▎                                                    | 42/7473 [00:00<00:56, 131.66it/s]  1%|▍                                                    | 56/7473 [00:00<00:56, 131.38it/s]  1%|▍                                                    | 70/7473 [00:00<00:56, 130.83it/s]  1%|▌                                                    | 84/7473 [00:00<00:56, 130.62it/s]  1%|▋                                                    | 98/7473 [00:00<00:57, 128.92it/s]  1%|▊                                                   | 112/7473 [00:00<00:56, 129.76it/s]  2%|▉                                                   | 126/7473 [00:00<00:56, 130.46it/s]  2%|▉                                                   | 140/7473 [00:01<00:55, 131.02it/s]  2%|█                                                   | 154/7473 [00:01<00:55, 131.83it/s]  2%|█▏                                                  | 168/7473 [00:01<00:55, 132.07it/s]  2%|█▎                                                  | 182/7473 [00:01<00:55, 132.25it/s]  3%|█▎                                                  | 196/7473 [00:01<00:54, 132.43it/s]  3%|█▍                                                  | 210/7473 [00:01<00:54, 132.79it/s]  3%|█▌                                                  | 224/7473 [00:01<00:55, 131.24it/s]  3%|█▋                                                  | 238/7473 [00:01<00:55, 131.16it/s]  3%|█▊                                                  | 252/7473 [00:01<00:55, 128.98it/s]  4%|█▊                                                  | 266/7473 [00:02<00:55, 130.18it/s]  4%|█▉                                                  | 280/7473 [00:02<00:54, 131.00it/s]  4%|██                                                  | 294/7473 [00:02<00:54, 131.54it/s]  4%|██▏                                                 | 308/7473 [00:02<00:54, 131.96it/s]  4%|██▏                                                 | 322/7473 [00:02<00:53, 133.55it/s]  5%|██▍                                                 | 343/7473 [00:02<00:46, 153.98it/s]  5%|██▌                                                 | 364/7473 [00:02<00:42, 168.28it/s]  5%|██▋                                                 | 385/7473 [00:02<00:39, 178.50it/s]  5%|██▊                                                 | 405/7473 [00:02<00:38, 184.63it/s]  6%|██▉                                                 | 426/7473 [00:02<00:37, 190.15it/s]  6%|███                                                 | 447/7473 [00:03<00:36, 193.60it/s]  6%|███▎                                                | 468/7473 [00:03<00:35, 196.29it/s]  7%|███▍                                                | 488/7473 [00:03<00:37, 188.53it/s]  7%|███▌                                                | 509/7473 [00:03<00:36, 192.35it/s]  7%|███▋                                                | 530/7473 [00:03<00:35, 195.62it/s]  7%|███▊                                                | 551/7473 [00:03<00:34, 197.79it/s]  8%|███▉                                                | 572/7473 [00:03<00:34, 199.12it/s]  8%|████▏                                               | 593/7473 [00:03<00:34, 200.11it/s]  8%|████▎                                               | 614/7473 [00:03<00:34, 200.60it/s]  8%|████▍                                               | 635/7473 [00:04<00:34, 200.35it/s]  9%|████▌                                               | 656/7473 [00:04<00:33, 200.86it/s]  9%|████▋                                               | 677/7473 [00:04<00:33, 201.69it/s]  9%|████▊                                               | 698/7473 [00:04<00:33, 202.30it/s] 10%|█████                                               | 719/7473 [00:04<00:33, 201.07it/s] 10%|█████▏                                              | 740/7473 [00:04<00:33, 201.72it/s] 10%|█████▎                                              | 761/7473 [00:04<00:33, 201.11it/s] 10%|█████▍                                              | 782/7473 [00:04<00:33, 200.95it/s] 11%|█████▌                                              | 803/7473 [00:04<00:33, 201.14it/s] 11%|█████▋                                              | 824/7473 [00:04<00:33, 200.97it/s] 11%|█████▉                                              | 845/7473 [00:05<00:33, 200.83it/s] 12%|██████                                              | 866/7473 [00:05<00:32, 200.87it/s] 12%|██████▏                                             | 887/7473 [00:05<00:32, 200.59it/s] 12%|██████▎                                             | 908/7473 [00:05<00:32, 199.28it/s] 12%|██████▍                                             | 929/7473 [00:05<00:32, 200.00it/s] 13%|██████▌                                             | 950/7473 [00:05<00:32, 198.86it/s] 13%|██████▊                                             | 971/7473 [00:05<00:32, 199.40it/s] 13%|██████▉                                             | 991/7473 [00:05<00:32, 199.25it/s] 14%|██████▉                                            | 1012/7473 [00:05<00:32, 199.97it/s] 14%|███████                                            | 1033/7473 [00:05<00:32, 200.86it/s] 14%|███████▏                                           | 1054/7473 [00:06<00:31, 201.41it/s] 14%|███████▎                                           | 1075/7473 [00:06<00:31, 201.87it/s] 15%|███████▍                                           | 1096/7473 [00:06<00:31, 202.05it/s] 15%|███████▌                                           | 1117/7473 [00:06<00:31, 202.26it/s] 15%|███████▊                                           | 1138/7473 [00:06<00:31, 202.18it/s] 16%|███████▉                                           | 1159/7473 [00:06<00:32, 196.89it/s] 16%|████████                                           | 1180/7473 [00:06<00:31, 198.41it/s] 16%|████████▏                                          | 1200/7473 [00:06<00:31, 198.53it/s] 16%|████████▎                                          | 1220/7473 [00:06<00:31, 197.64it/s] 17%|████████▍                                          | 1240/7473 [00:07<00:31, 198.21it/s] 17%|████████▌                                          | 1261/7473 [00:07<00:31, 199.58it/s] 17%|████████▋                                          | 1282/7473 [00:07<00:30, 200.07it/s] 17%|████████▉                                          | 1303/7473 [00:07<00:30, 200.40it/s] 18%|█████████                                          | 1324/7473 [00:07<00:30, 201.25it/s] 18%|█████████▏                                         | 1345/7473 [00:07<00:30, 201.48it/s] 18%|█████████▎                                         | 1366/7473 [00:07<00:30, 201.76it/s] 19%|█████████▍                                         | 1387/7473 [00:07<00:30, 199.65it/s] 19%|█████████▌                                         | 1408/7473 [00:07<00:30, 200.40it/s] 19%|█████████▊                                         | 1429/7473 [00:07<00:30, 200.56it/s] 19%|█████████▉                                         | 1450/7473 [00:08<00:29, 200.94it/s] 20%|██████████                                         | 1471/7473 [00:08<00:29, 201.19it/s] 20%|██████████▏                                        | 1492/7473 [00:08<00:29, 201.52it/s] 20%|██████████▎                                        | 1513/7473 [00:08<00:29, 201.85it/s] 21%|██████████▍                                        | 1534/7473 [00:08<00:29, 201.94it/s] 21%|██████████▌                                        | 1555/7473 [00:08<00:29, 201.51it/s] 21%|██████████▊                                        | 1576/7473 [00:08<00:29, 201.21it/s] 21%|██████████▉                                        | 1597/7473 [00:08<00:29, 201.43it/s] 22%|███████████                                        | 1618/7473 [00:08<00:29, 199.94it/s] 22%|███████████▏                                       | 1639/7473 [00:09<00:29, 200.75it/s] 22%|███████████▎                                       | 1660/7473 [00:09<00:28, 200.50it/s] 22%|███████████▍                                       | 1681/7473 [00:09<00:28, 201.27it/s] 23%|███████████▌                                       | 1702/7473 [00:09<00:28, 200.81it/s] 23%|███████████▊                                       | 1723/7473 [00:09<00:28, 200.67it/s] 23%|███████████▉                                       | 1744/7473 [00:09<00:28, 200.55it/s] 24%|████████████                                       | 1765/7473 [00:09<00:28, 199.79it/s] 24%|████████████▏                                      | 1786/7473 [00:09<00:28, 200.29it/s] 24%|████████████▎                                      | 1807/7473 [00:09<00:28, 200.77it/s] 24%|████████████▍                                      | 1828/7473 [00:09<00:28, 200.58it/s] 25%|████████████▌                                      | 1849/7473 [00:10<00:28, 199.08it/s] 25%|████████████▊                                      | 1870/7473 [00:10<00:28, 199.80it/s] 25%|████████████▉                                      | 1891/7473 [00:10<00:27, 200.45it/s] 26%|█████████████                                      | 1912/7473 [00:10<00:27, 200.50it/s] 26%|█████████████▏                                     | 1933/7473 [00:10<00:27, 200.71it/s] 26%|█████████████▎                                     | 1954/7473 [00:10<00:27, 200.87it/s] 26%|█████████████▍                                     | 1975/7473 [00:10<00:27, 201.24it/s] 27%|█████████████▌                                     | 1996/7473 [00:10<00:27, 201.29it/s] 27%|█████████████▊                                     | 2017/7473 [00:10<00:27, 201.38it/s] 27%|█████████████▉                                     | 2038/7473 [00:11<00:26, 201.59it/s] 28%|██████████████                                     | 2059/7473 [00:11<00:26, 201.87it/s] 28%|██████████████▏                                    | 2080/7473 [00:11<00:26, 199.90it/s] 28%|██████████████▎                                    | 2101/7473 [00:11<00:26, 200.63it/s] 28%|██████████████▍                                    | 2122/7473 [00:11<00:26, 199.75it/s] 29%|██████████████▋                                    | 2143/7473 [00:11<00:26, 200.52it/s] 29%|██████████████▊                                    | 2164/7473 [00:11<00:26, 200.72it/s] 29%|██████████████▉                                    | 2185/7473 [00:11<00:26, 200.33it/s] 30%|███████████████                                    | 2206/7473 [00:11<00:26, 199.73it/s] 30%|███████████████▏                                   | 2227/7473 [00:11<00:26, 200.26it/s] 30%|███████████████▎                                   | 2248/7473 [00:12<00:26, 200.61it/s] 30%|███████████████▍                                   | 2269/7473 [00:12<00:25, 200.88it/s] 31%|███████████████▋                                   | 2290/7473 [00:12<00:26, 199.31it/s] 31%|███████████████▊                                   | 2311/7473 [00:12<00:25, 200.33it/s] 31%|███████████████▉                                   | 2332/7473 [00:12<00:25, 200.96it/s] 31%|████████████████                                   | 2353/7473 [00:12<00:25, 201.03it/s] 32%|████████████████▏                                  | 2374/7473 [00:12<00:25, 201.15it/s] 32%|████████████████▎                                  | 2395/7473 [00:12<00:25, 200.92it/s] 32%|████████████████▍                                  | 2416/7473 [00:12<00:25, 200.11it/s] 33%|████████████████▋                                  | 2437/7473 [00:13<00:25, 199.29it/s] 33%|████████████████▊                                  | 2458/7473 [00:13<00:25, 200.01it/s] 33%|████████████████▉                                  | 2479/7473 [00:13<00:24, 200.15it/s] 33%|█████████████████                                  | 2500/7473 [00:13<00:24, 199.93it/s] 34%|█████████████████▏                                 | 2520/7473 [00:13<00:28, 175.83it/s] 34%|█████████████████▎                                 | 2540/7473 [00:13<00:27, 181.51it/s] 34%|█████████████████▍                                 | 2560/7473 [00:13<00:26, 186.45it/s] 35%|█████████████████▌                                 | 2581/7473 [00:13<00:25, 190.55it/s] 35%|█████████████████▊                                 | 2601/7473 [00:13<00:25, 192.95it/s] 35%|█████████████████▉                                 | 2622/7473 [00:13<00:24, 195.04it/s] 35%|██████████████████                                 | 2642/7473 [00:14<00:24, 196.29it/s] 36%|██████████████████▏                                | 2662/7473 [00:14<00:24, 197.04it/s] 36%|██████████████████▎                                | 2682/7473 [00:14<00:24, 197.80it/s] 36%|██████████████████▍                                | 2702/7473 [00:14<00:24, 197.96it/s] 36%|██████████████████▌                                | 2723/7473 [00:14<00:23, 198.66it/s] 37%|██████████████████▋                                | 2743/7473 [00:14<00:23, 198.63it/s] 37%|██████████████████▊                                | 2763/7473 [00:14<00:24, 196.12it/s] 37%|██████████████████▉                                | 2783/7473 [00:14<00:23, 197.20it/s] 38%|███████████████████▏                               | 2803/7473 [00:14<00:23, 198.01it/s] 38%|███████████████████▎                               | 2823/7473 [00:14<00:23, 198.39it/s] 38%|███████████████████▍                               | 2843/7473 [00:15<00:23, 198.74it/s] 38%|███████████████████▌                               | 2863/7473 [00:15<00:23, 196.26it/s] 39%|███████████████████▋                               | 2883/7473 [00:15<00:23, 196.72it/s] 39%|███████████████████▊                               | 2903/7473 [00:15<00:23, 197.22it/s] 39%|███████████████████▉                               | 2924/7473 [00:15<00:22, 198.40it/s] 39%|████████████████████                               | 2945/7473 [00:15<00:22, 199.41it/s] 40%|████████████████████▏                              | 2966/7473 [00:15<00:22, 200.09it/s] 40%|████████████████████▍                              | 2987/7473 [00:15<00:22, 198.79it/s] 40%|████████████████████▌                              | 3008/7473 [00:15<00:22, 199.45it/s] 41%|████████████████████▋                              | 3029/7473 [00:16<00:22, 200.01it/s] 41%|████████████████████▊                              | 3050/7473 [00:16<00:22, 200.22it/s] 41%|████████████████████▉                              | 3071/7473 [00:16<00:21, 200.69it/s] 41%|█████████████████████                              | 3092/7473 [00:16<00:21, 200.77it/s] 42%|█████████████████████▏                             | 3113/7473 [00:16<00:21, 198.65it/s] 42%|█████████████████████▍                             | 3134/7473 [00:16<00:21, 199.26it/s] 42%|█████████████████████▌                             | 3155/7473 [00:16<00:21, 199.60it/s] 42%|█████████████████████▋                             | 3176/7473 [00:16<00:21, 200.11it/s] 43%|█████████████████████▊                             | 3197/7473 [00:16<00:21, 200.41it/s] 43%|█████████████████████▉                             | 3218/7473 [00:16<00:21, 199.04it/s] 43%|██████████████████████                             | 3239/7473 [00:17<00:21, 199.36it/s] 44%|██████████████████████▏                            | 3260/7473 [00:17<00:21, 199.94it/s] 44%|██████████████████████▍                            | 3281/7473 [00:17<00:20, 200.41it/s] 44%|██████████████████████▌                            | 3302/7473 [00:17<00:20, 200.29it/s] 44%|██████████████████████▋                            | 3323/7473 [00:17<00:20, 200.46it/s] 45%|██████████████████████▊                            | 3344/7473 [00:17<00:20, 200.02it/s] 45%|██████████████████████▉                            | 3365/7473 [00:17<00:20, 200.18it/s] 45%|███████████████████████                            | 3386/7473 [00:17<00:20, 200.24it/s] 46%|███████████████████████▎                           | 3407/7473 [00:17<00:20, 200.35it/s] 46%|███████████████████████▍                           | 3428/7473 [00:18<00:20, 198.82it/s] 46%|███████████████████████▌                           | 3448/7473 [00:18<00:20, 197.15it/s] 46%|███████████████████████▋                           | 3468/7473 [00:18<00:20, 197.74it/s] 47%|███████████████████████▊                           | 3489/7473 [00:18<00:20, 199.03it/s] 47%|███████████████████████▉                           | 3509/7473 [00:18<00:19, 199.23it/s] 47%|████████████████████████                           | 3530/7473 [00:18<00:19, 199.58it/s] 48%|████████████████████████▏                          | 3551/7473 [00:18<00:19, 199.99it/s] 48%|████████████████████████▍                          | 3572/7473 [00:18<00:19, 200.28it/s] 48%|████████████████████████▌                          | 3593/7473 [00:18<00:19, 200.44it/s] 48%|████████████████████████▋                          | 3614/7473 [00:18<00:19, 200.43it/s] 49%|████████████████████████▊                          | 3635/7473 [00:19<00:19, 200.36it/s] 49%|████████████████████████▉                          | 3656/7473 [00:19<00:19, 198.37it/s] 49%|█████████████████████████                          | 3676/7473 [00:19<00:19, 198.78it/s] 49%|█████████████████████████▏                         | 3696/7473 [00:19<00:18, 198.93it/s] 50%|█████████████████████████▎                         | 3716/7473 [00:19<00:18, 198.72it/s] 50%|█████████████████████████▌                         | 3737/7473 [00:19<00:18, 199.19it/s] 50%|█████████████████████████▋                         | 3757/7473 [00:19<00:18, 199.36it/s] 51%|█████████████████████████▊                         | 3778/7473 [00:19<00:18, 199.95it/s] 51%|█████████████████████████▉                         | 3798/7473 [00:19<00:18, 198.58it/s] 51%|██████████████████████████                         | 3819/7473 [00:19<00:18, 199.54it/s] 51%|██████████████████████████▏                        | 3839/7473 [00:20<00:18, 199.64it/s] 52%|██████████████████████████▎                        | 3860/7473 [00:20<00:18, 199.99it/s] 52%|██████████████████████████▍                        | 3880/7473 [00:20<00:18, 198.51it/s] 52%|██████████████████████████▌                        | 3901/7473 [00:20<00:17, 199.39it/s] 52%|██████████████████████████▊                        | 3922/7473 [00:20<00:17, 199.74it/s] 53%|██████████████████████████▉                        | 3943/7473 [00:20<00:17, 200.17it/s] 53%|███████████████████████████                        | 3964/7473 [00:20<00:17, 200.51it/s] 53%|███████████████████████████▏                       | 3985/7473 [00:20<00:17, 200.53it/s] 54%|███████████████████████████▎                       | 4006/7473 [00:20<00:17, 201.06it/s] 54%|███████████████████████████▍                       | 4027/7473 [00:21<00:17, 201.24it/s] 54%|███████████████████████████▋                       | 4048/7473 [00:21<00:17, 201.23it/s] 54%|███████████████████████████▊                       | 4069/7473 [00:21<00:16, 201.20it/s] 55%|███████████████████████████▉                       | 4090/7473 [00:21<00:16, 201.25it/s] 55%|████████████████████████████                       | 4111/7473 [00:21<00:16, 198.73it/s] 55%|████████████████████████████▏                      | 4131/7473 [00:21<00:16, 197.13it/s] 56%|████████████████████████████▎                      | 4151/7473 [00:21<00:16, 197.81it/s] 56%|████████████████████████████▍                      | 4172/7473 [00:21<00:16, 198.76it/s] 56%|████████████████████████████▌                      | 4192/7473 [00:21<00:16, 199.07it/s] 56%|████████████████████████████▋                      | 4212/7473 [00:21<00:16, 198.91it/s] 57%|████████████████████████████▉                      | 4232/7473 [00:22<00:16, 198.90it/s] 57%|█████████████████████████████                      | 4252/7473 [00:22<00:16, 198.66it/s] 57%|█████████████████████████████▏                     | 4272/7473 [00:22<00:16, 198.36it/s] 57%|█████████████████████████████▎                     | 4292/7473 [00:22<00:16, 198.13it/s] 58%|█████████████████████████████▍                     | 4312/7473 [00:22<00:15, 198.21it/s] 58%|█████████████████████████████▌                     | 4332/7473 [00:22<00:15, 198.60it/s] 58%|█████████████████████████████▋                     | 4352/7473 [00:22<00:15, 196.95it/s] 59%|█████████████████████████████▊                     | 4372/7473 [00:22<00:15, 197.12it/s] 59%|█████████████████████████████▉                     | 4392/7473 [00:22<00:15, 197.22it/s] 59%|██████████████████████████████                     | 4412/7473 [00:22<00:15, 197.57it/s] 59%|██████████████████████████████▏                    | 4432/7473 [00:23<00:15, 197.52it/s] 60%|██████████████████████████████▍                    | 4452/7473 [00:23<00:15, 197.44it/s] 60%|██████████████████████████████▌                    | 4472/7473 [00:23<00:15, 195.51it/s] 60%|██████████████████████████████▋                    | 4492/7473 [00:23<00:15, 196.16it/s] 60%|██████████████████████████████▊                    | 4512/7473 [00:23<00:15, 196.34it/s] 61%|██████████████████████████████▉                    | 4533/7473 [00:23<00:14, 197.60it/s] 61%|███████████████████████████████                    | 4554/7473 [00:23<00:14, 198.85it/s] 61%|███████████████████████████████▏                   | 4574/7473 [00:23<00:14, 197.45it/s] 61%|███████████████████████████████▎                   | 4594/7473 [00:23<00:14, 198.16it/s] 62%|███████████████████████████████▍                   | 4615/7473 [00:23<00:14, 198.86it/s] 62%|███████████████████████████████▋                   | 4635/7473 [00:24<00:14, 199.15it/s] 62%|███████████████████████████████▊                   | 4656/7473 [00:24<00:14, 199.56it/s] 63%|███████████████████████████████▉                   | 4676/7473 [00:24<00:14, 199.59it/s] 63%|████████████████████████████████                   | 4696/7473 [00:24<00:13, 199.41it/s] 63%|████████████████████████████████▏                  | 4716/7473 [00:24<00:13, 199.32it/s] 63%|████████████████████████████████▎                  | 4736/7473 [00:24<00:13, 199.46it/s] 64%|████████████████████████████████▍                  | 4757/7473 [00:24<00:13, 199.71it/s] 64%|████████████████████████████████▌                  | 4777/7473 [00:24<00:13, 199.61it/s] 64%|████████████████████████████████▋                  | 4797/7473 [00:24<00:13, 197.52it/s] 64%|████████████████████████████████▊                  | 4817/7473 [00:25<00:13, 197.60it/s] 65%|█████████████████████████████████                  | 4837/7473 [00:25<00:13, 196.86it/s] 65%|█████████████████████████████████▏                 | 4857/7473 [00:25<00:13, 197.36it/s] 65%|█████████████████████████████████▎                 | 4877/7473 [00:25<00:13, 197.57it/s] 66%|█████████████████████████████████▍                 | 4897/7473 [00:25<00:12, 198.20it/s] 66%|█████████████████████████████████▌                 | 4917/7473 [00:25<00:12, 198.15it/s] 66%|█████████████████████████████████▋                 | 4937/7473 [00:25<00:12, 198.29it/s] 66%|█████████████████████████████████▊                 | 4958/7473 [00:25<00:12, 199.02it/s] 67%|█████████████████████████████████▉                 | 4978/7473 [00:25<00:12, 198.83it/s] 67%|██████████████████████████████████                 | 4998/7473 [00:25<00:12, 198.71it/s] 67%|██████████████████████████████████▏                | 5018/7473 [00:26<00:12, 197.52it/s] 67%|██████████████████████████████████▍                | 5038/7473 [00:26<00:12, 197.72it/s] 68%|██████████████████████████████████▌                | 5058/7473 [00:26<00:12, 198.27it/s] 68%|██████████████████████████████████▋                | 5078/7473 [00:26<00:12, 198.51it/s] 68%|██████████████████████████████████▊                | 5098/7473 [00:26<00:11, 198.55it/s] 68%|██████████████████████████████████▉                | 5118/7473 [00:26<00:11, 198.75it/s] 69%|███████████████████████████████████                | 5138/7473 [00:26<00:11, 199.02it/s] 69%|███████████████████████████████████▏               | 5158/7473 [00:26<00:11, 199.25it/s] 69%|███████████████████████████████████▎               | 5178/7473 [00:26<00:11, 199.26it/s] 70%|███████████████████████████████████▍               | 5198/7473 [00:26<00:11, 199.03it/s] 70%|███████████████████████████████████▌               | 5218/7473 [00:27<00:11, 199.26it/s] 70%|███████████████████████████████████▋               | 5238/7473 [00:27<00:11, 198.24it/s] 70%|███████████████████████████████████▉               | 5258/7473 [00:27<00:13, 169.21it/s] 71%|████████████████████████████████████               | 5278/7473 [00:27<00:12, 177.12it/s] 71%|████████████████████████████████████▏              | 5298/7473 [00:27<00:11, 182.85it/s] 71%|████████████████████████████████████▎              | 5318/7473 [00:27<00:11, 186.93it/s] 71%|████████████████████████████████████▍              | 5338/7473 [00:27<00:11, 190.44it/s] 72%|████████████████████████████████████▌              | 5358/7473 [00:27<00:10, 192.90it/s] 72%|████████████████████████████████████▋              | 5378/7473 [00:27<00:10, 194.75it/s] 72%|████████████████████████████████████▊              | 5398/7473 [00:27<00:10, 196.10it/s] 73%|████████████████████████████████████▉              | 5418/7473 [00:28<00:10, 197.01it/s] 73%|█████████████████████████████████████              | 5439/7473 [00:28<00:10, 198.27it/s] 73%|█████████████████████████████████████▎             | 5459/7473 [00:28<00:10, 198.75it/s] 73%|█████████████████████████████████████▍             | 5479/7473 [00:28<00:16, 123.95it/s] 74%|█████████████████████████████████████▌             | 5500/7473 [00:28<00:14, 140.54it/s] 74%|█████████████████████████████████████▋             | 5521/7473 [00:28<00:12, 154.76it/s] 74%|█████████████████████████████████████▊             | 5541/7473 [00:28<00:11, 165.66it/s] 74%|█████████████████████████████████████▉             | 5562/7473 [00:29<00:10, 175.37it/s] 75%|██████████████████████████████████████             | 5582/7473 [00:29<00:10, 181.88it/s] 75%|██████████████████████████████████████▏            | 5602/7473 [00:29<00:10, 186.87it/s] 75%|██████████████████████████████████████▎            | 5622/7473 [00:29<00:09, 190.17it/s] 76%|██████████████████████████████████████▌            | 5643/7473 [00:29<00:09, 193.21it/s] 76%|██████████████████████████████████████▋            | 5663/7473 [00:29<00:09, 195.15it/s] 76%|██████████████████████████████████████▊            | 5683/7473 [00:29<00:09, 194.80it/s] 76%|██████████████████████████████████████▉            | 5704/7473 [00:29<00:09, 196.47it/s] 77%|███████████████████████████████████████            | 5724/7473 [00:29<00:08, 197.24it/s] 77%|███████████████████████████████████████▏           | 5744/7473 [00:29<00:08, 197.98it/s] 77%|███████████████████████████████████████▎           | 5764/7473 [00:30<00:08, 198.45it/s] 77%|███████████████████████████████████████▍           | 5784/7473 [00:30<00:08, 198.70it/s] 78%|███████████████████████████████████████▌           | 5805/7473 [00:30<00:08, 199.19it/s] 78%|███████████████████████████████████████▊           | 5825/7473 [00:30<00:08, 199.13it/s] 78%|███████████████████████████████████████▉           | 5846/7473 [00:30<00:08, 199.44it/s] 79%|████████████████████████████████████████           | 5867/7473 [00:30<00:08, 199.74it/s] 79%|████████████████████████████████████████▏          | 5888/7473 [00:30<00:07, 199.88it/s] 79%|████████████████████████████████████████▎          | 5908/7473 [00:30<00:07, 197.88it/s] 79%|████████████████████████████████████████▍          | 5928/7473 [00:30<00:07, 198.27it/s] 80%|████████████████████████████████████████▌          | 5948/7473 [00:30<00:07, 198.59it/s] 80%|████████████████████████████████████████▋          | 5968/7473 [00:31<00:07, 198.46it/s] 80%|████████████████████████████████████████▊          | 5989/7473 [00:31<00:07, 199.02it/s] 80%|█████████████████████████████████████████          | 6009/7473 [00:31<00:07, 199.19it/s] 81%|█████████████████████████████████████████▏         | 6030/7473 [00:31<00:07, 199.31it/s] 81%|█████████████████████████████████████████▎         | 6051/7473 [00:31<00:07, 199.93it/s] 81%|█████████████████████████████████████████▍         | 6071/7473 [00:31<00:07, 199.36it/s] 82%|█████████████████████████████████████████▌         | 6092/7473 [00:31<00:06, 199.61it/s] 82%|█████████████████████████████████████████▋         | 6112/7473 [00:31<00:06, 199.48it/s] 82%|█████████████████████████████████████████▊         | 6132/7473 [00:31<00:06, 197.94it/s] 82%|█████████████████████████████████████████▉         | 6153/7473 [00:31<00:06, 198.76it/s] 83%|██████████████████████████████████████████▏        | 6173/7473 [00:32<00:06, 198.99it/s] 83%|██████████████████████████████████████████▎        | 6194/7473 [00:32<00:06, 199.48it/s] 83%|██████████████████████████████████████████▍        | 6214/7473 [00:32<00:06, 199.53it/s] 83%|██████████████████████████████████████████▌        | 6234/7473 [00:32<00:06, 199.03it/s] 84%|██████████████████████████████████████████▋        | 6255/7473 [00:32<00:06, 199.56it/s] 84%|██████████████████████████████████████████▊        | 6276/7473 [00:32<00:05, 199.79it/s] 84%|██████████████████████████████████████████▉        | 6296/7473 [00:32<00:05, 199.63it/s] 85%|███████████████████████████████████████████        | 6317/7473 [00:32<00:05, 200.17it/s] 85%|███████████████████████████████████████████▎       | 6338/7473 [00:32<00:05, 200.37it/s] 85%|███████████████████████████████████████████▍       | 6359/7473 [00:33<00:05, 198.44it/s] 85%|███████████████████████████████████████████▌       | 6379/7473 [00:33<00:05, 197.97it/s] 86%|███████████████████████████████████████████▋       | 6399/7473 [00:33<00:05, 198.17it/s] 86%|███████████████████████████████████████████▊       | 6419/7473 [00:33<00:05, 198.56it/s] 86%|███████████████████████████████████████████▉       | 6439/7473 [00:33<00:05, 198.32it/s] 86%|████████████████████████████████████████████       | 6459/7473 [00:33<00:05, 198.23it/s] 87%|████████████████████████████████████████████▏      | 6480/7473 [00:33<00:04, 198.73it/s] 87%|████████████████████████████████████████████▎      | 6500/7473 [00:33<00:04, 198.69it/s] 87%|████████████████████████████████████████████▍      | 6520/7473 [00:33<00:04, 198.88it/s] 88%|████████████████████████████████████████████▋      | 6541/7473 [00:33<00:04, 199.41it/s] 88%|████████████████████████████████████████████▊      | 6562/7473 [00:34<00:04, 199.61it/s] 88%|████████████████████████████████████████████▉      | 6582/7473 [00:34<00:04, 197.95it/s] 88%|█████████████████████████████████████████████      | 6603/7473 [00:34<00:04, 198.74it/s] 89%|█████████████████████████████████████████████▏     | 6623/7473 [00:34<00:04, 198.89it/s] 89%|█████████████████████████████████████████████▎     | 6643/7473 [00:34<00:04, 198.62it/s] 89%|█████████████████████████████████████████████▍     | 6663/7473 [00:34<00:04, 198.01it/s] 89%|█████████████████████████████████████████████▌     | 6683/7473 [00:34<00:03, 198.14it/s] 90%|█████████████████████████████████████████████▊     | 6704/7473 [00:34<00:03, 198.72it/s] 90%|█████████████████████████████████████████████▉     | 6724/7473 [00:34<00:03, 198.81it/s] 90%|██████████████████████████████████████████████     | 6744/7473 [00:34<00:03, 198.93it/s] 91%|██████████████████████████████████████████████▏    | 6764/7473 [00:35<00:03, 198.62it/s] 91%|██████████████████████████████████████████████▎    | 6784/7473 [00:35<00:03, 198.90it/s] 91%|██████████████████████████████████████████████▍    | 6804/7473 [00:35<00:03, 198.82it/s] 91%|██████████████████████████████████████████████▌    | 6824/7473 [00:35<00:03, 196.84it/s] 92%|██████████████████████████████████████████████▋    | 6844/7473 [00:35<00:03, 197.73it/s] 92%|██████████████████████████████████████████████▊    | 6864/7473 [00:35<00:03, 197.65it/s] 92%|██████████████████████████████████████████████▉    | 6885/7473 [00:35<00:02, 198.77it/s] 92%|███████████████████████████████████████████████▏   | 6906/7473 [00:35<00:02, 199.60it/s] 93%|███████████████████████████████████████████████▎   | 6926/7473 [00:35<00:02, 199.52it/s] 93%|███████████████████████████████████████████████▍   | 6946/7473 [00:35<00:02, 199.34it/s] 93%|███████████████████████████████████████████████▌   | 6966/7473 [00:36<00:02, 198.96it/s] 93%|███████████████████████████████████████████████▋   | 6986/7473 [00:36<00:02, 198.93it/s] 94%|███████████████████████████████████████████████▊   | 7007/7473 [00:36<00:02, 199.18it/s] 94%|███████████████████████████████████████████████▉   | 7027/7473 [00:36<00:02, 199.18it/s] 94%|████████████████████████████████████████████████   | 7047/7473 [00:36<00:02, 197.20it/s] 95%|████████████████████████████████████████████████▏  | 7068/7473 [00:36<00:02, 198.16it/s] 95%|████████████████████████████████████████████████▍  | 7089/7473 [00:36<00:01, 198.81it/s] 95%|████████████████████████████████████████████████▌  | 7109/7473 [00:36<00:01, 199.11it/s] 95%|████████████████████████████████████████████████▋  | 7129/7473 [00:36<00:01, 199.11it/s] 96%|████████████████████████████████████████████████▊  | 7149/7473 [00:36<00:01, 199.27it/s] 96%|████████████████████████████████████████████████▉  | 7169/7473 [00:37<00:01, 199.26it/s] 96%|█████████████████████████████████████████████████  | 7189/7473 [00:37<00:01, 199.25it/s] 96%|█████████████████████████████████████████████████▏ | 7209/7473 [00:37<00:01, 199.47it/s] 97%|█████████████████████████████████████████████████▎ | 7230/7473 [00:37<00:01, 199.73it/s] 97%|█████████████████████████████████████████████████▍ | 7251/7473 [00:37<00:01, 199.84it/s] 97%|█████████████████████████████████████████████████▌ | 7271/7473 [00:37<00:01, 197.64it/s] 98%|█████████████████████████████████████████████████▊ | 7292/7473 [00:37<00:00, 198.52it/s] 98%|█████████████████████████████████████████████████▉ | 7312/7473 [00:37<00:00, 198.86it/s] 98%|██████████████████████████████████████████████████ | 7332/7473 [00:37<00:00, 199.03it/s] 98%|██████████████████████████████████████████████████▏| 7353/7473 [00:38<00:00, 199.39it/s] 99%|██████████████████████████████████████████████████▎| 7373/7473 [00:38<00:00, 198.87it/s] 99%|██████████████████████████████████████████████████▍| 7394/7473 [00:38<00:00, 199.52it/s] 99%|██████████████████████████████████████████████████▌| 7414/7473 [00:38<00:00, 199.57it/s] 99%|██████████████████████████████████████████████████▋| 7435/7473 [00:38<00:00, 199.77it/s]100%|██████████████████████████████████████████████████▉| 7455/7473 [00:38<00:00, 199.24it/s]100%|███████████████████████████████████████████████████| 7473/7473 [00:38<00:00, 193.50it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:04<00:09,  4.97s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.01s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.36s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.43s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:09<00:04,  4.89s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:09<00:04,  4.96s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.31s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.35s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.30s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.47s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.35s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.52s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.72s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.88s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.77s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.94s/it]
[2023-08-13 04:00:26,044] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-13 04:00:33,929] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-13 04:00:33,929] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-13 04:00:33,930] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-13 04:00:33,930] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-13 04:00:33,930] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-13 04:00:33,930] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-13 04:00:33,930] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-13 04:00:33,930] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-13 04:00:33,930] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-13 04:00:33,930] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-13 04:00:33,930] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-13 04:00:33,930] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f47b9820b20>
[2023-08-13 04:00:33,930] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-13 04:00:33,930] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-13 04:00:33,930] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-13 04:00:33,930] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f47b98208b0>
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-13 04:00:33,931] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-13 04:00:33,932] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.5954673290252686 seconds
Loading extension module utils...
Loading extension module utils...
Time to load utils op: 0.504774808883667 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Time to load utils op: 0.6048107147216797 seconds
Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]Loading extension module utils...
############### Example ###############
Time to load utils op: 0.5043718814849854 seconds
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Fabric is cut to order at what type of seller? Choices:  A: curtains B: tailor shop C: clothing store D: sewing room E: hardware store
Rationales: Step 1: Start by understanding the question. You need to find out where fabric is cut to order.

Step 2: Look at each option and evaluate it based on the given information. 

Step 3: Assess option A: curtains. Curtains is a product, not a type of seller. You cannot order fabric to be cut at 'curtains'. So, A is not the answer.

Step 4: Evaluate option B: tailor shop. A tailor shop is a place where fabric is measured, cut, and sewed according to specific orders. It fits the requirement of the question. Therefore, B could be the answer.

Step 5: Consider option C: clothing store. While a clothing store does sell items made from fabric, they typically do not cut fabric to order. They sell pre-made and pre-size clothes. Hence, C is not the answer.

Step 6: Reflect on option D: sewing room. A sewing room isn't a type of seller; it's a room in someone's home where sewing tasks are done. Therefore, D cannot be the answer.

Step 7: Evaluate option E: hardware store. A hardware store generally sells items such as tools, home repair supplies, and other hardware necessities. It is not typically a place where fabric is cut to order. Thus, E is not the answer.

Step 8: Compare the remaining options. Only B - tailor shop qualifies as a seller where fabric is cut specifically to order.

Conclusion: The answer is B: tailor shop.
Answer: B: tailor shop

Input: Where are you if your reading magazines while waiting for a vehicle on rails? Choices:  A: vegetables B: market C: doctor D: train station E: bookstore
Rationales: The question provides some specific details that can be used to determine the answer:

1. It is mentioned that you are waiting for a vehicle on rails. This immediately eliminates some options like vegetables, market, and doctor as these don't involve any waiting for a vehicle on rails.
   
2. Among the remaining options, you could read a magazine in a bookstore but you are unlikely to be waiting for a vehicle on rails in a bookstore.
   
3. Therefore, the only place where you're likely to wait for a vehicle on rails, such as a train, is a train station.
   
Hence, the answer is D: train station.
Answer: D: train station

Input: What would need oil to be used? Choices:  A: ground B: human  body C: repair shop D: combustion engines E: service station
Rationales: 1. The first step in answering this question is to understand what is being asked. Oil is a lubricant or fuel that's often used in various mechanisms and systems to help them run smoothly or provide energy. In this context, we can eliminate options that absolutely cannot use oil in any form.
   
2. Looking at option A, which is "ground", we can safely eliminate it as a choice. Although oil can originate from the ground, the ground itself does not use or need oil.
   
3. Considering option B, the "human body," oil is not typically used or needed by the human body. Natural oils are produced by the body, but we do not externally apply or intake oil for our bodies to function. Thus, option B can be eliminated.
   
4. Option C is "repair shop". While a repair shop might use oil in repairing certain items, the shop itself does not need oil. The machines within the shop might need oil, but in terms of what needs oil to be used, a repair shop doesn’t need it to function. So, option C can also be eliminated.
   
5. Option E, a "service station", is similar to option C. While a service station might sell or use oil, the station itself doesn't need oil to function.
   
6. Upon elimination of these options, we are left with option D, "combustion engines." Now, an internal combustion engine runs on a type of oil (fuel), and the mechanical parts are typically lubricated by oil as well. In this case, oil is crucial for the functioning and efficiency of the engine. 
   
7. Therefore, the answer to the question "What would need oil to be used?" is D: combustion engines.
Answer: D: combustion engines

Input: What is person probably feeling that plans on stopping being married to their spouse? Choices:  A: detachment B: bankruptcy C: sad D: fights E: wrong
Rationales: 1. The question is asking about the emotional state of a person who intends to end their marriage.
2. The choice of words "plans on stopping being married" suggests a certain degree of emotional distance or pulling away from their spouse. 
3. This suggests they are likely to be feeling increasingly less emotionally attached or "detached" rather than necessarily feeling a stronger negative emotion. 
4. Looking at the options, "detachment" represents this kind of emotional distancing or pulling away. 
5. While someone might feel "sad" about the situation, or they could even be facing "bankruptcy" or "fights" due to the divorce, or they might even feel they are "wrong", these are not necessarily the primary emotions someone might feel when they are planning to end the marriage.
6. "Detachment", in this context, could be the overriding sentiment, suggesting they are already emotionally preparing for life without their spouse.
7. Hence, the conclusion that the answer is A: detachment.
Answer: A: detachment

Input: What could you use to store a clock? Choices:  A: shelf B: own bedroom C: desk D: wall E: car
Rationales: 1. The question asks where a clock can be stored. 
2. The option A: shelf is a physical object where items can be placed or stored. Therefore, it can be used to store a clock.
3. Alternately, B: own bedroom is a place, not a tool or object for storage. Therefore, it's not the best answer, as the clock will still need a surface or stand within the bedroom.
4. Similarly, C: desk and D: wall are both places where a clock might be positioned or hung, but they are not, themselves, storage.
5. The option E: car could be feasible, but it's not an ideal location to store a clock, given that cars are often exposed to temperature extremes.
6. Hence, out of all the given options, A: shelf is the most appropriate to be used to store a clock as it provides a dedicated and stable space for storage.
Answer: A: shelf

Input: The person put on lotion, what did they want? Choices:  A: fresh smell B: good credit C: smooth skin D: fresh produce E: headache
Rationales: 1. This question gives us a situation where a person is putting on lotion. 
2. The first thing to understand is the primary purpose of lotion, which is mostly to hydrate and moisturize the skin.
3. With this knowledge, we then look at the given choices and analyze which one makes the most sense. 
4. Choice A, fresh smell might be a plausible choice as some lotions do have a fragrance. However, the main purpose of lotions isn't to create a fresh smell.
5. Choice B, good credit, is irrelevant as applying lotion has no relatability to financial products or situations.
6. Choice C, smooth skin, fits into the primary purpose what we established earlier about what lotion is mainly used for, moisturizing, which makes skin smooth. 
7. Choice D, fresh produce, has no relevance to the context of applying lotion.
8. Similarly, choice E, headache, is also not related to the application of lotion. 
9. Hence, the best answer is C: smooth skin, which aligns with the primary purpose of lotion, that is, to hydrate and moisturize to achieve smooth skin.
Answer: C: smooth skin

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o6-tcommonsenseqa-s10-rTrue
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 139, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 116, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
Evaluating gsm8k :   0%|                                              | 0/50 [00:05<?, ?it/s]
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 139, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 116, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 139, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 116, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 139, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 116, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3615605 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 3615602) of binary: /home/ylu130/.conda/envs/distllm/bin/python
Traceback (most recent call last):
  File "/home/ylu130/.conda/envs/distllm/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/run.py", line 761, in main
    run(args)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/ylu130/workspace/in-context-generalization/inference.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-08-13_04:00:41
  host      : ia1.wse.jhu.edu
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 3615603)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-08-13_04:00:41
  host      : ia1.wse.jhu.edu
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 3615604)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-08-13_04:00:41
  host      : ia1.wse.jhu.edu
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3615602)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o7-tcommonsenseqa-s10-rTrue --seed 10 --rationales --num-out-domain 7
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[nltk_data]   Package punkt is already up-to-date!
[2023-08-13 04:00:45,500] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o7-tcommonsenseqa-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 7
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o7-tcommonsenseqa-s10-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  0%|                                                     | 16/7473 [00:00<00:48, 154.03it/s]  0%|▏                                                    | 32/7473 [00:00<00:48, 153.47it/s]  1%|▎                                                    | 48/7473 [00:00<00:48, 153.41it/s]  1%|▍                                                    | 64/7473 [00:00<00:48, 153.43it/s]  1%|▌                                                    | 80/7473 [00:00<00:47, 154.10it/s]  1%|▋                                                    | 96/7473 [00:00<00:47, 154.47it/s]  1%|▊                                                   | 112/7473 [00:00<00:47, 153.98it/s]  2%|▉                                                   | 128/7473 [00:00<00:49, 149.51it/s]  2%|█                                                   | 144/7473 [00:00<00:48, 151.41it/s]  2%|█                                                   | 160/7473 [00:01<00:47, 153.40it/s]  2%|█▏                                                  | 176/7473 [00:01<00:47, 154.01it/s]  3%|█▎                                                  | 192/7473 [00:01<00:46, 155.08it/s]  3%|█▍                                                  | 208/7473 [00:01<00:46, 155.67it/s]  3%|█▌                                                  | 224/7473 [00:01<00:47, 153.84it/s]  3%|█▋                                                  | 240/7473 [00:01<00:47, 152.85it/s]  3%|█▊                                                  | 256/7473 [00:01<00:47, 151.91it/s]  4%|█▉                                                  | 272/7473 [00:01<00:47, 152.99it/s]  4%|██                                                  | 288/7473 [00:01<00:47, 152.37it/s]  4%|██                                                  | 304/7473 [00:01<00:47, 150.09it/s]  4%|██▏                                                 | 320/7473 [00:02<00:47, 151.92it/s]  4%|██▎                                                 | 336/7473 [00:02<00:46, 152.61it/s]  5%|██▍                                                 | 352/7473 [00:02<00:46, 153.72it/s]  5%|██▌                                                 | 368/7473 [00:02<00:46, 153.83it/s]  5%|██▋                                                 | 384/7473 [00:02<00:46, 151.99it/s]  5%|██▊                                                 | 404/7473 [00:02<00:42, 165.75it/s]  6%|██▉                                                 | 428/7473 [00:02<00:37, 186.44it/s]  6%|███▏                                                | 452/7473 [00:02<00:34, 201.13it/s]  6%|███▎                                                | 476/7473 [00:02<00:33, 209.84it/s]  7%|███▍                                                | 500/7473 [00:03<00:32, 217.43it/s]  7%|███▋                                                | 524/7473 [00:03<00:31, 223.42it/s]  7%|███▊                                                | 548/7473 [00:03<00:30, 226.88it/s]  8%|███▉                                                | 571/7473 [00:03<00:30, 227.28it/s]  8%|████▏                                               | 595/7473 [00:03<00:29, 229.47it/s]  8%|████▎                                               | 619/7473 [00:03<00:29, 230.52it/s]  9%|████▍                                               | 643/7473 [00:03<00:29, 232.96it/s]  9%|████▋                                               | 667/7473 [00:03<00:29, 232.01it/s]  9%|████▊                                               | 691/7473 [00:03<00:28, 234.02it/s] 10%|████▉                                               | 715/7473 [00:03<00:28, 233.83it/s] 10%|█████▏                                              | 739/7473 [00:04<00:28, 235.45it/s] 10%|█████▎                                              | 763/7473 [00:04<00:28, 232.85it/s] 11%|█████▍                                              | 787/7473 [00:04<00:28, 231.10it/s] 11%|█████▋                                              | 811/7473 [00:04<00:28, 230.37it/s] 11%|█████▊                                              | 835/7473 [00:04<00:28, 232.58it/s] 11%|█████▉                                              | 859/7473 [00:04<00:28, 233.53it/s] 12%|██████▏                                             | 883/7473 [00:04<00:28, 235.31it/s] 12%|██████▎                                             | 907/7473 [00:04<00:27, 236.13it/s] 12%|██████▍                                             | 931/7473 [00:04<00:27, 234.61it/s] 13%|██████▋                                             | 956/7473 [00:04<00:27, 236.54it/s] 13%|██████▊                                             | 981/7473 [00:05<00:27, 237.92it/s] 13%|██████▊                                            | 1005/7473 [00:05<00:27, 237.22it/s] 14%|███████                                            | 1030/7473 [00:05<00:27, 238.14it/s] 14%|███████▏                                           | 1054/7473 [00:05<00:26, 238.24it/s] 14%|███████▎                                           | 1078/7473 [00:05<00:27, 235.94it/s] 15%|███████▌                                           | 1102/7473 [00:05<00:26, 237.03it/s] 15%|███████▋                                           | 1126/7473 [00:05<00:26, 236.85it/s] 15%|███████▊                                           | 1150/7473 [00:05<00:26, 236.63it/s] 16%|████████                                           | 1174/7473 [00:05<00:26, 235.27it/s] 16%|████████▏                                          | 1198/7473 [00:05<00:26, 236.22it/s] 16%|████████▎                                          | 1222/7473 [00:06<00:26, 236.52it/s] 17%|████████▌                                          | 1246/7473 [00:06<00:26, 237.16it/s] 17%|████████▋                                          | 1270/7473 [00:06<00:26, 237.26it/s] 17%|████████▊                                          | 1294/7473 [00:06<00:26, 237.59it/s] 18%|████████▉                                          | 1318/7473 [00:06<00:25, 238.07it/s] 18%|█████████▏                                         | 1342/7473 [00:06<00:25, 237.14it/s] 18%|█████████▎                                         | 1366/7473 [00:06<00:25, 234.94it/s] 19%|█████████▍                                         | 1390/7473 [00:06<00:26, 232.81it/s] 19%|█████████▋                                         | 1414/7473 [00:06<00:25, 234.35it/s] 19%|█████████▊                                         | 1438/7473 [00:07<00:25, 235.36it/s] 20%|█████████▉                                         | 1462/7473 [00:07<00:25, 234.26it/s] 20%|██████████▏                                        | 1486/7473 [00:07<00:25, 235.46it/s] 20%|██████████▎                                        | 1510/7473 [00:07<00:25, 236.63it/s] 21%|██████████▍                                        | 1534/7473 [00:07<00:24, 237.57it/s] 21%|██████████▋                                        | 1558/7473 [00:07<00:24, 237.20it/s] 21%|██████████▊                                        | 1582/7473 [00:07<00:24, 236.46it/s] 21%|██████████▉                                        | 1606/7473 [00:07<00:24, 236.99it/s] 22%|███████████                                        | 1630/7473 [00:07<00:24, 234.79it/s] 22%|███████████▎                                       | 1654/7473 [00:07<00:24, 235.08it/s] 22%|███████████▍                                       | 1678/7473 [00:08<00:24, 236.14it/s] 23%|███████████▌                                       | 1702/7473 [00:08<00:24, 236.65it/s] 23%|███████████▊                                       | 1726/7473 [00:08<00:24, 237.15it/s] 23%|███████████▉                                       | 1750/7473 [00:08<00:24, 237.32it/s] 24%|████████████                                       | 1774/7473 [00:08<00:24, 232.24it/s] 24%|████████████▎                                      | 1798/7473 [00:08<00:24, 233.65it/s] 24%|████████████▍                                      | 1822/7473 [00:08<00:24, 234.21it/s] 25%|████████████▌                                      | 1846/7473 [00:08<00:24, 231.56it/s] 25%|████████████▊                                      | 1870/7473 [00:08<00:24, 233.04it/s] 25%|████████████▉                                      | 1894/7473 [00:08<00:23, 234.23it/s] 26%|█████████████                                      | 1918/7473 [00:09<00:23, 234.36it/s] 26%|█████████████▎                                     | 1942/7473 [00:09<00:23, 235.03it/s] 26%|█████████████▍                                     | 1966/7473 [00:09<00:23, 235.67it/s] 27%|█████████████▌                                     | 1990/7473 [00:09<00:23, 233.73it/s] 27%|█████████████▋                                     | 2014/7473 [00:09<00:23, 234.63it/s] 27%|█████████████▉                                     | 2038/7473 [00:09<00:23, 235.26it/s] 28%|██████████████                                     | 2062/7473 [00:09<00:22, 236.01it/s] 28%|██████████████▏                                    | 2086/7473 [00:09<00:23, 233.95it/s] 28%|██████████████▍                                    | 2110/7473 [00:09<00:22, 234.55it/s] 29%|██████████████▌                                    | 2134/7473 [00:09<00:22, 234.30it/s] 29%|██████████████▋                                    | 2158/7473 [00:10<00:22, 235.42it/s] 29%|██████████████▉                                    | 2182/7473 [00:10<00:22, 235.60it/s] 30%|███████████████                                    | 2206/7473 [00:10<00:22, 233.35it/s] 30%|███████████████▏                                   | 2230/7473 [00:10<00:22, 234.63it/s] 30%|███████████████▍                                   | 2254/7473 [00:10<00:22, 232.36it/s] 30%|███████████████▌                                   | 2278/7473 [00:10<00:22, 232.94it/s] 31%|███████████████▋                                   | 2302/7473 [00:10<00:22, 232.98it/s] 31%|███████████████▊                                   | 2326/7473 [00:10<00:21, 234.48it/s] 31%|████████████████                                   | 2350/7473 [00:10<00:21, 235.35it/s] 32%|████████████████▏                                  | 2374/7473 [00:10<00:21, 235.79it/s] 32%|████████████████▎                                  | 2398/7473 [00:11<00:21, 236.55it/s] 32%|████████████████▌                                  | 2422/7473 [00:11<00:21, 233.11it/s] 33%|████████████████▋                                  | 2446/7473 [00:11<00:21, 233.75it/s] 33%|████████████████▊                                  | 2470/7473 [00:11<00:21, 234.65it/s] 33%|█████████████████                                  | 2494/7473 [00:11<00:21, 235.30it/s] 34%|█████████████████▏                                 | 2518/7473 [00:11<00:21, 235.83it/s] 34%|█████████████████▎                                 | 2542/7473 [00:11<00:23, 210.09it/s] 34%|█████████████████▌                                 | 2566/7473 [00:11<00:22, 218.00it/s] 35%|█████████████████▋                                 | 2590/7473 [00:11<00:21, 223.76it/s] 35%|█████████████████▊                                 | 2614/7473 [00:12<00:21, 228.07it/s] 35%|██████████████████                                 | 2638/7473 [00:12<00:20, 230.99it/s] 36%|██████████████████▏                                | 2662/7473 [00:12<00:20, 230.76it/s] 36%|██████████████████▎                                | 2686/7473 [00:12<00:20, 229.58it/s] 36%|██████████████████▍                                | 2710/7473 [00:12<00:21, 225.11it/s] 37%|██████████████████▋                                | 2734/7473 [00:12<00:20, 228.30it/s] 37%|██████████████████▊                                | 2758/7473 [00:12<00:20, 229.05it/s] 37%|██████████████████▉                                | 2782/7473 [00:12<00:20, 231.72it/s] 38%|███████████████████▏                               | 2806/7473 [00:12<00:19, 233.93it/s] 38%|███████████████████▎                               | 2830/7473 [00:12<00:19, 234.61it/s] 38%|███████████████████▍                               | 2854/7473 [00:13<00:19, 234.97it/s] 39%|███████████████████▋                               | 2878/7473 [00:13<00:19, 234.84it/s] 39%|███████████████████▊                               | 2902/7473 [00:13<00:19, 233.10it/s] 39%|███████████████████▉                               | 2926/7473 [00:13<00:19, 234.35it/s] 39%|████████████████████▏                              | 2950/7473 [00:13<00:19, 235.71it/s] 40%|████████████████████▎                              | 2974/7473 [00:13<00:19, 234.80it/s] 40%|████████████████████▍                              | 2998/7473 [00:13<00:19, 233.62it/s] 40%|████████████████████▌                              | 3022/7473 [00:13<00:19, 232.91it/s] 41%|████████████████████▊                              | 3046/7473 [00:13<00:18, 233.94it/s] 41%|████████████████████▉                              | 3070/7473 [00:14<00:18, 235.34it/s] 41%|█████████████████████                              | 3094/7473 [00:14<00:18, 234.76it/s] 42%|█████████████████████▎                             | 3118/7473 [00:14<00:18, 234.50it/s] 42%|█████████████████████▍                             | 3142/7473 [00:14<00:18, 234.42it/s] 42%|█████████████████████▌                             | 3166/7473 [00:14<00:18, 233.01it/s] 43%|█████████████████████▊                             | 3190/7473 [00:14<00:18, 234.10it/s] 43%|█████████████████████▉                             | 3214/7473 [00:14<00:18, 232.66it/s] 43%|██████████████████████                             | 3238/7473 [00:14<00:18, 232.29it/s] 44%|██████████████████████▎                            | 3262/7473 [00:14<00:18, 232.97it/s] 44%|██████████████████████▍                            | 3286/7473 [00:14<00:17, 234.80it/s] 44%|██████████████████████▌                            | 3310/7473 [00:15<00:17, 235.83it/s] 45%|██████████████████████▊                            | 3334/7473 [00:15<00:17, 235.21it/s] 45%|██████████████████████▉                            | 3358/7473 [00:15<00:17, 232.53it/s] 45%|███████████████████████                            | 3382/7473 [00:15<00:17, 232.66it/s] 46%|███████████████████████▏                           | 3406/7473 [00:15<00:17, 233.36it/s] 46%|███████████████████████▍                           | 3430/7473 [00:15<00:17, 232.93it/s] 46%|███████████████████████▌                           | 3454/7473 [00:15<00:17, 233.25it/s] 47%|███████████████████████▋                           | 3478/7473 [00:15<00:17, 234.05it/s] 47%|███████████████████████▉                           | 3502/7473 [00:15<00:16, 235.20it/s] 47%|████████████████████████                           | 3526/7473 [00:15<00:16, 235.85it/s] 48%|████████████████████████▏                          | 3550/7473 [00:16<00:16, 236.43it/s] 48%|████████████████████████▍                          | 3574/7473 [00:16<00:16, 237.11it/s] 48%|████████████████████████▌                          | 3598/7473 [00:16<00:16, 236.99it/s] 48%|████████████████████████▋                          | 3622/7473 [00:16<00:16, 237.21it/s] 49%|████████████████████████▉                          | 3646/7473 [00:16<00:16, 235.97it/s] 49%|█████████████████████████                          | 3670/7473 [00:16<00:16, 234.01it/s] 49%|█████████████████████████▏                         | 3694/7473 [00:16<00:16, 233.55it/s] 50%|█████████████████████████▎                         | 3718/7473 [00:16<00:16, 234.49it/s] 50%|█████████████████████████▌                         | 3742/7473 [00:16<00:15, 235.09it/s] 50%|█████████████████████████▋                         | 3766/7473 [00:16<00:15, 235.39it/s] 51%|█████████████████████████▊                         | 3790/7473 [00:17<00:15, 236.15it/s] 51%|██████████████████████████                         | 3814/7473 [00:17<00:15, 236.29it/s] 51%|██████████████████████████▏                        | 3838/7473 [00:17<00:15, 234.42it/s] 52%|██████████████████████████▎                        | 3862/7473 [00:17<00:17, 204.01it/s] 52%|██████████████████████████▌                        | 3884/7473 [00:17<00:19, 185.50it/s] 52%|██████████████████████████▋                        | 3904/7473 [00:17<00:20, 176.56it/s] 52%|██████████████████████████▊                        | 3923/7473 [00:17<00:20, 170.56it/s] 53%|██████████████████████████▉                        | 3941/7473 [00:17<00:21, 166.80it/s] 53%|███████████████████████████                        | 3958/7473 [00:18<00:21, 163.55it/s] 53%|███████████████████████████▏                       | 3975/7473 [00:18<00:21, 161.45it/s] 53%|███████████████████████████▏                       | 3992/7473 [00:18<00:21, 160.08it/s] 54%|███████████████████████████▎                       | 4009/7473 [00:18<00:21, 159.08it/s] 54%|███████████████████████████▍                       | 4025/7473 [00:18<00:21, 158.40it/s] 54%|███████████████████████████▌                       | 4041/7473 [00:18<00:21, 157.78it/s] 54%|███████████████████████████▋                       | 4057/7473 [00:18<00:21, 157.36it/s] 55%|███████████████████████████▊                       | 4073/7473 [00:18<00:21, 156.50it/s] 55%|███████████████████████████▉                       | 4089/7473 [00:18<00:21, 156.89it/s] 55%|████████████████████████████                       | 4105/7473 [00:18<00:21, 155.96it/s] 55%|████████████████████████████                       | 4121/7473 [00:19<00:21, 154.09it/s] 55%|████████████████████████████▎                      | 4141/7473 [00:19<00:19, 167.18it/s] 56%|████████████████████████████▍                      | 4165/7473 [00:19<00:17, 187.96it/s] 56%|████████████████████████████▌                      | 4189/7473 [00:19<00:16, 202.20it/s] 56%|████████████████████████████▊                      | 4213/7473 [00:19<00:15, 211.77it/s] 57%|████████████████████████████▉                      | 4237/7473 [00:19<00:14, 218.50it/s] 57%|█████████████████████████████                      | 4261/7473 [00:19<00:14, 223.57it/s] 57%|█████████████████████████████▏                     | 4285/7473 [00:19<00:14, 227.20it/s] 58%|█████████████████████████████▍                     | 4309/7473 [00:19<00:13, 230.18it/s] 58%|█████████████████████████████▌                     | 4333/7473 [00:20<00:13, 232.95it/s] 58%|█████████████████████████████▋                     | 4357/7473 [00:20<00:13, 232.64it/s] 59%|█████████████████████████████▉                     | 4381/7473 [00:20<00:13, 233.67it/s] 59%|██████████████████████████████                     | 4405/7473 [00:20<00:13, 234.87it/s] 59%|██████████████████████████████▏                    | 4429/7473 [00:20<00:12, 234.75it/s] 60%|██████████████████████████████▍                    | 4453/7473 [00:20<00:12, 234.10it/s] 60%|██████████████████████████████▌                    | 4477/7473 [00:20<00:12, 234.21it/s] 60%|██████████████████████████████▋                    | 4501/7473 [00:20<00:12, 233.84it/s] 61%|██████████████████████████████▉                    | 4525/7473 [00:20<00:12, 234.56it/s] 61%|███████████████████████████████                    | 4549/7473 [00:20<00:12, 233.93it/s] 61%|███████████████████████████████▏                   | 4573/7473 [00:21<00:12, 233.50it/s] 62%|███████████████████████████████▎                   | 4597/7473 [00:21<00:12, 234.44it/s] 62%|███████████████████████████████▌                   | 4621/7473 [00:21<00:12, 235.10it/s] 62%|███████████████████████████████▋                   | 4645/7473 [00:21<00:12, 235.42it/s] 62%|███████████████████████████████▊                   | 4669/7473 [00:21<00:11, 235.70it/s] 63%|████████████████████████████████                   | 4693/7473 [00:21<00:11, 236.01it/s] 63%|████████████████████████████████▏                  | 4717/7473 [00:21<00:11, 235.13it/s] 63%|████████████████████████████████▎                  | 4741/7473 [00:21<00:11, 235.70it/s] 64%|████████████████████████████████▌                  | 4765/7473 [00:21<00:11, 236.60it/s] 64%|████████████████████████████████▋                  | 4789/7473 [00:21<00:11, 234.65it/s] 64%|████████████████████████████████▊                  | 4813/7473 [00:22<00:11, 234.98it/s] 65%|█████████████████████████████████                  | 4837/7473 [00:22<00:11, 235.89it/s] 65%|█████████████████████████████████▏                 | 4861/7473 [00:22<00:11, 236.08it/s] 65%|█████████████████████████████████▎                 | 4885/7473 [00:22<00:10, 236.36it/s] 66%|█████████████████████████████████▌                 | 4909/7473 [00:22<00:10, 237.16it/s] 66%|█████████████████████████████████▋                 | 4933/7473 [00:22<00:10, 236.60it/s] 66%|█████████████████████████████████▊                 | 4957/7473 [00:22<00:10, 234.75it/s] 67%|█████████████████████████████████▉                 | 4981/7473 [00:22<00:10, 233.70it/s] 67%|██████████████████████████████████▏                | 5005/7473 [00:22<00:10, 234.57it/s] 67%|██████████████████████████████████▎                | 5029/7473 [00:22<00:10, 233.73it/s] 68%|██████████████████████████████████▍                | 5053/7473 [00:23<00:10, 234.93it/s] 68%|██████████████████████████████████▋                | 5077/7473 [00:23<00:10, 235.74it/s] 68%|██████████████████████████████████▊                | 5101/7473 [00:23<00:10, 236.16it/s] 69%|██████████████████████████████████▉                | 5125/7473 [00:23<00:09, 236.55it/s] 69%|███████████████████████████████████▏               | 5149/7473 [00:23<00:09, 236.76it/s] 69%|███████████████████████████████████▎               | 5173/7473 [00:23<00:09, 236.85it/s] 70%|███████████████████████████████████▍               | 5197/7473 [00:23<00:09, 236.80it/s] 70%|███████████████████████████████████▋               | 5221/7473 [00:23<00:09, 237.03it/s] 70%|███████████████████████████████████▊               | 5245/7473 [00:23<00:10, 210.14it/s] 71%|███████████████████████████████████▉               | 5269/7473 [00:24<00:10, 217.05it/s] 71%|████████████████████████████████████               | 5293/7473 [00:24<00:09, 222.63it/s] 71%|████████████████████████████████████▎              | 5317/7473 [00:24<00:09, 226.52it/s] 71%|████████████████████████████████████▍              | 5340/7473 [00:24<00:09, 227.20it/s] 72%|████████████████████████████████████▌              | 5364/7473 [00:24<00:09, 230.14it/s] 72%|████████████████████████████████████▊              | 5388/7473 [00:24<00:08, 232.27it/s] 72%|████████████████████████████████████▉              | 5412/7473 [00:24<00:08, 233.33it/s] 73%|█████████████████████████████████████              | 5436/7473 [00:24<00:08, 234.37it/s] 73%|█████████████████████████████████████▎             | 5460/7473 [00:24<00:08, 234.91it/s] 73%|█████████████████████████████████████▍             | 5484/7473 [00:25<00:12, 154.56it/s] 74%|█████████████████████████████████████▌             | 5508/7473 [00:25<00:11, 172.75it/s] 74%|█████████████████████████████████████▊             | 5532/7473 [00:25<00:10, 188.37it/s] 74%|█████████████████████████████████████▉             | 5556/7473 [00:25<00:09, 200.47it/s] 75%|██████████████████████████████████████             | 5580/7473 [00:25<00:09, 210.28it/s] 75%|██████████████████████████████████████▏            | 5604/7473 [00:25<00:08, 217.37it/s] 75%|██████████████████████████████████████▍            | 5628/7473 [00:25<00:08, 222.34it/s] 76%|██████████████████████████████████████▌            | 5652/7473 [00:25<00:08, 227.06it/s] 76%|██████████████████████████████████████▋            | 5676/7473 [00:25<00:07, 228.27it/s] 76%|██████████████████████████████████████▉            | 5700/7473 [00:26<00:07, 229.20it/s] 77%|███████████████████████████████████████            | 5724/7473 [00:26<00:07, 230.87it/s] 77%|███████████████████████████████████████▏           | 5748/7473 [00:26<00:07, 233.00it/s] 77%|███████████████████████████████████████▍           | 5772/7473 [00:26<00:07, 234.37it/s] 78%|███████████████████████████████████████▌           | 5796/7473 [00:26<00:07, 234.74it/s] 78%|███████████████████████████████████████▋           | 5820/7473 [00:26<00:07, 234.41it/s] 78%|███████████████████████████████████████▉           | 5844/7473 [00:26<00:06, 235.09it/s] 79%|████████████████████████████████████████           | 5868/7473 [00:26<00:06, 234.07it/s] 79%|████████████████████████████████████████▏          | 5892/7473 [00:26<00:06, 234.42it/s] 79%|████████████████████████████████████████▎          | 5916/7473 [00:26<00:06, 232.29it/s] 79%|████████████████████████████████████████▌          | 5940/7473 [00:27<00:06, 231.84it/s] 80%|████████████████████████████████████████▋          | 5964/7473 [00:27<00:06, 231.78it/s] 80%|████████████████████████████████████████▊          | 5988/7473 [00:27<00:06, 232.39it/s] 80%|█████████████████████████████████████████          | 6012/7473 [00:27<00:06, 232.54it/s] 81%|█████████████████████████████████████████▏         | 6036/7473 [00:27<00:06, 233.41it/s] 81%|█████████████████████████████████████████▎         | 6060/7473 [00:27<00:06, 234.10it/s] 81%|█████████████████████████████████████████▌         | 6084/7473 [00:27<00:05, 234.82it/s] 82%|█████████████████████████████████████████▋         | 6108/7473 [00:27<00:05, 232.43it/s] 82%|█████████████████████████████████████████▊         | 6132/7473 [00:27<00:05, 231.61it/s] 82%|██████████████████████████████████████████         | 6156/7473 [00:27<00:05, 232.58it/s] 83%|██████████████████████████████████████████▏        | 6180/7473 [00:28<00:05, 233.09it/s] 83%|██████████████████████████████████████████▎        | 6204/7473 [00:28<00:05, 233.43it/s] 83%|██████████████████████████████████████████▌        | 6228/7473 [00:28<00:05, 232.37it/s] 84%|██████████████████████████████████████████▋        | 6252/7473 [00:28<00:05, 233.44it/s] 84%|██████████████████████████████████████████▊        | 6276/7473 [00:28<00:05, 233.77it/s] 84%|██████████████████████████████████████████▉        | 6300/7473 [00:28<00:05, 233.76it/s] 85%|███████████████████████████████████████████▏       | 6324/7473 [00:28<00:04, 234.34it/s] 85%|███████████████████████████████████████████▎       | 6348/7473 [00:28<00:04, 227.92it/s] 85%|███████████████████████████████████████████▍       | 6371/7473 [00:28<00:04, 227.37it/s] 86%|███████████████████████████████████████████▋       | 6395/7473 [00:29<00:04, 228.71it/s] 86%|███████████████████████████████████████████▊       | 6419/7473 [00:29<00:04, 230.25it/s] 86%|███████████████████████████████████████████▉       | 6443/7473 [00:29<00:04, 231.16it/s] 87%|████████████████████████████████████████████▏      | 6467/7473 [00:29<00:04, 232.60it/s] 87%|████████████████████████████████████████████▎      | 6491/7473 [00:29<00:04, 232.85it/s] 87%|████████████████████████████████████████████▍      | 6515/7473 [00:29<00:04, 233.12it/s] 88%|████████████████████████████████████████████▋      | 6539/7473 [00:29<00:03, 234.48it/s] 88%|████████████████████████████████████████████▊      | 6563/7473 [00:29<00:03, 235.13it/s] 88%|████████████████████████████████████████████▉      | 6587/7473 [00:29<00:03, 234.13it/s] 88%|█████████████████████████████████████████████      | 6611/7473 [00:29<00:03, 235.05it/s] 89%|█████████████████████████████████████████████▎     | 6635/7473 [00:30<00:03, 235.04it/s] 89%|█████████████████████████████████████████████▍     | 6659/7473 [00:30<00:03, 235.21it/s] 89%|█████████████████████████████████████████████▌     | 6683/7473 [00:30<00:03, 234.90it/s] 90%|█████████████████████████████████████████████▊     | 6707/7473 [00:30<00:03, 235.73it/s] 90%|█████████████████████████████████████████████▉     | 6731/7473 [00:30<00:03, 235.94it/s] 90%|██████████████████████████████████████████████     | 6755/7473 [00:30<00:03, 235.84it/s] 91%|██████████████████████████████████████████████▎    | 6779/7473 [00:30<00:02, 235.34it/s] 91%|██████████████████████████████████████████████▍    | 6803/7473 [00:30<00:02, 235.40it/s] 91%|██████████████████████████████████████████████▌    | 6827/7473 [00:30<00:02, 233.35it/s] 92%|██████████████████████████████████████████████▊    | 6851/7473 [00:30<00:02, 234.00it/s] 92%|██████████████████████████████████████████████▉    | 6875/7473 [00:31<00:02, 235.12it/s] 92%|███████████████████████████████████████████████    | 6899/7473 [00:31<00:02, 235.70it/s] 93%|███████████████████████████████████████████████▏   | 6923/7473 [00:31<00:02, 236.27it/s] 93%|███████████████████████████████████████████████▍   | 6947/7473 [00:31<00:02, 236.38it/s] 93%|███████████████████████████████████████████████▌   | 6971/7473 [00:31<00:02, 235.70it/s] 94%|███████████████████████████████████████████████▋   | 6995/7473 [00:31<00:02, 235.81it/s] 94%|███████████████████████████████████████████████▉   | 7019/7473 [00:31<00:01, 235.78it/s] 94%|████████████████████████████████████████████████   | 7043/7473 [00:31<00:01, 233.52it/s] 95%|████████████████████████████████████████████████▏  | 7067/7473 [00:31<00:01, 233.91it/s] 95%|████████████████████████████████████████████████▍  | 7091/7473 [00:31<00:01, 235.03it/s] 95%|████████████████████████████████████████████████▌  | 7115/7473 [00:32<00:01, 235.08it/s] 96%|████████████████████████████████████████████████▋  | 7139/7473 [00:32<00:01, 234.44it/s] 96%|████████████████████████████████████████████████▉  | 7163/7473 [00:32<00:01, 234.72it/s] 96%|█████████████████████████████████████████████████  | 7187/7473 [00:32<00:01, 228.06it/s] 96%|█████████████████████████████████████████████████▏ | 7211/7473 [00:32<00:01, 231.08it/s] 97%|█████████████████████████████████████████████████▍ | 7235/7473 [00:32<00:01, 233.04it/s] 97%|█████████████████████████████████████████████████▌ | 7259/7473 [00:32<00:00, 234.21it/s] 97%|█████████████████████████████████████████████████▋ | 7283/7473 [00:32<00:00, 232.13it/s] 98%|█████████████████████████████████████████████████▊ | 7307/7473 [00:32<00:00, 233.38it/s] 98%|██████████████████████████████████████████████████ | 7331/7473 [00:33<00:00, 233.98it/s] 98%|██████████████████████████████████████████████████▏| 7355/7473 [00:33<00:00, 234.68it/s] 99%|██████████████████████████████████████████████████▎| 7379/7473 [00:33<00:00, 234.78it/s] 99%|██████████████████████████████████████████████████▌| 7403/7473 [00:33<00:00, 234.86it/s] 99%|██████████████████████████████████████████████████▋| 7427/7473 [00:33<00:00, 234.26it/s]100%|██████████████████████████████████████████████████▊| 7451/7473 [00:33<00:00, 235.00it/s]100%|███████████████████████████████████████████████████| 7473/7473 [00:33<00:00, 222.29it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.19s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.39s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.68s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.63s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.49s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.62s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.94s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.89s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.03s/it]
Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.71s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.15s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.26s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:16<00:00,  5.31s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:16<00:00,  5.45s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.16s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.30s/it]
[2023-08-13 04:02:15,133] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-13 04:02:25,812] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-13 04:02:25,814] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-13 04:02:25,814] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-13 04:02:25,814] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-13 04:02:25,814] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-13 04:02:25,814] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-13 04:02:25,815] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-13 04:02:25,815] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-13 04:02:25,815] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-13 04:02:25,815] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-13 04:02:25,815] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-13 04:02:25,815] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fb3f7755fa0>
[2023-08-13 04:02:25,815] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-13 04:02:25,815] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-13 04:02:25,815] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-13 04:02:25,815] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-13 04:02:25,815] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-13 04:02:25,815] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-13 04:02:25,815] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-13 04:02:25,815] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-13 04:02:25,815] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-13 04:02:25,815] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-13 04:02:25,815] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-13 04:02:25,815] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-13 04:02:25,815] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-13 04:02:25,815] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-13 04:02:25,815] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-13 04:02:25,815] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-13 04:02:25,815] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-13 04:02:25,815] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fb3f7871700>
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-13 04:02:25,816] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-13 04:02:25,817] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-13 04:02:25,817] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-13 04:02:25,817] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-13 04:02:25,817] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-13 04:02:25,817] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.7110183238983154 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Loading extension module utils...
Time to load utils op: 0.7050955295562744 seconds
Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Fabric is cut to order at what type of seller? Choices:  A: curtains B: tailor shop C: clothing store D: sewing room E: hardware store
Rationales: 1. The question is asking where fabric is cut specifically to order.
2. Option A, curtains, doesn't make sense because curtains are a type of product, not a place where fabric is cut.
3. Option C, clothing store, is not usually a place where fabric is cut to order as they usually sell pre-made clothes.
4. Option D, sewing room, can be a place where fabric is cut but not typically to order. It's more of a personal workspace for sewing.
5. Option E, hardware store, is not the correct answer as they don't typically deal with fabric but with hardware items such as tools and construction materials.
6. Option B, tailor shop, is a place where garments are made to measure and fits the description of a place where fabric is cut to order.
7. Therefore, the correct answer is B: tailor shop.
Answer: B: tailor shop

Input: Where are you if your reading magazines while waiting for a vehicle on rails? Choices:  A: vegetables B: market C: doctor D: train station E: bookstore
Rationales: 1. The question asks where you are if you're waiting for a "vehicle on rails".
2. This clue points to some kind of transportation that operates on a rail system.
3. The choices given are vegetables, market, doctor, train station, and bookstore.
4. Vehicles on rails, can refer to trains, trams or trolleys. 
5. Considering the choices, "train station" is the only location related to a vehicle on rails.
6. Therefore, the answer is D: train station.
Answer: D: train station

Input: What would need oil to be used? Choices:  A: ground B: human  body C: repair shop D: combustion engines E: service station
Rationales: Reasoning:

Step 1: Ground usually doesn't require oil, it can absorb oil or other liquids but it doesn't actively need it to function.

Step 2: While the human body does need fats and moisture to function properly, it does not necessarily require oil as such.

Step 3: A repair shop and a service station are places where oil may be used but they themselves do not require oil.

Step 4: Combustion engines, however, require oil to lubricate the moving parts and control the temperature by reducing friction. 

From the given choices, it is clear that combustion engines need oil to operate efficiently. Hence, the answer is D: Combustion engines.
Answer: D: combustion engines

Input: What is person probably feeling that plans on stopping being married to their spouse? Choices:  A: detachment B: bankruptcy C: sad D: fights E: wrong
Rationales: 1. The question asks us about the probable feeling of a person who plans on stopping being married to their spouse. 
2. This indicates that the person is already thinking about ending the marital relationship. 
3. The options given are detachment, bankruptcy, sad, fights, and wrong.
4. Bankruptcy and fights are circumstantial and may not reflect the emotional state of the person. They simply reflect situations but not feelings. So, we can eliminate options B and D. 
5. Next, we tackle the option 'wrong'. This again is not an emotion but a state of moral judgment. Thus, it can also be ruled out.
6. Now, we are left with two options: detachment and sad. The person might feel sad about the situation. But, planning to end the relationship suggested that the person may feel emotionally disconnected or detached. 
7. So, considering the dialogue and focusing on the emotional perspective, the best choice would be detachment. The person is experiencing a sense of emotional separation or 'detachment' from their spouse.
8. Therefore, the right answer is A: detachment.
Answer: A: detachment

Input: What could you use to store a clock? Choices:  A: shelf B: own bedroom C: desk D: wall E: car
Rationales: 1. Analyze each of the possible choices in relation to the question "What could you use to store a clock?"
2. The first option is a shelf. You could certainly place a clock on a shelf. Therefore, it is a valid option.
3. The second option is own bedroom. A bedroom is a place where you could keep a clock, but it's not something you use specifically to store a clock. Therefore, in terms of the logic of this question, it is not a suitable answer.
4. The third option is a desk. You can definitely place a clock on a desk, but the desk itself is not intended to store a clock. Hence, it is not a correct answer in this context.
5. The fourth option is a wall. While some clocks are wall-mounted, the wall itself is not exactly used to store a clock. Hence, it can be eliminated.
6. The last option is a car. Yes, many cars have clocks but again, a car is not used to store a clock. Hence, it is not suitable.
7. After considering all the possible choices, you can conclude that a shelf is the best option. Hence, the answer is A: shelf.
Answer: A: shelf

Input: The person put on lotion, what did they want? Choices:  A: fresh smell B: good credit C: smooth skin D: fresh produce E: headache
Rationales: 1. We begin by understanding the question. From the statement, a person has put on lotion.
2. Next, we identify the purpose of lotion. Lotion is primarily used to moisturize the skin.
3. Now, we match the purpose of lotion to our answer choices. We eliminate the irrelevant choices first. Fresh smell (A) could be a possible secondary purpose of using a scented lotion, but isn't the primary purpose. Good credit (B), fresh produce (D), and headache (E) have no relevance with the act of putting on lotion.
4. This leaves us with the choice C: smooth skin which perfectly corresponds to the main purpose of using lotion.
5. Hence, we conclude that the answer is C: smooth skin.
Answer: C: smooth skin

Input: They burned the record, they were trying to do what to history? Choices:  A: compact disc B: tape C: rewrite D: play music E: erase
Rationales: 1. The question is asking about the action taken and its parallel to some related action in history. 
2. The action stated in the question is burning a record. We need to equate it with a similar action performed concerning history. 
3. The available choices are: compact disc, tape, rewrite, play music, and erase. It's obvious that the choices compact disc, tape, and play music are irrelevant to the context, as these are all related to audio or video recording and not history. 
4. The remaining two options are'rewrite' and 'erase'. While both could potentially be related to how one manipulates history, in this context we see that when a record is burned, its contents are lost forever, which is similar to erasing a part of history. 
5. So, the correct answer is E: erase.
Answer: E: erase

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o7-tcommonsenseqa-s10-rTrue
Loading extension module utils...
Time to load utils op: 0.7048678398132324 seconds
Loading extension module utils...
Time to load utils op: 0.706047534942627 seconds
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 139, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 116, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
Evaluating gsm8k :   0%|                                              | 0/50 [00:05<?, ?it/s]
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 139, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 116, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 139, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 116, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 139, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 116, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/in-context-generalization/transformers/src/transformers/generation/utils.py", line 2568, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 3616766) of binary: /home/ylu130/.conda/envs/distllm/bin/python
Traceback (most recent call last):
  File "/home/ylu130/.conda/envs/distllm/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/run.py", line 761, in main
    run(args)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/ylu130/workspace/in-context-generalization/inference.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-08-13_04:02:38
  host      : ia1.wse.jhu.edu
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 3616767)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-08-13_04:02:38
  host      : ia1.wse.jhu.edu
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 3616768)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-08-13_04:02:38
  host      : ia1.wse.jhu.edu
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 3616769)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-08-13_04:02:38
  host      : ia1.wse.jhu.edu
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3616766)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o8-tcommonsenseqa-s10-rTrue --seed 10 --rationales --num-out-domain 8
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-13 04:02:41,765] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date![nltk_data]   Package punkt is already up-to-date!

[nltk_data]   Package punkt is already up-to-date!
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o8-tcommonsenseqa-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 8
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o8-tcommonsenseqa-s10-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  0%|                                                     | 11/7473 [00:00<01:13, 100.89it/s]  0%|▏                                                    | 22/7473 [00:00<01:13, 101.11it/s]  0%|▏                                                    | 33/7473 [00:00<01:13, 101.07it/s]  1%|▎                                                    | 44/7473 [00:00<01:13, 101.23it/s]  1%|▍                                                    | 55/7473 [00:00<01:13, 101.33it/s]  1%|▍                                                    | 66/7473 [00:00<01:13, 101.26it/s]  1%|▌                                                    | 77/7473 [00:00<01:12, 101.32it/s]  1%|▌                                                    | 88/7473 [00:00<01:12, 101.48it/s]  1%|▋                                                    | 99/7473 [00:00<01:13, 100.39it/s]  1%|▊                                                   | 110/7473 [00:01<01:13, 100.57it/s]  2%|▊                                                   | 121/7473 [00:01<01:12, 100.74it/s]  2%|▉                                                   | 132/7473 [00:01<01:12, 100.89it/s]  2%|▉                                                   | 143/7473 [00:01<01:12, 101.19it/s]  2%|█                                                   | 154/7473 [00:01<01:12, 101.44it/s]  2%|█▏                                                  | 165/7473 [00:01<01:11, 101.52it/s]  2%|█▏                                                  | 176/7473 [00:01<01:11, 101.35it/s]  3%|█▎                                                  | 187/7473 [00:01<01:11, 101.42it/s]  3%|█▍                                                  | 198/7473 [00:01<01:11, 101.54it/s]  3%|█▍                                                  | 209/7473 [00:02<01:12, 100.23it/s]  3%|█▌                                                  | 220/7473 [00:02<01:12, 100.56it/s]  3%|█▌                                                  | 231/7473 [00:02<01:11, 100.82it/s]  3%|█▋                                                  | 242/7473 [00:02<01:09, 103.40it/s]  3%|█▊                                                  | 257/7473 [00:02<01:02, 115.64it/s]  4%|█▉                                                  | 273/7473 [00:02<00:56, 126.82it/s]  4%|██                                                  | 289/7473 [00:02<00:53, 135.30it/s]  4%|██                                                  | 305/7473 [00:02<00:50, 141.13it/s]  4%|██▏                                                 | 321/7473 [00:02<00:49, 145.69it/s]  5%|██▎                                                 | 337/7473 [00:03<00:48, 148.16it/s]  5%|██▍                                                 | 353/7473 [00:03<00:47, 150.06it/s]  5%|██▌                                                 | 369/7473 [00:03<00:46, 151.28it/s]  5%|██▋                                                 | 385/7473 [00:03<00:46, 152.51it/s]  5%|██▊                                                 | 401/7473 [00:03<00:46, 152.66it/s]  6%|██▉                                                 | 417/7473 [00:03<00:46, 153.19it/s]  6%|███                                                 | 433/7473 [00:03<00:45, 153.56it/s]  6%|███                                                 | 449/7473 [00:03<00:45, 153.90it/s]  6%|███▏                                                | 465/7473 [00:03<00:45, 154.18it/s]  6%|███▎                                                | 481/7473 [00:03<00:45, 152.65it/s]  7%|███▍                                                | 497/7473 [00:04<00:45, 153.17it/s]  7%|███▌                                                | 513/7473 [00:04<00:45, 153.60it/s]  7%|███▋                                                | 529/7473 [00:04<00:45, 154.04it/s]  7%|███▊                                                | 545/7473 [00:04<00:44, 154.22it/s]  8%|███▉                                                | 561/7473 [00:04<00:44, 154.46it/s]  8%|████                                                | 577/7473 [00:04<00:44, 154.40it/s]  8%|████▏                                               | 593/7473 [00:04<00:44, 154.24it/s]  8%|████▏                                               | 609/7473 [00:04<00:44, 154.08it/s]  8%|████▎                                               | 625/7473 [00:04<00:44, 153.87it/s]  9%|████▍                                               | 641/7473 [00:04<00:44, 153.81it/s]  9%|████▌                                               | 657/7473 [00:05<00:44, 153.90it/s]  9%|████▋                                               | 673/7473 [00:05<00:44, 154.20it/s]  9%|████▊                                               | 689/7473 [00:05<00:43, 154.24it/s]  9%|████▉                                               | 705/7473 [00:05<00:44, 152.52it/s] 10%|█████                                               | 721/7473 [00:05<00:44, 153.05it/s] 10%|█████▏                                              | 737/7473 [00:05<00:43, 153.31it/s] 10%|█████▏                                              | 753/7473 [00:05<00:43, 153.68it/s] 10%|█████▎                                              | 769/7473 [00:05<00:43, 153.38it/s] 11%|█████▍                                              | 785/7473 [00:05<00:43, 153.44it/s] 11%|█████▌                                              | 801/7473 [00:06<00:43, 153.53it/s] 11%|█████▋                                              | 817/7473 [00:06<00:43, 153.44it/s] 11%|█████▊                                              | 833/7473 [00:06<00:43, 153.36it/s] 11%|█████▉                                              | 849/7473 [00:06<00:43, 153.22it/s] 12%|██████                                              | 865/7473 [00:06<00:43, 153.19it/s] 12%|██████▏                                             | 881/7473 [00:06<00:43, 153.18it/s] 12%|██████▏                                             | 897/7473 [00:06<00:42, 153.08it/s] 12%|██████▎                                             | 913/7473 [00:06<00:42, 153.13it/s] 12%|██████▍                                             | 929/7473 [00:06<00:42, 152.88it/s] 13%|██████▌                                             | 945/7473 [00:06<00:43, 150.87it/s] 13%|██████▋                                             | 961/7473 [00:07<00:42, 151.66it/s] 13%|██████▊                                             | 977/7473 [00:07<00:42, 152.25it/s] 13%|██████▉                                             | 993/7473 [00:07<00:42, 152.56it/s] 14%|██████▉                                            | 1009/7473 [00:07<00:42, 152.41it/s] 14%|██████▉                                            | 1025/7473 [00:07<00:42, 152.84it/s] 14%|███████                                            | 1041/7473 [00:07<00:42, 152.85it/s] 14%|███████▏                                           | 1057/7473 [00:07<00:41, 153.02it/s] 14%|███████▎                                           | 1073/7473 [00:07<00:41, 153.20it/s] 15%|███████▍                                           | 1089/7473 [00:07<00:41, 153.37it/s] 15%|███████▌                                           | 1105/7473 [00:08<00:41, 152.97it/s] 15%|███████▋                                           | 1121/7473 [00:08<00:41, 152.96it/s] 15%|███████▊                                           | 1137/7473 [00:08<00:41, 151.80it/s] 15%|███████▊                                           | 1153/7473 [00:08<00:41, 152.29it/s] 16%|███████▉                                           | 1169/7473 [00:08<00:41, 150.71it/s] 16%|████████                                           | 1185/7473 [00:08<00:41, 151.20it/s] 16%|████████▏                                          | 1201/7473 [00:08<00:41, 151.74it/s] 16%|████████▎                                          | 1217/7473 [00:08<00:41, 151.89it/s] 16%|████████▍                                          | 1233/7473 [00:08<00:41, 151.86it/s] 17%|████████▌                                          | 1249/7473 [00:08<00:40, 152.21it/s] 17%|████████▋                                          | 1265/7473 [00:09<00:40, 152.48it/s] 17%|████████▋                                          | 1281/7473 [00:09<00:40, 152.53it/s] 17%|████████▊                                          | 1297/7473 [00:09<00:40, 152.58it/s] 18%|████████▉                                          | 1313/7473 [00:09<00:40, 152.59it/s] 18%|█████████                                          | 1329/7473 [00:09<00:40, 152.72it/s] 18%|█████████▏                                         | 1345/7473 [00:09<00:40, 152.76it/s] 18%|█████████▎                                         | 1361/7473 [00:09<00:39, 152.86it/s] 18%|█████████▍                                         | 1377/7473 [00:09<00:39, 152.63it/s] 19%|█████████▌                                         | 1393/7473 [00:09<00:40, 150.71it/s] 19%|█████████▌                                         | 1409/7473 [00:10<00:40, 151.32it/s] 19%|█████████▋                                         | 1425/7473 [00:10<00:39, 151.64it/s] 19%|█████████▊                                         | 1441/7473 [00:10<00:39, 151.80it/s] 19%|█████████▉                                         | 1457/7473 [00:10<00:39, 151.96it/s] 20%|██████████                                         | 1473/7473 [00:10<00:39, 152.14it/s] 20%|██████████▏                                        | 1489/7473 [00:10<00:39, 152.17it/s] 20%|██████████▎                                        | 1505/7473 [00:10<00:39, 152.18it/s] 20%|██████████▍                                        | 1521/7473 [00:10<00:39, 152.42it/s] 21%|██████████▍                                        | 1537/7473 [00:10<00:38, 152.43it/s] 21%|██████████▌                                        | 1553/7473 [00:10<00:38, 152.08it/s] 21%|██████████▋                                        | 1569/7473 [00:11<00:38, 151.80it/s] 21%|██████████▊                                        | 1585/7473 [00:11<00:38, 151.68it/s] 21%|██████████▉                                        | 1601/7473 [00:11<00:38, 151.67it/s] 22%|███████████                                        | 1617/7473 [00:11<00:38, 150.33it/s] 22%|███████████▏                                       | 1633/7473 [00:11<00:38, 150.92it/s] 22%|███████████▎                                       | 1649/7473 [00:11<00:38, 150.94it/s] 22%|███████████▎                                       | 1665/7473 [00:11<00:38, 151.30it/s] 22%|███████████▍                                       | 1681/7473 [00:11<00:38, 151.78it/s] 23%|███████████▌                                       | 1697/7473 [00:11<00:37, 152.31it/s] 23%|███████████▋                                       | 1713/7473 [00:12<00:37, 152.72it/s] 23%|███████████▊                                       | 1729/7473 [00:12<00:37, 152.11it/s] 23%|███████████▉                                       | 1745/7473 [00:12<00:37, 152.03it/s] 24%|████████████                                       | 1761/7473 [00:12<00:37, 152.52it/s] 24%|████████████▏                                      | 1777/7473 [00:12<00:37, 152.60it/s] 24%|████████████▏                                      | 1793/7473 [00:12<00:37, 152.71it/s] 24%|████████████▎                                      | 1809/7473 [00:12<00:37, 152.88it/s] 24%|████████████▍                                      | 1825/7473 [00:12<00:37, 152.62it/s] 25%|████████████▌                                      | 1841/7473 [00:12<00:37, 150.99it/s] 25%|████████████▋                                      | 1857/7473 [00:12<00:37, 151.66it/s] 25%|████████████▊                                      | 1873/7473 [00:13<00:36, 152.17it/s] 25%|████████████▉                                      | 1889/7473 [00:13<00:36, 152.52it/s] 25%|█████████████                                      | 1905/7473 [00:13<00:36, 152.24it/s] 26%|█████████████                                      | 1921/7473 [00:13<00:36, 152.46it/s] 26%|█████████████▏                                     | 1937/7473 [00:13<00:36, 151.35it/s] 26%|█████████████▎                                     | 1953/7473 [00:13<00:36, 152.01it/s] 26%|█████████████▍                                     | 1969/7473 [00:13<00:36, 152.47it/s] 27%|█████████████▌                                     | 1985/7473 [00:13<00:35, 152.68it/s] 27%|█████████████▋                                     | 2001/7473 [00:13<00:35, 152.68it/s] 27%|█████████████▊                                     | 2017/7473 [00:14<00:35, 152.83it/s] 27%|█████████████▊                                     | 2033/7473 [00:14<00:35, 153.20it/s] 27%|█████████████▉                                     | 2049/7473 [00:14<00:35, 153.10it/s] 28%|██████████████                                     | 2065/7473 [00:14<00:35, 151.37it/s] 28%|██████████████▏                                    | 2081/7473 [00:14<00:35, 151.60it/s] 28%|██████████████▎                                    | 2097/7473 [00:14<00:35, 152.44it/s] 28%|██████████████▍                                    | 2113/7473 [00:14<00:35, 152.47it/s] 28%|██████████████▌                                    | 2129/7473 [00:14<00:35, 151.84it/s] 29%|██████████████▋                                    | 2145/7473 [00:14<00:34, 152.28it/s] 29%|██████████████▋                                    | 2161/7473 [00:14<00:34, 152.79it/s] 29%|██████████████▊                                    | 2177/7473 [00:15<00:34, 152.89it/s] 29%|██████████████▉                                    | 2193/7473 [00:15<00:34, 152.79it/s] 30%|███████████████                                    | 2209/7473 [00:15<00:34, 153.12it/s] 30%|███████████████▏                                   | 2225/7473 [00:15<00:34, 153.26it/s] 30%|███████████████▎                                   | 2241/7473 [00:15<00:34, 153.01it/s] 30%|███████████████▍                                   | 2257/7473 [00:15<00:34, 152.92it/s] 30%|███████████████▌                                   | 2273/7473 [00:15<00:34, 152.87it/s] 31%|███████████████▌                                   | 2289/7473 [00:15<00:33, 152.89it/s] 31%|███████████████▋                                   | 2305/7473 [00:15<00:34, 151.93it/s] 31%|███████████████▊                                   | 2321/7473 [00:16<00:33, 152.46it/s] 31%|███████████████▉                                   | 2337/7473 [00:16<00:33, 152.85it/s] 31%|████████████████                                   | 2353/7473 [00:16<00:33, 152.75it/s] 32%|████████████████▏                                  | 2369/7473 [00:16<00:33, 152.73it/s] 32%|████████████████▎                                  | 2385/7473 [00:16<00:33, 153.03it/s] 32%|████████████████▍                                  | 2401/7473 [00:16<00:33, 152.86it/s] 32%|████████████████▍                                  | 2417/7473 [00:16<00:33, 152.97it/s] 33%|████████████████▌                                  | 2433/7473 [00:16<00:32, 153.24it/s] 33%|████████████████▋                                  | 2449/7473 [00:16<00:32, 153.34it/s] 33%|████████████████▊                                  | 2465/7473 [00:16<00:32, 153.11it/s] 33%|████████████████▉                                  | 2481/7473 [00:17<00:32, 153.22it/s] 33%|█████████████████                                  | 2497/7473 [00:17<00:32, 153.12it/s] 34%|█████████████████▏                                 | 2513/7473 [00:17<00:32, 152.80it/s] 34%|█████████████████▎                                 | 2529/7473 [00:17<00:38, 128.96it/s] 34%|█████████████████▎                                 | 2545/7473 [00:17<00:36, 135.30it/s] 34%|█████████████████▍                                 | 2561/7473 [00:17<00:35, 140.32it/s] 34%|█████████████████▌                                 | 2577/7473 [00:17<00:33, 144.02it/s] 35%|█████████████████▋                                 | 2593/7473 [00:17<00:33, 146.59it/s] 35%|█████████████████▊                                 | 2609/7473 [00:17<00:32, 148.69it/s] 35%|█████████████████▉                                 | 2625/7473 [00:18<00:32, 150.02it/s] 35%|██████████████████                                 | 2641/7473 [00:18<00:32, 150.84it/s] 36%|██████████████████▏                                | 2657/7473 [00:18<00:31, 151.59it/s] 36%|██████████████████▏                                | 2673/7473 [00:18<00:31, 152.23it/s] 36%|██████████████████▎                                | 2689/7473 [00:18<00:31, 152.60it/s] 36%|██████████████████▍                                | 2705/7473 [00:18<00:31, 152.62it/s] 36%|██████████████████▌                                | 2721/7473 [00:18<00:31, 152.82it/s] 37%|██████████████████▋                                | 2737/7473 [00:18<00:31, 152.70it/s] 37%|██████████████████▊                                | 2753/7473 [00:18<00:31, 151.55it/s] 37%|██████████████████▉                                | 2769/7473 [00:18<00:30, 151.98it/s] 37%|███████████████████                                | 2785/7473 [00:19<00:30, 152.52it/s] 37%|███████████████████                                | 2801/7473 [00:19<00:30, 152.77it/s] 38%|███████████████████▏                               | 2817/7473 [00:19<00:30, 152.88it/s] 38%|███████████████████▎                               | 2833/7473 [00:19<00:30, 153.14it/s] 38%|███████████████████▍                               | 2849/7473 [00:19<00:30, 153.05it/s] 38%|███████████████████▌                               | 2865/7473 [00:19<00:30, 152.95it/s] 39%|███████████████████▋                               | 2881/7473 [00:19<00:30, 152.83it/s] 39%|███████████████████▊                               | 2897/7473 [00:19<00:29, 152.86it/s] 39%|███████████████████▉                               | 2913/7473 [00:19<00:29, 152.88it/s] 39%|███████████████████▉                               | 2929/7473 [00:20<00:29, 153.27it/s] 39%|████████████████████                               | 2945/7473 [00:20<00:29, 153.36it/s] 40%|████████████████████▏                              | 2961/7473 [00:20<00:29, 153.46it/s] 40%|████████████████████▎                              | 2977/7473 [00:20<00:29, 151.75it/s] 40%|████████████████████▍                              | 2993/7473 [00:20<00:29, 152.30it/s] 40%|████████████████████▌                              | 3009/7473 [00:20<00:29, 152.45it/s] 40%|████████████████████▋                              | 3025/7473 [00:20<00:29, 152.33it/s] 41%|████████████████████▊                              | 3041/7473 [00:20<00:29, 152.24it/s] 41%|████████████████████▊                              | 3057/7473 [00:20<00:28, 152.59it/s] 41%|████████████████████▉                              | 3073/7473 [00:20<00:28, 152.72it/s] 41%|█████████████████████                              | 3089/7473 [00:21<00:28, 152.75it/s] 42%|█████████████████████▏                             | 3105/7473 [00:21<00:28, 152.66it/s] 42%|█████████████████████▎                             | 3121/7473 [00:21<00:28, 152.04it/s] 42%|█████████████████████▍                             | 3137/7473 [00:21<00:28, 152.00it/s] 42%|█████████████████████▌                             | 3153/7473 [00:21<00:28, 152.23it/s] 42%|█████████████████████▋                             | 3169/7473 [00:21<00:28, 152.14it/s] 43%|█████████████████████▋                             | 3185/7473 [00:21<00:28, 152.29it/s] 43%|█████████████████████▊                             | 3201/7473 [00:21<00:28, 150.93it/s] 43%|█████████████████████▉                             | 3217/7473 [00:21<00:28, 151.55it/s] 43%|██████████████████████                             | 3233/7473 [00:22<00:27, 151.86it/s] 43%|██████████████████████▏                            | 3249/7473 [00:22<00:27, 152.25it/s] 44%|██████████████████████▎                            | 3265/7473 [00:22<00:27, 152.22it/s] 44%|██████████████████████▍                            | 3281/7473 [00:22<00:27, 152.43it/s] 44%|██████████████████████▌                            | 3297/7473 [00:22<00:27, 152.55it/s] 44%|██████████████████████▌                            | 3313/7473 [00:22<00:27, 152.66it/s] 45%|██████████████████████▋                            | 3329/7473 [00:22<00:27, 152.52it/s] 45%|██████████████████████▊                            | 3345/7473 [00:22<00:27, 152.24it/s] 45%|██████████████████████▉                            | 3361/7473 [00:22<00:26, 152.39it/s] 45%|███████████████████████                            | 3377/7473 [00:22<00:26, 152.37it/s] 45%|███████████████████████▏                           | 3393/7473 [00:23<00:26, 152.21it/s] 46%|███████████████████████▎                           | 3409/7473 [00:23<00:26, 152.42it/s] 46%|███████████████████████▎                           | 3425/7473 [00:23<00:26, 151.79it/s] 46%|███████████████████████▍                           | 3441/7473 [00:23<00:26, 150.41it/s] 46%|███████████████████████▌                           | 3457/7473 [00:23<00:26, 150.62it/s] 46%|███████████████████████▋                           | 3473/7473 [00:23<00:26, 151.22it/s] 47%|███████████████████████▊                           | 3489/7473 [00:23<00:26, 151.85it/s] 47%|███████████████████████▉                           | 3505/7473 [00:23<00:26, 152.20it/s] 47%|████████████████████████                           | 3521/7473 [00:23<00:25, 152.05it/s] 47%|████████████████████████▏                          | 3537/7473 [00:24<00:25, 152.31it/s] 48%|████████████████████████▏                          | 3553/7473 [00:24<00:26, 146.30it/s] 48%|████████████████████████▎                          | 3569/7473 [00:24<00:26, 148.35it/s] 48%|████████████████████████▍                          | 3585/7473 [00:24<00:25, 149.67it/s] 48%|████████████████████████▌                          | 3601/7473 [00:24<00:25, 150.73it/s] 48%|████████████████████████▋                          | 3617/7473 [00:24<00:25, 151.24it/s] 49%|████████████████████████▊                          | 3633/7473 [00:24<00:26, 145.91it/s] 49%|████████████████████████▉                          | 3649/7473 [00:24<00:25, 147.35it/s] 49%|█████████████████████████                          | 3664/7473 [00:24<00:25, 147.55it/s] 49%|█████████████████████████                          | 3679/7473 [00:25<00:25, 148.07it/s] 49%|█████████████████████████▏                         | 3695/7473 [00:25<00:25, 149.38it/s] 50%|█████████████████████████▎                         | 3711/7473 [00:25<00:25, 150.26it/s] 50%|█████████████████████████▍                         | 3727/7473 [00:25<00:24, 151.05it/s] 50%|█████████████████████████▌                         | 3743/7473 [00:25<00:24, 151.40it/s] 50%|█████████████████████████▋                         | 3759/7473 [00:25<00:24, 151.69it/s] 51%|█████████████████████████▊                         | 3775/7473 [00:25<00:24, 152.05it/s] 51%|█████████████████████████▊                         | 3791/7473 [00:25<00:24, 152.02it/s] 51%|█████████████████████████▉                         | 3807/7473 [00:25<00:24, 152.25it/s] 51%|██████████████████████████                         | 3823/7473 [00:25<00:23, 152.29it/s] 51%|██████████████████████████▏                        | 3839/7473 [00:26<00:23, 152.29it/s] 52%|██████████████████████████▎                        | 3855/7473 [00:26<00:23, 152.25it/s] 52%|██████████████████████████▍                        | 3871/7473 [00:26<00:23, 152.45it/s] 52%|██████████████████████████▌                        | 3887/7473 [00:26<00:23, 150.72it/s] 52%|██████████████████████████▋                        | 3903/7473 [00:26<00:23, 151.30it/s] 52%|██████████████████████████▋                        | 3919/7473 [00:26<00:23, 151.65it/s] 53%|██████████████████████████▊                        | 3935/7473 [00:26<00:23, 150.89it/s] 53%|██████████████████████████▉                        | 3951/7473 [00:26<00:23, 150.36it/s] 53%|███████████████████████████                        | 3967/7473 [00:26<00:23, 151.13it/s] 53%|███████████████████████████▏                       | 3983/7473 [00:27<00:23, 151.32it/s] 54%|███████████████████████████▎                       | 3999/7473 [00:27<00:22, 151.86it/s] 54%|███████████████████████████▍                       | 4015/7473 [00:27<00:22, 152.29it/s] 54%|███████████████████████████▌                       | 4031/7473 [00:27<00:22, 152.46it/s] 54%|███████████████████████████▌                       | 4047/7473 [00:27<00:22, 152.74it/s] 54%|███████████████████████████▋                       | 4063/7473 [00:27<00:22, 152.82it/s] 55%|███████████████████████████▊                       | 4079/7473 [00:27<00:22, 152.46it/s] 55%|███████████████████████████▉                       | 4095/7473 [00:27<00:22, 152.52it/s] 55%|████████████████████████████                       | 4111/7473 [00:27<00:22, 150.36it/s] 55%|████████████████████████████▏                      | 4127/7473 [00:27<00:22, 150.63it/s] 55%|████████████████████████████▎                      | 4143/7473 [00:28<00:22, 150.93it/s] 56%|████████████████████████████▍                      | 4159/7473 [00:28<00:21, 151.40it/s] 56%|████████████████████████████▍                      | 4175/7473 [00:28<00:21, 151.79it/s] 56%|████████████████████████████▌                      | 4191/7473 [00:28<00:21, 150.94it/s] 56%|████████████████████████████▋                      | 4207/7473 [00:28<00:21, 151.25it/s] 57%|████████████████████████████▊                      | 4223/7473 [00:28<00:21, 151.67it/s] 57%|████████████████████████████▉                      | 4239/7473 [00:28<00:21, 151.77it/s] 57%|█████████████████████████████                      | 4255/7473 [00:28<00:21, 151.78it/s] 57%|█████████████████████████████▏                     | 4271/7473 [00:28<00:21, 151.85it/s] 57%|█████████████████████████████▎                     | 4287/7473 [00:29<00:20, 151.97it/s] 58%|█████████████████████████████▎                     | 4303/7473 [00:29<00:20, 151.99it/s] 58%|█████████████████████████████▍                     | 4319/7473 [00:29<00:20, 152.24it/s] 58%|█████████████████████████████▌                     | 4335/7473 [00:29<00:20, 150.91it/s] 58%|█████████████████████████████▋                     | 4351/7473 [00:29<00:20, 151.04it/s] 58%|█████████████████████████████▊                     | 4367/7473 [00:29<00:20, 151.46it/s] 59%|█████████████████████████████▉                     | 4383/7473 [00:29<00:20, 151.55it/s] 59%|██████████████████████████████                     | 4399/7473 [00:29<00:20, 151.99it/s] 59%|██████████████████████████████▏                    | 4415/7473 [00:29<00:20, 152.04it/s] 59%|██████████████████████████████▏                    | 4431/7473 [00:29<00:20, 151.90it/s] 60%|██████████████████████████████▎                    | 4447/7473 [00:30<00:20, 150.85it/s] 60%|██████████████████████████████▍                    | 4463/7473 [00:30<00:19, 150.92it/s] 60%|██████████████████████████████▌                    | 4479/7473 [00:30<00:19, 151.41it/s] 60%|██████████████████████████████▋                    | 4495/7473 [00:30<00:19, 151.56it/s] 60%|██████████████████████████████▊                    | 4511/7473 [00:30<00:19, 151.63it/s] 61%|██████████████████████████████▉                    | 4527/7473 [00:30<00:19, 151.71it/s] 61%|███████████████████████████████                    | 4543/7473 [00:30<00:19, 152.25it/s] 61%|███████████████████████████████                    | 4559/7473 [00:30<00:19, 152.50it/s] 61%|███████████████████████████████▏                   | 4575/7473 [00:30<00:19, 150.42it/s] 61%|███████████████████████████████▎                   | 4591/7473 [00:31<00:19, 150.75it/s] 62%|███████████████████████████████▍                   | 4607/7473 [00:31<00:18, 151.34it/s] 62%|███████████████████████████████▌                   | 4623/7473 [00:31<00:18, 151.67it/s] 62%|███████████████████████████████▋                   | 4639/7473 [00:31<00:18, 151.43it/s] 62%|███████████████████████████████▊                   | 4655/7473 [00:31<00:18, 151.76it/s] 63%|███████████████████████████████▉                   | 4671/7473 [00:31<00:18, 151.78it/s] 63%|███████████████████████████████▉                   | 4687/7473 [00:31<00:18, 152.12it/s] 63%|████████████████████████████████                   | 4703/7473 [00:31<00:18, 151.00it/s] 63%|████████████████████████████████▏                  | 4719/7473 [00:31<00:18, 151.23it/s] 63%|████████████████████████████████▎                  | 4735/7473 [00:31<00:18, 151.56it/s] 64%|████████████████████████████████▍                  | 4751/7473 [00:32<00:17, 151.87it/s] 64%|████████████████████████████████▌                  | 4767/7473 [00:32<00:17, 152.23it/s] 64%|████████████████████████████████▋                  | 4783/7473 [00:32<00:17, 152.37it/s] 64%|████████████████████████████████▊                  | 4799/7473 [00:32<00:17, 150.70it/s] 64%|████████████████████████████████▊                  | 4815/7473 [00:32<00:17, 151.17it/s] 65%|████████████████████████████████▉                  | 4831/7473 [00:32<00:17, 151.55it/s] 65%|█████████████████████████████████                  | 4847/7473 [00:32<00:17, 151.81it/s] 65%|█████████████████████████████████▏                 | 4863/7473 [00:32<00:17, 151.97it/s] 65%|█████████████████████████████████▎                 | 4879/7473 [00:32<00:17, 151.95it/s] 66%|█████████████████████████████████▍                 | 4895/7473 [00:33<00:16, 152.13it/s] 66%|█████████████████████████████████▌                 | 4911/7473 [00:33<00:16, 152.25it/s] 66%|█████████████████████████████████▌                 | 4927/7473 [00:33<00:16, 152.03it/s] 66%|█████████████████████████████████▋                 | 4943/7473 [00:33<00:16, 152.02it/s] 66%|█████████████████████████████████▊                 | 4959/7473 [00:33<00:16, 151.60it/s] 67%|█████████████████████████████████▉                 | 4975/7473 [00:33<00:16, 151.50it/s] 67%|██████████████████████████████████                 | 4991/7473 [00:33<00:16, 151.68it/s] 67%|██████████████████████████████████▏                | 5007/7473 [00:33<00:16, 152.16it/s] 67%|██████████████████████████████████▎                | 5023/7473 [00:33<00:16, 150.84it/s] 67%|██████████████████████████████████▍                | 5039/7473 [00:33<00:16, 151.08it/s] 68%|██████████████████████████████████▍                | 5055/7473 [00:34<00:15, 151.52it/s] 68%|██████████████████████████████████▌                | 5071/7473 [00:34<00:15, 151.74it/s] 68%|██████████████████████████████████▋                | 5087/7473 [00:34<00:15, 151.94it/s] 68%|██████████████████████████████████▊                | 5103/7473 [00:34<00:15, 152.18it/s] 68%|██████████████████████████████████▉                | 5119/7473 [00:34<00:15, 152.16it/s] 69%|███████████████████████████████████                | 5135/7473 [00:34<00:15, 152.41it/s] 69%|███████████████████████████████████▏               | 5151/7473 [00:34<00:15, 152.28it/s] 69%|███████████████████████████████████▎               | 5167/7473 [00:34<00:15, 152.52it/s] 69%|███████████████████████████████████▎               | 5183/7473 [00:34<00:15, 152.57it/s] 70%|███████████████████████████████████▍               | 5199/7473 [00:35<00:14, 151.83it/s] 70%|███████████████████████████████████▌               | 5215/7473 [00:35<00:14, 152.05it/s] 70%|███████████████████████████████████▋               | 5231/7473 [00:35<00:14, 152.16it/s] 70%|███████████████████████████████████▊               | 5247/7473 [00:35<00:17, 127.76it/s] 70%|███████████████████████████████████▉               | 5262/7473 [00:35<00:16, 133.17it/s] 71%|████████████████████████████████████               | 5278/7473 [00:35<00:15, 138.37it/s] 71%|████████████████████████████████████▏              | 5294/7473 [00:35<00:15, 142.15it/s] 71%|████████████████████████████████████▏              | 5310/7473 [00:35<00:14, 145.10it/s] 71%|████████████████████████████████████▎              | 5326/7473 [00:35<00:14, 146.93it/s] 71%|████████████████████████████████████▍              | 5342/7473 [00:36<00:14, 147.92it/s] 72%|████████████████████████████████████▌              | 5358/7473 [00:36<00:14, 149.17it/s] 72%|████████████████████████████████████▋              | 5374/7473 [00:36<00:13, 150.01it/s] 72%|████████████████████████████████████▊              | 5390/7473 [00:36<00:13, 150.79it/s] 72%|████████████████████████████████████▉              | 5406/7473 [00:36<00:13, 151.13it/s] 73%|█████████████████████████████████████              | 5422/7473 [00:36<00:13, 151.47it/s] 73%|█████████████████████████████████████              | 5438/7473 [00:36<00:13, 151.40it/s] 73%|█████████████████████████████████████▏             | 5454/7473 [00:36<00:13, 151.34it/s] 73%|██████████████████████████████████████              | 5470/7473 [00:37<00:20, 96.52it/s] 73%|█████████████████████████████████████▍             | 5486/7473 [00:37<00:18, 108.11it/s] 74%|█████████████████████████████████████▌             | 5502/7473 [00:37<00:16, 118.12it/s] 74%|█████████████████████████████████████▋             | 5518/7473 [00:37<00:15, 126.67it/s] 74%|█████████████████████████████████████▊             | 5534/7473 [00:37<00:14, 133.14it/s] 74%|█████████████████████████████████████▉             | 5550/7473 [00:37<00:13, 137.88it/s] 74%|█████████████████████████████████████▉             | 5566/7473 [00:37<00:13, 141.83it/s] 75%|██████████████████████████████████████             | 5582/7473 [00:37<00:13, 144.68it/s] 75%|██████████████████████████████████████▏            | 5598/7473 [00:37<00:12, 146.69it/s] 75%|██████████████████████████████████████▎            | 5614/7473 [00:38<00:12, 148.35it/s] 75%|██████████████████████████████████████▍            | 5630/7473 [00:38<00:12, 149.29it/s] 76%|██████████████████████████████████████▌            | 5646/7473 [00:38<00:12, 150.24it/s] 76%|██████████████████████████████████████▋            | 5662/7473 [00:38<00:12, 150.80it/s] 76%|██████████████████████████████████████▋            | 5678/7473 [00:38<00:11, 149.61it/s] 76%|██████████████████████████████████████▊            | 5694/7473 [00:38<00:11, 150.43it/s] 76%|██████████████████████████████████████▉            | 5710/7473 [00:38<00:11, 150.86it/s] 77%|███████████████████████████████████████            | 5726/7473 [00:38<00:11, 150.93it/s] 77%|███████████████████████████████████████▏           | 5742/7473 [00:38<00:11, 151.22it/s] 77%|███████████████████████████████████████▎           | 5758/7473 [00:38<00:11, 151.52it/s] 77%|███████████████████████████████████████▍           | 5774/7473 [00:39<00:11, 151.77it/s] 77%|███████████████████████████████████████▌           | 5790/7473 [00:39<00:11, 151.72it/s] 78%|███████████████████████████████████████▌           | 5806/7473 [00:39<00:10, 151.84it/s] 78%|███████████████████████████████████████▋           | 5822/7473 [00:39<00:10, 151.68it/s] 78%|███████████████████████████████████████▊           | 5838/7473 [00:39<00:10, 151.68it/s] 78%|███████████████████████████████████████▉           | 5854/7473 [00:39<00:10, 151.71it/s] 79%|████████████████████████████████████████           | 5870/7473 [00:39<00:10, 151.68it/s] 79%|████████████████████████████████████████▏          | 5886/7473 [00:39<00:10, 151.73it/s] 79%|████████████████████████████████████████▎          | 5902/7473 [00:39<00:10, 150.31it/s] 79%|████████████████████████████████████████▍          | 5918/7473 [00:40<00:10, 150.74it/s] 79%|████████████████████████████████████████▍          | 5934/7473 [00:40<00:10, 150.92it/s] 80%|████████████████████████████████████████▌          | 5950/7473 [00:40<00:10, 150.96it/s] 80%|████████████████████████████████████████▋          | 5966/7473 [00:40<00:09, 150.83it/s] 80%|████████████████████████████████████████▊          | 5982/7473 [00:40<00:09, 151.08it/s] 80%|████████████████████████████████████████▉          | 5998/7473 [00:40<00:09, 151.19it/s] 80%|█████████████████████████████████████████          | 6014/7473 [00:40<00:09, 151.41it/s] 81%|█████████████████████████████████████████▏         | 6030/7473 [00:40<00:09, 151.86it/s] 81%|█████████████████████████████████████████▎         | 6046/7473 [00:40<00:09, 152.34it/s] 81%|█████████████████████████████████████████▎         | 6062/7473 [00:40<00:09, 152.81it/s] 81%|█████████████████████████████████████████▍         | 6078/7473 [00:41<00:09, 153.02it/s] 82%|█████████████████████████████████████████▌         | 6094/7473 [00:41<00:09, 152.94it/s] 82%|█████████████████████████████████████████▋         | 6110/7473 [00:41<00:08, 153.07it/s] 82%|█████████████████████████████████████████▊         | 6126/7473 [00:41<00:08, 153.06it/s] 82%|█████████████████████████████████████████▉         | 6142/7473 [00:41<00:08, 151.70it/s] 82%|██████████████████████████████████████████         | 6158/7473 [00:41<00:08, 151.96it/s] 83%|██████████████████████████████████████████▏        | 6174/7473 [00:41<00:08, 152.28it/s] 83%|██████████████████████████████████████████▏        | 6190/7473 [00:41<00:08, 152.54it/s] 83%|██████████████████████████████████████████▎        | 6206/7473 [00:41<00:08, 152.88it/s] 83%|██████████████████████████████████████████▍        | 6222/7473 [00:42<00:08, 152.58it/s] 83%|██████████████████████████████████████████▌        | 6238/7473 [00:42<00:08, 152.52it/s] 84%|██████████████████████████████████████████▋        | 6254/7473 [00:42<00:07, 152.82it/s] 84%|██████████████████████████████████████████▊        | 6270/7473 [00:42<00:07, 152.85it/s] 84%|██████████████████████████████████████████▉        | 6286/7473 [00:42<00:08, 147.26it/s] 84%|███████████████████████████████████████████        | 6302/7473 [00:42<00:07, 148.93it/s] 85%|███████████████████████████████████████████        | 6318/7473 [00:42<00:07, 150.26it/s] 85%|███████████████████████████████████████████▏       | 6334/7473 [00:42<00:07, 151.20it/s] 85%|███████████████████████████████████████████▎       | 6350/7473 [00:42<00:07, 151.75it/s] 85%|███████████████████████████████████████████▍       | 6366/7473 [00:42<00:07, 150.48it/s] 85%|███████████████████████████████████████████▌       | 6382/7473 [00:43<00:07, 150.93it/s] 86%|███████████████████████████████████████████▋       | 6398/7473 [00:43<00:07, 151.41it/s] 86%|███████████████████████████████████████████▊       | 6414/7473 [00:43<00:06, 151.94it/s] 86%|███████████████████████████████████████████▉       | 6430/7473 [00:43<00:06, 152.22it/s] 86%|███████████████████████████████████████████▉       | 6446/7473 [00:43<00:06, 152.55it/s] 86%|████████████████████████████████████████████       | 6462/7473 [00:43<00:06, 152.45it/s] 87%|████████████████████████████████████████████▏      | 6478/7473 [00:43<00:06, 152.70it/s] 87%|████████████████████████████████████████████▎      | 6494/7473 [00:43<00:06, 153.00it/s] 87%|████████████████████████████████████████████▍      | 6510/7473 [00:43<00:06, 153.08it/s] 87%|████████████████████████████████████████████▌      | 6526/7473 [00:44<00:06, 152.90it/s] 88%|████████████████████████████████████████████▋      | 6542/7473 [00:44<00:06, 152.99it/s] 88%|████████████████████████████████████████████▊      | 6558/7473 [00:44<00:05, 153.11it/s] 88%|████████████████████████████████████████████▊      | 6574/7473 [00:44<00:05, 153.37it/s] 88%|████████████████████████████████████████████▉      | 6590/7473 [00:44<00:05, 152.15it/s] 88%|█████████████████████████████████████████████      | 6606/7473 [00:44<00:05, 152.59it/s] 89%|█████████████████████████████████████████████▏     | 6622/7473 [00:44<00:05, 152.82it/s] 89%|█████████████████████████████████████████████▎     | 6638/7473 [00:44<00:05, 152.69it/s] 89%|█████████████████████████████████████████████▍     | 6654/7473 [00:44<00:05, 152.94it/s] 89%|█████████████████████████████████████████████▌     | 6670/7473 [00:44<00:05, 152.79it/s] 89%|█████████████████████████████████████████████▋     | 6686/7473 [00:45<00:05, 152.74it/s] 90%|█████████████████████████████████████████████▋     | 6702/7473 [00:45<00:05, 152.92it/s] 90%|█████████████████████████████████████████████▊     | 6718/7473 [00:45<00:04, 152.91it/s] 90%|█████████████████████████████████████████████▉     | 6734/7473 [00:45<00:04, 153.40it/s] 90%|██████████████████████████████████████████████     | 6750/7473 [00:45<00:04, 153.07it/s] 91%|██████████████████████████████████████████████▏    | 6766/7473 [00:45<00:04, 152.89it/s] 91%|██████████████████████████████████████████████▎    | 6782/7473 [00:45<00:04, 152.80it/s] 91%|██████████████████████████████████████████████▍    | 6798/7473 [00:45<00:04, 152.89it/s] 91%|██████████████████████████████████████████████▌    | 6814/7473 [00:45<00:04, 151.53it/s] 91%|██████████████████████████████████████████████▌    | 6830/7473 [00:46<00:04, 151.89it/s] 92%|██████████████████████████████████████████████▋    | 6846/7473 [00:46<00:04, 152.28it/s] 92%|██████████████████████████████████████████████▊    | 6862/7473 [00:46<00:04, 152.32it/s] 92%|██████████████████████████████████████████████▉    | 6878/7473 [00:46<00:03, 152.84it/s] 92%|███████████████████████████████████████████████    | 6894/7473 [00:46<00:03, 152.88it/s] 92%|███████████████████████████████████████████████▏   | 6910/7473 [00:46<00:03, 153.30it/s] 93%|███████████████████████████████████████████████▎   | 6926/7473 [00:46<00:03, 153.11it/s] 93%|███████████████████████████████████████████████▍   | 6942/7473 [00:46<00:03, 153.23it/s] 93%|███████████████████████████████████████████████▍   | 6958/7473 [00:46<00:03, 153.10it/s] 93%|███████████████████████████████████████████████▌   | 6974/7473 [00:46<00:03, 153.04it/s] 94%|███████████████████████████████████████████████▋   | 6990/7473 [00:47<00:03, 152.74it/s] 94%|███████████████████████████████████████████████▊   | 7006/7473 [00:47<00:03, 152.80it/s] 94%|███████████████████████████████████████████████▉   | 7022/7473 [00:47<00:02, 152.81it/s] 94%|████████████████████████████████████████████████   | 7038/7473 [00:47<00:02, 151.26it/s] 94%|████████████████████████████████████████████████▏  | 7054/7473 [00:47<00:02, 151.86it/s] 95%|████████████████████████████████████████████████▏  | 7070/7473 [00:47<00:02, 152.05it/s] 95%|████████████████████████████████████████████████▎  | 7086/7473 [00:47<00:02, 152.36it/s] 95%|████████████████████████████████████████████████▍  | 7102/7473 [00:47<00:02, 152.75it/s] 95%|████████████████████████████████████████████████▌  | 7118/7473 [00:47<00:02, 152.63it/s] 95%|████████████████████████████████████████████████▋  | 7134/7473 [00:48<00:02, 152.39it/s] 96%|████████████████████████████████████████████████▊  | 7150/7473 [00:48<00:02, 152.69it/s] 96%|████████████████████████████████████████████████▉  | 7166/7473 [00:48<00:02, 152.72it/s] 96%|█████████████████████████████████████████████████  | 7182/7473 [00:48<00:01, 152.78it/s] 96%|█████████████████████████████████████████████████  | 7198/7473 [00:48<00:01, 152.86it/s] 97%|█████████████████████████████████████████████████▏ | 7214/7473 [00:48<00:01, 152.84it/s] 97%|█████████████████████████████████████████████████▎ | 7230/7473 [00:48<00:01, 152.80it/s] 97%|█████████████████████████████████████████████████▍ | 7246/7473 [00:48<00:01, 153.07it/s] 97%|█████████████████████████████████████████████████▌ | 7262/7473 [00:48<00:01, 151.65it/s] 97%|█████████████████████████████████████████████████▋ | 7278/7473 [00:48<00:01, 151.47it/s] 98%|█████████████████████████████████████████████████▊ | 7294/7473 [00:49<00:01, 152.05it/s] 98%|█████████████████████████████████████████████████▉ | 7310/7473 [00:49<00:01, 152.24it/s] 98%|█████████████████████████████████████████████████▉ | 7326/7473 [00:49<00:00, 152.30it/s] 98%|██████████████████████████████████████████████████ | 7342/7473 [00:49<00:00, 152.24it/s] 98%|██████████████████████████████████████████████████▏| 7358/7473 [00:49<00:00, 152.45it/s] 99%|██████████████████████████████████████████████████▎| 7374/7473 [00:49<00:00, 152.35it/s] 99%|██████████████████████████████████████████████████▍| 7390/7473 [00:49<00:00, 152.45it/s] 99%|██████████████████████████████████████████████████▌| 7406/7473 [00:49<00:00, 152.13it/s] 99%|██████████████████████████████████████████████████▋| 7422/7473 [00:49<00:00, 152.08it/s]100%|██████████████████████████████████████████████████▊| 7438/7473 [00:50<00:00, 151.85it/s]100%|██████████████████████████████████████████████████▊| 7454/7473 [00:50<00:00, 151.97it/s]100%|██████████████████████████████████████████████████▉| 7470/7473 [00:50<00:00, 152.05it/s]100%|███████████████████████████████████████████████████| 7473/7473 [00:50<00:00, 148.74it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.15s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.28s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.37s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.53s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.18s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.15s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.68s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.41s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.63s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.78s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.52s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.70s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.75s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.94s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:16<00:00,  5.35s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:16<00:00,  5.41s/it]
[2023-08-13 04:04:26,266] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-13 04:04:38,876] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-13 04:04:38,877] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-13 04:04:38,878] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-13 04:04:38,878] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-13 04:04:38,878] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-13 04:04:38,878] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-13 04:04:38,878] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-13 04:04:38,878] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-13 04:04:38,878] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-13 04:04:38,878] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-13 04:04:38,878] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-13 04:04:38,878] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f8a72c6afa0>
[2023-08-13 04:04:38,878] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-13 04:04:38,878] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-13 04:04:38,878] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-13 04:04:38,878] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f8a72c60700>
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-13 04:04:38,879] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-13 04:04:38,880] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-13 04:04:38,880] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-13 04:04:38,880] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.7471280097961426 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Fabric is cut to order at what type of seller? Choices:  A: curtains B: tailor shop C: clothing store D: sewing room E: hardware store
Rationales: 1. The question asks where fabric is cut to order.
2. "Cut to order" implies that the fabric is cut according to specific measurements or requirements of the customer.
3. Curtains (option A) commonly come in standard sizes and are often pre-made, thus they don't usually involve custom cutting to order.
4. Clothing stores (option C) typically sell ready-made clothes and don't usually offer custom tailoring or cutting services.
5. Sewing room (option D) might involve cutting fabric, but it's not a type of seller.
6. Hardware store (option E) sell tools and materials for home improvement projects but not typically fabric.
7. Therefore, the most plausible option is the Tailor shop (option B) where custom cutting to specific measurements is usually done for suits, dresses or other garments. Tailors offer professional service involving measurements and custom cuts, making option B the correct answer.
Answer: B: tailor shop

Input: Where are you if your reading magazines while waiting for a vehicle on rails? Choices:  A: vegetables B: market C: doctor D: train station E: bookstore
Rationales: 1. The question is asking you to identify your location based on the information that you're waiting for a'vehicle on rails'.
2. 'Vehicle on rails' commonly refers to a train or a tram.
3. Therefore, it is important to recognize the common places where you would wait for such vehicles.
4. Options A: Vegetables and B: market are not usually places where rails vehicles stop for passengers.
5. Option C: doctor is irrelevant as doctors do not typically operate in the vicinity of rail vehicles.
6. While you might read magazines at a bookstore, option E: bookstore, it doesn't meet the criterion of waiting for a vehicle on rails.
7. Contrastingly, option D: train station is a predominant place where people often wait for trains.
8. Therefore, based on the information provided, the answer is D: train station.
Answer: D: train station

Input: What would need oil to be used? Choices:  A: ground B: human  body C: repair shop D: combustion engines E: service station
Rationales: 1. The question asks about where oil would be necessary for functionality.
2. Starting with option A: "ground". Ground doesn't need oil to function, it can naturally sustain plant life and it works along with ecological processes without external additives. So, this option is incorrect.
3. Then, looking at option B: "human body". In the context of needing oil, the human body does not need literal oil. It needs oils in a dietary sense (like fats and lipids), but not in the sense of mechanical oil.
4. Next, we consider option C: "repair shop". While a repair shop might use oil as part of its operations to fix or maintain machinery or vehicles, the shop itself does not need oil to exist.
5. Option D: "combustion engines", on the other hand, do require oil to function. This oil helps to lubricate the engine, reduce friction between the moving parts and also to clean, cool and protect the engine components. Therefore, combustion engines directly need oil to work.
6. Finally, option E: "service station". Similar to a repair shop, a service station might use oil as part of its service provision, but it does not inherently require oil for its existence.
7. After going through all the choices, we can see that "combustion engines" is the only option which directly requires oil to function properly. Therefore, choice D: "combustion engines" is the correct answer.
Answer: D: combustion engines

Input: What is person probably feeling that plans on stopping being married to their spouse? Choices:  A: detachment B: bankruptcy C: sad D: fights E: wrong
Rationales: 1. Start by considering the prompt: a person is planning to stop being married to their spouse. This directly implies that there will be a separation or a divorce.
2. Given this, assess the possible emotions such a person might be feeling. Divorces or separations involve a feeling of becoming distant or less emotionally invested in another person — a detachment.
3. Therefore, consider each answer choice one by one. 
    A: Detachment is the most directly related feeling, it's plausible as it matches the context of distance or less emotional investment.
    B: Bankruptcy is a financial situation and has no direct correlation to feelings.
    C: Sadness is possible, but it's not necessarily automatic or inherent in the decision to divorce. Some may feel relief or liberation instead.
    D: Fights are a situation or event, not a feeling.
    E: Wrong is a moral judgment, not a specific emotion.
4. Given the above reasoning, Option A: Detachment is the correct answer as it directly links to the emotional state of the person planning to stop being married.
Answer: A: detachment

Input: What could you use to store a clock? Choices:  A: shelf B: own bedroom C: desk D: wall E: car
Rationales: 1. The requirement here is a place or object that can potentially store a clock. 
2. A clock can be stored or placed in various places. For the options given, a shelf, a bedroom, a desk, a wall, or a car can potentially store a clock.
3. However, the places should ideally be indoors to protect the clock from damage caused by weather conditions.
4. Keeping the clock in a car is not ideal as the changing weather conditions can damage it. Hence, we eliminate option E: car.
5. Considering option B: own bedroom, while this is a larger room where a clock may be placed, it's not specific enough to count as a place to store a clock. Hence, we eliminate option B.
6. Next, a wall (option D) is a location where clocks are often hung, but the statement specifies storing a clock which implies a place where one can place and safely keep the clock, so this option is eliminated.
7. Looking at option A: shelf and option C: desk, both places can hold a clock. However, a shelf is generally a more suitable place for storing many types of clocks.
8. Thus, the most suitable answer is A: Shelf.
Answer: A: shelf

Input: The person put on lotion, what did they want? Choices:  A: fresh smell B: good credit C: smooth skin D: fresh produce E: headache
Rationales: 1. Analyzing the question, it's asking about the possible reason why a person would put on lotion.
2. It is important to understand the functions or benefits of lotion in this case. The main benefit of lotion is to moisturize and smoothen skin.
3. Now, consider the choices one by one from options A to E to find the one that points to the use of lotion. We are looking for a match that is related to reason for using lotion.
4. Option A "Fresh smell" could be plausible as some lotions are scented but its not the primary reason one uses lotion.
5. Option B, “good credit”, doesn’t connect to the action of applying lotion as it's related to financial status.
6. Similarly, option D "Fresh produce" and option E "headache" doesn't relate to the use of lotion. 
7. The only option left is option C "Smooth skin" which matches the primary use of lotion.
8. Therefore, the logical answer is C: smooth skin.
9. So, when the person put on lotion, they wanted smooth skin.
Answer: C: smooth skin

Input: They burned the record, they were trying to do what to history? Choices:  A: compact disc B: tape C: rewrite D: play music E: erase
Rationales: 1. In analyzing the question, it's important to understand what "burning the record" signifies.
2. The phrase implies some form of destruction or elimination of information.
3. The form of the information being a record, it can be interpreted as the history or evidence of some events or actions.
4. Therefore, they are trying to remove some portion or aspect of history by burning the record.
5. To refine this action to a single word from the choices provided, it can be said that they are trying to 'er
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o8-tcommonsenseqa-s10-rTrue
Loading extension module utils...
Time to load utils op: 0.6048159599304199 seconds
Loading extension module utils...
Time to load utils op: 0.7050380706787109 seconds
Loading extension module utils...
Time to load utils op: 0.7031881809234619 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:42<34:23, 42.11s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:23<33:11, 41.49s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:04<32:20, 41.30s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [02:45<31:33, 41.17s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [03:26<30:50, 41.12s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [04:07<30:07, 41.09s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [04:48<29:25, 41.06s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [05:29<28:44, 41.07s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [06:10<28:04, 41.09s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [06:51<27:21, 41.03s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [07:32<26:41, 41.06s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [08:13<26:01, 41.08s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [08:54<25:19, 41.08s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [09:35<24:39, 41.09s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [10:16<23:56, 41.04s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [10:57<23:15, 41.05s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [11:38<22:35, 41.06s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [12:19<21:53, 41.05s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [13:00<21:12, 41.04s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [13:41<20:30, 41.03s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [14:23<19:50, 41.07s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [15:04<19:10, 41.08s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [15:45<18:29, 41.09s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [16:26<17:47, 41.05s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [17:07<17:05, 41.04s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [17:48<16:25, 41.07s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [18:29<15:43, 41.01s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [19:10<15:01, 40.99s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [19:51<14:20, 41.00s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [20:32<13:39, 40.98s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [21:13<12:59, 41.01s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [21:54<12:18, 41.05s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [22:36<11:43, 41.38s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [23:17<11:01, 41.36s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [23:59<10:19, 41.31s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [24:40<09:38, 41.33s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [25:21<08:56, 41.28s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [26:02<08:14, 41.25s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [26:44<07:33, 41.27s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [27:25<06:52, 41.25s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [28:06<06:10, 41.21s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [28:47<05:30, 41.25s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [29:28<04:48, 41.21s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [30:10<04:07, 41.26s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [30:51<03:26, 41.29s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [31:32<02:44, 41.23s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [32:14<02:03, 41.27s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [32:55<01:22, 41.25s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [33:36<00:41, 41.24s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [34:17<00:00, 41.26s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [34:17<00:00, 41.16s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.0877} | lm_loss 13.4736 | avg. gen lenth: 429.696
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o9-tcommonsenseqa-s10-rTrue --seed 10 --rationales --num-out-domain 9
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date![nltk_data]   Package punkt is already up-to-date![nltk_data]   Package punkt is already up-to-date!


[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-13 04:39:25,928] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o9-tcommonsenseqa-s10-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 9
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o9-tcommonsenseqa-s10-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  0%|                                                       | 9/7473 [00:00<01:23, 89.03it/s]  0%|▏                                                     | 18/7473 [00:00<01:23, 89.54it/s]  0%|▏                                                     | 27/7473 [00:00<01:23, 89.43it/s]  0%|▎                                                     | 36/7473 [00:00<01:23, 89.28it/s]  1%|▎                                                     | 45/7473 [00:00<01:23, 89.34it/s]  1%|▍                                                     | 54/7473 [00:00<01:24, 88.16it/s]  1%|▍                                                     | 63/7473 [00:00<01:23, 88.49it/s]  1%|▌                                                     | 73/7473 [00:00<01:23, 88.94it/s]  1%|▌                                                     | 82/7473 [00:00<01:22, 89.16it/s]  1%|▋                                                     | 92/7473 [00:01<01:22, 89.43it/s]  1%|▋                                                    | 101/7473 [00:01<01:22, 89.40it/s]  1%|▊                                                    | 110/7473 [00:01<01:23, 88.20it/s]  2%|▊                                                    | 119/7473 [00:01<01:23, 88.34it/s]  2%|▉                                                    | 128/7473 [00:01<01:22, 88.71it/s]  2%|▉                                                    | 137/7473 [00:01<01:22, 88.88it/s]  2%|█                                                    | 146/7473 [00:01<01:23, 87.68it/s]  2%|█                                                    | 156/7473 [00:01<01:22, 88.44it/s]  2%|█▏                                                   | 165/7473 [00:01<01:22, 88.78it/s]  2%|█▏                                                   | 174/7473 [00:01<01:22, 88.91it/s]  2%|█▎                                                   | 183/7473 [00:02<01:21, 89.02it/s]  3%|█▎                                                   | 192/7473 [00:02<01:21, 89.29it/s]  3%|█▍                                                   | 203/7473 [00:02<01:17, 93.58it/s]  3%|█▌                                                  | 217/7473 [00:02<01:08, 105.17it/s]  3%|█▌                                                  | 231/7473 [00:02<01:03, 114.12it/s]  3%|█▋                                                  | 245/7473 [00:02<00:59, 120.70it/s]  3%|█▊                                                  | 258/7473 [00:02<00:58, 122.73it/s]  4%|█▉                                                  | 272/7473 [00:02<00:56, 126.78it/s]  4%|█▉                                                  | 285/7473 [00:02<00:57, 125.19it/s]  4%|██                                                  | 299/7473 [00:02<00:55, 128.36it/s]  4%|██▏                                                 | 313/7473 [00:03<00:54, 130.88it/s]  4%|██▎                                                 | 327/7473 [00:03<00:53, 132.64it/s]  5%|██▎                                                 | 341/7473 [00:03<00:53, 133.72it/s]  5%|██▍                                                 | 355/7473 [00:03<00:52, 134.44it/s]  5%|██▌                                                 | 369/7473 [00:03<00:52, 134.21it/s]  5%|██▋                                                 | 383/7473 [00:03<00:52, 134.69it/s]  5%|██▊                                                 | 397/7473 [00:03<00:52, 135.02it/s]  5%|██▊                                                 | 411/7473 [00:03<00:52, 135.21it/s]  6%|██▉                                                 | 425/7473 [00:03<00:52, 135.22it/s]  6%|███                                                 | 439/7473 [00:04<00:51, 135.38it/s]  6%|███▏                                                | 453/7473 [00:04<00:51, 135.59it/s]  6%|███▏                                                | 467/7473 [00:04<00:51, 135.67it/s]  6%|███▎                                                | 481/7473 [00:04<00:52, 134.32it/s]  7%|███▍                                                | 495/7473 [00:04<00:51, 134.27it/s]  7%|███▌                                                | 509/7473 [00:04<00:51, 134.18it/s]  7%|███▋                                                | 523/7473 [00:04<00:51, 135.15it/s]  7%|███▋                                                | 537/7473 [00:04<00:51, 135.82it/s]  7%|███▊                                                | 551/7473 [00:04<00:50, 136.37it/s]  8%|███▉                                                | 565/7473 [00:04<00:50, 136.38it/s]  8%|████                                                | 579/7473 [00:05<00:50, 136.41it/s]  8%|████▏                                               | 593/7473 [00:05<00:50, 136.77it/s]  8%|████▏                                               | 607/7473 [00:05<00:50, 135.69it/s]  8%|████▎                                               | 621/7473 [00:05<00:50, 135.89it/s]  8%|████▍                                               | 635/7473 [00:05<00:50, 136.56it/s]  9%|████▌                                               | 649/7473 [00:05<00:50, 135.84it/s]  9%|████▌                                               | 663/7473 [00:05<00:49, 136.25it/s]  9%|████▋                                               | 677/7473 [00:05<00:49, 136.57it/s]  9%|████▊                                               | 691/7473 [00:05<00:49, 136.74it/s]  9%|████▉                                               | 705/7473 [00:05<00:50, 135.06it/s] 10%|█████                                               | 719/7473 [00:06<00:49, 135.79it/s] 10%|█████                                               | 733/7473 [00:06<00:49, 136.34it/s] 10%|█████▏                                              | 747/7473 [00:06<00:49, 136.77it/s] 10%|█████▎                                              | 761/7473 [00:06<00:49, 136.91it/s] 10%|█████▍                                              | 775/7473 [00:06<00:49, 136.48it/s] 11%|█████▍                                              | 789/7473 [00:06<00:49, 135.23it/s] 11%|█████▌                                              | 803/7473 [00:06<00:49, 135.52it/s] 11%|█████▋                                              | 817/7473 [00:06<00:49, 135.67it/s] 11%|█████▊                                              | 831/7473 [00:06<00:48, 135.79it/s] 11%|█████▉                                              | 845/7473 [00:07<00:48, 136.03it/s] 11%|█████▉                                              | 859/7473 [00:07<00:48, 136.46it/s] 12%|██████                                              | 873/7473 [00:07<00:48, 136.74it/s] 12%|██████▏                                             | 887/7473 [00:07<00:48, 136.93it/s] 12%|██████▎                                             | 901/7473 [00:07<00:47, 137.02it/s] 12%|██████▎                                             | 915/7473 [00:07<00:47, 137.12it/s] 12%|██████▍                                             | 929/7473 [00:07<00:47, 137.05it/s] 13%|██████▌                                             | 943/7473 [00:07<00:48, 134.77it/s] 13%|██████▋                                             | 957/7473 [00:07<00:48, 134.90it/s] 13%|██████▊                                             | 971/7473 [00:07<00:47, 135.68it/s] 13%|██████▊                                             | 985/7473 [00:08<00:47, 136.11it/s] 13%|██████▉                                             | 999/7473 [00:08<00:47, 136.22it/s] 14%|██████▉                                            | 1013/7473 [00:08<00:47, 136.58it/s] 14%|███████                                            | 1027/7473 [00:08<00:47, 137.05it/s] 14%|███████                                            | 1041/7473 [00:08<00:46, 136.99it/s] 14%|███████▏                                           | 1055/7473 [00:08<00:46, 136.94it/s] 14%|███████▎                                           | 1069/7473 [00:08<00:46, 137.34it/s] 14%|███████▍                                           | 1083/7473 [00:08<00:46, 137.23it/s] 15%|███████▍                                           | 1097/7473 [00:08<00:46, 137.12it/s] 15%|███████▌                                           | 1111/7473 [00:08<00:46, 136.47it/s] 15%|███████▋                                           | 1125/7473 [00:09<00:46, 136.53it/s] 15%|███████▊                                           | 1139/7473 [00:09<00:46, 136.80it/s] 15%|███████▊                                           | 1153/7473 [00:09<00:46, 136.99it/s] 16%|███████▉                                           | 1167/7473 [00:09<00:46, 135.30it/s] 16%|████████                                           | 1181/7473 [00:09<00:46, 135.73it/s] 16%|████████▏                                          | 1195/7473 [00:09<00:46, 135.69it/s] 16%|████████▎                                          | 1209/7473 [00:09<00:46, 136.06it/s] 16%|████████▎                                          | 1223/7473 [00:09<00:45, 136.52it/s] 17%|████████▍                                          | 1237/7473 [00:09<00:45, 136.78it/s] 17%|████████▌                                          | 1251/7473 [00:09<00:45, 137.03it/s] 17%|████████▋                                          | 1265/7473 [00:10<00:45, 136.38it/s] 17%|████████▋                                          | 1279/7473 [00:10<00:45, 136.39it/s] 17%|████████▊                                          | 1293/7473 [00:10<00:45, 136.49it/s] 17%|████████▉                                          | 1307/7473 [00:10<00:45, 136.48it/s] 18%|█████████                                          | 1321/7473 [00:10<00:45, 136.64it/s] 18%|█████████                                          | 1335/7473 [00:10<00:44, 136.83it/s] 18%|█████████▏                                         | 1349/7473 [00:10<00:44, 136.94it/s] 18%|█████████▎                                         | 1363/7473 [00:10<00:44, 137.04it/s] 18%|█████████▍                                         | 1377/7473 [00:10<00:44, 137.08it/s] 19%|█████████▍                                         | 1391/7473 [00:11<00:45, 134.88it/s] 19%|█████████▌                                         | 1405/7473 [00:11<00:44, 135.60it/s] 19%|█████████▋                                         | 1419/7473 [00:11<00:44, 136.05it/s] 19%|█████████▊                                         | 1433/7473 [00:11<00:44, 135.93it/s] 19%|█████████▉                                         | 1447/7473 [00:11<00:44, 135.45it/s] 20%|█████████▉                                         | 1461/7473 [00:11<00:44, 135.89it/s] 20%|██████████                                         | 1475/7473 [00:11<00:43, 136.36it/s] 20%|██████████▏                                        | 1489/7473 [00:11<00:43, 136.68it/s] 20%|██████████▎                                        | 1503/7473 [00:11<00:43, 136.88it/s] 20%|██████████▎                                        | 1517/7473 [00:11<00:43, 137.15it/s] 20%|██████████▍                                        | 1531/7473 [00:12<00:43, 136.68it/s] 21%|██████████▌                                        | 1545/7473 [00:12<00:43, 136.57it/s] 21%|██████████▋                                        | 1559/7473 [00:12<00:43, 136.38it/s] 21%|██████████▋                                        | 1573/7473 [00:12<00:43, 136.43it/s] 21%|██████████▊                                        | 1587/7473 [00:12<00:43, 136.48it/s] 21%|██████████▉                                        | 1601/7473 [00:12<00:43, 135.94it/s] 22%|███████████                                        | 1615/7473 [00:12<00:43, 134.77it/s] 22%|███████████                                        | 1629/7473 [00:12<00:43, 134.74it/s] 22%|███████████▏                                       | 1643/7473 [00:12<00:42, 135.71it/s] 22%|███████████▎                                       | 1657/7473 [00:12<00:43, 135.22it/s] 22%|███████████▍                                       | 1671/7473 [00:13<00:42, 135.45it/s] 23%|███████████▍                                       | 1685/7473 [00:13<00:42, 135.97it/s] 23%|███████████▌                                       | 1699/7473 [00:13<00:42, 136.28it/s] 23%|███████████▋                                       | 1713/7473 [00:13<00:42, 136.47it/s] 23%|███████████▊                                       | 1727/7473 [00:13<00:42, 136.50it/s] 23%|███████████▉                                       | 1741/7473 [00:13<00:42, 136.38it/s] 23%|███████████▉                                       | 1755/7473 [00:13<00:41, 136.64it/s] 24%|████████████                                       | 1769/7473 [00:13<00:42, 135.71it/s] 24%|████████████▏                                      | 1783/7473 [00:13<00:41, 135.86it/s] 24%|████████████▎                                      | 1797/7473 [00:13<00:41, 136.31it/s] 24%|████████████▎                                      | 1811/7473 [00:14<00:41, 136.80it/s] 24%|████████████▍                                      | 1825/7473 [00:14<00:41, 136.68it/s] 25%|████████████▌                                      | 1839/7473 [00:14<00:41, 135.08it/s] 25%|████████████▋                                      | 1853/7473 [00:14<00:41, 135.72it/s] 25%|████████████▋                                      | 1867/7473 [00:14<00:41, 135.80it/s] 25%|████████████▊                                      | 1881/7473 [00:14<00:41, 135.57it/s] 25%|████████████▉                                      | 1895/7473 [00:14<00:41, 135.85it/s] 26%|█████████████                                      | 1909/7473 [00:14<00:40, 135.87it/s] 26%|█████████████                                      | 1923/7473 [00:14<00:40, 135.93it/s] 26%|█████████████▏                                     | 1937/7473 [00:15<00:40, 135.29it/s] 26%|█████████████▎                                     | 1951/7473 [00:15<00:40, 135.74it/s] 26%|█████████████▍                                     | 1965/7473 [00:15<00:40, 136.23it/s] 26%|█████████████▌                                     | 1979/7473 [00:15<00:40, 136.45it/s] 27%|█████████████▌                                     | 1993/7473 [00:15<00:40, 136.61it/s] 27%|█████████████▋                                     | 2007/7473 [00:15<00:39, 136.70it/s] 27%|█████████████▊                                     | 2021/7473 [00:15<00:39, 137.00it/s] 27%|█████████████▉                                     | 2035/7473 [00:15<00:39, 137.13it/s] 27%|█████████████▉                                     | 2049/7473 [00:15<00:39, 137.04it/s] 28%|██████████████                                     | 2063/7473 [00:15<00:39, 137.16it/s] 28%|██████████████▏                                    | 2077/7473 [00:16<00:39, 135.28it/s] 28%|██████████████▎                                    | 2091/7473 [00:16<00:39, 135.34it/s] 28%|██████████████▎                                    | 2105/7473 [00:16<00:39, 135.43it/s] 28%|██████████████▍                                    | 2119/7473 [00:16<00:39, 134.43it/s] 29%|██████████████▌                                    | 2133/7473 [00:16<00:39, 134.79it/s] 29%|██████████████▋                                    | 2147/7473 [00:16<00:39, 134.99it/s] 29%|██████████████▋                                    | 2161/7473 [00:16<00:39, 135.70it/s] 29%|██████████████▊                                    | 2175/7473 [00:16<00:38, 135.89it/s] 29%|██████████████▉                                    | 2189/7473 [00:16<00:38, 136.02it/s] 29%|███████████████                                    | 2203/7473 [00:16<00:38, 136.47it/s] 30%|███████████████▏                                   | 2217/7473 [00:17<00:38, 136.83it/s] 30%|███████████████▏                                   | 2231/7473 [00:17<00:38, 136.66it/s] 30%|███████████████▎                                   | 2245/7473 [00:17<00:38, 136.06it/s] 30%|███████████████▍                                   | 2259/7473 [00:17<00:38, 135.53it/s] 30%|███████████████▌                                   | 2273/7473 [00:17<00:38, 135.52it/s] 31%|███████████████▌                                   | 2287/7473 [00:17<00:38, 135.97it/s] 31%|███████████████▋                                   | 2301/7473 [00:17<00:38, 134.80it/s] 31%|███████████████▊                                   | 2315/7473 [00:17<00:38, 135.60it/s] 31%|███████████████▉                                   | 2329/7473 [00:17<00:37, 136.04it/s] 31%|███████████████▉                                   | 2343/7473 [00:18<00:37, 135.14it/s] 32%|████████████████                                   | 2357/7473 [00:18<00:37, 135.34it/s] 32%|████████████████▏                                  | 2371/7473 [00:18<00:37, 135.65it/s] 32%|████████████████▎                                  | 2385/7473 [00:18<00:37, 136.15it/s] 32%|████████████████▎                                  | 2399/7473 [00:18<00:37, 136.20it/s] 32%|████████████████▍                                  | 2413/7473 [00:18<00:37, 135.79it/s] 32%|████████████████▌                                  | 2427/7473 [00:18<00:37, 135.67it/s] 33%|████████████████▋                                  | 2441/7473 [00:18<00:36, 136.16it/s] 33%|████████████████▊                                  | 2455/7473 [00:18<00:36, 136.45it/s] 33%|████████████████▊                                  | 2469/7473 [00:18<00:36, 136.45it/s] 33%|████████████████▉                                  | 2483/7473 [00:19<00:36, 136.59it/s] 33%|█████████████████                                  | 2497/7473 [00:19<00:36, 136.57it/s] 34%|█████████████████▏                                 | 2511/7473 [00:19<00:36, 136.80it/s] 34%|█████████████████▏                                 | 2525/7473 [00:19<00:42, 115.68it/s] 34%|█████████████████▎                                 | 2539/7473 [00:19<00:40, 120.98it/s] 34%|█████████████████▍                                 | 2553/7473 [00:19<00:39, 123.98it/s] 34%|█████████████████▌                                 | 2567/7473 [00:19<00:38, 126.54it/s] 35%|█████████████████▌                                 | 2581/7473 [00:19<00:37, 129.13it/s] 35%|█████████████████▋                                 | 2595/7473 [00:19<00:37, 130.96it/s] 35%|█████████████████▊                                 | 2609/7473 [00:20<00:36, 132.06it/s] 35%|█████████████████▉                                 | 2623/7473 [00:20<00:36, 133.04it/s] 35%|█████████████████▉                                 | 2637/7473 [00:20<00:36, 134.14it/s] 35%|██████████████████                                 | 2651/7473 [00:20<00:35, 135.18it/s] 36%|██████████████████▏                                | 2665/7473 [00:20<00:35, 135.79it/s] 36%|██████████████████▎                                | 2679/7473 [00:20<00:35, 135.99it/s] 36%|██████████████████▍                                | 2693/7473 [00:20<00:35, 135.90it/s] 36%|██████████████████▍                                | 2707/7473 [00:20<00:35, 134.93it/s] 36%|██████████████████▌                                | 2721/7473 [00:20<00:35, 134.24it/s] 37%|██████████████████▋                                | 2735/7473 [00:20<00:35, 134.91it/s] 37%|██████████████████▊                                | 2749/7473 [00:21<00:35, 133.82it/s] 37%|██████████████████▊                                | 2763/7473 [00:21<00:34, 134.78it/s] 37%|██████████████████▉                                | 2777/7473 [00:21<00:34, 135.32it/s] 37%|███████████████████                                | 2791/7473 [00:21<00:34, 135.77it/s] 38%|███████████████████▏                               | 2805/7473 [00:21<00:34, 135.04it/s] 38%|███████████████████▏                               | 2819/7473 [00:21<00:34, 135.35it/s] 38%|███████████████████▎                               | 2833/7473 [00:21<00:34, 136.13it/s] 38%|███████████████████▍                               | 2847/7473 [00:21<00:34, 135.79it/s] 38%|███████████████████▌                               | 2861/7473 [00:21<00:34, 135.29it/s] 38%|███████████████████▌                               | 2875/7473 [00:21<00:33, 135.70it/s] 39%|███████████████████▋                               | 2889/7473 [00:22<00:33, 136.16it/s] 39%|███████████████████▊                               | 2903/7473 [00:22<00:33, 136.32it/s] 39%|███████████████████▉                               | 2917/7473 [00:22<00:33, 136.64it/s] 39%|████████████████████                               | 2931/7473 [00:22<00:33, 137.12it/s] 39%|████████████████████                               | 2945/7473 [00:22<00:33, 137.19it/s] 40%|████████████████████▏                              | 2959/7473 [00:22<00:33, 136.71it/s] 40%|████████████████████▎                              | 2973/7473 [00:22<00:33, 134.96it/s] 40%|████████████████████▍                              | 2987/7473 [00:22<00:33, 135.58it/s] 40%|████████████████████▍                              | 3001/7473 [00:22<00:33, 135.30it/s] 40%|████████████████████▌                              | 3015/7473 [00:23<00:33, 134.58it/s] 41%|████████████████████▋                              | 3029/7473 [00:23<00:33, 133.96it/s] 41%|████████████████████▊                              | 3043/7473 [00:23<00:32, 134.71it/s] 41%|████████████████████▊                              | 3057/7473 [00:23<00:32, 135.52it/s] 41%|████████████████████▉                              | 3071/7473 [00:23<00:32, 135.64it/s] 41%|█████████████████████                              | 3085/7473 [00:23<00:32, 136.10it/s] 41%|█████████████████████▏                             | 3099/7473 [00:23<00:32, 136.31it/s] 42%|█████████████████████▏                             | 3113/7473 [00:23<00:32, 135.83it/s] 42%|█████████████████████▎                             | 3127/7473 [00:23<00:31, 135.82it/s] 42%|█████████████████████▍                             | 3141/7473 [00:23<00:31, 135.87it/s] 42%|█████████████████████▌                             | 3155/7473 [00:24<00:31, 135.54it/s] 42%|█████████████████████▋                             | 3169/7473 [00:24<00:31, 135.03it/s] 43%|█████████████████████▋                             | 3183/7473 [00:24<00:31, 135.61it/s] 43%|█████████████████████▊                             | 3197/7473 [00:24<00:31, 136.03it/s] 43%|█████████████████████▉                             | 3211/7473 [00:24<00:31, 134.81it/s] 43%|██████████████████████                             | 3225/7473 [00:24<00:31, 135.05it/s] 43%|██████████████████████                             | 3239/7473 [00:24<00:31, 135.37it/s] 44%|██████████████████████▏                            | 3253/7473 [00:24<00:31, 135.88it/s] 44%|██████████████████████▎                            | 3267/7473 [00:24<00:30, 136.34it/s] 44%|██████████████████████▍                            | 3281/7473 [00:24<00:30, 136.58it/s] 44%|██████████████████████▍                            | 3295/7473 [00:25<00:30, 136.41it/s] 44%|██████████████████████▌                            | 3309/7473 [00:25<00:30, 136.35it/s] 44%|██████████████████████▋                            | 3323/7473 [00:25<00:30, 136.07it/s] 45%|██████████████████████▊                            | 3337/7473 [00:25<00:30, 135.02it/s] 45%|██████████████████████▊                            | 3351/7473 [00:25<00:30, 135.43it/s] 45%|██████████████████████▉                            | 3365/7473 [00:25<00:30, 135.63it/s] 45%|███████████████████████                            | 3379/7473 [00:25<00:30, 135.81it/s] 45%|███████████████████████▏                           | 3393/7473 [00:25<00:30, 135.87it/s] 46%|███████████████████████▎                           | 3407/7473 [00:25<00:29, 136.18it/s] 46%|███████████████████████▎                           | 3421/7473 [00:26<00:29, 136.22it/s] 46%|███████████████████████▍                           | 3435/7473 [00:26<00:29, 134.86it/s] 46%|███████████████████████▌                           | 3449/7473 [00:26<00:29, 134.65it/s] 46%|███████████████████████▋                           | 3463/7473 [00:26<00:29, 134.92it/s] 47%|███████████████████████▋                           | 3477/7473 [00:26<00:29, 135.53it/s] 47%|███████████████████████▊                           | 3491/7473 [00:26<00:29, 135.91it/s] 47%|███████████████████████▉                           | 3505/7473 [00:26<00:29, 135.56it/s] 47%|████████████████████████                           | 3519/7473 [00:26<00:29, 135.41it/s] 47%|████████████████████████                           | 3533/7473 [00:26<00:29, 135.71it/s] 47%|████████████████████████▏                          | 3547/7473 [00:26<00:28, 136.07it/s] 48%|████████████████████████▎                          | 3561/7473 [00:27<00:28, 135.95it/s] 48%|████████████████████████▍                          | 3575/7473 [00:27<00:28, 136.47it/s] 48%|████████████████████████▍                          | 3589/7473 [00:27<00:28, 136.40it/s] 48%|████████████████████████▌                          | 3603/7473 [00:27<00:28, 135.49it/s] 48%|████████████████████████▋                          | 3617/7473 [00:27<00:28, 135.00it/s] 49%|████████████████████████▊                          | 3631/7473 [00:27<00:28, 135.29it/s] 49%|████████████████████████▉                          | 3645/7473 [00:27<00:28, 135.43it/s] 49%|████████████████████████▉                          | 3659/7473 [00:27<00:28, 133.97it/s] 49%|█████████████████████████                          | 3673/7473 [00:27<00:28, 134.24it/s] 49%|█████████████████████████▏                         | 3687/7473 [00:27<00:28, 134.88it/s] 50%|█████████████████████████▎                         | 3701/7473 [00:28<00:27, 135.31it/s] 50%|█████████████████████████▎                         | 3715/7473 [00:28<00:27, 135.67it/s] 50%|█████████████████████████▍                         | 3729/7473 [00:28<00:27, 135.88it/s] 50%|█████████████████████████▌                         | 3743/7473 [00:28<00:27, 135.37it/s] 50%|█████████████████████████▋                         | 3757/7473 [00:28<00:27, 135.25it/s] 50%|█████████████████████████▋                         | 3771/7473 [00:28<00:27, 135.67it/s] 51%|█████████████████████████▊                         | 3785/7473 [00:28<00:27, 135.13it/s] 51%|█████████████████████████▉                         | 3799/7473 [00:28<00:27, 135.75it/s] 51%|██████████████████████████                         | 3813/7473 [00:28<00:26, 135.99it/s] 51%|██████████████████████████                         | 3827/7473 [00:29<00:26, 135.92it/s] 51%|██████████████████████████▏                        | 3841/7473 [00:29<00:26, 135.96it/s] 52%|██████████████████████████▎                        | 3855/7473 [00:29<00:26, 135.84it/s] 52%|██████████████████████████▍                        | 3869/7473 [00:29<00:26, 135.93it/s] 52%|██████████████████████████▍                        | 3883/7473 [00:29<00:26, 133.69it/s] 52%|██████████████████████████▌                        | 3897/7473 [00:29<00:26, 133.46it/s] 52%|██████████████████████████▋                        | 3911/7473 [00:29<00:26, 133.97it/s] 53%|██████████████████████████▊                        | 3925/7473 [00:29<00:26, 134.21it/s] 53%|██████████████████████████▉                        | 3939/7473 [00:29<00:26, 134.78it/s] 53%|██████████████████████████▉                        | 3953/7473 [00:29<00:26, 135.21it/s] 53%|███████████████████████████                        | 3967/7473 [00:30<00:25, 135.42it/s] 53%|███████████████████████████▏                       | 3981/7473 [00:30<00:25, 135.07it/s] 53%|███████████████████████████▎                       | 3995/7473 [00:30<00:25, 135.23it/s] 54%|███████████████████████████▎                       | 4009/7473 [00:30<00:25, 135.54it/s] 54%|███████████████████████████▍                       | 4023/7473 [00:30<00:25, 135.70it/s] 54%|███████████████████████████▌                       | 4037/7473 [00:30<00:25, 135.11it/s] 54%|███████████████████████████▋                       | 4051/7473 [00:30<00:25, 134.04it/s] 54%|███████████████████████████▋                       | 4065/7473 [00:30<00:25, 134.39it/s] 55%|███████████████████████████▊                       | 4079/7473 [00:30<00:25, 134.62it/s] 55%|███████████████████████████▉                       | 4093/7473 [00:30<00:25, 135.11it/s] 55%|████████████████████████████                       | 4107/7473 [00:31<00:24, 134.74it/s] 55%|████████████████████████████                       | 4121/7473 [00:31<00:25, 133.21it/s] 55%|████████████████████████████▏                      | 4135/7473 [00:31<00:25, 133.42it/s] 56%|████████████████████████████▎                      | 4149/7473 [00:31<00:24, 133.82it/s] 56%|████████████████████████████▍                      | 4163/7473 [00:31<00:24, 134.56it/s] 56%|████████████████████████████▌                      | 4177/7473 [00:31<00:24, 134.78it/s] 56%|████████████████████████████▌                      | 4191/7473 [00:31<00:24, 134.32it/s] 56%|████████████████████████████▋                      | 4205/7473 [00:31<00:24, 133.16it/s] 56%|████████████████████████████▊                      | 4219/7473 [00:31<00:24, 133.30it/s] 57%|████████████████████████████▉                      | 4233/7473 [00:32<00:24, 134.13it/s] 57%|████████████████████████████▉                      | 4247/7473 [00:32<00:24, 134.25it/s] 57%|█████████████████████████████                      | 4261/7473 [00:32<00:23, 134.61it/s] 57%|█████████████████████████████▏                     | 4275/7473 [00:32<00:23, 134.63it/s] 57%|█████████████████████████████▎                     | 4289/7473 [00:32<00:23, 134.92it/s] 58%|█████████████████████████████▎                     | 4303/7473 [00:32<00:23, 135.06it/s] 58%|█████████████████████████████▍                     | 4317/7473 [00:32<00:23, 135.09it/s] 58%|█████████████████████████████▌                     | 4331/7473 [00:32<00:23, 135.43it/s] 58%|█████████████████████████████▋                     | 4345/7473 [00:32<00:23, 134.00it/s] 58%|█████████████████████████████▋                     | 4359/7473 [00:32<00:23, 134.44it/s] 59%|█████████████████████████████▊                     | 4373/7473 [00:33<00:23, 134.04it/s] 59%|█████████████████████████████▉                     | 4387/7473 [00:33<00:23, 133.23it/s] 59%|██████████████████████████████                     | 4401/7473 [00:33<00:22, 133.97it/s] 59%|██████████████████████████████▏                    | 4415/7473 [00:33<00:22, 134.18it/s] 59%|██████████████████████████████▏                    | 4429/7473 [00:33<00:22, 134.11it/s] 59%|██████████████████████████████▎                    | 4443/7473 [00:33<00:22, 134.33it/s] 60%|██████████████████████████████▍                    | 4457/7473 [00:33<00:22, 134.46it/s] 60%|██████████████████████████████▌                    | 4471/7473 [00:33<00:22, 134.65it/s] 60%|██████████████████████████████▌                    | 4485/7473 [00:33<00:22, 134.86it/s] 60%|██████████████████████████████▋                    | 4499/7473 [00:34<00:22, 135.18it/s] 60%|██████████████████████████████▊                    | 4513/7473 [00:34<00:21, 135.30it/s] 61%|██████████████████████████████▉                    | 4527/7473 [00:34<00:21, 135.14it/s] 61%|██████████████████████████████▉                    | 4541/7473 [00:34<00:21, 135.44it/s] 61%|███████████████████████████████                    | 4555/7473 [00:34<00:21, 134.56it/s] 61%|███████████████████████████████▏                   | 4569/7473 [00:34<00:21, 132.31it/s] 61%|███████████████████████████████▎                   | 4583/7473 [00:34<00:21, 133.16it/s] 62%|███████████████████████████████▎                   | 4597/7473 [00:34<00:21, 133.35it/s] 62%|███████████████████████████████▍                   | 4611/7473 [00:34<00:21, 133.94it/s] 62%|███████████████████████████████▌                   | 4625/7473 [00:34<00:21, 134.56it/s] 62%|███████████████████████████████▋                   | 4639/7473 [00:35<00:21, 134.69it/s] 62%|███████████████████████████████▊                   | 4653/7473 [00:35<00:20, 134.86it/s] 62%|███████████████████████████████▊                   | 4667/7473 [00:35<00:20, 135.19it/s] 63%|███████████████████████████████▉                   | 4681/7473 [00:35<00:20, 135.15it/s] 63%|████████████████████████████████                   | 4695/7473 [00:35<00:20, 135.15it/s] 63%|████████████████████████████████▏                  | 4709/7473 [00:35<00:20, 135.28it/s] 63%|████████████████████████████████▏                  | 4723/7473 [00:35<00:20, 134.85it/s] 63%|████████████████████████████████▎                  | 4737/7473 [00:35<00:20, 132.29it/s] 64%|████████████████████████████████▍                  | 4751/7473 [00:35<00:20, 132.28it/s] 64%|████████████████████████████████▌                  | 4765/7473 [00:35<00:20, 133.64it/s] 64%|████████████████████████████████▌                  | 4779/7473 [00:36<00:20, 134.52it/s] 64%|████████████████████████████████▋                  | 4793/7473 [00:36<00:20, 133.59it/s] 64%|████████████████████████████████▊                  | 4807/7473 [00:36<00:19, 134.26it/s] 65%|████████████████████████████████▉                  | 4821/7473 [00:36<00:19, 134.76it/s] 65%|████████████████████████████████▉                  | 4835/7473 [00:36<00:19, 135.21it/s] 65%|█████████████████████████████████                  | 4849/7473 [00:36<00:19, 135.57it/s] 65%|█████████████████████████████████▏                 | 4863/7473 [00:36<00:19, 135.39it/s] 65%|█████████████████████████████████▎                 | 4877/7473 [00:36<00:19, 135.07it/s] 65%|█████████████████████████████████▍                 | 4891/7473 [00:36<00:19, 134.63it/s] 66%|█████████████████████████████████▍                 | 4905/7473 [00:37<00:19, 134.60it/s] 66%|█████████████████████████████████▌                 | 4919/7473 [00:37<00:18, 135.01it/s] 66%|█████████████████████████████████▋                 | 4933/7473 [00:37<00:18, 135.30it/s] 66%|█████████████████████████████████▊                 | 4947/7473 [00:37<00:18, 135.53it/s] 66%|█████████████████████████████████▊                 | 4961/7473 [00:37<00:18, 135.72it/s] 67%|█████████████████████████████████▉                 | 4975/7473 [00:37<00:18, 135.76it/s] 67%|██████████████████████████████████                 | 4989/7473 [00:37<00:18, 135.95it/s] 67%|██████████████████████████████████▏                | 5003/7473 [00:37<00:18, 135.98it/s] 67%|██████████████████████████████████▏                | 5017/7473 [00:37<00:18, 134.58it/s] 67%|██████████████████████████████████▎                | 5031/7473 [00:37<00:18, 134.13it/s] 68%|██████████████████████████████████▍                | 5045/7473 [00:38<00:18, 133.52it/s] 68%|██████████████████████████████████▌                | 5059/7473 [00:38<00:18, 134.05it/s] 68%|██████████████████████████████████▌                | 5073/7473 [00:38<00:17, 134.88it/s] 68%|██████████████████████████████████▋                | 5087/7473 [00:38<00:17, 135.32it/s] 68%|██████████████████████████████████▊                | 5101/7473 [00:38<00:17, 135.58it/s] 68%|██████████████████████████████████▉                | 5115/7473 [00:38<00:17, 134.93it/s] 69%|███████████████████████████████████                | 5129/7473 [00:38<00:17, 135.26it/s] 69%|███████████████████████████████████                | 5143/7473 [00:38<00:17, 135.10it/s] 69%|███████████████████████████████████▏               | 5157/7473 [00:38<00:17, 135.63it/s] 69%|███████████████████████████████████▎               | 5171/7473 [00:39<00:16, 135.57it/s] 69%|███████████████████████████████████▍               | 5185/7473 [00:39<00:16, 134.75it/s] 70%|███████████████████████████████████▍               | 5199/7473 [00:39<00:16, 134.82it/s] 70%|███████████████████████████████████▌               | 5213/7473 [00:39<00:16, 135.47it/s] 70%|███████████████████████████████████▋               | 5227/7473 [00:39<00:16, 135.75it/s] 70%|███████████████████████████████████▊               | 5241/7473 [00:39<00:16, 135.79it/s] 70%|███████████████████████████████████▊               | 5255/7473 [00:39<00:18, 118.02it/s] 71%|███████████████████████████████████▉               | 5269/7473 [00:39<00:17, 122.88it/s] 71%|████████████████████████████████████               | 5283/7473 [00:39<00:17, 126.07it/s] 71%|████████████████████████████████████▏              | 5297/7473 [00:39<00:16, 129.11it/s] 71%|████████████████████████████████████▏              | 5311/7473 [00:40<00:16, 130.98it/s] 71%|████████████████████████████████████▎              | 5325/7473 [00:40<00:16, 130.58it/s] 71%|████████████████████████████████████▍              | 5339/7473 [00:40<00:16, 131.20it/s] 72%|████████████████████████████████████▌              | 5353/7473 [00:40<00:15, 132.59it/s] 72%|████████████████████████████████████▋              | 5367/7473 [00:40<00:15, 133.65it/s] 72%|████████████████████████████████████▋              | 5381/7473 [00:40<00:15, 134.48it/s] 72%|████████████████████████████████████▊              | 5395/7473 [00:40<00:15, 134.76it/s] 72%|████████████████████████████████████▉              | 5409/7473 [00:40<00:15, 133.67it/s] 73%|█████████████████████████████████████              | 5423/7473 [00:40<00:15, 134.58it/s] 73%|█████████████████████████████████████              | 5437/7473 [00:41<00:15, 135.27it/s] 73%|█████████████████████████████████████▏             | 5451/7473 [00:41<00:14, 135.65it/s] 73%|█████████████████████████████████████▎             | 5465/7473 [00:41<00:14, 134.95it/s] 73%|██████████████████████████████████████              | 5479/7473 [00:41<00:24, 80.56it/s] 74%|██████████████████████████████████████▏             | 5493/7473 [00:41<00:21, 91.84it/s] 74%|█████████████████████████████████████▌             | 5507/7473 [00:41<00:19, 101.42it/s] 74%|█████████████████████████████████████▋             | 5521/7473 [00:41<00:17, 109.89it/s] 74%|█████████████████████████████████████▊             | 5535/7473 [00:41<00:16, 116.58it/s] 74%|█████████████████████████████████████▊             | 5549/7473 [00:42<00:15, 120.96it/s] 74%|█████████████████████████████████████▉             | 5563/7473 [00:42<00:15, 124.65it/s] 75%|██████████████████████████████████████             | 5577/7473 [00:42<00:14, 127.40it/s] 75%|██████████████████████████████████████▏            | 5591/7473 [00:42<00:14, 129.42it/s] 75%|██████████████████████████████████████▎            | 5605/7473 [00:42<00:14, 131.03it/s] 75%|██████████████████████████████████████▎            | 5619/7473 [00:42<00:13, 132.54it/s] 75%|██████████████████████████████████████▍            | 5633/7473 [00:42<00:13, 133.69it/s] 76%|██████████████████████████████████████▌            | 5647/7473 [00:42<00:13, 133.95it/s] 76%|██████████████████████████████████████▋            | 5661/7473 [00:42<00:13, 134.77it/s] 76%|██████████████████████████████████████▋            | 5675/7473 [00:43<00:13, 132.61it/s] 76%|██████████████████████████████████████▊            | 5689/7473 [00:43<00:13, 133.87it/s] 76%|██████████████████████████████████████▉            | 5703/7473 [00:43<00:13, 134.51it/s] 77%|███████████████████████████████████████            | 5717/7473 [00:43<00:13, 134.73it/s] 77%|███████████████████████████████████████            | 5731/7473 [00:43<00:13, 133.78it/s] 77%|███████████████████████████████████████▏           | 5745/7473 [00:43<00:12, 133.32it/s] 77%|███████████████████████████████████████▎           | 5759/7473 [00:43<00:12, 134.04it/s] 77%|███████████████████████████████████████▍           | 5773/7473 [00:43<00:12, 134.63it/s] 77%|███████████████████████████████████████▍           | 5787/7473 [00:43<00:12, 134.69it/s] 78%|███████████████████████████████████████▌           | 5801/7473 [00:43<00:12, 135.17it/s] 78%|███████████████████████████████████████▋           | 5815/7473 [00:44<00:12, 135.04it/s] 78%|███████████████████████████████████████▊           | 5829/7473 [00:44<00:12, 131.23it/s] 78%|███████████████████████████████████████▉           | 5843/7473 [00:44<00:12, 132.62it/s] 78%|███████████████████████████████████████▉           | 5857/7473 [00:44<00:12, 133.66it/s] 79%|████████████████████████████████████████           | 5871/7473 [00:44<00:11, 133.94it/s] 79%|████████████████████████████████████████▏          | 5885/7473 [00:44<00:11, 134.21it/s] 79%|████████████████████████████████████████▎          | 5899/7473 [00:44<00:11, 134.52it/s] 79%|████████████████████████████████████████▎          | 5913/7473 [00:44<00:11, 132.89it/s] 79%|████████████████████████████████████████▍          | 5927/7473 [00:44<00:11, 133.64it/s] 79%|████████████████████████████████████████▌          | 5941/7473 [00:45<00:11, 134.24it/s] 80%|████████████████████████████████████████▋          | 5955/7473 [00:45<00:11, 134.65it/s] 80%|████████████████████████████████████████▋          | 5969/7473 [00:45<00:11, 133.87it/s] 80%|████████████████████████████████████████▊          | 5983/7473 [00:45<00:11, 134.65it/s] 80%|████████████████████████████████████████▉          | 5997/7473 [00:45<00:10, 134.94it/s] 80%|█████████████████████████████████████████          | 6011/7473 [00:45<00:10, 134.99it/s] 81%|█████████████████████████████████████████          | 6025/7473 [00:45<00:10, 135.04it/s] 81%|█████████████████████████████████████████▏         | 6039/7473 [00:45<00:10, 135.27it/s] 81%|█████████████████████████████████████████▎         | 6053/7473 [00:45<00:10, 135.56it/s] 81%|█████████████████████████████████████████▍         | 6067/7473 [00:45<00:10, 135.38it/s] 81%|█████████████████████████████████████████▌         | 6081/7473 [00:46<00:10, 135.58it/s] 82%|█████████████████████████████████████████▌         | 6095/7473 [00:46<00:10, 135.91it/s] 82%|█████████████████████████████████████████▋         | 6109/7473 [00:46<00:10, 136.15it/s] 82%|█████████████████████████████████████████▊         | 6123/7473 [00:46<00:09, 136.40it/s] 82%|█████████████████████████████████████████▉         | 6137/7473 [00:46<00:09, 134.83it/s] 82%|█████████████████████████████████████████▉         | 6151/7473 [00:46<00:09, 135.22it/s] 82%|██████████████████████████████████████████         | 6165/7473 [00:46<00:09, 135.52it/s] 83%|██████████████████████████████████████████▏        | 6179/7473 [00:46<00:09, 135.47it/s] 83%|██████████████████████████████████████████▎        | 6193/7473 [00:46<00:09, 135.32it/s] 83%|██████████████████████████████████████████▎        | 6207/7473 [00:46<00:09, 135.54it/s] 83%|██████████████████████████████████████████▍        | 6221/7473 [00:47<00:09, 135.62it/s] 83%|██████████████████████████████████████████▌        | 6235/7473 [00:47<00:09, 135.73it/s] 84%|██████████████████████████████████████████▋        | 6249/7473 [00:47<00:08, 136.18it/s] 84%|██████████████████████████████████████████▋        | 6263/7473 [00:47<00:08, 135.14it/s] 84%|██████████████████████████████████████████▊        | 6277/7473 [00:47<00:08, 135.57it/s] 84%|██████████████████████████████████████████▉        | 6291/7473 [00:47<00:08, 135.48it/s] 84%|███████████████████████████████████████████        | 6305/7473 [00:47<00:08, 135.97it/s] 85%|███████████████████████████████████████████        | 6319/7473 [00:47<00:08, 135.73it/s] 85%|███████████████████████████████████████████▏       | 6333/7473 [00:47<00:08, 135.73it/s] 85%|███████████████████████████████████████████▎       | 6347/7473 [00:48<00:08, 135.87it/s] 85%|███████████████████████████████████████████▍       | 6361/7473 [00:48<00:08, 134.53it/s] 85%|███████████████████████████████████████████▌       | 6375/7473 [00:48<00:08, 134.43it/s] 85%|███████████████████████████████████████████▌       | 6389/7473 [00:48<00:08, 135.01it/s] 86%|███████████████████████████████████████████▋       | 6403/7473 [00:48<00:07, 135.23it/s] 86%|███████████████████████████████████████████▊       | 6417/7473 [00:48<00:07, 135.36it/s] 86%|███████████████████████████████████████████▉       | 6431/7473 [00:48<00:07, 135.08it/s] 86%|███████████████████████████████████████████▉       | 6445/7473 [00:48<00:07, 135.22it/s] 86%|████████████████████████████████████████████       | 6459/7473 [00:48<00:07, 135.01it/s] 87%|████████████████████████████████████████████▏      | 6473/7473 [00:48<00:07, 135.37it/s] 87%|████████████████████████████████████████████▎      | 6487/7473 [00:49<00:07, 135.55it/s] 87%|████████████████████████████████████████████▎      | 6501/7473 [00:49<00:07, 135.70it/s] 87%|████████████████████████████████████████████▍      | 6515/7473 [00:49<00:07, 135.26it/s] 87%|████████████████████████████████████████████▌      | 6529/7473 [00:49<00:06, 135.42it/s] 88%|████████████████████████████████████████████▋      | 6543/7473 [00:49<00:06, 135.47it/s] 88%|████████████████████████████████████████████▋      | 6557/7473 [00:49<00:06, 135.73it/s] 88%|████████████████████████████████████████████▊      | 6571/7473 [00:49<00:06, 135.01it/s] 88%|████████████████████████████████████████████▉      | 6585/7473 [00:49<00:06, 134.04it/s] 88%|█████████████████████████████████████████████      | 6599/7473 [00:49<00:06, 135.07it/s] 88%|█████████████████████████████████████████████▏     | 6613/7473 [00:49<00:06, 135.34it/s] 89%|█████████████████████████████████████████████▏     | 6627/7473 [00:50<00:06, 135.11it/s] 89%|█████████████████████████████████████████████▎     | 6641/7473 [00:50<00:06, 134.91it/s] 89%|█████████████████████████████████████████████▍     | 6655/7473 [00:50<00:06, 135.24it/s] 89%|█████████████████████████████████████████████▌     | 6669/7473 [00:50<00:05, 135.15it/s] 89%|█████████████████████████████████████████████▌     | 6683/7473 [00:50<00:05, 135.35it/s] 90%|█████████████████████████████████████████████▋     | 6697/7473 [00:50<00:05, 135.85it/s] 90%|█████████████████████████████████████████████▊     | 6711/7473 [00:50<00:05, 135.98it/s] 90%|█████████████████████████████████████████████▉     | 6725/7473 [00:50<00:05, 135.70it/s] 90%|█████████████████████████████████████████████▉     | 6739/7473 [00:50<00:05, 135.91it/s] 90%|██████████████████████████████████████████████     | 6753/7473 [00:51<00:05, 135.92it/s] 91%|██████████████████████████████████████████████▏    | 6767/7473 [00:51<00:05, 135.82it/s] 91%|██████████████████████████████████████████████▎    | 6781/7473 [00:51<00:05, 135.95it/s] 91%|██████████████████████████████████████████████▎    | 6795/7473 [00:51<00:04, 136.29it/s] 91%|██████████████████████████████████████████████▍    | 6809/7473 [00:51<00:04, 134.52it/s] 91%|██████████████████████████████████████████████▌    | 6823/7473 [00:51<00:04, 134.14it/s] 91%|██████████████████████████████████████████████▋    | 6837/7473 [00:51<00:04, 134.76it/s] 92%|██████████████████████████████████████████████▊    | 6851/7473 [00:51<00:04, 134.85it/s] 92%|██████████████████████████████████████████████▊    | 6865/7473 [00:51<00:04, 133.25it/s] 92%|██████████████████████████████████████████████▉    | 6879/7473 [00:51<00:04, 134.29it/s] 92%|███████████████████████████████████████████████    | 6893/7473 [00:52<00:04, 134.86it/s] 92%|███████████████████████████████████████████████▏   | 6907/7473 [00:52<00:04, 135.32it/s] 93%|███████████████████████████████████████████████▏   | 6921/7473 [00:52<00:04, 135.53it/s] 93%|███████████████████████████████████████████████▎   | 6935/7473 [00:52<00:03, 135.86it/s] 93%|███████████████████████████████████████████████▍   | 6949/7473 [00:52<00:03, 136.06it/s] 93%|███████████████████████████████████████████████▌   | 6963/7473 [00:52<00:03, 135.86it/s] 93%|███████████████████████████████████████████████▌   | 6977/7473 [00:52<00:03, 135.86it/s] 94%|███████████████████████████████████████████████▋   | 6991/7473 [00:52<00:03, 135.55it/s] 94%|███████████████████████████████████████████████▊   | 7005/7473 [00:52<00:03, 134.90it/s] 94%|███████████████████████████████████████████████▉   | 7019/7473 [00:52<00:03, 134.65it/s] 94%|███████████████████████████████████████████████▉   | 7033/7473 [00:53<00:03, 134.96it/s] 94%|████████████████████████████████████████████████   | 7047/7473 [00:53<00:03, 133.51it/s] 94%|████████████████████████████████████████████████▏  | 7061/7473 [00:53<00:03, 134.44it/s] 95%|████████████████████████████████████████████████▎  | 7075/7473 [00:53<00:02, 134.96it/s] 95%|████████████████████████████████████████████████▍  | 7089/7473 [00:53<00:02, 135.31it/s] 95%|████████████████████████████████████████████████▍  | 7103/7473 [00:53<00:02, 135.82it/s] 95%|████████████████████████████████████████████████▌  | 7117/7473 [00:53<00:02, 135.59it/s] 95%|████████████████████████████████████████████████▋  | 7131/7473 [00:53<00:02, 135.37it/s] 96%|████████████████████████████████████████████████▊  | 7145/7473 [00:53<00:02, 135.65it/s] 96%|████████████████████████████████████████████████▊  | 7159/7473 [00:54<00:02, 133.95it/s] 96%|████████████████████████████████████████████████▉  | 7173/7473 [00:54<00:02, 134.17it/s] 96%|█████████████████████████████████████████████████  | 7187/7473 [00:54<00:02, 134.43it/s] 96%|█████████████████████████████████████████████████▏ | 7201/7473 [00:54<00:02, 135.04it/s] 97%|█████████████████████████████████████████████████▏ | 7215/7473 [00:54<00:01, 135.39it/s] 97%|█████████████████████████████████████████████████▎ | 7229/7473 [00:54<00:01, 135.68it/s] 97%|█████████████████████████████████████████████████▍ | 7243/7473 [00:54<00:01, 136.02it/s] 97%|█████████████████████████████████████████████████▌ | 7257/7473 [00:54<00:01, 136.04it/s] 97%|█████████████████████████████████████████████████▌ | 7271/7473 [00:54<00:01, 134.05it/s] 97%|█████████████████████████████████████████████████▋ | 7285/7473 [00:55<00:01, 112.94it/s] 98%|█████████████████████████████████████████████████▊ | 7297/7473 [00:55<00:01, 105.46it/s] 98%|█████████████████████████████████████████████████▊ | 7308/7473 [00:55<00:01, 100.37it/s] 98%|██████████████████████████████████████████████████▉ | 7319/7473 [00:55<00:01, 97.09it/s] 98%|██████████████████████████████████████████████████▉ | 7329/7473 [00:55<00:01, 94.80it/s] 98%|███████████████████████████████████████████████████ | 7339/7473 [00:55<00:01, 93.12it/s] 98%|███████████████████████████████████████████████████▏| 7349/7473 [00:55<00:01, 92.08it/s] 98%|███████████████████████████████████████████████████▏| 7359/7473 [00:55<00:01, 91.14it/s] 99%|███████████████████████████████████████████████████▎| 7369/7473 [00:55<00:01, 90.37it/s] 99%|███████████████████████████████████████████████████▎| 7379/7473 [00:56<00:01, 89.82it/s] 99%|███████████████████████████████████████████████████▍| 7388/7473 [00:56<00:00, 89.79it/s] 99%|███████████████████████████████████████████████████▍| 7397/7473 [00:56<00:00, 88.48it/s] 99%|███████████████████████████████████████████████████▌| 7406/7473 [00:56<00:00, 88.67it/s] 99%|███████████████████████████████████████████████████▌| 7418/7473 [00:56<00:00, 97.26it/s] 99%|██████████████████████████████████████████████████▋| 7432/7473 [00:56<00:00, 108.63it/s]100%|██████████████████████████████████████████████████▊| 7446/7473 [00:56<00:00, 116.54it/s]100%|██████████████████████████████████████████████████▉| 7460/7473 [00:56<00:00, 121.29it/s]100%|███████████████████████████████████████████████████| 7473/7473 [00:56<00:00, 131.37it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.29s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.56s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.50s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.88s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.19s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.52s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.45s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.94s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.67s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.82s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.91s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.08s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.85s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.02s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:16<00:00,  5.45s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:16<00:00,  5.58s/it]
[2023-08-13 04:41:17,734] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-13 04:41:29,185] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-13 04:41:29,186] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-13 04:41:29,187] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-13 04:41:29,187] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-13 04:41:29,187] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-13 04:41:29,187] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-13 04:41:29,187] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-13 04:41:29,187] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-13 04:41:29,187] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-13 04:41:29,187] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-13 04:41:29,187] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-13 04:41:29,187] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fd5c2dd8490>
[2023-08-13 04:41:29,187] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-13 04:41:29,187] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-13 04:41:29,187] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-13 04:41:29,187] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-13 04:41:29,187] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-13 04:41:29,187] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-13 04:41:29,187] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-13 04:41:29,187] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-13 04:41:29,187] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-13 04:41:29,187] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-13 04:41:29,187] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-13 04:41:29,187] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-13 04:41:29,187] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-13 04:41:29,187] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-13 04:41:29,187] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-13 04:41:29,187] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-13 04:41:29,187] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-13 04:41:29,187] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fd582e2b0a0>
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-13 04:41:29,188] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-13 04:41:29,188] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.7907075881958008 seconds
Loading extension module utils...
Time to load utils op: 0.8049216270446777 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Loading extension module utils...
Time to load utils op: 0.7047951221466064 seconds
Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Fabric is cut to order at what type of seller? Choices:  A: curtains B: tailor shop C: clothing store D: sewing room E: hardware store
Rationales: 1. The question asks where fabric is customarily cut to order. This means we're looking for a place where fabric is typically cut based on individual, specific requirements.
2. We can start by eliminating choices that are obviously incorrect. 
3. Curtains (Choice A) could be made from fabric but are not places where fabric is cut.
4. Clothing store (Choice C) typically sell factory-made clothes instead of custom, made to order pieces; they generally don’t cut fabric to fit the customer's personal needs.
5. A hardware store (Choice E) generally sells hardware, tools, or other heavy-duty items, not fabric.
6. A sewing room (Choice D) may be a place where someone cuts fabric to order, but it can be a private or personal space, not a location where one can go to have their fabric cut professionally.
7. This leaves us with Choice B, a tailor shop, which indeed is a place where fabric is customarily cut to fit individual requirements or orders. Tailors provide services of adjusting clothing to fit the customer's measurements accurately, which involves cutting and altering fabric.
8. Hence, the answer is B: tailor shop.
Answer: B: tailor shop

Input: Where are you if your reading magazines while waiting for a vehicle on rails? Choices:  A: vegetables B: market C: doctor D: train station E: bookstore
Rationales: Step 1: The sentence implies that the location is associated with "waiting for a vehicle on rails". 
Step 2: Resolve "vehicle on rails" - this is typically used to describe a train. 
Step 3: Now check where one waits for a train. The answer is a train station. 
Step 4: The answer is therefore D: train station as none of the other options typically have areas where you wait for a train.
Answer: D: train station

Input: What would need oil to be used? Choices:  A: ground B: human  body C: repair shop D: combustion engines E: service station
Rationales: 1. The first step is to understand what the question is asking. We need to determine which of the available options would require the use of oil. 
2. Then, we need to consider each of the choices one by one.
3. Starting with choice A: oil is not needed by the ground. It might be used in some treatments for soil, but it's not a prime requirement. So, this option is unlikely.
4. Now, considering choice B: human body. Some oils are indeed used for various health and beauty purposes, but the human body doesn't require oil to function, thus this choice can also be excluded.
5. Moving on to choice C: repair shop. Although oil might be used frequently in a repair shop, it's used for servicing the machines and vehicles brought in, and not necessary for the basic functionality of the shop itself. So, this choice is less likely to be the correct one.  
6. Choice D: combustion engines. Oil is essential for the functioning of a combustion engine. It lubricates the moving parts of the engine, preventing them from overheating due to friction. So, this choice is a probable answer.
7. Last choice is E: service station. Similar to the repair shop, while a service station would likely have and use oil, it's not specifically required for the operation of a service station itself.
8. Comparing all the choices, combustion engines are the only option that require oil for operation and performance.
9. Therefore, the correct answer is D: combustion engines.
Answer: D: combustion engines

Input: What is person probably feeling that plans on stopping being married to their spouse? Choices:  A: detachment B: bankruptcy C: sad D: fights E: wrong
Rationales: 1. The first step is to understand the question. The phrase "plans on stopping being married to their spouse" refers to a person who intends to initiate a divorce or separation.
2. The next step is to associate this situation with the possible emotions or states a person may experience. 
3. Bankruptcy (choice B) is not necessarily connected to divorce or separation, while choice D, fights, and choice E, wrong, are situational and not emotions.
4. While it's true that sadness (choice C) is a common emotion related to divorce or separation, it's not always the prevailing emotion, as some may feel relief or freedom. 
5. Detachment (choice A) makes the most sense as the probable feeling as it implies a person is emotionally divesting themselves from a relationship, which aligns with the decision to end a marriage. 
6. Therefore, the best answer is A: Detachment.
Answer: A: detachment

Input: What could you use to store a clock? Choices:  A: shelf B: own bedroom C: desk D: wall E: car
Rationales: 1. The question asks where one can store a clock.
2. Clocks are typically small objects that can be placed or hung in various areas.
3. "Own Bedroom" could be a location to place a clock, but it would require a specific place within the bedroom, like a desk or a wall, to store it, so B is not the correct answer.
4. A "car" is usually not a place where a clock is stored, so E cannot be the right answer.
5. A "desk" or a "wall" could be places to keep a clock, but they are not storage places in a traditional sense.
6. A "shelf" can be used to store various objects including a clock, making it a suitable place to keep a clock.
7. Therefore, the answer is A: shelf.
Answer: A: shelf

Input: The person put on lotion, what did they want? Choices:  A: fresh smell B: good credit C: smooth skin D: fresh produce E: headache
Rationales: 1. The question asks us to consider what someone would want after applying lotion.
2. The answer should represent a common result or benefit of using lotion.
3. We consider each option: fresh smell, good credit, smooth skin, fresh produce, and headache.
4. Fresh smell could be a result of using lotion, but other products such as perfume are more commonly associated with this benefit. Therefore, this option doesn't seem like the best fit.
5. Good credit is not a result of using lotion. It is related to financial management, so we can eliminate this option.
6. Smooth skin is a common result of using lotion, making it a plausible answer.
7. Fresh produce and headaches are not related to using lotion in any way, so we can eliminate these options.
8. Therefore, the answer is C: smooth skin; this is the most common reason for someone to use lotion.
Answer: C: smooth skin

Input: They burned the record, they were trying to do what to history? Choices:  A: compact disc B: tape C: rewrite D: play music E: erase
Rationales: 1. First, understand the question. The phrase "they burned the record" does not literally mean a physical record being burned. It is actually a metaphor meaning removing evidence or traces of past events. 
2. Now, interpret the possible answer choices. It's important to remember that we're looking at what one does to history, not to a physical record. 
3. Option A: compact disc. This is not applicable as the literal meaning of record doesn't apply here.
4. Option B: tape. Again, this has the same problem as option A. It does not fit the metaphorical meaning of "record." 
5. Option C: rewrite. This could be a possible answer, as burning the old record could imply creating a new, different one. However, the phrase "trying to do" suggests intention, and simply burning the record does not confirm the intention of rewriting.
6. Option D: play music. This is not relevant to the metaphorical meaning of "record" in this context.
7. Option E: erase. Erasing history is the metaphorical equivalent of burning a record. It's removing all traces of past events. This fits the most with the intention implied in the phrase "they were trying to do." Therefore, E: erase is the correct answer.
Answer: E: erase

Input: She sure didn't have a green thumb, every time she thought she
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o9-tcommonsenseqa-s10-rTrue
Loading extension module utils...
Time to load utils op: 0.8065941333770752 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:42<34:24, 42.14s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:23<33:15, 41.57s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:04<32:24, 41.38s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [02:45<31:40, 41.32s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [03:26<30:57, 41.27s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [04:08<30:14, 41.25s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [04:49<29:33, 41.24s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [05:30<28:52, 41.24s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [06:11<28:10, 41.22s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [06:52<27:28, 41.20s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [07:34<26:46, 41.19s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [08:15<26:04, 41.17s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [08:56<25:24, 41.20s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [09:37<24:43, 41.22s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [10:18<24:01, 41.18s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [10:59<23:20, 41.18s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [11:41<22:38, 41.17s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [12:22<21:57, 41.17s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [13:03<21:15, 41.14s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [13:44<20:33, 41.13s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [14:25<19:52, 41.13s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [15:06<19:11, 41.12s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [15:48<18:31, 41.17s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [16:29<17:49, 41.13s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [17:10<17:08, 41.15s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [17:51<16:28, 41.18s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [18:32<15:45, 41.13s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [19:13<15:05, 41.15s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [19:54<14:24, 41.14s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [20:35<13:42, 41.11s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [21:17<13:01, 41.14s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [21:58<12:20, 41.12s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [22:39<11:38, 41.09s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [23:20<10:56, 41.03s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [24:01<10:15, 41.06s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [24:42<09:36, 41.15s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [25:23<08:55, 41.21s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [26:04<08:14, 41.18s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [26:46<07:33, 41.23s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [27:27<06:52, 41.21s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [28:08<06:11, 41.23s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [28:50<05:30, 41.26s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [29:31<04:48, 41.24s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [30:12<04:07, 41.30s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [30:54<03:26, 41.32s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [31:35<02:45, 41.28s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [32:16<02:03, 41.31s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [32:57<01:22, 41.30s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [33:39<00:41, 41.29s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [34:20<00:00, 41.30s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [34:20<00:00, 41.21s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.0671} | lm_loss 11.96 | avg. gen lenth: 451.324
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o1-tcommonsenseqa-s10-rFalse --seed 10 --num-out-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-13 05:16:34,606] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o1-tcommonsenseqa-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 1
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o1-tcommonsenseqa-s10-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  3%|█▍                                                 | 210/7473 [00:00<00:03, 2098.48it/s]  6%|██▊                                                | 421/7473 [00:00<00:03, 2101.20it/s]  8%|████▎                                              | 632/7473 [00:00<00:03, 2104.95it/s] 11%|█████▊                                             | 847/7473 [00:00<00:03, 2122.23it/s] 14%|███████                                           | 1064/7473 [00:00<00:02, 2136.72it/s] 17%|████████▌                                         | 1278/7473 [00:00<00:02, 2127.40it/s] 20%|█████████▉                                        | 1491/7473 [00:00<00:02, 2128.00it/s] 23%|███████████▍                                      | 1704/7473 [00:00<00:02, 2125.30it/s] 26%|████████████▊                                     | 1917/7473 [00:00<00:02, 2069.25it/s] 28%|██████████████▏                                   | 2128/7473 [00:01<00:02, 2079.31it/s] 31%|███████████████▋                                  | 2342/7473 [00:01<00:02, 2097.28it/s] 34%|█████████████████                                 | 2552/7473 [00:01<00:02, 2061.77it/s] 37%|██████████████████▌                               | 2769/7473 [00:01<00:02, 2092.37it/s] 40%|███████████████████▉                              | 2987/7473 [00:01<00:02, 2118.34it/s] 43%|█████████████████████▍                            | 3200/7473 [00:01<00:02, 2111.65it/s] 46%|██████████████████████▊                           | 3412/7473 [00:01<00:01, 2109.86it/s] 49%|████████████████████████▎                         | 3625/7473 [00:01<00:01, 2114.28it/s] 51%|█████████████████████████▋                        | 3837/7473 [00:01<00:01, 2109.29it/s] 54%|███████████████████████████                       | 4050/7473 [00:01<00:01, 2113.73it/s] 57%|████████████████████████████▌                     | 4262/7473 [00:02<00:01, 2105.78it/s] 60%|█████████████████████████████▉                    | 4474/7473 [00:02<00:01, 2107.20it/s] 63%|███████████████████████████████▎                  | 4686/7473 [00:02<00:01, 2110.76it/s] 66%|████████████████████████████████▊                 | 4898/7473 [00:02<00:01, 2112.71it/s] 68%|██████████████████████████████████▏               | 5114/7473 [00:02<00:01, 2126.62it/s] 73%|████████████████████████████████████▎             | 5423/7473 [00:02<00:00, 2414.33it/s] 76%|█████████████████████████████████████▉            | 5665/7473 [00:02<00:00, 2210.95it/s] 80%|████████████████████████████████████████          | 5982/7473 [00:02<00:00, 2479.67it/s] 84%|██████████████████████████████████████████▏       | 6308/7473 [00:02<00:00, 2702.63it/s] 89%|████████████████████████████████████████████▎     | 6630/7473 [00:02<00:00, 2851.71it/s] 93%|██████████████████████████████████████████████▌   | 6951/7473 [00:03<00:00, 2955.62it/s] 97%|████████████████████████████████████████████████▋ | 7270/7473 [00:03<00:00, 3023.54it/s]100%|██████████████████████████████████████████████████| 7473/7473 [00:03<00:00, 2321.43it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.16s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.32s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.53s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.59s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.05s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.33s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.33s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.52s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.45s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.62s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.64s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.83s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.63s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.85s/it]
[2023-08-13 05:17:29,625] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.83s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.01s/it]
[2023-08-13 05:17:46,738] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-13 05:17:46,739] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-13 05:17:46,739] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-13 05:17:46,739] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-13 05:17:46,739] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-13 05:17:46,739] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f651d9fcb20>
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f651d9fc8b0>
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-13 05:17:46,740] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-13 05:17:46,741] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-13 05:17:46,741] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-13 05:17:46,741] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-13 05:17:46,741] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-13 05:17:46,741] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-13 05:17:46,741] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-13 05:17:46,741] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-13 05:17:46,741] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-13 05:17:46,741] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-13 05:17:46,741] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-13 05:17:46,741] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-13 05:17:46,741] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-13 05:17:46,741] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.3652069568634033 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Fabric is cut to order at what type of seller? Choices:  A: curtains B: tailor shop C: clothing store D: sewing room E: hardware store
Answer: B: tailor shop

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o1-tcommonsenseqa-s10-rFalse
Loading extension module utils...
Time to load utils op: 0.40578579902648926 seconds
Loading extension module utils...
Time to load utils op: 0.3041834831237793 seconds
Loading extension module utils...
Time to load utils op: 0.3044559955596924 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:58<47:36, 58.29s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:54<45:49, 57.28s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:52<44:53, 57.30s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [03:49<43:49, 57.15s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [04:46<43:03, 57.41s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [05:38<40:34, 55.34s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [06:22<37:06, 51.78s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [07:20<37:40, 53.82s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [08:17<37:27, 54.81s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [09:01<34:12, 51.32s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [09:59<34:37, 53.27s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [10:55<34:22, 54.28s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [11:53<34:03, 55.23s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [12:50<33:27, 55.77s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [13:48<32:55, 56.43s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [14:18<27:32, 48.61s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [15:16<28:12, 51.28s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [15:38<22:41, 42.56s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [16:36<24:25, 47.26s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [16:59<20:01, 40.07s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [17:37<18:58, 39.28s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [18:34<20:47, 44.54s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [19:14<19:32, 43.43s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [19:55<18:25, 42.53s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [20:52<19:33, 46.93s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [21:33<17:59, 45.00s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [22:28<18:25, 48.06s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [23:02<16:09, 44.06s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [23:37<14:26, 41.27s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [24:15<13:23, 40.20s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [24:55<12:41, 40.10s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [25:51<13:29, 44.97s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [26:48<13:45, 48.58s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [27:02<10:12, 38.25s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [28:00<11:03, 44.21s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [28:58<11:16, 48.36s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [29:42<10:10, 46.93s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [30:33<09:39, 48.26s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [31:30<09:17, 50.67s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [32:02<07:31, 45.11s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [33:00<07:21, 49.02s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [33:57<06:51, 51.49s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [34:56<06:15, 53.58s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [35:45<05:13, 52.31s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [36:42<04:28, 53.71s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [37:37<03:36, 54.21s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [38:13<02:26, 48.77s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [38:42<01:25, 42.56s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [39:38<00:46, 46.64s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [40:34<00:00, 49.65s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [40:34<00:00, 48.70s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.2123} | lm_loss 9.7666 | avg. gen lenth: 208.872
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o2-tcommonsenseqa-s10-rFalse --seed 10 --num-out-domain 2
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-13 05:58:28,475] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o2-tcommonsenseqa-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 2
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o2-tcommonsenseqa-s10-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  2%|█▏                                                 | 166/7473 [00:00<00:04, 1659.16it/s]  4%|██▎                                                | 336/7473 [00:00<00:04, 1681.02it/s]  7%|███▍                                               | 505/7473 [00:00<00:04, 1665.48it/s]  9%|████▌                                              | 676/7473 [00:00<00:04, 1680.64it/s] 11%|█████▊                                             | 848/7473 [00:00<00:03, 1693.29it/s] 14%|██████▊                                           | 1020/7473 [00:00<00:03, 1698.93it/s] 16%|███████▉                                          | 1190/7473 [00:00<00:03, 1698.33it/s] 18%|█████████                                         | 1361/7473 [00:00<00:03, 1701.22it/s] 21%|██████████▎                                       | 1532/7473 [00:00<00:03, 1694.94it/s] 23%|███████████▍                                      | 1702/7473 [00:01<00:03, 1646.98it/s] 25%|████████████▌                                     | 1869/7473 [00:01<00:03, 1650.77it/s] 27%|█████████████▋                                    | 2038/7473 [00:01<00:03, 1658.47it/s] 30%|██████████████▊                                   | 2207/7473 [00:01<00:03, 1665.26it/s] 32%|███████████████▉                                  | 2376/7473 [00:01<00:03, 1670.21it/s] 34%|█████████████████                                 | 2544/7473 [00:01<00:03, 1634.46it/s] 36%|██████████████████▏                               | 2717/7473 [00:01<00:02, 1660.73it/s] 39%|███████████████████▎                              | 2888/7473 [00:01<00:02, 1672.81it/s] 41%|████████████████████▍                             | 3061/7473 [00:01<00:02, 1688.18it/s] 43%|█████████████████████▌                            | 3230/7473 [00:01<00:02, 1673.98it/s] 45%|██████████████████████▋                           | 3398/7473 [00:02<00:02, 1669.98it/s] 48%|███████████████████████▊                          | 3566/7473 [00:02<00:02, 1668.00it/s] 50%|████████████████████████▉                         | 3733/7473 [00:02<00:02, 1660.32it/s] 52%|██████████████████████████                        | 3900/7473 [00:02<00:02, 1662.35it/s] 54%|███████████████████████████▏                      | 4070/7473 [00:02<00:02, 1672.95it/s] 57%|████████████████████████████▍                     | 4250/7473 [00:02<00:01, 1709.44it/s] 60%|██████████████████████████████                    | 4502/7473 [00:02<00:01, 1949.74it/s] 64%|███████████████████████████████▊                  | 4756/7473 [00:02<00:01, 2124.79it/s] 67%|█████████████████████████████████▌                | 5010/7473 [00:02<00:01, 2247.26it/s] 70%|███████████████████████████████████▏              | 5253/7473 [00:02<00:00, 2298.85it/s] 73%|████████████████████████████████████▋             | 5483/7473 [00:03<00:01, 1812.38it/s] 77%|██████████████████████████████████████▍           | 5737/7473 [00:03<00:00, 1982.10it/s] 80%|████████████████████████████████████████          | 5983/7473 [00:03<00:00, 2105.98it/s] 83%|█████████████████████████████████████████▋        | 6236/7473 [00:03<00:00, 2220.22it/s] 87%|███████████████████████████████████████████▍      | 6489/7473 [00:03<00:00, 2307.01it/s] 90%|█████████████████████████████████████████████     | 6740/7473 [00:03<00:00, 2363.02it/s] 94%|██████████████████████████████████████████████▊   | 6991/7473 [00:03<00:00, 2405.37it/s] 97%|████████████████████████████████████████████████▍ | 7241/7473 [00:03<00:00, 2431.16it/s]100%|██████████████████████████████████████████████████| 7473/7473 [00:03<00:00, 1904.68it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:04<00:09,  4.95s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.91s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.66s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.61s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.01s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.55s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.47s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.36s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.53s/it]
Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.50s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.00s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.18s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.82s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.02s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.94s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.10s/it]
[2023-08-13 05:59:28,235] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-13 05:59:37,910] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-13 05:59:37,911] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-13 05:59:37,911] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-13 05:59:37,911] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-13 05:59:37,911] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-13 05:59:37,911] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fed2510ab20>
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-13 05:59:37,912] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-13 05:59:37,913] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-13 05:59:37,913] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-13 05:59:37,913] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-13 05:59:37,913] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-13 05:59:37,913] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-13 05:59:37,913] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-13 05:59:37,913] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fed2510af10>
[2023-08-13 05:59:37,913] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-13 05:59:37,913] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-13 05:59:37,913] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-13 05:59:37,913] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-13 05:59:37,913] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-13 05:59:37,913] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-13 05:59:37,913] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-13 05:59:37,913] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-13 05:59:37,913] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-13 05:59:37,913] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-13 05:59:37,913] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-13 05:59:37,913] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-13 05:59:37,913] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-13 05:59:37,913] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-13 05:59:37,913] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-13 05:59:37,913] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-13 05:59:37,913] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-13 05:59:37,913] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-13 05:59:37,913] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-13 05:59:37,913] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-13 05:59:37,913] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-13 05:59:37,913] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-13 05:59:37,913] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.37942981719970703 seconds
Loading extension module utils...
Time to load utils op: 0.30437636375427246 seconds
Loading extension module utils...
Time to load utils op: 0.40482401847839355 seconds
Loading extension module utils...
Time to load utils op: 0.40457820892333984 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Fabric is cut to order at what type of seller? Choices:  A: curtains B: tailor shop C: clothing store D: sewing room E: hardware store
Answer: B: tailor shop

Input: Where are you if your reading magazines while waiting for a vehicle on rails? Choices:  A: vegetables B: market C: doctor D: train station E: bookstore
Answer: D: train station

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o2-tcommonsenseqa-s10-rFalse
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:57<46:41, 57.17s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:53<45:22, 56.71s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:50<44:20, 56.60s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [03:45<43:10, 56.31s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [04:37<40:54, 54.54s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [04:55<30:49, 42.04s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [05:22<26:36, 37.13s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [05:45<22:58, 32.83s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [06:38<26:36, 38.94s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [07:35<29:40, 44.52s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [08:31<31:19, 48.19s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [08:58<26:25, 41.73s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [09:44<26:29, 42.97s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [10:01<21:04, 35.11s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [10:57<24:14, 41.56s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [11:28<21:45, 38.40s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [12:26<24:16, 44.13s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [13:22<25:31, 47.87s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [13:58<22:44, 44.03s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [14:42<22:09, 44.31s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [15:25<21:05, 43.64s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [15:55<18:34, 39.80s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [16:15<15:11, 33.74s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [17:08<17:06, 39.49s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [18:05<18:39, 44.78s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [19:02<19:20, 48.37s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [20:00<19:37, 51.20s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [20:57<19:29, 53.18s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [21:53<18:52, 53.95s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [22:50<18:18, 54.92s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [23:47<17:32, 55.39s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [24:17<14:19, 47.77s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [25:13<14:14, 50.29s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [26:06<13:40, 51.26s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [27:01<13:05, 52.38s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [27:58<12:29, 53.56s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [28:37<10:41, 49.38s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [29:23<09:39, 48.27s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [29:34<06:48, 37.13s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [30:31<07:10, 43.00s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [31:27<07:01, 46.87s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [31:50<05:17, 39.70s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [32:37<04:53, 41.88s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [33:33<04:37, 46.29s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [34:28<04:03, 48.71s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [35:24<03:23, 50.98s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [36:13<02:30, 50.25s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [37:09<01:44, 52.18s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [38:05<00:53, 53.33s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [38:41<00:00, 48.11s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [38:41<00:00, 46.43s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.6587} | lm_loss 9.6674 | avg. gen lenth: 200.456
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o3-tcommonsenseqa-s10-rFalse --seed 10 --num-out-domain 3
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date![nltk_data]   Package punkt is already up-to-date!

[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-13 06:38:27,572] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o3-tcommonsenseqa-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 3
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o3-tcommonsenseqa-s10-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  2%|▉                                                  | 139/7473 [00:00<00:05, 1383.38it/s]  4%|█▉                                                 | 281/7473 [00:00<00:05, 1399.86it/s]  6%|██▉                                                | 422/7473 [00:00<00:05, 1403.19it/s]  8%|███▊                                               | 564/7473 [00:00<00:04, 1406.84it/s]  9%|████▊                                              | 706/7473 [00:00<00:04, 1407.93it/s] 11%|█████▊                                             | 848/7473 [00:00<00:04, 1411.71it/s] 13%|██████▊                                            | 992/7473 [00:00<00:04, 1418.98it/s] 15%|███████▌                                          | 1135/7473 [00:00<00:04, 1422.00it/s] 17%|████████▌                                         | 1278/7473 [00:00<00:04, 1389.73it/s] 19%|█████████▍                                        | 1418/7473 [00:01<00:04, 1392.20it/s] 21%|██████████▍                                       | 1560/7473 [00:01<00:04, 1398.21it/s] 23%|███████████▎                                      | 1700/7473 [00:01<00:04, 1397.85it/s] 25%|████████████▎                                     | 1840/7473 [00:01<00:04, 1394.07it/s] 26%|█████████████▏                                    | 1980/7473 [00:01<00:03, 1394.57it/s] 28%|██████████████▏                                   | 2121/7473 [00:01<00:03, 1395.94it/s] 30%|███████████████▏                                  | 2263/7473 [00:01<00:03, 1400.85it/s] 32%|████████████████                                  | 2405/7473 [00:01<00:03, 1403.92it/s] 34%|█████████████████                                 | 2546/7473 [00:01<00:03, 1367.14it/s] 36%|█████████████████▉                                | 2688/7473 [00:01<00:03, 1382.13it/s] 38%|██████████████████▉                               | 2831/7473 [00:02<00:03, 1393.93it/s] 40%|███████████████████▉                              | 2974/7473 [00:02<00:03, 1402.71it/s] 42%|████████████████████▊                             | 3115/7473 [00:02<00:03, 1400.98it/s] 44%|█████████████████████▉                            | 3284/7473 [00:02<00:02, 1485.84it/s] 47%|███████████████████████▍                          | 3495/7473 [00:02<00:02, 1670.41it/s] 50%|████████████████████████▊                         | 3708/7473 [00:02<00:02, 1806.30it/s] 52%|██████████████████████████▏                       | 3922/7473 [00:02<00:01, 1904.29it/s] 55%|███████████████████████████▋                      | 4134/7473 [00:02<00:01, 1967.47it/s] 58%|█████████████████████████████                     | 4348/7473 [00:02<00:01, 2017.14it/s] 61%|██████████████████████████████▌                   | 4561/7473 [00:02<00:01, 2048.67it/s] 64%|███████████████████████████████▉                  | 4775/7473 [00:03<00:01, 2074.63it/s] 67%|█████████████████████████████████▍                | 4989/7473 [00:03<00:01, 2092.34it/s] 70%|██████████████████████████████████▊               | 5205/7473 [00:03<00:01, 2110.83it/s] 72%|████████████████████████████████████▏             | 5417/7473 [00:03<00:00, 2075.57it/s] 75%|█████████████████████████████████████▋            | 5625/7473 [00:03<00:01, 1631.33it/s] 78%|███████████████████████████████████████           | 5836/7473 [00:03<00:00, 1748.74it/s] 81%|████████████████████████████████████████▍         | 6048/7473 [00:03<00:00, 1844.25it/s] 84%|█████████████████████████████████████████▉        | 6264/7473 [00:03<00:00, 1929.64it/s] 87%|███████████████████████████████████████████▎      | 6476/7473 [00:03<00:00, 1981.12it/s] 89%|████████████████████████████████████████████▋     | 6688/7473 [00:04<00:00, 2018.71it/s] 92%|██████████████████████████████████████████████▏   | 6900/7473 [00:04<00:00, 2047.84it/s] 95%|███████████████████████████████████████████████▌  | 7114/7473 [00:04<00:00, 2071.70it/s] 98%|█████████████████████████████████████████████████ | 7329/7473 [00:04<00:00, 2091.82it/s]100%|██████████████████████████████████████████████████| 7473/7473 [00:04<00:00, 1698.97it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.35s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.29s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.36s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.96s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.14s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.21s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.18s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:13<00:07,  7.03s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.49s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.70s/it]
[2023-08-13 06:39:23,221] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.55s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.74s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.59s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.76s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:19<00:00,  6.37s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:19<00:00,  6.44s/it]
[2023-08-13 06:39:38,283] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-13 06:39:38,284] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-13 06:39:38,284] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-13 06:39:38,284] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-13 06:39:38,284] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-13 06:39:38,284] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-13 06:39:38,285] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-13 06:39:38,285] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-13 06:39:38,285] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-13 06:39:38,285] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-13 06:39:38,285] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-13 06:39:38,285] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f18b9d07b20>
[2023-08-13 06:39:38,285] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-13 06:39:38,285] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-13 06:39:38,285] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-13 06:39:38,285] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-13 06:39:38,285] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-13 06:39:38,285] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-13 06:39:38,285] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-13 06:39:38,285] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-13 06:39:38,285] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-13 06:39:38,285] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-13 06:39:38,285] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-13 06:39:38,285] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-13 06:39:38,285] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-13 06:39:38,285] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f18b9d078b0>
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-13 06:39:38,286] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-13 06:39:38,287] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-13 06:39:38,287] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-13 06:39:38,287] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-13 06:39:38,287] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-13 06:39:38,287] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-13 06:39:38,287] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.39920902252197266 seconds
Loading extension module utils...
Loading extension module utils...
Time to load utils op: 0.40471673011779785 seconds
Time to load utils op: 0.4046201705932617 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Loading extension module utils...
Time to load utils op: 0.4043147563934326 seconds
Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Fabric is cut to order at what type of seller? Choices:  A: curtains B: tailor shop C: clothing store D: sewing room E: hardware store
Answer: B: tailor shop

Input: Where are you if your reading magazines while waiting for a vehicle on rails? Choices:  A: vegetables B: market C: doctor D: train station E: bookstore
Answer: D: train station

Input: What would need oil to be used? Choices:  A: ground B: human  body C: repair shop D: combustion engines E: service station
Answer: D: combustion engines

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o3-tcommonsenseqa-s10-rFalse
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:56<46:27, 56.88s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:34<36:18, 45.39s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:31<39:40, 50.64s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [03:26<40:11, 52.42s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [04:19<39:33, 52.75s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [05:11<38:23, 52.35s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [06:07<38:26, 53.63s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [06:21<28:48, 41.17s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [07:18<31:28, 46.06s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [07:54<28:29, 42.74s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [08:42<28:55, 44.49s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [08:56<22:17, 35.20s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [09:28<21:04, 34.16s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [10:24<24:33, 40.94s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [11:20<26:25, 45.30s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [12:15<27:26, 48.42s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [13:06<26:55, 48.94s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [13:22<20:55, 39.23s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [14:11<21:46, 42.15s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [14:58<21:51, 43.72s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [15:55<22:57, 47.51s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [16:35<21:07, 45.29s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [17:32<21:55, 48.71s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [18:26<21:53, 50.52s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [19:21<21:36, 51.86s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [20:17<21:10, 52.92s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [21:12<20:35, 53.71s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [21:50<17:52, 48.77s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [22:09<13:56, 39.83s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [23:04<14:52, 44.61s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [24:01<15:14, 48.14s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [24:55<15:02, 50.12s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [25:13<11:27, 40.42s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [25:44<10:00, 37.54s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [26:25<09:40, 38.67s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [27:22<10:16, 44.06s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [27:45<08:12, 37.86s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [28:42<08:40, 43.35s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [29:15<07:23, 40.36s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [30:11<07:29, 44.99s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [30:52<06:35, 43.92s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [31:48<06:20, 47.53s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [32:44<05:50, 50.14s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [33:07<04:10, 41.79s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [34:01<03:48, 45.69s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [34:56<03:13, 48.40s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [35:53<02:32, 50.86s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [36:48<01:44, 52.33s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [37:43<00:53, 53.13s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [38:12<00:00, 45.84s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [38:12<00:00, 45.86s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.3998} | lm_loss 9.6026 | avg. gen lenth: 184.14
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o4-tcommonsenseqa-s10-rFalse --seed 10 --num-out-domain 4
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-13 07:18:01,386] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o4-tcommonsenseqa-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 4
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o4-tcommonsenseqa-s10-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  2%|▊                                                  | 120/7473 [00:00<00:06, 1192.61it/s]  3%|█▋                                                 | 242/7473 [00:00<00:05, 1208.14it/s]  5%|██▍                                                | 363/7473 [00:00<00:05, 1208.23it/s]  6%|███▎                                               | 484/7473 [00:00<00:05, 1202.50it/s]  8%|████▏                                              | 606/7473 [00:00<00:05, 1208.07it/s] 10%|████▉                                              | 729/7473 [00:00<00:05, 1215.26it/s] 11%|█████▊                                             | 851/7473 [00:00<00:05, 1216.20it/s] 13%|██████▋                                            | 974/7473 [00:00<00:05, 1219.77it/s] 15%|███████▎                                          | 1096/7473 [00:00<00:05, 1202.14it/s] 16%|████████▏                                         | 1217/7473 [00:01<00:05, 1201.73it/s] 18%|████████▉                                         | 1339/7473 [00:01<00:05, 1206.81it/s] 20%|█████████▊                                        | 1460/7473 [00:01<00:04, 1204.20it/s] 21%|██████████▌                                       | 1582/7473 [00:01<00:04, 1206.02it/s] 23%|███████████▍                                      | 1704/7473 [00:01<00:04, 1208.58it/s] 24%|████████████▏                                     | 1825/7473 [00:01<00:04, 1208.79it/s] 26%|█████████████                                     | 1946/7473 [00:01<00:04, 1204.51it/s] 28%|█████████████▊                                    | 2068/7473 [00:01<00:04, 1206.36it/s] 29%|██████████████▋                                   | 2190/7473 [00:01<00:04, 1208.27it/s] 31%|███████████████▍                                  | 2311/7473 [00:01<00:04, 1206.35it/s] 33%|████████████████▎                                 | 2433/7473 [00:02<00:04, 1210.03it/s] 34%|█████████████████                                 | 2555/7473 [00:02<00:04, 1176.75it/s] 36%|█████████████████▉                                | 2679/7473 [00:02<00:04, 1193.30it/s] 37%|██████████████████▋                               | 2801/7473 [00:02<00:03, 1199.05it/s] 39%|███████████████████▌                              | 2923/7473 [00:02<00:03, 1205.19it/s] 41%|████████████████████▎                             | 3045/7473 [00:02<00:03, 1209.16it/s] 42%|█████████████████████▏                            | 3166/7473 [00:02<00:03, 1206.43it/s] 45%|██████████████████████▍                           | 3345/7473 [00:02<00:02, 1378.05it/s] 47%|███████████████████████▌                          | 3528/7473 [00:02<00:02, 1511.76it/s] 50%|████████████████████████▊                         | 3710/7473 [00:02<00:02, 1603.37it/s] 52%|██████████████████████████                        | 3893/7473 [00:03<00:02, 1670.55it/s] 55%|███████████████████████████▎                      | 4079/7473 [00:03<00:01, 1725.83it/s] 57%|████████████████████████████▍                     | 4256/7473 [00:03<00:01, 1738.60it/s] 59%|█████████████████████████████▋                    | 4440/7473 [00:03<00:01, 1766.74it/s] 62%|██████████████████████████████▉                   | 4624/7473 [00:03<00:01, 1788.59it/s] 64%|████████████████████████████████▏                 | 4807/7473 [00:03<00:01, 1800.96it/s] 67%|█████████████████████████████████▍                | 4992/7473 [00:03<00:01, 1812.95it/s] 69%|██████████████████████████████████▋               | 5177/7473 [00:03<00:01, 1821.52it/s] 72%|███████████████████████████████████▊              | 5360/7473 [00:03<00:01, 1786.92it/s] 74%|█████████████████████████████████████             | 5539/7473 [00:03<00:01, 1519.30it/s] 77%|██████████████████████████████████████▎           | 5721/7473 [00:04<00:01, 1598.49it/s] 79%|███████████████████████████████████████▍          | 5903/7473 [00:04<00:00, 1658.29it/s] 81%|████████████████████████████████████████▋         | 6085/7473 [00:04<00:00, 1703.05it/s] 84%|█████████████████████████████████████████▉        | 6268/7473 [00:04<00:00, 1739.01it/s] 86%|███████████████████████████████████████████       | 6445/7473 [00:04<00:00, 1739.79it/s] 89%|████████████████████████████████████████████▎     | 6628/7473 [00:04<00:00, 1763.56it/s] 91%|█████████████████████████████████████████████▌    | 6810/7473 [00:04<00:00, 1776.85it/s] 94%|██████████████████████████████████████████████▊   | 6994/7473 [00:04<00:00, 1792.82it/s] 96%|████████████████████████████████████████████████  | 7176/7473 [00:04<00:00, 1798.07it/s] 98%|█████████████████████████████████████████████████▏| 7360/7473 [00:05<00:00, 1808.80it/s]100%|██████████████████████████████████████████████████| 7473/7473 [00:05<00:00, 1476.16it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:04<00:09,  4.97s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.24s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.48s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.42s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:09<00:04,  4.93s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.41s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.67s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.58s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.37s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.52s/it]
[2023-08-13 07:18:57,329] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.86s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.99s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.91s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.08s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.19s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.30s/it]
[2023-08-13 07:19:12,563] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-13 07:19:12,564] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-13 07:19:12,564] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-13 07:19:12,564] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-13 07:19:12,564] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-13 07:19:12,564] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-13 07:19:12,565] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-13 07:19:12,565] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-13 07:19:12,565] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-13 07:19:12,565] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-13 07:19:12,565] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-13 07:19:12,565] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fd430ab6fa0>
[2023-08-13 07:19:12,565] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-13 07:19:12,565] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-13 07:19:12,565] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-13 07:19:12,565] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-13 07:19:12,565] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-13 07:19:12,565] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-13 07:19:12,565] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-13 07:19:12,565] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-13 07:19:12,565] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-13 07:19:12,565] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-13 07:19:12,565] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-13 07:19:12,565] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-13 07:19:12,565] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-13 07:19:12,565] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-13 07:19:12,565] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-13 07:19:12,565] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-13 07:19:12,565] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-13 07:19:12,565] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-13 07:19:12,565] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fd430ab0700>
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-13 07:19:12,566] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-13 07:19:12,567] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-13 07:19:12,567] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-13 07:19:12,567] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-13 07:19:12,567] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.42077183723449707 seconds
Loading extension module utils...
Time to load utils op: 0.4046618938446045 seconds
Loading extension module utils...
Time to load utils op: 0.404376745223999 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Fabric is cut to order at what type of seller? Choices:  A: curtains B: tailor shop C: clothing store D: sewing room E: hardware store
Answer: B: tailor shop

Input: Where are you if your reading magazines while waiting for a vehicle on rails? Choices:  A: vegetables B: market C: doctor D: train station E: bookstore
Answer: D: train station

Input: What would need oil to be used? Choices:  A: ground B: human  body C: repair shop D: combustion engines E: service station
Answer: D: combustion engines

Input: What is person probably feeling that plans on stopping being married to their spouse? Choices:  A: detachment B: bankruptcy C: sad D: fights E: wrong
Answer: A: detachment

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o4-tcommonsenseqa-s10-rFalse
Loading extension module utils...
Time to load utils op: 0.40482544898986816 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:55<45:42, 55.97s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:28<33:37, 42.03s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [01:59<28:53, 36.89s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [02:14<21:43, 28.33s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [03:09<28:30, 38.01s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [03:36<25:07, 34.27s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [04:31<29:23, 41.00s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [05:02<26:31, 37.89s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [05:57<29:36, 43.33s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [06:53<31:20, 47.00s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [07:47<32:04, 49.36s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [08:24<28:47, 45.45s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [08:49<24:14, 39.31s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [09:07<19:47, 32.99s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [09:37<18:42, 32.09s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [10:32<21:58, 38.78s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [10:56<19:01, 34.58s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [11:12<15:27, 29.00s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [11:53<16:42, 32.33s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [12:46<19:18, 38.63s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [13:40<20:55, 43.30s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [14:32<21:29, 46.05s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [15:17<20:31, 45.61s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [16:12<21:01, 48.54s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [17:06<20:52, 50.09s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [18:01<20:34, 51.45s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [18:32<17:24, 45.40s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [19:26<17:37, 48.05s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [19:52<14:27, 41.29s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [20:42<14:36, 43.84s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [21:36<14:55, 47.14s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [22:30<14:41, 49.00s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [23:17<13:43, 48.46s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [24:13<13:29, 50.62s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [25:09<13:04, 52.29s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [25:29<09:57, 42.66s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [26:25<10:07, 46.72s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [26:46<07:46, 38.88s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [27:40<07:57, 43.39s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [28:03<06:12, 37.24s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [28:57<06:22, 42.46s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [29:14<04:38, 34.85s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [29:43<03:51, 33.08s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [30:23<03:30, 35.11s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [30:45<02:36, 31.27s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [31:31<02:22, 35.59s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [32:26<02:04, 41.50s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [33:20<01:30, 45.14s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [33:46<00:39, 39.54s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [34:36<00:00, 42.66s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [34:36<00:00, 41.54s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.1948} | lm_loss 9.5871 | avg. gen lenth: 168.148
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o5-tcommonsenseqa-s10-rFalse --seed 10 --num-out-domain 5
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-13 07:56:10,127] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o5-tcommonsenseqa-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 5
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o5-tcommonsenseqa-s10-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  1%|▋                                                  | 108/7473 [00:00<00:06, 1073.13it/s]  3%|█▍                                                 | 219/7473 [00:00<00:06, 1092.20it/s]  4%|██▏                                                | 329/7473 [00:00<00:06, 1093.64it/s]  6%|██▉                                                | 439/7473 [00:00<00:06, 1089.42it/s]  7%|███▋                                               | 549/7473 [00:00<00:06, 1091.71it/s]  9%|████▍                                              | 659/7473 [00:00<00:06, 1091.94it/s] 10%|█████▎                                             | 771/7473 [00:00<00:06, 1099.27it/s] 12%|██████                                             | 881/7473 [00:00<00:05, 1098.93it/s] 13%|██████▊                                            | 991/7473 [00:00<00:06, 1076.31it/s] 15%|███████▎                                          | 1102/7473 [00:01<00:05, 1084.65it/s] 16%|████████                                          | 1211/7473 [00:01<00:05, 1085.12it/s] 18%|████████▊                                         | 1322/7473 [00:01<00:05, 1090.06it/s] 19%|█████████▌                                        | 1432/7473 [00:01<00:05, 1088.01it/s] 21%|██████████▎                                       | 1544/7473 [00:01<00:05, 1095.94it/s] 22%|███████████▏                                      | 1670/7473 [00:01<00:05, 1143.98it/s] 25%|████████████▎                                     | 1837/7473 [00:01<00:04, 1299.39it/s] 27%|█████████████▍                                    | 2003/7473 [00:01<00:03, 1404.55it/s] 29%|██████████████▌                                   | 2170/7473 [00:01<00:03, 1482.99it/s] 31%|███████████████▌                                  | 2333/7473 [00:01<00:03, 1524.89it/s] 33%|████████████████▋                                 | 2499/7473 [00:02<00:03, 1564.18it/s] 36%|█████████████████▊                                | 2656/7473 [00:02<00:03, 1554.37it/s] 38%|██████████████████▉                               | 2823/7473 [00:02<00:02, 1586.81it/s] 40%|████████████████████                              | 2991/7473 [00:02<00:02, 1612.55it/s] 42%|█████████████████████                             | 3156/7473 [00:02<00:02, 1622.87it/s] 44%|██████████████████████▏                           | 3323/7473 [00:02<00:02, 1634.71it/s] 47%|███████████████████████▎                          | 3487/7473 [00:02<00:02, 1634.11it/s] 49%|████████████████████████▍                         | 3653/7473 [00:02<00:02, 1641.23it/s] 51%|█████████████████████████▌                        | 3819/7473 [00:02<00:02, 1645.59it/s] 53%|██████████████████████████▋                       | 3985/7473 [00:02<00:02, 1647.45it/s] 56%|███████████████████████████▊                      | 4150/7473 [00:03<00:02, 1646.01it/s] 58%|████████████████████████████▊                     | 4315/7473 [00:03<00:01, 1641.40it/s] 60%|█████████████████████████████▉                    | 4480/7473 [00:03<00:01, 1630.44it/s] 62%|███████████████████████████████                   | 4646/7473 [00:03<00:01, 1636.93it/s] 64%|████████████████████████████████▏                 | 4811/7473 [00:03<00:01, 1638.66it/s] 67%|█████████████████████████████████▎                | 4977/7473 [00:03<00:01, 1642.26it/s] 69%|██████████████████████████████████▍               | 5143/7473 [00:03<00:01, 1647.35it/s] 71%|███████████████████████████████████▌              | 5308/7473 [00:03<00:01, 1614.76it/s] 73%|████████████████████████████████████▌             | 5471/7473 [00:03<00:01, 1233.62it/s] 75%|█████████████████████████████████████▋            | 5636/7473 [00:04<00:01, 1334.55it/s] 78%|██████████████████████████████████████▊           | 5801/7473 [00:04<00:01, 1414.03it/s] 80%|███████████████████████████████████████▉          | 5961/7473 [00:04<00:01, 1463.69it/s] 82%|████████████████████████████████████████▉         | 6126/7473 [00:04<00:00, 1514.70it/s] 84%|██████████████████████████████████████████        | 6290/7473 [00:04<00:00, 1549.69it/s] 86%|███████████████████████████████████████████▏      | 6450/7473 [00:04<00:00, 1553.28it/s] 89%|████████████████████████████████████████████▎     | 6616/7473 [00:04<00:00, 1581.58it/s] 91%|█████████████████████████████████████████████▎    | 6781/7473 [00:04<00:00, 1599.19it/s] 93%|██████████████████████████████████████████████▍   | 6947/7473 [00:04<00:00, 1614.84it/s] 95%|███████████████████████████████████████████████▌  | 7110/7473 [00:04<00:00, 1618.29it/s] 97%|████████████████████████████████████████████████▋ | 7275/7473 [00:05<00:00, 1625.76it/s]100%|█████████████████████████████████████████████████▊| 7442/7473 [00:05<00:00, 1637.03it/s]100%|██████████████████████████████████████████████████| 7473/7473 [00:05<00:00, 1446.27it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.50s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.41s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.55s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.39s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.41s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:07<00:14,  7.44s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.77s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.72s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.91s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.84s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.99s/it]
Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:13<00:06,  6.85s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:16<00:00,  5.60s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:16<00:00,  5.63s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:18<00:00,  5.86s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:18<00:00,  6.19s/it]
[2023-08-13 07:57:15,236] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-13 07:57:26,248] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-13 07:57:26,249] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f2bea57fac0>
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-13 07:57:26,250] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f2bea501580>
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-13 07:57:26,251] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-13 07:57:26,251] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4221823215484619 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Fabric is cut to order at what type of seller? Choices:  A: curtains B: tailor shop C: clothing store D: sewing room E: hardware store
Answer: B: tailor shop

Input: Where are you if your reading magazines while waiting for a vehicle on rails? Choices:  A: vegetables B: market C: doctor D: train station E: bookstore
Answer: D: train station

Input: What would need oil to be used? Choices:  A: ground B: human  body C: repair shop D: combustion engines E: service station
Answer: D: combustion engines

Input: What is person probably feeling that plans on stopping being married to their spouse? Choices:  A: detachment B: bankruptcy C: sad D: fights E: wrong
Answer: A: detachment

Input: What could you use to store a clock? Choices:  A: shelf B: own bedroom C: desk D: wall E: car
Answer: A: shelf

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o5-tcommonsenseqa-s10-rFalse
Loading extension module utils...
Time to load utils op: 0.40445494651794434 seconds
Loading extension module utils...
Time to load utils op: 0.4046027660369873 seconds
Loading extension module utils...
Time to load utils op: 0.40451574325561523 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:56<45:45, 56.03s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:49<43:31, 54.41s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:43<42:30, 54.26s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [03:35<40:53, 53.34s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [04:12<35:38, 47.52s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [05:07<36:38, 49.96s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [06:01<36:54, 51.50s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [06:56<36:43, 52.47s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [07:50<36:09, 52.92s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [08:44<35:32, 53.31s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [09:37<34:29, 53.08s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [10:01<28:04, 44.33s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [10:21<22:49, 37.00s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [11:15<25:17, 42.15s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [12:09<26:37, 45.63s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [13:02<27:13, 48.05s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [13:36<24:04, 43.78s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [14:31<25:10, 47.20s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [15:22<24:54, 48.20s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [15:56<21:58, 43.96s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [16:50<22:39, 46.88s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [17:43<22:50, 48.94s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [18:28<21:27, 47.70s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [19:10<19:51, 45.83s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [20:03<20:01, 48.05s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [20:49<18:56, 47.36s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [21:41<18:45, 48.94s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [21:55<14:02, 38.32s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [22:49<15:06, 43.19s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [23:44<15:29, 46.49s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [24:37<15:24, 48.68s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [25:03<12:29, 41.66s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [25:16<09:21, 33.01s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [25:41<08:10, 30.64s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [26:34<09:22, 37.48s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [27:28<09:53, 42.39s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [28:21<09:51, 45.51s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [29:00<08:44, 43.70s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [29:41<07:49, 42.69s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [30:11<06:29, 38.98s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [31:03<06:25, 42.85s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [31:56<06:08, 46.01s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [32:50<05:38, 48.34s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [33:42<04:56, 49.40s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [33:58<03:17, 39.59s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [34:46<02:47, 41.87s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [35:30<02:08, 42.71s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [35:58<01:16, 38.15s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [36:51<00:42, 42.75s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [37:46<00:00, 46.43s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [37:46<00:00, 45.34s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.3687} | lm_loss 9.6254 | avg. gen lenth: 211.476
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o6-tcommonsenseqa-s10-rFalse --seed 10 --num-out-domain 6
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
using world size: 4
[nltk_data]   Package punkt is already up-to-date!
[2023-08-13 08:36:29,019] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o6-tcommonsenseqa-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 6
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o6-tcommonsenseqa-s10-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  1%|▋                                                    | 97/7473 [00:00<00:07, 968.56it/s]  3%|█▎                                                  | 196/7473 [00:00<00:07, 976.47it/s]  4%|██                                                  | 295/7473 [00:00<00:07, 978.69it/s]  5%|██▋                                                 | 394/7473 [00:00<00:07, 980.78it/s]  7%|███▍                                                | 493/7473 [00:00<00:07, 977.92it/s]  8%|████▏                                               | 593/7473 [00:00<00:07, 982.65it/s]  9%|████▊                                               | 692/7473 [00:00<00:06, 983.04it/s] 11%|█████▌                                              | 792/7473 [00:00<00:06, 986.13it/s] 12%|██████▏                                             | 891/7473 [00:00<00:06, 966.32it/s] 13%|██████▉                                             | 990/7473 [00:01<00:06, 972.84it/s] 15%|███████▍                                           | 1090/7473 [00:01<00:06, 978.90it/s] 16%|████████                                           | 1188/7473 [00:01<00:06, 978.38it/s] 17%|████████▊                                          | 1287/7473 [00:01<00:06, 981.37it/s] 19%|█████████▍                                         | 1386/7473 [00:01<00:06, 981.89it/s] 20%|██████████▏                                        | 1486/7473 [00:01<00:06, 985.34it/s] 21%|██████████▊                                        | 1585/7473 [00:01<00:05, 984.59it/s] 23%|███████████▍                                       | 1685/7473 [00:01<00:05, 986.36it/s] 24%|████████████▏                                      | 1784/7473 [00:01<00:05, 986.43it/s] 25%|████████████▊                                      | 1883/7473 [00:01<00:05, 979.26it/s] 27%|█████████████▌                                     | 1981/7473 [00:02<00:05, 978.88it/s] 28%|██████████████▏                                    | 2080/7473 [00:02<00:05, 980.49it/s] 29%|██████████████▉                                    | 2180/7473 [00:02<00:05, 984.05it/s] 30%|███████████████▌                                   | 2279/7473 [00:02<00:05, 985.48it/s] 32%|████████████████▏                                  | 2379/7473 [00:02<00:05, 986.93it/s] 33%|████████████████▉                                  | 2480/7473 [00:02<00:05, 990.92it/s] 35%|█████████████████▌                                 | 2580/7473 [00:02<00:05, 959.28it/s] 36%|██████████████████▎                                | 2687/7473 [00:02<00:04, 990.39it/s] 38%|██████████████████▉                               | 2839/7473 [00:02<00:04, 1145.67it/s] 40%|████████████████████                              | 2991/7473 [00:02<00:03, 1256.20it/s] 42%|█████████████████████                             | 3141/7473 [00:03<00:03, 1328.02it/s] 44%|██████████████████████                            | 3293/7473 [00:03<00:03, 1382.68it/s] 46%|███████████████████████                           | 3438/7473 [00:03<00:02, 1400.92it/s] 48%|████████████████████████                          | 3589/7473 [00:03<00:02, 1433.14it/s] 50%|█████████████████████████                         | 3738/7473 [00:03<00:02, 1448.83it/s] 52%|██████████████████████████                        | 3888/7473 [00:03<00:02, 1462.45it/s] 54%|███████████████████████████                       | 4041/7473 [00:03<00:02, 1479.88it/s] 56%|████████████████████████████                      | 4190/7473 [00:03<00:02, 1482.17it/s] 58%|█████████████████████████████                     | 4341/7473 [00:03<00:02, 1488.56it/s] 60%|██████████████████████████████                    | 4491/7473 [00:03<00:02, 1490.98it/s] 62%|███████████████████████████████                   | 4641/7473 [00:04<00:01, 1493.52it/s] 64%|████████████████████████████████                  | 4792/7473 [00:04<00:01, 1496.45it/s] 66%|█████████████████████████████████                 | 4943/7473 [00:04<00:01, 1498.95it/s] 68%|██████████████████████████████████                | 5094/7473 [00:04<00:01, 1499.13it/s] 70%|███████████████████████████████████               | 5244/7473 [00:04<00:01, 1466.83it/s] 72%|████████████████████████████████████              | 5391/7473 [00:04<00:01, 1452.99it/s] 74%|█████████████████████████████████████             | 5537/7473 [00:04<00:01, 1131.91it/s] 76%|██████████████████████████████████████            | 5688/7473 [00:04<00:01, 1223.79it/s] 78%|███████████████████████████████████████           | 5839/7473 [00:04<00:01, 1296.31it/s] 80%|████████████████████████████████████████          | 5988/7473 [00:05<00:01, 1346.47it/s] 82%|█████████████████████████████████████████         | 6140/7473 [00:05<00:00, 1392.30it/s] 84%|██████████████████████████████████████████        | 6291/7473 [00:05<00:00, 1425.24it/s] 86%|███████████████████████████████████████████       | 6441/7473 [00:05<00:00, 1445.02it/s] 88%|████████████████████████████████████████████      | 6592/7473 [00:05<00:00, 1462.73it/s] 90%|█████████████████████████████████████████████     | 6743/7473 [00:05<00:00, 1474.21it/s] 92%|██████████████████████████████████████████████    | 6893/7473 [00:05<00:00, 1479.91it/s] 94%|███████████████████████████████████████████████   | 7043/7473 [00:05<00:00, 1484.68it/s] 96%|████████████████████████████████████████████████▏ | 7193/7473 [00:05<00:00, 1484.44it/s] 98%|█████████████████████████████████████████████████ | 7342/7473 [00:05<00:00, 1486.04it/s]100%|██████████████████████████████████████████████████| 7473/7473 [00:06<00:00, 1236.58it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.53s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.38s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.42s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.55s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.22s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.16s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.43s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.43s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.58s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.75s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.79s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.94s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.85s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.01s/it]
[2023-08-13 08:37:27,284] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.79s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.98s/it]
[2023-08-13 08:37:40,737] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-13 08:37:40,738] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-13 08:37:40,738] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fba7e57efa0>
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-13 08:37:40,739] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-13 08:37:40,740] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-13 08:37:40,740] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-13 08:37:40,740] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-13 08:37:40,740] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-13 08:37:40,740] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-13 08:37:40,740] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-13 08:37:40,740] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fba7e56e700>
[2023-08-13 08:37:40,740] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-13 08:37:40,740] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-13 08:37:40,740] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-13 08:37:40,740] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-13 08:37:40,740] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-13 08:37:40,740] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-13 08:37:40,740] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-13 08:37:40,740] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-13 08:37:40,740] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-13 08:37:40,740] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-13 08:37:40,740] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-13 08:37:40,740] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-13 08:37:40,740] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-13 08:37:40,740] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-13 08:37:40,740] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-13 08:37:40,740] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-13 08:37:40,740] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-13 08:37:40,740] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-13 08:37:40,740] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-13 08:37:40,740] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-13 08:37:40,740] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-13 08:37:40,740] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-13 08:37:40,740] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.41065430641174316 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Loading extension module utils...
Time to load utils op: 0.40245652198791504 seconds
Loading extension module utils...
Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Time to load utils op: 0.30409741401672363 seconds
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Fabric is cut to order at what type of seller? Choices:  A: curtains B: tailor shop C: clothing store D: sewing room E: hardware store
Answer: B: tailor shop

Input: Where are you if your reading magazines while waiting for a vehicle on rails? Choices:  A: vegetables B: market C: doctor D: train station E: bookstore
Answer: D: train station

Input: What would need oil to be used? Choices:  A: ground B: human  body C: repair shop D: combustion engines E: service station
Answer: D: combustion engines

Input: What is person probably feeling that plans on stopping being married to their spouse? Choices:  A: detachment B: bankruptcy C: sad D: fights E: wrong
Answer: A: detachment

Input: What could you use to store a clock? Choices:  A: shelf B: own bedroom C: desk D: wall E: car
Answer: A: shelf

Input: The person put on lotion, what did they want? Choices:  A: fresh smell B: good credit C: smooth skin D: fresh produce E: headache
Answer: C: smooth skin

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o6-tcommonsenseqa-s10-rFalse
Loading extension module utils...
Time to load utils op: 0.40468716621398926 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:26<21:57, 26.90s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:19<33:37, 42.02s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:10<36:03, 46.02s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [02:42<31:11, 40.68s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [03:35<33:53, 45.18s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [04:28<34:53, 47.57s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [05:21<35:25, 49.42s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [05:50<30:05, 42.98s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [06:43<31:30, 46.11s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [07:35<31:58, 47.97s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [08:12<28:55, 44.49s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [09:03<29:31, 46.63s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [09:42<27:19, 44.30s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [10:12<23:59, 39.98s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [10:26<18:44, 32.13s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [10:48<16:31, 29.16s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [11:42<20:03, 36.48s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [12:33<21:44, 40.76s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [13:05<19:42, 38.15s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [13:24<16:13, 32.44s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [14:17<18:41, 38.66s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [15:10<20:04, 43.00s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [16:01<20:23, 45.32s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [16:19<16:09, 37.28s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [17:09<17:04, 40.97s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [18:03<17:53, 44.73s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [18:24<14:29, 37.78s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [18:47<12:14, 33.36s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [19:41<13:49, 39.51s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [20:07<11:48, 35.42s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [21:00<12:52, 40.66s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [21:53<13:18, 44.37s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [22:46<13:20, 47.11s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [23:39<12:59, 48.71s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [24:33<12:33, 50.26s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [25:11<10:53, 46.65s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [25:47<09:25, 43.52s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [26:39<09:14, 46.18s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [27:12<07:42, 42.07s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [28:05<07:35, 45.51s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [28:42<06:24, 42.73s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [29:35<06:07, 45.91s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [30:27<05:34, 47.78s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [31:14<04:45, 47.54s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [31:34<03:16, 39.21s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [32:07<02:29, 37.45s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [33:00<02:06, 42.02s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [33:53<01:30, 45.37s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [34:16<00:38, 38.72s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [35:10<00:00, 43.25s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [35:10<00:00, 42.21s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.3712} | lm_loss 9.6785 | avg. gen lenth: 190.8
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o7-tcommonsenseqa-s10-rFalse --seed 10 --num-out-domain 7
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-13 09:16:57,890] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o7-tcommonsenseqa-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 7
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o7-tcommonsenseqa-s10-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  1%|▌                                                    | 88/7473 [00:00<00:08, 875.95it/s]  2%|█▏                                                  | 177/7473 [00:00<00:08, 881.89it/s]  4%|█▊                                                  | 266/7473 [00:00<00:08, 883.13it/s]  5%|██▍                                                 | 356/7473 [00:00<00:08, 886.35it/s]  6%|███                                                 | 445/7473 [00:00<00:07, 882.80it/s]  7%|███▋                                                | 534/7473 [00:00<00:07, 882.99it/s]  8%|████▎                                               | 623/7473 [00:00<00:07, 882.09it/s] 10%|████▉                                               | 712/7473 [00:00<00:07, 884.15it/s] 11%|█████▌                                              | 801/7473 [00:00<00:07, 868.49it/s] 12%|██████▏                                             | 889/7473 [00:01<00:07, 871.55it/s] 13%|██████▊                                             | 978/7473 [00:01<00:07, 876.32it/s] 14%|███████▎                                           | 1068/7473 [00:01<00:07, 881.28it/s] 15%|███████▉                                           | 1157/7473 [00:01<00:07, 882.77it/s] 17%|████████▌                                          | 1246/7473 [00:01<00:07, 880.09it/s] 18%|█████████                                          | 1335/7473 [00:01<00:06, 882.07it/s] 19%|█████████▋                                         | 1424/7473 [00:01<00:06, 878.82it/s] 20%|██████████▎                                        | 1514/7473 [00:01<00:06, 883.17it/s] 21%|██████████▉                                        | 1603/7473 [00:01<00:06, 880.79it/s] 23%|███████████▌                                       | 1692/7473 [00:01<00:06, 876.10it/s] 24%|████████████▏                                      | 1780/7473 [00:02<00:06, 875.84it/s] 25%|████████████▋                                      | 1868/7473 [00:02<00:06, 875.13it/s] 27%|█████████████▌                                     | 1985/7473 [00:02<00:05, 962.37it/s] 28%|██████████████▏                                   | 2118/7473 [00:02<00:04, 1071.44it/s] 30%|███████████████                                   | 2252/7473 [00:02<00:04, 1151.58it/s] 32%|███████████████▉                                  | 2385/7473 [00:02<00:04, 1203.68it/s] 34%|████████████████▊                                 | 2520/7473 [00:02<00:04, 1206.47it/s] 36%|█████████████████▊                                | 2655/7473 [00:02<00:03, 1248.21it/s] 37%|██████████████████▋                               | 2789/7473 [00:02<00:03, 1273.93it/s] 39%|███████████████████▌                              | 2922/7473 [00:02<00:03, 1288.32it/s] 41%|████████████████████▍                             | 3051/7473 [00:03<00:03, 1282.75it/s] 43%|█████████████████████▎                            | 3180/7473 [00:03<00:03, 1282.16it/s] 44%|██████████████████████▏                           | 3311/7473 [00:03<00:03, 1287.99it/s] 46%|███████████████████████                           | 3443/7473 [00:03<00:03, 1294.54it/s] 48%|███████████████████████▉                          | 3577/7473 [00:03<00:02, 1307.47it/s] 50%|████████████████████████▊                         | 3709/7473 [00:03<00:02, 1310.44it/s] 51%|█████████████████████████▋                        | 3842/7473 [00:03<00:02, 1315.06it/s] 53%|██████████████████████████▌                       | 3975/7473 [00:03<00:02, 1318.82it/s] 55%|███████████████████████████▍                      | 4109/7473 [00:03<00:02, 1322.15it/s] 57%|████████████████████████████▍                     | 4242/7473 [00:03<00:02, 1323.03it/s] 59%|█████████████████████████████▎                    | 4375/7473 [00:04<00:02, 1323.39it/s] 60%|██████████████████████████████▏                   | 4508/7473 [00:04<00:02, 1322.85it/s] 62%|███████████████████████████████                   | 4641/7473 [00:04<00:02, 1318.09it/s] 64%|███████████████████████████████▉                  | 4773/7473 [00:04<00:02, 1315.36it/s] 66%|████████████████████████████████▊                 | 4906/7473 [00:04<00:01, 1317.87it/s] 67%|█████████████████████████████████▋                | 5038/7473 [00:04<00:01, 1301.66it/s] 69%|██████████████████████████████████▌               | 5173/7473 [00:04<00:01, 1313.70it/s] 71%|███████████████████████████████████▍              | 5305/7473 [00:04<00:01, 1256.86it/s] 73%|████████████████████████████████████▍             | 5439/7473 [00:04<00:01, 1278.34it/s] 75%|█████████████████████████████████████▉             | 5568/7473 [00:05<00:01, 963.29it/s] 76%|██████████████████████████████████████▏           | 5701/7473 [00:05<00:01, 1049.25it/s] 78%|███████████████████████████████████████           | 5835/7473 [00:05<00:01, 1121.21it/s] 80%|███████████████████████████████████████▉          | 5966/7473 [00:05<00:01, 1170.93it/s] 82%|████████████████████████████████████████▊         | 6100/7473 [00:05<00:01, 1215.29it/s] 83%|█████████████████████████████████████████▋        | 6229/7473 [00:05<00:01, 1235.91it/s] 85%|██████████████████████████████████████████▌       | 6362/7473 [00:05<00:00, 1262.47it/s] 87%|███████████████████████████████████████████▍      | 6494/7473 [00:05<00:00, 1278.64it/s] 89%|████████████████████████████████████████████▎     | 6625/7473 [00:05<00:00, 1285.67it/s] 90%|█████████████████████████████████████████████▏    | 6757/7473 [00:05<00:00, 1295.40it/s] 92%|██████████████████████████████████████████████    | 6889/7473 [00:06<00:00, 1301.55it/s] 94%|██████████████████████████████████████████████▉   | 7023/7473 [00:06<00:00, 1310.19it/s] 96%|███████████████████████████████████████████████▊  | 7155/7473 [00:06<00:00, 1270.12it/s] 98%|████████████████████████████████████████████████▊ | 7288/7473 [00:06<00:00, 1287.14it/s] 99%|█████████████████████████████████████████████████▋| 7421/7473 [00:06<00:00, 1297.28it/s]100%|██████████████████████████████████████████████████| 7473/7473 [00:06<00:00, 1142.84it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.38s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.93s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:06<00:12,  6.10s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:06<00:12,  6.10s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.20s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.56s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.63s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:14<00:07,  7.19s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.65s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.82s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.01s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.19s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.98s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.20s/it]
[2023-08-13 09:17:57,526] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:19<00:00,  6.30s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:19<00:00,  6.43s/it]
[2023-08-13 09:18:12,098] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-13 09:18:12,099] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-13 09:18:12,100] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-13 09:18:12,100] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-13 09:18:12,100] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-13 09:18:12,100] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-13 09:18:12,100] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-13 09:18:12,100] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-13 09:18:12,100] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-13 09:18:12,100] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-13 09:18:12,100] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-13 09:18:12,100] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f57b104fb20>
[2023-08-13 09:18:12,100] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-13 09:18:12,100] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-13 09:18:12,100] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-13 09:18:12,100] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-13 09:18:12,100] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-13 09:18:12,100] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-13 09:18:12,100] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-13 09:18:12,100] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-13 09:18:12,100] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-13 09:18:12,100] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-13 09:18:12,100] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-13 09:18:12,100] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-13 09:18:12,100] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-13 09:18:12,100] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-13 09:18:12,100] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-13 09:18:12,100] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-13 09:18:12,100] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-13 09:18:12,100] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f57b104ff10>
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-13 09:18:12,101] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-13 09:18:12,101] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4363737106323242 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Fabric is cut to order at what type of seller? Choices:  A: curtains B: tailor shop C: clothing store D: sewing room E: hardware store
Answer: B: tailor shop

Input: Where are you if your reading magazines while waiting for a vehicle on rails? Choices:  A: vegetables B: market C: doctor D: train station E: bookstore
Answer: D: train station

Input: What would need oil to be used? Choices:  A: ground B: human  body C: repair shop D: combustion engines E: service station
Answer: D: combustion engines

Input: What is person probably feeling that plans on stopping being married to their spouse? Choices:  A: detachment B: bankruptcy C: sad D: fights E: wrong
Answer: A: detachment

Input: What could you use to store a clock? Choices:  A: shelf B: own bedroom C: desk D: wall E: car
Answer: A: shelf

Input: The person put on lotion, what did they want? Choices:  A: fresh smell B: good credit C: smooth skin D: fresh produce E: headache
Answer: C: smooth skin

Input: They burned the record, they were trying to do what to history? Choices:  A: compact disc B: tape C: rewrite D: play music E: erase
Answer: E: erase

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o7-tcommonsenseqa-s10-rFalse
Loading extension module utils...
Time to load utils op: 0.4046354293823242 seconds
Loading extension module utils...
Time to load utils op: 0.4045693874359131 seconds
Loading extension module utils...
Time to load utils op: 0.5048317909240723 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:26<21:39, 26.51s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:18<33:02, 41.31s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:11<36:43, 46.89s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [02:56<35:09, 45.87s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [03:27<30:32, 40.72s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [04:18<32:24, 44.18s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [04:58<30:43, 42.86s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [05:51<32:16, 46.11s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [06:45<33:11, 48.56s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [07:38<33:18, 49.95s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [08:07<28:11, 43.38s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [09:00<29:19, 46.31s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [09:12<22:15, 36.08s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [10:05<24:38, 41.07s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [10:31<21:23, 36.67s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [11:24<23:30, 41.50s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [12:16<24:31, 44.60s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [13:08<24:56, 46.76s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [14:00<25:00, 48.41s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [14:52<24:46, 49.56s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [15:41<23:47, 49.23s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [16:33<23:23, 50.11s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [17:18<21:51, 48.56s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [18:09<21:20, 49.27s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [18:59<20:39, 49.57s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [19:39<18:38, 46.59s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [20:24<17:43, 46.22s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [21:00<15:49, 43.16s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [21:52<16:03, 45.86s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [22:11<12:38, 37.91s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [23:04<13:23, 42.27s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [23:43<12:24, 41.38s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [24:35<12:35, 44.42s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [25:26<12:25, 46.60s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [26:19<12:07, 48.52s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [27:09<11:22, 48.74s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [28:00<10:45, 49.63s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [28:28<08:36, 43.06s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [29:20<08:24, 45.85s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [30:11<07:53, 47.34s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [30:35<06:03, 40.36s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [31:16<05:23, 40.44s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [31:56<04:43, 40.47s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [32:49<04:24, 44.13s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [33:41<03:51, 46.37s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [34:33<03:12, 48.15s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [35:25<02:27, 49.29s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [36:04<01:32, 46.08s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [36:56<00:48, 48.02s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [37:17<00:00, 39.75s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [37:17<00:00, 44.74s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.2959} | lm_loss 9.7146 | avg. gen lenth: 202.62
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o8-tcommonsenseqa-s10-rFalse --seed 10 --num-out-domain 8
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date![nltk_data]   Package punkt is already up-to-date!

[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-13 09:57:11,750] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o8-tcommonsenseqa-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 8
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o8-tcommonsenseqa-s10-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  1%|▌                                                    | 77/7473 [00:00<00:09, 768.27it/s]  2%|█                                                   | 156/7473 [00:00<00:09, 779.33it/s]  3%|█▋                                                  | 236/7473 [00:00<00:09, 783.95it/s]  4%|██▏                                                 | 315/7473 [00:00<00:09, 782.82it/s]  5%|██▋                                                 | 394/7473 [00:00<00:09, 783.20it/s]  6%|███▎                                                | 473/7473 [00:00<00:08, 780.77it/s]  7%|███▊                                                | 552/7473 [00:00<00:08, 782.76it/s]  8%|████▍                                               | 631/7473 [00:00<00:08, 781.55it/s] 10%|████▉                                               | 710/7473 [00:00<00:08, 765.67it/s] 11%|█████▍                                              | 789/7473 [00:01<00:08, 771.94it/s] 12%|██████                                              | 868/7473 [00:01<00:08, 776.53it/s] 13%|██████▌                                             | 947/7473 [00:01<00:08, 778.50it/s] 14%|███████                                            | 1028/7473 [00:01<00:08, 785.15it/s] 15%|███████▌                                           | 1108/7473 [00:01<00:08, 787.43it/s] 16%|████████                                           | 1187/7473 [00:01<00:08, 784.59it/s] 17%|████████▋                                          | 1266/7473 [00:01<00:07, 786.01it/s] 18%|█████████▏                                         | 1346/7473 [00:01<00:07, 787.63it/s] 19%|█████████▋                                         | 1425/7473 [00:01<00:07, 783.23it/s] 20%|██████████▎                                        | 1504/7473 [00:01<00:07, 782.86it/s] 21%|██████████▊                                        | 1583/7473 [00:02<00:07, 780.70it/s] 22%|███████████▎                                       | 1662/7473 [00:02<00:07, 781.31it/s] 23%|███████████▉                                       | 1741/7473 [00:02<00:07, 783.79it/s] 24%|████████████▍                                      | 1820/7473 [00:02<00:07, 783.55it/s] 25%|████████████▉                                      | 1899/7473 [00:02<00:07, 779.68it/s] 26%|█████████████▍                                     | 1977/7473 [00:02<00:07, 779.34it/s] 28%|██████████████▎                                    | 2091/7473 [00:02<00:06, 886.48it/s] 30%|███████████████                                    | 2211/7473 [00:02<00:05, 980.02it/s] 31%|███████████████▌                                  | 2331/7473 [00:02<00:04, 1043.79it/s] 33%|████████████████▍                                 | 2452/7473 [00:02<00:04, 1092.09it/s] 34%|█████████████████▏                                | 2562/7473 [00:03<00:04, 1084.06it/s] 36%|█████████████████▉                                | 2683/7473 [00:03<00:04, 1121.47it/s] 37%|██████████████████▋                               | 2799/7473 [00:03<00:04, 1132.01it/s] 39%|███████████████████▌                              | 2920/7473 [00:03<00:03, 1153.43it/s] 41%|████████████████████▎                             | 3040/7473 [00:03<00:03, 1166.42it/s] 42%|█████████████████████▏                            | 3159/7473 [00:03<00:03, 1172.77it/s] 44%|█████████████████████▉                            | 3279/7473 [00:03<00:03, 1178.39it/s] 45%|██████████████████████▋                           | 3397/7473 [00:03<00:03, 1178.33it/s] 47%|███████████████████████▌                          | 3516/7473 [00:03<00:03, 1179.05it/s] 49%|████████████████████████▎                         | 3636/7473 [00:03<00:03, 1183.25it/s] 50%|█████████████████████████                         | 3755/7473 [00:04<00:03, 1179.21it/s] 52%|█████████████████████████▉                        | 3874/7473 [00:04<00:03, 1181.21it/s] 53%|██████████████████████████▋                       | 3993/7473 [00:04<00:02, 1183.55it/s] 55%|███████████████████████████▌                      | 4112/7473 [00:04<00:02, 1185.00it/s] 57%|████████████████████████████▎                     | 4231/7473 [00:04<00:02, 1184.56it/s] 58%|█████████████████████████████                     | 4350/7473 [00:04<00:02, 1167.14it/s] 60%|█████████████████████████████▉                    | 4468/7473 [00:04<00:02, 1169.86it/s] 61%|██████████████████████████████▋                   | 4587/7473 [00:04<00:02, 1173.47it/s] 63%|███████████████████████████████▍                  | 4706/7473 [00:04<00:02, 1176.08it/s] 65%|████████████████████████████████▎                 | 4825/7473 [00:04<00:02, 1180.12it/s] 66%|█████████████████████████████████                 | 4945/7473 [00:05<00:02, 1183.51it/s] 68%|█████████████████████████████████▉                | 5065/7473 [00:05<00:02, 1186.48it/s] 69%|██████████████████████████████████▋               | 5184/7473 [00:05<00:01, 1187.31it/s] 71%|███████████████████████████████████▍              | 5303/7473 [00:05<00:01, 1135.67it/s] 73%|████████████████████████████████████▎             | 5422/7473 [00:05<00:01, 1149.48it/s] 74%|█████████████████████████████████████▊             | 5538/7473 [00:05<00:02, 880.20it/s] 76%|██████████████████████████████████████▌            | 5657/7473 [00:05<00:01, 954.26it/s] 77%|██████████████████████████████████████▋           | 5776/7473 [00:05<00:01, 1012.81it/s] 79%|███████████████████████████████████████▍          | 5894/7473 [00:05<00:01, 1056.08it/s] 80%|████████████████████████████████████████▏         | 6011/7473 [00:06<00:01, 1086.09it/s] 82%|█████████████████████████████████████████         | 6132/7473 [00:06<00:01, 1118.44it/s] 84%|█████████████████████████████████████████▊        | 6253/7473 [00:06<00:01, 1141.79it/s] 85%|██████████████████████████████████████████▋       | 6372/7473 [00:06<00:00, 1154.00it/s] 87%|███████████████████████████████████████████▍      | 6490/7473 [00:06<00:00, 1160.97it/s] 88%|████████████████████████████████████████████▏     | 6610/7473 [00:06<00:00, 1170.15it/s] 90%|█████████████████████████████████████████████     | 6728/7473 [00:06<00:00, 1173.01it/s] 92%|█████████████████████████████████████████████▊    | 6846/7473 [00:06<00:00, 1173.93it/s] 93%|██████████████████████████████████████████████▌   | 6966/7473 [00:06<00:00, 1180.40it/s] 95%|███████████████████████████████████████████████▍  | 7085/7473 [00:06<00:00, 1179.47it/s] 96%|████████████████████████████████████████████████▏ | 7204/7473 [00:07<00:00, 1178.94it/s] 98%|████████████████████████████████████████████████▉ | 7323/7473 [00:07<00:00, 1180.68it/s]100%|█████████████████████████████████████████████████▊| 7442/7473 [00:07<00:00, 1182.18it/s]100%|██████████████████████████████████████████████████| 7473/7473 [00:07<00:00, 1022.58it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.21s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.03s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.01s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.54s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.16s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:09<00:04,  4.91s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:09<00:04,  4.94s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.33s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.53s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.70s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.42s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.56s/it]
[2023-08-13 09:58:09,758] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.48s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.61s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.65s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.85s/it]
[2023-08-13 09:58:17,253] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-13 09:58:17,254] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-13 09:58:17,254] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-13 09:58:17,254] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-13 09:58:17,254] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-13 09:58:17,254] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f4e3f285fa0>
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-13 09:58:17,255] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f4e3f28b700>
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-13 09:58:17,256] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-13 09:58:17,256] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.38144683837890625 seconds
Loading extension module utils...
Time to load utils op: 0.30416321754455566 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Loading extension module utils...
Time to load utils op: 0.3044164180755615 seconds
Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Fabric is cut to order at what type of seller? Choices:  A: curtains B: tailor shop C: clothing store D: sewing room E: hardware store
Answer: B: tailor shop

Input: Where are you if your reading magazines while waiting for a vehicle on rails? Choices:  A: vegetables B: market C: doctor D: train station E: bookstore
Answer: D: train station

Input: What would need oil to be used? Choices:  A: ground B: human  body C: repair shop D: combustion engines E: service station
Answer: D: combustion engines

Input: What is person probably feeling that plans on stopping being married to their spouse? Choices:  A: detachment B: bankruptcy C: sad D: fights E: wrong
Answer: A: detachment

Input: What could you use to store a clock? Choices:  A: shelf B: own bedroom C: desk D: wall E: car
Answer: A: shelf

Input: The person put on lotion, what did they want? Choices:  A: fresh smell B: good credit C: smooth skin D: fresh produce E: headache
Answer: C: smooth skin

Input: They burned the record, they were trying to do what to history? Choices:  A: compact disc B: tape C: rewrite D: play music E: erase
Answer: E: erase

Input: She sure didn't have a green thumb, every time she thought she was making grow something it would what? Choices:  A: growth B: flowering C: ground D: die E: plants
Answer: D: die

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o8-tcommonsenseqa-s10-rFalse
Loading extension module utils...
Time to load utils op: 0.4043307304382324 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:52<42:39, 52.23s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:30<35:03, 43.83s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:20<36:47, 46.96s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [03:11<37:14, 48.57s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [04:03<37:07, 49.51s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [04:54<36:49, 50.22s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [05:46<36:20, 50.72s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [06:38<35:42, 51.00s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [07:29<34:56, 51.12s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [08:03<30:33, 45.84s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [08:53<30:41, 47.21s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [09:45<30:44, 48.55s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [10:19<27:11, 44.08s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [11:10<27:49, 46.38s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [12:01<27:51, 47.75s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [12:52<27:38, 48.78s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [13:41<26:51, 48.83s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [14:32<26:22, 49.45s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [15:24<25:50, 50.00s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [16:10<24:29, 48.98s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [16:47<21:53, 45.28s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [17:39<22:07, 47.39s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [18:31<21:59, 48.87s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [19:22<21:19, 49.23s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [20:12<20:38, 49.52s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [20:41<17:25, 43.56s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [21:33<17:38, 46.01s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [22:11<15:59, 43.60s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [23:02<16:01, 45.78s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [23:53<15:45, 47.29s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [24:44<15:22, 48.58s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [25:36<14:49, 49.44s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [26:22<13:42, 48.40s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [27:13<13:08, 49.27s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [27:33<10:07, 40.47s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [28:05<08:49, 37.79s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [28:56<09:05, 41.96s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [29:47<08:56, 44.69s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [30:39<08:33, 46.67s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [31:00<06:29, 38.96s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [31:51<06:23, 42.63s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [32:43<06:04, 45.51s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [33:35<05:31, 47.41s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [33:47<03:41, 36.92s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [34:39<03:27, 41.41s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [35:30<02:56, 44.10s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [35:48<01:49, 36.40s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [36:21<01:10, 35.25s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [37:06<00:38, 38.21s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [37:57<00:00, 42.26s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [37:57<00:00, 45.56s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.9785} | lm_loss 9.675 | avg. gen lenth: 213.724
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o9-tcommonsenseqa-s10-rFalse --seed 10 --num-out-domain 9
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-13 10:36:25,549] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o9-tcommonsenseqa-s10-rFalse
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 9
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o9-tcommonsenseqa-s10-rFalse
  rationales ................... False
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 10
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  1%|▍                                                    | 68/7473 [00:00<00:10, 675.78it/s]  2%|▉                                                   | 137/7473 [00:00<00:10, 681.07it/s]  3%|█▍                                                  | 207/7473 [00:00<00:10, 686.17it/s]  4%|█▉                                                  | 276/7473 [00:00<00:10, 684.05it/s]  5%|██▍                                                 | 345/7473 [00:00<00:10, 685.06it/s]  6%|██▉                                                 | 414/7473 [00:00<00:10, 683.35it/s]  6%|███▎                                                | 483/7473 [00:00<00:10, 680.15it/s]  7%|███▊                                                | 552/7473 [00:00<00:10, 668.41it/s]  8%|████▎                                               | 620/7473 [00:00<00:10, 668.91it/s]  9%|████▊                                               | 690/7473 [00:01<00:10, 676.45it/s] 10%|█████▎                                              | 759/7473 [00:01<00:09, 678.84it/s] 11%|█████▊                                              | 827/7473 [00:01<00:09, 678.81it/s] 12%|██████▏                                             | 896/7473 [00:01<00:09, 681.16it/s] 13%|██████▋                                             | 965/7473 [00:01<00:09, 681.90it/s] 14%|███████▏                                           | 1062/7473 [00:01<00:08, 767.21it/s] 16%|███████▉                                           | 1166/7473 [00:01<00:07, 846.70it/s] 17%|████████▋                                          | 1270/7473 [00:01<00:06, 904.14it/s] 18%|█████████▍                                         | 1374/7473 [00:01<00:06, 942.58it/s] 20%|██████████                                         | 1476/7473 [00:01<00:06, 965.48it/s] 21%|██████████▊                                        | 1580/7473 [00:02<00:05, 985.78it/s] 23%|███████████▍                                       | 1684/7473 [00:02<00:05, 999.67it/s] 24%|███████████▉                                      | 1788/7473 [00:02<00:05, 1010.71it/s] 25%|████████████▋                                     | 1891/7473 [00:02<00:05, 1014.66it/s] 27%|█████████████▎                                    | 1995/7473 [00:02<00:05, 1020.60it/s] 28%|██████████████                                    | 2098/7473 [00:02<00:05, 1019.71it/s] 29%|██████████████▋                                   | 2202/7473 [00:02<00:05, 1024.00it/s] 31%|███████████████▍                                  | 2306/7473 [00:02<00:05, 1026.26it/s] 32%|████████████████                                  | 2410/7473 [00:02<00:04, 1028.71it/s] 34%|████████████████▊                                 | 2515/7473 [00:02<00:04, 1032.68it/s] 35%|█████████████████▊                                 | 2619/7473 [00:03<00:04, 992.33it/s] 36%|██████████████████▏                               | 2723/7473 [00:03<00:04, 1003.78it/s] 38%|██████████████████▉                               | 2826/7473 [00:03<00:04, 1010.68it/s] 39%|███████████████████▌                              | 2930/7473 [00:03<00:04, 1018.84it/s] 41%|████████████████████▎                             | 3033/7473 [00:03<00:04, 1018.31it/s] 42%|████████████████████▉                             | 3136/7473 [00:03<00:04, 1020.58it/s] 43%|█████████████████████▋                            | 3239/7473 [00:03<00:04, 1021.01it/s] 45%|██████████████████████▎                           | 3342/7473 [00:03<00:04, 1021.18it/s] 46%|███████████████████████                           | 3445/7473 [00:03<00:03, 1019.88it/s] 47%|███████████████████████▋                          | 3549/7473 [00:03<00:03, 1023.05it/s] 49%|████████████████████████▍                         | 3652/7473 [00:04<00:03, 1024.90it/s] 50%|█████████████████████████                         | 3755/7473 [00:04<00:03, 1023.25it/s] 52%|█████████████████████████▊                        | 3859/7473 [00:04<00:03, 1025.85it/s] 53%|██████████████████████████▌                       | 3962/7473 [00:04<00:03, 1026.97it/s] 54%|███████████████████████████▏                      | 4065/7473 [00:04<00:03, 1022.54it/s] 56%|███████████████████████████▉                      | 4168/7473 [00:04<00:03, 1020.51it/s] 57%|████████████████████████████▌                     | 4272/7473 [00:04<00:03, 1024.89it/s] 59%|█████████████████████████████▎                    | 4376/7473 [00:04<00:03, 1026.89it/s] 60%|█████████████████████████████▉                    | 4480/7473 [00:04<00:02, 1027.70it/s] 61%|██████████████████████████████▋                   | 4584/7473 [00:04<00:02, 1029.94it/s] 63%|███████████████████████████████▎                  | 4687/7473 [00:05<00:02, 1025.57it/s] 64%|████████████████████████████████                  | 4790/7473 [00:05<00:02, 1021.76it/s] 65%|████████████████████████████████▋                 | 4894/7473 [00:05<00:02, 1024.86it/s] 67%|█████████████████████████████████▍                | 4998/7473 [00:05<00:02, 1026.47it/s] 68%|██████████████████████████████████▊                | 5101/7473 [00:05<00:02, 998.59it/s] 70%|██████████████████████████████████▊               | 5206/7473 [00:05<00:02, 1011.51it/s] 71%|████████████████████████████████████▏              | 5308/7473 [00:05<00:02, 986.46it/s] 72%|████████████████████████████████████▉              | 5408/7473 [00:05<00:02, 990.00it/s] 74%|█████████████████████████████████████▌             | 5508/7473 [00:05<00:02, 745.33it/s] 75%|██████████████████████████████████████▎            | 5612/7473 [00:06<00:02, 815.47it/s] 76%|███████████████████████████████████████            | 5715/7473 [00:06<00:02, 867.88it/s] 78%|███████████████████████████████████████▋           | 5819/7473 [00:06<00:01, 911.86it/s] 79%|████████████████████████████████████████▍          | 5922/7473 [00:06<00:01, 941.91it/s] 81%|█████████████████████████████████████████          | 6025/7473 [00:06<00:01, 966.60it/s] 82%|█████████████████████████████████████████▊         | 6130/7473 [00:06<00:01, 987.77it/s] 83%|█████████████████████████████████████████▋        | 6235/7473 [00:06<00:01, 1003.36it/s] 85%|██████████████████████████████████████████▍       | 6340/7473 [00:06<00:01, 1014.78it/s] 86%|███████████████████████████████████████████       | 6443/7473 [00:06<00:01, 1016.93it/s] 88%|███████████████████████████████████████████▊      | 6548/7473 [00:07<00:00, 1024.34it/s] 89%|████████████████████████████████████████████▌     | 6651/7473 [00:07<00:00, 1010.30it/s] 90%|█████████████████████████████████████████████▏    | 6755/7473 [00:07<00:00, 1018.28it/s] 92%|█████████████████████████████████████████████▉    | 6858/7473 [00:07<00:00, 1017.81it/s] 93%|██████████████████████████████████████████████▌   | 6962/7473 [00:07<00:00, 1022.61it/s] 95%|███████████████████████████████████████████████▎  | 7065/7473 [00:07<00:00, 1022.11it/s] 96%|███████████████████████████████████████████████▉  | 7168/7473 [00:07<00:00, 1023.19it/s] 97%|████████████████████████████████████████████████▋ | 7272/7473 [00:07<00:00, 1025.39it/s] 99%|█████████████████████████████████████████████████▎| 7375/7473 [00:07<00:00, 1026.39it/s]100%|███████████████████████████████████████████████████| 7473/7473 [00:07<00:00, 945.03it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.45s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.45s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.44s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.48s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.33s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.39s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.37s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.39s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.73s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.90s/it]
[2023-08-13 10:37:25,403] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.73s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.91s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.76s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.94s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.01s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.12s/it]
[2023-08-13 10:37:36,104] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-13 10:37:36,105] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-13 10:37:36,106] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-13 10:37:36,106] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-13 10:37:36,106] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-13 10:37:36,106] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-13 10:37:36,107] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-13 10:37:36,107] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-13 10:37:36,107] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-13 10:37:36,107] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-13 10:37:36,107] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-13 10:37:36,107] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f843a138b20>
[2023-08-13 10:37:36,107] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-13 10:37:36,107] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-13 10:37:36,107] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-13 10:37:36,107] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-13 10:37:36,107] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-13 10:37:36,107] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-13 10:37:36,107] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-13 10:37:36,107] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-13 10:37:36,107] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-13 10:37:36,107] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-13 10:37:36,107] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-13 10:37:36,107] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-13 10:37:36,107] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-13 10:37:36,107] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-13 10:37:36,107] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-13 10:37:36,107] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-13 10:37:36,107] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-13 10:37:36,107] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-13 10:37:36,107] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f843a1388b0>
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-13 10:37:36,108] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-13 10:37:36,109] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-13 10:37:36,109] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-13 10:37:36,109] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.42762327194213867 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Loading extension module utils...
Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]Time to load utils op: 0.4043877124786377 seconds
############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: Fabric is cut to order at what type of seller? Choices:  A: curtains B: tailor shop C: clothing store D: sewing room E: hardware store
Answer: B: tailor shop

Input: Where are you if your reading magazines while waiting for a vehicle on rails? Choices:  A: vegetables B: market C: doctor D: train station E: bookstore
Answer: D: train station

Input: What would need oil to be used? Choices:  A: ground B: human  body C: repair shop D: combustion engines E: service station
Answer: D: combustion engines

Input: What is person probably feeling that plans on stopping being married to their spouse? Choices:  A: detachment B: bankruptcy C: sad D: fights E: wrong
Answer: A: detachment

Input: What could you use to store a clock? Choices:  A: shelf B: own bedroom C: desk D: wall E: car
Answer: A: shelf

Input: The person put on lotion, what did they want? Choices:  A: fresh smell B: good credit C: smooth skin D: fresh produce E: headache
Answer: C: smooth skin

Input: They burned the record, they were trying to do what to history? Choices:  A: compact disc B: tape C: rewrite D: play music E: erase
Answer: E: erase

Input: She sure didn't have a green thumb, every time she thought she was making grow something it would what? Choices:  A: growth B: flowering C: ground D: die E: plants
Answer: D: die

Input: After a long night out the drunken man lost consciousness, he showed a sign of sickness right before passing out, what was it? Choices:  A: dream B: vomiting C: panic D: cancer E: blurred vision
Answer: B: vomiting

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o9-tcommonsenseqa-s10-rFalse
Loading extension module utils...
Time to load utils op: 0.3045015335083008 seconds
Loading extension module utils...
Time to load utils op: 0.5051071643829346 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:41<33:46, 41.35s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:31<37:25, 46.78s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:22<37:57, 48.46s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [03:13<37:57, 49.51s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [04:03<37:20, 49.80s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [04:53<36:30, 49.79s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [05:43<35:48, 49.97s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [06:34<35:03, 50.08s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [07:01<29:15, 42.81s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [07:51<30:00, 45.01s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [08:39<30:02, 46.21s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [09:30<30:06, 47.55s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [10:06<27:10, 44.07s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [10:56<27:34, 45.96s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [11:11<21:16, 36.48s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [11:38<19:02, 33.61s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [12:27<21:05, 38.35s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [13:18<22:22, 41.96s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [14:08<22:55, 44.37s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [14:48<21:38, 43.27s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [15:26<20:05, 41.55s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [16:13<20:07, 43.12s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [17:02<20:12, 44.91s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [17:52<20:09, 46.51s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [18:41<19:43, 47.34s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [19:17<17:32, 43.84s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [20:07<17:30, 45.66s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [20:57<17:12, 46.94s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [21:43<16:18, 46.60s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [22:10<13:37, 40.86s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [22:59<13:45, 43.43s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [23:50<13:37, 45.44s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [24:41<13:23, 47.29s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [25:32<12:54, 48.41s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [26:23<12:17, 49.16s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [26:52<10:01, 42.98s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [27:21<08:24, 38.78s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [28:11<08:28, 42.38s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [28:46<07:19, 39.94s/it]Evaluating gsm8k :  80%|█████████████████████████████▌       | 40/50 [29:35<07:06, 42.69s/it]Evaluating gsm8k :  82%|██████████████████████████████▎      | 41/50 [30:12<06:10, 41.14s/it]Evaluating gsm8k :  84%|███████████████████████████████      | 42/50 [31:03<05:53, 44.15s/it]Evaluating gsm8k :  86%|███████████████████████████████▊     | 43/50 [31:35<04:42, 40.41s/it]Evaluating gsm8k :  88%|████████████████████████████████▌    | 44/50 [32:27<04:22, 43.73s/it]Evaluating gsm8k :  90%|█████████████████████████████████▎   | 45/50 [33:17<03:49, 45.81s/it]Evaluating gsm8k :  92%|██████████████████████████████████   | 46/50 [34:08<03:09, 47.29s/it]Evaluating gsm8k :  94%|██████████████████████████████████▊  | 47/50 [34:40<02:07, 42.54s/it]Evaluating gsm8k :  96%|███████████████████████████████████▌ | 48/50 [35:31<01:30, 45.19s/it]Evaluating gsm8k :  98%|████████████████████████████████████▎| 49/50 [36:22<00:46, 46.97s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [36:39<00:00, 38.04s/it]Evaluating gsm8k : 100%|█████████████████████████████████████| 50/50 [36:39<00:00, 43.99s/it]
name: gsm8k | {'exact_match': 0.0, 'rougeL': 0.3422} | lm_loss 9.7187 | avg. gen lenth: 229.216
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name gsm8k --num-eval 1000 --num-workers 0 --num-in-domain 0 --out-domain-data-name commonsenseqa --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 5 --data-dir /scratch/ylu130/processed_data/gsm8k/out-domain/o1-tcommonsenseqa-s20-rTrue --seed 20 --rationales --num-out-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date![nltk_data]   Package punkt is already up-to-date!

[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-13 11:15:09,345] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... gsm8k
  data_dir ..................... /scratch/ylu130/processed_data/gsm8k/out-domain/o1-tcommonsenseqa-s20-rTrue
  processed_data_dir ........... None
  num_eval ..................... 1000
  num_in_domain ................ 0
  num_out_domain ............... 1
  out_domain_data_name ......... commonsenseqa
  out_domain_data_dir .......... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o1-tcommonsenseqa-s20-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  num_beams .................... 1
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 5
  clip_grad .................... 1.0
  seed ......................... 20
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                               | 0/7473 [00:00<?, ?it/s]  1%|▋                                                   | 100/7473 [00:00<00:07, 990.24it/s]  3%|█▍                                                 | 202/7473 [00:00<00:07, 1002.62it/s]  4%|██                                                 | 303/7473 [00:00<00:07, 1005.19it/s]  5%|██▊                                                | 404/7473 [00:00<00:07, 1005.14it/s]  7%|███▍                                               | 505/7473 [00:00<00:06, 1001.96it/s]  8%|████▏                                              | 607/7473 [00:00<00:06, 1008.01it/s]  9%|████▊                                              | 709/7473 [00:00<00:06, 1010.34it/s] 11%|█████▌                                             | 812/7473 [00:00<00:06, 1014.79it/s] 12%|██████▎                                             | 914/7473 [00:00<00:06, 996.82it/s] 14%|██████▉                                            | 1014/7473 [00:01<00:06, 997.56it/s] 15%|███████▍                                          | 1117/7473 [00:01<00:06, 1005.79it/s] 16%|████████▏                                         | 1218/7473 [00:01<00:06, 1003.69it/s] 18%|████████▊                                         | 1320/7473 [00:01<00:06, 1005.94it/s] 19%|█████████▌                                        | 1421/7473 [00:01<00:06, 1002.18it/s] 20%|██████████▏                                       | 1523/7473 [00:01<00:05, 1006.63it/s] 22%|███████████                                        | 1624/7473 [00:01<00:05, 999.54it/s] 23%|███████████▌                                      | 1726/7473 [00:01<00:05, 1004.98it/s] 24%|████████████▏                                     | 1827/7473 [00:01<00:05, 1002.99it/s] 26%|█████████████▏                                     | 1928/7473 [00:01<00:05, 995.74it/s] 27%|█████████████▊                                     | 2029/7473 [00:02<00:05, 998.61it/s] 28%|██████████████▌                                    | 2129/7473 [00:02<00:05, 998.36it/s] 30%|██████████████▉                                   | 2231/7473 [00:02<00:05, 1004.10it/s] 31%|███████████████▌                                  | 2332/7473 [00:02<00:05, 1004.13it/s] 33%|████████████████▎                                 | 2434/7473 [00:02<00:05, 1007.14it/s] 34%|█████████████████▎                                 | 2535/7473 [00:02<00:04, 992.54it/s] 36%|█████████████████▉                                | 2690/7473 [00:02<00:04, 1155.71it/s] 38%|███████████████████                               | 2844/7473 [00:02<00:03, 1268.86it/s] 40%|████████████████████                              | 2999/7473 [00:02<00:03, 1350.53it/s] 42%|█████████████████████                             | 3151/7473 [00:02<00:03, 1400.47it/s] 44%|██████████████████████                            | 3304/7473 [00:03<00:02, 1437.90it/s] 46%|███████████████████████                           | 3454/7473 [00:03<00:02, 1455.27it/s] 48%|████████████████████████                          | 3602/7473 [00:03<00:02, 1462.17it/s] 50%|█████████████████████████                         | 3752/7473 [00:03<00:02, 1471.17it/s] 52%|██████████████████████████                        | 3904/7473 [00:03<00:02, 1485.09it/s] 54%|███████████████████████████▏                      | 4059/7473 [00:03<00:02, 1502.39it/s] 56%|████████████████████████████▏                     | 4210/7473 [00:03<00:02, 1501.89it/s] 58%|█████████████████████████████▏                    | 4362/7473 [00:03<00:02, 1505.07it/s] 60%|██████████████████████████████▏                   | 4513/7473 [00:03<00:01, 1497.20it/s] 62%|███████████████████████████████▏                  | 4665/7473 [00:03<00:01, 1500.75it/s] 64%|████████████████████████████████▏                 | 4817/7473 [00:04<00:01, 1505.88it/s] 66%|█████████████████████████████████▏                | 4969/7473 [00:04<00:01, 1509.29it/s] 69%|██████████████████████████████████▎               | 5122/7473 [00:04<00:01, 1512.88it/s] 71%|███████████████████████████████████▎              | 5274/7473 [00:04<00:01, 1476.40it/s] 73%|████████████████████████████████████▎             | 5426/7473 [00:04<00:01, 1488.85it/s] 75%|█████████████████████████████████████▎            | 5576/7473 [00:04<00:01, 1085.24it/s] 77%|██████████████████████████████████████▎           | 5728/7473 [00:04<00:01, 1186.74it/s] 79%|███████████████████████████████████████▎          | 5880/7473 [00:04<00:01, 1269.44it/s] 81%|████████████████████████████████████████▎         | 6030/7473 [00:04<00:01, 1327.80it/s] 83%|█████████████████████████████████████████▎        | 6183/7473 [00:05<00:00, 1382.19it/s] 85%|██████████████████████████████████████████▍       | 6337/7473 [00:05<00:00, 1425.74it/s] 87%|███████████████████████████████████████████▍      | 6487/7473 [00:05<00:00, 1446.75it/s] 89%|████████████████████████████████████████████▍     | 6638/7473 [00:05<00:00, 1462.90it/s] 91%|█████████████████████████████████████████████▍    | 6790/7473 [00:05<00:00, 1477.48it/s] 93%|██████████████████████████████████████████████▍   | 6942/7473 [00:05<00:00, 1489.01it/s] 95%|███████████████████████████████████████████████▍  | 7093/7473 [00:05<00:00, 1489.15it/s] 97%|████████████████████████████████████████████████▍ | 7243/7473 [00:05<00:00, 1488.12it/s] 99%|█████████████████████████████████████████████████▍| 7393/7473 [00:05<00:00, 1490.15it/s]100%|██████████████████████████████████████████████████| 7473/7473 [00:05<00:00, 1259.58it/s]
Load End
Num instances: 1000
Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.08s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:10,  5.36s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.88s/it]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:05<00:11,  5.64s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:09<00:04,  4.96s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.31s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:10<00:05,  5.43s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:11<00:05,  5.73s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.38s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:13<00:00,  4.55s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.67s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:14<00:00,  4.85s/it]
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  4.85s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.03s/it]
[2023-08-13 11:16:07,893] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.10s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:15<00:00,  5.28s/it]
[2023-08-13 11:16:17,083] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-13 11:16:17,084] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-13 11:16:17,084] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-13 11:16:17,084] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-13 11:16:17,084] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-13 11:16:17,084] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-13 11:16:17,084] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f5255aeefa0>
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f5255afb700>
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   train_batch_size ............. 20
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  5
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-13 11:16:17,085] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-13 11:16:17,086] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-13 11:16:17,086] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-13 11:16:17,086] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-13 11:16:17,086] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-13 11:16:17,086] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-13 11:16:17,086] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 5, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.4010169506072998 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Loading extension module utils...
Evaluating gsm8k :   0%|                                              | 0/50 [00:00<?, ?it/s]Time to load utils op: 0.30416345596313477 seconds
############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following grade math question.

### Demonstration:
Input: The machine was very intricate, it was quite an what? Choices:  A: box B: apparatus C: appliance D: wash dishes E: implement
Rationales: 1. The given statement describes the machine as "intricate" which means it is complex and detailed.
2. We need to choose a word among the options that best fits with the description of the machine.
3. "Box" is too plain and does not directly imply complexity.
4. "Appliance" typically refers to a simple device used for a particular purpose, not necessarily intricate.
5. "Wash dishes" is an action, not a description of a thing.
6. "Implement" refers to a tool, but it doesn't necessarily suggest complexity.
7. "Apparatus", on the other hand, represents a complex structure within a machine or system.
8. Therefore, the word that best fits the description of the machine in the context of the sentence is "apparatus". Hence, the answer is B: apparatus.
Answer: B: apparatus

### Input:Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?

### Response:
############### End ###############
Experiment Save Path: /home/ylu130/workspace/in-context-generalization/results/llama2-7b/gsm8k/out-domain/o1-tcommonsenseqa-s20-rTrue
Loading extension module utils...
Time to load utils op: 0.3041973114013672 seconds
Loading extension module utils...
Time to load utils op: 0.40444421768188477 seconds
Evaluating gsm8k :   2%|▊                                     | 1/50 [00:49<40:26, 49.52s/it]Evaluating gsm8k :   4%|█▌                                    | 2/50 [01:41<40:35, 50.74s/it]Evaluating gsm8k :   6%|██▎                                   | 3/50 [02:34<40:38, 51.87s/it]Evaluating gsm8k :   8%|███                                   | 4/50 [03:27<40:08, 52.36s/it]Evaluating gsm8k :  10%|███▊                                  | 5/50 [04:19<39:18, 52.41s/it]Evaluating gsm8k :  12%|████▌                                 | 6/50 [05:12<38:34, 52.61s/it]Evaluating gsm8k :  14%|█████▎                                | 7/50 [06:06<37:51, 52.81s/it]Evaluating gsm8k :  16%|██████                                | 8/50 [06:59<37:01, 52.88s/it]Evaluating gsm8k :  18%|██████▊                               | 9/50 [07:52<36:15, 53.06s/it]Evaluating gsm8k :  20%|███████▍                             | 10/50 [08:37<33:41, 50.54s/it]Evaluating gsm8k :  22%|████████▏                            | 11/50 [09:11<29:32, 45.45s/it]Evaluating gsm8k :  24%|████████▉                            | 12/50 [09:30<23:45, 37.52s/it]Evaluating gsm8k :  26%|█████████▌                           | 13/50 [10:23<25:57, 42.10s/it]Evaluating gsm8k :  28%|██████████▎                          | 14/50 [11:17<27:23, 45.65s/it]Evaluating gsm8k :  30%|███████████                          | 15/50 [12:10<27:52, 47.78s/it]Evaluating gsm8k :  32%|███████████▊                         | 16/50 [13:02<27:54, 49.25s/it]Evaluating gsm8k :  34%|████████████▌                        | 17/50 [13:55<27:36, 50.19s/it]Evaluating gsm8k :  36%|█████████████▎                       | 18/50 [14:48<27:12, 51.02s/it]Evaluating gsm8k :  38%|██████████████                       | 19/50 [15:38<26:13, 50.77s/it]Evaluating gsm8k :  40%|██████████████▊                      | 20/50 [16:30<25:35, 51.18s/it]Evaluating gsm8k :  42%|███████████████▌                     | 21/50 [17:23<25:03, 51.86s/it]Evaluating gsm8k :  44%|████████████████▎                    | 22/50 [18:15<24:13, 51.91s/it]Evaluating gsm8k :  46%|█████████████████                    | 23/50 [19:09<23:32, 52.30s/it]Evaluating gsm8k :  48%|█████████████████▊                   | 24/50 [19:39<19:47, 45.66s/it]Evaluating gsm8k :  50%|██████████████████▌                  | 25/50 [20:32<19:57, 47.92s/it]Evaluating gsm8k :  52%|███████████████████▏                 | 26/50 [21:25<19:46, 49.43s/it]Evaluating gsm8k :  54%|███████████████████▉                 | 27/50 [22:18<19:22, 50.56s/it]Evaluating gsm8k :  56%|████████████████████▋                | 28/50 [23:11<18:46, 51.19s/it]Evaluating gsm8k :  58%|█████████████████████▍               | 29/50 [23:46<16:15, 46.47s/it]Evaluating gsm8k :  60%|██████████████████████▏              | 30/50 [24:14<13:38, 40.92s/it]Evaluating gsm8k :  62%|██████████████████████▉              | 31/50 [25:06<14:02, 44.34s/it]Evaluating gsm8k :  64%|███████████████████████▋             | 32/50 [25:30<11:25, 38.07s/it]Evaluating gsm8k :  66%|████████████████████████▍            | 33/50 [26:23<12:04, 42.63s/it]Evaluating gsm8k :  68%|█████████████████████████▏           | 34/50 [27:17<12:16, 46.03s/it]Evaluating gsm8k :  70%|█████████████████████████▉           | 35/50 [28:11<12:07, 48.48s/it]Evaluating gsm8k :  72%|██████████████████████████▋          | 36/50 [28:50<10:39, 45.65s/it]Evaluating gsm8k :  74%|███████████████████████████▍         | 37/50 [29:44<10:24, 48.02s/it]Evaluating gsm8k :  76%|████████████████████████████         | 38/50 [30:37<09:54, 49.56s/it]Evaluating gsm8k :  78%|████████████████████████████▊        | 39/50 [31:30<09:17, 50.71s/it]