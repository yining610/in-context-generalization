PYTHONPATH=/home/ylu130/workspace/in-context-generalization
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 800 --num-workers 0 --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 8 --seed 42 --data-dir /scratch/ylu130/processed_data/commonsenseqa/n0-seed42-rationalesTrue --rationales --num-in-domain 0
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-07 14:37:18,593] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/n0-seed42-rationalesTrue
  processed_data_dir ........... None
  num_eval ..................... 800
  num_in_domain ................ 0
  num_out_domain ............... None
  out_domain ................... None
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/t1-m512-i0-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 8
  clip_grad .................... 1.0
  seed ......................... 42
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                                                                                                             | 0/9741 [00:00<?, ?it/s]  3%|████▎                                                                                                                            | 321/9741 [00:00<00:02, 3205.99it/s]  7%|████████▌                                                                                                                        | 643/9741 [00:00<00:02, 3209.48it/s] 10%|████████████▊                                                                                                                    | 969/9741 [00:00<00:02, 3231.19it/s] 13%|█████████████████                                                                                                               | 1295/9741 [00:00<00:02, 3242.24it/s] 17%|█████████████████████▎                                                                                                          | 1620/9741 [00:00<00:02, 3231.74it/s] 20%|█████████████████████████▌                                                                                                      | 1944/9741 [00:00<00:02, 3215.11it/s] 23%|█████████████████████████████▊                                                                                                  | 2266/9741 [00:00<00:02, 3210.47it/s] 27%|██████████████████████████████████                                                                                              | 2589/9741 [00:00<00:02, 3216.49it/s] 30%|██████████████████████████████████████▎                                                                                         | 2911/9741 [00:00<00:02, 3149.39it/s] 33%|██████████████████████████████████████████▍                                                                                     | 3231/9741 [00:01<00:02, 3163.04it/s] 36%|██████████████████████████████████████████████▋                                                                                 | 3552/9741 [00:01<00:01, 3176.20it/s] 40%|██████████████████████████████████████████████████▉                                                                             | 3874/9741 [00:01<00:01, 3187.87it/s] 43%|███████████████████████████████████████████████████████▏                                                                        | 4197/9741 [00:01<00:01, 3199.41it/s] 46%|███████████████████████████████████████████████████████████▎                                                                    | 4518/9741 [00:01<00:01, 3163.18it/s] 50%|███████████████████████████████████████████████████████████████▌                                                                | 4835/9741 [00:01<00:02, 2326.86it/s] 53%|███████████████████████████████████████████████████████████████████▊                                                            | 5157/9741 [00:01<00:01, 2538.19it/s] 56%|███████████████████████████████████████████████████████████████████████▉                                                        | 5478/9741 [00:01<00:01, 2706.57it/s] 60%|████████████████████████████████████████████████████████████████████████████▎                                                   | 5810/9741 [00:01<00:01, 2868.63it/s] 63%|████████████████████████████████████████████████████████████████████████████████▋                                               | 6145/9741 [00:02<00:01, 2998.73it/s] 67%|█████████████████████████████████████████████████████████████████████████████████████▏                                          | 6480/9741 [00:02<00:01, 3095.63it/s] 71%|██████████████████████████████████████████████████████████████████████████████████████████▉                                     | 6922/9741 [00:02<00:00, 3474.96it/s] 76%|█████████████████████████████████████████████████████████████████████████████████████████████████▊                              | 7440/9741 [00:02<00:00, 3970.39it/s] 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████▎                       | 7943/9741 [00:02<00:00, 4279.31it/s] 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                | 8460/9741 [00:02<00:00, 4541.52it/s] 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉          | 8975/9741 [00:02<00:00, 4719.86it/s] 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋   | 9493/9741 [00:02<00:00, 4855.67it/s]100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:02<00:00, 3495.36it/s]
Load End
Num instances: 800
Loading checkpoint shards:   0%|                                                                                                                     | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                                                                                     | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                                                                                     | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                                                                                     | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|████████████████████████████████████▎                                                                        | 1/3 [00:05<00:10,  5.11s/it]Loading checkpoint shards:  33%|████████████████████████████████████▎                                                                        | 1/3 [00:05<00:10,  5.22s/it]Loading checkpoint shards:  33%|████████████████████████████████████▎                                                                        | 1/3 [00:05<00:11,  5.64s/it]Loading checkpoint shards:  33%|████████████████████████████████████▎                                                                        | 1/3 [00:05<00:10,  5.49s/it]Loading checkpoint shards:  67%|████████████████████████████████████████████████████████████████████████▋                                    | 2/3 [00:10<00:05,  5.11s/it]Loading checkpoint shards:  67%|████████████████████████████████████████████████████████████████████████▋                                    | 2/3 [00:10<00:05,  5.21s/it]Loading checkpoint shards:  67%|████████████████████████████████████████████████████████████████████████▋                                    | 2/3 [00:10<00:05,  5.43s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.53s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.70s/it]
[2023-08-07 14:38:12,797] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.60s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.75s/it]
Loading checkpoint shards:  67%|████████████████████████████████████████████████████████████████████████▋                                    | 2/3 [00:10<00:05,  5.35s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:15<00:00,  4.83s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.02s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.70s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.89s/it]
[2023-08-07 14:38:23,998] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-07 14:38:24,000] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-07 14:38:24,000] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-07 14:38:24,000] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-07 14:38:24,000] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-07 14:38:24,000] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-07 14:38:24,001] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-07 14:38:24,001] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-07 14:38:24,001] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-07 14:38:24,001] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-07 14:38:24,001] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-07 14:38:24,001] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fb2c18b3c10>
[2023-08-07 14:38:24,001] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-07 14:38:24,001] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-07 14:38:24,001] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-07 14:38:24,001] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-07 14:38:24,001] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-07 14:38:24,001] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-07 14:38:24,001] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-07 14:38:24,001] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-07 14:38:24,001] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-07 14:38:24,001] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-07 14:38:24,001] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-07 14:38:24,001] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-07 14:38:24,001] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-07 14:38:24,001] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-07 14:38:24,001] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-07 14:38:24,001] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-07 14:38:24,001] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-07 14:38:24,001] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-07 14:38:24,001] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-07 14:38:24,001] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fb2c18b32b0>
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   train_batch_size ............. 32
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  8
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-07 14:38:24,002] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-07 14:38:24,003] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-07 14:38:24,003] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-07 14:38:24,003] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 8, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.34490275382995605 seconds
Loading extension module utils...
Time to load utils op: 0.3043508529663086 seconds
Loading extension module utils...
Loading extension module utils...
Time to load utils op: 0.30442094802856445 seconds
Time to load utils op: 0.3041074275970459 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                                                                    | 0/25 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following multiple choice question.

### Demonstration:None

### Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid

### Response:
############### End ###############
Evaluating commonsenseqa :   4%|████▎                                                                                                       | 1/25 [01:30<36:09, 90.38s/it]Evaluating commonsenseqa :   8%|████████▋                                                                                                   | 2/25 [01:46<17:55, 46.74s/it]Evaluating commonsenseqa :  12%|████████████▉                                                                                               | 3/25 [03:16<24:17, 66.25s/it]Evaluating commonsenseqa :  16%|█████████████████▎                                                                                          | 4/25 [04:45<26:25, 75.51s/it]Evaluating commonsenseqa :  20%|█████████████████████▌                                                                                      | 5/25 [06:14<26:48, 80.44s/it]Evaluating commonsenseqa :  24%|█████████████████████████▉                                                                                  | 6/25 [07:24<24:19, 76.83s/it]Evaluating commonsenseqa :  28%|██████████████████████████████▏                                                                             | 7/25 [08:04<19:27, 64.83s/it]Evaluating commonsenseqa :  32%|██████████████████████████████████▌                                                                         | 8/25 [08:22<14:07, 49.84s/it]Evaluating commonsenseqa :  36%|██████████████████████████████████████▉                                                                     | 9/25 [09:51<16:32, 62.06s/it]Evaluating commonsenseqa :  40%|██████████████████████████████████████████▊                                                                | 10/25 [10:49<15:11, 60.75s/it]Evaluating commonsenseqa :  44%|███████████████████████████████████████████████                                                            | 11/25 [12:18<16:13, 69.51s/it]Evaluating commonsenseqa :  48%|███████████████████████████████████████████████████▎                                                       | 12/25 [13:48<16:22, 75.59s/it]Evaluating commonsenseqa :  52%|███████████████████████████████████████████████████████▋                                                   | 13/25 [15:02<15:03, 75.32s/it]Evaluating commonsenseqa :  56%|███████████████████████████████████████████████████████████▉                                               | 14/25 [16:32<14:35, 79.57s/it]Evaluating commonsenseqa :  60%|████████████████████████████████████████████████████████████████▏                                          | 15/25 [17:16<11:30, 69.02s/it]Evaluating commonsenseqa :  64%|████████████████████████████████████████████████████████████████████▍                                      | 16/25 [18:36<10:50, 72.25s/it]Evaluating commonsenseqa :  68%|████████████████████████████████████████████████████████████████████████▊                                  | 17/25 [19:47<09:33, 71.68s/it]Evaluating commonsenseqa :  72%|█████████████████████████████████████████████████████████████████████████████                              | 18/25 [20:38<07:40, 65.76s/it]Evaluating commonsenseqa :  76%|█████████████████████████████████████████████████████████████████████████████████▎                         | 19/25 [21:21<05:52, 58.82s/it]Evaluating commonsenseqa :  80%|█████████████████████████████████████████████████████████████████████████████████████▌                     | 20/25 [22:48<05:36, 67.36s/it]Evaluating commonsenseqa :  84%|█████████████████████████████████████████████████████████████████████████████████████████▉                 | 21/25 [23:30<03:58, 59.73s/it]Evaluating commonsenseqa :  88%|██████████████████████████████████████████████████████████████████████████████████████████████▏            | 22/25 [24:09<02:39, 53.30s/it]Evaluating commonsenseqa :  92%|██████████████████████████████████████████████████████████████████████████████████████████████████▍        | 23/25 [24:33<01:29, 44.76s/it]Evaluating commonsenseqa :  96%|██████████████████████████████████████████████████████████████████████████████████████████████████████▋    | 24/25 [25:11<00:42, 42.67s/it]Evaluating commonsenseqa : 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [25:48<00:00, 40.95s/it]Evaluating commonsenseqa : 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [25:48<00:00, 61.95s/it]
name: commonsenseqa | {'exact_match': 0.0, 'rougeL': 2.5847} | lm_loss 7.3728 | avg. gen lenth: 110.69
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 800 --num-workers 0 --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 8 --seed 42 --data-dir /scratch/ylu130/processed_data/commonsenseqa/n1-seed42-rationalesTrue --rationales --num-in-domain 1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-07 15:06:46,709] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/n1-seed42-rationalesTrue
  processed_data_dir ........... None
  num_eval ..................... 800
  num_in_domain ................ 1
  num_out_domain ............... None
  cross ........................ False
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/t1-m512-i1-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 8
  clip_grad .................... 1.0
  seed ......................... 42
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                                                                                                             | 0/9740 [00:00<?, ?it/s]  1%|▉                                                                                                                                  | 69/9740 [00:00<00:14, 687.46it/s]  1%|█▊                                                                                                                                | 139/9740 [00:00<00:13, 692.25it/s]  2%|██▊                                                                                                                               | 209/9740 [00:00<00:13, 688.85it/s]  3%|███▋                                                                                                                              | 279/9740 [00:00<00:13, 689.54it/s]  4%|████▋                                                                                                                             | 349/9740 [00:00<00:13, 689.72it/s]  4%|█████▌                                                                                                                            | 419/9740 [00:00<00:13, 690.49it/s]  5%|██████▌                                                                                                                           | 489/9740 [00:00<00:13, 688.87it/s]  6%|███████▍                                                                                                                          | 558/9740 [00:00<00:13, 677.77it/s]  6%|████████▎                                                                                                                         | 627/9740 [00:00<00:13, 679.60it/s]  7%|█████████▎                                                                                                                        | 696/9740 [00:01<00:13, 680.71it/s]  8%|██████████▏                                                                                                                       | 765/9740 [00:01<00:13, 682.68it/s]  9%|███████████▏                                                                                                                      | 835/9740 [00:01<00:12, 685.23it/s]  9%|████████████                                                                                                                      | 904/9740 [00:01<00:12, 685.20it/s] 10%|████████████▉                                                                                                                     | 973/9740 [00:01<00:12, 686.01it/s] 11%|█████████████▊                                                                                                                   | 1043/9740 [00:01<00:12, 687.34it/s] 11%|██████████████▋                                                                                                                  | 1112/9740 [00:01<00:12, 686.71it/s] 12%|███████████████▋                                                                                                                 | 1181/9740 [00:01<00:12, 686.78it/s] 13%|████████████████▌                                                                                                                | 1250/9740 [00:01<00:12, 683.45it/s] 14%|█████████████████▊                                                                                                               | 1344/9740 [00:01<00:11, 759.66it/s] 15%|███████████████████▏                                                                                                             | 1450/9740 [00:02<00:09, 848.68it/s] 16%|████████████████████▌                                                                                                            | 1556/9740 [00:02<00:08, 911.11it/s] 17%|██████████████████████                                                                                                           | 1662/9740 [00:02<00:08, 953.65it/s] 18%|███████████████████████▍                                                                                                         | 1768/9740 [00:02<00:08, 985.34it/s] 19%|████████████████████████▋                                                                                                        | 1867/9740 [00:02<00:08, 984.01it/s] 20%|█████████████████████████▉                                                                                                      | 1973/9740 [00:02<00:07, 1005.51it/s] 21%|███████████████████████████▎                                                                                                    | 2078/9740 [00:02<00:07, 1017.85it/s] 22%|████████████████████████████▋                                                                                                   | 2184/9740 [00:02<00:07, 1029.46it/s] 24%|██████████████████████████████                                                                                                  | 2290/9740 [00:02<00:07, 1036.03it/s] 25%|███████████████████████████████▍                                                                                                | 2396/9740 [00:02<00:07, 1042.77it/s] 26%|████████████████████████████████▉                                                                                               | 2502/9740 [00:03<00:06, 1046.03it/s] 27%|██████████████████████████████████▎                                                                                             | 2608/9740 [00:03<00:06, 1049.67it/s] 28%|███████████████████████████████████▋                                                                                            | 2713/9740 [00:03<00:06, 1048.59it/s] 29%|█████████████████████████████████████                                                                                           | 2819/9740 [00:03<00:06, 1049.21it/s] 30%|██████████████████████████████████████▍                                                                                         | 2925/9740 [00:03<00:06, 1052.36it/s] 31%|███████████████████████████████████████▊                                                                                        | 3031/9740 [00:03<00:06, 1051.81it/s] 32%|█████████████████████████████████████████▏                                                                                      | 3137/9740 [00:03<00:06, 1052.61it/s] 33%|██████████████████████████████████████████▌                                                                                     | 3243/9740 [00:03<00:06, 1052.25it/s] 34%|████████████████████████████████████████████                                                                                    | 3349/9740 [00:03<00:06, 1051.53it/s] 35%|█████████████████████████████████████████████▍                                                                                  | 3455/9740 [00:03<00:06, 1042.76it/s] 37%|██████████████████████████████████████████████▊                                                                                 | 3560/9740 [00:04<00:05, 1043.43it/s] 38%|████████████████████████████████████████████████▏                                                                               | 3665/9740 [00:04<00:05, 1044.16it/s] 39%|█████████████████████████████████████████████████▌                                                                              | 3771/9740 [00:04<00:05, 1048.11it/s] 40%|██████████████████████████████████████████████████▉                                                                             | 3876/9740 [00:04<00:05, 1047.49it/s] 41%|████████████████████████████████████████████████████▎                                                                           | 3981/9740 [00:04<00:05, 1042.35it/s] 42%|█████████████████████████████████████████████████████▋                                                                          | 4086/9740 [00:04<00:05, 1043.90it/s] 43%|███████████████████████████████████████████████████████                                                                         | 4192/9740 [00:04<00:05, 1046.71it/s] 44%|████████████████████████████████████████████████████████▍                                                                       | 4298/9740 [00:04<00:05, 1048.45it/s] 45%|█████████████████████████████████████████████████████████▉                                                                      | 4404/9740 [00:04<00:05, 1051.11it/s] 46%|███████████████████████████████████████████████████████████▎                                                                    | 4510/9740 [00:04<00:04, 1053.34it/s] 47%|████████████████████████████████████████████████████████████▋                                                                   | 4616/9740 [00:05<00:04, 1026.60it/s] 48%|██████████████████████████████████████████████████████████████                                                                  | 4723/9740 [00:05<00:04, 1036.60it/s] 50%|███████████████████████████████████████████████████████████████▉                                                                 | 4827/9740 [00:05<00:05, 839.93it/s] 51%|█████████████████████████████████████████████████████████████████▎                                                               | 4933/9740 [00:05<00:05, 893.96it/s] 52%|██████████████████████████████████████████████████████████████████▋                                                              | 5038/9740 [00:05<00:05, 934.27it/s] 53%|████████████████████████████████████████████████████████████████████▏                                                            | 5144/9740 [00:05<00:04, 967.37it/s] 54%|█████████████████████████████████████████████████████████████████████▍                                                           | 5246/9740 [00:05<00:04, 981.66it/s] 55%|██████████████████████████████████████████████████████████████████████▎                                                         | 5352/9740 [00:05<00:04, 1001.65it/s] 56%|███████████████████████████████████████████████████████████████████████▋                                                        | 5457/9740 [00:05<00:04, 1014.36it/s] 57%|█████████████████████████████████████████████████████████████████████████▏                                                      | 5567/9740 [00:06<00:04, 1037.15it/s] 58%|██████████████████████████████████████████████████████████████████████████▌                                                     | 5676/9740 [00:06<00:03, 1050.57it/s] 59%|████████████████████████████████████████████████████████████████████████████                                                    | 5786/9740 [00:06<00:03, 1063.09it/s] 61%|█████████████████████████████████████████████████████████████████████████████▍                                                  | 5895/9740 [00:06<00:03, 1069.93it/s] 62%|██████████████████████████████████████████████████████████████████████████████▉                                                 | 6003/9740 [00:06<00:03, 1072.18it/s] 63%|████████████████████████████████████████████████████████████████████████████████▎                                               | 6113/9740 [00:06<00:03, 1077.52it/s] 64%|█████████████████████████████████████████████████████████████████████████████████▊                                              | 6223/9740 [00:06<00:03, 1082.78it/s] 65%|███████████████████████████████████████████████████████████████████████████████████▏                                            | 6333/9740 [00:06<00:03, 1085.45it/s] 66%|████████████████████████████████████████████████████████████████████████████████████▋                                           | 6444/9740 [00:06<00:03, 1090.69it/s] 67%|██████████████████████████████████████████████████████████████████████████████████████▏                                         | 6554/9740 [00:06<00:02, 1091.24it/s] 68%|███████████████████████████████████████████████████████████████████████████████████████▌                                        | 6664/9740 [00:07<00:02, 1081.26it/s] 70%|█████████████████████████████████████████████████████████████████████████████████████████                                       | 6773/9740 [00:07<00:02, 1083.82it/s] 71%|██████████████████████████████████████████████████████████████████████████████████████████▍                                     | 6884/9740 [00:07<00:02, 1089.80it/s] 72%|███████████████████████████████████████████████████████████████████████████████████████████▉                                    | 6994/9740 [00:07<00:02, 1091.57it/s] 73%|█████████████████████████████████████████████████████████████████████████████████████████████▎                                  | 7105/9740 [00:07<00:02, 1094.86it/s] 74%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                 | 7215/9740 [00:07<00:02, 1095.86it/s] 75%|████████████████████████████████████████████████████████████████████████████████████████████████▎                               | 7325/9740 [00:07<00:02, 1094.35it/s] 76%|█████████████████████████████████████████████████████████████████████████████████████████████████▋                              | 7435/9740 [00:07<00:02, 1095.98it/s] 77%|███████████████████████████████████████████████████████████████████████████████████████████████████▏                            | 7545/9740 [00:07<00:02, 1051.80it/s] 79%|████████████████████████████████████████████████████████████████████████████████████████████████████▌                           | 7652/9740 [00:07<00:01, 1055.15it/s] 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████▉                          | 7761/9740 [00:08<00:01, 1064.90it/s] 81%|███████████████████████████████████████████████████████████████████████████████████████████████████████▍                        | 7871/9740 [00:08<00:01, 1075.09it/s] 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████▉                       | 7981/9740 [00:08<00:01, 1081.69it/s] 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▎                     | 8092/9740 [00:08<00:01, 1088.40it/s] 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▊                    | 8202/9740 [00:08<00:01, 1091.44it/s] 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                  | 8312/9740 [00:08<00:01, 1092.99it/s] 86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                 | 8423/9740 [00:08<00:01, 1095.19it/s] 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏               | 8533/9740 [00:08<00:01, 1090.79it/s] 89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌              | 8643/9740 [00:08<00:01, 1090.96it/s] 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████             | 8754/9740 [00:08<00:00, 1094.10it/s] 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍           | 8864/9740 [00:09<00:00, 1093.57it/s] 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉          | 8975/9740 [00:09<00:00, 1095.62it/s] 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍        | 9085/9740 [00:09<00:00, 1094.77it/s] 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊       | 9196/9740 [00:09<00:00, 1097.36it/s] 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎     | 9306/9740 [00:09<00:00, 1097.08it/s] 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊    | 9417/9740 [00:09<00:00, 1098.48it/s] 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  | 9527/9740 [00:09<00:00, 1096.48it/s] 99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋ | 9637/9740 [00:09<00:00, 1095.45it/s]100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9740/9740 [00:09<00:00, 986.90it/s]
Load End
Num instances: 800
Loading checkpoint shards:   0%|                                                                                                                     | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                                                                                     | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                                                                                     | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                                                                                     | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|████████████████████████████████████▎                                                                        | 1/3 [00:04<00:09,  4.99s/it]Loading checkpoint shards:  33%|████████████████████████████████████▎                                                                        | 1/3 [00:05<00:10,  5.14s/it]Loading checkpoint shards:  33%|████████████████████████████████████▎                                                                        | 1/3 [00:05<00:11,  5.53s/it]Loading checkpoint shards:  33%|████████████████████████████████████▎                                                                        | 1/3 [00:05<00:11,  5.67s/it]Loading checkpoint shards:  67%|████████████████████████████████████████████████████████████████████████▋                                    | 2/3 [00:10<00:05,  5.09s/it]Loading checkpoint shards:  67%|████████████████████████████████████████████████████████████████████████▋                                    | 2/3 [00:10<00:05,  5.22s/it]Loading checkpoint shards:  67%|████████████████████████████████████████████████████████████████████████▋                                    | 2/3 [00:11<00:05,  5.68s/it]Loading checkpoint shards:  67%|████████████████████████████████████████████████████████████████████████▋                                    | 2/3 [00:11<00:05,  5.64s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.48s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.64s/it]
[2023-08-07 15:07:47,457] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.60s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.76s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:15<00:00,  4.81s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.04s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.02s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.18s/it]
[2023-08-07 15:07:59,901] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-07 15:07:59,902] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-07 15:07:59,903] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-07 15:07:59,903] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-07 15:07:59,903] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-07 15:07:59,903] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-07 15:07:59,903] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-07 15:07:59,903] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-07 15:07:59,903] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-07 15:07:59,903] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-07 15:07:59,903] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-07 15:07:59,903] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f3e8342dc10>
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-07 15:07:59,904] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-07 15:07:59,905] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-07 15:07:59,905] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-07 15:07:59,905] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f3e8342d2b0>
[2023-08-07 15:07:59,905] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-07 15:07:59,905] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-07 15:07:59,905] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-07 15:07:59,905] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-07 15:07:59,905] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-07 15:07:59,905] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-07 15:07:59,905] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-07 15:07:59,905] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-07 15:07:59,905] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-07 15:07:59,905] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-07 15:07:59,905] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-07 15:07:59,905] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-07 15:07:59,905] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-07 15:07:59,905] [INFO] [config.py:1012:print]   train_batch_size ............. 32
[2023-08-07 15:07:59,905] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  8
[2023-08-07 15:07:59,905] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-07 15:07:59,905] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-07 15:07:59,905] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-07 15:07:59,905] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-07 15:07:59,905] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-07 15:07:59,905] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-07 15:07:59,905] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-07 15:07:59,906] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 8, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.3558828830718994 seconds
Loading extension module utils...
Time to load utils op: 0.4044766426086426 seconds
Loading extension module utils...
Time to load utils op: 0.30416440963745117 seconds
Loading extension module utils...
Time to load utils op: 0.3040790557861328 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Evaluating commonsenseqa :   0%|                                                                                                                    | 0/25 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following multiple choice question.

### Demonstration:Input: He fantasied about getting a what while driving to work and the pros and cons of the extra responsibilities and benefits? Choices:  A: new car B: promotion C: boredom D: impatience E: pressure
Rationales: 1. The question is about someone who is fantasizing about something while driving to work. This person is also considering the pros and cons of the extra responsibilities and benefits. This helps narrow down the choices to something that would involve extra responsibilities and benefits.
   
2. Option A: A new car does not involve extra responsibilities and benefits. The responsibilities and benefits of a car remain the same, regardless of whether it's new or old. Hence, this option is incorrect.

3. Option B: A promotion at work would definitely involve extra responsibilities. It would also come with benefits, such as a higher salary or more influence within the company. Hence, this option fits the criteria mentioned in the question.

4. Option C: Boredom does not involve extra responsibilities and benefits. Hence, this option is incorrect.

5. Option D: Impatience does not involve extra responsibilities and benefits. Hence, this option is incorrect.

6. Option E: Pressure does not offer benefits, although it might involve extra responsibilities. However, considering the context of the question, it's unlikely that someone would fantasize about having more pressure. Hence, this option is incorrect.

7. Therefore, by process of elimination and by matching the criteria given in the question to the options, the correct answer is B: promotion.
Answer: B: promotion

### Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid

### Response:
############### End ###############
Evaluating commonsenseqa :   4%|████▎                                                                                                       | 1/25 [01:17<31:01, 77.58s/it]Evaluating commonsenseqa :   8%|████████▋                                                                                                   | 2/25 [02:34<29:33, 77.11s/it]Evaluating commonsenseqa :  12%|████████████▉                                                                                               | 3/25 [03:50<28:05, 76.60s/it]Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 136, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 114, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/minillm/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/minillm/transformers/src/transformers/generation/utils.py", line 2484, in sample
    outputs = self(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ylu130/workspace/minillm/transformers/src/transformers/models/llama/modeling_llama.py", line 727, in forward
    outputs = self.model(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ylu130/workspace/minillm/transformers/src/transformers/models/llama/modeling_llama.py", line 617, in forward
    layer_outputs = decoder_layer(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ylu130/workspace/minillm/transformers/src/transformers/models/llama/modeling_llama.py", line 328, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ylu130/workspace/minillm/transformers/src/transformers/models/llama/modeling_llama.py", line 245, in forward
    value_states = torch.cat([past_key_value[1], value_states], dim=2)
RuntimeError: CUDA out of memory. Tried to allocate 158.00 MiB (GPU 2; 47.54 GiB total capacity; 41.65 GiB already allocated; 75.88 MiB free; 46.33 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 374005 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 374006 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 374008 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 2 (pid: 374007) of binary: /home/ylu130/.conda/envs/distllm/bin/python
Traceback (most recent call last):
  File "/home/ylu130/.conda/envs/distllm/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/run.py", line 761, in main
    run(args)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/ylu130/workspace/in-context-generalization/inference.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-08-07_15:12:44
  host      : ia1.wse.jhu.edu
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 374007)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2113 /home/ylu130/workspace/in-context-generalization/inference.py --model-name llama2-7b --model-type llama --model-path /scratch/ylu130/model/llama-2-7b --n-gpu 4 --is-opensource --data-name commonsenseqa --num-eval 800 --num-workers 0 --save /home/ylu130/workspace/in-context-generalization/results --do-sample --top-k 50 --top-p 1 --temperature 1 --deepspeed --deepspeed_config /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json --batch-size 8 --seed 42 --data-dir /scratch/ylu130/processed_data/commonsenseqa/n2-seed42-rationalesTrue --rationales --num-in-domain 2
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to /home/ylu130/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
[nltk_data]   Package punkt is already up-to-date!
using world size: 4
[2023-08-07 15:12:49,480] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_name ................... llama2-7b
  model_type ................... llama
  model_path ................... /scratch/ylu130/model/llama-2-7b
  n_gpu ........................ 4
  n_nodes ...................... 1
  is_opensource ................ True
  model_parallel ............... False
  model_parallel_size .......... None
  data_name .................... commonsenseqa
  data_dir ..................... /scratch/ylu130/processed_data/commonsenseqa/n2-seed42-rationalesTrue
  processed_data_dir ........... None
  num_eval ..................... 800
  num_in_domain ................ 2
  num_out_domain ............... None
  cross ........................ False
  num_workers .................. 0
  max_prompt_length ............ 2048
  max_length ................... 512
  save ......................... /home/ylu130/workspace/in-context-generalization/results/llama2-7b/commonsenseqa/t1-m512-i2-rTrue
  rationales ................... True
  top_k ........................ 50
  top_p ........................ 1.0
  do_sample .................... True
  temperature .................. 1.0
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  gradient_accumulation_steps .. 1
  batch_size ................... 8
  clip_grad .................... 1.0
  seed ......................... 42
  deepspeed .................... True
  deepspeed_config ............. /home/ylu130/workspace/in-context-generalization/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  local_rank ................... 0
  rank ......................... 0
  world_size ................... 4
Loading Data
  0%|                                                                                                                                             | 0/9739 [00:00<?, ?it/s]  0%|▍                                                                                                                                  | 29/9739 [00:00<00:33, 289.63it/s]  1%|█▎                                                                                                                                | 100/9739 [00:00<00:18, 534.41it/s]  2%|██                                                                                                                                | 154/9739 [00:00<00:18, 517.33it/s]  2%|██▋                                                                                                                               | 206/9739 [00:00<00:18, 502.59it/s]  3%|███▍                                                                                                                              | 257/9739 [00:00<00:19, 495.74it/s]  3%|████                                                                                                                              | 307/9739 [00:00<00:19, 471.71it/s]  4%|████▉                                                                                                                             | 370/9739 [00:00<00:18, 518.53it/s]  4%|█████▋                                                                                                                            | 423/9739 [00:00<00:19, 489.31it/s]  5%|██████▎                                                                                                                           | 473/9739 [00:00<00:19, 485.31it/s]  5%|██████▉                                                                                                                           | 523/9739 [00:01<00:18, 488.87it/s]  6%|███████▋                                                                                                                          | 574/9739 [00:01<00:18, 492.34it/s]  6%|████████▎                                                                                                                         | 624/9739 [00:01<00:18, 489.16it/s]  7%|████████▉                                                                                                                         | 674/9739 [00:01<00:19, 472.73it/s]  7%|█████████▋                                                                                                                        | 725/9739 [00:01<00:18, 480.70it/s]  8%|██████████▎                                                                                                                       | 776/9739 [00:01<00:18, 487.11it/s]  8%|███████████                                                                                                                       | 827/9739 [00:01<00:18, 491.91it/s]  9%|███████████▋                                                                                                                      | 878/9739 [00:01<00:17, 495.29it/s] 10%|████████████▍                                                                                                                     | 928/9739 [00:01<00:17, 495.69it/s] 10%|█████████████                                                                                                                     | 979/9739 [00:01<00:17, 497.56it/s] 11%|█████████████▋                                                                                                                   | 1030/9739 [00:02<00:17, 498.67it/s] 11%|██████████████▎                                                                                                                  | 1081/9739 [00:02<00:17, 500.33it/s] 12%|██████████████▉                                                                                                                  | 1132/9739 [00:02<00:17, 498.71it/s] 12%|███████████████▋                                                                                                                 | 1183/9739 [00:02<00:17, 499.36it/s] 13%|████████████████▎                                                                                                                | 1233/9739 [00:02<00:17, 499.05it/s] 13%|█████████████████                                                                                                                | 1284/9739 [00:02<00:16, 499.51it/s] 14%|█████████████████▋                                                                                                               | 1335/9739 [00:02<00:16, 499.80it/s] 14%|██████████████████▎                                                                                                              | 1385/9739 [00:02<00:16, 498.44it/s] 15%|███████████████████                                                                                                              | 1435/9739 [00:02<00:16, 498.77it/s] 15%|███████████████████▋                                                                                                             | 1486/9739 [00:03<00:16, 499.25it/s] 16%|████████████████████▎                                                                                                            | 1536/9739 [00:03<00:16, 499.08it/s] 16%|█████████████████████                                                                                                            | 1586/9739 [00:03<00:16, 497.97it/s] 17%|█████████████████████▋                                                                                                           | 1637/9739 [00:03<00:16, 499.04it/s] 17%|██████████████████████▎                                                                                                          | 1688/9739 [00:03<00:16, 499.92it/s] 18%|███████████████████████                                                                                                          | 1739/9739 [00:03<00:15, 500.13it/s] 18%|███████████████████████▋                                                                                                         | 1790/9739 [00:03<00:15, 500.54it/s] 19%|████████████████████████▍                                                                                                        | 1841/9739 [00:03<00:16, 486.91it/s] 19%|█████████████████████████                                                                                                        | 1891/9739 [00:03<00:15, 490.61it/s] 20%|█████████████████████████▋                                                                                                       | 1941/9739 [00:03<00:15, 493.09it/s] 20%|██████████████████████████▍                                                                                                      | 1992/9739 [00:04<00:15, 495.34it/s] 21%|███████████████████████████▏                                                                                                     | 2056/9739 [00:04<00:14, 537.88it/s] 22%|████████████████████████████▏                                                                                                    | 2131/9739 [00:04<00:12, 598.94it/s] 23%|█████████████████████████████▏                                                                                                   | 2206/9739 [00:04<00:11, 643.05it/s] 23%|██████████████████████████████▏                                                                                                  | 2280/9739 [00:04<00:11, 671.83it/s] 24%|███████████████████████████████▏                                                                                                 | 2355/9739 [00:04<00:10, 694.15it/s] 25%|████████████████████████████████▏                                                                                                | 2430/9739 [00:04<00:10, 710.76it/s] 26%|█████████████████████████████████▏                                                                                               | 2502/9739 [00:04<00:10, 711.85it/s] 26%|██████████████████████████████████▏                                                                                              | 2577/9739 [00:04<00:09, 721.38it/s] 27%|███████████████████████████████████▏                                                                                             | 2652/9739 [00:04<00:09, 729.10it/s] 28%|████████████████████████████████████                                                                                             | 2726/9739 [00:05<00:09, 731.73it/s] 29%|█████████████████████████████████████                                                                                            | 2800/9739 [00:05<00:10, 653.59it/s] 29%|█████████████████████████████████████▉                                                                                           | 2867/9739 [00:05<00:11, 597.47it/s] 30%|██████████████████████████████████████▊                                                                                          | 2929/9739 [00:05<00:12, 561.93it/s] 31%|███████████████████████████████████████▌                                                                                         | 2987/9739 [00:05<00:12, 541.54it/s] 31%|████████████████████████████████████████▎                                                                                        | 3043/9739 [00:05<00:12, 527.59it/s] 32%|█████████████████████████████████████████                                                                                        | 3097/9739 [00:05<00:12, 513.86it/s] 32%|█████████████████████████████████████████▋                                                                                       | 3149/9739 [00:05<00:12, 507.39it/s] 33%|██████████████████████████████████████████▍                                                                                      | 3200/9739 [00:05<00:13, 500.23it/s] 33%|███████████████████████████████████████████                                                                                      | 3251/9739 [00:06<00:13, 495.90it/s] 34%|███████████████████████████████████████████▋                                                                                     | 3301/9739 [00:06<00:13, 493.97it/s] 34%|████████████████████████████████████████████▍                                                                                    | 3351/9739 [00:06<00:12, 493.08it/s] 35%|█████████████████████████████████████████████                                                                                    | 3401/9739 [00:06<00:12, 491.73it/s] 35%|█████████████████████████████████████████████▋                                                                                   | 3451/9739 [00:06<00:12, 491.90it/s] 36%|██████████████████████████████████████████████▎                                                                                  | 3501/9739 [00:06<00:12, 489.59it/s] 36%|███████████████████████████████████████████████                                                                                  | 3551/9739 [00:06<00:12, 490.18it/s] 37%|███████████████████████████████████████████████▋                                                                                 | 3601/9739 [00:06<00:12, 490.32it/s] 37%|████████████████████████████████████████████████▎                                                                                | 3651/9739 [00:06<00:12, 489.06it/s] 38%|█████████████████████████████████████████████████                                                                                | 3700/9739 [00:07<00:12, 488.10it/s] 39%|█████████████████████████████████████████████████▋                                                                               | 3750/9739 [00:07<00:12, 489.71it/s] 39%|██████████████████████████████████████████████████▎                                                                              | 3800/9739 [00:07<00:12, 490.48it/s] 40%|███████████████████████████████████████████████████▏                                                                             | 3866/9739 [00:07<00:10, 539.57it/s] 40%|████████████████████████████████████████████████████▏                                                                            | 3939/9739 [00:07<00:09, 595.00it/s] 41%|█████████████████████████████████████████████████████▏                                                                           | 4014/9739 [00:07<00:08, 638.81it/s] 42%|██████████████████████████████████████████████████████▏                                                                          | 4088/9739 [00:07<00:08, 667.39it/s] 43%|███████████████████████████████████████████████████████▏                                                                         | 4163/9739 [00:07<00:08, 690.43it/s] 44%|████████████████████████████████████████████████████████▏                                                                        | 4238/9739 [00:07<00:07, 705.72it/s] 44%|█████████████████████████████████████████████████████████▏                                                                       | 4313/9739 [00:07<00:07, 716.16it/s] 45%|██████████████████████████████████████████████████████████                                                                       | 4387/9739 [00:08<00:07, 723.00it/s] 46%|███████████████████████████████████████████████████████████                                                                      | 4462/9739 [00:08<00:07, 728.24it/s] 47%|████████████████████████████████████████████████████████████                                                                     | 4535/9739 [00:08<00:07, 679.14it/s] 47%|█████████████████████████████████████████████████████████████                                                                    | 4610/9739 [00:08<00:07, 698.27it/s] 48%|██████████████████████████████████████████████████████████████                                                                   | 4685/9739 [00:08<00:07, 712.15it/s] 49%|███████████████████████████████████████████████████████████████                                                                  | 4757/9739 [00:08<00:10, 483.85it/s] 50%|████████████████████████████████████████████████████████████████                                                                 | 4832/9739 [00:08<00:09, 541.63it/s] 50%|████████████████████████████████████████████████████████████████▉                                                                | 4907/9739 [00:08<00:08, 590.17it/s] 51%|█████████████████████████████████████████████████████████████████▉                                                               | 4981/9739 [00:09<00:07, 628.01it/s] 52%|██████████████████████████████████████████████████████████████████▉                                                              | 5056/9739 [00:09<00:07, 659.97it/s] 53%|███████████████████████████████████████████████████████████████████▉                                                             | 5129/9739 [00:09<00:06, 678.48it/s] 53%|████████████████████████████████████████████████████████████████████▉                                                            | 5203/9739 [00:09<00:06, 694.76it/s] 54%|█████████████████████████████████████████████████████████████████████▉                                                           | 5278/9739 [00:09<00:06, 708.84it/s] 55%|██████████████████████████████████████████████████████████████████████▉                                                          | 5353/9739 [00:09<00:06, 719.77it/s] 56%|███████████████████████████████████████████████████████████████████████▉                                                         | 5428/9739 [00:09<00:05, 725.94it/s] 56%|████████████████████████████████████████████████████████████████████████▉                                                        | 5502/9739 [00:09<00:05, 729.03it/s] 57%|█████████████████████████████████████████████████████████████████████████▉                                                       | 5580/9739 [00:09<00:05, 741.87it/s] 58%|██████████████████████████████████████████████████████████████████████████▉                                                      | 5657/9739 [00:09<00:05, 749.18it/s] 59%|███████████████████████████████████████████████████████████████████████████▉                                                     | 5735/9739 [00:10<00:05, 757.49it/s] 60%|████████████████████████████████████████████████████████████████████████████▉                                                    | 5813/9739 [00:10<00:05, 764.10it/s] 60%|██████████████████████████████████████████████████████████████████████████████                                                   | 5891/9739 [00:10<00:05, 765.97it/s] 61%|███████████████████████████████████████████████████████████████████████████████                                                  | 5970/9739 [00:10<00:04, 770.39it/s] 62%|████████████████████████████████████████████████████████████████████████████████                                                 | 6049/9739 [00:10<00:04, 773.32it/s] 63%|█████████████████████████████████████████████████████████████████████████████████▏                                               | 6127/9739 [00:10<00:04, 770.49it/s] 64%|██████████████████████████████████████████████████████████████████████████████████▏                                              | 6205/9739 [00:10<00:04, 772.80it/s] 65%|███████████████████████████████████████████████████████████████████████████████████▏                                             | 6283/9739 [00:10<00:04, 746.31it/s] 65%|████████████████████████████████████████████████████████████████████████████████████▏                                            | 6360/9739 [00:10<00:04, 752.66it/s] 66%|█████████████████████████████████████████████████████████████████████████████████████▎                                           | 6438/9739 [00:10<00:04, 760.02it/s] 67%|██████████████████████████████████████████████████████████████████████████████████████▎                                          | 6516/9739 [00:11<00:04, 764.01it/s] 68%|███████████████████████████████████████████████████████████████████████████████████████▎                                         | 6593/9739 [00:11<00:04, 765.52it/s] 69%|████████████████████████████████████████████████████████████████████████████████████████▍                                        | 6672/9739 [00:11<00:03, 770.01it/s] 69%|█████████████████████████████████████████████████████████████████████████████████████████▍                                       | 6750/9739 [00:11<00:03, 771.58it/s] 70%|██████████████████████████████████████████████████████████████████████████████████████████▍                                      | 6828/9739 [00:11<00:03, 771.23it/s] 71%|███████████████████████████████████████████████████████████████████████████████████████████▍                                     | 6906/9739 [00:11<00:03, 772.08it/s] 72%|████████████████████████████████████████████████████████████████████████████████████████████▌                                    | 6984/9739 [00:11<00:03, 773.68it/s] 73%|█████████████████████████████████████████████████████████████████████████████████████████████▌                                   | 7062/9739 [00:11<00:03, 772.60it/s] 73%|██████████████████████████████████████████████████████████████████████████████████████████████▌                                  | 7140/9739 [00:11<00:03, 772.73it/s] 74%|███████████████████████████████████████████████████████████████████████████████████████████████▌                                 | 7218/9739 [00:11<00:03, 770.28it/s] 75%|████████████████████████████████████████████████████████████████████████████████████████████████▋                                | 7296/9739 [00:12<00:03, 771.76it/s] 76%|█████████████████████████████████████████████████████████████████████████████████████████████████▋                               | 7374/9739 [00:12<00:03, 773.41it/s] 77%|██████████████████████████████████████████████████████████████████████████████████████████████████▋                              | 7452/9739 [00:12<00:03, 744.35it/s] 77%|███████████████████████████████████████████████████████████████████████████████████████████████████▋                             | 7530/9739 [00:12<00:02, 752.80it/s] 78%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                            | 7608/9739 [00:12<00:02, 760.01it/s] 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████▊                           | 7685/9739 [00:12<00:02, 760.72it/s] 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████▊                          | 7763/9739 [00:12<00:02, 764.98it/s] 81%|███████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 7840/9739 [00:12<00:02, 764.30it/s] 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 7917/9739 [00:12<00:02, 765.19it/s] 82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▉                       | 7995/9739 [00:12<00:02, 767.81it/s] 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▉                      | 8073/9739 [00:13<00:02, 769.82it/s] 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▉                     | 8151/9739 [00:13<00:02, 770.69it/s] 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                    | 8229/9739 [00:13<00:01, 770.01it/s] 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████                   | 8307/9739 [00:13<00:01, 770.80it/s] 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████                  | 8385/9739 [00:13<00:01, 768.05it/s] 87%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████                 | 8463/9739 [00:13<00:01, 768.81it/s] 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏               | 8541/9739 [00:13<00:01, 769.11it/s] 88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏              | 8618/9739 [00:13<00:01, 767.48it/s] 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏             | 8696/9739 [00:13<00:01, 769.59it/s] 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏            | 8774/9739 [00:13<00:01, 770.12it/s] 91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎           | 8852/9739 [00:14<00:01, 768.21it/s] 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎          | 8930/9739 [00:14<00:01, 768.85it/s] 92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎         | 9007/9739 [00:14<00:00, 769.15it/s] 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎        | 9084/9739 [00:14<00:00, 766.97it/s] 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 9162/9739 [00:14<00:00, 768.48it/s] 95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍      | 9239/9739 [00:14<00:00, 768.26it/s] 96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍     | 9316/9739 [00:14<00:00, 768.38it/s] 96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍    | 9394/9739 [00:14<00:00, 769.54it/s] 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍   | 9471/9739 [00:14<00:00, 769.07it/s] 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍  | 9548/9739 [00:15<00:00, 757.33it/s] 99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍ | 9625/9739 [00:15<00:00, 760.49it/s]100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌| 9703/9739 [00:15<00:00, 763.89it/s]100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9739/9739 [00:15<00:00, 638.52it/s]
Load End
Num instances: 800
Loading checkpoint shards:   0%|                                                                                                                     | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                                                                                     | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                                                                                     | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                                                                                     | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|████████████████████████████████████▎                                                                        | 1/3 [00:04<00:09,  4.89s/it]Loading checkpoint shards:  33%|████████████████████████████████████▎                                                                        | 1/3 [00:05<00:10,  5.35s/it]Loading checkpoint shards:  33%|████████████████████████████████████▎                                                                        | 1/3 [00:06<00:12,  6.08s/it]Loading checkpoint shards:  33%|████████████████████████████████████▎                                                                        | 1/3 [00:06<00:12,  6.40s/it]Loading checkpoint shards:  67%|████████████████████████████████████████████████████████████████████████▋                                    | 2/3 [00:09<00:04,  4.81s/it]Loading checkpoint shards:  67%|████████████████████████████████████████████████████████████████████████▋                                    | 2/3 [00:11<00:05,  5.55s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.35s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.48s/it]
Loading checkpoint shards:  67%|████████████████████████████████████████████████████████████████████████▋                                    | 2/3 [00:11<00:05,  5.83s/it]Loading checkpoint shards:  67%|████████████████████████████████████████████████████████████████████████▋                                    | 2/3 [00:12<00:06,  6.12s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:15<00:00,  4.99s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.12s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:16<00:00,  5.13s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:16<00:00,  5.34s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:16<00:00,  5.33s/it]Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:16<00:00,  5.57s/it]
[2023-08-07 15:13:58,947] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown
[2023-08-07 15:14:11,728] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-07 15:14:11,729] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:
[2023-08-07 15:14:11,730] [INFO] [config.py:1012:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-08-07 15:14:11,730] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-08-07 15:14:11,730] [INFO] [config.py:1012:print]   amp_enabled .................. False
[2023-08-07 15:14:11,730] [INFO] [config.py:1012:print]   amp_params ................... False
[2023-08-07 15:14:11,730] [INFO] [config.py:1012:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-08-07 15:14:11,730] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False
[2023-08-07 15:14:11,730] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False
[2023-08-07 15:14:11,730] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True
[2023-08-07 15:14:11,730] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False
[2023-08-07 15:14:11,730] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f89863bcc10>
[2023-08-07 15:14:11,730] [INFO] [config.py:1012:print]   communication_data_type ...... None
[2023-08-07 15:14:11,730] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-08-07 15:14:11,730] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   disable_allgather ............ False
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   dump_state ................... False
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'min_scale': 1}
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   elasticity_enabled ........... False
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   fp16_enabled ................. True
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   global_rank .................. 0
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   gradient_clipping ............ 1.0
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 2048
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   loss_scale ................... 0
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   memory_breakdown ............. False
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f89863bc2b0>
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   optimizer_name ............... None
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   optimizer_params ............. None
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   pld_enabled .................. False
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   pld_params ................... False
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   prescale_gradients ........... False
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   scheduler_name ............... None
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   scheduler_params ............. None
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   sparse_attention ............. None
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   steps_per_print .............. 1
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   train_batch_size ............. 32
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  8
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   use_node_local_storage ....... False
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   world_size ................... 4
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  True
[2023-08-07 15:14:11,731] [INFO] [config.py:1012:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-08-07 15:14:11,732] [INFO] [config.py:1012:print]   zero_enabled ................. False
[2023-08-07 15:14:11,732] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 0
[2023-08-07 15:14:11,732] [INFO] [config.py:997:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 8, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1
}
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Using /home/ylu130/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...
Emitting ninja build file /home/ylu130/.cache/torch_extensions/py39_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.42887282371520996 seconds
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   12916 MB |   12916 MB |   12916 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      64 MB |      64 MB |      64 MB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   12918 MB |   12918 MB |   12918 MB |       0 B  |
|       from large pool |   12852 MB |   12852 MB |   12852 MB |       0 B  |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |
|       from small pool |    1512 KB |    2047 KB |   34815 KB |   33303 KB |
|---------------------------------------------------------------------------|
| Allocations           |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     387    |     387    |     387    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |     161    |     161    |     161    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     259    |     259    |     259    |       0    |
|       from large pool |     226    |     226    |     226    |       0    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       2    |      33    |      31    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |       2    |      33    |      31    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Loading extension module utils...
Loading extension module utils...
Time to load utils op: 0.3041994571685791 seconds
Time to load utils op: 0.40457844734191895 seconds
Evaluating commonsenseqa :   0%|                                                                                                                    | 0/25 [00:00<?, ?it/s]############### Example ###############
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:Answer the following multiple choice question.

### Demonstration:Input: He fantasied about getting a what while driving to work and the pros and cons of the extra responsibilities and benefits? Choices:  A: new car B: promotion C: boredom D: impatience E: pressure
Rationales: Step 1: Identify the key terms in the question. Here, the protagonist is fantasizing while driving to work about something that comes with both additional responsibilities and benefits.

Step 2: Consider each answer choice in relation to the key terms. 

Choice A: A new car may be a desire, but it does not inherently carry extra responsibilities and benefits.

Choice B: A promotion at work would logically involve both additional responsibilities and benefits, fitting the description in the question.

Choice C: Boredom is a state of mind, not something one would fantasize about on the way to work, and it does not involve responsibilities or benefits. 

Choice D: Impatience is an emotion, not a situation one would fantasize about. Additionally, it doesn't involve responsibilities or benefits. 

Choice E: Pressure, like impatience, is more of a feeling or situation one might experience but not fantasize about. It also doesn't inherently have responsibilities or benefits.

Step 3: Choose the answer that best fits the key terms in the question. In this case, the answer is B: promotion.
Answer: B: promotion

Input: He was good at traditional science but excelled at social science, his favorite subject was what? Choices:  A: geography B: history studies C: math D: religion E: dancing
Rationales: Step 1: The question tells us that the person is good at traditional science but excels at social science. That means we should look for a subject that falls under the category of social science. 

Step 2: From the choices given, geography, history studies, and religion can be considered as social sciences. Math and dancing are not social sciences, so we can eliminate choices C and E. 

Step 3: Although geography and religion are part of social sciences, the question indicates that "his favorite subject was what". We're looking for a subject he would likely excel at, since it's his favorite.

Step 4: The question does not provide any information suggesting the person has a particular interest in geography or religion.

Step 5: By default, the answer is B: history studies, as it's the only remaining social science subject among the choices.
Answer: B: history studies

### Input:The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? Choices:  A: ignore B: enforce C: authoritarian D: yell at E: avoid

### Response:
############### End ###############
Loading extension module utils...
Time to load utils op: 0.4045298099517822 seconds
Evaluating commonsenseqa :   4%|████▎                                                                                                       | 1/25 [01:12<28:50, 72.10s/it]Evaluating commonsenseqa :   8%|████████▋                                                                                                   | 2/25 [02:23<27:28, 71.68s/it]^CTraceback (most recent call last):
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
Evaluating commonsenseqa :   8%|████████▌                                                                                                  | 2/25 [03:20<38:29, 100.43s/it]
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 136, in evaluate_main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 136, in evaluate_main
Traceback (most recent call last):
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 114, in run_model
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 114, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/minillm/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/minillm/transformers/src/transformers/generation/utils.py", line 1454, in generate
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 136, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 114, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
        return self.sample(return func(*args, **kwargs)

  File "/home/ylu130/workspace/minillm/transformers/src/transformers/generation/utils.py", line 2509, in sample
  File "/home/ylu130/workspace/minillm/transformers/src/transformers/generation/utils.py", line 1454, in generate
WARNING:torch.distributed.elastic.agent.server.api:Received 2 death signal, shutting down workers
    return self.sample(
  File "/home/ylu130/workspace/minillm/transformers/src/transformers/generation/utils.py", line 2484, in sample
    next_token_scores = logits_processor(input_ids, next_token_logits)
  File "/home/ylu130/workspace/minillm/transformers/src/transformers/generation/logits_process.py", line 92, in __call__
    scores = processor(input_ids, scores)
  File "/home/ylu130/workspace/minillm/transformers/src/transformers/generation/logits_process.py", line 487, in __call__
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 375034 closing signal SIGINT
    return self.sample(
  File "/home/ylu130/workspace/minillm/transformers/src/transformers/generation/utils.py", line 2484, in sample
    banned_batch_tokens = _calc_banned_ngram_tokens(self.ngram_size, input_ids, num_batch_hypotheses, cur_len)
  File "/home/ylu130/workspace/minillm/transformers/src/transformers/generation/logits_process.py", line 460, in _calc_banned_ngram_tokens
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    generated_ngrams = _get_ngrams(ngram_size, prev_input_ids, num_hypos)
  File "/home/ylu130/workspace/minillm/transformers/src/transformers/generation/logits_process.py", line 441, in _get_ngrams
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 375035 closing signal SIGINT
    outputs = self(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
KeyboardInterrupt    return forward_call(*input, **kwargs)

  File "/home/ylu130/workspace/minillm/transformers/src/transformers/models/llama/modeling_llama.py", line 727, in forward
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 375036 closing signal SIGINT
    outputs = self.model(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 375037 closing signal SIGINT
    return forward_call(*input, **kwargs)
  File "/home/ylu130/workspace/minillm/transformers/src/transformers/models/llama/modeling_llama.py", line 727, in forward
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ylu130/workspace/minillm/transformers/src/transformers/models/llama/modeling_llama.py", line 617, in forward
    return forward_call(*input, **kwargs)
  File "/home/ylu130/workspace/minillm/transformers/src/transformers/models/llama/modeling_llama.py", line 617, in forward
    layer_outputs = decoder_layer(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    layer_outputs = decoder_layer(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ylu130/workspace/minillm/transformers/src/transformers/models/llama/modeling_llama.py", line 340, in forward
        hidden_states = self.post_attention_layernorm(hidden_states)return forward_call(*input, **kwargs)

  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
  File "/home/ylu130/workspace/minillm/transformers/src/transformers/models/llama/modeling_llama.py", line 328, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ylu130/workspace/minillm/transformers/src/transformers/models/llama/modeling_llama.py", line 118, in forward
    variance = hidden_states.to(torch.float32).pow(2).mean(-1, keepdim=True)
KeyboardInterrupt
    return forward_call(*input, **kwargs)
  File "/home/ylu130/workspace/minillm/transformers/src/transformers/models/llama/modeling_llama.py", line 249, in forward
    attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 125, in <module>
    main()
  File "/home/ylu130/workspace/in-context-generalization/inference.py", line 122, in main
    evaluate_main(args, tokenizer, model, dataset["test"], device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 136, in evaluate_main
    lm_loss, query_ids, response_ids, rest_ids = run_model(args, tokenizer, model, dataset, device)
  File "/home/ylu130/workspace/in-context-generalization/inference_main.py", line 114, in run_model
    gen_out = model.generate(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/ylu130/workspace/minillm/transformers/src/transformers/generation/utils.py", line 1454, in generate
    return self.sample(
  File "/home/ylu130/workspace/minillm/transformers/src/transformers/generation/utils.py", line 2509, in sample
    next_token_scores = logits_processor(input_ids, next_token_logits)
  File "/home/ylu130/workspace/minillm/transformers/src/transformers/generation/logits_process.py", line 92, in __call__
    scores = processor(input_ids, scores)
  File "/home/ylu130/workspace/minillm/transformers/src/transformers/generation/logits_process.py", line 487, in __call__
    banned_batch_tokens = _calc_banned_ngram_tokens(self.ngram_size, input_ids, num_batch_hypotheses, cur_len)
  File "/home/ylu130/workspace/minillm/transformers/src/transformers/generation/logits_process.py", line 460, in _calc_banned_ngram_tokens
    generated_ngrams = _get_ngrams(ngram_size, prev_input_ids, num_hypos)
  File "/home/ylu130/workspace/minillm/transformers/src/transformers/generation/logits_process.py", line 437, in _get_ngrams
    gen_tokens = prev_input_ids[idx].tolist()
KeyboardInterrupt
^CWARNING:torch.distributed.elastic.multiprocessing.api:Sending process 375034 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 375035 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 375036 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 375037 closing signal SIGTERM
^CTraceback (most recent call last):
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = self._invoke_run(role)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 850, in _invoke_run
    time.sleep(monitor_interval)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 60, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 374965 got signal: 2

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 716, in run
    self._shutdown(e.sigval)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py", line 193, in _shutdown
    self._pcontext.close(death_sig)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 330, in close
    self._close(death_sig=death_sig, timeout=timeout)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 707, in _close
    handler.proc.wait(time_to_wait)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/subprocess.py", line 1189, in wait
    return self._wait(timeout=timeout)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/subprocess.py", line 1927, in _wait
    time.sleep(delay)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 60, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 374965 got signal: 2

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ylu130/.conda/envs/distllm/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/run.py", line 761, in main
    run(args)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 236, in launch_agent
    result = agent.run()
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 125, in wrapper
    result = f(*args, **kwargs)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 721, in run
    self._shutdown()
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py", line 193, in _shutdown
    self._pcontext.close(death_sig)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 330, in close
    self._close(death_sig=death_sig, timeout=timeout)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 707, in _close
    handler.proc.wait(time_to_wait)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/subprocess.py", line 1189, in wait
    return self._wait(timeout=timeout)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/subprocess.py", line 1927, in _wait
    time.sleep(delay)
  File "/home/ylu130/.conda/envs/distllm/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 60, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 374965 got signal: 2
^C